<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Design a streaming ELT pipeline to ingest real-time JSON events from a REST webhook into ADLS Gen2, apply schema drift tolerant transformations, store as Delta Lake tables on ADLS Gen2, and surface aggregates in Azure Synapse with Purview lineage. Explain how you would handle schema drift, versioned schemas, tombstone events, and how you would implement error handling, retry, and backpressure, including component choices for ingestion, processing, and governance?</title>
  <meta name="description" content="">
</head>
<body>
  <article data-pagefind-body>
    <h1 data-pagefind-meta="title">Design a streaming ELT pipeline to ingest real-time JSON events from a REST webhook into ADLS Gen2, apply schema drift tolerant transformations, store as Delta Lake tables on ADLS Gen2, and surface aggregates in Azure Synapse with Purview lineage. Explain how you would handle schema drift, versioned schemas, tombstone events, and how you would implement error handling, retry, and backpressure, including component choices for ingestion, processing, and governance?</h1>
    
    <div data-pagefind-filter="channel">azure-data-engineer</div>
    <div data-pagefind-filter="difficulty">intermediate</div>
    <div data-pagefind-filter="topic">General</div>
    
    <div data-pagefind-meta="channel" data-pagefind-meta-value="azure-data-engineer"></div>
    <div data-pagefind-meta="difficulty" data-pagefind-meta-value="intermediate"></div>
    <div data-pagefind-meta="id" data-pagefind-meta-value="q-7475"></div>
    
    <main>
      <section class="answer">
        
      </section>
      
      
      <section class="tags">
        <span>azure-data-engineer</span>
      </section>
      
      
      
      <section class="companies" data-pagefind-filter="company">
        <span>Anthropic</span> <span>OpenAI</span> <span>Snowflake</span>
      </section>
      
    </main>
  </article>
</body>
</html>