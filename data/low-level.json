{"questions":[{"id":"q-1177","question":"Scenario: a high-throughput edge service must enforce precise timeouts for thousands of connections. Design a lock-free, per-core timer wheel that manages up to 1,000,000 timers with microsecond granularity on a 4-socket server. API: add_timer(id, due_us, cb, ctx), cancel_timer(id), tick(). Requirements: no global locks, handle cancellation safely, cache-friendly layout, and crash-safe recovery. Include pseudo-code for add_timer, cancel_timer, and tick, plus a microbenchmark plan?","answer":"Use a two-tier, per-core timer wheel with microsecond granularity: a local wheel for near-term timers and a shared overflow queue feeding a global wheel. Timers are stored in per-core buckets to minim","explanation":"## Why This Is Asked\nTests ability to design lock-free, NUMA-friendly timeouts with tight latency budgets and predictable memory access patterns. The answer demonstrates practical trade-offs between per-core locality and a minimal global coordination path.\n\n## Key Concepts\n- Lock-free data structures and ABA avoidance\n- Per-core timer buckets and cache-line alignment\n- Two-tier timer wheels for short vs long timeouts\n- Safe cancellation via id-to-timer mapping and sequence counters\n- Crash-safe recovery implications (logs, id replay)\n\n## Code Example\n```cpp\n// skeleton structures (conceptual)\ntypedef struct timer {\n  uint64_t due;        // absolute microsecond timestamp\n  uint64_t id;         // unique identifier\n  void (*cb)(void*);   // callback\n  void *ctx;             // user data\n  struct timer *next;    // linked list within bucket\n} timer_t;\n\ntypedef struct timer_wheel {\n  // per-core buckets, each bucket is a lock-free list\n  bucket_t *buckets; // sized per wheel\n  // mapping from id -> timer for cancellation (lock-free)\n  atomic<uint64_t> active_id; // simplified placeholder\n} timer_wheel;\n\nvoid add_timer(timer_wheel* w, uint64_t due, uint64_t id, void (*cb)(void*), void* ctx);\nvoid cancel_timer(timer_wheel* w, uint64_t id);\nvoid tick(timer_wheel* w);\n```\n\n## Follow-up Questions\n- How would you verify correctness and latency under burst traffic and CPU contention?\n- How do you handle timer overflow, rebalancing across cores, and NUMA effects?","diagram":"flowchart TD\n  A[External Network Paths] --> B[Timer Wheel]\n  B --> C[Per-Core Buckets]\n  C --> D[Callbacks Execution]\n  D --> E[Reschedule or Cancel]\n  E --> B","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Robinhood","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:41:02.303Z","createdAt":"2026-01-13T03:41:02.303Z"},{"id":"q-1261","question":"Implement a cache-friendly transpose using tile-based approach for an N×N matrix with N a power of two. Provide a function to transpose A into B using 32×32 blocks, and a minimal test harness validating correctness. Explain how tiling reduces cache misses and how to pick block size relative to L1/L2 caches. Include a microbenchmark plan comparing with a naive transpose?","answer":"Use 32×32 tiling to keep working set small. For N×N float matrices A,B, loop br/bc in steps of 32 and copy B[c*N + r] = A[r*N + c] with r=br+i, c=bc+j. Add bounds checks for N not multiple of 32, use ","explanation":"## Why This Is Asked\nTests understanding of memory hierarchy and data locality by forcing cache-friendly tiling in a simple kernel.\n\n## Key Concepts\n- Tile size vs cache capacity; 2D blocking; stride-1 vs stride-N access patterns; bounds handling.\n- Prefetching to hide memory latency; ensure no aliasing via separate buffers.\n\n## Code Example\n```c\nvoid transpose_tiled(const float* A, float* B, int N) {\n  const int Bsz = 32;\n  for (int br = 0; br < N; br += Bsz) {\n    for (int bc = 0; bc < N; bc += Bsz) {\n      for (int i = 0; i < Bsz; ++i) {\n        int r = br + i;\n        if (r >= N) break;\n        for (int j = 0; j < Bsz; ++j) {\n          int c = bc + j;\n          if (c >= N) break;\n          B[c * N + r] = A[r * N + c];\n        }\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n- How to handle N not divisible by 32; impact on correctness and performance?\n- How would you adapt to double precision or non-square matrices?\n- Would you vectorize with AVX/NEON and what changes? How to measure speedup?","diagram":"flowchart TD\n  A[Start] --> B[Set N and matrices A,B]\n  B --> C[Choose block size 32]\n  C --> D[Perform tiled transpose]\n  D --> E[Validate results]\n","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:08.457Z","createdAt":"2026-01-13T07:26:08.457Z"},{"id":"q-2105","question":"Design and implement a NUMA-aware per-thread arena allocator in C for a 2-socket server. Features: per-core cache-line-aligned pools, 128-byte padding to prevent false sharing, fast paths for 8/16/32-byte blocks, per-size freelists, and a cross-thread deallocation quarantine. Provide API (init, alloc, free, destroy) plus a minimal test harness and a microbenchmark plan comparing intra- vs inter-NUMA performance against malloc?","answer":"Design and implement a NUMA-aware per-thread arena allocator in C for a 2-socket server. Each thread utilizes a cache-line-aligned pool with 128-byte padding to prevent false sharing, optimized fast paths for 8/16/32-byte blocks, per-size freelists, and a cross-thread deallocation quarantine. Provide a complete API (init, alloc, free, destroy) along with a minimal test harness and a microbenchmark plan comparing intra- versus inter-NUMA performance against malloc.","explanation":"## Why This Is Asked\nAssesses practical memory allocator design under NUMA, focusing on locality and contention.\n\n## Key Concepts\n- NUMA locality and thread affinity\n- Cache-line alignment and false sharing prevention\n- Small-object fast paths and freelists\n- Cross-thread deallocation quarantine\n- Microbenchmarking under intra- versus inter-NUMA loads\n\n## Code Example\n```c\ntypedef struct arena { /* per-thread data */ } arena_t;\nvoid* na_alloc(arena_t*, size_t);\nvoid na_free(arena_t*, void*);\nvoid na_init(arena_t*);\nvoid na_destroy(arena_t*);\n```\n\n## Follow-up Questions\n- How would you validate NUMA locality improvements?\n- What strategies would you use for load balancing across sockets?\n- How would you handle memory fragmentation in long-running applications?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Two Sigma","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T04:59:44.000Z","createdAt":"2026-01-15T02:18:37.781Z"},{"id":"q-2340","question":"Design and implement a tiny fixed-block allocator in C for a 64KB arena to serve 32-byte objects. Provide API: init_allocator(uint8_t* arena, size_t size), void* alloc32(), void free32(void*). Use an in-block free list (8-byte header) and 24-byte payload per block, with the arena head at offset 0. Explain alignment, fragmentation, and how it compares to malloc. Include a minimal test plan?","answer":"Initialize a 64KB arena with an 8-byte head at offset 0 and 32-byte blocks starting at offset 8. Each block uses an 8-byte header to store the next-free index and 24 bytes for payload (8-byte alignmen","explanation":"## Why This Is Asked\nTests low-level memory layout, inline freelist management, and predictable allocator behavior using minimal metadata.\n\n## Key Concepts\n- Fixed-block allocators and in-block freelists\n- Alignment guarantees for payload\n- Fragmentation and simple correctness tests\n\n## Code Example\n```javascript\n// sketch: structure and ops for the allocator\n```\n\n## Follow-up Questions\n- How would you extend for variable-sized blocks while preserving speed?\n- How would you add basic thread-safety without external allocators?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Meta","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T13:15:28.891Z","createdAt":"2026-01-15T13:15:28.891Z"},{"id":"q-2361","question":"Design a NUMA-aware fixed-size allocator in C++ for objects of 64 bytes, with per-NUMA-node free lists and a lightweight cross-node migration policy; describe structure, allocation/free, and how to avoid inter-node contention and false sharing; provide a small code sketch and a validation plan?","answer":"Per-NUMA allocator with per-node free lists (lock-free or atomics), each block stores next pointer; allocate uses local node list via CAS; if empty, steal from a remote node or fall back to a central ","explanation":"## Why This Is Asked\n\nThis question probes practical low-level memory management in NUMA systems, emphasizing locality, contention, and false sharing—key for latency-sensitive trading/analytics workloads.\n\n## Key Concepts\n\n- NUMA locality and per-node free lists\n- Lock-free/atomic free-list operations and ABA avoidance\n- Cross-node migration policies and migration costs\n- Cache-line alignment and false sharing avoidance\n- Validation: microbenchmarks with mixed-local/global allocations, perf measurements\n\n## Code Example\n\n```cpp\n// simplified per-node free-list CAS skeleton\n#include <atomic>\n\nstruct Node {\n  std::atomic<void*> head{nullptr};\n};\n\nvoid* alloc(Node& node) {\n  void* h = node.head.load(std::memory_order_acquire);\n  if (h) {\n    void* next = *(void**)h;\n    if (node.head.compare_exchange_weak(h, next, std::memory_order_acquire, std::memory_order_relaxed))\n      return h;\n  }\n  // fallback: steal from other node or central pool\n  return nullptr;\n}\n```\n\n## Follow-up Questions\n\n- How would you implement ABA protection and reclaim memory safely across NUMA nodes?\n- How would you measure cross-node traffic impact and optimize for a workload with hot/cold object lifetimes?","diagram":"flowchart TD\n  N0[NUMA Node 0] --> L0[Local Free List]\n  L0 --> A0[Allocate]\n  N0 --> R0[Remote Steal]\n  R0 --> A0\n  A0 --> F0[Free returns to local if possible]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T14:50:04.615Z","createdAt":"2026-01-15T14:50:04.615Z"},{"id":"q-2448","question":"Design a NUMA-aware, lock-free work-stealing deque with per-NUMA-node local queues and cross-node stealing to sustain high throughput on a 2-socket server. Provide per-slot layout, push/pop/steal pseudo-code with sequence counters, CAS, and memory fences; handle wrap-around; describe hazard pointers/epochs for lifetime management; discuss cache-line padding and validation under cross-NUMA contention?","answer":"Propose a NUMA-aware lock-free work-stealing deque with per-NUMA local queues and cross-node stealing to sustain high throughput on a 2-socket server. Provide per-slot layout, push/pop/steal pseudocod","explanation":"## Why This Is Asked\nEvaluates mastery of low-latency concurrent data structures, memory locality, cross-socket traffic, and safe memory reclamation in production environments.\n\n## Key Concepts\n- NUMA-aware memory locality and per-node queues\n- Lock-free push/pop/steal using CAS\n- ABA avoidance via sequence counters\n- Lifetime management with hazard pointers or epoch-based reclamation\n- Cache-line padding to avoid false sharing\n- Correct wrap-around handling under bounded capacity\n- Validation plan under cross-NUMA contention\n\n## Code Example\n```c\n// Pseudo-code sketch (high-level C-like)\ntypedef struct slot {\n  uint64_t seq;\n  void* data;\n} slot_t;\n\ntypedef struct deque {\n  slot_t* slots;\n  size_t mask; // N-1\n  _Atomic(size_t) head, tail;\n} deque;\n\n// push/pop/steal skeleton (high level; details omitted)\n```\n\n## Follow-up Questions\n- How would you debug a perf anomaly with cross-node steals?\n- How would you scale to more NUMA nodes or adapt to varying task sizes?","diagram":"flowchart TD\n  P[Producer] -->|push| LQ[Local Queue (per-NUMA)]\n  LQ -->|pop| W[Worker]\n  Steal[Stealer] -->|steals| LQ\n  W -->|work| D[Done]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T18:53:13.785Z","createdAt":"2026-01-15T18:53:13.785Z"},{"id":"q-2517","question":"Design a beginner-friendly micro-benchmark in C to quantify false sharing. Create two layouts of per-thread counters: one unpadded (counters reside on the same cache line) and one padded to a full 64-byte cache line. Two threads update their own counter 10,000,000 times each. Measure throughput with clock_gettime(CLOCK_MONOTONIC) and compare results, explaining the impact of padding on cache coherence in multi-core systems?","answer":"I would implement a small harness: two threads increment their own 64-bit counters for 10M iterations. Provide two layouts: Unpadded with a single 64-bit field and Padded with an extra 64-byte pad. Ti","explanation":"## Why This Is Asked\n\nProbes understanding of cache topology, false sharing, and practical microbenchmark design.\n\n## Key Concepts\n\n- False sharing\n- Cache lines\n- Padding strategies\n- Throughput benchmarking\n\n## Code Example\n\n```c\ntypedef struct { long long c; } Unpadded;\ntypedef struct { long long c; char pad[64]; } Padded;\n```\n\n```c\n// Minimal harness would create two threads updating their respective structs\n```\n\n## Follow-up Questions\n\n- How would results change with more threads or different cache-line sizes?\n- How would you make the benchmark portable across CPUs and memory hierarchies?\n","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T21:02:06.327Z","createdAt":"2026-01-15T21:02:06.327Z"},{"id":"q-2688","question":"Design and implement a per-thread arena allocator for 16-byte blocks from a fixed 256KB pool. Provide API: init_arena(void* arena, size_t size), void* alloc16(), void free16(void*). Use a global bitmap to track 16,384 blocks and a thread-local cache of 8 blocks to reduce contention. Explain alignment, fragmentation, and how this approach compares to malloc under multi-core contention. Include a minimal test harness?","answer":"```c\n#include <stdint.h>\n#include <string.h>\n#include <stdatomic.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <time.h>\n#include <stdlib.h>\n\n#define ARENA_SIZE (256 * 1024)\n#define BLOCK_SIZE 16\n#define NUM_BLOCKS (ARENA_SIZE / BLOCK_SIZE)\n#define BITMAP_WORDS ((NUM_BLOCKS + 63) / 64)\n#define CACHE_SIZE 8\n\ntypedef struct {\n    uint64_t bitmap[BITMAP_WORDS];\n    uint8_t arena[ARENA_SIZE];\n    pthread_mutex_t mutex;\n} arena_t;\n\ntypedef struct {\n    void* cache[CACHE_SIZE];\n    int count;\n} thread_cache_t;\n\nstatic arena_t g_arena;\nstatic _Thread_local thread_cache_t t_cache;\n\nvoid init_arena(void* arena_ptr, size_t size) {\n    if (size < sizeof(arena_t)) return;\n    \n    arena_t* a = (arena_t*)arena_ptr;\n    memset(a->bitmap, 0, sizeof(a->bitmap));\n    a->mutex = (pthread_mutex_t)PTHREAD_MUTEX_INITIALIZER;\n    \n    g_arena = *a;\n    memset(&t_cache, 0, sizeof(t_cache));\n}\n\nstatic int find_free_block(void) {\n    for (int i = 0; i < BITMAP_WORDS; i++) {\n        uint64_t word = g_arena.bitmap[i];\n        if (word != UINT64_MAX) {\n            int bit = __builtin_ctzll(~word);\n            g_arena.bitmap[i] |= (1ULL << bit);\n            return i * 64 + bit;\n        }\n    }\n    return -1;\n}\n\nvoid* alloc16(void) {\n    if (t_cache.count > 0) {\n        return t_cache.cache[--t_cache.count];\n    }\n    \n    pthread_mutex_lock(&g_arena.mutex);\n    int block_idx = find_free_block();\n    if (block_idx == -1) {\n        pthread_mutex_unlock(&g_arena.mutex);\n        return NULL;\n    }\n    \n    void* ptr = &g_arena.arena[block_idx * BLOCK_SIZE];\n    pthread_mutex_unlock(&g_arena.mutex);\n    \n    return ptr;\n}\n\nvoid free16(void* ptr) {\n    if (!ptr) return;\n    \n    if (t_cache.count < CACHE_SIZE) {\n        t_cache.cache[t_cache.count++] = ptr;\n        return;\n    }\n    \n    ptrdiff_t offset = (uint8_t*)ptr - g_arena.arena;\n    if (offset < 0 || offset >= ARENA_SIZE || offset % BLOCK_SIZE != 0) {\n        return;\n    }\n    \n    int block_idx = offset / BLOCK_SIZE;\n    int word_idx = block_idx / 64;\n    int bit_idx = block_idx % 64;\n    \n    pthread_mutex_lock(&g_arena.mutex);\n    g_arena.bitmap[word_idx] &= ~(1ULL << bit_idx);\n    pthread_mutex_unlock(&g_arena.mutex);\n}\n\ndouble benchmark_alloc(size_t iterations) {\n    struct timespec start, end;\n    clock_gettime(CLOCK_MONOTONIC, &start);\n    \n    void** ptrs = malloc(iterations * sizeof(void*));\n    for (size_t i = 0; i < iterations; i++) {\n        ptrs[i] = alloc16();\n    }\n    \n    clock_gettime(CLOCK_MONOTONIC, &end);\n    double elapsed = (end.tv_sec - start.tv_sec) + \n                    (end.tv_nsec - start.tv_nsec) / 1e9;\n    \n    for (size_t i = 0; i < iterations; i++) {\n        free16(ptrs[i]);\n    }\n    free(ptrs);\n    \n    return elapsed;\n}\n\ndouble benchmark_malloc(size_t iterations) {\n    struct timespec start, end;\n    clock_gettime(CLOCK_MONOTONIC, &start);\n    \n    void** ptrs = malloc(iterations * sizeof(void*));\n    for (size_t i = 0; i < iterations; i++) {\n        ptrs[i] = malloc(16);\n    }\n    \n    clock_gettime(CLOCK_MONOTONIC, &end);\n    double elapsed = (end.tv_sec - start.tv_sec) + \n                    (end.tv_nsec - start.tv_nsec) / 1e9;\n    \n    for (size_t i = 0; i < iterations; i++) {\n        free(ptrs[i]);\n    }\n    free(ptrs);\n    \n    return elapsed;\n}\n\nint main() {\n    arena_t arena;\n    init_arena(&arena, sizeof(arena));\n    \n    printf(\"=== Basic Functionality Test ===\\n\");\n    void* p1 = alloc16();\n    void* p2 = alloc16();\n    printf(\"Allocated: %p, %p\\n\", p1, p2);\n    \n    free16(p1);\n    free16(p2);\n    printf(\"Freed blocks\\n\");\n    \n    printf(\"\\n=== Performance Comparison ===\\n\");\n    const size_t iterations = 100000;\n    \n    double alloc_time = benchmark_alloc(iterations);\n    double malloc_time = benchmark_malloc(iterations);\n    \n    printf(\"Arena allocator: %.6f seconds (%.0f ops/sec)\\n\", \n           alloc_time, iterations / alloc_time);\n    printf(\"System malloc:    %.6f seconds (%.0f ops/sec)\\n\", \n           malloc_time, iterations / malloc_time);\n    printf(\"Speedup: %.2fx\\n\", malloc_time / alloc_time);\n    \n    return 0;\n}\n```\n\n**Key Design Points:**\n- **16-byte alignment**: Each block is exactly 16 bytes, guaranteeing alignment requirements for SSE/AVX\n- **Bitmap efficiency**: 256 words (64KB) manage 16,384 blocks with O(1) allocation using `ctzll` to find first zero bit\n- **Thread-local cache**: 8-block LIFO cache reduces mutex contention - most allocations hit fast path without locking\n- **Fragmentation**: Zero external fragmentation (fixed blocks), minimal internal fragmentation (≤15 bytes per alloc)\n\n**Multi-core Contention Analysis:**\nThe thread-local cache reduces lock acquisitions by ~87.5% (1 in 8 allocations needs the mutex). Under high contention, this scales much better than malloc which typically uses global heap locks. The bitmap's cache-friendly access pattern also reduces false sharing compared to pointer-chasing free lists.","explanation":"## Why This Is Asked\nDemonstrates practical low-level memory management, fixed-size allocators, thread-local caches, and fragmentation trade-offs. A bitmap-based free-tracking scheme avoids pointer-chasing and supports fast scans on aligned blocks.\n\n## Key Concepts\n- Fixed-size block allocator with 16-byte alignment guarantees\n- Bitmap-based free tracking using bit manipulation for O(1) allocation\n- Thread-local caches to reduce contention under multi-core workloads\n- Fragmentation analysis: zero external fragmentation, bounded internal fragmentation\n- Performance comparison with system malloc under contention\n\n## Implementation Highlights\n- **Bitmap operations**: Uses `__builtin_ctzll` for O(1) first-free-bit finding\n- **Thread cache**: 8-block LIFO cache reduces mutex acquisitions significantly\n- **Safety checks**: Validates pointers in free() to prevent corruption\n- **Benchmark**: Includes performance comparison showing speedup under various loads\n\n## Follow-up Questions\n- How would you handle arena resizing or varying block sizes?\n- How would you ensure NUMA-awareness and fault containment?\n- What strategies would you use for garbage collection when thread caches become full?\n- How could this design be extended for larger allocations or mixed-size workloads?","diagram":"flowchart TD\n  Arena[Arena 256KB]\n  Bitmap[Bitmap 16k blocks]\n  Cache[Thread-Local Cache (8 blocks)]\n  Alloc[alloc16()]\n  Free[free16()]\n  Arena --> Bitmap\n  Bitmap --> Alloc\n  Cache --> Alloc\n  Alloc --> Free","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":["arena allocator","16-byte blocks","fixed 256kb pool","global bitmap","thread-local cache","per-thread allocation","multi-core contention","fragmentation analysis","bitmap operations","performance benchmark","memory alignment","lock contention"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-25T05:07:52.257Z","createdAt":"2026-01-16T07:00:45.223Z"},{"id":"q-2699","question":"Design a bounded, lock-free, multi-producer/multi-consumer queue where each slot holds a variable-length payload with a 4-byte length prefix. Use a power-of-two ring, per-slot sequence numbers, and epoch-based reclamation. Provide enqueue/dequeue pseudo-code, describe memory layout, backpressure handling, and a microbenchmark plan under high contention?","answer":"Use a bounded MPMC queue on a power-of-two ring, per-slot length field and a sequence number to avoid ABA. Pad indices to cache lines; publish slot content with release stores and consume with acquire","explanation":"## Why This Is Asked\nTests mastery of lock-free design, memory ordering, and reclamation with real-world payloads.\n\n## Key Concepts\n- Bounded MPMC queue with CAS-based progression\n- Power-of-two ring and per-slot sequence numbers to avoid ABA\n- Epoch-based reclamation for safe memory reclamation\n- Variable-length payloads via 4-byte length prefix\n- Cache-line alignment to prevent false sharing\n- Backpressure handling and fragmentation management\n\n## Code Example\n```cpp\n// Enqueue pseudo\n```\n\n```cpp\n// Dequeue pseudo\n```\n\n## Follow-up Questions\n- How would you adapt this for NUMA-aware memory placements?\n- What stress tests would you run to validate under heavy contention and backpressure?","diagram":"flowchart TD\n  A[Producers] --> B[Enqueue Path]\n  B --> C[Ring Buffer Slot with Seq]\n  C --> D[Consumers Dequeue]\n  D --> E[Epoch Reclamation]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T07:34:44.148Z","createdAt":"2026-01-16T07:34:44.149Z"},{"id":"q-2750","question":"On a dual-socket NUMA server with persistent memory (PMEM), design a crash-consistent, lock-free ring buffer that supports multiple producers and a single consumer. Data is written to PMEM and a compact in-memory log captures operations for recovery after power loss. Include slot layout, enqueue/dequeue steps, memory ordering, and a recovery protocol, plus a microbenchmark plan to verify throughput and durability under power interruption?","answer":"Leverage per-slot sequence numbers and a compact PMEM log. Enqueue: write data to PMEM, flush, publish tail with a release store and memory fence; dequeue validates sequence, advances head with atomic","explanation":"## Why This Is Asked\n\nTests understanding of crash-consistency with non-volatile memory, cross-NUMA coordination, and lock-free design under real-world failure modes.\n\n## Key Concepts\n\n- PMEM crash-consistency and recovery\n- Lock-free MPSC ring design with sequence numbers\n- Memory ordering: fences (mfence, sfence) and cache-line flushes (clwb/clflushopt)\n- In-memory log for durable recovery; replay semantics\n- NUMA-aware layout and false-sharing avoidance\n\n## Code Example\n\n```c\ntypedef struct {\n  uint64_t seq;\n  uint8_t data[DATA_SIZE];\n} Slot;\n\ntypedef struct {\n  Slot* slots;\n  uint64_t head;\n  uint64_t tail;\n  uint8_t pad[64];\n} RingPMEM;\n```\n\n## Follow-up Questions\n\n- How would you extend to multiple consumers?\n- How do you ensure correctness if power loss occurs during a log flush or data write?","diagram":"flowchart TD\n  P[Producers] --> E[Enqueue Path]\n  E --> S[Slot PMEM Write]\n  S --> F[Flush to PMEM]\n  F --> C[Publish Tail]\n  C --> D[Consumer Reads Slot]\n  D --> L[Log Flush for Recovery]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","NVIDIA","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T10:38:05.431Z","createdAt":"2026-01-16T10:38:05.431Z"},{"id":"q-2916","question":"Design and implement a 256-entry software TLB for 32-bit virtual addresses mapping to 4KB pages. Provide API: tlb_init(), tlb_lookup(uint32_t va, uint32_t* pa), tlb_insert(uint32_t va, uint32_t pa). Use linear probing with an LRU replacement policy. Explain interaction with a two-level page table and a microbenchmark plan to measure hit rate under changing working-set sizes?","answer":"Implement a 256-entry TLB with fields: tag (VA page number), pa, valid, and an LRU counter. tlb_init zeros the table. tlb_lookup hashes va to a page index, linearly probes for a valid tag match, retur","explanation":"## Why This Is Asked\nTests practical understanding of cache-like structures, address translation, and replacement policies at low level. \n\n## Key Concepts\n- TLB structure and page number tagging\n- Linear probing and wraparound\n- LRU replacement and correctness in a small cache\n- Interaction with two-level page tables during misses\n\n## Code Example\n```c\ntypedef struct { uint32_t tag; uint32_t pa; uint8_t valid; uint8_t lru; } tlb_entry;\nstatic tlb_entry tlb[256];\nvoid tlb_init() { for (int i=0;i<256;i++) tlb[i].valid=0; }\nbool tlb_lookup(uint32_t va, uint32_t* pa){ uint32_t page = va >> 12; uint32_t idx = page & 0xFF; for(int i=0;i<256;i++){ tlb_entry* e = &tlb[(idx+i)&0xFF]; if(!e->valid) continue; if(e->tag==page){ *pa = e->pa; e->lru = 0; return true; } e->lru++; } return false; }\nvoid tlb_insert(uint32_t va, uint32_t pa){ uint32_t page = va >> 12; uint32_t idx = page & 0xFF; int miss_pos = -1; uint8_t oldest = 0; for(int i=0;i<256;i++){ tlb_entry* e = &tlb[(idx+i)&0xFF]; if(!e->valid){ miss_pos = (idx+i)&0xFF; break; } if(e->lru > oldest){ oldest = e->lru; miss_pos = (idx+i)&0xFF; } }\n tlb[miss_pos].tag = page; tlb[miss_pos].pa = pa; tlb[miss_pos].valid = 1; tlb[miss_pos].lru = 0; }\n```\n\n## Follow-up Questions\n- How would you adapt this to multi-core without races?\n- What trade-offs arise if you instead make it a set-associative cache?","diagram":"flowchart TD\n  A[TLB Lookup] --> B{Hit?}\n  B -- Yes --> C[Return PA]\n  B -- No --> D[Page Walk]\n  D --> E[TLB Insert]\n  E --> C","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T17:34:20.716Z","createdAt":"2026-01-16T17:34:20.716Z"},{"id":"q-3079","question":"Design a cross-process, lock-free bounded queue in shared memory for two processes on a NUMA system, with 1<<18 slots of 128 bytes. Use per-slot 64-bit sequence numbers and head/tail indices. Producers spin until slot.seq==tail, write payload, and publish slot.seq=tail+1 with a release; consumers read with acquire, validate, and advance head. Reclaim via epoch-based scheme across both processes. Microbenchmark: vary producers/consumers, report p95/p99 latency and sustained throughput; check data integrity under contention?","answer":"Implement a cross-process lock-free bounded queue with N=1<<18 slots of 128 bytes each, utilizing per-slot 64-bit sequence numbers for synchronization. Maintain padded head and tail indices to prevent false sharing on NUMA systems. Producers spin until `slot.seq == tail`, write the payload, then publish with `slot.seq = tail + 1` using a release fence. Consumers read with an acquire fence, validate the sequence number, and advance the head index. Reclaim slots using an epoch-based reclamation scheme coordinated across both processes.","explanation":"## Why This Is Asked\nThis question evaluates expertise in cross-process IPC, memory ordering semantics, and memory reclamation in NUMA environments under realistic contention scenarios.\n\n## Key Concepts\n- Cross-process lock-free data structures\n- Memory ordering: acquire/release fences and sequence counters\n- False sharing prevention through cache-line padding\n- Epoch-based reclamation across process boundaries\n- NUMA-aware performance optimization\n- Microbenchmark design for IPC throughput and latency analysis\n\n## Code Example\n```c\ntypedef struct {\n    uint64_t seq;\n    uint8_t payload[128];\n```\n\n## Implementation Details\nThe queue uses a circular buffer with sequence numbers to track slot ownership. Each slot has a 64-bit sequence number that ensures proper synchronization between producers and consumers without locks. The padded head/tail indices prevent false sharing on cache lines.\n\n## Performance Considerations\nNUMA-aware placement of shared memory regions minimizes cross-node memory access. The spin-wait approach is suitable for high-throughput scenarios where the queue is rarely empty or full.\n\n## Benchmarking Strategy\nDesign microbenchmarks that vary producer/consumer ratios (1:1, 1:N, N:1) and measure p95/p99 latencies under different contention levels. Validate data integrity by embedding checksums in payloads and verifying them after each operation.","diagram":"flowchart TD\n  P[Producer enqueues] --> S[Slot selected by tail]\n  S --> W[Write payload]\n  W --> PUBLISH[Publish slot.seq=tail+1 (release)]\n  C[Consumer dequeues] --> R[Read slot and verify seq]\n  R --> ADV[Advance head (acquire)]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Lyft","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T05:12:15.085Z","createdAt":"2026-01-16T23:47:21.619Z"},{"id":"q-3280","question":"Design and implement a lock-free concurrent map using a skip-list with probabilistic levels, supporting O(log n) inserts, finds, and deletes under high contention. Use hazard pointers for memory reclamation and marked pointers for logical deletion. Provide node layout with per-level forward pointers, random level generator, and pseudocode for insert, search, and delete that avoids ABA. Include a minimal microbenchmark plan to validate throughput and correctness under heavy parallelism?","answer":"Key ideas: a skip-list map with lock-free inserts/finds/deletes. Use hazard pointers for reclamation and marked next pointers for logical deletion. Nodes carry per-level forward pointers, and new node","explanation":"## Why This Is Asked\nTests ability to implement a lock-free structure with correct memory reclamation and ABA avoidance in a real-world pattern.\n\n## Key Concepts\n- Lock-free data structures\n- Hazard pointers memory reclamation\n- ABA avoidance\n- Skip-list levels and randomization\n- Memory ordering and fences\n\n## Code Example\n```c\ntypedef struct Node {\n  int key;\n  void* value;\n  struct Node** next; // per-level forward pointers\n  int topLevel;\n  _Atomic(int) marked; // 0/1\n} Node;\n```\n\n## Follow-up Questions\n- How to resize or balance levels without locks?\n- How to validate memory reuse and detect ABA-related failures?","diagram":"flowchart TD\n  A[Thread] --> B[Operation]\n  B --> C[CAS/Link]\n  C --> D[Hazard Pointers]\n  D --> E[Unlink/Retire]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Slack","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T09:43:37.298Z","createdAt":"2026-01-17T09:43:37.298Z"},{"id":"q-3455","question":"Implement a simple spinlock in C using C11 atomics. Provide lock and unlock functions for a shared 32-bit counter. Use an exponential backoff (pause) when contention is detected. Then write a small test with four threads each incrementing the counter one million times. Explain how backoff avoids livelock and how you would measure contention?","answer":"Use a 32-bit atomic flag. In lock(), spin with atomic_flag_test_and_set_explicit(&lock, memory_order_acquire) until it succeeds; on miss, perform exponential backoff with _mm_pause() (cap at 1024). un","explanation":"## Why This Is Asked\nTests knowledge of low-level synchronization, memory ordering, and backoff strategies under contention. Also checks ability to translate theory into working code and simple performance measurement.\n\n## Key Concepts\n- C11 atomics and memory_order_acquire/release\n- atomic_flag spinlocks and their correctness\n- exponential backoff to prevent livelock\n- basic contention metrics (wall time, backoffs)\n\n## Code Example\n```javascript\n#include <stdatomic.h>\n#include <emmintrin.h>\n\nstatic atomic_uint counter = 0;\nstatic atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid lock_spin() {\n  unsigned int backoff = 1;\n  while (atomic_flag_test_and_set_explicit(&lock, memory_order_acquire)) {\n    _mm_pause();\n    if (backoff < 1024) backoff <<= 1;\n    for (volatile unsigned int i = 0; i < backoff; ++i) _mm_pause();\n  }\n}\n\nvoid unlock_spin() {\n  atomic_flag_clear_explicit(&lock, memory_order_release);\n}\n```","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T16:50:37.236Z","createdAt":"2026-01-17T16:50:37.236Z"},{"id":"q-3478","question":"Design a small, beginner-friendly spinlock in C to protect a shared 64-bit counter on a multi-core system. Implement init(), lock(), unlock() using C11 atomics (memory_order_acquire for lock, memory_order_release for unlock). Provide a minimal test plan with 8 threads incrementing the counter and a short fairness note. How would you verify correctness under contention?","answer":"Use an atomic_flag-based spinlock. init: atomic_flag_clear(lock); lock: while (atomic_flag_test_and_set_explicit(lock, memory_order_acquire)) { _mm_pause(); } unlock: atomic_flag_clear_explicit(lock, ","explanation":"## Why This Is Asked\n\nTests fundamental low-level synchronization and memory ordering concepts in a realistic micro-optimization context.\n\n## Key Concepts\n\n- Atomic flags and test_and_set semantics\n- memory_order_acquire vs memory_order_release\n- Busy-wait with cpu pause for reduced contention\n- Backoff strategies to avoid cache-line thrashing\n\n## Code Example\n\n```javascript\n#include <stdatomic.h>\n#include <immintrin.h>\n\ntypedef atomic_flag spinlock_t;\nvoid spinlock_init(spinlock_t* s) { atomic_flag_clear(s); }\nvoid spinlock_lock(spinlock_t* s) { while (atomic_flag_test_and_set_explicit(s, memory_order_acquire)) { _mm_pause(); } }\nvoid spinlock_unlock(spinlock_t* s) { atomic_flag_clear_explicit(s, memory_order_release); }\n```\n\n## Follow-up Questions\n\n- How would you modify to minimize starvation?\n- How would you test for fairness across threads under high contention?\n","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T17:44:16.820Z","createdAt":"2026-01-17T17:44:16.820Z"},{"id":"q-3485","question":"Design a crash‑consistent, lock‑free, bounded ring buffer in shared memory that acts as a persistent queue across restarts. It must be backed by a memory‑mapped file, use per‑slot CRCs, and a two‑phase commit so writers can resume after power loss. Describe enqueue/dequeue algorithms, restoration after crash, and how you handle memory ordering, reclamation of retired descriptors, and backpressure. Include a microbenchmark plan?","answer":"Propose a crash‑consistent, lock‑free bounded ring in shared memory backed by a mmapped file. Use per‑slot CRCs and a two‑phase commit so writers can resume after power loss; dequeue under reader prog","explanation":"## Why This Is Asked\nTests crash‑recovery, memory ordering, and lock‑free design for production‑like persistent queues.\n\n## Key Concepts\n- Crash consistency, memory‑mapped persistence\n- Lock‑free enqueue/dequeue with two‑phase commit\n- Reclamation (hazard pointers/epochs) and memory fences\n- Backpressure, recovery after crash, NUMA considerations\n\n## Code Example\n```javascript\n// Pseudo enqueue/dequeue framework for crash‑consistent queue\nfunction enqueue(queue, item) {\n  // reserve slot, write, commit tail, flush\n}\nfunction dequeue(queue) {\n  // read, validate, advance head, reclaim if needed\n}\n```\n\n## Follow-up Questions\n- How would you simulate power loss during commit and validate recovery?\n- How would you extend to multiple readers and ensure fairness?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Square","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T18:42:37.299Z","createdAt":"2026-01-17T18:42:37.299Z"},{"id":"q-3813","question":"Design a crash‑consistent, lock‑free allocator over persistent memory (PMEM). Provide API: init_pmem_pool(void* base, size_t size), void* pmem_alloc(size_t n), void pmem_free(void* p). Use a log-structured approach with per‑block headers (offset, version, CRC) and a bitmap to track free blocks. Explain recovery after power loss, how to prevent double frees, and minimize writes. Include pseudo-code for alloc and recovery?","answer":"Propose a log-structured PMEM allocator: append allocations to a durable log, then atomically update a per-block header (version, CRC). Maintain a free-block bitmap and a per-thread cache. Recovery re","explanation":"## Why This Is Asked\n\nAssess ability to design crash‑safe, low‑level memory allocators for persistent memory, including ordering, recovery, and reclamation. Tests understanding of write amplification, ABA risks, and practical recovery semantics.\n\n## Key Concepts\n\n- Persistent memory semantics and durability guarantees\n- Log-structured allocation and per-block headers\n- Versioning, CRC, and bitmap for consistency\n- Recovery: replay log up to last committed epoch; handle partial writes\n- Cache-line padding and memory fences to avoid false sharing and ABA\n\n## Code Example\n\n```c\ntypedef struct {\n  uint64_t offset;\n  uint64_t size;\n  uint64_t version;\n  uint64_t crc;\n} BlockHeader;\n\n// Pseudo-code skeletons\nvoid* pmem_alloc(size_t n) {\n  // locate free block via bitmap; append descriptor to log; flush; update header version\n  return NULL;\n}\n\nvoid pmem_free(void* p) {\n  // mark block free in bitmap; record in log; ensure idempotence\n}\n\nvoid recover_pmem() {\n  // replay log to last committed epoch; validate CRCs; reclaim partial writes\n}\n```\n\n## Follow-up Questions\n\n- How would you test crash power-loss scenarios and verify no leaks?\n- What metrics would you track (throughput, write amplification, recovery time)?","diagram":"flowchart TD\n  A[Pmem pool] --> B[Alloc path]\n  B --> C[Append to log]\n  C --> D[Persist header]\n  D --> E[Free path]\n  E --> F[Recovery]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T10:37:53.498Z","createdAt":"2026-01-18T10:37:53.499Z"},{"id":"q-3917","question":"Implement a portable spinlock in C using stdatomic.h. Provide acquire() and release() with an exponential backoff strategy for contention. Explain memory ordering choices (memory_order_acquire on acquire and memory_order_release on release), and how you would test correctness with two threads incrementing a shared counter to 1e7. Include a minimal C snippet and a test harness plan?","answer":"Use stdatomic.h atomic_flag for a spinlock. Acquire: while (atomic_flag_test_and_set_explicit(&lock->flag, memory_order_acquire)) { _mm_pause(); for (int b=1; b<1024; b<<=1) _mm_pause(); }. Release: a","explanation":"## Why This Is Asked\n\nAssess understanding of low-level synchronization, atomic operations, and memory ordering in a practical, portable way.\n\n## Key Concepts\n\n- Spinlock using atomic_flag\n- Memory ordering: acquire on lock, release on unlock\n- Exponential backoff with PAUSE to reduce contention\n- Correctness test with concurrent increments\n\n## Code Example\n\n```c\n#include <stdatomic.h>\n#include <immintrin.h>\n\ntypedef struct { atomic_flag flag; } spinlock;\n\nstatic inline void spinlock_init(spinlock* s) {\n  atomic_flag_clear(&s->flag);\n}\n\nstatic inline void spin_lock(spinlock* s) {\n  while (atomic_flag_test_and_set_explicit(&s->flag, memory_order_acquire)) {\n    _mm_pause();\n    // small exponential backoff\n    for (int b = 1; b < 1024; b <<= 1) {\n      _mm_pause();\n    }\n  }\n}\n\nstatic inline void spin_unlock(spinlock* s) {\n  atomic_flag_clear_explicit(&s->flag, memory_order_release);\n}\n```\n\n## Follow-up Questions\n\n- How would you adapt this for NUMA systems to reduce cross-socket traffic?\n- What are the trade-offs of using a ticket-lock vs this spinlock in high-contention workloads?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T15:34:07.387Z","createdAt":"2026-01-18T15:34:07.387Z"},{"id":"q-3978","question":"Write a cooperative user-space scheduler that preempts green threads using a timer signal. In a single process, implement N coroutines with contexts (ucontext or setjmp/longjmp), maintain a ready queue, and use a per-thread timer (ITIMER_REAL) to trigger SIGALRM, performing yield by swapping to the next context. Include stack guard pages, an async-signal-safe enqueue/dequeue, and discuss race conditions, reentrancy, and performance implications?","answer":"Implementation approach: use ucontext to create N contexts with stacks aligned to 16/64 bytes; install a single signal handler for SIGALRM that is async-signal-safe; on timer expiry, save current cont","explanation":"## Why This Is Asked\nTests practical low-level skills: user-space scheduling, context switching, and signal safety. It probes how candidates manage cross-core timing, layout stacks, and handle preemption without kernel help.\n\n## Key Concepts\n- Async-signal-safety and reentrancy in a signal handler\n- Context switching APIs (ucontext vs setjmp/longjmp)\n- Stack guards and guard pages to detect overflows\n- Preemption cost and jitter; worst-case latency\n\n## Code Example\n```javascript\n// Minimal skeleton (C-like) for a preemptive user-space scheduler\n#include <signal.h>\n#include <ucontext.h>\n#include <sys/mman.h>\n#include <unistd.h>\n\n#define N 4\n\nucontext_t ctxs[N], main_ctx;\nint current = 0;\nvoid scheduler_tick(int sig){ /* async-signal-safe yield to next */ }\n```\n\n## Follow-up Questions\n- How would you extend to handle more coroutines than hardware threads while keeping latency predictable?\n- How would you measure and minimize preemption jitter across cores in a dense workload?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T18:39:24.891Z","createdAt":"2026-01-18T18:39:24.891Z"},{"id":"q-4008","question":"Design a per-core, bounded publish-subscribe queue for a NUMA multi-socket server. Producers write to local rings and publish to a shared log with per-slot sequence numbers. Provide data structures, enqueue/dequeue pseudo-code, handle wrap-around, memory ordering on x86-64, and validation plan for throughput and message ordering under cross-core contention?","answer":"Propose a per-core, bounded publish–subscribe queue: each producer writes to a local ring buffer and publishes to a shared log with per-slot sequence numbers. Use per-slot 64-byte, cache-aligned slots","explanation":"## Why This Is Asked\nTests knowledge of low-latency IPC, NUMA locality, and cache-coherence with careful memory ordering. It also probes design trade-offs for per-core buffering vs a centralized log.\n\n## Key Concepts\n- Per-core buffering and cross-core publication\n- Sequence-numbered slots and wrap-around handling\n- Memory ordering on x86-64 (relaxed/upholds with fences)\n- False sharing avoidance and cacheline padding\n- Validation: throughput, ordering, and backpressure under contention\n\n## Code Example\n```c\n// Pseudo-enqueue\nbool enqueue(int core_id, void* msg) {\n  uint64_t pos = atomic_fetch_add(&tail[core_id], 1);\n  slot_t* s = &ring[core_id][pos & (N-1)];\n  if (s->seq != pos) return false; // consumer hasn't advanced\n  s->payload = msg;\n  s->seq = pos + 1;\n  return true;\n}\n```\n\n## Follow-up Questions\n- How would you extend this to support dynamic growth of the log while preserving wait-freedom?\n- How would you test correctness with synthetic workloads that stress cross-core contention?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Instacart","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T19:28:07.261Z","createdAt":"2026-01-18T19:28:07.262Z"},{"id":"q-4021","question":"Implement a NUMA-aware fixed-size block allocator for 64-byte blocks in a multi-threaded process. Each thread uses a per-NUMA-node cache and refills from a central pool on miss; design lock-free freelists with atomic operations, ensure alignment and quick-path fast-path, and discuss fragmentation and cross-socket traffic. Include a microbenchmark plan comparing against a naive malloc?","answer":"Describe a NUMA-aware allocator: per-thread caches on local NUMA nodes, a central pool for cross-node refills, and lock-free freelists using atomic push/pop. Ensure 64-byte alignment, cache-friendly l","explanation":"## Why This Is Asked\n\nThe task probes practical memory allocator design under NUMA, highlighting locality, contention, and fragmentation trade-offs with lock-free data structures.\n\n## Key Concepts\n\n- NUMA locality\n- Per-thread caches\n- Lock-free freelists and memory reclamation\n- Fragmentation and refill strategies\n- Benchmark design\n\n## Code Example\n\n```c\n// High-level sketch of data structures\ntypedef struct Block { struct Block *next; } Block;\ntypedef struct { _Atomic(Block*) central; Block *local; int node; } Allocator;\n\nvoid* malloc64(Allocator *A){\n  Block *b = A->local; if(b){ A->local = b->next; return (void*)b; }\n  Block *c = atomic_load_explicit(&A->central, memory_order_acquire);\n  if(c){ atomic_store_explicit(&A->central, c->next, memory_order_release); return (void*)c; }\n  // refill from OS or malloc from system\n  return system_alloc(A);\n}\nvoid free64(Allocator *A, Block *b){\n  b->next = A->local; A->local = b;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle thread migration across NUMA nodes? \n- What metrics identify improvement (latency, bandwidth, cache misses)?","diagram":"flowchart TD\n  A[Thread requests alloc] --> B{Local cache?}\n  B -- yes --> C[Return block]\n  B -- no --> D[Refill from central pool]\n  D --> E[Return block to thread]\n  E --> F[Done]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Meta","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T20:33:25.504Z","createdAt":"2026-01-18T20:33:25.504Z"},{"id":"q-4110","question":"Design a NUMA-aware, lock-free free-list based allocator in C for a 2-socket system. Each thread should allocate from its local allocator first; if local memory runs out, steal from the other node with minimal synchronization. Provide data structures, allocate/free pseudo-code using atomic ops, and discuss fragmentation, cross-node traffic, and microbenchmark plan?","answer":"Per-thread local caches fed by per-NUMA node free lists. Allocation first uses the thread cache; if empty, pop from the local free-list; on underflow, CAS-steal a block from the remote node and insert into the local cache.","explanation":"## Why This Is Asked\n\nTests NUMA awareness, lock-free free-list mechanics, and cache-padding trade-offs under cross-socket contention.\n\n## Key Concepts\n\n- NUMA-aware allocation paths and locality\n- Lock-free free-lists with atomic CAS\n- Cache-line padding to prevent false sharing and 64-byte alignment\n\n## Code Example\n\n```c\n// Skeleton: per-node free-list with thread-local cache; CAS-based steal from remote\ntypedef struct NodeBlock { struct NodeBlock* next; } NodeBlock;\ntypedef struct FreeList {\n  _Atomic(NodeBlock*) head;\n  // padding to avoid false sharing\n  uint8_t pad[64];\n} FreeList;\n```","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Microsoft","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:30:07.132Z","createdAt":"2026-01-19T02:43:10.774Z"},{"id":"q-4241","question":"Design a fixed-size-object allocator for a 4-core NUMA machine that minimizes inter-core traffic. Implement per-core caches, a small global cache, non-blocking refill of core caches, and safe bulk release during teardown. Explain cache-line alignment and false sharing avoidance, how you reclaim freed objects, and how you'd benchmark latency under bursty allocations?","answer":"Per-core caches hold 64 objects each, cache-line aligned to 64 bytes; a global lock-free freelist handles cross-core refills in batches (e.g., 64). Fast path alloc/free uses local cache with relaxed a","explanation":"## Why This Is Asked\n\nTests practical design choices for low-latency allocators in multi-core, NUMA contexts, including cache locality, lock-free synchronization, and teardown safety.\n\n## Key Concepts\n\n- Per-core caches for locality\n- Global lock-free freelist for cross-core refills\n- Batch operations to amortize synchronization cost\n- Cache-line padding to avoid false sharing\n\n## Code Example\n\n```c\n// Pseudo: per-core cache node and refill logic\ntypedef struct Object { struct Object *next; } Object;\ntypedef struct { _Atomic(Object*) head; } FreeList;\n\n#define BATCH 64\n\nObject* allocate(FreeList *local, FreeList *global){\n    Object* head = atomic_load_explicit(&local->head, memory_order_acquire);\n    if(head){\n        local->head = atomic_fetch_sub_explicit(&local->head, NULL, memory_order_acquire);\n        return head;\n    }\n    // refill from global (simplified)\n    for(int i=0;i<BATCH;i++){\n        Object* o = pop_global(global);\n        if(!o) break;\n        push_local(local, o);\n    }\n    return allocate(local, global);\n}\n\nvoid deallocate(FreeList *local, Object *o){\n    push_local(local, o);\n}\n```\n\n## Follow-up Questions\n\n- How would you adapt this for varying object sizes and allocator fragmentation?\n- What microbenchmarks would validate latency under high contention and NUMA effects?","diagram":"flowchart TD\n  A[Allocate] --> B{LocalCache?}\n  B -- Yes --> C[Return Object]\n  B -- No --> D[RefillFromGlobal]\n  D --> E[Return Object]\n  E --> F[Deallocate]\n  F --> G[LocalCacheAggressiveRelease]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Cloudflare","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T09:53:24.186Z","createdAt":"2026-01-19T09:53:24.186Z"},{"id":"q-4632","question":"Design a bounded MPMC DMA ring for a 2-socket NUMA server. Use N=1<<16 128-byte slots (16B header, 112B payload) aligned to 128B. Per-slot fields: seq and len. Producers publish payload with store-release, consumers read with acquire and recycle; wrap around via seq xor 1. Use epoch-based reclamation for descriptors. Propose a 100G microbenchmark and how you verify stall, latency, and backpressure?","answer":"Provide a 1<<16, 128-byte per-slot bounded MPMC ring. Slot header: 16B seq/len plus 112B payload. Producers publish with store-release, then advance via CAS; consumers use load-acquire, process, and r","explanation":"## Why This Is Asked\nTests lock-free MPMC design, memory ordering, and NUMA-aware DMA paths.\n\n## Key Concepts\n- Lock-free synchronization with per-slot sequencing\n- Cache-line alignment to avoid false sharing\n- ABA avoidance and safe wrap-around\n- Epoch-based reclamation for descriptors\n- Realistic NIC/user-space memory interactions\n\n## Code Example\n```javascript\n// Pseudo-C sketch for publish/consume paths\n```\n\n## Follow-up Questions\n- How would you adapt for HW-assisted reclamation? \n- How would you validate correctness under burst traffic?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Scale Ai","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:48:57.975Z","createdAt":"2026-01-20T05:48:57.975Z"},{"id":"q-4909","question":"Design a lock-free, concurrent graph data structure with adjacency lists that supports add_node(id), add_edge(u,v), and remove_node(id) without locking. Target a 16-core NUMA server handling high update rates; ensure memory safety using hazard pointers or epoch-based reclamation for removed nodes. Describe node/edge layout, edge insertion as a lock-free CAS operation, and a minimal stress test plan?","answer":"Lock-free graph: each node has an atomic head pointer to a singly linked list of edges; Edge {int to; atomic next}. add_edge uses CAS to prepend; add_node allocates a node and links it atomically. rem","explanation":"## Why This Is Asked\nThe problem probes mastery of lock-free data structures, safe memory reclamation, and performance under high contention in a graph primitive.\n\n## Key Concepts\n- Lock-free updates (CAS-based edge insertion)\n- Hazard pointers vs epoch-based reclamation\n- Cache-line alignment and false sharing mitigation\n- Safe removal of nodes with concurrent readers\n\n## Code Example\n```javascript\n// Skeleton (conceptual; real impl uses C/C++)\nclass Node{ constructor(id){ this.id=id; this.head=null; this.marked=false; } }\nclass Edge{ constructor(to,next){ this.to=to; this.next=next; } }\nfunction addEdge(u,v){ // lock-free prepend with CAS on u.head }\nfunction addNode(id){ // allocate and link atomically }\nfunction removeNode(id){ // mark and reclaim via hazard pointers/epochs }\n```\n\n## Follow-up Questions\n- How would you benchmark contention under parallel add_edge/remove_node workloads?\n- How would you extend to support directed vs undirected graphs without sacrificing lock-freedom?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T18:59:20.173Z","createdAt":"2026-01-20T18:59:20.173Z"},{"id":"q-5029","question":"Design and implement a beginner-friendly line-based decoder for a fixed 4KB ring buffer shared by a producer (socket reader) and a consumer (processor). Lines are ASCII terminated by '\\n'. Provide C-like pseudo-code for a ring buffer struct and a decode_lines function that returns all complete lines in a single call, preserves partial lines, handles wrap-around, and signals backpressure when full. Include a tiny test harness?","answer":"Approach: Implement a 4KB ring buffer with head and tail indices to track read and write positions. Write incoming data at the tail position, advance the tail pointer, and use newline delimiters to segment complete lines. The decode_lines function iterates while head != tail, reads until encountering '\n' or buffer wrap-around, copies complete lines to the output buffer, preserves partial lines for subsequent calls, and returns a backpressure indicator when the buffer reaches capacity.","explanation":"## Why This Is Asked\nThis practical low-level buffer management task mirrors real-world service architectures and tests understanding of memory layout, line framing, and concurrent data handling.\n\n## Key Concepts\n- Ring buffer indexing and wrap-around logic\n- Line framing with partial line preservation\n- Backpressure signaling and thread-safe visibility\n- Memory-efficient buffer utilization\n\n## Code Example\n```c\ntypedef struct {\n  unsigned char data[4096];\n  size_t head; // read position\n  size_t tail; // write position\n  size_t cap;  // 4096\n} RingBuf;\n\nint decode_lines(RingBuf* rb, char* out","diagram":"flowchart TD\n  P[Producer] --> RB[RingBuffer]\n  RB --> C[Consumer]\n  P -- writes data --> RB\n  RB -- delivers lines --> C","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:15:39.616Z","createdAt":"2026-01-21T02:28:51.658Z"},{"id":"q-5058","question":"Design a NUMA-aware slab allocator for 64-byte objects on a 4-core, 2-socket system. Each core maintains a private freelist; allocations preferentially use local slabs; deallocations migrate cross-socket via a per-node buffer for batch transfer. Provide data structures, allocate/free pseudo-code, discuss locking-free design, cache-line alignment, and a microbenchmark plan comparing local vs cross-socket allocations?","answer":"Per-core freelists with a lock-free stack; slabs 4KB, 64-byte slots; hot path uses thread-local cache; misses refill from NUMA-local pool; remote frees buffered per-node and migrated in bulk to minimi","explanation":"## Why This Is Asked\nTests practical NUMA locality, lock-free data structures, and cross-socket migration decisions under realistic constraints. It probes memory ordering, cache-line contention, and batch reclamation strategies.\n\n## Key Concepts\n- NUMA locality and cross-socket traffic\n- Lock-free freelists and per-core caches\n- Cache-line padding to avoid false sharing\n- Batch migration of remote frees\n- Memory ordering in hot paths\n\n## Code Example\n```c\n// Pseudo-structure for per-core cache (simplified)\ntypedef struct core_cache {\n  alignas(64) void *head; // atomic head of freelist\n  char padding[60];\n} core_cache_t;\n```\n\n## Follow-up Questions\n- How would you extend for variable-sized objects?\n- How would you measure scalability across more sockets and cores?","diagram":"flowchart TD\n  A[Thread Local Alloc] --> B[Local Freelist]\n  B --> C[Allocate]\n  C --> D[Success]\n  A --> E[Miss -> Refill]\n  E --> F[NUMA Local Pool]\n  F --> G[Migrate on Free -> Remote Buffer]\n  G --> H[Bulk Migration]\n  I[Remote Free] --> J[Migration Buffer] --> D","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","MongoDB","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T04:14:52.458Z","createdAt":"2026-01-21T04:14:52.458Z"},{"id":"q-5123","question":"Implement a simple 256-slot software timer wheel in C for a single-threaded event loop. Each slot stores a list of tasks: struct Task { void (*cb)(void*); void* ctx; struct Task* next; }. API: void init_wheel(); void schedule(void (*cb)(void*), void* ctx, uint32_t delay_ms); void tick_one_ms(); The wheel uses wrap-around, fixed pool of 512 nodes, and a per-slot head pointer. Provide enqueue/dequeue pseudo-code, wrap-around handling, and a minimal test plan?","answer":"Use a 256-slot ring; keep current_slot. schedule maps to slot = (current_slot + delay_ms) & 0xFF; pull a node from a preallocated pool, set cb/ctx, push to front of slot's list. tick executes all node","explanation":"## Why This Is Asked\nLow-level timer logic is common in network and game loops; beginner-friendly but tests memory layout, wrap-around, and basic lock-free thinking without heavy concurrency.\n\n## Key Concepts\n- Ring buffers and wrap-around\n- Pre-allocated object pools\n- Scheduling by slot arithmetic and locality\n- Minimal locking assumptions in single-threaded loop\n\n## Code Example\n```c\ntypedef struct Task { void (*cb)(void*); void* ctx; struct Task* next; } Task;\n#define WHEEL_SIZE 256\nstatic Task* wheel[WHEEL_SIZE];\nstatic int cur = 0;\nstatic Task pool[512]; static int pool_free = 512;\nvoid init_wheel(){ for(int i=0;i<WHEEL_SIZE;i++) wheel[i]=NULL; cur=0; pool_free=512; }\nstatic Task* alloc_task(){ return &pool[--pool_free]; }\nvoid schedule(void (*cb)(void*), void* ctx, uint32_t delay_ms){ int slot = (cur + delay_ms) & (WHEEL_SIZE-1); Task* t = alloc_task(); t->cb=cb; t->ctx=ctx; t->next=wheel[slot]; wheel[slot]=t; }\nvoid tick_one_ms(){ Task* t = wheel[cur]; wheel[cur]=NULL; while(t){ Task* next=t->next; t->cb(t->ctx); t = next; } cur=(cur+1)&(WHEEL_SIZE-1); }\n```\n\n## Follow-up Questions\n- How would you adapt for multiple producers? \n- How would you test with bursty traffic and verify timing guarantees?\n","diagram":"flowchart TD\n  A[Schedule(cb,ctx,delay)] --> B[slot = (cur + delay) % 256]\n  B --> C[push task into wheel[slot]]\n  D[tick_one_ms] --> E[execute wheel[cur]]\n  E --> F[cur = (cur+1) % 256]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Uber","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T07:11:47.040Z","createdAt":"2026-01-21T07:11:47.040Z"},{"id":"q-5215","question":"Design a bounded, lock-free work-stealing queue (WSQ) for a fixed thread pool of N workers. Each worker has a local deque; producers push to their own tail; workers pop from their own tail; idle workers steal from other heads. Provide pseudocode for push, pop, steal; discuss ABA avoidance, memory reclamation (hazard pointers or epochs), and cache-line layout to minimize false sharing. Include a concrete stress-validation plan?","answer":"Propose a bounded, lock-free WSQ with per-thread deques. Push to local tail; pop from local tail; thieves steal from heads. Use versioned pointers or tagged CAS to avoid ABA; apply hazard pointers or ","explanation":"## Why This Is Asked\nTests ability to design high-throughput concurrent queues under contention, covering memory reclamation, false sharing, and backpressure—critical for scalable data platforms at large-scale storage and analytics workloads.\n\n## Key Concepts\n- Lock-free queue basics, per-thread locality, and work-stealing semantics\n- ABA avoidance via versioned pointers or sequence counters\n- Hazard pointers or epoch-based reclamation for memory safety\n- Cache-line alignment and padding to reduce false sharing\n- Bounded capacity and spill-over strategies for backpressure\n\n## Code Example\n```c\ntypedef struct node {\n  void* data;\n  _Atomic(struct node*) next;\n  int stamp; // version counter\n} node_t;\n\ntypedef struct wsq {\n  _Atomic(node_t*) head;\n  _Atomic(node_t*) tail;\n  // per-thread deques omitted for brevity\n} wsq_t;\n```\n\n## Follow-up Questions\n- How would you adapt WSQ design for NUMA and high-core-count machines?\n- What metrics would you collect to detect bottlenecks and starvation, and how would you validate scalability?","diagram":"flowchart TD\n  A[Push to local tail] --> B{Space in local deque?}\n  B -- Yes --> C[Write and advance tail]\n  B -- No --> D[ Spill to shared spill ring ]\n  E[Steal from heads] --> F[Update owner state]\n  C --> G[Operation complete]\n  F --> G","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:01:14.152Z","createdAt":"2026-01-21T11:01:14.152Z"},{"id":"q-5284","question":"Design and implement a tiny software transactional memory (STM) in C11 that supports two concurrent transactions operating on a shared array of 64-bit integers. Provide begin(), read(addr), write(addr, val), commit(), and abort(). Use per-slot versioning to detect conflicts, a read/write set, and simple rollback. Explain how you avoid ABA, ensure serializability, and validate with a minimal two-transaction test under contention?","answer":"Begin with per-slot version counters and per-transaction read/write logs. On read, snapshot value and ver; on write, stash in the log. Commit validates all prior versions unchanged using CAS to advanc","explanation":"## Why This Is Asked\n\nTests understanding of memory ordering, non-blocking progress, and correctness of transactional memory in a tight two-thread scenario.\n\n## Key Concepts\n\n- Per-slot version counters to detect conflicts\n- Read/write logs and commit protocol\n- ABA avoidance with version increments and monotonic counters\n- Memory_order semantics and atomic CAS\n\n## Code Example\n\n```c\ntypedef struct { atomic_uint64_t ver; uint64_t val; } slot_t;\ntypedef struct { slot_t *slots; size_t n; log_t read, write; } tx_t;\n\n// begin, read, write, commit skeletons...\n```\n\n## Follow-up Questions\n\n- How would you scale to many concurrent transactions and nested transactions?\n- How would you detect starvation and unfairness?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T14:59:59.477Z","createdAt":"2026-01-21T14:59:59.477Z"},{"id":"q-5466","question":"You are given a microcontroller without an FPU. Implement a tiny 16.16 fixed-point math library for non-negative numbers. Provide fixed_mul and fixed_div that take 32-bit inputs in 16.16 form, perform correct rounding, guard divide-by-zero, and document overflow handling. Include a small test harness and discuss performance on flash/RAM?","answer":"Multiply: use uint64_t t = (uint64_t)a * (uint64_t)b; return (uint32_t)(t >> 16); Divide: if (b==0) return MAX; uint64_t t = ((uint64_t)a << 16) / b; return (uint32_t)t; Guard overflow by saturating t","explanation":"## Why This Is Asked\nTests fixed-point fundamentals, overflow/rounding, and testing on resource-constrained MCUs.\n\n## Key Concepts\n- 16.16 representation, 64‑bit intermediates, rounding, saturation.\n- Edge cases: division by zero, overflow, sign handling.\n- Minimal test harness design for corner cases.\n\n## Code Example\n```c\nstatic inline uint32_t fixed_mul(uint32_t a, uint32_t b) {\n  uint64_t t = (uint64_t)a * (uint64_t)b;\n  return (uint32_t)(t >> 16);\n}\nstatic inline uint32_t fixed_div(uint32_t a, uint32_t b) {\n  if (b == 0) return 0xFFFFFFFFu; // saturate\n  uint64_t t = ((uint64_t)a << 16) /","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T05:52:53.286Z","createdAt":"2026-01-21T23:37:50.816Z"},{"id":"q-5504","question":"Implement a minimal spinlock in C using atomic_flag with lock, unlock, and trylock APIs. lock: while (atomic_flag_test_and_set(&flag)) { pause; } unlock: atomic_flag_clear(&flag); Use memory_order_acquire for lock and memory_order_release for unlock; trylock() returns true if acquired. Pad to 64 bytes to avoid false sharing; add simple backoff to prevent livelock. Stress test: two threads increment a shared counter 1e6 times and verify final value?","answer":"Implement a minimal spinlock in C using atomic_flag with lock, unlock, and trylock APIs. The lock function should use `while (atomic_flag_test_and_set(&flag)) { pause; }`, unlock should use `atomic_flag_clear(&flag)`, with memory_order_acquire for lock and memory_order_release for unlock. The trylock() function returns true if the lock was acquired. Pad the structure to 64 bytes to avoid false sharing and add simple backoff to prevent livelock.","explanation":"## Why This Is Asked\nTests understanding of low-level synchronization, atomic primitives, and memory ordering in a beginner-friendly way.\n\n## Key Concepts\n- atomic_flag basics\n- memory_order_acquire/release semantics\n- backoff to avoid livelock\n- cache-line padding to prevent false sharing\n\n## Code Example\n```c\n#include <stdatomic.h>\n\ntypedef struct { \n    alignas(64) atomic_flag flag; \n} spinlock_t;\n\nvoid spinlock_init(spinlock_t* s) {\n    atomic_flag_clear(&s->flag);\n}\n\nvoid spinlock_lock(spinlock_t* s) {\n    while (atomic_flag_test_and_set_explicit(&s->flag, memory_order_acquire)) {\n        // Simple backoff to prevent livelock\n        for (volatile int i = 0; i < 100; i++);\n    }\n}\n\nvoid spinlock_unlock(spinlock_t* s) {\n    atomic_flag_clear_explicit(&s->flag, memory_order_release);\n}\n\nbool spinlock_trylock(spinlock_t* s) {\n    return !atomic_flag_test_and_set_explicit(&s->flag, memory_order_acquire);\n}\n```\n\n## Stress Test\n```c\n#include <pthread.h>\n#include <stdio.h>\n\nspinlock_t lock;\nlong long counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < 1000000; i++) {\n        spinlock_lock(&lock);\n        counter++;\n        spinlock_unlock(&lock);\n    }\n    return NULL;\n}\n\nint main() {\n    spinlock_init(&lock);\n    pthread_t t1, t2;\n    \n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n    \n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    \n    printf(\"Final counter: %lld\\n\", counter);\n    return 0;\n}\n```","diagram":"flowchart TD\n  A[Start] --> B[Acquire spinlock]\n  B --> C{Locked?}\n  C -->|Yes| D[Pause/backoff]\n  D --> B\n  C -->|No| E[Enter critical section]\n  E --> F[Release spinlock]\n  F --> G[End]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T05:07:24.221Z","createdAt":"2026-01-22T02:46:03.445Z"},{"id":"q-5524","question":"Design a lock-free, NUMA-aware concurrent hash map in C11 that supports inserts and lookups with bounded rehashing. Use epoch-based reclamation to retire nodes and avoid ABA. Describe per-bucket structure, CAS-based insert, and a safe resize strategy. Provide pseudo-code for insert and lookup, and a microbenchmark plan focusing on locality and contention across NUMA nodes. How would you validate correctness and performance?","answer":"Use per-bucket head pointers with atomic CAS for inserts; each node holds key, value, next; pad nodes to cache-lines. Use epoch-based reclamation to retire removed nodes to prevent ABA. Resize by doub","explanation":"## Why This Is Asked\nConcrete, end-to-end lock-free structure tailored for NUMA-aware workloads.\n\n## Key Concepts\n- Lock-free data structures\n- Epoch-based reclamation (EBR)\n- NUMA locality and cache-line padding\n- Safe dynamic resizing of hash tables\n\n## Code Example\n```c\n// Pseudocode for insert and lookup with CAS and EBR\n```\n\n## Follow-up Questions\n- How would you verify correctness under heavy contention?\n- What failure scenarios would you test (power loss, crashes) and how ensure crash resilience?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T04:24:44.231Z","createdAt":"2026-01-22T04:24:44.231Z"},{"id":"q-5577","question":"Implement a streaming CRC-32 calculator using a 256-entry lookup table with polynomial 0xEDB88320. Provide init_crc32_table(), crc32_update(uint32_t crc, const uint8_t* data, size_t len), crc32_finalize(uint32_t crc). It must handle arbitrary lengths and cross-boundary chunks. Include a minimal test outline?","answer":"Use a 256-entry LUT for speed, poly 0xEDB88320. Init crc = 0xFFFFFFFF; for each byte b: crc = table[(crc ^ b) & 0xFF] ^ (crc >> 8); finalize with crc ^ 0xFFFFFFFF. Provide init_crc32_table, crc32_upda","explanation":"## Why This Is Asked\nChecks understanding of bitwise ops, table-driven CRC and streaming data handling.\n\n## Key Concepts\n- CRC32 fundamentals\n- Lookup-table optimization\n- Streaming updates and finalization\n- Endianness considerations\n\n## Code Example\n```c\n#include <stdint.h>\n#include <stddef.h>\nstatic uint32_t crc32_table[256];\n\nvoid init_crc32_table(void){\n  const uint32_t poly = 0xEDB88320U;\n  for (int i=0;i<256;i++){\n    uint32_t c = i;\n    for (int j=0;j<8;j++) c = (c & 1) ? (c >> 1) ^ poly : (c >> 1);\n    crc32_table[i] = c;\n  }\n}\n\nuint32_t crc32_update(uint32_t crc, const uint8_t* data, size_t len){\n  crc ^= 0xFFFFFFFFU;\n  for (size_t i=0;i<len;i++){\n    crc = crc32_table[(crc ^ data[i]) & 0xFF] ^ (crc >> 8);\n  }\n  return crc ^ 0xFFFFFFFFU;\n}\n\n```\n\n## Follow-up Questions\n- How would you adapt for incremental calls with chunked input sizes?\n- How does endianness affect the final CRC value on different architectures?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Discord","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T07:07:34.897Z","createdAt":"2026-01-22T07:07:34.897Z"},{"id":"q-5625","question":"Design a lock-free, bounded object pool for fixed-size 128-byte objects to be used in a high-throughput network path on a 2-socket x86-64 server. Provide APIs pool_create(capacity), pool_alloc(), pool_free(). Use hazard pointers or epoch-based reclamation, per-thread caches, and cacheline-aligned blocks. Explain ABA avoidance, memory ordering, and how you would test under contention and backpressure?","answer":"Build a lock-free, bounded object pool for 128-byte objects on a 2-socket system. API: pool_create(capacity), pool_alloc(), pool_free(). Use per-thread caches, 64-byte aligned blocks, hazard pointers ","explanation":"## Why This Is Asked\n\nTests practical mastery of non-blocking memory reclamation, ABA avoidance, and performance on multi-socket systems.\n\n## Key Concepts\n\n- Lock-free pools with per-thread caches\n- Hazard pointers vs epoch-based reclamation\n- Cacheline alignment and false sharing\n- NUMA/2-socket contention and memory ordering\n\n## Code Example\n\n```javascript\n// Pseudo API\nfunction pool_create(capacity) { /*...*/ }\nfunction pool_alloc() { /*...*/ }\nfunction pool_free(obj) { /*...*/ }\n```\n\n## Follow-up Questions\n\n- How would you resize the pool at runtime?\n- Compare hazard pointers and epochs for this workload.","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","IBM","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T08:58:03.183Z","createdAt":"2026-01-22T08:58:03.184Z"},{"id":"q-5762","question":"Design a bounded, lock-free SPMC ring with 1<<12 64-byte slots. The producer uses fetch_add on tail to claim a slot; a slot is ready when slot.seq == tail. After writing the payload, set slot.seq = tail+1. Each consumer tracks its own read index; spins until slot.seq == read_idx, then copies payload, increments read_idx, and sets slot.seq = read_idx. Pad slots to avoid false sharing. Include a minimal stress test idea with multiple affinity-bound consumers?","answer":"This SP MC queue uses per-slot seq and a single tail. Producer does tail = fetch_add(1) to pick slot i, writes payload, then stores seq = i+1. Each consumer has a local read index r and spins until sl","explanation":"Why This Is Asked\n- Tests lock-free synchronization fundamentals in a practical pattern (SPMC) with concrete constraints.\n\nKey Concepts\n- fetch_add/CAS-based slot reservation, per-slot sequence counters to avoid ABA, and memory-order considerations.\n- Cache-line padding to prevent false sharing and reduce cross-slot traffic.\n- Correctness under contention and bounded capacity handling.\n\nCode Example\n\n```c\n#define N (1<<12)\ntypedef struct { volatile uint64_t seq; uint8_t data[64]; } slot_t;\nslot_t ring[N];\n_Atomic uint64_t tail;\nuint64_t read_idx[NUM_CONSUMERS]; // one per consumer\n\n```\n\nFollow-up Questions\n- How would you adapt this for dynamic resizing or multiple producers?\n- What stress-test suite would you run to validate both throughput and data integrity under high contention?","diagram":"flowchart TD\n  A[Producer] --> B[Claim Slot with tail via fetch_add]\n  B --> C[Write Payload]\n  C --> D[Publish tail+1 via seq]\n  E[Consumer] --> F[Spin on read_idx until slot.seq == read_idx]\n  F --> G[Read Payload] --> H[Increment read_idx and publish seq]\n  G --> I[Repeat]\n  D --> J[Repeat]\n","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Twitter","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T15:44:40.027Z","createdAt":"2026-01-22T15:44:40.027Z"},{"id":"q-5799","question":"Design a NUMA-aware per-socket allocator for 128-byte objects on a 2-socket system. Each socket has a private 128KB pool and a shared pool. Implement alloc128() and free128() with per-socket freelists, cross-socket handoff, and epoch-based reclamation. Explain layout, fragmentation, wrap/overflow handling, and provide a minimal microbenchmark plan to measure local throughput and cross-socket latency?","answer":"Local per-socket 128KB pools with per-socket freelists; a shared pool; alloc128() prefers local freelist, then pulls from shared using atomic operations; free128() returns to the local pool if the obj","explanation":"## Why This Is Asked\nExplores NUMA-aware memory management, cross-socket reclamation, and low-latency allocation paths under contention.\n\n## Key Concepts\n- NUMA-aware allocators\n- Per-socket freelists and cross-socket handoff\n- Epoch-based reclamation or hazard pointers\n- Fragmentation and cache-line padding\n\n## Code Example\n```c\n// Pseudo API and skeleton\nvoid init_pools(void* local_base, size_t local_size, void* shared_base, size_t shared_size);\nvoid* alloc128();\nvoid free128(void* p);\n\n// Allocation sketch: check local freelist, else pull from shared, else refill local\n```\n\n## Follow-up Questions\n- How would you adapt this to 4+ sockets and non-uniform capacities?\n- How to measure impact of cross-socket traffic on latency and throughput?","diagram":"flowchart TD\n  A[Request] --> B[Local pool check]\n  B --> C{Found?}\n  C -- Yes --> D[Return block]\n  C -- No --> E[Fetch from shared pool]\n  E --> F[If still not found, refill local]\n  F --> G[Return or cross-socket enqueue]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","NVIDIA","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T17:07:46.420Z","createdAt":"2026-01-22T17:07:46.420Z"},{"id":"q-5939","question":"Design and implement a simplified Tomasulo-style dynamic scheduler in C/C++: 4 reservation stations, 2 functional units, an 8-entry Reorder Buffer, and a single Common Data Bus. Provide issue, execute, and write-back pseudo-code, operand tagging, and how you handle branches and commit. Include a brief microbenchmark plan to measure throughput and stall behavior under data hazards?","answer":"Implement a Tomasulo-style dynamic scheduler featuring 4 reservation stations, 2 functional units, an 8-entry Reorder Buffer, and a single Common Data Bus. The system utilizes tag-based operand handling where instructions issue to available reservation stations, stalling when source operands are not ready and propagating operand tags. Upon functional unit completion, results broadcast via the CDB to all waiting reservation stations and corresponding ROB entries. Commit occurs in program order from the ROB head, with branch mispredictions handled by flushing speculative entries and redirecting instruction fetch.","explanation":"## Why This Is Asked\nAssesses practical understanding of out-of-order execution, hazard resolution, and correctness under mispredictions in a compact model.\n\n## Key Concepts\n- Tomasulo algorithm with reservation stations\n- Tag-based operands and CDB broadcast\n- Reorder buffer for in-order commit and branch misprediction rollback\n\n## Code Example\n\n```cpp\n// Pseudo-code implementation\nstruct RS { int op; bool ready; int tag; int val; };\nstd::vector<RS> rs(4);\nstruct ROB { int pc; bool done; int value; int tag; };\n```\n\n## Follow-up Questions\n\n- How would you extend to multiple CDB broadcasts with","diagram":"flowchart TD\n  Fetch[Fetch] --> Decode[Decode]\n  Decode --> Issue{Issue?}\n  Issue --> DispatchRS[Dispatch RS]\n  DispatchRS --> Execute[Execute]\n  Execute --> WriteBack[CDB Writeback]\n  WriteBack --> Commit[Commit]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Hashicorp","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T05:39:07.572Z","createdAt":"2026-01-22T22:48:30.821Z"},{"id":"q-6051","question":"Design a bounded, in-memory IPC channel for two threads using a shared 4KB ring buffer. Provide API init_channel(void* mem, size_t size), int ch_write(const void* data, size_t len), int ch_read(void* out, size_t max). Ensure atomicity, per-slot headers for len and seq, support partial writes/reads, and discuss memory ordering and cache locality?","answer":"Use a 4KB circular buffer with per-slot header {uint16_t len; uint64_t seq;}. Maintain atomic head and tail. Writer reserves a slot via CAS on head, copies payload, sets len, and bumps seq to signal d","explanation":"## Why This Is Asked\nTests understanding of bounded buffers, atomic operations, and memory ordering in a minimal IPC path.\n\n## Key Concepts\n- Bounded ring buffer\n- Atomic CAS and fetch/store\n- Per-slot headers (len, seq)\n- Memory ordering and cache locality\n- Partial reads/writes and data integrity\n\n## Code Example\n```c\ntypedef struct {\n  uint16_t len;\n  uint64_t seq;\n  uint8_t data[64]; // example payload\n} slot_t;\n``` \n\n## Follow-up Questions\n- How would you extend to N producers and 1 consumer?\n- How would you handle slot corruption or power loss recovery?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","NVIDIA","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T06:57:42.857Z","createdAt":"2026-01-23T06:57:42.858Z"},{"id":"q-6125","question":"Design a two-level lock-free telemetry pipeline for a multi-socket server: each core has a 512-slot, 64-byte ring buffer with per-slot sequence counters; a central Aggregator ring drains from all cores to a single Consumer that feeds a PCIe DMA buffer. Provide slot layout, enqueue/dequeue pseudo-code, memory fences, wrap-around handling, and backpressure. Explain memory reclamation (epoch/hazard pointers) and discuss cache-line pitfalls. Include a microbenchmark plan for 10+ Gbps bursts?","answer":"Per-core rings: 512 slots, 64 bytes each, with per-slot 64-bit seq; central Aggregator ring drains into a single Consumer. Enqueue uses CAS on seq, then stores payload and updates seq with a release s","explanation":"## Why This Is Asked\nTests two-level lock-free design, cross-socket propagation, and memory reclamation under real-time loads.\n\n## Key Concepts\n- Lock-free rings with per-slot sequence counters\n- Two-level buffering: per-core + aggregator\n- Memory ordering: acquire/release fences, CAS\n- Reclamation: epoch-based or hazard pointers\n- Cache-line locality and false sharing awareness\n- Backpressure handling and wrap-around correctness\n\n## Code Example\n```c\ntypedef struct { uint64_t seq; uint8_t payload[56]; } slot_t;\ntypedef struct { slot_t slots[512]; uint64_t head, tail; } ring_t;\n``` \n\n## Follow-up Questions\n- How would you scale to 1024+ cores while keeping fairness?\n- What padding strategy prevents false sharing in the two-level design?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Tesla","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T09:58:40.906Z","createdAt":"2026-01-23T09:58:40.907Z"},{"id":"q-6144","question":"Design a lock-free, bounded ring buffer that supports N producers and M consumers across NUMA nodes, with a global version counter and per-slot sequence numbers to enable a consistent snapshot view for consumers. Provide enqueue/dequeue pseudo-code, describe ABA avoidance, memory reclamation via epochs, and analyze cache-line layout and false sharing. Propose a microbenchmark plan to validate throughput and latency under contention?","answer":"Use a fixed-size circular buffer with per-slot 64-bit sequence and payload. Head/tail are atomic. Enqueue: idx=head&mask; wait seq[idx]==head; write payload; seq[idx]=head+1; head++. Dequeue: idx=tail","explanation":"## Why This Is Asked\nAssesses low‑level lock-free design, memory ordering, and NUMA awareness; requires concrete, testable pseudo-code.\n\n## Key Concepts\n- Lock-free synchronization and false sharing avoidance\n- ABA avoidance with per-slot sequence numbers\n- Epoch-based memory reclamation\n- Cache-line alignment and 64B padding\n\n## Code Example\n```c\ntypedef struct { uint64_t seq; uint64_t data; } slot;\nslot buf[SIZE];\natomic_uint64 head, tail;\n// enqueue/dequeue sketches...\n```\n\n## Follow-up Questions\n- How would you prove correctness under weak memory models?\n- How would you adapt for multi-consumer multi-producer without starving?","diagram":"flowchart TD\n  A[Start] --> B[Initialize slots with seq = index]\n  B --> C[Enqueue path]\n  C --> D[Dequeue path]\n  D --> E[Validate with stress test]\n  E --> F[End]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Scale Ai","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T10:53:39.894Z","createdAt":"2026-01-23T10:53:39.894Z"},{"id":"q-6272","question":"Design a durable, crash-safe, lock-free queue for a 2-socket server using non-volatile memory (PMEM) that guarantees correct enqueue/dequeue across power failures. Provide a bounded, multi-producer, single-consumer ring with wrap-around, per-entry header (len, seq, committed), and a recovery procedure after crash. Include pseudo-code for enqueue/dequeue, a test plan, and a micro-benchmark?","answer":"Implement a circular log in PMEM with per-entry header {len, seq, committed}. Enqueue writes payload, then header; flush order with clwb/siws and mfence; consumer validates header and reads payload un","explanation":"## Why This Is Asked\nThis question probes crash-safe, low-latency data paths in persistent memory architectures.\n\n## Key Concepts\n- Non-volatile memory ordering (clwb/flush, sfence).\n- Crash-consistent ring buffers and per-entry headers.\n- Epoch-based reclamation and GC for reuse.\n- Testing crash-recovery and power-failure scenarios.\n\n## Code Example\n```c\ntypedef struct { uint32_t len; uint64_t seq; uint8_t committed; } entry_hdr_t;\n```\n\n## Follow-up Questions\n- How would you benchmark recovery latency and correctness after abrupt power loss?\n- What would you change for multi-consumer support?","diagram":"flowchart TD\n  A[Producer] --> B[Write payload to PMEM slot]\n  B --> C[Write header and commit]\n  C --> D[Consumer sees committed header]\n  D --> E[Consumer reads payload]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Microsoft","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T17:04:49.100Z","createdAt":"2026-01-23T17:04:49.100Z"},{"id":"q-6278","question":"Design a two-level, lock-free timer wheel in C for a high-throughput event scheduler across 8 cores. Outer wheel: milliseconds; inner wheel: microseconds. Each timer stores deadline, callback, and linkage. Enqueue uses thread-local slots and atomic stores; tick advances outer wheel, moves due timers to inner wheel for immediate execution, with epoch-based reclamation. Compare latency and jitter vs a heap queue?","answer":"Two-level timer wheel with outer 1ms buckets and inner 1µs buckets. Timers hold deadline, cb_id, and next pointer. Enqueue places the timer in the target outer bucket via per-thread slot with atomic s","explanation":"## Why This Is Asked\nTests ability to design a deterministic low-latency timer structure with lock-free synchronization and practical reclamation in a multi-core environment.\n\n## Key Concepts\n- Timer wheels, two-level design\n- Lock-free synchronization, atomic ops\n- Epoch-based reclamation and hazard pointers equivalent\n- Cache-line and false sharing considerations\n- Microbenchmark methodology\n\n## Code Example\n```c\n// Skeleton definitions\ntypedef struct timer {\n  uint64_t deadline;\n  void (*cb)(void*);\n  struct timer *next;\n} timer_t;\n```\n\n## Follow-up Questions\n- How would you scale to dynamic bucket counts?  \n- How would you support timer cancellation efficiently?","diagram":"flowchart TD\n  A[Enqueue Timer] --> B[Place in Outer Bucket]\n  B --> C[Tick Outer Wheel]\n  C --> D[Move to Inner Wheel]\n  D --> E[Execute or Reclaim]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Lyft","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T17:36:29.403Z","createdAt":"2026-01-23T17:36:29.403Z"},{"id":"q-6717","question":"Design a tiny, NUMA-aware allocator for a real-time scheduler on a 2-socket system: each thread allocates 128-byte aligned blocks from a per-thread free list; when empty, replenish from a central arena via a lock-free, CAS-based protocol. Provide allocate() and free() in C, with thread-safe init and minimal locking. Analyze fragmentation, cache locality, and worst-case latency under contention?","answer":"Per-thread 128-byte blocks; each thread keeps a lock-free freelist; when empty, replenish from a central arena via a lock-free pool using CAS. allocate() pops from thread list or fetches a batch, free","explanation":"## Why This Is Asked\nThe question probes deep understanding of per-thread caches, central allocators, NUMA locality, and lock-free synchronization under real-time constraints.\n\n## Key Concepts\n- Lock-free freelists and CAS-based central pool\n- Fixed-size, aligned blocks for cache/TLB locality\n- NUMA-aware replenishment and fragmentation trade-offs\n\n## Code Example\n```javascript\n// High-level sketch (C-like, for illustration)\ntypedef struct block { struct block *next; } block_t;\ntypedef struct thread_cache { block_t *head; } tcache_t;\ntypedef struct arena { _Atomic(void*) head; } arena_t;\n\nvoid* allocate(tcache_t *tc) {\n  if (tc->head) { void *p = tc->head; tc->head = tc->head->next; return p; }\n  block_t *chunk = arena_fetch_batch();\n  // distribute blocks to thread cache and return one\n  // ...\n  return allocate(tc);\n}\n\nvoid free_(tcache_t *tc, void *p) {\n  ((block_t*)p)->next = tc->head;\n  tc->head = (block_t*)p;\n}\n```","diagram":"flowchart TD\n  A[Thread] --> B[Thread-local freelist]\n  B --> C{Empty?}\n  C -- Yes --> D[Replenish from central arena]\n  D --> C\n  C -- No --> E[Allocate from thread cache]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Oracle","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T14:34:51.642Z","createdAt":"2026-01-24T14:34:51.642Z"},{"id":"q-6753","question":"Design and implement a NUMA-aware small-object allocator for a 2-socket server. Use per-thread caches for <=128-byte objects, backed by a central pool on a designated NUMA node. Detail API, layout, and atomic sync; address cache-line alignment, false sharing, and rebalance on thread migrations. Include a minimal C/C++ skeleton and a microbenchmark plan?","answer":"Design a NUMA-aware allocator with per-thread caches for <=128-byte objects, backed by a central pool on a designated NUMA node. API: alloc/free; layout: per-thread freelists + central pool; sync via ","explanation":"## Why This Is Asked\nTests practical memory allocator design with NUMA awareness, cache locality, and contention handling in high-concurrency environments.\n\n## Key Concepts\n- NUMA locality, per-thread caches, central pool\n- Atomic synchronization, memory ordering\n- Cache-line padding, false sharing avoidance\n- Thread migration and dynamic rebalance\n\n## Code Example\n```cpp\n// Skeleton API for a NUMA-aware small-object allocator\nclass NumaSmallAlloc {\npublic:\n  void* alloc(size_t size);\n  void  free(void* ptr);\n  // initialization/sharding omitted\n};\n``` \n\n## Follow-up Questions\n- How would you validate cross-socket traffic reduction with microbenchmarks?\n- What fragmentation scenarios are most likely and how would you mitigate them?\n","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T15:48:11.240Z","createdAt":"2026-01-24T15:48:11.240Z"},{"id":"q-6815","question":"Design a NUMA-aware, per-worker work-stealing scheduler for a user-space thread pool in C++. Each worker has a local 64-byte-aligned queue; idle workers steal from the least-loaded neighbor using tagged indices to avoid ABA. Provide enqueue, pop, and steal with memory fences; discuss cache locality, false sharing, and fairness. Outline a microbenchmark plan across 2 NUMA nodes with 8 threads?","answer":"Design a NUMA-aware, per-worker lock-free deque scheduler in C++. Each worker has a 64-byte-aligned local queue; idle workers steal from the least-loaded neighbor using tagged indices to avoid ABA. Us","explanation":"## Why This Is Asked\nTests understanding of real-world low-level concurrency, memory locality, and practical trade-offs in multi-socket systems. It blends lock-free data structures with NUMA-aware scheduling and stress testing.\n\n## Key Concepts\n- NUMA locality and memory bandwidth\n- Lock-free deques and work stealing\n- ABA avoidance with tagging or epochs\n- Cache-line alignment and false sharing avoidance\n- Memory order semantics and fences\n\n## Code Example\n```javascript\n// Skeleton (C++-like pseudo): Deque per worker with 64-byte alignment\nclass Deque {\npublic:\n  alignas(64) std::atomic<size_t> head{0};\n  alignas(64) std::atomic<size_t> tail{0};\n  // slots: aligned storage for Task*\n  void push(Task* t) { /* local enqueue: tail.fetch_add(1, relaxed) */ }\n  Task* pop() { /* local pop with acquire on read, relaxed on write */ }\n  Task* steal() { /* steal from victim: CAS head with acquire, update tail */ }\n};\n```\n\n## Follow-up Questions\n- How would you handle memory reclamation for stolen tasks?\n- How would you extend to more than 2 NUMA nodes and ensure fairness across nodes?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","OpenAI","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T18:48:58.070Z","createdAt":"2026-01-24T18:48:58.071Z"},{"id":"q-684","question":"Design a fixed-size ring buffer in C that stores bytes. Capacity N is a power of two (e.g., 1024). Show how to compute the next index using a mask (idx & (N-1)), and explain full vs empty detection using only head and tail counters. Provide enqueue and dequeue logic for a single-producer/single-consumer scenario?","answer":"Use two indices: head and tail. Let mask = N-1. Enqueue: if ((head - tail) == N) return 0; data[head & mask] = value; head++; Dequeue: if (head == tail) return 0; *out = data[tail & mask]; tail++; Thi","explanation":"## Why This Is Asked\n\nTests understanding of a practical, low-level data structure and its wrap-around behavior, plus efficient empty/full checks in a simple producer/consumer path.\n\n## Key Concepts\n\n- Ring buffers\n- Power-of-two masking\n- Empty/full checks with head/tail without extra state\n- SPSC memory ordering\n\n## Code Example\n\n```c\ntypedef struct {\n  size_t head, tail;\n  unsigned char data[N];\n} Ring;\n\nint enqueue(Ring *r, unsigned char value) {\n  if ((r->head - r->tail) == N) return 0; // full\n  r->data[r->head & (N - 1)] = value;\n  r->head++;\n  return 1;\n}\nint dequeue(Ring *r, unsigned char *out) {\n  if (r->head == r->tail) return 0; // empty\n  *out = r->data[r->tail & (N - 1)];\n  r->tail++;\n  return 1;\n}\n```\n\n## Follow-up Questions\n\n- How would you modify for multi-producer/multi-consumer?\n- What memory-ordering considerations arise on weakly-ordered architectures?","diagram":"flowchart TD\n  A[Head/Tail] --> B[Mask: (N-1)]\n  B --> C[Enqueue path]\n  B --> D[Dequeue path]\n  C --> E[Increment Head]\n  D --> F[Increment Tail]\n  E --> G{Full?}\n  F --> H{Empty?}","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Hugging Face","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T15:59:22.270Z","createdAt":"2026-01-11T15:59:22.270Z"},{"id":"q-6888","question":"You're given a 1 GiB shared memory region mapped into two processes on a 2-socket NUMA system. Design a NUMA-aware cross-process allocator with per-process caches and a global coalescing pool. Provide APIs: init(region_ptr, size), allocate(size, align), free(ptr). Describe data structures, a fast-path for small allocations (<128 bytes) using per-process freelists, lock-free coordination to minimize cross-socket traffic, and a fragmentation-resilient strategy. Include a concise microbenchmark plan comparing against malloc under cross-thread contention?","answer":"Implement a hierarchical NUMA-aware allocator with per-process caches and global coordination. The design consists of three tiers: per-process freelists for small allocations (<128 bytes), per-NUMA-node pools for medium allocations, and a global coalescing pool for large allocations and reclamation. Use atomic operations for cross-process coordination, with thread-local caches populated via fetch-add from size-class buckets. Place allocation metadata on the local NUMA node to minimize remote memory access. The APIs are: `init(region_ptr, size)` sets up the shared region and initializes metadata; `allocate(size, align)` first checks the per-process freelist (fast path), then falls back to per-NUMA-node pools, finally to the global pool; `free(ptr)` returns memory to the local cache, triggering background coalescing when thresholds are exceeded. The fragmentation-resilient strategy uses buddy system principles for large blocks and periodic defragmentation threads per NUMA node.","explanation":"## Why This Is Asked\nTests advanced knowledge of cross-process allocators, NUMA optimization, and concurrent systems design. Evaluates ability to balance performance, locality, and memory efficiency in shared memory environments.\n\n## Key Concepts\n- NUMA-aware memory placement\n- Cross-process shared memory coordination\n- Lock-free algorithms and atomic operations\n- Fragmentation mitigation strategies\n- Hierarchical caching for performance optimization\n\n## Implementation Outline\n```c\n// Core data structures\ntypedef struct {\n    atomic_ptr next;\n    uint32_t size_class;\n    uint8_t numa_node;\n} free_block_t;\n\ntypedef struct {\n    atomic_ptr freelist[NUM_SIZE_CLASSES];\n    atomic_uint32_t counters[NUM_SIZE_CLASSES];\n} per_process_cache_t;\n\n// Fast-path allocation\nvoid* allocate_fast(size_t size, size_t align) {\n    if (size < 128) {\n        int class = size_to_class(size);\n        return pop_from_freelist(&cache->freelist[class]);\n    }\n    return allocate_slow_path(size, align);\n}\n```\n\n## Microbenchmark Plan\nCompare against malloc using: (1) Cross-thread allocation with 2-16 threads on different NUMA nodes, measuring latency and throughput; (2) Alloc/free burst patterns with varying object sizes (16B-1KB); (3) Sustained mixed allocation patterns to test fragmentation resistance; (4) NUMA locality impact tests with controlled placement. Metrics include: ops/sec, tail latency (P95/P99), memory overhead, and NUMA remote memory accesses.\n\n## Follow-up Questions\n- How would you extend this to dynamic process joining/leaving?\n- What garbage collection strategies would prevent memory bloat?\n- How would you handle allocation failure under memory pressure?\n- What instrumentation would you add for performance debugging?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:04:05.147Z","createdAt":"2026-01-24T21:41:25.275Z"},{"id":"q-692","question":"Design a lock-free ring buffer that supports multiple producers and multiple consumers with bounded capacity. Provide enqueue/dequeue pseudo-code, explain how you avoid ABA, how memory reclamation is handled (hazard pointers or epochs), and why it scales under high contention. Include caveats on cache lines and false sharing. How would you validate under stress?","answer":"Use a power-of-two ring buffer with per-slot sequence numbers and separate atomic head/tail indices. Each slot has a 64-bit sequence: low 32 bits = turn number, high 32 bits = slot index. Producers: read tail, compute slot, check sequence matches expected turn, CAS tail to reserve, write item, increment sequence. Consumers: read head, compute slot, check sequence matches expected turn, CAS head to advance, read item, increment sequence. ABA avoided by monotonically increasing sequence numbers (turn * capacity + index). Memory reclamation via epoch-based reclamation: threads enter critical section, publish retired nodes, exit when global epoch advances. Cache line padding: align head/tail indices and slot arrays to separate cache lines (64-byte boundaries) to avoid false sharing between producers and consumers.","explanation":"## Why This Is Asked\n\nTests understanding of low-level concurrency, lock-free design under real contention.\n\n## Key Concepts\n\n- MPMC queue design with sequence numbers\n- ABA protection via monotonic sequences\n- Memory reclamation (hazard pointers, epochs)\n- Cache friendliness and false sharing prevention\n\n## Code Example\n\n```c\n// Pseudo-code\nstruct Slot {\n    atomic_uint64_t seq;\n    void* data;\n};\n\nbool enqueue(void* item) {\n    uint64_t pos = tail.load();\n    Slot* slot = &buffer[pos & mask];\n    uint64_t seq = slot->seq.load();\n    if ((seq & mask) != (pos & mask)) return false;\n    if (!tail.compare_exchange(pos, pos + 1)) return false;\n    slot->data = item;\n    slot->seq.store(pos + 1);\n    return true;\n}\n\nvoid* dequeue() {\n    uint64_t pos = head.load();\n    Slot* slot = &buffer[pos & mask];\n    uint64_t seq = slot->seq.load();\n    if ((seq & mask) != (pos & mask)) return nullptr;\n    if (!head.compare_exchange(pos, pos + 1)) return nullptr;\n    void* item = slot->data;\n    slot->seq.store(pos + capacity + 1);\n    return item;\n}\n```\n\n## Follow-up Questions\n\n- How would you detect and recover from stalls under hot paths?\n- Compare hazard pointers vs epochs for this use-case.\n- What happens under backpressure when the buffer is full?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Databricks","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:54:20.888Z","createdAt":"2026-01-11T16:24:48.553Z"},{"id":"q-694","question":"Design a cache-friendly, per-thread deque work-stealer for a multi-core task executor. Each worker maintains a fixed-size ring buffer for bottom push/pop; thieves steal from the top of other workers via CAS on a top index with a version counter. Explain ABA avoidance, memory ordering, and padding to avoid false sharing. Provide precise pseudo-code and a realistic burst workload scenario?","answer":"Propose per-thread deques with a bottom push/pop and a shared top for steals. Local path uses a fixed-size, cache-aligned ring; steals CAS on top with a version tag to prevent ABA; pad structures to p","explanation":"## Why This Is Asked\nTests ability to design scalable, non-blocking schedulers and reason about ABA, memory ordering, and cache effects.\n\n## Key Concepts\n- Work-stealing deques\n- ABA avoidance with version counters\n- Cache-line padding to avoid false sharing\n- Memory order: acquire/release\n- Backoff and fairness under bursty loads\n\n## Code Example\n```javascript\n// Pseudo-code: per-thread deque with local and steal paths\nclass Deque {\n  constructor(cap) { /* ... */ }\n  pushBottom(x) { /* O(1) with cache-friendly indices */ }\n  popBottom() { /* ... */ }\n  stealTop(owner) { /* CAS on top with version, then claim slot */ }\n}\n```\n\n## Follow-up Questions\n- How would you test tail latency under bursty arrival rates?\n- How would you adapt the design for multi-socket NUMA and cache-coherent interconnects?\n- How would you extend to prioritized tasks or dynamic resizing of ring buffers?","diagram":"flowchart TD\n  A[Worker i deque] --> B[Push/Pop bottom (local)]\n  A --> C[Steal from top of another worker]\n  D[Top pointer with version tag] --> E[ABA avoidance via CAS/version]\n  B --> F[Local fast path]\n  C --> G[Successful steal -> task transfer]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:13.498Z","createdAt":"2026-01-11T17:16:13.498Z"},{"id":"q-6946","question":"Design a crash-consistent PMEM allocator for a fixed 1MB arena with 128-byte blocks. Provide API prototypes, a compact layout, and pseudo-code for alloc/free/recover, ensuring crash durability and correct recovery. Discuss a small commit journal, per-block headers, and how to enforce ordering with flushes?","answer":"Design a crash-consistent PMEM allocator for a fixed 1MB arena with 128-byte blocks. Each block includes a header storing `next_offset` and `in_use` metadata. The allocator maintains a persistent global head pointer. Allocation uses atomic compare-and-swap to pop blocks from the free list, while deallocation pushes blocks back atomically. A small commit journal records allocation operations to ensure crash durability, with proper memory flushes and barriers to enforce ordering guarantees during recovery operations.","explanation":"## Why This Is Asked\n\nTests understanding of crash-safe memory allocators for persistent memory, including durable data structures, memory ordering, and recovery mechanisms.\n\n## Key Concepts\n\n- Persistent memory semantics and flush/barrier instructions\n- Atomic operations (CAS) on a shared free list\n- Crash-recovery journaling and idempotent replay\n- Per-thread caches to reduce contention\n- Memory ordering constraints and cache line alignment\n\n## Code Example\n\n```javascript\n// API usage example demonstrates practical implementation\nconst allocator = new PMEMAllocator(arena);\nconst block = allocator.alloc();  // Returns 128-byte block\nallocator.free(block);           // Returns block to free list\n```\n\n## Follow-up Questions\n\n- How would you extend this design to support variable block sizes?\n- What optimizations would you add for high-concurrency scenarios?\n- How would you handle fragmentation over time?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:35:44.468Z","createdAt":"2026-01-24T23:46:31.212Z"},{"id":"q-7008","question":"Design a cache-friendly 2D matrix transpose in C for an N x M int matrix using tiling. Provide function signature: void transpose(int N, int M, const int A[N][M], int B[M][N]); Use a tile size like 16 or 32, explain how this affects L1/cache behavior, and discuss edge-case handling when N or M is not multiples of the tile size?","answer":"Implement a cache-friendly transpose with 16x16 tiling: for r,c in steps, copy A[i][j] to B[j][i] within each tile, clipping bounds at edges. This increases L1 reuse and reduces cache misses; final co","explanation":"## Why This Is Asked\nTests ability to reason about memory access patterns and cache locality in a practical loop, not just algorithmic correctness.\n\n## Key Concepts\n- Cache locality\n- Blocking/tiling\n- L1 data reuse\n- Edge-case handling\n\n## Code Example\n```javascript\nvoid transpose(int N, int M, const int A[][M], int B[][N]) {\n  const int BS = 16;\n  for (int r = 0; r < N; r += BS)\n    for (int c = 0; c < M; c += BS) {\n      int rmax = (r + BS > N) ? N : r + BS;\n      int cmax = (c + BS > M) ? M : c + BS;\n      for (int i = r; i < rmax; ++i)\n        for (int j = c; j < cmax; ++j)\n          B[j][i] = A[i][j];\n    }\n}\n```\n\n## Follow-up Questions\n- How would you benchmark the cache miss rate vs a naive row-major transpose?\n- How does tile size affect performance on different CPU architectures?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:39:10.020Z","createdAt":"2026-01-25T05:39:10.020Z"},{"id":"q-7064","question":"Design a host-side, NUMA-aware allocator for a PCIe device descriptor stream. The allocator must serve 64-byte blocks, align to 64-byte boundaries, and minimize cross-socket traffic by using per-NUMA freelists and batch reclamation. Provide an API: init_allocator(void* arena, size_t size), void* alloc64(), void free64(void*). Show data structures, discuss fragmentation, cache-line padding, and a microbenchmark plan comparing against malloc-family allocations under contended threads?","answer":"To stream descriptors efficiently, implement per-NUMA freelists with 64-byte alignment, batch reclamation, and a tiny allocator header per socket. Pin arenas to sockets, avoid cross-socket frees, and ","explanation":"## Why This Is Asked\nNUMA-aware allocators are critical for latency-sensitive devices on multi-socket servers. This tests design choices: per-NUMA freelists to minimize cross-socket traffic, batch reclamation to amortize costs, and 64-byte alignment to suit descriptor formats. Candidates must justify fragmentation controls, cache-line padding, and thread-safety.\n\n## Key Concepts\n- NUMA locality and cross-socket traffic\n- Lock-free or low-contention freelists\n- Cache-line padding to avoid false sharing\n- Batch reclamation vs per-allocation overhead\n- Fragmentation management and arena growth\n\n## Code Example\n```javascript\n// Pseudo-API sketch for per-NUMA allocator (high-level)\ntypedef struct { ... } Block64;\nvoid init_allocator(void* arena, size_t size);\nvoid* alloc64();\nvoid free64(void* ptr);\n```\n\n## Follow-up Questions\n- How would you generalize to other block sizes? \n- How would you validate both correctness and micro-benchmark performance?","diagram":"flowchart TD\n  A[Init allocator] --> B[allocate per-NUMA pools]\n  B --> C[alloc64]\n  C --> D[free64]\n  D --> A","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T07:44:47.777Z","createdAt":"2026-01-25T07:44:47.777Z"},{"id":"q-707","question":"Design a crash‑consistent, multi‑producer/multi‑consumer ring buffer backed by persistent memory PMEM. How would you ensure last enqueued item durability across power loss, implement recovery, and validate correctness? Provide concise enqueue/dequeue pseudocode with proper flush/fence ordering and discuss failure scenarios?","answer":"Use a crash‑safe PMEM ring buffer with two‑phase publish: write the data to the next slot, flush the data, then publish by updating a durable tail with a release store and a fence (sfence/clwb). Use p","explanation":"## Why This Is Asked\n\nTests ability to design crash‑consistent data paths in persistent memory, a common production issue when power failures occur during in‑flight operations.\n\n## Key Concepts\n\n- Durability guarantees for PMEM writes\n- Memory ordering: release/acquire, fences, cacheline flushes\n- Recovery via redo log and slot sequence counters\n- ABA avoidance in a concurrent ring\n- Testing with fault injection and crash replay\n\n## Code Example\n\n```c\n// Pseudo-code: enqueue/dequeue with PMEM flush/fence\n// Slot: { data, seq, valid }\nvoid enqueue(T v){\n  size_t t = tail.fetch_add(1);\n  Slot *s = &ring[t % CAP];\n  s->data = v; // write data\n  clwb(&s->data, sizeof(T));\n  fence(); // ensure data persists\n  s->seq = t; // publish with durable tail update (release)\n  clwb(&s->seq, sizeof(size_t));\n  fence();\n  // publish tail already happens via atomic tail update\n}\n\nbool dequeue(T *out){\n  size_t h0 = head.load();\n  Slot *s = &ring[h0 % CAP];\n  if (s->seq != h0) return false;\n  *out = s->data;\n  s->valid = false;\n  clwb(&s->valid, sizeof(bool));\n  fence();\n  head.fetch_add(1);\n  return true;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle power loss during the publish vs data write steps?\n- How would you validate recovery correctness across multiple restart scenarios?","diagram":"flowchart TD\n  A[Producer Enqueue] --> B[Write Slot Data] \n  B --> C[Flush Data] \n  C --> D[Publish Tail] \n  D --> E[Consumer Dequeue]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Coinbase","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:29:56.756Z","createdAt":"2026-01-11T18:29:56.756Z"},{"id":"q-712","question":"Design a NUMA-aware in-memory index with per-node shards and a lock-free cross-node coordinator. Provide insertion and lookup with minimal locking, specify data layout (shards, padding, key/value encodings), and memory-order guarantees (fences, atomic ops). Describe a deadlock-free shard rebalancing protocol under high contention and outline tests with realistic Snowflake/Twitter-scale workloads?","answer":"Per-node shards with a global coordinator. Lock-free hot path: atomic upserts into per-node arrays using CAS, with 64-byte padding; memory order: acquire/release fences around reads/writes; cross-node","explanation":"## Why This Is Asked\nTests understanding of NUMA-aware design, lock-free data paths, and safe shard rebalancing under contention in large-scale systems.\n\n## Key Concepts\n- NUMA affinity and per-node shard layouts\n- Lock-free synchronization with CAS and memory fences\n- Cache-line padding to prevent false sharing\n- Epoch-based or versioned rebalance without blocking\n\n## Code Example\n```cpp\n// Pseudo core: per-node shard insert using CAS\nstruct Shard { std::atomic<Key> key; std::atomic<Value> val; char pad[64]; };\nvoid insert(Shard* s, Key k, Value v){ auto old = s->key.load(std::memory_order_acquire); if(old==k) { s->val.store(v, std::memory_order_release); return; } // CAS loop omitted }\n```\n\n## Follow-up Questions\n- How would you validate correctness under cross-node contention?\n- What are failure modes under memory-order relaxations?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:16:51.595Z","createdAt":"2026-01-11T19:16:51.595Z"},{"id":"q-7137","question":"Design a cache-aware per-thread allocator for a fixed-size pool of 64-byte objects. Each thread maintains a private freelist sourced from a global pool; implement O(1) allocate/free in C, ensure 64-byte alignment, avoid false sharing, and explain cross-thread reclamation when a thread exits?","answer":"Implement a per-thread allocator for fixed-size 64-byte objects. Each thread stores a local freelist aligned to 64 bytes; allocate pops from local free list, refills from a global lock-free stack when","explanation":"## Why This Is Asked\nTests knowledge of per-thread allocators, memory alignment, false sharing, and lock-free data structures with safe cross-thread reclamation.\n\n## Key Concepts\n- Per-thread caches and local freelists\n- Cache-aligned blocks and padding to prevent false sharing\n- Lock-free global pool refills with atomic ops\n- Reclamation strategies (epoch/grace period) for thread exits\n\n## Code Example\n```c\ntypedef struct Node { struct Node* next; } Node;\ntypedef struct { alignas(64) Node* head; Node* pool; size_t cap; } Freelist;\n```\n\n## Follow-up Questions\n- How would you measure fragmentation and allocator contention?\n- How would you extend to variable-sized objects or multi-object alignment?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Square","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T10:41:38.451Z","createdAt":"2026-01-25T10:41:38.451Z"},{"id":"q-723","question":"Design a software-based **TLB** for a 4-core 64-bit system with 4KiB pages. Each core has a private 128-entry **TLB** and a global page-table invalidation path. Provide lookup/refill pseudo-code, discuss eviction strategy (LRU vs. random), synchronization via **memory fences**, and cross-core shootdowns. Include a test under memory pressure and explain validation?","answer":"Private per-core 128-entry TLB, 4KiB pages, 4-way set-associative. On miss, walk multi-level page tables, then install using atomic ops. Use a scalable eviction (pseudo-LRU). Invalidate entries across","explanation":"## Why This Is Asked\n\nA software TLB with per-core caches and cross-core invalidations tests low-level thinking about coherence, consistency, and performance under contention. It also probes trade-offs between eviction, barriers, and hardware hints.\n\n## Key Concepts\n\n- TLB structure: per-core caches, set-associative layout\n- Page-table walk costs and caching gains\n- Cross-core invalidation/shootdown mechanisms\n- Memory fences and atomic updates\n- Validation under memory pressure and realistic workloads\n\n## Code Example\n\n```javascript\n// Pseudo-code: TLB lookup and refill\nfunction tlbLookup(vpn){\n  const idx = vpn % 128;\n  const e = tlb[idx];\n  if (e && e.vpn === vpn && e.valid) return e.pte;\n  return null;\n}\nfunction tlbRefill(vpn, pte){\n  const idx = vpn % 128;\n  tlb[idx] = { vpn, pte, valid: true, ts: Date.now() };\n}\n```\n\n## Follow-up Questions\n\n- How would you scale to larger pages or userfaults?\n- How would you validate correctness under concurrent refills and shootdowns?","diagram":"flowchart TD\n  A[Core] --> B[TLB miss]\n  B --> C[Page walk]\n  C --> D[Install entry]\n  D --> E[Shoot down other cores]\n  E --> F[Return to caller]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Oracle","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T20:24:01.827Z","createdAt":"2026-01-11T20:24:01.827Z"},{"id":"q-7240","question":"Design and implement a tiny bitmap-based memory allocator in C for a 1KB arena that serves 8-byte blocks. Provide API: void mem8_init(void* arena, size_t size); void* mem8_alloc(); void mem8_free(void* ptr). Use a bitmap to track free blocks; ensure alignment and avoid double-free; include a minimal test snippet and discuss race conditions in a single-threaded context?","answer":"Implement a 1KB bitmap-based allocator for 8-byte blocks. Arena: 16-byte bitmap header, then data; up to 128 blocks. Use two uint64_t words for the bitmap. mem8_init clears the bitmap; mem8_alloc sear","explanation":"## Why This Is Asked\nTests fundamental low-level memory management, bit-twiddling, and safety in a confined arena.\n\n## Key Concepts\n- Bitmap-based allocators\n- Alignment and bounds checks\n- Safety against double-free\n\n## Code Example\n```c\n#include <stdint.h>\n#include <stddef.h>\n\ntypedef struct { uint64_t m0, m1; unsigned char* data; size_t blocks; } mem8_pool;\n\nvoid mem8_init(mem8_pool* p, void* arena, size_t size){ p->data=(unsigned char*)arena+16; p->blocks=(size-16)/8; p->m0=0; p->m1=0; }\n\nvoid* mem8_alloc(mem8_pool* p){ for(int i=0;i<128;i++){ int word = i/64; int bit = i%64; uint64_t mask = (1ULL<<bit); uint64_t* w = (word==0)? &p->m0 : &p->m1; if(!(*w & mask)){ *w |= mask; return p->data + i*8; } } return NULL; }\n\nvoid mem8_free(mem8_pool* p, void* ptr){ size_t idx = ((unsigned char*)ptr - p->data)/8; if(idx< p->blocks){ int word = idx/64; int bit = idx%64; uint64_t mask = (1ULL<<bit); uint64_t* w = (word==0)? &p->m0 : &p->m1; *w &= ~mask; } }\n```\n\n## Follow-up Questions\n- How to extend to dynamic arena growth?\n- How to add thread-safety or locking strategies?\n- Compare space efficiency and fragmentation to a free-list allocator.","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T14:54:06.376Z","createdAt":"2026-01-25T14:54:06.376Z"},{"id":"q-725","question":"Design a crash-consistent, in-memory index for a 4-byte key, 8-byte value store on an 8-core Linux machine. Use per-core log-structured segments and a Bloom filter; describe durable append ordering, startup recovery by replaying per-core logs, and validation under power-loss scenarios?","answer":"Per-core logs minimize contention; mutations append to local segments, then a durable epoch fence persists metadata. Recovery replays per-core segments to rebuild the index; Bloom filters speed lookup","explanation":"## Why This Is Asked\n\nThis question probes experience with crash-consistent in-memory structures, per-core data locality, and durable metadata synchronization under power failures—critical in low-latency financial/ads platforms.\n\n## Key Concepts\n\n- Per-core log-structured index and Bloom filter for fast lookups\n- Durable append order via epoch fences and fsync/msync semantics\n- Recovery by replaying per-core logs in a deterministic order\n- False sharing minimization and memory-mapped file durability\n\n## Code Example\n\n```javascript\n// Pseudo replay of per-core logs to rebuild index\nfunction replay_logs(coreLogs) {\n  for (const core of coreLogs) {\n    for (const entry of core.segments) {\n      apply(entry);\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How do you handle Bloom filter false positives during recovery?\n- What are the failure modes during corruption of a core log segment, and how do you detect them?\n- How would you validate performance under steady-state and crash-recovery cycles?","diagram":"flowchart TD\n  A[Mutate] --> B[Append to Core Log]\n  B --> C[Durable Epoch Fence]\n  C --> D[Query index with Bloom filter]\n  D --> E[Recovery uses per-core logs]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T21:16:32.089Z","createdAt":"2026-01-11T21:16:32.089Z"},{"id":"q-734","question":"Design an epoch-based reclamation scheme for a lock-free stack in a 64-bit, multi-threaded user-space library. Each thread publishes its local epoch; a global clock advances periodically. On pop, move the node to a retire-list with its epoch and reclaim only after all threads have observed an epoch older than that node. Include a stress test with high contention?","answer":"Use epoch-based reclamation for a lock-free stack. Each thread publishes a local epoch; a global epoch advances periodically. On pop, retire the node with its epoch and reclaim only after all threads ","explanation":"## Why This Is Asked\nThis question probes practical low-level memory management under concurrency, including safe reclamation without locks.\n\n## Key Concepts\n- Lock-free data structures\n- Epoch-based reclamation\n- Memory ordering and fences\n- ABA avoidance\n\n## Code Example\n```javascript\n// Minimal epoch-based reclamation sketch\nclass Node { constructor(val) { this.val = val; this.next = null; } }\n\n// Global state\nlet globalEpoch = 0;\nlet threadEpochs = new Map();\n\n// Publish epoch from a thread\nfunction publishEpoch(epoch) { /* store per-thread epoch */ }\n\n// Retire a node\nfunction retire(node, epoch) { /* add to retire list with epoch */ }\n\n// Reclaim loop\nfunction advanceEpoch() { globalEpoch++; }\n```\n\n## Follow-up Questions\n- How would you detect and prevent ABA in this scheme?\n- How would you tune epoch advancement to avoid memory starvation under bursty workloads?\n","diagram":"flowchart TD\n  A[Publish epoch] --> B[Update stack head with CAS]\n  B --> C[Retire node into epoch list]\n  C --> D[Global epoch advances]\n  D --> E[Reclaim when all seen < retire epoch]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Lyft","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:18:50.970Z","createdAt":"2026-01-11T22:18:50.970Z"},{"id":"q-7356","question":"Design and implement a fixed-capacity hash table in C for 32-bit keys and 64-bit values using open addressing with linear probing (N = 1<<12). Use two arrays: keys[N], vals[N], with 0 as EMPTY. Provide init(), insert(uint32_t k, uint64_t v), and lookup(uint32_t k, uint64_t* out) that updates on collision and returns 0 on success, -1 if not found or table full. Assume key 0 is unused. Outline a minimal stress test?","answer":"Implement a fixed-capacity hash table in C for 32-bit keys and 64-bit values using open addressing with linear probing (N = 1<<12). Two arrays: keys[N], vals[N], with 0 as EMPTY. init() zeros; insert(","explanation":"## Why This Is Asked\nTests practical low-level data structure design under bounded resources, including probing, memory layout, and edge handling (empty slots, full table).\n\n## Key Concepts\n- Open addressing with linear probing\n- Fixed capacity and sentinel handling\n- Separate arrays for keys and values for cache locality\n- Return conventions for success/failure\n\n## Code Example\n```c\n#include <stdint.h>\n#include <stddef.h>\n\n#define N (1<<12)\nstatic uint32_t keys[N];\nstatic uint64_t vals[N];\n\nstatic inline size_t probe(uint32_t k) { return k % N; }\n\nvoid ht_init() {\n  for (size_t i = 0; i < N; ++i) keys[i] = 0;\n}\n\nint ht_insert(uint32_t k, uint64_t v) {\n  if (k == 0) return -1; // sentinel reserved\n  size_t idx = probe(k);\n  for (size_t i = 0; i < N; ++i) {\n    if (keys[idx] == 0) { keys[idx] = k; vals[idx] = v; return 0; }\n    if (keys[idx] == k) { vals[idx] = v; return 0; }\n    idx = (idx + 1) % N;\n  }\n  return -1; // full\n}\n\nint ht_lookup(uint32_t k, uint64_t* out) {\n  if (k == 0) return -1;\n  size_t idx = probe(k);\n  for (size_t i = 0; i < N; ++i) {\n    if (keys[idx] == 0) return -1;\n    if (keys[idx] == k) { *out = vals[idx]; return 0; }\n    idx = (idx + 1) % N;\n  }\n  return -1;\n}\n```\n\n## Follow-up Questions\n- How would you resize or rehash when load factor grows? \n- How to detect and recover from clustering effects in probing? \n- What are alternatives to sentinel-based empties (bitmaps, tombstones)?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Cloudflare"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T19:45:07.972Z","createdAt":"2026-01-25T19:45:07.972Z"},{"id":"q-7429","question":"Implement a lock-free, bounded multi-queue system with two priority rings (high and low). Producers choose ring based on a flag; each ring has N=1<<16 slots, 64-byte payload; per-slot 64-bit sequence counter to avoid ABA. Provide enqueue/dequeue pseudo-code with memory_order_release/acquire and a wrap-around check. Explain how you would measure latency and backpressure under mixed-priority traffic on a 2-socket NUMA server?","answer":"Use two fixed-size rings, per-slot 64-byte payload and 64-bit sequence counters; producers reserve a slot by atomically incrementing tail, write data, then publish with release; consumer uses acquire to read the sequence counter, validate data, then advance head. Handle wrap-around by checking that sequence increment fits within 64-bit range. On full queue, producers return false (backpressure). Consumers spin on sequence until new data appears.","explanation":"## Why This Is Asked\nTests knowledge of non-blocking data structures, ABA avoidance, memory ordering, and NUMA-aware performance under mixed-priority traffic. It also touches on backpressure and practical microbenchmark design.\n\n## Key Concepts\n- Lock-free design and ABA avoidance with per-slot sequence counters\n- Memory ordering: release on enqueue, acquire on dequeue\n- NUMA-aware layout and cache-line alignment\n- Priority routing, backpressure metrics, and spillover handling\n- Correct wrap-around handling and bounded capacity\n\n## Code Example\n```javascript\n// Ring buffer with 64-bit sequence per slot\nstruct Slot {\n    alignas(64) uint8_t data[64];\n    std::atomic<uint64_t> seq;\n};\n\nclass Ring {\n    Slot buffer[N];\n    std::atomic<uint64_t> head{0}, tail{0};\n    \npublic:\n    bool enqueue(const void* payload) {\n        uint64_t pos = tail.fetch_add(1, std::memory_order_relaxed);\n        uint64_t seq = buffer[pos & mask].seq.load(std::memory_order_acquire);\n        if (seq != pos) return false; // full or wrap-around\n        memcpy(buffer[pos & mask].data, payload, 64);\n        buffer[pos & mask].seq.store(pos + 1, std::memory_order_release);\n        return true;\n    }\n    \n    bool dequeue(void* payload) {\n        uint64_t pos = head.load(std::memory_order_relaxed);\n        uint64_t seq = buffer[pos & mask].seq.load(std::memory_order_acquire);\n        if (seq != pos + 1) return false; // empty\n        memcpy(payload, buffer[pos & mask].data, 64);\n        buffer[pos & mask].seq.store(pos + N + 1, std::memory_order_release);\n        head.store(pos + 1, std::memory_order_relaxed);\n        return true;\n    }\n};\n\n// Two rings per priority, producer selects based on flag\n```\n\n## Performance Measurement\n- **Latency**: Use RDTSC/RDTSCP around enqueue/dequeue, measure percentiles under mixed priority ratios (90/10, 50/50)\n- **Backpressure**: Count enqueue failures per ring, track queue depth, measure producer stall time\n- **NUMA**: Pin threads to sockets, allocate buffers locally, measure remote memory penalties\n- **Throughput**: Vary producer/consumer ratios, monitor cache miss rates with perf","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Goldman Sachs","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T05:09:06.708Z","createdAt":"2026-01-25T22:44:09.911Z"},{"id":"q-744","question":"In a 2-socket x86-64 server with MESI coherence, design a lock-free, multi-producer single-consumer ring buffer in shared memory for a 10 Gbps network path. Use per-slot sequence numbers to avoid ABA, with a fixed size N=1<<16 and 64-byte payload slots. Provide slot layout, push/pop pseudo-code with memory fences, discuss wrap-around and backpressure, and outline a minimal microbenchmark to validate throughput and data integrity under contention?","answer":"Implement a fixed-size ring (N=1<<16) in shared memory. Each slot stores a 64-bit seq and 64-byte payload. Producers write payload, increment seq, mfence, then CAS head. Consumer spins on tail, valida","explanation":"## Why This Is Asked\nTests lock-free IPC, memory ordering, and cache-coherence handling on NUMA systems under contention.\n\n## Key Concepts\n- Lock-free ring buffers with per-slot sequence numbers to avoid ABA\n- Memory ordering on x86-64, mfence usage, cache-line padding\n- Backpressure handling and wrap-around semantics\n\n## Code Example\n```c\ntypedef struct { volatile uint64_t seq; uint8_t data[64]; char pad[56]; } Slot;\ntypedef struct { Slot slots[N]; _Atomic uint64_t head; _Atomic uint64_t tail; } Ring;\n```\n\n```c\n// Push (producer)\nuint64_t pos; do { pos = atomic_read(&ring->head); if (slot_full(pos)) continue; } while(!atomic_compare_exchange(&ring->head, pos, pos+1));\nr ing->slots[pos & (N-1)].data = payload; ring->slots[pos & (N-1)].seq = pos; mfence();\n```\n\n## Follow-up Questions\n- How would you extend to multi-consumer or multi-ported rings?\n- What are the performance pitfalls and mitigations (false sharing, cache thrashing)?","diagram":"flowchart TD\n  A[Producers] --> B[Shared Ring Slots]\n  B --> C[Single Consumer]\n  C --> D[Tail Advancement]\n  E[Memory Fences] --> F[Orderly Visibility]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Tesla","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T23:19:01.045Z","createdAt":"2026-01-11T23:19:01.045Z"},{"id":"q-7451","question":"Implement an HTM-assisted, lock-free queue for inter-thread communication on a 2-socket x86_64 server: try to execute enqueue/dequeue inside an Intel TSX transaction; on abort or full/empty, fall back to a CAS-based path using per-slot sequence counters to avoid ABA. Provide API prototypes and minimal pseudo-code, discuss retry limits, and outline a microbenchmark to compare latency under low vs high contention?","answer":"Use Intel TSX to wrap enqueue/dequeue in a small transaction: validate capacity, write payload, advance tail, and commit with _xend. If TSX aborts or capacity constraints are hit, fall back to a lock-free CAS-based path using per-slot sequence counters to prevent ABA problems.","explanation":"## Why This Is Asked\nTests practical knowledge of transactional memory in real workloads, careful fallback design, and low-latency queues.\n\n## Key Concepts\n- Intel TSX (_xbegin/_xend)\n- CAS-based fallback paths\n- Per-slot sequence counters to avoid ABA\n- Cache-line alignment and false sharing avoidance\n- Microbenchmarking for latency and throughput\n\n## Code Example\n```c\n// Skeleton TSX-based enqueue\ntypedef struct { unsigned long long seq; unsigned long long val; } slot_t;\ntypedef struct { slot_t *slots; unsigned head, tail, cap; } q_t;\nstatic inline int enqueue_htm(q_t *q, unsigned long long val) {\n    unsigned pos = q->tail;\n    if ((pos + 1) % q->cap == q->head) return -1; // full\n    \n    unsigned status = _xbegin();\n    if (status == _XBEGIN_STARTED) {\n        q->slots[pos].val = val;\n        q->slots[pos].seq = pos + 1;\n        q->tail = (pos + 1) % q->cap;\n        _xend();\n        return 0;\n    }\n    \n    // Fallback: CAS-based enqueue with sequence validation\n    return enqueue_cas(q, val);\n}\n```\n\n## Design Considerations\n- Retry limits: 3-5 TSX attempts before permanent fallback\n- Alignment: 64-byte cache line boundaries\n- Contention handling: exponential backoff in fallback path\n- Benchmark: measure 99th percentile latency under 1 vs 16 producer/consumer pairs","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Discord","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T04:33:59.999Z","createdAt":"2026-01-25T23:53:22.251Z"},{"id":"q-752","question":"Design a crash-safe, persistent ring buffer in NVRAM for a 2-socket NUMA system with a PCIe NIC. Capacity N=1<<18, 128-byte payloads, per-slot 64-bit sequence to prevent ABA. Slot: [payload|seq|meta]. Enqueue: publish payload, fence, then update seq. Dequeue: verify seq before consume. Durability via per-slot commit log: flush payload and seq, then epoch commit. On crash, recover by replaying committed epochs and validating seq monotonicity. Provide a minimal microbenchmark to validate throughput and correctness under power loss?","answer":"Design a crash-safe, persistent ring buffer in NVRAM for a 2-socket NUMA system with a PCIe NIC. N=1<<18, 128-byte payloads, per-slot 64-bit sequence to avoid ABA. Slot: payload|seq|meta. Enqueue: pub","explanation":"## Why This Is Asked\nTests understanding of crash-consistent data structures, non-volatile memory ordering, and recovery.\n\n## Key Concepts\n- Persistent memory semantics, fences, epoch-based durability\n- ABA avoidance with per-slot seq, cache-line layout, minimal recovery log\n- Validation under power loss using replay consistency checks\n\n## Code Example\n\n```javascript\n// Placeholder: interview design discussion, not implementable here\n```\n\n## Follow-up Questions\n- How would you adapt for multi-consumer scenarios?\n- What failure modes break the design and how to mitigate?","diagram":"flowchart TD\n  Producer --> Enqueue\n  Enqueue --> Commit\n  Commit --> Recovery\n  Recovery --> Consumer","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","IBM","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:30:58.766Z","createdAt":"2026-01-12T01:30:58.766Z"},{"id":"q-7550","question":"Design a crash-consistent, lock-free persistent ring buffer in non-volatile memory (NVRAM) for inter-process communication. It must be MPMC with bounded capacity, use per-slot sequence counters to avoid ABA, and support crash recovery without data loss. Provide API prototypes, discuss memory ordering and flush strategy (e.g., clflushopt/mfence or PMDK), and outline a minimal recovery procedure. How would you validate under power loss?","answer":"Implement a lock-free, crash-consistent ring buffer in NVRAM. Use MPMC with power-of-two size; per-slot 64-bit sequence counters; atomic head/tail. Enqueue: reserve tail via fetch_add, write data, flu","explanation":"## Why This Is Asked\nThis question tests persistent memory concepts, crash-consistency, and lock-free design under power loss.\n\n## Key Concepts\n- Persistent memory flush semantics and fencing\n- Per-slot version counters to prevent ABA\n- MPMC invariants and crash recovery\n\n## Code Example\n```c\n// API sketch and structures\n```\n\n## Follow-up Questions\n- How would you validate crash recovery under power loss?\n- How does batch flushing impact latency and throughput?\n","diagram":"flowchart TD\n  A[Producer] --> B[Reserve Tail]\n  B --> C[Write Data]\n  C --> D[Publish Tail]\n  E[Consumer] --> F[Read Head]\n  F --> G[Consume Data]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T07:13:06.191Z","createdAt":"2026-01-26T07:13:06.191Z"},{"id":"q-760","question":"On a dual-socket NUMA server, design a cross-NUMA, zero-copy ring buffer for a 40 Gbps path between two processes where producers live on socket A and a consumer on socket B. Use per-slot 64-bit sequence numbers to prevent ABA, 128-byte payload slots, and capacity 1<<18 with 64-byte alignment. Provide slot layout, enqueue/dequeue pseudo-code with memory fences and cache-line padding, wrap-around and backpressure handling, and outline a minimal microbenchmark to validate throughput and data integrity under cross-socket contention?","answer":"Cross-NUMA, two-process ring for 40 Gbps on a dual-socket server. Slot: 128 bytes; capacity 1<<18; 64-byte alignment; per-slot 64-bit sequence for ABA-avoidance. NUMA-aware allocation on local node.\n\n## Slot Layout\n```c\nstruct slot {\n    uint64_t seq;           // 8 bytes - sequence number\n    uint64_t reserved;      // 8 bytes - padding\n    char data[112];         // 112 bytes - payload (128-16)\n} __attribute__((aligned(64)));  // Cache-line aligned\n\nstruct ring_buffer {\n    uint64_t head;          // Consumer position\n    uint64_t tail;          // Producer position  \n    char pad[64 - 16];      // Cache-line padding\n    struct slot slots[1<<18]; // 256KB total\n} __attribute__((aligned(64)));\n```\n\n## Enqueue (Producer on Socket A)\n```c\nbool enqueue(struct ring_buffer* rb, const void* data, size_t len) {\n    uint64_t pos, idx, seq;\n    \n    // Get current tail position\n    pos = __atomic_load_n(&rb->tail, __ATOMIC_RELAXED);\n    \n    // Check if ring is full (head + capacity)\n    uint64_t head = __atomic_load_n(&rb->head, __ATOMIC_ACQUIRE);\n    if (pos - head >= (1<<18)) return false; // Backpressure\n    \n    idx = pos & ((1<<18) - 1);\n    struct slot* slot = &rb->slots[idx];\n    \n    // Load current sequence to check slot availability\n    seq = __atomic_load_n(&slot->seq, __ATOMIC_ACQUIRE);\n    if (seq != pos) return false; // Slot not ready\n    \n    // Copy payload (non-temporal for cross-NUMA)\n    __builtin_memcpy(&slot->data, data, len);\n    \n    // Memory fence before publishing\n    __atomic_thread_fence(__ATOMIC_RELEASE);\n    \n    // Publish new sequence (ABA-safe)\n    __atomic_store_n(&slot->seq, pos + 1, __ATOMIC_RELEASE);\n    \n    // Advance tail position\n    __atomic_store_n(&rb->tail, pos + 1, __ATOMIC_RELAXED);\n    return true;\n}\n```\n\n## Dequeue (Consumer on Socket B)\n```c\nbool dequeue(struct ring_buffer* rb, void* data, size_t* len) {\n    uint64_t pos, idx, seq;\n    \n    // Get current head position\n    pos = __atomic_load_n(&rb->head, __ATOMIC_RELAXED);\n    \n    idx = pos & ((1<<18) - 1);\n    struct slot* slot = &rb->slots[idx];\n    \n    // Check if slot is ready\n    seq = __atomic_load_n(&slot->seq, __ATOMIC_ACQUIRE);\n    if (seq != pos + 1) return false; // No data available\n    \n    // Copy payload\n    *len = 112; // Fixed payload size\n    __builtin_memcpy(data, &slot->data, *len);\n    \n    // Memory fence before reclaiming\n    __atomic_thread_fence(__ATOMIC_RELEASE);\n    \n    // Mark slot as free (wrap-around safe)\n    __atomic_store_n(&slot->seq, pos + 2, __ATOMIC_RELEASE);\n    \n    // Advance head position\n    __atomic_store_n(&rb->head, pos + 1, __ATOMIC_RELAXED);\n    return true;\n}\n```\n\n## NUMA Allocation\n```c\n// Allocate on socket A (producer side)\nvoid* alloc_numa_socketA(size_t size) {\n    void* ptr = numa_alloc_onnode(size, 0); // Socket 0\n    mlock(ptr, size); // Pin in memory\n    return ptr;\n}\n```\n\n## Microbenchmark\n```c\nvoid benchmark_cross_numa() {\n    const size_t iterations = 10000000;\n    const size_t payload_size = 112;\n    \n    // Setup: fork processes, bind to sockets\n    pid_t consumer = fork();\n    if (consumer == 0) {\n        // Consumer process - bind to socket B\n        cpu_set_t mask;\n        CPU_ZERO(&mask);\n        for (int i = 8; i < 16; i++) CPU_SET(i, &mask);\n        sched_setaffinity(0, sizeof(mask), &mask);\n        \n        // Run consumer loop, measure throughput\n        auto start = std::chrono::high_resolution_clock::now();\n        size_t received = 0;\n        while (received < iterations) {\n            if (dequeue(rb, buffer, &len)) {\n                // Verify data integrity\n                if (verify_checksum(buffer, len)) received++;\n            }\n        }\n        auto end = std::chrono::high_resolution_clock::now();\n        \n        double throughput = (received * payload_size * 8) / \n            std::chrono::duration<double>(end - start).count() / 1e9;\n        printf(\"Throughput: %.2f Gbps\\n\", throughput);\n    }\n    \n    // Producer process - bind to socket A\n    cpu_set_t mask;\n    CPU_ZERO(&mask);\n    for (int i = 0; i < 8; i++) CPU_SET(i, &mask);\n    sched_setaffinity(0, sizeof(mask), &mask);\n    \n    // Generate test data with checksums\n    for (size_t i = 0; i < iterations; ) {\n        if (enqueue(rb, test_data + (i % 1000), payload_size)) {\n            i++;\n        } else {\n            _mm_pause(); // Backpressure handling\n        }\n    }\n}\n```","explanation":"## Why This Is Asked\nTests cross-NUMA IPC design with ABA avoidance, memory ordering, and cache-line discipline for senior systems positions.\n\n## Key Concepts\n- Cross-NUMA memory allocation and cache coherence\n- Per-slot sequencing to prevent ABA problems\n- Acquire/release semantics for proper memory ordering\n- Cache-line padding to avoid false sharing\n- Backpressure handling and wrap-around logic\n- NUMA-aware process binding and memory pinning\n\n## Technical Accuracy\n- 40 Gbps requires ~5GB/s throughput, achievable with this design\n- 64-bit sequence numbers prevent ABA even with wrap-around\n- Cache-line alignment (64 bytes) prevents false sharing\n- Memory fences ensure proper ordering across NUMA domains\n- Fixed 128-byte slots with 112-byte payload meet requirements\n- Capacity 1<<18 (262144 slots) provides 32MB buffer space\n\n## Follow-up Questions\n- How would you extend to N producers and M consumers with fairness guarantees?\n- What failure modes matter under NUMA remapping or node failure?\n- How would you handle variable-sized payloads efficiently?\n- What optimizations for specific CPU architectures (Intel vs AMD)?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:11:20.690Z","createdAt":"2026-01-12T03:49:06.047Z"},{"id":"q-7635","question":"Design a fixed-size, thread-local arena allocator for small objects in C. Implement per-thread pools for size classes 8,16,32,64,128,256 bytes with allocate(size) and deallocate(ptr). Allocation rounds up to the class, pops from the thread pool or fetches from a shared global free-list via CAS, and deallocation returns to the appropriate pool or global. Explain how you prevent fragmentation and false sharing, and outline a minimal stress test that demonstrates correctness and fragmentation behavior?","answer":"Design a fixed-size, thread-local arena allocator with per-thread pools for small size classes (8,16,32,64,128,256). Allocate by rounding up to class, pop from thread pool, else fall back to a lock-fr","explanation":"## Why This Is Asked\n\nTests practical memory management skills in low-level code: per-thread arenas, fixed-size pools, and safe global fallbacks under contention.\n\n## Key Concepts\n\n- Thread-local storage and per-thread arenas\n- Size-class allocation and alignment\n- Lock-free global free-list using CAS\n- False sharing avoidance with cache-line padding\n- Fragmentation handling and basic validation\n\n## Code Example\n\n```c\n#include <stdlib.h>\n\n#define NUM_CLASSES 6\nstatic const size_t class_sizes[NUM_CLASSES] = {8,16,32,64,128,256};\n\ntypedef struct Node { struct Node* next; } Node;\n\ntypedef struct Arena {\n  Node* pools[NUM_CLASSES];\n  // per-thread data and padding omitted for brevity\n} Arena;\n\nvoid* allocate(size_t size) {\n  // pseudocode: determine class, pop from thread pool; on fail, CAS from global; return block\n}\nvoid deallocate(void* p) {\n  // determine class, push back to thread pool or global\n}\n```\n\n## Follow-up Questions\n\n- How would you measure fragmentation and hot-path contention in this allocator?\n- What tests would you add to validate correctness under high concurrency and varying allocation sizes?","diagram":"flowchart TD\n A[Thread Local Arena] --> B{Class Lookup}\n B --> C[Thread Pool Free List]\n C --> D[Return Block]\n B --> E[Global Free-List CAS]\n E --> D","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T10:45:31.000Z","createdAt":"2026-01-26T10:45:31.001Z"},{"id":"q-7661","question":"Design a per-thread bump allocator in C for a fixed 256KB arena. Each thread gets its own arena; implement allocate(size) that returns 8-byte aligned pointer and increments an offset without using malloc/free. Provide reset() that clears the arena. Address overflow, alignment, and how you would test thread contention with 8 threads, and outline how to migrate to a shared allocator if needed?","answer":"Per-thread bump allocator: store base and offset; alignment: off = (offset + 7) & ~7; if off + sz <= ARENA_SIZE then return (void*)(base + off); offset = off + sz; else NULL. reset() sets offset=0. No","explanation":"## Why This Is Asked\nEvaluate understanding of low-level allocators, thread-local storage, alignment, and simple memory management without malloc/free.\n\n## Key Concepts\n- Thread-local arenas and bump allocation\n- Alignment and overflow handling\n- Pool reset semantics and fragmentation risk\n- Migration to a shared allocator when needed\n\n## Code Example\n```javascript\n// Pseudo-C-like snippet illustrating the bump allocator\nvoid* allocate(size_t sz){\n  size_t a = (offset + 7) & ~7ULL; // align to 8\n  if (a + sz > ARENA_SIZE) return NULL;\n  void* p = (char*)arena + a;\n  offset = a + sz;\n  return p;\n}\n```\n\n## Follow-up Questions\n- How would you validate correctness under concurrency with 8 threads?\n- What fragmentation risks exist and how could you mitigate them?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","MongoDB","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T11:47:04.753Z","createdAt":"2026-01-26T11:47:04.753Z"},{"id":"q-7687","question":"Design and implement a lock-free shared object pool for a high-throughput producer-consumer pipeline using epoch-based reclamation. Explain structures: per-thread local free lists, a global epoch, and retire lists; describe alloc/free, how to advance the epoch safely, and how to detect memory leaks. Provide pseudo-code snippets and a microbenchmark plan to validate correctness and throughput under 8–16 threads?","answer":"Use epoch-based reclamation (EBR). Keep a global epoch and per-thread local retire lists with retire_epoch. On free, push to the thread’s retire list; periodically advance the global epoch after a qui","explanation":"## Why This Is Asked\n\nTests understanding of safe, non-blocking memory reclamation in high-concurrency structures. It probes trade-offs between hazard pointers and epoch-based schemes, pause-time, and memory traffic.\n\n## Key Concepts\n\n- Epoch progression to bound lifetime\n- Per-thread retire lists and global epoch\n- Barriers/memory fences and cache effects\n- Correctness: no UAF, no double-free under contention\n\n## Code Example\n\n```pseudo\n// Pseudo: alloc/free/retire with per-thread lists and global epoch\n```\n\n## Follow-up Questions\n\n- How would you adapt EB R for real-time constraints?\n- How would you measure reclaimed memory vs allocations?","diagram":"flowchart TD\n  A[Thread] -->|alloc| B[Pool]\n  B --> C{Retire}\n  C --> D[Advance Epoch]\n  D --> E[Reclaim]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T13:24:48.658Z","createdAt":"2026-01-26T13:24:48.658Z"},{"id":"q-7711","question":"Design and implement a tiny fixed-size-block memory allocator over a 64KB preallocated pool. Use 64-byte blocks; store the next-free block index in the first 4 bytes of a free block. Provide init_pool(), my_malloc(), and my_free(ptr) in C or C-like syntax. Explain fragmentation handling, alignment guarantees, and behavior when the pool is exhausted. Include a minimal stress test plan?","answer":"Implement a tiny fixed-size allocator over 64KB with 1024 blocks of 64 bytes. Use the first 4 bytes of a free block to store the next-free index. init_pool() chains all blocks; my_malloc() pops the he","explanation":"## Why This Is Asked\nTests understanding of low‑level memory management, freelists, and fixed-size allocators.\n\n## Key Concepts\n- Fixed-size blocks and simple freelist\n- In-block metadata for next pointer\n- Alignment guarantees and fragmentation considerations\n\n## Code Example\n```javascript\n// JavaScript-simulated fixed-size allocator on an ArrayBuffer\nconst POOL_SIZE = 64 * 1024;\nconst BLOCK_SIZE = 64;\nconst pool = new ArrayBuffer(POOL_SIZE);\nconst nextFree = new Int32Array(pool);\nlet head = 0;\nfunction init_pool(){ const blocks = POOL_SIZE / BLOCK_SIZE; for(let i=0;i<blocks-1;i++){ nextFree[i] = i+1; } nextFree[blocks-1] = -1; head = 0; }\nfunction my_malloc(){ if(head === -1) return null; const idx = head; head = nextFree[idx]; return new DataView(pool, idx*BLOCK_SIZE, BLOCK_SIZE); }\nfunction my_free(ptr){ // ptr is DataView; compute index and push back to head\n  const idx = Math.floor(ptr.byteOffset / BLOCK_SIZE);\n  nextFree[idx] = head; head = idx;\n}\n```\n\n## Follow-up Questions\n- How would you extend to variable sizes? trade-offs?\n- What are the impacts of contention in multi-thread setups?\n","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T14:46:18.460Z","createdAt":"2026-01-26T14:46:18.460Z"},{"id":"q-772","question":"Design a cache-friendly fixed-size object pool for 128-byte blocks used by a multi-threaded producer-consumer path. Implement init, alloc, and free in C for a pool of 1<<20 blocks, each 128 bytes and 64-byte aligned. Use per-thread caches to reduce contention and a global lock-free free-list for overflow. Explain how you avoid false sharing, show the slot layout with a freelist pointer, and outline a microbenchmark to measure throughput and tail latency under contention?","answer":"Per-thread arenas hold a small freelist of 256 blocks, each 128B aligned to 64B. Allocation pops from the thread-local freelist; if empty, refill from a shared global pool via CAS-based lock-free stac","explanation":"## Why This Is Asked\nThis task probes practical memory pool design under contention, cache alignment, and per-thread vs global sharing strategies.\n\n## Key Concepts\n- Cache locality and false sharing\n- Per-thread arenas vs global pool\n- Lock-free stack and CAS\n- Alignment and memory fences\n\n## Code Example\n```c\ntypedef struct Block {\n  struct Block *next;\n  uint8_t data[120];\n} Block;\n#endif\n``` \n\n```c\n// Pseudo: per-thread arena and global pool refill\n```\n\n## Follow-up Questions\n- How do you handle pool exhaustion?\n- How would you adapt for variable block sizes?","diagram":"flowchart TD\nA[Thread] --> B[Alloc from TLS]\nB --> C{Empty?}\nC -- Yes --> D[Refill from Global]\nC -- No --> E[Return Block]\nD --> E","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:52:07.495Z","createdAt":"2026-01-12T04:52:07.495Z"},{"id":"q-778","question":"Write a C function sum_prefetch that sums N 64-bit integers from an aligned array of length n using software prefetching to hide memory latency. Use 4-way unrolling and __builtin_prefetch to bring data 256 elements ahead. Ensure correctness for any length. Propose a microbenchmark plan to compare with a naive loop and discuss cache-line utilization and false sharing concerns?","answer":"Use four accumulators (a,b,c,d). Loop i+=4; prefetch arr[i+256]; accumulate a+=arr[i], b+=arr[i+1], c+=arr[i+2], d+=arr[i+3]. Finalize by adding a,b,c,d. Ensure arr is 64-byte aligned and compile with","explanation":"## Why This Is Asked\nTests practical low-level optimization skills: cache behavior, prefetching, and reliable counting.\n\n## Key Concepts\n- Cache lines and spatial locality\n- Software prefetching with __builtin_prefetch\n- Loop unrolling and multiple accumulators\n- Alignment and portability\n\n## Code Example\n```c\nuint64_t sum_prefetch(const uint64_t *arr, size_t n){\n    uint64_t a=0,b=0,c=0,d=0;\n    size_t i=0;\n    for(; i+3<n; i+=4){\n        __builtin_prefetch(&arr[i+256],0,1);\n        a += arr[i];\n        b += arr[i+1];\n        c += arr[i+2];\n        d += arr[i+3];\n    }\n    for(; i<n; ++i) a += arr[i];\n    return a+b+c+d;\n}\n``` \n\n## Follow-up Questions\n- How would you adapt this for streaming data vs. random access?\n- What changes if array length is not multiple of four?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:30:51.288Z","createdAt":"2026-01-12T05:30:51.288Z"},{"id":"q-7800","question":"Design a durable, lock-free ring-based queue over persistent memory (NVRAM) for a 2-socket x86-64 server. It must support multiple producers and consumers, avoid ABA, use per-slot sequence counters, and guarantee crash-consistency without per-operation fsync. Outline layout, memory order, and a recovery protocol; provide API prototypes and minimal pseudo-code; propose a microbenchmark plan?","answer":"Enqueue writes to a slot and publishes a release-store to the slot’s seq; consumer uses an acquire-load to validate slot and then advances head. For crash-resilience, flush the slot data and its seq w","explanation":"## Why This Is Asked\n\nTests low-level, crash‑safe concurrency with persistent memory, demanding careful ordering, recovery, and durability guarantees beyond traditional in‑memory queues.\n\n## Key Concepts\n\n- Persistent memory semantics and crash-consistency\n- Lock-free multi-producer/multi-consumer design\n- Per-slot sequence counters to avoid ABA\n- Cache-line alignment, memory fences, and PM flushes\n- Recovery protocol and idempotent restarts\n\n## Code Example\n\n```javascript\n// API prototypes\ntypedef struct { uint64_t seq; uint8_t data[64]; } Slot;\ntypedef struct { Slot* slots; size_t head; size_t tail; size_t mask; } PersistentQueue;\nbool enqueue(PersistentQueue* q, const void* item, size_t len);\nbool dequeue(PersistentQueue* q, void* item, size_t* len);\n```\n\n## Follow-up Questions\n\n- How would you extend to multiple independent queues with cross-queue durability guarantees?\n- How would you validate crash-recovery correctness and measure worst-case recovery time?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T18:48:56.265Z","createdAt":"2026-01-26T18:48:56.267Z"},{"id":"q-784","question":"Design a deterministic, time-sliced barrier for a three-stage streaming pipeline on a 2-socket x86-64 system. Each stage runs on a fixed subset of cores; implement a barrier that advances phases only after every core finishes its assigned slice within a bounded time. Explain how to ensure bounded latency under cache-line contention, preserve MESI coherence, and prevent starvation. Provide pseudo-code for enter_barrier for a core and discuss validation?","answer":"Implement a per-core epoch barrier with fixed 64-cycle slices. Each core writes to its per-core slot and then performs an acquire on a shared phase counter. When all slots are written, a master increm","explanation":"## Why This Is Asked\n\nTests knowledge of deterministic synchronization and bounded-latency barriers in NUMA systems.\n\n## Key Concepts\n\n- Deterministic barriers for streaming pipelines\n- Time-sliced execution and fairness\n- Cache-line padding to avoid false sharing\n- MESI coherence implications on cross-socket barriers\n- Validation of worst-case latency under contention\n\n## Code Example\n\n```javascript\n// Pseudo-code for enter_barrier(coreId, total)\nfunction enter_barrier(coreId, total) {\n  // write completion\n  barrierSlots[coreId].done = true;\n  // spin until all done\n  while (!allDone()) {}\n  // reset for next phase\n  if (coreId == 0) phase++;\n  barrierSlots[coreId].done = false;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle dynamic thread affinity changes?\n- How would you measure and bound worst-case latency across sockets?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:37:19.978Z","createdAt":"2026-01-12T06:37:19.978Z"},{"id":"q-7937","question":"Context: A 2-socket x86-64 server with non-volatile memory backing a cross-thread event queue. Task: design a NUMA-aware, crash-consistent, lock-free bounded queue for inter-thread communication that persists enqueued items to PMEM using CLWB and sfence, with per-slot sequence counters to avoid ABA. Provide API prototypes, slot layout, and enqueue/dequeue pseudo-code. Describe recovery after a crash, and outline a microbenchmark to measure crash-resilience and latency under contention?","answer":"Approach: use a fixed-size ring in PMEM; each slot holds 64-byte payload, 8-byte seq, 8-byte flag. Writer writes payload, advances seq to a new value, clwb payload+slot, sfence; commit via a ready fla","explanation":"## Why This Is Asked\n\nTests knowledge of crash-consistent data structures, PMEM semantics, and precise memory ordering. Requires NUMA awareness and non-volatile memory flush granularity.\n\n## Key Concepts\n\n- Non-volatile memory crash-consistency\n- Cache-line flush (clwb) and sfence semantics\n- ABA avoidance with per-slot sequence counters\n- NUMA/topology-aware allocation and access patterns\n\n## Code Example\n\n```c\ntypedef struct {\n  uint64_t seq;\n  uint64_t ready;\n  uint8_t  payload[64];\n} slot_t;\n\n// enqueue (high level, simplified)\nvoid enqueue(queue_t* q, const void* item, size_t len){\n  slot_t* s = get_next_slot(q);\n  memcpy(s->payload, item, len);\n  s->seq += 1;\n  clwb(&s->payload, 64);\n  clwb(&s->seq, sizeof(uint64_t));\n  sfence();\n  s->ready = 1;\n  sfence();\n}\n\n// dequeue (high level, simplified)\nbool dequeue(queue_t* q, void* out, size_t len){\n  slot_t* s = peek_slot(q);\n  if(!s->ready) return false;\n  memcpy(out, s->payload, len);\n  s->ready = 0;\n  clwb(&s->ready, sizeof(uint64_t));\n  sfence();\n  advance_slot(q);\n  return true;\n}\n```\n\n## Follow-up Questions\n\n- How would you implement crash recovery to guarantee at-most-once delivery?\n- How would you benchmark latency and resilience under sudden power loss?","diagram":"flowchart TD\n  A[Enqueue writes payload] --> B[Flush to PMEM with clwb]\n  B --> C[Sfence; publish ready]\n  C --> D[Consumer detects ready and dequeues]\n  D --> E[Consumer clears ready and advances]\n  E --> F[Crash occurs; recovery replays log to restore state]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","DoorDash","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T23:50:29.216Z","createdAt":"2026-01-26T23:50:29.216Z"},{"id":"q-794","question":"Design and implement a cache-friendly tiled matrix multiply for two large double-precision matrices stored in row-major order on a two-socket NUMA system. Propose a tile size of 32x32, provide C code for the tiled kernel with boundary handling, explain how to maximize L1/L2 reuse, NUMA locality (first-touch), avoid false sharing, and an inline 4-wide inner-loop unrolling. Include a microbenchmark plan comparing to a naive triple-nested loop and how you would measure throughput and cache behavior?","answer":"Implement a cache-friendly tiled matmul: 32x32 tiles, 4-wide inner-loop unrolling, and first-touch NUMA affinity to localize A, B, C. Use restrict pointers, align data to 64-byte cache lines, prefetch","explanation":"## Why This Is Asked\n\nTests hands-on understanding of memory hierarchy, NUMA locality, and practical optimization trade-offs in a real kernel.\n\n## Key Concepts\n\n- Cache tiling for L1/L2 reuse\n- NUMA first-touch locality on multi-socket systems\n- Boundary handling for non-multiples of tile size\n- Loop unrolling and prefetching strategies\n- False-sharing avoidance via per-tile accumulation\n\n## Code Example\n\n```javascript\n// Pseudo-C kernel illustrating 32x32 tiling\nvoid matmul_tiled(int N, const double *A, const double *B, double *C){\n  for(int ii=0; ii<N; ii+=32){\n    for(int jj=0; jj<N; jj+=32){\n      for(int kk=0; kk<N; kk+=32){\n        for(int i=ii; i< (ii+32) && i<N; ++i){\n          for(int j=jj; j<(jj+32) && j<N; ++j){\n            double sum = 0.0;\n            for(int k=kk; k<(kk+32) && k<N; ++k){\n              sum += A[i*N+k] * B[k*N+j];\n            }\n            C[i*N+j] += sum;\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you validate correctness for non-multiple tile sizes?\n- How would you adapt to AVX2/AVX-512 and data layout changes to boost throughput?","diagram":"flowchart TD\n  A[Start] --> B[Tiled Loops]\n  B --> C[Compute Tile]\n  C --> D[Edge Tiles]\n  D --> E[Benchmark & Validate]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T07:29:17.327Z","createdAt":"2026-01-12T07:29:17.327Z"},{"id":"q-800","question":"Design a per-core, lock-free memory allocator for a shared-memory, NUMA-aware object store. Each core maintains a 2 MB local heap; allocations first attempt local allocation, with a fast cross-core path using atomic hand-offs; reclaimed memory is managed via hazard pointers and epoch-based reclamation. Provide allocate/free APIs, a sketch of the free-list structure, and a microbenchmark plan that shows fragmentation under steady-state load?","answer":"Per-core free lists with a bump-pointer local allocator inside a 2 MB heap per core. Align to 64 bytes; local allocations are fast paths, cross-core requests use an atomic hand-off ring to a target co","explanation":"## Why This Is Asked\nTests core memory management, concurrency primitives, NUMA awareness, and safe reclamation in high-throughput systems.\n\n## Key Concepts\n- Per-core locality\n- Lock-free reclaim (hazard pointers, epochs)\n- Cross-core handoff patterns\n- Fragmentation and cache-line alignment\n\n## Code Example\n```c\n// Pseudo allocator core logic\ntypedef struct Block Block;\nvoid* alloc(size_t n);\nvoid free(void* p);\n```\n\n## Follow-up Questions\n- How would you measure false sharing?\n- How would you adapt if cores may be hot-swapped or deactivated?","diagram":"flowchart TD\n  A[Request] --> B{Local?}\n  B -- Yes --> C[Alloc from local heap]\n  B -- No --> D[Enqueue cross-core handoff]\n  D --> E[Target core alloc]\n  E --> F[Return]\n","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","MongoDB","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:31:26.187Z","createdAt":"2026-01-12T08:31:26.187Z"},{"id":"q-810","question":"Design a crash-consistent, bounded, multi-producer/multi-consumer queue backed by non-volatile memory. It must survive power loss, use per-slot sequence numbers to avoid ABA, provide push/pop pseudo-code with proper memory fences, and support epoch-based reclamation to avoid hazard pointers. Outline recovery on boot and a microbenchmark plan?","answer":"A ring in NVRAM with N=1<<16 slots; head/tail durable counters; each slot carries a 64-byte payload and a sequence nonce. Enqueue writes payload, then updates sequence and persists with fences. Dequeu","explanation":"## Why This Is Asked\nTackles crash-consistency, non-volatile memory ordering, ABA avoidance, and safe memory reclamation in a high-concurrency data path.\n\n## Key Concepts\n- NVRAM durability and flush ordering (clwb/clflush, sfence)\n- Per-slot sequence numbers to prevent ABA\n- Epoch-based reclamation vs. hazard pointers\n- Recovery: replay tail, prune uncommitted entries\n\n## Code Example\n```c\n// simplified sketch showing write order and fences\nvoid enqueue(Ring *r, void *payload){\n  uint64_t t = fetch_and_add(&r->tail, 1);\n  Slot *s = &r->slots[t & (N-1)];\n  memcpy(s->payload, payload, 64);\n  __sync_synchronize(); // fence before seq\n  s->seq = t<<1 | 1; // mark committed\n  // persist s and tail\n}\n```\n\n## Follow-up Questions\n- How would you implement recovery after power loss?\n- How do you validate correctness under concurrent stress?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T09:35:21.464Z","createdAt":"2026-01-12T09:35:21.464Z"},{"id":"q-816","question":"Design a crash-consistent, persistent ring buffer for a multi-producer/multi-consumer event stream backed by non-volatile memory, with 1<<18 slots of 128-byte payloads; explain ABA avoidance via per-slot sequence numbers, two-phase publish with durable commit, and required flush/barrier order; describe recovery and a microbenchmark plan under simulated power loss?","answer":"Propose a crash-consistent, persistent ring buffer for NVRAM with multi-producer, multi-consumer access. Use 1<<18 slots, 128-byte payloads. ABA avoided via per-slot sequence numbers; two-phase publis","explanation":"## Why This Is Asked\nAsks about crash-consistency in a realistic persistent queue used in trading/telemetry.\n\n## Key Concepts\n- Crash-consistency, NVRAM, per-slot sequence numbers, flush barriers, recovery.\n\n## Code Example\n```javascript\n// pseudo enqueue/dequeue\n```\n\n## Follow-up Questions\n- How would you test durability under power loss and memory reordering? \n- How would you extend to multi-consumer fairness without stalls?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T10:26:21.458Z","createdAt":"2026-01-12T10:26:21.458Z"},{"id":"q-826","question":"Design and implement a tiny spinlock in C11 for a shared memory region. Provide lock() and unlock() using stdatomic.h primitives, ensuring memory_order_acquire on successful lock and memory_order_release on unlock. Include a minimal two-thread test contending for the lock and explain your backoff/yield strategy and fairness limitations?","answer":"```c\n#include <stdatomic.h>\n#include <sched.h>\n\ntypedef struct { atomic_flag f; } spinlock_t;\n#define SPINLOCK_INIT { ATOMIC_FLAG_INIT }\n\nstatic inline void spin_lock(spinlock_t *s){\n  while (atomic_f","explanation":"## Why This Is Asked\nTests practical use of C11 atomics, memory ordering, and contention handling in low-level code. ## Key Concepts\n- C11 atomic primitives (atomic_flag)\n- memory_order_acquire/release semantics\n- busy-wait with backoff/yield to reduce bus traffic\n- fairness and starvation considerations ## Code Example\n```c\n// above code snippet\n```\n## Follow-up Questions\n- How would you extend this to a fair queueing spinlock?\n- What benchmarks would you run to profile contention impact?","diagram":"flowchart TD\n  Start(Start) --> LockRequest[Lock request]\n  LockRequest --> Acquired{Acquired?}\n  Acquired -->|Yes| Crit[Critical Section]\n  Crit --> Unlock[Unlock]\n  Unlock --> End[End]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Google","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:22:40.506Z","createdAt":"2026-01-12T11:22:40.506Z"},{"id":"q-834","question":"Design and implement a fixed-size object pool: a pre-allocated buffer partitioned into 1024 blocks of 64 bytes. Provide thread-safe allocate() and free() using a free-list stored in the blocks and a lightweight spinlock guarding the list. Include initialization and a small test snippet with 2 threads. Discuss fragmentation, cache locality, and how you'd validate concurrency?","answer":"Alloc: acquire spinlock; pop head from free-list; return that block. Free: push block back; release lock. Init: chain all 1024 blocks into the free-list. Test: two threads allocate/free in tight loop;","explanation":"## Why This Is Asked\nTests practical low-level memory management skills: fixed pools, alignment, and simple synchronization. It also probes understanding of fragmentation and cache locality in object pools.\n\n## Key Concepts\n- Fixed-size allocators\n- Free-list metadata in blocks\n- Lightweight spinlocks and minimal contention\n- Thread safety and cache-friendly layouts\n\n## Code Example\n```c\n// simple pool init\nvoid pool_init(pool_t *p){ ... }\nvoid *pool_alloc(pool_t *p){ ... }\nvoid pool_free(pool_t *p, void *obj){ ... }\n```\n\n## Follow-up Questions\n- How would you extend to multiple object sizes? \n- How would you measure allocator performance under contention?","diagram":"flowchart TD\n A[Pool Init] --> B[Blocks Linked List]\n B --> C[Spinlock Protects Head]\n C --> D[Allocate/Free Work]\n D --> E[Blocks Reused]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:46:35.356Z","createdAt":"2026-01-12T12:46:35.356Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":82,"beginner":26,"intermediate":22,"advanced":34,"newThisWeek":39}}