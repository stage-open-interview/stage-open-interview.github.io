{"questions":[{"id":"q-1177","question":"Scenario: a high-throughput edge service must enforce precise timeouts for thousands of connections. Design a lock-free, per-core timer wheel that manages up to 1,000,000 timers with microsecond granularity on a 4-socket server. API: add_timer(id, due_us, cb, ctx), cancel_timer(id), tick(). Requirements: no global locks, handle cancellation safely, cache-friendly layout, and crash-safe recovery. Include pseudo-code for add_timer, cancel_timer, and tick, plus a microbenchmark plan?","answer":"Use a two-tier, per-core timer wheel with microsecond granularity: a local wheel for near-term timers and a shared overflow queue feeding a global wheel. Timers are stored in per-core buckets to minim","explanation":"## Why This Is Asked\nTests ability to design lock-free, NUMA-friendly timeouts with tight latency budgets and predictable memory access patterns. The answer demonstrates practical trade-offs between per-core locality and a minimal global coordination path.\n\n## Key Concepts\n- Lock-free data structures and ABA avoidance\n- Per-core timer buckets and cache-line alignment\n- Two-tier timer wheels for short vs long timeouts\n- Safe cancellation via id-to-timer mapping and sequence counters\n- Crash-safe recovery implications (logs, id replay)\n\n## Code Example\n```cpp\n// skeleton structures (conceptual)\ntypedef struct timer {\n  uint64_t due;        // absolute microsecond timestamp\n  uint64_t id;         // unique identifier\n  void (*cb)(void*);   // callback\n  void *ctx;             // user data\n  struct timer *next;    // linked list within bucket\n} timer_t;\n\ntypedef struct timer_wheel {\n  // per-core buckets, each bucket is a lock-free list\n  bucket_t *buckets; // sized per wheel\n  // mapping from id -> timer for cancellation (lock-free)\n  atomic<uint64_t> active_id; // simplified placeholder\n} timer_wheel;\n\nvoid add_timer(timer_wheel* w, uint64_t due, uint64_t id, void (*cb)(void*), void* ctx);\nvoid cancel_timer(timer_wheel* w, uint64_t id);\nvoid tick(timer_wheel* w);\n```\n\n## Follow-up Questions\n- How would you verify correctness and latency under burst traffic and CPU contention?\n- How do you handle timer overflow, rebalancing across cores, and NUMA effects?","diagram":"flowchart TD\n  A[External Network Paths] --> B[Timer Wheel]\n  B --> C[Per-Core Buckets]\n  C --> D[Callbacks Execution]\n  D --> E[Reschedule or Cancel]\n  E --> B","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Robinhood","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:41:02.303Z","createdAt":"2026-01-13T03:41:02.303Z"},{"id":"q-1261","question":"Implement a cache-friendly transpose using tile-based approach for an N×N matrix with N a power of two. Provide a function to transpose A into B using 32×32 blocks, and a minimal test harness validating correctness. Explain how tiling reduces cache misses and how to pick block size relative to L1/L2 caches. Include a microbenchmark plan comparing with a naive transpose?","answer":"Use 32×32 tiling to keep working set small. For N×N float matrices A,B, loop br/bc in steps of 32 and copy B[c*N + r] = A[r*N + c] with r=br+i, c=bc+j. Add bounds checks for N not multiple of 32, use ","explanation":"## Why This Is Asked\nTests understanding of memory hierarchy and data locality by forcing cache-friendly tiling in a simple kernel.\n\n## Key Concepts\n- Tile size vs cache capacity; 2D blocking; stride-1 vs stride-N access patterns; bounds handling.\n- Prefetching to hide memory latency; ensure no aliasing via separate buffers.\n\n## Code Example\n```c\nvoid transpose_tiled(const float* A, float* B, int N) {\n  const int Bsz = 32;\n  for (int br = 0; br < N; br += Bsz) {\n    for (int bc = 0; bc < N; bc += Bsz) {\n      for (int i = 0; i < Bsz; ++i) {\n        int r = br + i;\n        if (r >= N) break;\n        for (int j = 0; j < Bsz; ++j) {\n          int c = bc + j;\n          if (c >= N) break;\n          B[c * N + r] = A[r * N + c];\n        }\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n- How to handle N not divisible by 32; impact on correctness and performance?\n- How would you adapt to double precision or non-square matrices?\n- Would you vectorize with AVX/NEON and what changes? How to measure speedup?","diagram":"flowchart TD\n  A[Start] --> B[Set N and matrices A,B]\n  B --> C[Choose block size 32]\n  C --> D[Perform tiled transpose]\n  D --> E[Validate results]\n","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:08.457Z","createdAt":"2026-01-13T07:26:08.457Z"},{"id":"q-2105","question":"Design and implement a NUMA-aware per-thread arena allocator in C for a 2-socket server. Features: per-core cache-line-aligned pools, 128-byte padding to prevent false sharing, fast paths for 8/16/32-byte blocks, per-size freelists, and a cross-thread deallocation quarantine. Provide API (init, alloc, free, destroy) plus a minimal test harness and a microbenchmark plan comparing intra- vs inter-NUMA performance against malloc?","answer":"Design and implement a NUMA-aware per-thread arena allocator in C for a 2-socket server. Each thread utilizes a cache-line-aligned pool with 128-byte padding to prevent false sharing, optimized fast paths for 8/16/32-byte blocks, per-size freelists, and a cross-thread deallocation quarantine. Provide a complete API (init, alloc, free, destroy) along with a minimal test harness and a microbenchmark plan comparing intra- versus inter-NUMA performance against malloc.","explanation":"## Why This Is Asked\nAssesses practical memory allocator design under NUMA, focusing on locality and contention.\n\n## Key Concepts\n- NUMA locality and thread affinity\n- Cache-line alignment and false sharing prevention\n- Small-object fast paths and freelists\n- Cross-thread deallocation quarantine\n- Microbenchmarking under intra- versus inter-NUMA loads\n\n## Code Example\n```c\ntypedef struct arena { /* per-thread data */ } arena_t;\nvoid* na_alloc(arena_t*, size_t);\nvoid na_free(arena_t*, void*);\nvoid na_init(arena_t*);\nvoid na_destroy(arena_t*);\n```\n\n## Follow-up Questions\n- How would you validate NUMA locality improvements?\n- What strategies would you use for load balancing across sockets?\n- How would you handle memory fragmentation in long-running applications?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Two Sigma","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:59:44.000Z","createdAt":"2026-01-15T02:18:37.781Z"},{"id":"q-2340","question":"Design and implement a tiny fixed-block allocator in C for a 64KB arena to serve 32-byte objects. Provide API: init_allocator(uint8_t* arena, size_t size), void* alloc32(), void free32(void*). Use an in-block free list (8-byte header) and 24-byte payload per block, with the arena head at offset 0. Explain alignment, fragmentation, and how it compares to malloc. Include a minimal test plan?","answer":"Initialize a 64KB arena with an 8-byte head at offset 0 and 32-byte blocks starting at offset 8. Each block uses an 8-byte header to store the next-free index and 24 bytes for payload (8-byte alignmen","explanation":"## Why This Is Asked\nTests low-level memory layout, inline freelist management, and predictable allocator behavior using minimal metadata.\n\n## Key Concepts\n- Fixed-block allocators and in-block freelists\n- Alignment guarantees for payload\n- Fragmentation and simple correctness tests\n\n## Code Example\n```javascript\n// sketch: structure and ops for the allocator\n```\n\n## Follow-up Questions\n- How would you extend for variable-sized blocks while preserving speed?\n- How would you add basic thread-safety without external allocators?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Meta","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T13:15:28.891Z","createdAt":"2026-01-15T13:15:28.891Z"},{"id":"q-2361","question":"Design a NUMA-aware fixed-size allocator in C++ for objects of 64 bytes, with per-NUMA-node free lists and a lightweight cross-node migration policy; describe structure, allocation/free, and how to avoid inter-node contention and false sharing; provide a small code sketch and a validation plan?","answer":"Per-NUMA allocator with per-node free lists (lock-free or atomics), each block stores next pointer; allocate uses local node list via CAS; if empty, steal from a remote node or fall back to a central ","explanation":"## Why This Is Asked\n\nThis question probes practical low-level memory management in NUMA systems, emphasizing locality, contention, and false sharing—key for latency-sensitive trading/analytics workloads.\n\n## Key Concepts\n\n- NUMA locality and per-node free lists\n- Lock-free/atomic free-list operations and ABA avoidance\n- Cross-node migration policies and migration costs\n- Cache-line alignment and false sharing avoidance\n- Validation: microbenchmarks with mixed-local/global allocations, perf measurements\n\n## Code Example\n\n```cpp\n// simplified per-node free-list CAS skeleton\n#include <atomic>\n\nstruct Node {\n  std::atomic<void*> head{nullptr};\n};\n\nvoid* alloc(Node& node) {\n  void* h = node.head.load(std::memory_order_acquire);\n  if (h) {\n    void* next = *(void**)h;\n    if (node.head.compare_exchange_weak(h, next, std::memory_order_acquire, std::memory_order_relaxed))\n      return h;\n  }\n  // fallback: steal from other node or central pool\n  return nullptr;\n}\n```\n\n## Follow-up Questions\n\n- How would you implement ABA protection and reclaim memory safely across NUMA nodes?\n- How would you measure cross-node traffic impact and optimize for a workload with hot/cold object lifetimes?","diagram":"flowchart TD\n  N0[NUMA Node 0] --> L0[Local Free List]\n  L0 --> A0[Allocate]\n  N0 --> R0[Remote Steal]\n  R0 --> A0\n  A0 --> F0[Free returns to local if possible]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:50:04.615Z","createdAt":"2026-01-15T14:50:04.615Z"},{"id":"q-2448","question":"Design a NUMA-aware, lock-free work-stealing deque with per-NUMA-node local queues and cross-node stealing to sustain high throughput on a 2-socket server. Provide per-slot layout, push/pop/steal pseudo-code with sequence counters, CAS, and memory fences; handle wrap-around; describe hazard pointers/epochs for lifetime management; discuss cache-line padding and validation under cross-NUMA contention?","answer":"Propose a NUMA-aware lock-free work-stealing deque with per-NUMA local queues and cross-node stealing to sustain high throughput on a 2-socket server. Provide per-slot layout, push/pop/steal pseudocod","explanation":"## Why This Is Asked\nEvaluates mastery of low-latency concurrent data structures, memory locality, cross-socket traffic, and safe memory reclamation in production environments.\n\n## Key Concepts\n- NUMA-aware memory locality and per-node queues\n- Lock-free push/pop/steal using CAS\n- ABA avoidance via sequence counters\n- Lifetime management with hazard pointers or epoch-based reclamation\n- Cache-line padding to avoid false sharing\n- Correct wrap-around handling under bounded capacity\n- Validation plan under cross-NUMA contention\n\n## Code Example\n```c\n// Pseudo-code sketch (high-level C-like)\ntypedef struct slot {\n  uint64_t seq;\n  void* data;\n} slot_t;\n\ntypedef struct deque {\n  slot_t* slots;\n  size_t mask; // N-1\n  _Atomic(size_t) head, tail;\n} deque;\n\n// push/pop/steal skeleton (high level; details omitted)\n```\n\n## Follow-up Questions\n- How would you debug a perf anomaly with cross-node steals?\n- How would you scale to more NUMA nodes or adapt to varying task sizes?","diagram":"flowchart TD\n  P[Producer] -->|push| LQ[Local Queue (per-NUMA)]\n  LQ -->|pop| W[Worker]\n  Steal[Stealer] -->|steals| LQ\n  W -->|work| D[Done]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T18:53:13.785Z","createdAt":"2026-01-15T18:53:13.785Z"},{"id":"q-2517","question":"Design a beginner-friendly micro-benchmark in C to quantify false sharing. Create two layouts of per-thread counters: one unpadded (counters reside on the same cache line) and one padded to a full 64-byte cache line. Two threads update their own counter 10,000,000 times each. Measure throughput with clock_gettime(CLOCK_MONOTONIC) and compare results, explaining the impact of padding on cache coherence in multi-core systems?","answer":"I would implement a small harness: two threads increment their own 64-bit counters for 10M iterations. Provide two layouts: Unpadded with a single 64-bit field and Padded with an extra 64-byte pad. Ti","explanation":"## Why This Is Asked\n\nProbes understanding of cache topology, false sharing, and practical microbenchmark design.\n\n## Key Concepts\n\n- False sharing\n- Cache lines\n- Padding strategies\n- Throughput benchmarking\n\n## Code Example\n\n```c\ntypedef struct { long long c; } Unpadded;\ntypedef struct { long long c; char pad[64]; } Padded;\n```\n\n```c\n// Minimal harness would create two threads updating their respective structs\n```\n\n## Follow-up Questions\n\n- How would results change with more threads or different cache-line sizes?\n- How would you make the benchmark portable across CPUs and memory hierarchies?\n","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T21:02:06.327Z","createdAt":"2026-01-15T21:02:06.327Z"},{"id":"q-2688","question":"Design and implement a per-thread arena allocator for 16-byte blocks from a fixed 256KB pool. Provide API: init_arena(void* arena, size_t size), void* alloc16(), void free16(void*). Use a global bitmap to track 16,384 blocks and a thread-local cache of 8 blocks to reduce contention. Explain alignment, fragmentation, and how this approach compares to malloc under multi-core contention. Include a minimal test harness?","answer":"Allocate from a fixed 256KB arena, divided into 16-byte blocks (16,384 blocks total). Maintain a 256-word bitmap (16,384 bits) to mark free/used blocks. Each thread keeps a cache of up to 8 free block","explanation":"## Why This Is Asked\nDemonstrates practical low-level memory management, fixed-size allocators, thread-local caches, and fragmentation trade-offs. A bitmap-based free-tracking scheme avoids pointer-chasing and supports fast scans on aligned blocks.\n\n## Key Concepts\n- Fixed-size block allocator\n- Bitmap-based free tracking\n- Thread-local caches to reduce contention\n- Fragmentation and alignment\n\n## Code Example\n\n```c\ntypedef struct { unsigned long bitmap[256]; void* arena; size_t block_size; } arena_t;\nvoid init_arena(arena_t* a, void* arena, size_t size);\nvoid* alloc16();\nvoid free16(void* p);\n```\n\n## Follow-up Questions\n- How would you handle arena resizing or varying block sizes?\n- How would you ensure NUMA-awareness and fault containment?\n","diagram":"flowchart TD\n  Arena[Arena 256KB]\n  Bitmap[Bitmap 16k blocks]\n  Cache[Thread-Local Cache (8 blocks)]\n  Alloc[alloc16()]\n  Free[free16()]\n  Arena --> Bitmap\n  Bitmap --> Alloc\n  Cache --> Alloc\n  Alloc --> Free","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T07:00:45.222Z","createdAt":"2026-01-16T07:00:45.223Z"},{"id":"q-2699","question":"Design a bounded, lock-free, multi-producer/multi-consumer queue where each slot holds a variable-length payload with a 4-byte length prefix. Use a power-of-two ring, per-slot sequence numbers, and epoch-based reclamation. Provide enqueue/dequeue pseudo-code, describe memory layout, backpressure handling, and a microbenchmark plan under high contention?","answer":"Use a bounded MPMC queue on a power-of-two ring, per-slot length field and a sequence number to avoid ABA. Pad indices to cache lines; publish slot content with release stores and consume with acquire","explanation":"## Why This Is Asked\nTests mastery of lock-free design, memory ordering, and reclamation with real-world payloads.\n\n## Key Concepts\n- Bounded MPMC queue with CAS-based progression\n- Power-of-two ring and per-slot sequence numbers to avoid ABA\n- Epoch-based reclamation for safe memory reclamation\n- Variable-length payloads via 4-byte length prefix\n- Cache-line alignment to prevent false sharing\n- Backpressure handling and fragmentation management\n\n## Code Example\n```cpp\n// Enqueue pseudo\n```\n\n```cpp\n// Dequeue pseudo\n```\n\n## Follow-up Questions\n- How would you adapt this for NUMA-aware memory placements?\n- What stress tests would you run to validate under heavy contention and backpressure?","diagram":"flowchart TD\n  A[Producers] --> B[Enqueue Path]\n  B --> C[Ring Buffer Slot with Seq]\n  C --> D[Consumers Dequeue]\n  D --> E[Epoch Reclamation]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T07:34:44.148Z","createdAt":"2026-01-16T07:34:44.149Z"},{"id":"q-2750","question":"On a dual-socket NUMA server with persistent memory (PMEM), design a crash-consistent, lock-free ring buffer that supports multiple producers and a single consumer. Data is written to PMEM and a compact in-memory log captures operations for recovery after power loss. Include slot layout, enqueue/dequeue steps, memory ordering, and a recovery protocol, plus a microbenchmark plan to verify throughput and durability under power interruption?","answer":"Leverage per-slot sequence numbers and a compact PMEM log. Enqueue: write data to PMEM, flush, publish tail with a release store and memory fence; dequeue validates sequence, advances head with atomic","explanation":"## Why This Is Asked\n\nTests understanding of crash-consistency with non-volatile memory, cross-NUMA coordination, and lock-free design under real-world failure modes.\n\n## Key Concepts\n\n- PMEM crash-consistency and recovery\n- Lock-free MPSC ring design with sequence numbers\n- Memory ordering: fences (mfence, sfence) and cache-line flushes (clwb/clflushopt)\n- In-memory log for durable recovery; replay semantics\n- NUMA-aware layout and false-sharing avoidance\n\n## Code Example\n\n```c\ntypedef struct {\n  uint64_t seq;\n  uint8_t data[DATA_SIZE];\n} Slot;\n\ntypedef struct {\n  Slot* slots;\n  uint64_t head;\n  uint64_t tail;\n  uint8_t pad[64];\n} RingPMEM;\n```\n\n## Follow-up Questions\n\n- How would you extend to multiple consumers?\n- How do you ensure correctness if power loss occurs during a log flush or data write?","diagram":"flowchart TD\n  P[Producers] --> E[Enqueue Path]\n  E --> S[Slot PMEM Write]\n  S --> F[Flush to PMEM]\n  F --> C[Publish Tail]\n  C --> D[Consumer Reads Slot]\n  D --> L[Log Flush for Recovery]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","NVIDIA","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T10:38:05.431Z","createdAt":"2026-01-16T10:38:05.431Z"},{"id":"q-2916","question":"Design and implement a 256-entry software TLB for 32-bit virtual addresses mapping to 4KB pages. Provide API: tlb_init(), tlb_lookup(uint32_t va, uint32_t* pa), tlb_insert(uint32_t va, uint32_t pa). Use linear probing with an LRU replacement policy. Explain interaction with a two-level page table and a microbenchmark plan to measure hit rate under changing working-set sizes?","answer":"Implement a 256-entry TLB with fields: tag (VA page number), pa, valid, and an LRU counter. tlb_init zeros the table. tlb_lookup hashes va to a page index, linearly probes for a valid tag match, retur","explanation":"## Why This Is Asked\nTests practical understanding of cache-like structures, address translation, and replacement policies at low level. \n\n## Key Concepts\n- TLB structure and page number tagging\n- Linear probing and wraparound\n- LRU replacement and correctness in a small cache\n- Interaction with two-level page tables during misses\n\n## Code Example\n```c\ntypedef struct { uint32_t tag; uint32_t pa; uint8_t valid; uint8_t lru; } tlb_entry;\nstatic tlb_entry tlb[256];\nvoid tlb_init() { for (int i=0;i<256;i++) tlb[i].valid=0; }\nbool tlb_lookup(uint32_t va, uint32_t* pa){ uint32_t page = va >> 12; uint32_t idx = page & 0xFF; for(int i=0;i<256;i++){ tlb_entry* e = &tlb[(idx+i)&0xFF]; if(!e->valid) continue; if(e->tag==page){ *pa = e->pa; e->lru = 0; return true; } e->lru++; } return false; }\nvoid tlb_insert(uint32_t va, uint32_t pa){ uint32_t page = va >> 12; uint32_t idx = page & 0xFF; int miss_pos = -1; uint8_t oldest = 0; for(int i=0;i<256;i++){ tlb_entry* e = &tlb[(idx+i)&0xFF]; if(!e->valid){ miss_pos = (idx+i)&0xFF; break; } if(e->lru > oldest){ oldest = e->lru; miss_pos = (idx+i)&0xFF; } }\n tlb[miss_pos].tag = page; tlb[miss_pos].pa = pa; tlb[miss_pos].valid = 1; tlb[miss_pos].lru = 0; }\n```\n\n## Follow-up Questions\n- How would you adapt this to multi-core without races?\n- What trade-offs arise if you instead make it a set-associative cache?","diagram":"flowchart TD\n  A[TLB Lookup] --> B{Hit?}\n  B -- Yes --> C[Return PA]\n  B -- No --> D[Page Walk]\n  D --> E[TLB Insert]\n  E --> C","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T17:34:20.716Z","createdAt":"2026-01-16T17:34:20.716Z"},{"id":"q-3079","question":"Design a cross-process, lock-free bounded queue in shared memory for two processes on a NUMA system, with 1<<18 slots of 128 bytes. Use per-slot 64-bit sequence numbers and head/tail indices. Producers spin until slot.seq==tail, write payload, and publish slot.seq=tail+1 with a release; consumers read with acquire, validate, and advance head. Reclaim via epoch-based scheme across both processes. Microbenchmark: vary producers/consumers, report p95/p99 latency and sustained throughput; check data integrity under contention?","answer":"Implement a cross-process lock-free bounded queue with N=1<<18 slots of 128 bytes each, utilizing per-slot 64-bit sequence numbers for synchronization. Maintain padded head and tail indices to prevent false sharing on NUMA systems. Producers spin until `slot.seq == tail`, write the payload, then publish with `slot.seq = tail + 1` using a release fence. Consumers read with an acquire fence, validate the sequence number, and advance the head index. Reclaim slots using an epoch-based reclamation scheme coordinated across both processes.","explanation":"## Why This Is Asked\nThis question evaluates expertise in cross-process IPC, memory ordering semantics, and memory reclamation in NUMA environments under realistic contention scenarios.\n\n## Key Concepts\n- Cross-process lock-free data structures\n- Memory ordering: acquire/release fences and sequence counters\n- False sharing prevention through cache-line padding\n- Epoch-based reclamation across process boundaries\n- NUMA-aware performance optimization\n- Microbenchmark design for IPC throughput and latency analysis\n\n## Code Example\n```c\ntypedef struct {\n    uint64_t seq;\n    uint8_t payload[128];\n```\n\n## Implementation Details\nThe queue uses a circular buffer with sequence numbers to track slot ownership. Each slot has a 64-bit sequence number that ensures proper synchronization between producers and consumers without locks. The padded head/tail indices prevent false sharing on cache lines.\n\n## Performance Considerations\nNUMA-aware placement of shared memory regions minimizes cross-node memory access. The spin-wait approach is suitable for high-throughput scenarios where the queue is rarely empty or full.\n\n## Benchmarking Strategy\nDesign microbenchmarks that vary producer/consumer ratios (1:1, 1:N, N:1) and measure p95/p99 latencies under different contention levels. Validate data integrity by embedding checksums in payloads and verifying them after each operation.","diagram":"flowchart TD\n  P[Producer enqueues] --> S[Slot selected by tail]\n  S --> W[Write payload]\n  W --> PUBLISH[Publish slot.seq=tail+1 (release)]\n  C[Consumer dequeues] --> R[Read slot and verify seq]\n  R --> ADV[Advance head (acquire)]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Lyft","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:12:15.085Z","createdAt":"2026-01-16T23:47:21.619Z"},{"id":"q-3280","question":"Design and implement a lock-free concurrent map using a skip-list with probabilistic levels, supporting O(log n) inserts, finds, and deletes under high contention. Use hazard pointers for memory reclamation and marked pointers for logical deletion. Provide node layout with per-level forward pointers, random level generator, and pseudocode for insert, search, and delete that avoids ABA. Include a minimal microbenchmark plan to validate throughput and correctness under heavy parallelism?","answer":"Key ideas: a skip-list map with lock-free inserts/finds/deletes. Use hazard pointers for reclamation and marked next pointers for logical deletion. Nodes carry per-level forward pointers, and new node","explanation":"## Why This Is Asked\nTests ability to implement a lock-free structure with correct memory reclamation and ABA avoidance in a real-world pattern.\n\n## Key Concepts\n- Lock-free data structures\n- Hazard pointers memory reclamation\n- ABA avoidance\n- Skip-list levels and randomization\n- Memory ordering and fences\n\n## Code Example\n```c\ntypedef struct Node {\n  int key;\n  void* value;\n  struct Node** next; // per-level forward pointers\n  int topLevel;\n  _Atomic(int) marked; // 0/1\n} Node;\n```\n\n## Follow-up Questions\n- How to resize or balance levels without locks?\n- How to validate memory reuse and detect ABA-related failures?","diagram":"flowchart TD\n  A[Thread] --> B[Operation]\n  B --> C[CAS/Link]\n  C --> D[Hazard Pointers]\n  D --> E[Unlink/Retire]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Slack","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T09:43:37.298Z","createdAt":"2026-01-17T09:43:37.298Z"},{"id":"q-3455","question":"Implement a simple spinlock in C using C11 atomics. Provide lock and unlock functions for a shared 32-bit counter. Use an exponential backoff (pause) when contention is detected. Then write a small test with four threads each incrementing the counter one million times. Explain how backoff avoids livelock and how you would measure contention?","answer":"Use a 32-bit atomic flag. In lock(), spin with atomic_flag_test_and_set_explicit(&lock, memory_order_acquire) until it succeeds; on miss, perform exponential backoff with _mm_pause() (cap at 1024). un","explanation":"## Why This Is Asked\nTests knowledge of low-level synchronization, memory ordering, and backoff strategies under contention. Also checks ability to translate theory into working code and simple performance measurement.\n\n## Key Concepts\n- C11 atomics and memory_order_acquire/release\n- atomic_flag spinlocks and their correctness\n- exponential backoff to prevent livelock\n- basic contention metrics (wall time, backoffs)\n\n## Code Example\n```javascript\n#include <stdatomic.h>\n#include <emmintrin.h>\n\nstatic atomic_uint counter = 0;\nstatic atomic_flag lock = ATOMIC_FLAG_INIT;\n\nvoid lock_spin() {\n  unsigned int backoff = 1;\n  while (atomic_flag_test_and_set_explicit(&lock, memory_order_acquire)) {\n    _mm_pause();\n    if (backoff < 1024) backoff <<= 1;\n    for (volatile unsigned int i = 0; i < backoff; ++i) _mm_pause();\n  }\n}\n\nvoid unlock_spin() {\n  atomic_flag_clear_explicit(&lock, memory_order_release);\n}\n```","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T16:50:37.236Z","createdAt":"2026-01-17T16:50:37.236Z"},{"id":"q-3478","question":"Design a small, beginner-friendly spinlock in C to protect a shared 64-bit counter on a multi-core system. Implement init(), lock(), unlock() using C11 atomics (memory_order_acquire for lock, memory_order_release for unlock). Provide a minimal test plan with 8 threads incrementing the counter and a short fairness note. How would you verify correctness under contention?","answer":"Use an atomic_flag-based spinlock. init: atomic_flag_clear(lock); lock: while (atomic_flag_test_and_set_explicit(lock, memory_order_acquire)) { _mm_pause(); } unlock: atomic_flag_clear_explicit(lock, ","explanation":"## Why This Is Asked\n\nTests fundamental low-level synchronization and memory ordering concepts in a realistic micro-optimization context.\n\n## Key Concepts\n\n- Atomic flags and test_and_set semantics\n- memory_order_acquire vs memory_order_release\n- Busy-wait with cpu pause for reduced contention\n- Backoff strategies to avoid cache-line thrashing\n\n## Code Example\n\n```javascript\n#include <stdatomic.h>\n#include <immintrin.h>\n\ntypedef atomic_flag spinlock_t;\nvoid spinlock_init(spinlock_t* s) { atomic_flag_clear(s); }\nvoid spinlock_lock(spinlock_t* s) { while (atomic_flag_test_and_set_explicit(s, memory_order_acquire)) { _mm_pause(); } }\nvoid spinlock_unlock(spinlock_t* s) { atomic_flag_clear_explicit(s, memory_order_release); }\n```\n\n## Follow-up Questions\n\n- How would you modify to minimize starvation?\n- How would you test for fairness across threads under high contention?\n","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T17:44:16.820Z","createdAt":"2026-01-17T17:44:16.820Z"},{"id":"q-3485","question":"Design a crash‑consistent, lock‑free, bounded ring buffer in shared memory that acts as a persistent queue across restarts. It must be backed by a memory‑mapped file, use per‑slot CRCs, and a two‑phase commit so writers can resume after power loss. Describe enqueue/dequeue algorithms, restoration after crash, and how you handle memory ordering, reclamation of retired descriptors, and backpressure. Include a microbenchmark plan?","answer":"Propose a crash‑consistent, lock‑free bounded ring in shared memory backed by a mmapped file. Use per‑slot CRCs and a two‑phase commit so writers can resume after power loss; dequeue under reader prog","explanation":"## Why This Is Asked\nTests crash‑recovery, memory ordering, and lock‑free design for production‑like persistent queues.\n\n## Key Concepts\n- Crash consistency, memory‑mapped persistence\n- Lock‑free enqueue/dequeue with two‑phase commit\n- Reclamation (hazard pointers/epochs) and memory fences\n- Backpressure, recovery after crash, NUMA considerations\n\n## Code Example\n```javascript\n// Pseudo enqueue/dequeue framework for crash‑consistent queue\nfunction enqueue(queue, item) {\n  // reserve slot, write, commit tail, flush\n}\nfunction dequeue(queue) {\n  // read, validate, advance head, reclaim if needed\n}\n```\n\n## Follow-up Questions\n- How would you simulate power loss during commit and validate recovery?\n- How would you extend to multiple readers and ensure fairness?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Square","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T18:42:37.299Z","createdAt":"2026-01-17T18:42:37.299Z"},{"id":"q-3813","question":"Design a crash‑consistent, lock‑free allocator over persistent memory (PMEM). Provide API: init_pmem_pool(void* base, size_t size), void* pmem_alloc(size_t n), void pmem_free(void* p). Use a log-structured approach with per‑block headers (offset, version, CRC) and a bitmap to track free blocks. Explain recovery after power loss, how to prevent double frees, and minimize writes. Include pseudo-code for alloc and recovery?","answer":"Propose a log-structured PMEM allocator: append allocations to a durable log, then atomically update a per-block header (version, CRC). Maintain a free-block bitmap and a per-thread cache. Recovery re","explanation":"## Why This Is Asked\n\nAssess ability to design crash‑safe, low‑level memory allocators for persistent memory, including ordering, recovery, and reclamation. Tests understanding of write amplification, ABA risks, and practical recovery semantics.\n\n## Key Concepts\n\n- Persistent memory semantics and durability guarantees\n- Log-structured allocation and per-block headers\n- Versioning, CRC, and bitmap for consistency\n- Recovery: replay log up to last committed epoch; handle partial writes\n- Cache-line padding and memory fences to avoid false sharing and ABA\n\n## Code Example\n\n```c\ntypedef struct {\n  uint64_t offset;\n  uint64_t size;\n  uint64_t version;\n  uint64_t crc;\n} BlockHeader;\n\n// Pseudo-code skeletons\nvoid* pmem_alloc(size_t n) {\n  // locate free block via bitmap; append descriptor to log; flush; update header version\n  return NULL;\n}\n\nvoid pmem_free(void* p) {\n  // mark block free in bitmap; record in log; ensure idempotence\n}\n\nvoid recover_pmem() {\n  // replay log to last committed epoch; validate CRCs; reclaim partial writes\n}\n```\n\n## Follow-up Questions\n\n- How would you test crash power-loss scenarios and verify no leaks?\n- What metrics would you track (throughput, write amplification, recovery time)?","diagram":"flowchart TD\n  A[Pmem pool] --> B[Alloc path]\n  B --> C[Append to log]\n  C --> D[Persist header]\n  D --> E[Free path]\n  E --> F[Recovery]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T10:37:53.498Z","createdAt":"2026-01-18T10:37:53.499Z"},{"id":"q-3917","question":"Implement a portable spinlock in C using stdatomic.h. Provide acquire() and release() with an exponential backoff strategy for contention. Explain memory ordering choices (memory_order_acquire on acquire and memory_order_release on release), and how you would test correctness with two threads incrementing a shared counter to 1e7. Include a minimal C snippet and a test harness plan?","answer":"Use stdatomic.h atomic_flag for a spinlock. Acquire: while (atomic_flag_test_and_set_explicit(&lock->flag, memory_order_acquire)) { _mm_pause(); for (int b=1; b<1024; b<<=1) _mm_pause(); }. Release: a","explanation":"## Why This Is Asked\n\nAssess understanding of low-level synchronization, atomic operations, and memory ordering in a practical, portable way.\n\n## Key Concepts\n\n- Spinlock using atomic_flag\n- Memory ordering: acquire on lock, release on unlock\n- Exponential backoff with PAUSE to reduce contention\n- Correctness test with concurrent increments\n\n## Code Example\n\n```c\n#include <stdatomic.h>\n#include <immintrin.h>\n\ntypedef struct { atomic_flag flag; } spinlock;\n\nstatic inline void spinlock_init(spinlock* s) {\n  atomic_flag_clear(&s->flag);\n}\n\nstatic inline void spin_lock(spinlock* s) {\n  while (atomic_flag_test_and_set_explicit(&s->flag, memory_order_acquire)) {\n    _mm_pause();\n    // small exponential backoff\n    for (int b = 1; b < 1024; b <<= 1) {\n      _mm_pause();\n    }\n  }\n}\n\nstatic inline void spin_unlock(spinlock* s) {\n  atomic_flag_clear_explicit(&s->flag, memory_order_release);\n}\n```\n\n## Follow-up Questions\n\n- How would you adapt this for NUMA systems to reduce cross-socket traffic?\n- What are the trade-offs of using a ticket-lock vs this spinlock in high-contention workloads?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T15:34:07.387Z","createdAt":"2026-01-18T15:34:07.387Z"},{"id":"q-3978","question":"Write a cooperative user-space scheduler that preempts green threads using a timer signal. In a single process, implement N coroutines with contexts (ucontext or setjmp/longjmp), maintain a ready queue, and use a per-thread timer (ITIMER_REAL) to trigger SIGALRM, performing yield by swapping to the next context. Include stack guard pages, an async-signal-safe enqueue/dequeue, and discuss race conditions, reentrancy, and performance implications?","answer":"Implementation approach: use ucontext to create N contexts with stacks aligned to 16/64 bytes; install a single signal handler for SIGALRM that is async-signal-safe; on timer expiry, save current cont","explanation":"## Why This Is Asked\nTests practical low-level skills: user-space scheduling, context switching, and signal safety. It probes how candidates manage cross-core timing, layout stacks, and handle preemption without kernel help.\n\n## Key Concepts\n- Async-signal-safety and reentrancy in a signal handler\n- Context switching APIs (ucontext vs setjmp/longjmp)\n- Stack guards and guard pages to detect overflows\n- Preemption cost and jitter; worst-case latency\n\n## Code Example\n```javascript\n// Minimal skeleton (C-like) for a preemptive user-space scheduler\n#include <signal.h>\n#include <ucontext.h>\n#include <sys/mman.h>\n#include <unistd.h>\n\n#define N 4\n\nucontext_t ctxs[N], main_ctx;\nint current = 0;\nvoid scheduler_tick(int sig){ /* async-signal-safe yield to next */ }\n```\n\n## Follow-up Questions\n- How would you extend to handle more coroutines than hardware threads while keeping latency predictable?\n- How would you measure and minimize preemption jitter across cores in a dense workload?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T18:39:24.891Z","createdAt":"2026-01-18T18:39:24.891Z"},{"id":"q-4008","question":"Design a per-core, bounded publish-subscribe queue for a NUMA multi-socket server. Producers write to local rings and publish to a shared log with per-slot sequence numbers. Provide data structures, enqueue/dequeue pseudo-code, handle wrap-around, memory ordering on x86-64, and validation plan for throughput and message ordering under cross-core contention?","answer":"Propose a per-core, bounded publish–subscribe queue: each producer writes to a local ring buffer and publishes to a shared log with per-slot sequence numbers. Use per-slot 64-byte, cache-aligned slots","explanation":"## Why This Is Asked\nTests knowledge of low-latency IPC, NUMA locality, and cache-coherence with careful memory ordering. It also probes design trade-offs for per-core buffering vs a centralized log.\n\n## Key Concepts\n- Per-core buffering and cross-core publication\n- Sequence-numbered slots and wrap-around handling\n- Memory ordering on x86-64 (relaxed/upholds with fences)\n- False sharing avoidance and cacheline padding\n- Validation: throughput, ordering, and backpressure under contention\n\n## Code Example\n```c\n// Pseudo-enqueue\nbool enqueue(int core_id, void* msg) {\n  uint64_t pos = atomic_fetch_add(&tail[core_id], 1);\n  slot_t* s = &ring[core_id][pos & (N-1)];\n  if (s->seq != pos) return false; // consumer hasn't advanced\n  s->payload = msg;\n  s->seq = pos + 1;\n  return true;\n}\n```\n\n## Follow-up Questions\n- How would you extend this to support dynamic growth of the log while preserving wait-freedom?\n- How would you test correctness with synthetic workloads that stress cross-core contention?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Instacart","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T19:28:07.261Z","createdAt":"2026-01-18T19:28:07.262Z"},{"id":"q-4021","question":"Implement a NUMA-aware fixed-size block allocator for 64-byte blocks in a multi-threaded process. Each thread uses a per-NUMA-node cache and refills from a central pool on miss; design lock-free freelists with atomic operations, ensure alignment and quick-path fast-path, and discuss fragmentation and cross-socket traffic. Include a microbenchmark plan comparing against a naive malloc?","answer":"Describe a NUMA-aware allocator: per-thread caches on local NUMA nodes, a central pool for cross-node refills, and lock-free freelists using atomic push/pop. Ensure 64-byte alignment, cache-friendly l","explanation":"## Why This Is Asked\n\nThe task probes practical memory allocator design under NUMA, highlighting locality, contention, and fragmentation trade-offs with lock-free data structures.\n\n## Key Concepts\n\n- NUMA locality\n- Per-thread caches\n- Lock-free freelists and memory reclamation\n- Fragmentation and refill strategies\n- Benchmark design\n\n## Code Example\n\n```c\n// High-level sketch of data structures\ntypedef struct Block { struct Block *next; } Block;\ntypedef struct { _Atomic(Block*) central; Block *local; int node; } Allocator;\n\nvoid* malloc64(Allocator *A){\n  Block *b = A->local; if(b){ A->local = b->next; return (void*)b; }\n  Block *c = atomic_load_explicit(&A->central, memory_order_acquire);\n  if(c){ atomic_store_explicit(&A->central, c->next, memory_order_release); return (void*)c; }\n  // refill from OS or malloc from system\n  return system_alloc(A);\n}\nvoid free64(Allocator *A, Block *b){\n  b->next = A->local; A->local = b;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle thread migration across NUMA nodes? \n- What metrics identify improvement (latency, bandwidth, cache misses)?","diagram":"flowchart TD\n  A[Thread requests alloc] --> B{Local cache?}\n  B -- yes --> C[Return block]\n  B -- no --> D[Refill from central pool]\n  D --> E[Return block to thread]\n  E --> F[Done]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Meta","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T20:33:25.504Z","createdAt":"2026-01-18T20:33:25.504Z"},{"id":"q-4110","question":"Design a NUMA-aware, lock-free free-list based allocator in C for a 2-socket system. Each thread should allocate from its local allocator first; if local memory runs out, steal from the other node with minimal synchronization. Provide data structures, allocate/free pseudo-code using atomic ops, and discuss fragmentation, cross-node traffic, and microbenchmark plan?","answer":"Per-thread local caches fed by per-NUMA node free lists. Allocation first uses the thread cache; if empty, pop from the local free-list; on underflow, CAS-steal a block from the remote node and insert into the local cache.","explanation":"## Why This Is Asked\n\nTests NUMA awareness, lock-free free-list mechanics, and cache-padding trade-offs under cross-socket contention.\n\n## Key Concepts\n\n- NUMA-aware allocation paths and locality\n- Lock-free free-lists with atomic CAS\n- Cache-line padding to prevent false sharing and 64-byte alignment\n\n## Code Example\n\n```c\n// Skeleton: per-node free-list with thread-local cache; CAS-based steal from remote\ntypedef struct NodeBlock { struct NodeBlock* next; } NodeBlock;\ntypedef struct FreeList {\n  _Atomic(NodeBlock*) head;\n  // padding to avoid false sharing\n  uint8_t pad[64];\n} FreeList;\n```","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Microsoft","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T05:30:07.132Z","createdAt":"2026-01-19T02:43:10.774Z"},{"id":"q-4241","question":"Design a fixed-size-object allocator for a 4-core NUMA machine that minimizes inter-core traffic. Implement per-core caches, a small global cache, non-blocking refill of core caches, and safe bulk release during teardown. Explain cache-line alignment and false sharing avoidance, how you reclaim freed objects, and how you'd benchmark latency under bursty allocations?","answer":"Per-core caches hold 64 objects each, cache-line aligned to 64 bytes; a global lock-free freelist handles cross-core refills in batches (e.g., 64). Fast path alloc/free uses local cache with relaxed a","explanation":"## Why This Is Asked\n\nTests practical design choices for low-latency allocators in multi-core, NUMA contexts, including cache locality, lock-free synchronization, and teardown safety.\n\n## Key Concepts\n\n- Per-core caches for locality\n- Global lock-free freelist for cross-core refills\n- Batch operations to amortize synchronization cost\n- Cache-line padding to avoid false sharing\n\n## Code Example\n\n```c\n// Pseudo: per-core cache node and refill logic\ntypedef struct Object { struct Object *next; } Object;\ntypedef struct { _Atomic(Object*) head; } FreeList;\n\n#define BATCH 64\n\nObject* allocate(FreeList *local, FreeList *global){\n    Object* head = atomic_load_explicit(&local->head, memory_order_acquire);\n    if(head){\n        local->head = atomic_fetch_sub_explicit(&local->head, NULL, memory_order_acquire);\n        return head;\n    }\n    // refill from global (simplified)\n    for(int i=0;i<BATCH;i++){\n        Object* o = pop_global(global);\n        if(!o) break;\n        push_local(local, o);\n    }\n    return allocate(local, global);\n}\n\nvoid deallocate(FreeList *local, Object *o){\n    push_local(local, o);\n}\n```\n\n## Follow-up Questions\n\n- How would you adapt this for varying object sizes and allocator fragmentation?\n- What microbenchmarks would validate latency under high contention and NUMA effects?","diagram":"flowchart TD\n  A[Allocate] --> B{LocalCache?}\n  B -- Yes --> C[Return Object]\n  B -- No --> D[RefillFromGlobal]\n  D --> E[Return Object]\n  E --> F[Deallocate]\n  F --> G[LocalCacheAggressiveRelease]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Cloudflare","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T09:53:24.186Z","createdAt":"2026-01-19T09:53:24.186Z"},{"id":"q-4632","question":"Design a bounded MPMC DMA ring for a 2-socket NUMA server. Use N=1<<16 128-byte slots (16B header, 112B payload) aligned to 128B. Per-slot fields: seq and len. Producers publish payload with store-release, consumers read with acquire and recycle; wrap around via seq xor 1. Use epoch-based reclamation for descriptors. Propose a 100G microbenchmark and how you verify stall, latency, and backpressure?","answer":"Provide a 1<<16, 128-byte per-slot bounded MPMC ring. Slot header: 16B seq/len plus 112B payload. Producers publish with store-release, then advance via CAS; consumers use load-acquire, process, and r","explanation":"## Why This Is Asked\nTests lock-free MPMC design, memory ordering, and NUMA-aware DMA paths.\n\n## Key Concepts\n- Lock-free synchronization with per-slot sequencing\n- Cache-line alignment to avoid false sharing\n- ABA avoidance and safe wrap-around\n- Epoch-based reclamation for descriptors\n- Realistic NIC/user-space memory interactions\n\n## Code Example\n```javascript\n// Pseudo-C sketch for publish/consume paths\n```\n\n## Follow-up Questions\n- How would you adapt for HW-assisted reclamation? \n- How would you validate correctness under burst traffic?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Scale Ai","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:48:57.975Z","createdAt":"2026-01-20T05:48:57.975Z"},{"id":"q-4909","question":"Design a lock-free, concurrent graph data structure with adjacency lists that supports add_node(id), add_edge(u,v), and remove_node(id) without locking. Target a 16-core NUMA server handling high update rates; ensure memory safety using hazard pointers or epoch-based reclamation for removed nodes. Describe node/edge layout, edge insertion as a lock-free CAS operation, and a minimal stress test plan?","answer":"Lock-free graph: each node has an atomic head pointer to a singly linked list of edges; Edge {int to; atomic next}. add_edge uses CAS to prepend; add_node allocates a node and links it atomically. rem","explanation":"## Why This Is Asked\nThe problem probes mastery of lock-free data structures, safe memory reclamation, and performance under high contention in a graph primitive.\n\n## Key Concepts\n- Lock-free updates (CAS-based edge insertion)\n- Hazard pointers vs epoch-based reclamation\n- Cache-line alignment and false sharing mitigation\n- Safe removal of nodes with concurrent readers\n\n## Code Example\n```javascript\n// Skeleton (conceptual; real impl uses C/C++)\nclass Node{ constructor(id){ this.id=id; this.head=null; this.marked=false; } }\nclass Edge{ constructor(to,next){ this.to=to; this.next=next; } }\nfunction addEdge(u,v){ // lock-free prepend with CAS on u.head }\nfunction addNode(id){ // allocate and link atomically }\nfunction removeNode(id){ // mark and reclaim via hazard pointers/epochs }\n```\n\n## Follow-up Questions\n- How would you benchmark contention under parallel add_edge/remove_node workloads?\n- How would you extend to support directed vs undirected graphs without sacrificing lock-freedom?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T18:59:20.173Z","createdAt":"2026-01-20T18:59:20.173Z"},{"id":"q-5029","question":"Design and implement a beginner-friendly line-based decoder for a fixed 4KB ring buffer shared by a producer (socket reader) and a consumer (processor). Lines are ASCII terminated by '\\n'. Provide C-like pseudo-code for a ring buffer struct and a decode_lines function that returns all complete lines in a single call, preserves partial lines, handles wrap-around, and signals backpressure when full. Include a tiny test harness?","answer":"Approach: Implement a 4KB ring buffer with head and tail indices to track read and write positions. Write incoming data at the tail position, advance the tail pointer, and use newline delimiters to segment complete lines. The decode_lines function iterates while head != tail, reads until encountering '\n' or buffer wrap-around, copies complete lines to the output buffer, preserves partial lines for subsequent calls, and returns a backpressure indicator when the buffer reaches capacity.","explanation":"## Why This Is Asked\nThis practical low-level buffer management task mirrors real-world service architectures and tests understanding of memory layout, line framing, and concurrent data handling.\n\n## Key Concepts\n- Ring buffer indexing and wrap-around logic\n- Line framing with partial line preservation\n- Backpressure signaling and thread-safe visibility\n- Memory-efficient buffer utilization\n\n## Code Example\n```c\ntypedef struct {\n  unsigned char data[4096];\n  size_t head; // read position\n  size_t tail; // write position\n  size_t cap;  // 4096\n} RingBuf;\n\nint decode_lines(RingBuf* rb, char* out","diagram":"flowchart TD\n  P[Producer] --> RB[RingBuffer]\n  RB --> C[Consumer]\n  P -- writes data --> RB\n  RB -- delivers lines --> C","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:15:39.616Z","createdAt":"2026-01-21T02:28:51.658Z"},{"id":"q-5058","question":"Design a NUMA-aware slab allocator for 64-byte objects on a 4-core, 2-socket system. Each core maintains a private freelist; allocations preferentially use local slabs; deallocations migrate cross-socket via a per-node buffer for batch transfer. Provide data structures, allocate/free pseudo-code, discuss locking-free design, cache-line alignment, and a microbenchmark plan comparing local vs cross-socket allocations?","answer":"Per-core freelists with a lock-free stack; slabs 4KB, 64-byte slots; hot path uses thread-local cache; misses refill from NUMA-local pool; remote frees buffered per-node and migrated in bulk to minimi","explanation":"## Why This Is Asked\nTests practical NUMA locality, lock-free data structures, and cross-socket migration decisions under realistic constraints. It probes memory ordering, cache-line contention, and batch reclamation strategies.\n\n## Key Concepts\n- NUMA locality and cross-socket traffic\n- Lock-free freelists and per-core caches\n- Cache-line padding to avoid false sharing\n- Batch migration of remote frees\n- Memory ordering in hot paths\n\n## Code Example\n```c\n// Pseudo-structure for per-core cache (simplified)\ntypedef struct core_cache {\n  alignas(64) void *head; // atomic head of freelist\n  char padding[60];\n} core_cache_t;\n```\n\n## Follow-up Questions\n- How would you extend for variable-sized objects?\n- How would you measure scalability across more sockets and cores?","diagram":"flowchart TD\n  A[Thread Local Alloc] --> B[Local Freelist]\n  B --> C[Allocate]\n  C --> D[Success]\n  A --> E[Miss -> Refill]\n  E --> F[NUMA Local Pool]\n  F --> G[Migrate on Free -> Remote Buffer]\n  G --> H[Bulk Migration]\n  I[Remote Free] --> J[Migration Buffer] --> D","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","MongoDB","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T04:14:52.458Z","createdAt":"2026-01-21T04:14:52.458Z"},{"id":"q-5123","question":"Implement a simple 256-slot software timer wheel in C for a single-threaded event loop. Each slot stores a list of tasks: struct Task { void (*cb)(void*); void* ctx; struct Task* next; }. API: void init_wheel(); void schedule(void (*cb)(void*), void* ctx, uint32_t delay_ms); void tick_one_ms(); The wheel uses wrap-around, fixed pool of 512 nodes, and a per-slot head pointer. Provide enqueue/dequeue pseudo-code, wrap-around handling, and a minimal test plan?","answer":"Use a 256-slot ring; keep current_slot. schedule maps to slot = (current_slot + delay_ms) & 0xFF; pull a node from a preallocated pool, set cb/ctx, push to front of slot's list. tick executes all node","explanation":"## Why This Is Asked\nLow-level timer logic is common in network and game loops; beginner-friendly but tests memory layout, wrap-around, and basic lock-free thinking without heavy concurrency.\n\n## Key Concepts\n- Ring buffers and wrap-around\n- Pre-allocated object pools\n- Scheduling by slot arithmetic and locality\n- Minimal locking assumptions in single-threaded loop\n\n## Code Example\n```c\ntypedef struct Task { void (*cb)(void*); void* ctx; struct Task* next; } Task;\n#define WHEEL_SIZE 256\nstatic Task* wheel[WHEEL_SIZE];\nstatic int cur = 0;\nstatic Task pool[512]; static int pool_free = 512;\nvoid init_wheel(){ for(int i=0;i<WHEEL_SIZE;i++) wheel[i]=NULL; cur=0; pool_free=512; }\nstatic Task* alloc_task(){ return &pool[--pool_free]; }\nvoid schedule(void (*cb)(void*), void* ctx, uint32_t delay_ms){ int slot = (cur + delay_ms) & (WHEEL_SIZE-1); Task* t = alloc_task(); t->cb=cb; t->ctx=ctx; t->next=wheel[slot]; wheel[slot]=t; }\nvoid tick_one_ms(){ Task* t = wheel[cur]; wheel[cur]=NULL; while(t){ Task* next=t->next; t->cb(t->ctx); t = next; } cur=(cur+1)&(WHEEL_SIZE-1); }\n```\n\n## Follow-up Questions\n- How would you adapt for multiple producers? \n- How would you test with bursty traffic and verify timing guarantees?\n","diagram":"flowchart TD\n  A[Schedule(cb,ctx,delay)] --> B[slot = (cur + delay) % 256]\n  B --> C[push task into wheel[slot]]\n  D[tick_one_ms] --> E[execute wheel[cur]]\n  E --> F[cur = (cur+1) % 256]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Uber","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T07:11:47.040Z","createdAt":"2026-01-21T07:11:47.040Z"},{"id":"q-5215","question":"Design a bounded, lock-free work-stealing queue (WSQ) for a fixed thread pool of N workers. Each worker has a local deque; producers push to their own tail; workers pop from their own tail; idle workers steal from other heads. Provide pseudocode for push, pop, steal; discuss ABA avoidance, memory reclamation (hazard pointers or epochs), and cache-line layout to minimize false sharing. Include a concrete stress-validation plan?","answer":"Propose a bounded, lock-free WSQ with per-thread deques. Push to local tail; pop from local tail; thieves steal from heads. Use versioned pointers or tagged CAS to avoid ABA; apply hazard pointers or ","explanation":"## Why This Is Asked\nTests ability to design high-throughput concurrent queues under contention, covering memory reclamation, false sharing, and backpressure—critical for scalable data platforms at large-scale storage and analytics workloads.\n\n## Key Concepts\n- Lock-free queue basics, per-thread locality, and work-stealing semantics\n- ABA avoidance via versioned pointers or sequence counters\n- Hazard pointers or epoch-based reclamation for memory safety\n- Cache-line alignment and padding to reduce false sharing\n- Bounded capacity and spill-over strategies for backpressure\n\n## Code Example\n```c\ntypedef struct node {\n  void* data;\n  _Atomic(struct node*) next;\n  int stamp; // version counter\n} node_t;\n\ntypedef struct wsq {\n  _Atomic(node_t*) head;\n  _Atomic(node_t*) tail;\n  // per-thread deques omitted for brevity\n} wsq_t;\n```\n\n## Follow-up Questions\n- How would you adapt WSQ design for NUMA and high-core-count machines?\n- What metrics would you collect to detect bottlenecks and starvation, and how would you validate scalability?","diagram":"flowchart TD\n  A[Push to local tail] --> B{Space in local deque?}\n  B -- Yes --> C[Write and advance tail]\n  B -- No --> D[ Spill to shared spill ring ]\n  E[Steal from heads] --> F[Update owner state]\n  C --> G[Operation complete]\n  F --> G","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:01:14.152Z","createdAt":"2026-01-21T11:01:14.152Z"},{"id":"q-5284","question":"Design and implement a tiny software transactional memory (STM) in C11 that supports two concurrent transactions operating on a shared array of 64-bit integers. Provide begin(), read(addr), write(addr, val), commit(), and abort(). Use per-slot versioning to detect conflicts, a read/write set, and simple rollback. Explain how you avoid ABA, ensure serializability, and validate with a minimal two-transaction test under contention?","answer":"Begin with per-slot version counters and per-transaction read/write logs. On read, snapshot value and ver; on write, stash in the log. Commit validates all prior versions unchanged using CAS to advanc","explanation":"## Why This Is Asked\n\nTests understanding of memory ordering, non-blocking progress, and correctness of transactional memory in a tight two-thread scenario.\n\n## Key Concepts\n\n- Per-slot version counters to detect conflicts\n- Read/write logs and commit protocol\n- ABA avoidance with version increments and monotonic counters\n- Memory_order semantics and atomic CAS\n\n## Code Example\n\n```c\ntypedef struct { atomic_uint64_t ver; uint64_t val; } slot_t;\ntypedef struct { slot_t *slots; size_t n; log_t read, write; } tx_t;\n\n// begin, read, write, commit skeletons...\n```\n\n## Follow-up Questions\n\n- How would you scale to many concurrent transactions and nested transactions?\n- How would you detect starvation and unfairness?","diagram":null,"difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T14:59:59.477Z","createdAt":"2026-01-21T14:59:59.477Z"},{"id":"q-684","question":"Design a fixed-size ring buffer in C that stores bytes. Capacity N is a power of two (e.g., 1024). Show how to compute the next index using a mask (idx & (N-1)), and explain full vs empty detection using only head and tail counters. Provide enqueue and dequeue logic for a single-producer/single-consumer scenario?","answer":"Use two indices: head and tail. Let mask = N-1. Enqueue: if ((head - tail) == N) return 0; data[head & mask] = value; head++; Dequeue: if (head == tail) return 0; *out = data[tail & mask]; tail++; Thi","explanation":"## Why This Is Asked\n\nTests understanding of a practical, low-level data structure and its wrap-around behavior, plus efficient empty/full checks in a simple producer/consumer path.\n\n## Key Concepts\n\n- Ring buffers\n- Power-of-two masking\n- Empty/full checks with head/tail without extra state\n- SPSC memory ordering\n\n## Code Example\n\n```c\ntypedef struct {\n  size_t head, tail;\n  unsigned char data[N];\n} Ring;\n\nint enqueue(Ring *r, unsigned char value) {\n  if ((r->head - r->tail) == N) return 0; // full\n  r->data[r->head & (N - 1)] = value;\n  r->head++;\n  return 1;\n}\nint dequeue(Ring *r, unsigned char *out) {\n  if (r->head == r->tail) return 0; // empty\n  *out = r->data[r->tail & (N - 1)];\n  r->tail++;\n  return 1;\n}\n```\n\n## Follow-up Questions\n\n- How would you modify for multi-producer/multi-consumer?\n- What memory-ordering considerations arise on weakly-ordered architectures?","diagram":"flowchart TD\n  A[Head/Tail] --> B[Mask: (N-1)]\n  B --> C[Enqueue path]\n  B --> D[Dequeue path]\n  C --> E[Increment Head]\n  D --> F[Increment Tail]\n  E --> G{Full?}\n  F --> H{Empty?}","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Hugging Face","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T15:59:22.270Z","createdAt":"2026-01-11T15:59:22.270Z"},{"id":"q-692","question":"Design a lock-free ring buffer that supports multiple producers and multiple consumers with bounded capacity. Provide enqueue/dequeue pseudo-code, explain how you avoid ABA, how memory reclamation is handled (hazard pointers or epochs), and why it scales under high contention. Include caveats on cache lines and false sharing. How would you validate under stress?","answer":"Use a power-of-two ring buffer with per-slot sequence numbers and separate atomic head/tail indices. Each slot has a 64-bit sequence: low 32 bits = turn number, high 32 bits = slot index. Producers: read tail, compute slot, check sequence matches expected turn, CAS tail to reserve, write item, increment sequence. Consumers: read head, compute slot, check sequence matches expected turn, CAS head to advance, read item, increment sequence. ABA avoided by monotonically increasing sequence numbers (turn * capacity + index). Memory reclamation via epoch-based reclamation: threads enter critical section, publish retired nodes, exit when global epoch advances. Cache line padding: align head/tail indices and slot arrays to separate cache lines (64-byte boundaries) to avoid false sharing between producers and consumers.","explanation":"## Why This Is Asked\n\nTests understanding of low-level concurrency, lock-free design under real contention.\n\n## Key Concepts\n\n- MPMC queue design with sequence numbers\n- ABA protection via monotonic sequences\n- Memory reclamation (hazard pointers, epochs)\n- Cache friendliness and false sharing prevention\n\n## Code Example\n\n```c\n// Pseudo-code\nstruct Slot {\n    atomic_uint64_t seq;\n    void* data;\n};\n\nbool enqueue(void* item) {\n    uint64_t pos = tail.load();\n    Slot* slot = &buffer[pos & mask];\n    uint64_t seq = slot->seq.load();\n    if ((seq & mask) != (pos & mask)) return false;\n    if (!tail.compare_exchange(pos, pos + 1)) return false;\n    slot->data = item;\n    slot->seq.store(pos + 1);\n    return true;\n}\n\nvoid* dequeue() {\n    uint64_t pos = head.load();\n    Slot* slot = &buffer[pos & mask];\n    uint64_t seq = slot->seq.load();\n    if ((seq & mask) != (pos & mask)) return nullptr;\n    if (!head.compare_exchange(pos, pos + 1)) return nullptr;\n    void* item = slot->data;\n    slot->seq.store(pos + capacity + 1);\n    return item;\n}\n```\n\n## Follow-up Questions\n\n- How would you detect and recover from stalls under hot paths?\n- Compare hazard pointers vs epochs for this use-case.\n- What happens under backpressure when the buffer is full?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Databricks","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:54:20.888Z","createdAt":"2026-01-11T16:24:48.553Z"},{"id":"q-694","question":"Design a cache-friendly, per-thread deque work-stealer for a multi-core task executor. Each worker maintains a fixed-size ring buffer for bottom push/pop; thieves steal from the top of other workers via CAS on a top index with a version counter. Explain ABA avoidance, memory ordering, and padding to avoid false sharing. Provide precise pseudo-code and a realistic burst workload scenario?","answer":"Propose per-thread deques with a bottom push/pop and a shared top for steals. Local path uses a fixed-size, cache-aligned ring; steals CAS on top with a version tag to prevent ABA; pad structures to p","explanation":"## Why This Is Asked\nTests ability to design scalable, non-blocking schedulers and reason about ABA, memory ordering, and cache effects.\n\n## Key Concepts\n- Work-stealing deques\n- ABA avoidance with version counters\n- Cache-line padding to avoid false sharing\n- Memory order: acquire/release\n- Backoff and fairness under bursty loads\n\n## Code Example\n```javascript\n// Pseudo-code: per-thread deque with local and steal paths\nclass Deque {\n  constructor(cap) { /* ... */ }\n  pushBottom(x) { /* O(1) with cache-friendly indices */ }\n  popBottom() { /* ... */ }\n  stealTop(owner) { /* CAS on top with version, then claim slot */ }\n}\n```\n\n## Follow-up Questions\n- How would you test tail latency under bursty arrival rates?\n- How would you adapt the design for multi-socket NUMA and cache-coherent interconnects?\n- How would you extend to prioritized tasks or dynamic resizing of ring buffers?","diagram":"flowchart TD\n  A[Worker i deque] --> B[Push/Pop bottom (local)]\n  A --> C[Steal from top of another worker]\n  D[Top pointer with version tag] --> E[ABA avoidance via CAS/version]\n  B --> F[Local fast path]\n  C --> G[Successful steal -> task transfer]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:13.498Z","createdAt":"2026-01-11T17:16:13.498Z"},{"id":"q-707","question":"Design a crash‑consistent, multi‑producer/multi‑consumer ring buffer backed by persistent memory PMEM. How would you ensure last enqueued item durability across power loss, implement recovery, and validate correctness? Provide concise enqueue/dequeue pseudocode with proper flush/fence ordering and discuss failure scenarios?","answer":"Use a crash‑safe PMEM ring buffer with two‑phase publish: write the data to the next slot, flush the data, then publish by updating a durable tail with a release store and a fence (sfence/clwb). Use p","explanation":"## Why This Is Asked\n\nTests ability to design crash‑consistent data paths in persistent memory, a common production issue when power failures occur during in‑flight operations.\n\n## Key Concepts\n\n- Durability guarantees for PMEM writes\n- Memory ordering: release/acquire, fences, cacheline flushes\n- Recovery via redo log and slot sequence counters\n- ABA avoidance in a concurrent ring\n- Testing with fault injection and crash replay\n\n## Code Example\n\n```c\n// Pseudo-code: enqueue/dequeue with PMEM flush/fence\n// Slot: { data, seq, valid }\nvoid enqueue(T v){\n  size_t t = tail.fetch_add(1);\n  Slot *s = &ring[t % CAP];\n  s->data = v; // write data\n  clwb(&s->data, sizeof(T));\n  fence(); // ensure data persists\n  s->seq = t; // publish with durable tail update (release)\n  clwb(&s->seq, sizeof(size_t));\n  fence();\n  // publish tail already happens via atomic tail update\n}\n\nbool dequeue(T *out){\n  size_t h0 = head.load();\n  Slot *s = &ring[h0 % CAP];\n  if (s->seq != h0) return false;\n  *out = s->data;\n  s->valid = false;\n  clwb(&s->valid, sizeof(bool));\n  fence();\n  head.fetch_add(1);\n  return true;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle power loss during the publish vs data write steps?\n- How would you validate recovery correctness across multiple restart scenarios?","diagram":"flowchart TD\n  A[Producer Enqueue] --> B[Write Slot Data] \n  B --> C[Flush Data] \n  C --> D[Publish Tail] \n  D --> E[Consumer Dequeue]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Coinbase","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:29:56.756Z","createdAt":"2026-01-11T18:29:56.756Z"},{"id":"q-712","question":"Design a NUMA-aware in-memory index with per-node shards and a lock-free cross-node coordinator. Provide insertion and lookup with minimal locking, specify data layout (shards, padding, key/value encodings), and memory-order guarantees (fences, atomic ops). Describe a deadlock-free shard rebalancing protocol under high contention and outline tests with realistic Snowflake/Twitter-scale workloads?","answer":"Per-node shards with a global coordinator. Lock-free hot path: atomic upserts into per-node arrays using CAS, with 64-byte padding; memory order: acquire/release fences around reads/writes; cross-node","explanation":"## Why This Is Asked\nTests understanding of NUMA-aware design, lock-free data paths, and safe shard rebalancing under contention in large-scale systems.\n\n## Key Concepts\n- NUMA affinity and per-node shard layouts\n- Lock-free synchronization with CAS and memory fences\n- Cache-line padding to prevent false sharing\n- Epoch-based or versioned rebalance without blocking\n\n## Code Example\n```cpp\n// Pseudo core: per-node shard insert using CAS\nstruct Shard { std::atomic<Key> key; std::atomic<Value> val; char pad[64]; };\nvoid insert(Shard* s, Key k, Value v){ auto old = s->key.load(std::memory_order_acquire); if(old==k) { s->val.store(v, std::memory_order_release); return; } // CAS loop omitted }\n```\n\n## Follow-up Questions\n- How would you validate correctness under cross-node contention?\n- What are failure modes under memory-order relaxations?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:16:51.595Z","createdAt":"2026-01-11T19:16:51.595Z"},{"id":"q-723","question":"Design a software-based **TLB** for a 4-core 64-bit system with 4KiB pages. Each core has a private 128-entry **TLB** and a global page-table invalidation path. Provide lookup/refill pseudo-code, discuss eviction strategy (LRU vs. random), synchronization via **memory fences**, and cross-core shootdowns. Include a test under memory pressure and explain validation?","answer":"Private per-core 128-entry TLB, 4KiB pages, 4-way set-associative. On miss, walk multi-level page tables, then install using atomic ops. Use a scalable eviction (pseudo-LRU). Invalidate entries across","explanation":"## Why This Is Asked\n\nA software TLB with per-core caches and cross-core invalidations tests low-level thinking about coherence, consistency, and performance under contention. It also probes trade-offs between eviction, barriers, and hardware hints.\n\n## Key Concepts\n\n- TLB structure: per-core caches, set-associative layout\n- Page-table walk costs and caching gains\n- Cross-core invalidation/shootdown mechanisms\n- Memory fences and atomic updates\n- Validation under memory pressure and realistic workloads\n\n## Code Example\n\n```javascript\n// Pseudo-code: TLB lookup and refill\nfunction tlbLookup(vpn){\n  const idx = vpn % 128;\n  const e = tlb[idx];\n  if (e && e.vpn === vpn && e.valid) return e.pte;\n  return null;\n}\nfunction tlbRefill(vpn, pte){\n  const idx = vpn % 128;\n  tlb[idx] = { vpn, pte, valid: true, ts: Date.now() };\n}\n```\n\n## Follow-up Questions\n\n- How would you scale to larger pages or userfaults?\n- How would you validate correctness under concurrent refills and shootdowns?","diagram":"flowchart TD\n  A[Core] --> B[TLB miss]\n  B --> C[Page walk]\n  C --> D[Install entry]\n  D --> E[Shoot down other cores]\n  E --> F[Return to caller]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Oracle","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T20:24:01.827Z","createdAt":"2026-01-11T20:24:01.827Z"},{"id":"q-725","question":"Design a crash-consistent, in-memory index for a 4-byte key, 8-byte value store on an 8-core Linux machine. Use per-core log-structured segments and a Bloom filter; describe durable append ordering, startup recovery by replaying per-core logs, and validation under power-loss scenarios?","answer":"Per-core logs minimize contention; mutations append to local segments, then a durable epoch fence persists metadata. Recovery replays per-core segments to rebuild the index; Bloom filters speed lookup","explanation":"## Why This Is Asked\n\nThis question probes experience with crash-consistent in-memory structures, per-core data locality, and durable metadata synchronization under power failures—critical in low-latency financial/ads platforms.\n\n## Key Concepts\n\n- Per-core log-structured index and Bloom filter for fast lookups\n- Durable append order via epoch fences and fsync/msync semantics\n- Recovery by replaying per-core logs in a deterministic order\n- False sharing minimization and memory-mapped file durability\n\n## Code Example\n\n```javascript\n// Pseudo replay of per-core logs to rebuild index\nfunction replay_logs(coreLogs) {\n  for (const core of coreLogs) {\n    for (const entry of core.segments) {\n      apply(entry);\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How do you handle Bloom filter false positives during recovery?\n- What are the failure modes during corruption of a core log segment, and how do you detect them?\n- How would you validate performance under steady-state and crash-recovery cycles?","diagram":"flowchart TD\n  A[Mutate] --> B[Append to Core Log]\n  B --> C[Durable Epoch Fence]\n  C --> D[Query index with Bloom filter]\n  D --> E[Recovery uses per-core logs]","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T21:16:32.089Z","createdAt":"2026-01-11T21:16:32.089Z"},{"id":"q-734","question":"Design an epoch-based reclamation scheme for a lock-free stack in a 64-bit, multi-threaded user-space library. Each thread publishes its local epoch; a global clock advances periodically. On pop, move the node to a retire-list with its epoch and reclaim only after all threads have observed an epoch older than that node. Include a stress test with high contention?","answer":"Use epoch-based reclamation for a lock-free stack. Each thread publishes a local epoch; a global epoch advances periodically. On pop, retire the node with its epoch and reclaim only after all threads ","explanation":"## Why This Is Asked\nThis question probes practical low-level memory management under concurrency, including safe reclamation without locks.\n\n## Key Concepts\n- Lock-free data structures\n- Epoch-based reclamation\n- Memory ordering and fences\n- ABA avoidance\n\n## Code Example\n```javascript\n// Minimal epoch-based reclamation sketch\nclass Node { constructor(val) { this.val = val; this.next = null; } }\n\n// Global state\nlet globalEpoch = 0;\nlet threadEpochs = new Map();\n\n// Publish epoch from a thread\nfunction publishEpoch(epoch) { /* store per-thread epoch */ }\n\n// Retire a node\nfunction retire(node, epoch) { /* add to retire list with epoch */ }\n\n// Reclaim loop\nfunction advanceEpoch() { globalEpoch++; }\n```\n\n## Follow-up Questions\n- How would you detect and prevent ABA in this scheme?\n- How would you tune epoch advancement to avoid memory starvation under bursty workloads?\n","diagram":"flowchart TD\n  A[Publish epoch] --> B[Update stack head with CAS]\n  B --> C[Retire node into epoch list]\n  C --> D[Global epoch advances]\n  D --> E[Reclaim when all seen < retire epoch]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Lyft","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:18:50.970Z","createdAt":"2026-01-11T22:18:50.970Z"},{"id":"q-744","question":"In a 2-socket x86-64 server with MESI coherence, design a lock-free, multi-producer single-consumer ring buffer in shared memory for a 10 Gbps network path. Use per-slot sequence numbers to avoid ABA, with a fixed size N=1<<16 and 64-byte payload slots. Provide slot layout, push/pop pseudo-code with memory fences, discuss wrap-around and backpressure, and outline a minimal microbenchmark to validate throughput and data integrity under contention?","answer":"Implement a fixed-size ring (N=1<<16) in shared memory. Each slot stores a 64-bit seq and 64-byte payload. Producers write payload, increment seq, mfence, then CAS head. Consumer spins on tail, valida","explanation":"## Why This Is Asked\nTests lock-free IPC, memory ordering, and cache-coherence handling on NUMA systems under contention.\n\n## Key Concepts\n- Lock-free ring buffers with per-slot sequence numbers to avoid ABA\n- Memory ordering on x86-64, mfence usage, cache-line padding\n- Backpressure handling and wrap-around semantics\n\n## Code Example\n```c\ntypedef struct { volatile uint64_t seq; uint8_t data[64]; char pad[56]; } Slot;\ntypedef struct { Slot slots[N]; _Atomic uint64_t head; _Atomic uint64_t tail; } Ring;\n```\n\n```c\n// Push (producer)\nuint64_t pos; do { pos = atomic_read(&ring->head); if (slot_full(pos)) continue; } while(!atomic_compare_exchange(&ring->head, pos, pos+1));\nr ing->slots[pos & (N-1)].data = payload; ring->slots[pos & (N-1)].seq = pos; mfence();\n```\n\n## Follow-up Questions\n- How would you extend to multi-consumer or multi-ported rings?\n- What are the performance pitfalls and mitigations (false sharing, cache thrashing)?","diagram":"flowchart TD\n  A[Producers] --> B[Shared Ring Slots]\n  B --> C[Single Consumer]\n  C --> D[Tail Advancement]\n  E[Memory Fences] --> F[Orderly Visibility]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Tesla","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T23:19:01.045Z","createdAt":"2026-01-11T23:19:01.045Z"},{"id":"q-752","question":"Design a crash-safe, persistent ring buffer in NVRAM for a 2-socket NUMA system with a PCIe NIC. Capacity N=1<<18, 128-byte payloads, per-slot 64-bit sequence to prevent ABA. Slot: [payload|seq|meta]. Enqueue: publish payload, fence, then update seq. Dequeue: verify seq before consume. Durability via per-slot commit log: flush payload and seq, then epoch commit. On crash, recover by replaying committed epochs and validating seq monotonicity. Provide a minimal microbenchmark to validate throughput and correctness under power loss?","answer":"Design a crash-safe, persistent ring buffer in NVRAM for a 2-socket NUMA system with a PCIe NIC. N=1<<18, 128-byte payloads, per-slot 64-bit sequence to avoid ABA. Slot: payload|seq|meta. Enqueue: pub","explanation":"## Why This Is Asked\nTests understanding of crash-consistent data structures, non-volatile memory ordering, and recovery.\n\n## Key Concepts\n- Persistent memory semantics, fences, epoch-based durability\n- ABA avoidance with per-slot seq, cache-line layout, minimal recovery log\n- Validation under power loss using replay consistency checks\n\n## Code Example\n\n```javascript\n// Placeholder: interview design discussion, not implementable here\n```\n\n## Follow-up Questions\n- How would you adapt for multi-consumer scenarios?\n- What failure modes break the design and how to mitigate?","diagram":"flowchart TD\n  Producer --> Enqueue\n  Enqueue --> Commit\n  Commit --> Recovery\n  Recovery --> Consumer","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","IBM","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:30:58.766Z","createdAt":"2026-01-12T01:30:58.766Z"},{"id":"q-760","question":"On a dual-socket NUMA server, design a cross-NUMA, zero-copy ring buffer for a 40 Gbps path between two processes where producers live on socket A and a consumer on socket B. Use per-slot 64-bit sequence numbers to prevent ABA, 128-byte payload slots, and capacity 1<<18 with 64-byte alignment. Provide slot layout, enqueue/dequeue pseudo-code with memory fences and cache-line padding, wrap-around and backpressure handling, and outline a minimal microbenchmark to validate throughput and data integrity under cross-socket contention?","answer":"Cross-NUMA, two-process ring for 40 Gbps on a dual-socket server. Slot: 128 bytes; capacity 1<<18; 64-byte alignment; per-slot 64-bit sequence for ABA-avoidance. NUMA-aware allocation on local node.\n\n## Slot Layout\n```c\nstruct slot {\n    uint64_t seq;           // 8 bytes - sequence number\n    uint64_t reserved;      // 8 bytes - padding\n    char data[112];         // 112 bytes - payload (128-16)\n} __attribute__((aligned(64)));  // Cache-line aligned\n\nstruct ring_buffer {\n    uint64_t head;          // Consumer position\n    uint64_t tail;          // Producer position  \n    char pad[64 - 16];      // Cache-line padding\n    struct slot slots[1<<18]; // 256KB total\n} __attribute__((aligned(64)));\n```\n\n## Enqueue (Producer on Socket A)\n```c\nbool enqueue(struct ring_buffer* rb, const void* data, size_t len) {\n    uint64_t pos, idx, seq;\n    \n    // Get current tail position\n    pos = __atomic_load_n(&rb->tail, __ATOMIC_RELAXED);\n    \n    // Check if ring is full (head + capacity)\n    uint64_t head = __atomic_load_n(&rb->head, __ATOMIC_ACQUIRE);\n    if (pos - head >= (1<<18)) return false; // Backpressure\n    \n    idx = pos & ((1<<18) - 1);\n    struct slot* slot = &rb->slots[idx];\n    \n    // Load current sequence to check slot availability\n    seq = __atomic_load_n(&slot->seq, __ATOMIC_ACQUIRE);\n    if (seq != pos) return false; // Slot not ready\n    \n    // Copy payload (non-temporal for cross-NUMA)\n    __builtin_memcpy(&slot->data, data, len);\n    \n    // Memory fence before publishing\n    __atomic_thread_fence(__ATOMIC_RELEASE);\n    \n    // Publish new sequence (ABA-safe)\n    __atomic_store_n(&slot->seq, pos + 1, __ATOMIC_RELEASE);\n    \n    // Advance tail position\n    __atomic_store_n(&rb->tail, pos + 1, __ATOMIC_RELAXED);\n    return true;\n}\n```\n\n## Dequeue (Consumer on Socket B)\n```c\nbool dequeue(struct ring_buffer* rb, void* data, size_t* len) {\n    uint64_t pos, idx, seq;\n    \n    // Get current head position\n    pos = __atomic_load_n(&rb->head, __ATOMIC_RELAXED);\n    \n    idx = pos & ((1<<18) - 1);\n    struct slot* slot = &rb->slots[idx];\n    \n    // Check if slot is ready\n    seq = __atomic_load_n(&slot->seq, __ATOMIC_ACQUIRE);\n    if (seq != pos + 1) return false; // No data available\n    \n    // Copy payload\n    *len = 112; // Fixed payload size\n    __builtin_memcpy(data, &slot->data, *len);\n    \n    // Memory fence before reclaiming\n    __atomic_thread_fence(__ATOMIC_RELEASE);\n    \n    // Mark slot as free (wrap-around safe)\n    __atomic_store_n(&slot->seq, pos + 2, __ATOMIC_RELEASE);\n    \n    // Advance head position\n    __atomic_store_n(&rb->head, pos + 1, __ATOMIC_RELAXED);\n    return true;\n}\n```\n\n## NUMA Allocation\n```c\n// Allocate on socket A (producer side)\nvoid* alloc_numa_socketA(size_t size) {\n    void* ptr = numa_alloc_onnode(size, 0); // Socket 0\n    mlock(ptr, size); // Pin in memory\n    return ptr;\n}\n```\n\n## Microbenchmark\n```c\nvoid benchmark_cross_numa() {\n    const size_t iterations = 10000000;\n    const size_t payload_size = 112;\n    \n    // Setup: fork processes, bind to sockets\n    pid_t consumer = fork();\n    if (consumer == 0) {\n        // Consumer process - bind to socket B\n        cpu_set_t mask;\n        CPU_ZERO(&mask);\n        for (int i = 8; i < 16; i++) CPU_SET(i, &mask);\n        sched_setaffinity(0, sizeof(mask), &mask);\n        \n        // Run consumer loop, measure throughput\n        auto start = std::chrono::high_resolution_clock::now();\n        size_t received = 0;\n        while (received < iterations) {\n            if (dequeue(rb, buffer, &len)) {\n                // Verify data integrity\n                if (verify_checksum(buffer, len)) received++;\n            }\n        }\n        auto end = std::chrono::high_resolution_clock::now();\n        \n        double throughput = (received * payload_size * 8) / \n            std::chrono::duration<double>(end - start).count() / 1e9;\n        printf(\"Throughput: %.2f Gbps\\n\", throughput);\n    }\n    \n    // Producer process - bind to socket A\n    cpu_set_t mask;\n    CPU_ZERO(&mask);\n    for (int i = 0; i < 8; i++) CPU_SET(i, &mask);\n    sched_setaffinity(0, sizeof(mask), &mask);\n    \n    // Generate test data with checksums\n    for (size_t i = 0; i < iterations; ) {\n        if (enqueue(rb, test_data + (i % 1000), payload_size)) {\n            i++;\n        } else {\n            _mm_pause(); // Backpressure handling\n        }\n    }\n}\n```","explanation":"## Why This Is Asked\nTests cross-NUMA IPC design with ABA avoidance, memory ordering, and cache-line discipline for senior systems positions.\n\n## Key Concepts\n- Cross-NUMA memory allocation and cache coherence\n- Per-slot sequencing to prevent ABA problems\n- Acquire/release semantics for proper memory ordering\n- Cache-line padding to avoid false sharing\n- Backpressure handling and wrap-around logic\n- NUMA-aware process binding and memory pinning\n\n## Technical Accuracy\n- 40 Gbps requires ~5GB/s throughput, achievable with this design\n- 64-bit sequence numbers prevent ABA even with wrap-around\n- Cache-line alignment (64 bytes) prevents false sharing\n- Memory fences ensure proper ordering across NUMA domains\n- Fixed 128-byte slots with 112-byte payload meet requirements\n- Capacity 1<<18 (262144 slots) provides 32MB buffer space\n\n## Follow-up Questions\n- How would you extend to N producers and M consumers with fairness guarantees?\n- What failure modes matter under NUMA remapping or node failure?\n- How would you handle variable-sized payloads efficiently?\n- What optimizations for specific CPU architectures (Intel vs AMD)?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:11:20.690Z","createdAt":"2026-01-12T03:49:06.047Z"},{"id":"q-772","question":"Design a cache-friendly fixed-size object pool for 128-byte blocks used by a multi-threaded producer-consumer path. Implement init, alloc, and free in C for a pool of 1<<20 blocks, each 128 bytes and 64-byte aligned. Use per-thread caches to reduce contention and a global lock-free free-list for overflow. Explain how you avoid false sharing, show the slot layout with a freelist pointer, and outline a microbenchmark to measure throughput and tail latency under contention?","answer":"Per-thread arenas hold a small freelist of 256 blocks, each 128B aligned to 64B. Allocation pops from the thread-local freelist; if empty, refill from a shared global pool via CAS-based lock-free stac","explanation":"## Why This Is Asked\nThis task probes practical memory pool design under contention, cache alignment, and per-thread vs global sharing strategies.\n\n## Key Concepts\n- Cache locality and false sharing\n- Per-thread arenas vs global pool\n- Lock-free stack and CAS\n- Alignment and memory fences\n\n## Code Example\n```c\ntypedef struct Block {\n  struct Block *next;\n  uint8_t data[120];\n} Block;\n#endif\n``` \n\n```c\n// Pseudo: per-thread arena and global pool refill\n```\n\n## Follow-up Questions\n- How do you handle pool exhaustion?\n- How would you adapt for variable block sizes?","diagram":"flowchart TD\nA[Thread] --> B[Alloc from TLS]\nB --> C{Empty?}\nC -- Yes --> D[Refill from Global]\nC -- No --> E[Return Block]\nD --> E","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:52:07.495Z","createdAt":"2026-01-12T04:52:07.495Z"},{"id":"q-778","question":"Write a C function sum_prefetch that sums N 64-bit integers from an aligned array of length n using software prefetching to hide memory latency. Use 4-way unrolling and __builtin_prefetch to bring data 256 elements ahead. Ensure correctness for any length. Propose a microbenchmark plan to compare with a naive loop and discuss cache-line utilization and false sharing concerns?","answer":"Use four accumulators (a,b,c,d). Loop i+=4; prefetch arr[i+256]; accumulate a+=arr[i], b+=arr[i+1], c+=arr[i+2], d+=arr[i+3]. Finalize by adding a,b,c,d. Ensure arr is 64-byte aligned and compile with","explanation":"## Why This Is Asked\nTests practical low-level optimization skills: cache behavior, prefetching, and reliable counting.\n\n## Key Concepts\n- Cache lines and spatial locality\n- Software prefetching with __builtin_prefetch\n- Loop unrolling and multiple accumulators\n- Alignment and portability\n\n## Code Example\n```c\nuint64_t sum_prefetch(const uint64_t *arr, size_t n){\n    uint64_t a=0,b=0,c=0,d=0;\n    size_t i=0;\n    for(; i+3<n; i+=4){\n        __builtin_prefetch(&arr[i+256],0,1);\n        a += arr[i];\n        b += arr[i+1];\n        c += arr[i+2];\n        d += arr[i+3];\n    }\n    for(; i<n; ++i) a += arr[i];\n    return a+b+c+d;\n}\n``` \n\n## Follow-up Questions\n- How would you adapt this for streaming data vs. random access?\n- What changes if array length is not multiple of four?","diagram":null,"difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:30:51.288Z","createdAt":"2026-01-12T05:30:51.288Z"},{"id":"q-784","question":"Design a deterministic, time-sliced barrier for a three-stage streaming pipeline on a 2-socket x86-64 system. Each stage runs on a fixed subset of cores; implement a barrier that advances phases only after every core finishes its assigned slice within a bounded time. Explain how to ensure bounded latency under cache-line contention, preserve MESI coherence, and prevent starvation. Provide pseudo-code for enter_barrier for a core and discuss validation?","answer":"Implement a per-core epoch barrier with fixed 64-cycle slices. Each core writes to its per-core slot and then performs an acquire on a shared phase counter. When all slots are written, a master increm","explanation":"## Why This Is Asked\n\nTests knowledge of deterministic synchronization and bounded-latency barriers in NUMA systems.\n\n## Key Concepts\n\n- Deterministic barriers for streaming pipelines\n- Time-sliced execution and fairness\n- Cache-line padding to avoid false sharing\n- MESI coherence implications on cross-socket barriers\n- Validation of worst-case latency under contention\n\n## Code Example\n\n```javascript\n// Pseudo-code for enter_barrier(coreId, total)\nfunction enter_barrier(coreId, total) {\n  // write completion\n  barrierSlots[coreId].done = true;\n  // spin until all done\n  while (!allDone()) {}\n  // reset for next phase\n  if (coreId == 0) phase++;\n  barrierSlots[coreId].done = false;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle dynamic thread affinity changes?\n- How would you measure and bound worst-case latency across sockets?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:37:19.978Z","createdAt":"2026-01-12T06:37:19.978Z"},{"id":"q-794","question":"Design and implement a cache-friendly tiled matrix multiply for two large double-precision matrices stored in row-major order on a two-socket NUMA system. Propose a tile size of 32x32, provide C code for the tiled kernel with boundary handling, explain how to maximize L1/L2 reuse, NUMA locality (first-touch), avoid false sharing, and an inline 4-wide inner-loop unrolling. Include a microbenchmark plan comparing to a naive triple-nested loop and how you would measure throughput and cache behavior?","answer":"Implement a cache-friendly tiled matmul: 32x32 tiles, 4-wide inner-loop unrolling, and first-touch NUMA affinity to localize A, B, C. Use restrict pointers, align data to 64-byte cache lines, prefetch","explanation":"## Why This Is Asked\n\nTests hands-on understanding of memory hierarchy, NUMA locality, and practical optimization trade-offs in a real kernel.\n\n## Key Concepts\n\n- Cache tiling for L1/L2 reuse\n- NUMA first-touch locality on multi-socket systems\n- Boundary handling for non-multiples of tile size\n- Loop unrolling and prefetching strategies\n- False-sharing avoidance via per-tile accumulation\n\n## Code Example\n\n```javascript\n// Pseudo-C kernel illustrating 32x32 tiling\nvoid matmul_tiled(int N, const double *A, const double *B, double *C){\n  for(int ii=0; ii<N; ii+=32){\n    for(int jj=0; jj<N; jj+=32){\n      for(int kk=0; kk<N; kk+=32){\n        for(int i=ii; i< (ii+32) && i<N; ++i){\n          for(int j=jj; j<(jj+32) && j<N; ++j){\n            double sum = 0.0;\n            for(int k=kk; k<(kk+32) && k<N; ++k){\n              sum += A[i*N+k] * B[k*N+j];\n            }\n            C[i*N+j] += sum;\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you validate correctness for non-multiple tile sizes?\n- How would you adapt to AVX2/AVX-512 and data layout changes to boost throughput?","diagram":"flowchart TD\n  A[Start] --> B[Tiled Loops]\n  B --> C[Compute Tile]\n  C --> D[Edge Tiles]\n  D --> E[Benchmark & Validate]","difficulty":"intermediate","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T07:29:17.327Z","createdAt":"2026-01-12T07:29:17.327Z"},{"id":"q-800","question":"Design a per-core, lock-free memory allocator for a shared-memory, NUMA-aware object store. Each core maintains a 2 MB local heap; allocations first attempt local allocation, with a fast cross-core path using atomic hand-offs; reclaimed memory is managed via hazard pointers and epoch-based reclamation. Provide allocate/free APIs, a sketch of the free-list structure, and a microbenchmark plan that shows fragmentation under steady-state load?","answer":"Per-core free lists with a bump-pointer local allocator inside a 2 MB heap per core. Align to 64 bytes; local allocations are fast paths, cross-core requests use an atomic hand-off ring to a target co","explanation":"## Why This Is Asked\nTests core memory management, concurrency primitives, NUMA awareness, and safe reclamation in high-throughput systems.\n\n## Key Concepts\n- Per-core locality\n- Lock-free reclaim (hazard pointers, epochs)\n- Cross-core handoff patterns\n- Fragmentation and cache-line alignment\n\n## Code Example\n```c\n// Pseudo allocator core logic\ntypedef struct Block Block;\nvoid* alloc(size_t n);\nvoid free(void* p);\n```\n\n## Follow-up Questions\n- How would you measure false sharing?\n- How would you adapt if cores may be hot-swapped or deactivated?","diagram":"flowchart TD\n  A[Request] --> B{Local?}\n  B -- Yes --> C[Alloc from local heap]\n  B -- No --> D[Enqueue cross-core handoff]\n  D --> E[Target core alloc]\n  E --> F[Return]\n","difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","MongoDB","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:31:26.187Z","createdAt":"2026-01-12T08:31:26.187Z"},{"id":"q-810","question":"Design a crash-consistent, bounded, multi-producer/multi-consumer queue backed by non-volatile memory. It must survive power loss, use per-slot sequence numbers to avoid ABA, provide push/pop pseudo-code with proper memory fences, and support epoch-based reclamation to avoid hazard pointers. Outline recovery on boot and a microbenchmark plan?","answer":"A ring in NVRAM with N=1<<16 slots; head/tail durable counters; each slot carries a 64-byte payload and a sequence nonce. Enqueue writes payload, then updates sequence and persists with fences. Dequeu","explanation":"## Why This Is Asked\nTackles crash-consistency, non-volatile memory ordering, ABA avoidance, and safe memory reclamation in a high-concurrency data path.\n\n## Key Concepts\n- NVRAM durability and flush ordering (clwb/clflush, sfence)\n- Per-slot sequence numbers to prevent ABA\n- Epoch-based reclamation vs. hazard pointers\n- Recovery: replay tail, prune uncommitted entries\n\n## Code Example\n```c\n// simplified sketch showing write order and fences\nvoid enqueue(Ring *r, void *payload){\n  uint64_t t = fetch_and_add(&r->tail, 1);\n  Slot *s = &r->slots[t & (N-1)];\n  memcpy(s->payload, payload, 64);\n  __sync_synchronize(); // fence before seq\n  s->seq = t<<1 | 1; // mark committed\n  // persist s and tail\n}\n```\n\n## Follow-up Questions\n- How would you implement recovery after power loss?\n- How do you validate correctness under concurrent stress?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T09:35:21.464Z","createdAt":"2026-01-12T09:35:21.464Z"},{"id":"q-816","question":"Design a crash-consistent, persistent ring buffer for a multi-producer/multi-consumer event stream backed by non-volatile memory, with 1<<18 slots of 128-byte payloads; explain ABA avoidance via per-slot sequence numbers, two-phase publish with durable commit, and required flush/barrier order; describe recovery and a microbenchmark plan under simulated power loss?","answer":"Propose a crash-consistent, persistent ring buffer for NVRAM with multi-producer, multi-consumer access. Use 1<<18 slots, 128-byte payloads. ABA avoided via per-slot sequence numbers; two-phase publis","explanation":"## Why This Is Asked\nAsks about crash-consistency in a realistic persistent queue used in trading/telemetry.\n\n## Key Concepts\n- Crash-consistency, NVRAM, per-slot sequence numbers, flush barriers, recovery.\n\n## Code Example\n```javascript\n// pseudo enqueue/dequeue\n```\n\n## Follow-up Questions\n- How would you test durability under power loss and memory reordering? \n- How would you extend to multi-consumer fairness without stalls?","diagram":null,"difficulty":"advanced","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T10:26:21.458Z","createdAt":"2026-01-12T10:26:21.458Z"},{"id":"q-826","question":"Design and implement a tiny spinlock in C11 for a shared memory region. Provide lock() and unlock() using stdatomic.h primitives, ensuring memory_order_acquire on successful lock and memory_order_release on unlock. Include a minimal two-thread test contending for the lock and explain your backoff/yield strategy and fairness limitations?","answer":"```c\n#include <stdatomic.h>\n#include <sched.h>\n\ntypedef struct { atomic_flag f; } spinlock_t;\n#define SPINLOCK_INIT { ATOMIC_FLAG_INIT }\n\nstatic inline void spin_lock(spinlock_t *s){\n  while (atomic_f","explanation":"## Why This Is Asked\nTests practical use of C11 atomics, memory ordering, and contention handling in low-level code. ## Key Concepts\n- C11 atomic primitives (atomic_flag)\n- memory_order_acquire/release semantics\n- busy-wait with backoff/yield to reduce bus traffic\n- fairness and starvation considerations ## Code Example\n```c\n// above code snippet\n```\n## Follow-up Questions\n- How would you extend this to a fair queueing spinlock?\n- What benchmarks would you run to profile contention impact?","diagram":"flowchart TD\n  Start(Start) --> LockRequest[Lock request]\n  LockRequest --> Acquired{Acquired?}\n  Acquired -->|Yes| Crit[Critical Section]\n  Crit --> Unlock[Unlock]\n  Unlock --> End[End]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Google","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:22:40.506Z","createdAt":"2026-01-12T11:22:40.506Z"},{"id":"q-834","question":"Design and implement a fixed-size object pool: a pre-allocated buffer partitioned into 1024 blocks of 64 bytes. Provide thread-safe allocate() and free() using a free-list stored in the blocks and a lightweight spinlock guarding the list. Include initialization and a small test snippet with 2 threads. Discuss fragmentation, cache locality, and how you'd validate concurrency?","answer":"Alloc: acquire spinlock; pop head from free-list; return that block. Free: push block back; release lock. Init: chain all 1024 blocks into the free-list. Test: two threads allocate/free in tight loop;","explanation":"## Why This Is Asked\nTests practical low-level memory management skills: fixed pools, alignment, and simple synchronization. It also probes understanding of fragmentation and cache locality in object pools.\n\n## Key Concepts\n- Fixed-size allocators\n- Free-list metadata in blocks\n- Lightweight spinlocks and minimal contention\n- Thread safety and cache-friendly layouts\n\n## Code Example\n```c\n// simple pool init\nvoid pool_init(pool_t *p){ ... }\nvoid *pool_alloc(pool_t *p){ ... }\nvoid pool_free(pool_t *p, void *obj){ ... }\n```\n\n## Follow-up Questions\n- How would you extend to multiple object sizes? \n- How would you measure allocator performance under contention?","diagram":"flowchart TD\n A[Pool Init] --> B[Blocks Linked List]\n B --> C[Spinlock Protects Head]\n C --> D[Allocate/Free Work]\n D --> E[Blocks Reused]","difficulty":"beginner","tags":["low-level"],"channel":"low-level","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:46:35.356Z","createdAt":"2026-01-12T12:46:35.356Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","Plaid","Robinhood","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":50,"beginner":15,"intermediate":11,"advanced":24,"newThisWeek":28}}