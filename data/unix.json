{"questions":[{"id":"q-1002","question":"In a Unix environment logs are stored in /var/log/app/*.log with lines formatted as timestamp|user|action|resource. Write a practical one-liner using standard UNIX tools to output the top 5 users by total actions in the last 24 hours. Explain how you would handle log rotation and malformed lines?","answer":"One practical approach is to filter the last 24h files, extract the user, and count actions. Example: find /var/log/app/*.log -type f -mtime -1 -print0 | xargs -0 cat | awk -F'|' 'NF>=4{cnt[$2]++} END","explanation":"## Why This Is Asked\nTests practical log-scan skills: building a robust one-liner that handles log rotation, malformed lines, and spaces in fields. It also gauges comfort with standard tools and edge-case thinking.\n\n## Key Concepts\n- Log rotation: using -mtime to limit scope to last day.\n- Field delimiting: using a stable delimiter (|) for reliable parsing.\n- Robust counting: associative arrays in awk for tallying per user.\n- Safe I/O: null-delimited input with -print0/xargs -0 to support spaces.\n\n## Code Example\n```javascript\nfind /var/log/app/*.log -type f -mtime -1 -print0 | xargs -0 cat | awk -F'|' 'NF>=4{cnt[$2]++} END{for(u in cnt) print cnt[u], u}' | sort -nr | head -5\n```\n\n## Follow-up Questions\n- How would you handle logs where the user field is sometimes missing or empty?\n- How would you validate results across multiple days with varying time zones?\n- How would you adapt this for extremely large log pools to minimize I/O impact?","diagram":"flowchart TD\n  Start --> ReadLogs[Read log files in /var/log/app]\n  ReadLogs --> Filter[Filter last 24 hours with -mtime]\n  Filter --> Extract[Extract user field (split on |)]\n  Extract --> Count[Count per user (awk)]\n  Count --> Sort[Sort counts descending]\n  Sort --> Top5[Output top 5 users]\n  Top5 --> End[Done]","difficulty":"beginner","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:47:17.203Z","createdAt":"2026-01-12T18:47:17.203Z"},{"id":"q-1032","question":"How would you capture stdout and stderr of a simple shell command into separate log files while still displaying live output in the terminal? Provide a concrete Bash command and brief justification?","answer":"Use Bash process substitution to split streams: command > >(tee -a stdout.log) 2> >(tee -a stderr.log >&2). This sends stdout to both terminal and stdout.log, and stderr to both terminal (via 2>&) and","explanation":"## Why This Is Asked\n\nAssess understanding of Unix IO redirection, common tooling (tee), and Bash-specific features (process substitution) that enable real-time logging without losing output.\n\n## Key Concepts\n\n- stdout/stderr redirection\n- process substitution\n- tee for file logging\n\n## Code Example\n\n```bash\ncommand > >(tee -a stdout.log) 2> >(tee -a stderr.log >&2)\n```\n\n## Follow-up Questions\n\n- How would you implement a portable alternative for POSIX sh?\n- What if the command writes to stdout after its own buffering ends; how could you ensure timely logs?","diagram":null,"difficulty":"beginner","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","LinkedIn","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T20:22:14.784Z","createdAt":"2026-01-12T20:22:14.785Z"},{"id":"q-1069","question":"In a Unix environment, logs live under /var/log/metrics/*.log and are hourly rotated to .log and .log.gz. Each line is like [YYYY-MM-DD HH:MM:SS] LEVEL: message. Propose a robust, portable approach (one-liner preferred) to output the number of ERROR events per hour for the last 6 hours, handling missing files and rotations without external dependencies?","answer":"I’d implement a robust, portable pipeline reading both compressed and plain logs, extracting the hour from each timestamp, filtering for ERROR, and aggregating counts for the last 6 hours. Use globbin","explanation":"## Why This Is Asked\nTests practical mastery of Unix tooling, log rotation handling, and resilient scripting under real-world constraints.\n\n## Key Concepts\n- Robust log ingestion across rotated files\n- Mixed gzip/uncompressed handling with zcat\n- Time bucketing and boundary handling\n- Idempotent, side-effect-free pipelines\n\n## Code Example\n```javascript\n// Bash sketch\nstart=$(date -u -d '-6 hours' '+%Y-%m-%d %H')\nzcat /var/log/metrics/metrics-*.log.gz /var/log/metrics/metrics-*.log 2>/dev/null \\\n| awk -v cutoff=\"$start\" '/ERROR/ { if ($0 ~ /\\[/) { hour=substr($1,1,10)\" \"substr($2,1,2); if (hour>=cutoff) c[hour]++ } } END{for (h in c) print h\":00\", c[h]}'\n```\n\n## Follow-up Questions\n- How would you test this under log rotation? \n- How would you adapt for multiple timezones?","diagram":"flowchart TD\n  A[Start] --> B[Collect log files (gz and plain)]\n  B --> C[Parse timestamps to hour bucket]\n  C --> D[Filter ERROR events]\n  D --> E[Aggregate last 6 hours]\n  E --> F[Output results]","difficulty":"advanced","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Meta","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T21:30:28.843Z","createdAt":"2026-01-12T21:30:28.843Z"},{"id":"q-1123","question":"In a Unix environment, multiple services write JSON logs under /var/log/diag/*.log and rotated hourly to *.log.gz. Each line is a JSON object like {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"svc\":\"name\",\"lvl\":\"ERROR\",\"msg\":\"...\"}; Propose a robust one-liner (no external dependencies beyond standard UNIX tools) to output the number of ERROR events per hour for the last 4 hours, aggregated across all services, and tolerant of missing files and rotated archives?","answer":"I’d implement a robust portable one-liner that streams both .log and .log.gz files, extracts ts and lvl from each JSON line, converts ts to epoch, filters for the last 4 hours, buckets per hour (YYYY-","explanation":"## Why This Is Asked\n\nTests ability to write compact, production-grade log queries that tolerate rotations, mixed compression, and JSON-like lines using only core Unix tools.\n\n## Key Concepts\n\n- Robust file discovery with find and null-termination\n- Decompression with zcat for .gz files\n- Inline JSON-like parsing with simple regex in awk\n- Time-window filtering via epoch comparison using date\n- Hour bucketing and aggregation with associative arrays\n\n## Code Example\n\n```javascript\n#!/bin/sh\ncutoff=$(date -u -d '4 hours ago' +%s)\nfind /var/log/diag -type f \\( -name '*.log' -o -name '*.log.gz' \\) -print0 | \\\n  xargs -0 -I{} sh -c ' [ -f \"$1\" ] && { if [ \"${1##*.}\" = \"gz\" ]; then zcat \"$1\"; else cat \"$1\"; fi; }' _ {} | \\\nawk -v cut=\"$cutoff\" ' /\"lvl\":\"ERROR\"/ { if (match($0, /\"ts\":\"([^\\\\\"]+)\"/, a)) { cmd=\"date -u -d \\\"\" a[1] \"\\\" +%s\"; cmd | getline t; close(cmd); if (t >= cut) { hour = substr(a[1],1,13) \"Z\"; count[hour]++ } } } END { for (h in count) print h, count[h] } '\n```\n\n## Follow-up Questions\n\n- How would you adjust for millisecond timestamps?\n- How would this scale across many servers and years of logs?","diagram":"flowchart TD\n  A[Start] --> B[Find logs (*.log, *.log.gz)]\n  B --> C[Decompress and read lines]\n  C --> D[Parse JSON ts and lvl]\n  D --> E[Filter last 4 hours]\n  E --> F[Bucket by hour]\n  F --> G[Count ERRORs]\n  G --> H[Output]","difficulty":"intermediate","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","OpenAI","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T23:30:41.563Z","createdAt":"2026-01-12T23:30:41.563Z"},{"id":"q-1139","question":"Scenario: JSON logs at /var/log/diag/*.log, rotated hourly to *.log.gz. Each line: {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"svc\":\"name\",\"lvl\":\"ERROR\",\"msg\":\"...\"}. Propose a robust one-liner (no external deps beyond standard UNIX tools) that outputs the per-hour 99th percentile of message length for the last 4 hours, across all services, deduplicating identical messages per hour, and tolerant of missing files and gz archives?","answer":"Use a two-pass approach: 1) gzip -cd /var/log/diag/*.log.gz 2>/dev/null | awk to emit hour bucket and msg length, deduplicating by hour+msg with an associative array; filter to last 4 hours by ts; 2) ","explanation":"## Why This Is Asked\nTests real-world log ingestion under rotation; requires careful handling of gz files, missing files, and cross-service aggregation. The candidate should justify a robust percentile computation and dedup logic.\n\n## Key Concepts\n- Standard UNIX toolchain for parsing JSON-like lines without jq\n- Handling gzip-rotated logs and missing files\n- Per-hour bucketing and deduplication by message\n- Computation of a percentile from a 1-D length distribution\n\n## Code Example\n```bash\n# skeleton command outline (not complete here)\n```\n\n## Follow-up Questions\n- How would you test with synthetic logs at scale?\n- How would you adapt for different rotations or non-UTC timestamps?","diagram":"flowchart TD\n  A[Read logs (gz and plain)] --> B[Parse ts and msg length]\n  B --> C[Bucket by hour]\n  C --> D[Deduplicate by hour+msg]\n  D --> E[Compute 99th percentile per hour]\n  E --> F[Output results]","difficulty":"advanced","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:26:59.322Z","createdAt":"2026-01-13T01:26:59.322Z"},{"id":"q-1224","question":"Scenario: In a Unix cluster, logs are emitted as JSON lines under /var/log/cluster/*/*.log and rotated hourly to *.log.gz. Each line contains {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"tenant\":\"tenant-id\",\"svc\":\"service\",\"lvl\":\"LEVEL\",\"msg\":\"...\"}; Propose a robust one-liner (no external deps beyond standard UNIX tools) to identify the top 3 tenants by error rate (ERROR / total events) for the last 6 hours, aggregated across all services, tolerant of missing files and gz archives?","answer":"Stream all logs (including .log.gz), extract ts and tenant via awk regex, filter lines within the last 6 hours using START/END timestamps from date -u, accumulate per-tenant total and ERROR counts, th","explanation":"## Why This Is Asked\n- Assesses ability to build robust, single-line data pipelines over multi-file logs, including compressed files, without external dependencies. \n- Tests time-window handling, cross-service aggregation, and per-tenant bucketing under rotation. \n\n## Key Concepts\n- Stream processing with standard UNIX tools (find, xargs, zcat, awk). \n- JSON field extraction via regex in awk; resilient to line variations. \n- Time-window filtering using START/END derived from date; cross-file aggregation. \n- Sorting by computed metric (error rate) without extra tools.\n\n## Code Example\n```javascript\nSTART=$(date -u -d \"-6 hours\" +\"%Y-%m-%dT%H\")\nEND=$(date -u +\"%Y-%m-%dT%H\")\nfind /var/log/cluster -type f \\( -name '*.log' -o -name '*.log.gz' \\) -print0 | \\\n  xargs -0 -I{} sh -lc 'case \"{}\" in *.gz) zcat \"{}\" ;; *) cat \"{}\" ;; esac' | \\\n  awk -v s=\"$START\" -v e=\"$END\" '{\n    if (match($0, /\"ts\":\"([^\"]+)\"/, a)) ts=a[1]; hour=substr(ts,1,13); gsub(/T/,\" \",hour); hour_key=hour;\n    if (match($0, /\"tenant\":\"([^\"]+)\"/, b)) tenant=b[1];\n    if (match($0, /\"lvl\":\"([^\"]+)\"/, c)) lvl=c[1];\n    if (hour_key && tenant && hour_key>=s && hour_key<=e) {\n      total[tenant] += 1; if (lvl==\"ERROR\") errors[tenant] += 1;\n    }\n  }\n  END { for (t in total) { rate = total[t] ? errors[t] / total[t] : 0; printf \"%s\\t%.6f\\n\", t, rate } }\n``` \n\n## Follow-up Questions\n- How would you adapt this to include per-hour breakdowns in addition to the overall top 3? \n- How would you handle non-UTC timestamps or malformed JSON lines? ","diagram":null,"difficulty":"advanced","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Coinbase","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T05:34:59.109Z","createdAt":"2026-01-13T05:34:59.109Z"},{"id":"q-1241","question":"Scenario: In a multi-user Unix workspace, /home contains subdirectories per user with various files. Some are large, some are temporary. Provide a robust one-liner (no external dependencies) that lists the five largest regular files under /home (recursively), excluding hidden files and symlinks, printing each as 'size<TAB>path' with sizes in human-readable form. Explain how you ensure safety against spaces and newlines in filenames?","answer":"One robust option is a single pipeline that uses find with a safe delimiter, sorts by size, and formats to human units. For example: find /home -type f -not -path '*/.*' -print0 | xargs -0 stat -c '%s","explanation":"Why this is asked: tests understanding of safe file discovery, handling of spaces, and large-file detection. Key points: exclude hidden paths, only regular files, robust delimiting with null separators, and portable human-readable formatting via an awk function that scales from B up to GB. Edge considerations include spaces in names and potential binary data in paths.","diagram":"flowchart TD\n  A[Find largest files] --> B[Filter /home recursively]\n  B --> C[Exclude hidden/symlinks]\n  C --> D[Emit size+path]\n  D --> E[Sort desc & take top 5]\n  E --> F[Format human units]","difficulty":"beginner","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T06:36:11.300Z","createdAt":"2026-01-13T06:36:11.300Z"},{"id":"q-1492","question":"Scenario: multiple services log JSON lines to /var/log/app/*.log, rotated hourly to *.log.gz. Each line looks like {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"svc\":\"name\",\"lat_ms\":123}. Propose a robust one-liner (no external deps beyond standard UNIX tools) to compute the per-service average lat_ms in the last 2 hours, across all logs, tolerant of missing and gzipped files, ignoring malformed lines. Output: 'service avg_ms'?","answer":"cutoff=$(date -u -d '-2 hours' '+%Y-%m-%dT%H:%M:%SZ'); find /var/log/app -type f \\( -name '*.log' -o -name '*.log.gz' \\) -print0 | while IFS= read -r -d '' f; do if [[ \"$f\" == *.gz ]]; then zcat \"$f\";","explanation":"Why This Is Asked: tests robust log ingestion across gzipped rotations. Key Concepts: shell pipelines, handling gzip, JSON-like parsing with regex in awk, per-service aggregation, time-window filtering via ISO timestamps. Code Example: the command reads both .log and .log.gz, extracts ts/svc/lat_ms, filters to last 2 hours, accumulates sums and counts per service, then prints averages. Follow-ups explore error handling and performance tweaks.","diagram":null,"difficulty":"intermediate","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["PayPal","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T19:28:41.147Z","createdAt":"2026-01-13T19:28:41.149Z"},{"id":"q-481","question":"You're debugging a production system where processes are hanging. Using only Unix tools, how would you identify which processes are blocked on I/O, what they're waiting for, and safely terminate them without causing data corruption?","answer":"Use `lsof -p <PID>` to see open files and `strace -p <PID>` to identify blocked system calls. Check `/proc/<PID>/fd` for file descriptors. For safe termination, send SIGTERM first: `kill -15 <PID>`, wait for graceful shutdown, then use SIGKILL if necessary.","explanation":"## Process Identification\n- `ps aux | grep D` shows processes in uninterruptible sleep\n- `top` with 'H' shows thread-level status\n- `iostat -x 1` identifies I/O bottlenecks\n\n## Root Cause Analysis\n- `strace -p <PID>` reveals blocked system calls\n- `lsof -p <PID>` shows open files and network connections\n- `/proc/<PID>/status` provides process state details\n\n## Safe Termination\n- SIGTERM allows graceful shutdown\n- Check for child processes before killing\n- Verify no critical writes in progress","diagram":"flowchart TD\n  A[Detect hanging process] --> B[ps aux | grep D]\n  B --> C[strace -p PID]\n  C --> D[lsof -p PID]\n  D --> E{Safe to terminate?}\n  E -->|Yes| F[kill -15 PID]\n  E -->|No| G[Wait for I/O completion]\n  F --> H[Monitor with ps]\n  G --> F","difficulty":"advanced","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-10T03:29:09.162Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-510","question":"You're debugging a production issue where a process is stuck in uninterruptible sleep (D state). How would you identify and handle this situation?","answer":"Use `ps aux | awk '$8 ~ /D/ {print $2, $11}'` to find D-state processes. Check `dmesg | grep -i oom` for OOM killer activity. For I/O issues, use `lsof -p <PID>` to identify blocked files. If it's NFS, verify mount status and network connectivity.","explanation":"## Identifying D-State Processes\n\n- Use `ps` with state filtering to find uninterruptible processes\n- Check system logs for hardware or filesystem errors\n- Examine I/O queues and block device status\n\n## Common Causes\n\n- NFS mount issues or network storage problems\n- Faulty hardware devices (disk, controller)\n- Kernel bugs or driver issues\n- Memory pressure causing I/O blocking\n\n## Resolution Strategies\n\n- Wait for hardware timeout (usually 30-120 seconds)\n- Check and fix underlying storage issues\n- Reboot as last resort if process won't recover\n- Monitor `/proc/<PID>/stack` for kernel call traces","diagram":"flowchart TD\n  A[Process enters D state] --> B{Identify cause}\n  B --> C[Hardware issue]\n  B --> D[Network storage]\n  B --> E[Kernel/driver]\n  C --> F[Check dmesg/logs]\n  D --> G[Verify mount status]\n  E --> H[Examine stack trace]\n  F --> I[Wait or fix hardware]\n  G --> J[Resolve network/storage]\n  H --> K[Update/reboot if needed]","difficulty":"intermediate","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-09T03:44:39.931Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-538","question":"You notice a process is consuming excessive CPU on a production server. How would you diagnose and troubleshoot this issue using Unix commands?","answer":"I would start by using `top` or `htop` to identify the process ID (PID) consuming excessive CPU, then run `ps aux | grep PID` to get detailed process information and command line arguments. For deeper analysis, I'd use `strace -p PID` to monitor system calls in real-time, `lsof -p PID` to examine open files and network connections, and `perf top` for CPU performance profiling.","explanation":"## Diagnosis Steps\n- Use `top` or `htop` to identify the high CPU process and its PID\n- Run `ps aux` to view process details and command line arguments\n- Monitor system calls with `strace -p PID` to understand process behavior\n\n## Investigation Tools\n- `lsof -p PID` reveals open files and network connections\n- `perf top` provides CPU performance profiling and bottleneck identification\n- `/proc/PID/status` contains comprehensive memory and CPU statistics\n\n## Resolution\n- Send SIGTERM (`kill -15`) for graceful process shutdown\n- Use SIGKILL (`kill -9`) only when the process is unresponsive\n- Analyze logs in `/var/log/` to identify and address the root cause","diagram":"flowchart TD\n  A[High CPU Alert] --> B[top/htop - Identify PID]\n  B --> C[ps aux - Process Details]\n  C --> D[strace - System Calls]\n  D --> E[lsof - Open Files]\n  E --> F[perf top - Performance Profile]\n  F --> G{Process Responsive?}\n  G -->|Yes| H[kill -15 PID]\n  G -->|No| I[kill -9 PID]\n  H --> J[Monitor Resolution]\n  I --> J","difficulty":"intermediate","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Goldman Sachs","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["troubleshooting","cpu profiling","strace","lsof","performance","diagnosis"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:43:07.374Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-564","question":"You're debugging a production system where processes are hanging. Using only Unix tools, how would you identify which processes are stuck in uninterruptible sleep (D state) and what could be causing this?","answer":"Use `ps aux | awk '$8 ~ /^D/ {print $2, $11}'` to identify processes in uninterruptible sleep state. Examine `/proc/<pid>/stack` for kernel stack traces to understand what system calls are blocking. Common causes include NFS server issues, faulty storage drivers, hardware I/O problems, or disk bottlenecks. Use `iostat -x 1` to monitor I/O activity and `dmesg | grep -i error` to check for hardware or driver errors.","explanation":"## Identifying D-State Processes\n- Use `ps aux | awk '$8 ~ /^D/ {print $2, $11}'` to filter processes in uninterruptible sleep\n- Check `/proc/<pid>/status` for detailed process state information\n- Monitor system-wide D-state processes with `top` or `htop` filtered by state\n\n## Root Cause Analysis\n- Examine `/proc/<pid>/stack` to identify the specific kernel functions blocking the process\n- Use `dmesg | grep -i error` to detect hardware or driver-related issues\n- Monitor I/O statistics with `iostat -x 1` to identify storage bottlenecks\n- Check `lsblk` and `smartctl` for disk health and controller issues\n\n## Common Causes\n- NFS server unavailability or network connectivity issues\n- Faulty disk controllers, RAID arrays, or storage drivers\n- Hardware failures in storage subsystem (bad sectors, failing drives)\n- Memory pressure causing excessive swap activity\n- Kernel bugs or incompatible device drivers\n- Storage system saturation or filesystem corruption","diagram":"flowchart TD\n  A[ps aux | awk] --> B[Identify D-state PIDs]\n  B --> C[/proc/<pid>/stack]\n  C --> D[Analyze kernel stack]\n  D --> E[lsof -p <pid>]\n  E --> F[Check open files]\n  F --> G[strace -p <pid>]\n  G --> H[Trace syscalls]","difficulty":"advanced","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","OpenAI","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":["uninterruptible sleep","d state","ps command","proc filesystem","stack traces","nfs","i/o bottlenecks","kernel debugging"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:57:22.806Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-894","question":"On a Linux host, /var/log/myapp.log is written by multiple processes. Implement a robust log rotation that triggers when the file reaches 100MB, keeps 7 rotated files, compresses older logs, and ensures no log loss while writers continue. Describe the approach, commands, and failure modes for concurrent writers?","answer":"Configure logrotate for /var/log/myapp.log with size 100M, rotate 7, compress and delaycompress, using sharedscripts. Use a postrotate block to signal the processes to reopen the log (e.g., systemctl ","explanation":"## Why This Is Asked\\n\\nThis question probes practical log management under concurrency, emphasizing safe rotation with multi-process writers and minimizing data loss. Expect discussion of reopen signals vs copytruncate, service integration, and failure modes.\\n\\n## Key Concepts\\n- logrotate configuration: size-based rotation, retention, compression\\n- handling concurrent writers: reopen vs copytruncate, signals (SIGHUP)\\n- service integration: systemd or pid signaling; permissions and timing\\n\\n## Code Example\\n```javascript\\n/var/log/myapp.log {\\n  size 100M\\n  rotate 7\\n  compress\\n  delaycompress\\n  missingok\\n  notifempty\\n  create 0644 root root\\n  sharedscripts\\n  postrotate\\n    systemctl is-active myapp >/dev/null && systemctl kill -s HUP myapp || kill -HUP `cat /var/run/myapp.pid` 2>/dev/null || true\\n  endscript\\n}\\n```\\n\\n## Follow-up Questions\\n- What if the app cannot reopen log files on HUP?\\n- How would you test concurrent writers during rotation?","diagram":null,"difficulty":"intermediate","tags":["unix"],"channel":"unix","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Discord","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:35:24.296Z","createdAt":"2026-01-12T14:35:24.296Z"},{"id":"q-264","question":"How do Unix pipes enable inter-process communication and what are their performance implications?","answer":"Pipes provide unidirectional byte streams between processes, utilizing kernel buffers for efficient inter-process communication with blocking I/O semantics.","explanation":"## Why Asked\nTests understanding of IPC mechanisms and system design principles for scalable applications.\n\n## Key Concepts\nUnidirectional communication, kernel buffering, blocking I/O, file descriptor abstraction, pipe capacity limits.\n\n## Code Example\n```bash\n# Create pipe and connect processes\nls -l | grep \".txt\" | wc -l\n# Kernel manages 64KB buffer between processes\n```\n\n## Follow-up Questions\nWhat's the difference between named and anonymous pipes? How do pipes handle backpressure? What are alternatives to pipes?","diagram":"flowchart TD\n  A[Process A] -->|writes| B[Pipe Buffer]\n  B -->|reads| C[Process B]\n  D[Kernel] -->|manages| B","difficulty":"beginner","tags":["posix","signals","pipes","sockets"],"channel":"unix","subChannel":"system-programming","sourceUrl":"https://man7.org/linux/man-pages/pipe.2","videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-03T06:38:32.248Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["general","system-programming"],"companies":["Adobe","Amazon","Apple","Citadel","Coinbase","Databricks","Discord","Goldman Sachs","Google","LinkedIn","Lyft","Meta","Microsoft","OpenAI","PayPal","Plaid","Robinhood","Salesforce","Snap","Snowflake","Square","Tesla","Uber"],"stats":{"total":14,"beginner":4,"intermediate":5,"advanced":5,"newThisWeek":9}}