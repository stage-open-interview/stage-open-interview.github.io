{"questions":[{"id":"q-836","question":"You are analyzing a web app's login events, captured as an array of objects: { userId: string, ts: string (ISO 8601) }. Write a JavaScript function that returns the top 3 users by login count in the past 24 hours. Tie-break with alphabetical userId. Provide a concise implementation and explain its time complexity?","answer":"Use a rolling 24h window: parse ts to ms, keep per-user counts in a Map, filter to now - t <= 24h, sort by count desc then userId asc, return top 3. Time complexity O(n log m) where m is distinct user","explanation":"## Why This Is Asked\nTests practical data processing in JavaScript: time-window filtering, per-user aggregation, and deterministic tie-breaking.\n\n## Key Concepts\n- Time-window filtering\n- Hash map for counts\n- Stable sorting with tie-breakers\n- Input validation and edge cases\n\n## Code Example\n\n```javascript\nfunction topUsers(events) {\n  const now = Date.now();\n  const window = 24 * 60 * 60 * 1000;\n  const counts = new Map();\n  for (const e of events) {\n    const t = Date.parse(e.ts);\n    if (Number.isNaN(t)) continue;\n    if (now - t <= window) {\n      counts.set(e.userId, (counts.get(e.userId) || 0) + 1);\n    }\n  }\n  const arr = Array.from(counts.entries());\n  arr.sort((a, b) => b[1] - a[1] || a[0].localeCompare(b[0]));\n  return arr.slice(0, 3).map(([id]) => id);\n}\n```\n\n## Follow-up Questions\n- How would you adapt this for streaming data?\n- How would you test with synthetic data to cover edge cases?","diagram":"flowchart TD\n  A[Events] --> B{Filter 24h}\n  B --> C[Count per User]\n  C --> D[Sort by Count, then ID]\n  D --> E[Top 3 Results]","difficulty":"beginner","tags":["kcsa"],"channel":"kcsa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:21:30.077Z","createdAt":"2026-01-12T13:21:30.077Z"},{"id":"q-869","question":"In a high-traffic search suggestions feature, implement a Node.js module that debounces input by 300ms and caches per-query results in memory. Show cache invalidation and handle concurrent requests for the same key without duplicating work. Provide a compact, testable example with usage?","answer":"Implement an in-memory Map cache keyed by query with fields ts, data, and inFlight. Debounce input by 300ms; if cache exists and not expired (TTL 60s), return data; if inFlight exists for the key, awa","explanation":"This tests practical skills in debouncing, TTL caching, and in-flight deduplication under concurrent access.","diagram":null,"difficulty":"beginner","tags":["kcsa"],"channel":"kcsa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Lyft","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:50:03.410Z","createdAt":"2026-01-12T13:50:03.410Z"},{"id":"q-912","question":"**KCSA Beginner Question: Inventory Pagination** Scenario: In a warehouse app, design a minimal endpoint GET /items?limit=&offset= that returns items ordered by id, supports pagination, and scales with 10k+ rows. Explain data model, indexing, and error handling. How would you implement a function to validate and apply LIMIT/OFFSET in code, ensuring correctness?","answer":"Iâ€™d implement GET /items?limit=&offset= with items ordered by id. Use an index on id and query: SELECT id, name, qty FROM items ORDER BY id ASC LIMIT $limit OFFSET $offset; return {total, items}. Vali","explanation":"## Why This Is Asked\nThe goal is to assess practical pagination design and data modeling skills on a tiny API layer, including correctness and testability.\n\n## Key Concepts\n- Pagination parameters validation\n- Indexed queries and ORDER BY performance\n- Edge-case handling and test coverage\n\n## Code Example\n\n```javascript\nfunction paginate(items, limit, offset) {\n  if (limit <= 0 || offset < 0) throw new Error(\"Invalid pagination params\");\n  const total = items.length;\n  const paged = items.slice(offset, offset + limit);\n  return { total, items: paged };\n}\n```\n\n## Follow-up Questions\n- How would you test pagination with 10k+ records and caching?\n- How would you adapt logic for distributed databases or replicas?","diagram":null,"difficulty":"beginner","tags":["kcsa"],"channel":"kcsa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:24:39.634Z","createdAt":"2026-01-12T15:24:39.634Z"}],"subChannels":["general"],"companies":["Amazon","Apple","Lyft","Meta","NVIDIA","Zoom"],"stats":{"total":3,"beginner":3,"intermediate":0,"advanced":0,"newThisWeek":3}}