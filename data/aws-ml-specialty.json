{"questions":[{"id":"q-1228","question":"Design a drift-aware continuous training and multi-region deployment workflow for a fraud-detection model, using SageMaker Model Monitor, Pipelines, and Model Registry. Explain how you detect data and feature drift (PSI/KS against baselines), retrain triggers, versioning, canary validation, rollback, and how cross-region consistency is maintained?","answer":"Implement drift-aware continuous training and multi-region deployment with SageMaker Model Monitor, Pipelines, and Model Registry. Detect data and feature drift using PSI/KS against baselines; retrain","explanation":"## Why This Is Asked\nAssesses practical MLOps skills: drift detection, versioned deployment, cross-region consistency, and safe canary releases in a real-world, regulated context.\n\n## Key Concepts\n- Drift detection with PSI/KS against baselines\n- SageMaker Model Monitor and Pipelines integration\n- Model Registry versioning and promoted stages\n- Canary validation and rollback strategies\n\n## Code Example\n```python\n# Pseudo: define a drift check step in SageMaker Pipelines\npipeline_step = DriftCheckStep(..., drift_check_config={ 'DataDrift': {'Threshold': 0.2}, 'FeatureDrift': {'Threshold': 0.1} })\n```\n\n## Follow-up Questions\n- How would you determine Canary rollout percentages across regions?\n- What metrics would you surface in CloudWatch and SageMaker Model Monitor dashboards to detect drift early?","diagram":"flowchart TD\n  A[Data Ingest] --> B[Drift Check with PSI/KS]\n  B --> C{Drift > Threshold}\n  C -- Yes --> D[Trigger Retrain]\n  D --> E[Register New Version]\n  E --> F[Canary Rollout (Region A)]\n  F --> G[Monitor Metrics]\n  G -- Stable --> H[Full Rollout]\n  G -- Drift --> I[Rollback to Previous Version]","difficulty":"advanced","tags":["aws-ml-specialty"],"channel":"aws-ml-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Bloomberg","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:38:55.228Z","createdAt":"2026-01-13T05:38:55.228Z"},{"id":"q-1297","question":"You're deploying a multilingual sentiment-analysis model for a global customer-support chatbot. To minimize downtime when updating language adapters, design a SageMaker-based deployment with per-language variants, Model Registry, and canary rollouts that preserve latency SLAs and isolate traffic. Describe autoscaling, traffic routing, validation, and rollback criteria with concrete values?","answer":"Use per-language EndpointVariants and register adapters in Model Registry. Deploy a canary that shifts 20% of traffic to the new language adapter while 80% stays on the baseline. Scale per-region with","explanation":"## Why This Is Asked\n\nTests practical use of SageMaker features to handle multilingual adapters with zero-downtime updates and strict latency SLAs.\n\n## Key Concepts\n\n- SageMaker Model Registry and Endpoint Variants\n- Canary deployments and per-language traffic routing\n- Drift and latency validation; per-language observability\n- Rollback and promotion criteria; cross-region considerations\n\n## Code Example\n\n```javascript\n// Example: pseudo-configure per-language variants and canary rollout\nconst variants = [\n  { Language: 'en', VariantName: 'prod-en', ModelName: 'sentiment-en', TrafficSplit: 0.8 },\n  { Language: 'en', VariantName: 'canary-en', ModelName: 'sentiment-en-v2', TrafficSplit: 0.2 }\n  // ...additional languages\n];\n// Register models, create endpoint config, and set alarms for drift/latency\n```\n\n## Follow-up Questions\n\n- How would you monitor and react to per-language data drift in real time?\n- How would you handle adding a brand-new language with zero downtime across regions?","diagram":"flowchart TD\n  A[Language Adapter Update] --> B[Route Canary Traffic]\n  B --> C[Monitor Latency & Drift]\n  C --> D{OK?}\n  D -->|Yes| E[Promote to Baseline]\n  D -->|No| F[Rollback & Retry]\n  E --> G[Continue Serving]\n  F --> G","difficulty":"intermediate","tags":["aws-ml-specialty"],"channel":"aws-ml-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:43:55.886Z","createdAt":"2026-01-13T08:43:55.886Z"},{"id":"q-876","question":"You're deploying a SageMaker real-time endpoint for a model expected to see bursty, unpredictable traffic. Propose a concrete autoscaling setup using AWS Application Auto Scaling that keeps latency under a target while never scaling to zero. Specify min and max instances, the metric and target value (latency or invocations), the policy type, and cooldowns; discuss validation steps?","answer":"Configure a target-tracking policy on the endpoint with min 1, max 20 instances. Use SageMakerEndpointLatency (p95) as the predefined metric with target value 0.25s; set ScaleOutCooldown 300s and Scal","explanation":"## Why This Is Asked\n\nAssesses practical autoscaling setup for real-time endpoints, focusing on latency control, non-zero minimum, and stable scaling behavior.\n\n## Key Concepts\n\n- SageMaker real-time endpoints\n- AWS Application Auto Scaling\n- Target tracking vs step scaling\n- Latency vs concurrency metrics\n- Cooldown and stability\n\n## Code Example\n\n```javascript\n{\n  \"PolicyName\": \"EndpointLatencyTargetTracking\",\n  \"PolicyType\": \"TargetTrackingScaling\",\n  \"TargetTrackingScalingPolicyConfiguration\": {\n    \"TargetValue\": 0.25,\n    \"PredefinedMetricSpecification\": {\n      \"PredefinedMetricType\": \"SageMakerEndpointLatency\"\n    },\n    \"ScaleOutCooldown\": 300,\n    \"ScaleInCooldown\": 600\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you validate the setup under burst traffic?\n- How would you prevent over-scaling in steady-state?","diagram":null,"difficulty":"beginner","tags":["aws-ml-specialty"],"channel":"aws-ml-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:56:45.598Z","createdAt":"2026-01-12T13:56:45.598Z"},{"id":"q-896","question":"You run a SageMaker real-time endpoint serving a risk-scoring model for payments. After a drift alert, outline a canary deployment plan using endpoint variants and the Model Registry to shift 20% of traffic to a new version while preserving latency and safety. Describe how you automate metric validation (latency, error rate, and drift), rollback triggers, and guardrails, and how you promote a stable canary to baseline?","answer":"Design a canary deployment with two endpoint variants (Canary 0.2, Baseline 0.8) via a new EndpointConfig and Model Registry version. Automate with Step Functions to monitor p95 latency <180 ms, error","explanation":"## Why This Is Asked\nAssesses practical real-time deployment skills, canary traffic shifts, and automated rollback using SageMaker features.\n\n## Key Concepts\n- Endpoint variants and traffic shifting\n- Model Registry versioning\n- Automated validation windows and rollback triggers\n- Drift detection and monitoring integration\n\n## Code Example\n```python\n# Example using boto3\nimport boto3\nsm = boto3.client('sagemaker')\nsm.update_endpoint(\n  EndpointName='risk-endpoint',\n  DesiredWeightsAndVariants=[\n    {'VariantName': 'Canary', 'DesiredWeight': 0.2},\n    {'VariantName': 'Baseline', 'DesiredWeight': 0.8}\n  ]\n)\n```\n\n## Follow-up Questions\n- How would you scale back if latency spikes occur?  \n- What monitoring alerts would you configure and why?","diagram":"flowchart TD\n  A[New Model Version in Model Registry] --> B[Create EndpointConfig with Canary + Baseline]\n  B --> C[Update Endpoint Weights (Canary 0.2, Baseline 0.8)]\n  C --> D[CloudWatch + SageMaker Drift Monitoring]\n  D --> E{Stable for 15 min?}\n  E -->|Yes| F[Promote Canary to Baseline]\n  E -->|No| G[Rollback to Baseline]\n  G --> H[Notify Stakeholders]","difficulty":"intermediate","tags":["aws-ml-specialty"],"channel":"aws-ml-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","PayPal","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:36:26.853Z","createdAt":"2026-01-12T14:36:26.853Z"},{"id":"q-969","question":"In a production AWS ML pipeline, you must serve multiple fraud-detection models across two regions using a SageMaker Multi-Model Endpoint (MME). Propose a concrete deployment and autoscaling strategy that keeps p95 latency under 200 ms during peak, prevents cold starts, and optimizes memory by loading only active models. Describe per-model versioning with SageMaker Model Registry, traffic routing, canary validation, rollback triggers, cost implications, and cross-region consistency?","answer":"Proposed: use a SageMaker Multi-Model Endpoint (MME) with memory budgets per model and on-demand loading to fit bursts. Scale the endpoint via Application Auto Scaling on latency (p95 target 200 ms), ","explanation":"## Why This Is Asked\n\nThis question tests practical, scale-aware deployment of MME with versioning, cross-region consistency, and robust rollback.\n\n## Key Concepts\n\n- SageMaker Multi-Model Endpoint\n- Application Auto Scaling with latency targets\n- SageMaker Model Registry for versioning\n- Canary deployment and traffic routing\n- Drift monitoring and rollback\n\n## Code Example\n\n```javascript\n# Python-like pseudocode for boto3 usage\nimport boto3\nautoscaler = boto3.client('application-autoscaling')\nautoscaler.register_scalable_target(\n  ServiceNamespace='sagemaker',\n  ResourceId='endpoint/MMEEndpoint',\n  ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n  MinCapacity=2,\n  MaxCapacity=8\n)\n```\n\n## Follow-up Questions\n\n- How would you budget memory per model to avoid OOM across models in MME?\n- How would you ensure cross-region parity during canary rollouts?","diagram":null,"difficulty":"advanced","tags":["aws-ml-specialty"],"channel":"aws-ml-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:33:28.367Z","createdAt":"2026-01-12T17:33:28.367Z"}],"subChannels":["general"],"companies":["Amazon","Bloomberg","Google","Lyft","Netflix","PayPal","Robinhood","Square","Tesla"],"stats":{"total":5,"beginner":1,"intermediate":2,"advanced":2,"newThisWeek":5}}