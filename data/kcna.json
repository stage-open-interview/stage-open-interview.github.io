{"questions":[{"id":"kcna-container-orchestration-1768193476058-0","question":"In a three-node Kubernetes cluster, you want a deployment to evenly distribute its pods across nodes and adapt as nodes are added or removed. Which scheduling feature should you enable?","answer":"[{\"id\":\"a\",\"text\":\"nodeSelector\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"taints and tolerations\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"podAffinity\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"TopologySpreadConstraints\",\"isCorrect\":true}]","explanation":"## Correct Answer\n**TopologySpreadConstraints** evenly distributes Pods across topology domains such as nodes, helping the scheduler minimize skew. In this scenario, enabling topology spread ensures pods are not concentrated on a subset of nodes as nodes change.\n\n## Why Other Options Are Wrong\n- **nodeSelector** pins Pods to specific nodes and does not guarantee even distribution\n- **taints and tolerations** influence scheduling but do not guarantee even spread\n- **podAffinity** can encourage co-location of pods, which may worsen skew rather than improve it\n\n## Key Concepts\n- **TopologySpreadConstraints**\n- topologyKey (e.g., kubernetes.io/hostname)\n- workload distribution across nodes\n\n## Real-World Application\nApply topologySpreadConstraints to the PodSpec in your Deployment:\n\n```yaml\nspec:\n  template:\n    spec:\n      topologySpreadConstraints:\n      - maxSkew: 1\n        topologyKey: kubernetes.io/hostname\n        whenUnsatisfiable: DoNotSchedule\n```\nThis configuration ensures pods spread evenly across nodes and adapts when nodes are added or removed.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","kubectl","TopologySpreadConstraints","EKS","AWS","Terraform","Container Orchestration","certification-mcq","domain-weight-22"],"channel":"kcna","subChannel":"container-orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:16.059Z","createdAt":"2026-01-12 04:51:16"},{"id":"kcna-container-orchestration-1768193476058-1","question":"In an AWS-hosted Kubernetes cluster (e.g., EKS), which Service type automatically provisions a cloud load balancer to expose the service to the internet with a stable external endpoint?","answer":"[{\"id\":\"a\",\"text\":\"ClusterIP\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"NodePort\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"LoadBalancer\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"ExternalName\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**LoadBalancer** service automatically provisions an AWS Elastic Load Balancer (ELB) for the cluster and provides a stable external endpoint. \n\n## Why Other Options Are Wrong\n- **ClusterIP** only exposes the service within the cluster\n- **NodePort** opens a port on each node but does not automatically create a cloud LB with a stable external address\n- **ExternalName** maps the service to an external DNS name; it does not create an internal cluster service with a load balancer\n\n## Key Concepts\n- **Service types**: ClusterIP, NodePort, LoadBalancer\n- Cloud provider integration on **AWS/EKS** to provision external resources\n\n## Real-World Application\nIn production on AWS/EKS, use a Service of type **LoadBalancer** to obtain a public endpoint that remains stable for the life of the load balancer. For advanced routing patterns, you can pair this with an Ingress controller (e.g., ALB Ingress Controller).\n","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","kubectl","LoadBalancer","EKS","AWS","Terraform","Container Orchestration","certification-mcq","domain-weight-22"],"channel":"kcna","subChannel":"container-orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:16.470Z","createdAt":"2026-01-12 04:51:16"},{"id":"kcna-container-orchestration-1768193476058-2","question":"You rolled out a Deployment and want to revert to the previous revision if the new revision has issues. Which command should you run?","answer":"[{\"id\":\"a\",\"text\":\"kubectl rollout undo deployment/myapp\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"kubectl rollout restart deployment/myapp\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"kubectl apply -f deployment.yaml\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"kubectl delete deployment myapp\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**kubectl rollout undo deployment/myapp** reverts to the previous revision of the Deployment by restoring the prior ReplicaSet. \n\n## Why Other Options Are Wrong\n- **kubectl rollout restart deployment/myapp** triggers a rolling restart of the current revision rather than a rollback\n- **kubectl apply -f deployment.yaml** applies changes but does not automatically revert to a previous revision\n- **kubectl delete deployment myapp** removes the deployment entirely, not a rollback\n\n## Key Concepts\n- **kubectl rollout undo**\n- Deployment revision history and ReplicaSets\n- Rollout status monitoring\n\n## Real-World Application\nWhen a new rollout causes issues, run the undo command to quickly revert, then monitor with `kubectl rollout status deployment/myapp` and validate application health before deciding on subsequent steps.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","kubectl","rollout undo","EKS","AWS","Terraform","Container Orchestration","certification-mcq","domain-weight-22"],"channel":"kcna","subChannel":"container-orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:16.882Z","createdAt":"2026-01-12 04:51:16"},{"id":"kcna-k8s-fundamentals-1768151951289-0","question":"A Deployment creates Pods that start Running but show 0/1 READY, and the corresponding Service has 0 endpoints. Which change is most likely to fix the issue?","answer":"[{\"id\":\"a\",\"text\":\"Correct the readinessProbe to ensure it reports readiness (e.g., correct path/port) so the Pod becomes Ready.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase the number of replicas to 2.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Switch the Service type to NodePort to bypass readiness.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Remove the livenessProbe.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe Pod never reports Ready, so the endpoint set for the Service remains empty. Fixing the readinessProbe so the container signals readiness (correct path/port) makes the Pod Ready and populates endpoints.\n\n## Why Other Options Are Wrong\n- Increase replicas doesn't solve readiness of individual pods; endpoints remain 0 if pods aren't ready.\n- Switching to NodePort does not bypass readiness checks; traffic will still not be routed until the Pod reports Ready.\n- Removing the livenessProbe does not affect initial readiness state.\n\n## Key Concepts\n- Readiness probes control service endpoints exposure\n- Service endpoints reflect pods that report Ready\n- Kubernetes networking routes traffic to ready pods only\n\n## Real-World Application\n- When deploying new versions, ensure readiness probes accurately reflect application readiness to avoid routing errors and user-visible failures.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Networking","PodReadiness","Probes","certification-mcq","domain-weight-46"],"channel":"kcna","subChannel":"k8s-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:19:11.290Z","createdAt":"2026-01-11 17:19:11"},{"id":"kcna-k8s-fundamentals-1768151951289-1","question":"A Pod in namespace-a needs to access a ConfigMap in namespace-b; RBAC denies cross-namespace access by default. Which RBAC setup correctly grants this access across namespaces?","answer":"[{\"id\":\"a\",\"text\":\"Create a Role in namespace-a granting get on ConfigMaps in namespace-a and bind it in namespace-a.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a ClusterRole that permits get on configmaps and a ClusterRoleBinding binding the Pod's ServiceAccount from namespace-a across namespaces.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Create a Role in namespace-b granting get on ConfigMaps in namespace-b and bind it in namespace-b.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create a ServiceAccount in namespace-a and bind to a Role in namespace-a.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because cluster-scoped roles (ClusterRole) with a ClusterRoleBinding can grant permissions across namespaces to a ServiceAccount. This allows the SA in namespace-a to perform the configured access on ConfigMaps (in namespace-b) depending on the policy.\n\n## Why Other Options Are Wrong\n- A incorrectly limits permissions to namespace-a, not enabling cross-namespace access.\n- C binds within namespace-b, which does not grant cross-namespace access from namespace-a.\n- D binds within namespace-a but does not grant cross-namespace access to ConfigMaps.\n\n## Key Concepts\n- RBAC: ClusterRole vs Role semantics\n- ClusterRoleBinding can grant permissions across namespaces\n- ServiceAccount scope and subject namespace matter\n\n## Real-World Application\n- Designing cross-namespace access in multi-tenant clusters requires ClusterRole-based bindings to avoid per-namespace role duplication.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","RBAC","ClusterRole","CrossNamespace","certification-mcq","domain-weight-46"],"channel":"kcna","subChannel":"k8s-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:19:11.705Z","createdAt":"2026-01-11 17:19:12"},{"id":"kcna-k8s-fundamentals-1768151951289-2","question":"During a rolling update of a Deployment with 5 replicas, you want to guarantee at least 4 pods are always available and not more than one can be unavailable during the update. Which configuration achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Set RollingUpdate strategy with maxUnavailable: 1 and create a PodDisruptionBudget with minAvailable: 4.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Set RollingUpdate strategy with maxUnavailable: 0 and minAvailable: 5.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use RollingUpdate with maxSurge: 2 and PodDisruptionBudget minAvailable: 3.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Recreate strategy with PodDisruptionBudget minAvailable: 5.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because maxUnavailable: 1 ensures at most one pod is down during the update, and PodDisruptionBudget with minAvailable: 4 guarantees at least four pods are always available.\n\n## Why Other Options Are Wrong\n- B is overly strict and would block updates since zero pods can be unavailable, which is not required by the scenario.\n- C uses minAvailable 3, which would allow up to two pods to be down during disruptions, not meeting the 4-pod availability requirement.\n- D uses the Recreate strategy which stops all pods before recreating them, not providing rolling updates.\n\n## Key Concepts\n- Deployment rollingUpdate controls maxUnavailable\n- PodDisruptionBudget constrains voluntary disruptions\n- Combined settings yield predictable upgrade behavior\n\n## Real-World Application\n- In production, aligning deployment strategy with PDB prevents service outage during upgrades and maintenance.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","PodDisruptionBudget","RollingUpdate","Deployment","certification-mcq","domain-weight-46"],"channel":"kcna","subChannel":"k8s-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:19:12.138Z","createdAt":"2026-01-11 17:19:12"}],"subChannels":["container-orchestration","k8s-fundamentals"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}