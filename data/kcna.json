{"questions":[{"id":"q-1138","question":"You are building a real-time KCNA feed service used by Snap, Meta, and Discord-scale clients to publish and deliver announcements across regions with sub-100ms tail latency. Describe the end-to-end architecture, data model for Announcement, ingestion and delivery pipeline, guarantees (at-least-once vs exactly-once), ordering, deduplication, failover, tests, and observability. How would you scale to 10k updates/sec with 99.999% uptime?","answer":"Design a real-time KCNA feed with an event-sourced pipeline: publish to a durable log (Kafka/Kinesis), process via idempotent services, store state in a scalable DB, and stream updates to regional cac","explanation":"## Why This Is Asked\n\nThis question probes system design at scale, covering data modeling, ingestion pipelines, delivery guarantees, ordering, and observability in a globally distributed, low-latency context.\n\n## Key Concepts\n\n- Event sourcing and durable logs (Kafka/Kinesis)\n- Idempotent processing and deduplication\n- Region-local vs global ordering\n- Delivery guarantees (at-least-once vs exactly-once)\n- Observability, testing, and chaos engineering\n\n## Code Example\n\n```javascript\n// Example: idempotent publish wrapper\nfunction publishAnnouncement(store, event) {\n  const id = event.id;\n  if (store.has(id)) return; // dedup\n  store.set(id, event);\n  // emit to downstream\n}\n```\n\n## Follow-up Questions\n\n- How would you design feature flags for regional rollouts and rollback strategies?\n- What monitoring and tracing would you implement to detect tail latency regressions?","diagram":"flowchart TD\n  Ingest[Ingest] --> Proc[Process]\n  Proc --> Ent[Event Store]\n  Ent --> Del[Delivery]\n  Del --> Client[Client]","difficulty":"advanced","tags":["kcna"],"channel":"kcna","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:26:25.116Z","createdAt":"2026-01-13T01:26:25.116Z"},{"id":"q-1295","question":"**KCNA Consumer Backpressure & Gap Handling**: In a beginner-friendly KCNA consumer, design a pull-based ingestion path that preserves per-topic offsets, guarantees at-least-once processing, and recovers from transient network slowdowns without duplicating messages. Describe the API shape, offset persistence, retry/backoff strategy, and a minimal test plan including a canary scenario?","answer":"Proposed answer (concise example): A pull-based consumer tracks per-topic offsets in a durable local store, commits after successful processing, and uses idempotent handlers. Retries use exponential b","explanation":"## Why This Is Asked\nThis question probes practical dataflow design for reliable at-least-once delivery and simple backpressure handling in a beginner context.\n\n## Key Concepts\n- Pull-based consumption with per-topic offsets\n- Idempotent processing and offset commits\n- Retry/backoff with jitter and restart replay\n- Canary and integration testing\n\n## Code Example\n```javascript\n// Pseudo API sketch\nclass KCNAConsumer {\n  constructor(store, process) { this.store=store; this.process=process }\n  async poll() { /* fetch by offset, call process, commit */ }\n  commit(offset) { this.store.save(offset) }\n}\n```\n\n## Follow-up Questions\n- How would you test exactly-once vs at-least-once boundaries in this setup?\n- How would you extend this to handle multiple topics with independent offsets?","diagram":null,"difficulty":"beginner","tags":["kcna"],"channel":"kcna","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Plaid","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T08:41:04.859Z","createdAt":"2026-01-13T08:41:04.859Z"},{"id":"q-941","question":"Scenario: A global chat platform with 2B MAUs must detect policy-violating content (spam, hate speech) in near real-time while preserving user privacy and multilingual support. Propose an end-to-end pipeline: ingestion, moderation models (rules + ML), latency SLOs (1-2s), privacy safeguards, backpressure handling, retries, and dead-letter queues. Compare on-device vs cloud inference and monitoring?","answer":"Propose a tiered moderation pipeline: client-side tokenization + on-device classifier for first-pass filtering (multilingual light-weight model), with encrypted message IDs, then server-side streaming","explanation":"## Why This Is Asked\nThis question gauges real-time, scalable moderation design, privacy-safe multi-language handling, and the trade-offs between edge and cloud inference.\n\n## Key Concepts\n- Real-time streaming pipelines, SLOs, backpressure\n- Edge (on-device) vs cloud inference, multilingual models\n- Privacy safeguards (encryption, minimal data)\n- DLQ, retries, circuit breakers, monitoring\n\n## Code Example\n```javascript\n// Latency guard example\nif (latencyMs > 2000) {\n  tagAsSlowPath();\n  redirectToFallbackQueue();\n}\n```\n\n## Follow-up Questions\n- How would you validate model drift and false positives in production?\n- What metrics would you surface in dashboards to detect abuse transparently?","diagram":"flowchart TD\n  A[Ingest] --> B[Queue]\n  B --> C[Moderation]\n  C --> D[Enforce/Notify]\n  D --> E[Audit]","difficulty":"advanced","tags":["kcna"],"channel":"kcna","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Slack","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:31:29.566Z","createdAt":"2026-01-12T16:31:29.566Z"}],"subChannels":["general"],"companies":["Discord","Meta","Plaid","Slack","Snap","Twitter","Two Sigma"],"stats":{"total":3,"beginner":1,"intermediate":0,"advanced":2,"newThisWeek":3}}