{"questions":[{"id":"databricks-data-engineer-data-governance-1768252726521-0","question":"A Databricks workspace has Unity Catalog enabled with multiple catalogs, schemas, and tables. You need to enforce centralized access control so permissions apply consistently without duplicating rights for each user. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Grant privileges directly to individual users on each catalog, schema, and table.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Unity Catalog privileges to grant roles on catalogs, schemas, and tables and assign users to those roles.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Configure cluster-level ACLs to override data catalog permissions.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Maintain permissions in an external system and synchronize nightly.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is option B because Unity Catalog provides centralized access control by granting privileges to roles at catalog/schema/table levels, and users are assigned to roles, ensuring consistent permissions without per-user duplication.\n\n## Why Other Options Are Wrong\n- Option A grants to individuals creates drift and duplication across catalogs and is not scalable.\n- Option C describes cluster-level ACLs which do not enforce catalog-level data permissions consistently.\n- Option D introduces an external synchronization workflow that typically leads to drift and misses approvals consistency.\n\n## Key Concepts\n- Unity Catalog centralized access control\n- Role-based privileges at catalog/schema/table levels\n- Least privilege and scalable governance\n\n## Real-World Application\n- Implement RBAC in Unity Catalog for data teams; assign users to roles and apply grants at the catalog/schema/table level to ensure consistent access across notebooks and clusters.","diagram":null,"difficulty":"intermediate","tags":["Databricks Unity Catalog","Data Governance","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-9"],"channel":"databricks-data-engineer","subChannel":"data-governance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:18:46.524Z","createdAt":"2026-01-12 21:18:46"},{"id":"databricks-data-engineer-data-governance-1768252726521-1","question":"In a Databricks Delta Live Tables pipeline, which approach best enforces data quality by validating data as it ingests and failing the run on violations?","answer":"[{\"id\":\"a\",\"text\":\"Build custom Spark UDFs to check data quality within the pipeline.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Delta Live Tables with built-in Expectations to validate data and fail on violations.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on downstream dashboards to detect data quality issues.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Run separate QA jobs after ingestion to verify data quality.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Delta Live Tables provides built-in Expectations that enforce data quality during pipeline execution, failing the run when data does not meet the defined constraints.\n\n## Why Other Options Are Wrong\n- Option A relies on custom UDFs which are not integrated with DL T quality gates and require extra maintenance.\n- Option C is reactive and does not prevent bad data from landing in the lakehouse.\n- Option D adds latency and orchestration overhead, reducing timeliness of data.\n\n## Key Concepts\n- Delta Live Tables\n- Expectations-based validation\n- Data quality gates\n\n## Real-World Application\n- Define expectations like non-null IDs, value ranges, and referential integrity within a DLT pipeline to ensure only clean data progresses downstream.","diagram":null,"difficulty":"intermediate","tags":["Databricks Delta Live Tables","Data Governance","AWS","Terraform","certification-mcq","domain-weight-9"],"channel":"databricks-data-engineer","subChannel":"data-governance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:18:47.044Z","createdAt":"2026-01-12 21:18:47"},{"id":"databricks-data-engineer-data-governance-1768252726521-2","question":"You need to capture data lineage across Databricks jobs and notebooks for critical datasets to support governance and audits. Which Databricks feature provides end-to-end lineage visibility?","answer":"[{\"id\":\"a\",\"text\":\"Delta Time Travel\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Unity Catalog data lineage\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Delta Sharing\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"DBSQL Audit Logs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Unity Catalog includes data lineage capabilities that map data from sources through catalogs, schemas, and tables across notebooks and pipelines.\n\n## Why Other Options Are Wrong\n- Option A: Delta Time Travel shows historical versions, not complete lineage.\n- Option C: Delta Sharing focuses on data distribution, not lineage visibility.\n- Option D: DBSQL Audit Logs capture access events, not end-to-end data flow lineage.\n\n## Key Concepts\n- Data lineage in Unity Catalog\n- End-to-end data flow visibility\n- Governance and compliance\n\n## Real-World Application\n- Use lineage views to produce auditable lineage reports showing source systems to final datasets for regulators.","diagram":null,"difficulty":"intermediate","tags":["Databricks Unity Catalog","Data Governance","AWS","certification-mcq","domain-weight-9"],"channel":"databricks-data-engineer","subChannel":"data-governance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:18:47.559Z","createdAt":"2026-01-12 21:18:47"},{"id":"databricks-data-engineer-data-governance-1768252726521-3","question":"To protect PII in your lakehouse, you want per-user role-based masking at query time. Which feature enables this in Unity Catalog?","answer":"[{\"id\":\"a\",\"text\":\"Column-level encryption in Delta Lake\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Masking policies in Unity Catalog\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Row-level security via views\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Audit logging to detect unauthorized access\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Unity Catalog masking policies provide dynamic, per-role data masking at query time.\n\n## Why Other Options Are Wrong\n- Option A encrypts data at rest, not per-user masking during query.\n- Option C can hide data via views but does not offer dynamic per-user masking.\n- Option D helps detect access events but does not mask data for users.\n\n## Key Concepts\n- Dynamic data masking\n- Unity Catalog masking policies\n- Role-based data exposure\n\n## Real-World Application\n- Apply masking on sensitive columns (e.g., SSN, salary) so analysts see redacted values unless explicitly authorized.","diagram":null,"difficulty":"intermediate","tags":["Databricks Unity Catalog","Data Governance","AWS","certification-mcq","domain-weight-9"],"channel":"databricks-data-engineer","subChannel":"data-governance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:18:47.739Z","createdAt":"2026-01-12 21:18:47"},{"id":"databricks-data-engineer-data-governance-1768252726521-4","question":"You need to securely share a curated dataset with an external partner in a controlled, auditable manner. Which Databricks feature is designed specifically for this?","answer":"[{\"id\":\"a\",\"text\":\"Delta Sharing\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Manual CSV export to an FTP server\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Public REST API exposing the dataset\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Direct Unity Catalog access for external partners\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Delta Sharing enables secure, auditable, and seamless data sharing with external partners without exposing underlying storage or compromising governance.\n\n## Why Other Options Are Wrong\n- Option B lacks built-in governance and auditing capabilities and introduces manual steps.\n- Option C creates an insecure exposure surface and bypasses governance controls.\n- Option D is not a supported model for external partners and can compromise security boundaries.\n\n## Key Concepts\n- Delta Sharing\n- Secure external data sharing\n- Auditing and access controls\n\n## Real-World Application\n- Share curated datasets with partner organizations via Delta Sharing links with defined access windows and monitoring.","diagram":null,"difficulty":"intermediate","tags":["Databricks Delta Sharing","Data Governance","AWS","certification-mcq","domain-weight-9"],"channel":"databricks-data-engineer","subChannel":"data-governance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:18:47.919Z","createdAt":"2026-01-12 21:18:48"},{"id":"databricks-data-engineer-elt-spark-1768169996346-0","question":"In a Databricks Delta Lake ELT pipeline, a Delta table db.sales is frequently queried with filters on region and sale_date. The dataset is large and files are small, causing slow scans. Which of the following changes would most improve query performance for these filters?","answer":"[{\"id\":\"a\",\"text\":\"Run OPTIMIZE delta.`db.sales` ZORDER BY (region, sale_date)\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Partition the table by region at write time to improve filtering\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cache the entire table in memory before running queries\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Convert to a single large Parquet file per partition to reduce file fragmentation\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct. OPTIMIZE with ZORDER BY co-locates data based on frequently filtered columns (region, sale_date), reducing data scanned for common predicates and speeding up queries on large Delta tables.\n\n## Why Other Options Are Wrong\n- Option b: Rewriting partitioning after the fact is non-trivial for large datasets and does not guarantee improved performance for the common region/date predicates; ZORDER targets data layout for efficient pruning.\n- Option c: Caching a very large table yields diminishing returns and can exhaust cluster memory, offering transient benefits at best.\n- Option d: Creating a single large Parquet file per partition reduces parallelism and generally hurts read performance for distributed engines.\n\n## Key Concepts\n- Delta Lake OPTIMIZE\n- ZORDER BY for data locality\n\n## Real-World Application\n- Improves latency for frequent region/date range filters on large fact tables.\n```sql\nOPTIMIZE delta.`db.sales` ZORDER BY (region, sale_date)\n```\n","diagram":null,"difficulty":"intermediate","tags":["Delta-Lake","Spark-SQL","Python","ETL","Databricks","AWS-S3","certification-mcq","domain-weight-29"],"channel":"databricks-data-engineer","subChannel":"elt-spark","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:56.347Z","createdAt":"2026-01-11 22:19:56"},{"id":"databricks-data-engineer-elt-spark-1768169996346-1","question":"During an upsert from a staging table stg_sales to a Delta table dim_sales, you need to deduplicate on sale_id and apply inserts/updates idempotently. Which approach ensures ACID upserts and preserves history?","answer":"[{\"id\":\"a\",\"text\":\"Use a Spark SQL join and overwrite the target table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Delta Lake MERGE statement to upsert from staging into target\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use INSERT with DISTINCT and append\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use REPLACE TABLE with the staging data\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct. The Delta MERGE statement provides ACID upserts, handles insert/update semantics in a single atomic operation, and preserves the transaction log/history, making it ideal for deduping on a natural key like sale_id.\n\n## Why Other Options Are Wrong\n- Option a: Upserting via a join and overwrite can lose row-level history and is not atomic for concurrent writers.\n- Option c: INSERT with DISTINCT does not handle updates to existing rows and can miss deduplication if staging contains updated rows for existing keys.\n- Option d: REPLACE TABLE discards the previous table metadata and history, breaking ACID guarantees.\n\n## Key Concepts\n- Delta Lake MERGE for upserts\n- ACID transactions and transaction log\n\n## Real-World Application\n- Safely applying daily upserts from a staging layer into a production dimension/fact table.\n```sql\nMERGE INTO delta.`db.dim_sales` AS t\nUSING delta.`db.stg_sales` AS s\nON t.sale_id = s.sale_id\nWHEN MATCHED THEN UPDATE SET t.amount = s.amount, t.sale_date = s.sale_date\nWHEN NOT MATCHED THEN INSERT (sale_id, amount, sale_date) VALUES (s.sale_id, s.amount, s.sale_date);\n```\n","diagram":null,"difficulty":"intermediate","tags":["Delta-Lake","Spark-SQL","Python","ETL","Databricks","AWS-S3","certification-mcq","domain-weight-29"],"channel":"databricks-data-engineer","subChannel":"elt-spark","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:56.832Z","createdAt":"2026-01-11 22:19:57"},{"id":"databricks-data-engineer-elt-spark-1768169996346-2","question":"A daily Python-based ETL load ingests JSON payloads that introduce a new field customer_segment not present in the existing Delta table schema. You want to automatically evolve the schema on write. Which write option enables this behavior?","answer":"[{\"id\":\"a\",\"text\":\"Disable schema enforcement and append to the table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Write with option mergeSchema=true to enable schema evolution\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Pre-scan files and run ALTER TABLE to add new columns before writing\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Fail the job if a new field is detected\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct. Setting mergeSchema=true enables Delta Lake to evolve the schema on write, allowing new fields like customer_segment to be added automatically during append operations.\n\n## Why Other Options Are Wrong\n- Option a: Disabling schema enforcement can lead to inconsistent schemas and runtime errors when reading.\n- Option c: Pre-scanning and altering the schema before every write adds complexity and delay; schema evolution should be automatic.\n- Option d: Failing on new fields halts the pipeline and prevents automatic data ingestion.\n\n## Key Concepts\n- Delta Lake schema evolution\n- mergeSchema option in DataFrameWriter\n\n## Real-World Application\n- Ingesting semi-structured JSON that evolves over time without manual schema changes.\n```python\ndf.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(\"/mnt/delta/dim_sales\")\n```\n","diagram":null,"difficulty":"intermediate","tags":["Delta-Lake","Spark-SQL","Python","ETL","Databricks","AWS-S3","certification-mcq","domain-weight-29"],"channel":"databricks-data-engineer","subChannel":"elt-spark","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:57.298Z","createdAt":"2026-01-11 22:19:57"},{"id":"q-1100","question":"In a Databricks data pipeline, ingest JSON events from S3 into Delta Lake with Auto Loader. Each event has a nested user object (id, email) and an optional pages array. Some events miss user.email. How would you design the pipeline to safely flatten nested fields, handle missing values, and upsert the latest user state into a Delta Silver table using an idempotent MERGE?","answer":"Use Auto Loader with schema evolution, flatten nested fields, and a MERGE for idempotent upserts. ReadStream via cloudFiles, inferColumnTypes true, mergeSchema true. Flatten: user_id = user.id, email ","explanation":"## Why This Is Asked\n\nTests practical mastery of ingesting semi-structured data, flattening nested JSON, handling optional fields, and performing idempotent upserts in Delta Lake using Databricks primitives.\n\n## Key Concepts\n\n- Auto Loader with cloudFiles options for JSON with schema evolution\n- Flattening nested structs and handling missing fields safely\n- Upserts with MERGE to ensure idempotent state in Delta Lake\n- Null handling with COALESCE and robust array expansion (explode_outer)\n\n## Code Example\n\n```javascript\n// Databricks PySpark-like sketch (syntax-highlighted as javascript)\nval df = spark.readStream.format(\"cloudFiles\")\n  .option(\"cloudFiles.format\",\"json\")\n  .option(\"cloudFiles.inferColumnTypes\",\"true\")\n  .option(\"cloudFiles.mergeSchema\",\"true\")\n  .load(\"s3a://bucket/events/\")\n\nval flat = df.selectExpr(\"user.id as user_id\",\n                       \"coalesce(user.email, '') as email\",\n                       \"ts as event_ts\",\n                       \"explode_outer(pages) as page\")\n```\n\n## Follow-up Questions\n\n- How would you test this pipeline end-to-end, including schema evolution scenarios?\n- How would you handle new nested fields added to user in future deployments?","diagram":null,"difficulty":"beginner","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:31:52.482Z","createdAt":"2026-01-12T22:31:52.482Z"},{"id":"q-1112","question":"Scenario: In a Databricks Delta Live Tables pipeline, ingest JSON events from a Kafka source into a Bronze table, where nested fields drift over time (e.g., payload.user.locale is added later, some events miss payload.user). You then transform to a Silver table used by billing and marketing. How would you implement a robust schema-evolution strategy and gating so new fields are captured without breaking existing downstream queries, and how would you test this in a run?","answer":"Enable schema evolution in DLT by merging new fields into Bronze and keeping downstream schema backward compatible; treat optional nested fields as nullable and use defaults; gate with non-null expect","explanation":"## Why This Is Asked\nTests practical schema evolution and data quality gating in a real Delta Live Tables pipeline, focusing on drift in nested JSON and downstream stability.\n\n## Key Concepts\n- Delta Live Tables schema evolution\n- Nested JSON drift handling\n- Downstream backward compatibility\n- Data quality gates/expectations\n- End-to-end testing with mixed schemas\n\n## Code Example\n```python\n# PySpark-like sketch for Bronze -> Silver\nbronze = spark.readStream.format(\"cloudFiles\").option(\"cloudFiles.format\",\"json\").load(\"/bronze\")\nsilver = bronze.selectExpr(\"payload.user.id as user_id\", \"payload.user.locale as user_locale\", \"payload.action as action\", \"timestamp\")\nsilver = silver.withColumn(\"user_locale\", F.coalesce(col(\"user_locale\"), F.lit(\"unknown\")))\n```\n\n## Follow-up Questions\n- How would you roll schema changes from experimental to production with minimal downtime?\n- How would you monitor for schema drift in production and trigger alerts?","diagram":null,"difficulty":"intermediate","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Microsoft","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:23:17.885Z","createdAt":"2026-01-12T23:23:17.885Z"},{"id":"q-1144","question":"In a Databricks streaming pipeline ingesting tenant-scoped events from Kafka into Delta Lake, events may arrive late by up to 10 minutes. Describe a concrete end-to-end approach to upsert the latest state per (tenant_id, user_id) into a Silver table while preserving the full event history. Include: data model, CDC logic, watermarking and late data handling, an idempotent MERGE strategy, schema evolution handling, and governance considerations with Unity Catalog RBAC and data lineage?","answer":"Use Bronze→Silver CDC pattern with Delta Lake. Silver holds latest state per (tenant_id, user_id); History preserves all changes. Use a 10-minute watermark to bound late data; MERGE INTO Silver WHEN M","explanation":"## Why This Is Asked\nThis tests practical CDC design, late-arrival handling, and Delta Lake upserts in a multi-tenant setting.\n\n## Key Concepts\n- Delta Lake MERGE for upserts\n- Watermarks and late data handling in streaming\n- Bronze-Silver-History data modeling\n- Unity Catalog RBAC and data lineage\n\n## Code Example\n```javascript\n-- Spark SQL (illustrative)\nMERGE INTO silver_latest AS s\nUSING bronze AS b\nON s.tenant_id = b.tenant_id AND s.user_id = b.user_id\nWHEN MATCHED THEN UPDATE SET\n  s.state = b.state,\n  s.last_updated = current_timestamp(),\n  s.version = b.version\nWHEN NOT MATCHED THEN INSERT (tenant_id, user_id, state, last_updated, version)\nVALUES (b.tenant_id, b.user_id, b.state, current_timestamp(), b.version);\n```\n\n## Follow-up Questions\n- How would you validate late-data handling under bursty traffic?\n- How would you monitor and alert on data-skew and drift across tenants?","diagram":null,"difficulty":"advanced","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Cloudflare","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:30:54.604Z","createdAt":"2026-01-13T01:30:54.604Z"},{"id":"q-1182","question":"In a multi-tenant Databricks lakehouse ingesting per-tenant telemetry from Kafka and S3 into a unified Silver Delta table, describe an end-to-end CDC strategy to implement SCD2-like history per tenant with idempotent MERGE, handle late data with a watermark, and enforce governance through Unity Catalog RBAC and dynamic PII masking. Include data model, CDC logic, testing plan, and how you’d validate lineage?","answer":"Design a CDC-driven SCD2 history per tenant in a Delta table. Ingest via Delta Live Tables into a Silver table partitioned by tenant_id and timestamp. On MERGE, close previous history rows by setting ","explanation":"## Why This Is Asked\n\nTests the ability to design a CDC-based SCD2 history in a multi-tenant lakehouse with governance and masking requirements, using Delta Live Tables and MERGE semantics.\n\n## Key Concepts\n\n- CDC and SCD2 patterns in Delta Lake\n- Delta Live Tables and MERGE-based upserts\n- Watermarking and late-data handling\n- Unity Catalog RBAC and dynamic data masking\n- Data lineage and governance with Delta sharing\n\n## Code Example\n\n```sql\nMERGE INTO silver AS tgt\nUSING staging AS src\nON tgt.tenant_id = src.tenant_id AND tgt.key = src.key\nWHEN MATCHED AND (src.attributes_hash <> tgt.attributes_hash OR src.timestamp <> tgt.end_date) THEN\n  UPDATE SET end_date = current_timestamp()\nWHEN NOT MATCHED THEN\n  INSERT (tenant_id, key, attributes_hash, start_date, end_date)\n  VALUES (src.tenant_id, src.key, src.attributes_hash, current_timestamp(), NULL)\n```\n\n## Follow-up Questions\n\n- How would you test idempotency of MERGE under replayed CDC events?\n- How would you implement per-tenant masking policies in Unity Catalog and verify lineage against dashboards?","diagram":null,"difficulty":"advanced","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:43:29.150Z","createdAt":"2026-01-13T03:43:29.150Z"},{"id":"q-1226","question":"In a Databricks Delta Live Tables pipeline that ingests clickstream events from a cloud bucket into a Delta table, data quality checks are defined via expectations. A batch arrives with corrupted event_time values that would fail the run. Outline a concrete approach to quarantine bad data, feed downstream tables only from valid rows, and store invalids for audit, while still handling late data and deduplication?","answer":"Create a staging raw_events table, apply a light validation to tag rows as valid/invalid, store invalid rows in invalid_events, and feed downstream clean_events from valid rows only. Use a watermark o","explanation":"## Why This Is Asked\nDemonstrates practical, production-ready handling of partial data quality failures in a Delta Live Tables pipeline, balancing correctness with availability.\n\n## Key Concepts\n- Staging vs downstream separation\n- Expectations-based quality checks\n- Quarantine and audit of invalid data\n- Late data handling with watermarking\n- Deduplication strategies across micro-batches\n\n## Code Example\n```javascript\nimport dlt\nimport pyspark.sql.functions as F\n\n@dlt.table\ndef raw_events():\n  return spark.read.format(\"cloudFiles\").option(\"cloudFiles.format\",\"json\").load(\"/mnt/events/raw\")\n\n@dlt.table\ndef valid_events():\n  df = dlt.read(\"raw_events\")\n  return df.filter(F.col(\"event_time\").isNotNull() & F.col(\"user_id\").isNotNull())\n\n@dlt.table\ndef invalid_events():\n  raw = dlt.read(\"raw_events\")\n  valid_ids = dlt.read(\"valid_events\").select(\"event_id\").distinct()\n  return raw.join(valid_ids, \"event_id\", \"left_anti\")\n\n@dlt.table\ndef clean_events():\n  return dlt.read(\"valid_events\")\n```\n\n## Follow-up Questions\n- How would you monitor and alert if invalid_events growth spikes?\n- What changes would you make to support reprocessing of invalid data after fixes?","diagram":"flowchart TD\n  A[Ingest Raw Events] --> B[DLT Validation Tagging]\n  B --> C{Validity}\n  C -->|Valid| D[Feed Clean Events]\n  C -->|Invalid| E[Store Invalid Events]\n  D --> F[Analytics & BI]\n  E --> G[Audit & Reprocessing]\n  H[Late Data via Watermark] --> B","difficulty":"intermediate","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:38:03.397Z","createdAt":"2026-01-13T05:38:03.397Z"},{"id":"q-1264","question":"In a Databricks job ingesting daily Parquet files from S3 into Delta Lake, a new field 'campaign_id' may appear in newer files while older ones do not. Describe a concrete, beginner-friendly approach to ingest without data loss, allowing downstream joins, and handling the schema change gracefully. Include how to enable Delta schema evolution (mergeSchema/autoMerge), define a compatible target schema, and implement a minimal validation to drop rows missing essential fields?","answer":"Enable Delta schema evolution by using mergeSchema on write and enabling auto-merge: spark.conf.set('spark.databricks.delta.schema.autoMerge.enabled','true'); df.write.format('delta').option('mergeSch","explanation":"## Why This Is Asked\n\nTests understanding of practical schema evolution in Delta Lake during basic batch ingestion and how to keep data accessible for joins.\n\n## Key Concepts\n\n- Delta Lake schema evolution\n- mergeSchema and autoMerge\n- Nullability and backward compatibility\n- Data quality validation\n\n## Code Example\n\n```javascript\n// Ingestion example with schema evolution\ndf.write.format(\"delta\").option(\"mergeSchema\",\"true\").mode(\"append\").save(\"/delta/user_events\")\n```\n\n## Follow-up Questions\n\n- How would you validate that campaign_id is correctly populated in downstream queries?\n- How would you backfill the historical table to reflect a new campaigns dimension without downtime?","diagram":null,"difficulty":"beginner","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Coinbase","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:31:13.696Z","createdAt":"2026-01-13T07:31:13.696Z"},{"id":"q-906","question":"Scenario: A daily Delta Live Tables (DLT) pipeline ingests clickstream JSONs into a Bronze Delta table and then enriches with a users_dim to a Silver table. Build a beginner-friendly pipeline that: deduplicates by event_id, validates user_id via users_dim, filters to business hours 08:00–18:00, enriches with user fields, and writes to Silver partitioned by event_date. Outline minimal steps and rationale?","answer":"Proposed approach: Use a DLT pipeline with Bronze ingest from JSON, then Silver derived from Bronze. Deduplicate on event_id, keeping the latest by ingest_time. Join to users_dim on user_id to validat","explanation":"## Why This Is Asked\n\nTests ability to design an end-to-end DL pipeline focused on data quality, deduplication, enrichment, and partitioned storage for performance.\n\n## Key Concepts\n\n- Delta Live Tables basics and table dependencies\n- Deduplication by event_id using window or primary-key approaches\n- Referential integrity via dimension lookups during enrichment\n- Time-based filtering for business hours\n- Partitioning Silver by event_date for efficient queries\n\n## Code Example\n\n```javascript\n// Pseudo-DLT sketch (not runnable)\nBronze = read_json('s3://bucket/clicks/bronze/')\nSilver = Bronze\n  .dropDuplicates(['event_id'])\n  .join(users_dim, Bronze.user_id == users_dim.user_id, 'left')\n  .filter(hour(Bronze.event_timestamp) >= 8 and hour(Bronze.event_timestamp) <= 18)\n  .withColumn('event_date', to_date(Bronze.event_timestamp))\n  .writePartitionBy('event_date')\n```\n\n## Follow-up Questions\n\n- How would you handle late-arriving events or backfills in this pipeline?\n- What tests would you add to validate deduplication and the user_id join behavior?","diagram":null,"difficulty":"beginner","tags":["databricks-data-engineer"],"channel":"databricks-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Netflix","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:44:28.732Z","createdAt":"2026-01-12T14:44:28.732Z"},{"id":"databricks-data-engineer-incremental-processing-1768225886749-0","question":"In a Databricks Delta Lake incremental ETL scenario, you stream data from Kafka into a Delta table with a primary key on id. You need to upsert each micro-batch into the target table and handle late arriving updates efficiently. Which approach is recommended?","answer":"[{\"id\":\"a\",\"text\":\"writeStream with append mode to a new Delta location\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"foreachBatch with MERGE INTO target_table USING updates ON t.id = s.id WHEN MATCHED THEN UPDATE SET ... WHEN NOT MATCHED THEN INSERT ...\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"perform a daily batch upsert by running MERGE on the last 24h data\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"a static batch job that overwrites the target Delta table\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe recommended approach is to use foreachBatch to perform a MERGE INTO on the target Delta table, upserting the incoming micro-batch by its primary key. This pattern preserves incremental state and minimizes window latency, while correctly applying inserts and updates in a scalable way.\n\n## Why Other Options Are Wrong\n- Option A: Appending to a new Delta location does not upsert into the existing table and will create duplicates.\n- Option C: Upserting on a daily cadence undermines the real-time incremental goal and increases latency.\n- Option D: Overwriting the target discards existing data and breaks incremental semantics.\n\n## Key Concepts\n- Delta Lake MERGE for upserts\n- Structured Streaming with foreachBatch\n- Exactly-once semantics in micro-batch pipelines\n- Handling late data via deterministic upsert logic\n\n## Real-World Application\n- Use case: streaming real-time orders from Kafka that require upserts to keep the current order state up-to-date without duplicates.","diagram":null,"difficulty":"intermediate","tags":["Delta Lake","Apache Spark","Databricks","Kafka","AWS S3","Kubernetes","Terraform","Delta-Live-Tables","CDC","certification-mcq","domain-weight-22"],"channel":"databricks-data-engineer","subChannel":"incremental-processing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:51:26.750Z","createdAt":"2026-01-12 13:51:27"},{"id":"databricks-data-engineer-incremental-processing-1768225886749-1","question":"During incremental data ingestion, a new source occasionally adds new columns not present in the target Delta table. You want Delta to automatically evolve the schema without failing the write. Which option enables this behavior?","answer":"[{\"id\":\"a\",\"text\":\"Disable strict schema enforcement on the Delta table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Set option mergeSchema = true on the write/merge path\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Manually alter the Delta table to add columns before writes\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cast all incoming fields to the existing schema only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nSet option mergeSchema = true on the write/merge path to enable automatic schema evolution when new columns appear in incoming data. This allows Delta Lake to adapt without failing writes.\n\n## Why Other Options Are Wrong\n- Option A: There is no generic switch called 'strict schema enforcement'; manually disabling is not standard practice and can have risks.\n- Option C: Manual schema changes are brittle and slow for streaming schemas.\n- Option D: Casting everything constrains evolution and loses new data.\n\n## Key Concepts\n- Delta Lake schema evolution\n- mergeSchema option\n- Ingestion of evolving JSON/Parquet schemas\n\n## Real-World Application\n- Ingesting JSON logs where new fields appear over time; automatically adapt without downtime.","diagram":null,"difficulty":"intermediate","tags":["Delta Lake","Apache Spark","Databricks","Schema Evolution","ETL","Kubernetes","certification-mcq","domain-weight-22"],"channel":"databricks-data-engineer","subChannel":"incremental-processing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:51:27.571Z","createdAt":"2026-01-12 13:51:27"},{"id":"databricks-data-engineer-incremental-processing-1768225886749-2","question":"You are streaming events with an event_time field and you want to bound stateful memory and drop late events beyond a certain threshold. Which technique ensures progress and bounded state?","answer":"[{\"id\":\"a\",\"text\":\"Apply withWatermark on event_time with a defined delay\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use dropDuplicates on id\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable checkpointing only\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable watermarking and rely on micro-batch intervals\",\"isCorrect\":false}]","explanation":"## Correct Answer\nApply withWatermark on the event_time column with a defined delay to bound state and drop late data beyond the allowed lateness, ensuring the streaming query progresses.\n\n## Why Other Options Are Wrong\n- Option B: Deduplication doesn't bound state or control late data arrival.\n- Option C: Checkpointing tracks progress but does not bound state.\n- Option D: Removing watermarking eliminates a key control that allows bounded memory.\n\n## Key Concepts\n- Watermarking in Structured Streaming\n- Event-time processing\n- State pruning for bounded streams\n\n## Real-World Application\n- IoT telemetry with late-arriving packets; ensures timely results.","diagram":null,"difficulty":"intermediate","tags":["Apache Spark","Databricks","Structured Streaming","Watermark","Kafka","AWS-S3","Kubernetes","certification-mcq","domain-weight-22"],"channel":"databricks-data-engineer","subChannel":"incremental-processing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:51:28.092Z","createdAt":"2026-01-12 13:51:28"},{"id":"databricks-data-engineer-incremental-processing-1768225886749-3","question":"For large-scale incremental data pipelines with data quality checks and dependency modeling, which Databricks feature helps manage incremental processing and quality expectations?","answer":"[{\"id\":\"a\",\"text\":\"Delta TableTime Travel\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Delta Live Tables (DLT) with expectations\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Autoloader with incremental ingestion\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Spark Structured Streaming\",\"isCorrect\":false}]","explanation":"## Correct Answer\nDelta Live Tables (DLT) provides a managed pipeline experience with built-in data quality checks (expectations) and incremental processing, ideal for production-grade data engineering tasks.\n\n## Why Other Options Are Wrong\n- Option A: Time Travel helps revert to previous table versions, not pipeline quality management.\n- Option C: Autoloader focuses on ingestion rather than end-to-end pipeline quality checks.\n- Option D: Spark Structured Streaming is the engine, but lacks the declarative quality/CI-like pipeline management of DLT.\n\n## Key Concepts\n- Delta Live Tables\n- Data quality with expectations\n- Incremental data processing\n\n## Real-World Application\n- Building a reliable data pipeline with automated quality gates.","diagram":null,"difficulty":"intermediate","tags":["Delta Live Tables","Databricks","Data Quality","ETL","CI/CD","Kubernetes","certification-mcq","domain-weight-22"],"channel":"databricks-data-engineer","subChannel":"incremental-processing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:51:28.293Z","createdAt":"2026-01-12 13:51:28"},{"id":"databricks-data-engineer-incremental-processing-1768225886749-4","question":"In a multi-source streaming ingestion scenario with delete Tombstone messages, which approach ensures deletes are applied to the Delta table while preserving existing records?","answer":"[{\"id\":\"a\",\"text\":\"Use MERGE with an is_deleted flag and DELETE WHEN MATCHED AND source.is_deleted = true\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Ignore tombstones and only insert new rows\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Overwrite the Delta table on every batch\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a bulk UPDATE to set all rows as deleted\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUse MERGE with an is_deleted flag and DELETE WHEN MATCHED AND source.is_deleted = true to apply deletes while preserving existing non-deleted records.\n\n## Why Other Options Are Wrong\n- Option A is correct; Option B ignores deletes, causing data to accumulate. Option C overwrites and loses history. Option D would affect all rows, not just targeted deletes.\n\n## Key Concepts\n- Delta MERGE for deletes\n- Tombstone handling in CDC scenarios\n- Idempotent streaming with deletes\n\n## Real-World Application\n- CDC from multiple sources where deletes must propagate to the downstream table.","diagram":null,"difficulty":"intermediate","tags":["Delta Lake","Databricks","CDC","MERGE","Kubernetes","AWS-S3","certification-mcq","domain-weight-22"],"channel":"databricks-data-engineer","subChannel":"incremental-processing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:51:28.484Z","createdAt":"2026-01-12 13:51:28"},{"id":"databricks-data-engineer-lakehouse-arch-1768210219223-0","question":"In Delta Live Tables, you want to enforce data quality on a dataset of employees by ensuring age is between 0 and 120 and that department_id exists in the departments dimension before loading into the Silver layer. Which mechanism should you use to declaratively enforce these rules within the pipeline?","answer":"[{\"id\":\"a\",\"text\":\"Use a Python UDF with a filter to drop bad rows.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use a try/except around the write operation to skip invalid rows.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Define 'expect' constraints on the DLT table definitions.\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Move quality checks into a separate nightly job.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C: Define 'expect' constraints on the DLT table definitions.\n\nDLT provides built-in data quality constraints called expects that let you declare validation rules as part of the pipeline. This makes quality checks auditable, repeatable, and tied to the data lineage.\n\n## Why Other Options Are Wrong\n- Option A: Using a Python UDF with a filter to drop bad rows is ad-hoc and bypasses structured quality definitions, making it harder to maintain and monitor.\n- Option B: try/except handling may drop or skip bad rows unpredictably and doesn't enforce ongoing quality guarantees.\n- Option D: A separate nightly job delays enforcement and breaks end-to-end data quality guarantees.\n\n## Key Concepts\n- Delta Live Tables expects constraints for data quality\n- Declarative data validation integrates with lineage and monitoring\n\n## Real-World Application\n- In an HR data pipeline, enforce age 0-120 and department_id validity via DLT expects to ensure downstream analytics always receive clean Silver layer data.","diagram":null,"difficulty":"intermediate","tags":["Databricks","Delta-Live-Tables","Auto Loader","Unity Catalog","AWS","S3","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T09:30:19.226Z","createdAt":"2026-01-12 09:30:19"},{"id":"databricks-data-engineer-lakehouse-arch-1768210219223-1","question":"You ingest JSON event data into Delta Lake using Auto Loader; new fields are added over time. Which Auto Loader setting enables automatic schema evolution by merging new columns into the target schema?","answer":"[{\"id\":\"a\",\"text\":\"cloudFiles.schemaEvolutionMode = mergeSchema\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"cloudFiles.inferColumnTypes = true\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"cloudFiles.schemaEvolutionMode = addNewColumns\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"spark.databricks.delta.autoMerge.enabled = true\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A: cloudFiles.schemaEvolutionMode = mergeSchema.\n\nThis Auto Loader setting enables schema evolution by merging new fields from the source into the target Delta table, avoiding a full table rewrite when new columns appear.\n\n## Why Other Options Are Wrong\n- Option B: inferColumnTypes may infer types but does not control schema evolution for new columns.\n- Option C: addNewColumns can add columns but does not guarantee schema merging behavior in all cases.\n- Option D: Delta auto-merge is not the mechanism for Auto Loader schema evolution.\n\n## Key Concepts\n- Auto Loader schema evolution\n- Merging new columns into Delta schema\n\n## Real-World Application\n- Ingesting evolving JSON event logs without manual schema updates; the schema evolves automatically as new fields appear.","diagram":null,"difficulty":"intermediate","tags":["Databricks","Auto Loader","Delta-Lake","AWS","S3","Terraform","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T09:30:19.798Z","createdAt":"2026-01-12 09:30:20"},{"id":"databricks-data-engineer-lakehouse-arch-1768210219223-2","question":"You want to restrict access to a Delta table by region in a multi-team environment using Databricks Unity Catalog. What is the recommended scalable approach to implement row-level access without duplicating data?","answer":"[{\"id\":\"a\",\"text\":\"Enable built-in row-level security in Delta Lake.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a view with a region predicate and grant access to the view instead of the base table.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Create separate tables per region and grant access to the appropriate copies.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Hard-code region filters in every SQL/BI query.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B: Create a view with a region predicate and grant access to the view instead of the base table.\n\nUnity Catalog does not provide a native per-row security feature; using views with embedded predicates is the scalable pattern to enforce row-level access while keeping a single source of truth.\n\n## Why Other Options Are Wrong\n- Option A: Delta Lake does not offer built-in per-row RLS; this would require custom workarounds.\n- Option C: Duplicating data is not scalable and increases storage and maintenance overhead.\n- Option D: Hard-coding filters in queries is brittle and does not enforce security consistently.\n\n## Key Concepts\n- Unity Catalog access control via views\n- Row-level access via predicate-based views\n\n## Real-World Application\n- Restricting customer data by region for regional sales teams without data duplication.","diagram":null,"difficulty":"intermediate","tags":["Databricks","Unity Catalog","RLS","Delta-Lake","AWS","S3","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T09:30:20.318Z","createdAt":"2026-01-12 09:30:20"},{"id":"databricks-data-engineer-lakehouse-arch-1768282062657-0","question":"Your streaming pipeline ingests daily JSON logs from S3 into a Delta Lake table. The schema evolves over time (new fields added, some nested fields change). You want fault-tolerant ingestion with minimal manual schema management and support for schema evolution. Which approach is best?","answer":"[{\"id\":\"a\",\"text\":\"Use Databricks Auto Loader with cloudFiles and a schemaLocation, enabling schema evolution and metadata tracking\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Read the JSON directly with spark.read.json in a streaming query, manually inferring schema\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Load data via JDBC from a relational database\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use COPY INTO regularly to bulk load data from S3\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Using Auto Loader with a schemaLocation enables automatic schema inference and evolution while tracking metadata for fault tolerance.\n\n## Why Other Options Are Wrong\n- B: Manual schema inference in streaming is error-prone and requires ongoing maintenance for evolution.\n- C: JDBC is for relational databases, not S3 JSON streaming.\n- D: COPY INTO is for bulk loads, not continuous streaming ingestion.\n\n## Key Concepts\n- Auto Loader for scalable streaming ingestion\n- Schema evolution in Delta Lake\n- Metadata tracking with schemaLocation\n\n## Real-World Application\n- Ensures a robust streaming pipeline that adapts to changing data with minimal manual intervention.","diagram":null,"difficulty":"intermediate","tags":["AWS","Kubernetes","Terraform","Databricks","Delta-Lake","Unity-Catalog","S3","ETL","Data-Governance","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:27:42.658Z","createdAt":"2026-01-13 05:27:43"},{"id":"databricks-data-engineer-lakehouse-arch-1768282062657-1","question":"To implement data quality and auditable ETL for both batch and streaming in Databricks, you want automated lineage, tests, and incremental processing. Which feature is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Delta Live Tables (DLT)\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Notebook-based scheduled jobs\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Unity Catalog masking policies\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Traditional SQL scripts executed via jobs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Delta Live Tables provides declarative ETL pipelines with built-in data quality expectations and automatic lineage, suitable for both batch and streaming.\n\n## Why Other Options Are Wrong\n- B: Not built-in data quality checks or lineage; harder to enforce consistency across pipelines.\n- C: Governance features, not ETL quality and lineage tooling.\n- D: Lacks automatic governance, testing, and incremental semantics.\n\n## Key Concepts\n- Declarative ETL with DLT\n- Data quality expectations\n- End-to-end lineage\n\n## Real-World Application\n- Enables auditable, maintainable pipelines across multiple data domains with minimal custom boilerplate.","diagram":null,"difficulty":"intermediate","tags":["AWS","Kubernetes","Terraform","Databricks","DLT","Unity-Catalog","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:27:43.188Z","createdAt":"2026-01-13 05:27:43"},{"id":"databricks-data-engineer-lakehouse-arch-1768282062657-2","question":"You need to share datasets across teams in a multi-workspace environment with strict access control and audit trails. The data resides in Delta Lake tables backed by cloud storage. Which approach ensures governance across workspaces?","answer":"[{\"id\":\"a\",\"text\":\"Use Unity Catalog with a centralized metastore and grant privileges at catalog/schema/table level; enable audit logging\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on object storage ACLs on the bucket\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Copy data into per-user buckets and manage access separately\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use cluster-level permissions only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Unity Catalog provides centralized governance with fine-grained access controls and audit capabilities across workspaces, meeting multi-team governance needs.\n\n## Why Other Options Are Wrong\n- B: Bucket ACLs are not sufficient for granular row/column access control or cross-workspace auditing.\n- C: Creates data duplication and drift; hard to maintain.\n- D: Cluster-level permissions do not provide end-to-end governance across catalogs/schemas/tables or audit trails.\n\n## Key Concepts\n- Unity Catalog governance\n- Fine-grained access control\n- Auditability across workspaces\n\n## Real-World Application\n- Enables compliant data sharing across data science and analytics teams with centralized policy enforcement.","diagram":null,"difficulty":"intermediate","tags":["AWS","Kubernetes","Terraform","Databricks","Unity-Catalog","S3","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:27:43.710Z","createdAt":"2026-01-13 05:27:43"},{"id":"databricks-data-engineer-lakehouse-arch-1768282062657-3","question":"A 100+ billion row Delta table is used for daily dashboards with queries on date and customer_id. Performance is slow. What is the best practice to optimize scans without rewriting queries?","answer":"[{\"id\":\"a\",\"text\":\"Run OPTIMIZE delta_table ZORDER BY (date_column)\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase driver memory only\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cache the entire table in memory on all clusters\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Repartition to thousands of partitions and re-write all data\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. OPTIMIZE with ZORDER BY the frequently filtered columns (e.g., date) colocates related data, significantly improving pruning for large tables.\n\n## Why Other Options Are Wrong\n- B: More memory may help marginally but does not address data layout and pruning.\n- C: Caching the entire table is impractical for multi-GB/TB tables and adds memory pressure.\n- D: Rewriting with thousands of partitions is costly and often unnecessary; proper ZORDER + partitioning suffices.\n\n## Key Concepts\n- Delta Lake OPTIMIZE\n- ZORDER optimization\n- Pruning for large datasets\n\n## Real-World Application\n- Speeds up dashboards by reducing scanned data dramatically without changing queries.","diagram":null,"difficulty":"intermediate","tags":["AWS","Kubernetes","Terraform","Databricks","Delta-Lake","Spark","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:27:43.897Z","createdAt":"2026-01-13 05:27:43"},{"id":"databricks-data-engineer-lakehouse-arch-1768282062657-4","question":"You have a Delta Live Table pipeline and a separate Databricks job that runs SQL transformations. You want to orchestrate end-to-end with dependencies and optional retries. Which approach is best?","answer":"[{\"id\":\"a\",\"text\":\"Use Databricks Workflows to orchestrate both Delta Live Tables pipelines and Jobs, with defined task dependencies and retries\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use a cron scheduler on a separate VM\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a single notebook to run both, without explicit dependencies\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use AWS Step Functions to orchestrate Databricks tasks, but only with external triggers\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Databricks Workflows provide native orchestration for Delta Live Tables and Jobs with defined task dependencies and retry policies, delivering cohesive end-to-end pipelines.\n\n## Why Other Options Are Wrong\n- B: External cron scheduling is brittle and lacks native integration with Databricks lineage and retries.\n- C: A single notebook cannot reliably model multi-task dependencies or retries across diverse workloads.\n- D: Step Functions can orchestrate Databricks, but it is less integrated for end-to-end Delta Live Tables and may complicate error handling.\n\n## Key Concepts\n- Databricks Workflows orchestration\n- Task dependencies and retries\n- Delta Live Tables integration\n\n## Real-World Application\n- Enables resilient, auditable pipelines spanning data ingestion, transformation, and analytics with minimal operational overhead.","diagram":null,"difficulty":"intermediate","tags":["AWS","Kubernetes","Terraform","Databricks","Workflows","DLT","certification-mcq","domain-weight-24"],"channel":"databricks-data-engineer","subChannel":"lakehouse-arch","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:27:44.078Z","createdAt":"2026-01-13 05:27:44"},{"id":"databricks-data-engineer-production-pipelines-1768239000045-0","question":"In a Databricks streaming pipeline ingesting from Kafka into Delta Lake, late-arriving data can arrive after the window. Which approach ensures late data is processed without duplication or data loss?","answer":"[{\"id\":\"a\",\"text\":\"Enable event-time watermark using withWatermark on the event time and use append mode for streaming\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Process all data in a single micro-batch and ignore late arrivals\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Disable checkpoints to reduce overhead\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Repartition to a single partition to preserve ordering\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because a watermark with withWatermark allows late arrivals to be considered in future micro-batches while avoiding duplicates in windowed aggregations. The other options fail to handle late data appropriately: b ignores late data, leading to data loss; c removing checkpoints undermines fault tolerance and can cause reprocessing issues; d repartitioning does not address late data and can degrade throughput.","diagram":null,"difficulty":"intermediate","tags":["Databricks","DeltaLake","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-16"],"channel":"databricks-data-engineer","subChannel":"production-pipelines","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:30:00.046Z","createdAt":"2026-01-12 17:30:00"},{"id":"databricks-data-engineer-production-pipelines-1768239000045-1","question":"To ensure reproducibility and isolation in a multi-stage Databricks data pipeline, which orchestration approach is best for production pipelines?","answer":"[{\"id\":\"a\",\"text\":\"Run all stages on a single long-lived cluster and reuse intermediate state\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use separate job clusters per notebook and orchestrate with Databricks Jobs\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Manually trigger notebooks from a central control notebook\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Schedule runs with an external cron and reuse the same Spark context\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct because separate job clusters per task provide isolation, predictable resource usage, and reproducible environments, while Databricks Jobs orchestrate dependencies and retries. The other options either couple tasks too tightly (a, c) or rely on external schedulers with shared state (d) which risks interference and drift.","diagram":null,"difficulty":"intermediate","tags":["Databricks","DeltaLake","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-16"],"channel":"databricks-data-engineer","subChannel":"production-pipelines","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:30:00.615Z","createdAt":"2026-01-12 17:30:01"},{"id":"databricks-data-engineer-production-pipelines-1768239000045-2","question":"Which feature best supports data quality checks and lineage visibility in Databricks production pipelines?","answer":"[{\"id\":\"a\",\"text\":\"Delta Lake constraints and statistics\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Databricks Jobs retry policy\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Delta Live Tables with built-in expectations and monitoring\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Unity Catalog permissions auditing\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption c is correct because Delta Live Tables (DLT) provides built-in data quality constraints (expectations) and monitoring, giving visibility into data lineage and pipeline health. The other options offer partial value: a helps with data characteristics but not end-to-end quality enforcement; b affects resilience, not quality; d focuses on governance rather than data quality and lineage evaluation.","diagram":null,"difficulty":"intermediate","tags":["Databricks","DeltaLiveTables","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-16"],"channel":"databricks-data-engineer","subChannel":"production-pipelines","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:30:01.150Z","createdAt":"2026-01-12 17:30:01"},{"id":"databricks-data-engineer-production-pipelines-1768239000045-3","question":"When writing streaming data into a Delta Lake table from a Databricks job, which setting enables automatic schema evolution to accommodate new fields without failing the write?","answer":"[{\"id\":\"a\",\"text\":\"Set mergeSchema to true on write to Delta Lake\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Predefine all potential schema changes and block new fields\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Disable schema enforcement on the Delta table\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create separate tables for each incoming schema version\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because enabling mergeSchema on write allows Delta Lake to evolutionarily merge new fields into the target table schema during streaming writes. The other options either prevent evolution or are impractical for streaming data flows.","diagram":null,"difficulty":"intermediate","tags":["Databricks","DeltaLake","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-16"],"channel":"databricks-data-engineer","subChannel":"production-pipelines","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:30:01.340Z","createdAt":"2026-01-12 17:30:01"},{"id":"databricks-data-engineer-production-pipelines-1768239000045-4","question":"In Databricks Jobs, which configuration provides automatic retries with backoff for transient failures in a production pipeline?","answer":"[{\"id\":\"a\",\"text\":\"Configure maxRetries and minRetryInterval on the job\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Implement a retry loop inside the notebook and sleep between attempts\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a fixed 3-minute retry interval with no backoff\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable retries to avoid masking failures\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because Databricks Jobs support automatic retries with configurable maxRetries and backoff behavior, enabling resilient execution without manual retry logic. The other options either require manual scripting (b), specify fixed backoff that may not scale with load (c), or remove resilience altogether (d).","diagram":null,"difficulty":"intermediate","tags":["Databricks","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-16"],"channel":"databricks-data-engineer","subChannel":"production-pipelines","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:30:01.520Z","createdAt":"2026-01-12 17:30:01"}],"subChannels":["data-governance","elt-spark","general","incremental-processing","lakehouse-arch","production-pipelines"],"companies":["Airbnb","Anthropic","Apple","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Google","Hashicorp","Microsoft","MongoDB","Netflix","Oracle","Scale Ai","Snap","Snowflake","Uber","Zoom"],"stats":{"total":33,"beginner":3,"intermediate":28,"advanced":2,"newThisWeek":33}}