{"questions":[{"id":"consul-associate-consul-architecture-1768158882932-0","question":"You have Consul with ACLs enabled in a multi-team environment. Team A's service must call Team B's service in the same datacenter, but you want to prevent Team A from calling any other services. Which mechanism should you configure to implement this policy?","answer":"[{\"id\":\"a\",\"text\":\"Define a global allow token for Team A and restrict others\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a service-level intention to allow Team A's service to call Team B's service and deny all other calls\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on Kubernetes NetworkPolicy to restrict intra-cluster calls\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Store policy in Vault and apply at runtime\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA service-level intention that explicitly allows Team A's service to call Team B's service while denying other calls enforces least privilege in the data plane under ACLs.\n\n## Why Other Options Are Wrong\n- Option A: A global allow undermines ACLs and violates least privilege.\n- Option C: Kubernetes NetworkPolicy is not a Consul ACL mechanism and doesn't govern Consul service mesh traffic.\n- Option D: Vault policies don't enforce in-service mesh authorization.\n\n## Key Concepts\n- Service Intentions\n- ACLs and least privilege\n- Source and destination scoping\n\n## Real-World Application\n- In a team-driven environment, define explicit intentions for service-to-service calls to prevent lateral movement and reduce blast radius.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:14:42.934Z","createdAt":"2026-01-11 19:14:43"},{"id":"consul-associate-consul-architecture-1768158882932-1","question":"In a two-datacenter Consul deployment with the OSS edition, which component is responsible for storing cluster state and distributing health data across servers?","answer":"[{\"id\":\"a\",\"text\":\"Client agents\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Server agents\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Vault sidecar proxies\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"DNS interface\",\"isCorrect\":false}]","explanation":"## Correct Answer\nServer agents maintain the Raft-based state and propagate health data to other servers, forming the cluster's source of truth. Client agents report health status but do not distribute cluster state.\n\n## Why Other Options Are Wrong\n- Option A: Client agents do not hold the authoritative state.\n- Option C: Vault sidecar is unrelated to Consul cluster state.\n- Option D: DNS interface is for name resolution, not cluster state storage.\n\n## Key Concepts\n- Raft-based consensus\n- Health data distribution\n- Server vs client roles\n\n## Real-World Application\n- Ensures reliable service discovery and health information propagation across datacenters.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:14:43.404Z","createdAt":"2026-01-11 19:14:43"},{"id":"consul-associate-consul-architecture-1768158882932-2","question":"What is the recommended server deployment pattern to ensure quorum and high availability in a two-datacenter Consul deployment?","answer":"[{\"id\":\"a\",\"text\":\"Run at least 3 servers per datacenter to maintain quorum in each DC\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Run 2 servers per datacenter\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Run a single multi-datacenter server\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use only client agents and rely on external storage\",\"isCorrect\":false}]","explanation":"## Correct Answer\nRun at least 3 servers per datacenter to maintain a quorum and tolerate a single server failure within each DC; using odd numbers per DC is a best practice for Raft-based consensus.\n\n## Why Other Options Are Wrong\n- Option B: 2 servers per DC cannot sustain a single failure in that DC.\n- Option C: There is no single multi-datacenter server; Consul uses per-DC server pools.\n- Option D: Client agents are not sufficient to maintain cluster state.\n\n## Key Concepts\n- Quorum and Raft consensus\n- High availability per datacenter\n- Odd-numbered server counts\n\n## Real-World Application\n- Helps ensure service discovery remains available during node failures across both DCs.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:14:43.880Z","createdAt":"2026-01-11 19:14:43"},{"id":"consul-associate-consul-architecture-1768281939780-0","question":"You operate two data centers, DC-A and DC-B, each running a separate Consul server cluster. You want cross-datacenter service discovery with minimal inter-datacenter latency and consistent health state across DCs. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Enable WAN gossip federation by joining the two server clusters with the -wan flag\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Register all services in a single central server and proxy local requests\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on DNS round-robin across DCs without catalog replication\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Manual replication of service catalogs via external scripts\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because WAN gossip federation enables cross-datacenter catalog replication and cross-DC service discovery with consistent health state.\n\n## Why Other Options Are Wrong\n- B: Consul doesn’t support a single central server across DCs; per-DC clusters with WAN federation is the correct pattern.\n- C: DNS round-robin across DCs does not guarantee catalog consistency or health-state synchronization and can yield stale results.\n- D: Manual replication is not supported by Consul and is error-prone.\n\n## Key Concepts\n- WAN gossip federation\n- cross-datacenter service discovery\n- catalog replication\n\n## Real-World Application\n- Use WAN federation when you must have consistent service registration and health state across multiple data centers, enabling borderless service discovery for multi-DC deployments.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:25:39.781Z","createdAt":"2026-01-13 05:25:40"},{"id":"consul-associate-consul-architecture-1768281939780-1","question":"A service that cannot expose an HTTP endpoint uses Consul for health checks. You want to ensure a non-HTTP service can still participate in health checks and be quickly marked unhealthy when it fails. Which check type and mechanism accomplish this?","answer":"[{\"id\":\"a\",\"text\":\"TTL health check with a periodic heartbeat to PUT /agent/check/pass for the check_id\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"HTTP health check pointing to localhost:port/health\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Script-based check that pings a local socket\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"DNS TXT-based check that resolves a status record\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because TTL checks allow non-HTTP services to participate by requiring a periodic heartbeat via the agent API to mark the check as passing; this gives a reliable liveness signal without needing an HTTP endpoint.\n\n## Why Other Options Are Wrong\n- B: HTTP checks require an HTTP endpoint, which is not available here.\n- C: Script-based checks can monitor non-HTTP services but require implementing and maintaining a heartbeat mechanism; TTL checks provide a standardized approach.\n- D: DNS-based checks are not a supported health-check mechanism in the Consul catalog.\n\n## Key Concepts\n- TTL health checks\n- Check TTL heartbeat (PUT /agent/check/pass)\n- non-HTTP service health monitoring\n\n## Real-World Application\n- Use TTL checks for legacy or non-HTTP services to integrate health状态 into Consul without exposing HTTP endpoints.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:25:40.319Z","createdAt":"2026-01-13 05:25:40"},{"id":"consul-associate-consul-architecture-1768281939780-2","question":"You want to enable service-to-service encryption for east-west traffic between services in a Kubernetes cluster using Consul Connect. To allow external clients to reach services, you also want a gateway that terminates TLS for the outside world. Which configuration best enables a mesh gateway for external traffic?","answer":"[{\"id\":\"a\",\"text\":\"Enable a Mesh Gateway by deploying a dedicated gateway proxy and configuring a mesh_gateway in the Consul data center\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on per-service sidecars and expose services via Kubernetes Ingress only\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a global TLS terminator external load balancer without Connect integration\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable TLS to simplify traffic between services\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because a Mesh Gateway provides TLS termination and connectivity for external clients into the Consul Connect mesh, enabling secure east-west and north-south traffic in a Kubernetes-integrated setup.\n\n## Why Other Options Are Wrong\n- B: Ingress alone does not integrate with Consul Connect mesh TLS and border traffic shaping.\n- C: A standalone TLS terminator without Connect integration won’t enforce mutual TLS for mesh services or manage certificates inside the mesh.\n- D: Disabling TLS would remove the security guarantees of Connect and is not acceptable for a meshed environment.\n\n## Key Concepts\n- Consul Connect Mesh Gateway\n- TLS termination for external traffic\n- Kubernetes integration with Consul\n\n## Real-World Application\n- Use a Mesh Gateway to expose internal services securely to external clients while preserving mTLS within the mesh.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:25:40.838Z","createdAt":"2026-01-13 05:25:40"},{"id":"consul-associate-consul-architecture-1768281939780-3","question":"In a large Consul deployment, you want your clients to watch for catalog changes efficiently without polling frequently. Which approach correctly uses blocking queries to watch for changes?","answer":"[{\"id\":\"a\",\"text\":\"Use long-polling with index parameter and a wait time (eg. wait=10m) to receive updates only when there are changes\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Poll the catalog every few seconds regardless of changes\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Query the catalog once at startup and never again\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a separate external monitoring service instead of Consul's API\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because blocking queries leverage the index and wait parameters to push updates only when there are changes, reducing unnecessary traffic and latency.\n\n## Why Other Options Are Wrong\n- B: Frequent polling wastes bandwidth and increases load on the catalog service.\n- C: A single startup query misses subsequent changes entirely.\n- D: External monitoring can complement but does not replace the built-in blocking query mechanism for real-time catalog changes.\n\n## Key Concepts\n- Blocking queries\n- index and wait parameters\n- efficient change notification\n\n## Real-World Application\n- Use blocking queries in long-running watchers to scale service discovery in large clusters.","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:25:41.035Z","createdAt":"2026-01-13 05:25:41"},{"id":"consul-associate-consul-architecture-1768281939780-4","question":"You have a TTL-based health check configured for a service. After a temporary network partition, the TTL heartbeat stops. To ensure the service is correctly removed if the partition persists, which setting should you configure on the service registration?","answer":"[{\"id\":\"a\",\"text\":\"DeregisterCriticalServiceAfter to automatically deregister the service after a period of sustained failure\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase the TTL to a longer duration\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable periodic re-registration every minute regardless of health\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable TTL checks and switch to HTTP checks\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because DeregisterCriticalServiceAfter ensures a service that remains critical for a sustained period is automatically deregistered, preventing stale unhealthy services from lingering in the catalog.\n\n## Why Other Options Are Wrong\n- B: Simply increasing TTL delays deregistration and hides the failure longer.\n- C: Automatic re-registration without confirming health can reintroduce unhealthy services.\n- D: Switching to HTTP checks may not be possible for TTL-based checks or may require considerable rework; the deregistration setting directly addresses the failure mode.\n\n## Key Concepts\n- DeregisterCriticalServiceAfter\n- TTL health checks lifecycle\n- automatic cleanup of unhealthy services\n\n## Real-World Application\n- Use deregistration after sustained critical health to keep the catalog accurate during transient network issues.","diagram":null,"difficulty":"intermediate","tags":["Consul","Terraform","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-architecture","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:25:41.223Z","createdAt":"2026-01-13 05:25:41"},{"id":"consul-associate-consul-operations-1768256764516-0","question":"A service registered in Consul experiences intermittent health issues due to network blips, causing it to flip between healthy and unhealthy. Which configuration best ensures the service is automatically deregistered after it remains unhealthy for a defined period?","answer":"[{\"id\":\"a\",\"text\":\"Increase the health check interval to 60s\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Set deregister_critical_service_after to 10m\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use TTL-based checks with regular heartbeats\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable health checks during blips\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because deregister_critical_service_after defines the duration a service can remain in a critical state before it is automatically deregistered, which helps prevent routing to consistently unhealthy or flapping instances.\n\n## Why Other Options Are Wrong\n- Option A: Increasing the interval slows detection of unhealthy state and can prolong routing to unhealthy instances.\n- Option C: TTL checks require the service to heartbeat regularly; if heartbeats fail, the service will be deregistered or marked unhealthy, which may not align with transient blips.\n- Option D: Disabling health checks removes visibility into health state and can hide real failures.\n\n## Key Concepts\n- deregister_critical_service_after\n- health check intervals and flapping\n- service lifecycle in Consul\n\n## Real-World Application\nUsed to stabilize service routing during intermittent network issues by automatically removing unhealthy services after a defined window.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:26:04.517Z","createdAt":"2026-01-12 22:26:04"},{"id":"consul-associate-consul-operations-1768256764516-1","question":"You operate Consul in two data centers, dc-us and dc-eu. A service registered in dc-us must be discoverable from a client in dc-eu for failover testing. What is the correct approach to enable cross-datacenter service discovery?","answer":"[{\"id\":\"a\",\"text\":\"Manually replicate the service catalog to dc-eu\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Configure WAN gossip connectivity and use retry_join_wan to connect the two DCs\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use DNS to query remote DC's services\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use the KV store replication to mirror service entries\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because cross-datacenter service discovery relies on Consul's WAN gossip federation. You configure WAN connectivity (e.g., retry_join_wan) so agents in both DCs can learn about services in the other DC.\n\n## Why Other Options Are Wrong\n- Option A: Manual replication is not scalable and not how Consul operates in multi-DC setups.\n- Option C: DNS can help in some scenarios but does not automatically propagate service availability across DCs for dynamic discovery.\n- Option D: KV replication does not propagate service catalog entries.\n\n## Key Concepts\n- WAN gossip / multi-datacenter replication\n- retry_join_wan configuration\n- cross-datacenter service discovery\n\n## Real-World Application\nEnables automated failover testing and DR drills by allowing services in one DC to be discovered from another DC through the Consul WAN federation.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:26:05.057Z","createdAt":"2026-01-12 22:26:05"},{"id":"consul-associate-consul-operations-1768256764516-2","question":"To ensure all inter-service communications within a mesh are encrypted with mutual TLS in Consul Connect on Kubernetes, which step is essential?","answer":"[{\"id\":\"a\",\"text\":\"Deploy only TLS certificates to the applications and bypass sidecars\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Consul Connect, install sidecar proxies for each service, and configure a CA to issue mTLS certificates\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Disable TLS for internal traffic and rely on network ACLs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Hard-code certificates into each application container\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Consul Connect relies on sidecar proxies (e.g., Envoy) to terminate and re-encrypt mTLS traffic, with a CA issuing certificates for mutual authentication.\n\n## Why Other Options Are Wrong\n- Option A: Bypassing sidecars disables the automatic mTLS mechanism that Connect provides.\n- Option C: Relying on network ACLs does not provide mutual TLS encryption for service traffic.\n- Option D: Hard-coding certificates is brittle and defeats the certificate-management benefits of the mesh.\n\n## Key Concepts\n- Consul Connect and sidecar proxies\n- mTLS in a service mesh\n- Certificate Authority configuration\n\n## Real-World Application\nProvides encrypted, identity-driven communication between microservices without modifying application code.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:26:05.543Z","createdAt":"2026-01-12 22:26:05"},{"id":"consul-associate-consul-operations-1768256764516-3","question":"To achieve end-to-end tracing across services managed by Consul Connect on Kubernetes, which approach best enables distributed tracing integration?","answer":"[{\"id\":\"a\",\"text\":\"Rely solely on Consul health probes for tracing data\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Envoy sidecars with a tracing backend (Jaeger/Zipkin/Datadog) configured and enable tracing in the proxies\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use the KV store to propagate trace context between services\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use DNS-based lookups to retrieve traces from a centralized server\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Consul Connect commonly uses Envoy sidecars that can be configured to emit trace data to backends like Jaeger, Zipkin, or Datadog, enabling end-to-end distributed tracing across services.\n\n## Why Other Options Are Wrong\n- Option A: Health probes do not provide tracing data.\n- Option C: KV store is not designed for tracing context propagation.\n- Option D: DNS lookups do not transport trace data.\n\n## Key Concepts\n- Distributed tracing in service meshes\n- Envoy integration with tracing backends\n- Observability in Consul Connect\n\n## Real-World Application\nEnables developers to correlate requests across multiple microservices, improving root-cause analysis and performance tuning.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","Kubernetes","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:26:05.714Z","createdAt":"2026-01-12 22:26:05"},{"id":"consul-associate-consul-operations-1768256764516-4","question":"You want to grant a specific service read access to a KV path, for example '/config/app1/', using Consul ACLs. Which policy statement correctly defines this permission?","answer":"[{\"id\":\"a\",\"text\":\"Key prefix \\\"/config/app1/\\\" with read permission\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Key prefix \\\"/config/app1/\\\" with write permission\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Key prefix \\\"/config/app2/\\\" with read permission\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Key prefix \\\"/\\\" with read permission\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because ACL policies grant access by key prefixes and the specified permission (read) to restrict access to that subset of the KV store.\n\n## Why Other Options Are Wrong\n- Option B provides write access, which is broader than requested.\n- Option C targets a different path and would not grant access to /config/app1/.\n- Option D grants read access to all keys, violating the principle of least privilege.\n\n## Key Concepts\n- ACLs and policy definitions\n- key_prefix access control\n- least privilege in KV access\n\n## Real-World Application\nEnables enforcing granular access controls for configuration data stored in Consul KV.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:26:05.878Z","createdAt":"2026-01-12 22:26:05"},{"id":"consul-associate-consul-security-1768242892288-0","question":"To enforce per-service access control to Consul's HTTP APIs using ACLs, which configuration best ensures each service uses an identity-based token with least privilege?","answer":"[{\"id\":\"a\",\"text\":\"Disable ACLs and rely on Kubernetes RBAC\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Consul ACLs, create a dedicated token per service with tailored policies, and provision each service with its own token\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a single global admin token for all services\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Store per-service tokens in application configuration and rotate manually without using Consul policies\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because enabling ACLs and issuing per-service tokens with tailored policies enforces identity-based access control and the principle of least privilege for the Consul API.\n\n## Why Other Options Are Wrong\n- A: ACLs are the standard mechanism for Consul API authorization; relying on Kubernetes RBAC alone does not protect Consul API access.\n- C: A single global admin token creates a single-point-of-compromise and breaks least-privilege guarantees.\n- D: Storing tokens outside of Consul policies bypasses the policy engine and undermines centralized access control.\n\n## Key Concepts\n- Consul ACLs and tokens\n- Policy-based access control\n- Least privilege\n\n## Real-World Application\n- Deploy per-service tokens during service onboarding and inject them securely (e.g., via CI/CD secrets). Enforce policies that only permit required API actions for each service.","diagram":null,"difficulty":"intermediate","tags":["Consul","Security","Kubernetes","AWS","Terraform","TLS","RBAC","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:34:52.289Z","createdAt":"2026-01-12 18:34:52"},{"id":"consul-associate-consul-security-1768242892288-1","question":"You need to audit all Consul API interactions and KV store access for compliance. Which approach provides reliable, tamper-evident audit data?","answer":"[{\"id\":\"a\",\"text\":\"Enable an audit backend (for example file-based or syslog) in Consul and direct audit events to a secure log\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on standard agent logs and parse them for security events\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a third-party proxy to mirror API calls to a SIEM\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Audit is not supported in OSS; rely on metrics only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Consul supports audit backends (e.g., file-based, syslog) that provide tamper-able, stored records of API calls and KV access.\n\n## Why Other Options Are Wrong\n- B: Standard logs are useful but not guaranteed to be tamper-evident or comprehensive for compliance needs.\n- C: Proxying can help visibility but does not replace native audit backends and may miss API-level details.\n- D: OSS does support audit backends; assuming otherwise misses a core security capability.\n\n## Key Concepts\n- Audit backends\n- Tamper-evident logging\n- Compliance requirements\n\n## Real-World Application\n- Configure an audit backend and forward logs to a SIEM or a secure store to meet regulatory retention and tamper-evidence requirements.","diagram":null,"difficulty":"intermediate","tags":["Consul","Security","Audit","Kubernetes","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:34:52.764Z","createdAt":"2026-01-12 18:34:53"},{"id":"consul-associate-consul-security-1768242892288-2","question":"Which mechanism in Consul is designed to enforce which services may communicate with which within a mesh, independent of network topology?","answer":"[{\"id\":\"a\",\"text\":\"Service intentions\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"ACL tokens\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Namespace isolation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Service metadata labels\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because service intentions explicitly define which services are allowed to communicate, enforcing authorization at the mesh level rather than relying solely on network topology.\n\n## Why Other Options Are Wrong\n- B: ACL tokens control API access, not service-to-service connectivity within the mesh.\n- C: Namespace isolation helps segmentation but does not provide dynamic, service-to-service communication policies.\n- D: Metadata labels do not enforce connection authorization in the mesh.\n\n## Key Concepts\n- Service intentions\n- East–west traffic control\n- Mesh security model\n\n## Real-World Application\n- Define intentions such as allow {service-A} to connect to {service-B} and enforce via Connect proxies.\n","diagram":null,"difficulty":"intermediate","tags":["Consul","Service Mesh","Kubernetes","IAM","TLS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:34:53.248Z","createdAt":"2026-01-12 18:34:53"},{"id":"consul-associate-consul-security-1768242892288-3","question":"During a rolling upgrade of TLS certificates in Consul Connect, what is the recommended approach to rotate certificates with minimal downtime?","answer":"[{\"id\":\"a\",\"text\":\"Perform rolling certificate rotation by updating a subset of agents at a time, validating in-flight calls, then proceeding\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rotate certificates on all agents simultaneously to finish quickly\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Restart the entire cluster after rotation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Turn off TLS and rotate later\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because a staged, rolling rotation minimizes risk and downtime by validating new credentials in small batches before proceeding.\n\n## Why Other Options Are Wrong\n- B: Simultaneous rotation can cause widespread disruption if issues arise.\n- C: A full cluster restart is disruptive and unnecessary for certificate rotation.\n- D: TLS should remain enabled to maintain security; postponing rotation increases risk.\n\n## Key Concepts\n- Certificate rotation strategy\n- Zero-downtime upgrades\n- Live validation\n\n## Real-World Application\n- Use a controlled rollout to rotate CA/leaf certificates, monitoring for errors before expanding the scope.","diagram":null,"difficulty":"intermediate","tags":["Consul","Security","TLS","Kubernetes","AWS","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:34:53.412Z","createdAt":"2026-01-12 18:34:53"},{"id":"consul-associate-consul-security-1768242892288-4","question":"In a multi-data-center deployment, which configuration ensures encryption in transit for all Consul server-client RPC and Connect sidecar traffic?","answer":"[{\"id\":\"a\",\"text\":\"Enable TLS for server RPC, client RPC, and Connect with a configured CA, and enforce verify_incoming and verify_outgoing\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely solely on firewall rules between data centers\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use SSH tunnels for inter-data-center traffic\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable TLS and rely on VPN-only transport\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because enabling TLS for all RPC paths and Connect with a CA, along with verify_incoming/verify_outgoing, provides end-to-end encryption across data centers.\n\n## Why Other Options Are Wrong\n- B: Firewalls alone do not encrypt traffic and may not cover all paths consistently.\n- C: SSH tunnels add complexity and are not scalable for all RPC and sidecar traffic.\n- D: VPNs do not replace per-path TLS verification within Consul's control plane and mesh.\n\n## Key Concepts\n- TLS in transit for RPC and Connect\n- Cross-DC security posture\n- CA-based mutual authentication\n\n## Real-World Application\n- Configure a single CA, enable TLS for server and client RPC, enable Connect mTLS, and verify settings across all DCs to maintain consistent encryption.","diagram":null,"difficulty":"intermediate","tags":["Consul","Security","TLS","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"consul-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:34:53.580Z","createdAt":"2026-01-12 18:34:53"},{"id":"q-1027","question":"You're running a mixed Consul Connect mesh with Kubernetes services in DC1 and VM-based services in DC2. A new API service in DC1 calls a legacy VM backend behind a firewall via a mesh gateway, but TLS handshakes intermittently fail after a CA rotation. Propose a zero-downtime plan to diagnose, implement automatic CA rotation, and validate end-to-end, including config changes, monitoring, and rollback steps?","answer":"Plan to diagnose certificate chain mismatches, verify trust anchors on both sides, check mesh gateway TLS config and sidecar logs, and audit CA rotation events. Implement automatic CA rotation with sh","explanation":"## Why This Is Asked\n\nTests ability to design robust TLS CA rotation across mixed environments (Kubernetes and VM-backed services) with visibility into failures and rollback.\n\n## Key Concepts\n\n- Consul Connect TLS and CA rotation across datacenters\n- Mesh gateway behavior with mixed environments\n- Zero-downtime rotation and safe rollback\n- Observability for certificate issuance and handshake failures\n\n## Code Example\n\n```javascript\n// Pseudo-config: rotation window\n{\n  \"ca\": {\n    \"rotation\": {\n      \"enabled\": true,\n      \"rotationWindow\": \"15m\",\n      \"gracePeriod\": \"5m\"\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you validate rotation safety using canary deployments?\n- What metrics and alerts would confirm successful rotation without downtime?","diagram":null,"difficulty":"advanced","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","LinkedIn","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T19:40:06.222Z","createdAt":"2026-01-12T19:40:06.222Z"},{"id":"q-1178","question":"Across a tri-cloud Consul Connect mesh, a new microservice 'payments-api' in namespace 'payments' must reach a legacy data service 'orderdb' in namespace 'legacy' via a mesh gateway. Propose an end-to-end pattern that enforces strict identity via namespace-scoped Intention defaults, per-service tokens, and gateway ACLs, including resource definitions, deployment steps, and rollback plan?","answer":"Implement a default-deny policy per namespace, plus explicit Intention ACLs and a gateway ACL for payments→legacy. Create service tokens scoped to payments/payments-api and legacy/orderdb with least p","explanation":"## Why This Is Asked\n\nTests cross-namespace isolation and per-service identity in a multi-cloud Consul Connect mesh. It explores practical enforcement of Intention defaults, namespace-bound policies, and gateway ACLs—beyond single-namespace ACLs or in-cluster sidecars.\n\n## Key Concepts\n\n- Namespace-scoped policies with default-deny\n- Intention-based access across namespaces\n- Gateway ACLs and TLS certificate rotation\n- Canary deployment and rollback procedures\n\n## Code Example\n\n```bash\nconsul intention create payments/payments-api legacy/orderdb allow\n```\n\n```hcl\nnamespace \"payments\" {\n  service \"payments-api\" { capabilities = [\"read\",\"write\"] }\n  service \"orderdb\" { capabilities = [\"read\"] }\n}\n```\n\n```bash\n# TLS rotation for gateway\nconsul tls rotate --name payments-gateway-tls\n```\n\n## Follow-up Questions\n\n- How would you monitor and alert for misconfigurations in namespace-scoped Intention policies?\n- What deployment safeguards would you add to prevent downtime during TLS rotation?","diagram":null,"difficulty":"intermediate","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","DoorDash","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:41:32.453Z","createdAt":"2026-01-13T03:41:32.453Z"},{"id":"q-1293","question":"In a hybrid setup with Consul across two Kubernetes clusters (AWS) and VM-based services on-prem, how would you design cross-cluster service authentication and discovery using Consul Connect with mesh gateways, Namespaces, and ACLs to enforce zero-trust policy and automatic token rotation while preserving DNS-based discovery?","answer":"Use a shared Connect CA with per-namespace roles, assign each service a least-privilege ACL, and deploy dedicated mesh gateways per cluster to terminate mTLS and proxy cross-cluster traffic. Bind Vaul","explanation":"## Why This Is Asked\nTests ability to architect cross-cluster service mesh with strong isolation, automation, and observability.\n\n## Key Concepts\n- Mesh gateways for cross-cluster traffic\n- Namespaces and per-service ACLs\n- Central CA and automatic token rotation (Vault/Consul)\n- DNS federation across clusters\n- Telemetry and auditing\n\n## Code Example\n```yaml\n# Vault policy for Consul tokens\npath \"consul/roles/*\" {\n  capabilities = [\"read\",\"update\",\"create\",\"delete\",\"list\"]\n}\n```\n\n```json\n{\n  \"connect\": { \"enabled\": true, \"meshGateway\": { \"enabled\": true } }\n}\n```\n\n## Follow-up Questions\n- What failure modes occur if mesh gateway TLS certs expire?\n- How would you test token rotation without service downtime?","diagram":"flowchart TD\n  Hybrid[Hybrid Mesh] --> GatewayAWS[Mesh Gateway - AWS Cluster]\n  Hybrid --> GatewayOnprem[Mesh Gateway - On-Prem]\n  GatewayAWS --> ServiceA[Service A]\n  GatewayOnprem --> ServiceB[Service B]\n  ServiceA --> Vault[Token Rotation via Vault]\n  ServiceB --> Vault","difficulty":"advanced","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:38:22.855Z","createdAt":"2026-01-13T08:38:22.855Z"},{"id":"q-880","question":"In a Consul Connect-enabled dev cluster, two services run in namespace dev: 'reviews' and 'ratings'. You want to enforce that only reviews can call ratings via the mesh, with all other cross-service calls denied by default. Describe the minimal service-defaults and service-intentions changes needed, and how you would verify using a small client container in dev?","answer":"Configure a default deny for cross-service traffic in the dev mesh, then add an intention allowing only source reviews to access destination ratings. Validate by deploying a small client in dev and cu","explanation":"## Why This Is Asked\nTests understanding of default deny, service intentions, and basic mesh validation in a beginner-friendly setup.\n\n## Key Concepts\n- Service defaults\n- Service intentions\n- Mesh access control\n- Basic validation\n\n## Code Example\n```javascript\n// conceptual minimal intention (note: actual syntax varies by version)\nservice_intentions {\n  source = \\\"reviews\\\"\n  destination = \\\"ratings\\\"\n  action = \\\"allow\\\"\n}\n```\n\n## Follow-up Questions\n- How would you extend this if ratings is consumed by another service in the same namespace?\n- How do you test failure scenarios when the default deny blocks legitimate paths?","diagram":"flowchart TD\n  A[Dev Namespace] --> B[Default Deny]\n  B --> C{Intentions}\n  C --> D[reviews -> ratings: allow]\n  D --> E[Ratings service accessible]\n","difficulty":"beginner","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:59:13.055Z","createdAt":"2026-01-12T13:59:13.055Z"},{"id":"q-919","question":"You're operating a multi-datacenter Consul Connect mesh. A new API service in DC1 must reach a legacy monolith in DC2 that cannot run a sidecar. Design a cross-datacenter connectivity pattern using a mesh gateway, per-service Intentions with explicit allow rules, and TLS credential rotation. Include resource definitions, deployment steps, and rollback plan?","answer":"Configure a mesh gateway in DC2 for legacy-monolith and expose it as legacy-monolith-gw. In DC1, create a service-resolution for legacy-monolith via the gateway, and an Intentions rule from api to leg","explanation":"## Why This Is Asked\nThis question tests practical cross-datacenter connectivity with Consul Connect, mesh gateways, and per-service Intentions, including cross-DC identity and TLS rotation.\n\n## Key Concepts\n- Mesh gateway\n- Cross-DC Intentions\n- mTLS with Consul CA\n- MeshGateway routing and resolution\n- Rollback and testing strategies\n\n## Code Example\n```yaml\n# policy sketch\nservice_defaults:\n  protocol: http\n  mesh_gateway: true\n\nintentions:\n  - source: api.dc1\n    destination: legacy-monolith.dc2\n    action: allow\n    via_gateway: legacy-monolith-gw\n```\n\n## Follow-up Questions\n- What if legacy-monolith-gw fails? How to fail closed?\n- How would you verify TLS rotation and revocation in production?\n","diagram":null,"difficulty":"advanced","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Hugging Face","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:31:19.737Z","createdAt":"2026-01-12T15:31:19.737Z"},{"id":"q-999","question":"Design a cross-datacenter Consul Connect pattern in a three-datacenter setup where api-service.dc1 must reach legacy-db.dc3 (no sidecar). Use a MeshGateway to bridge DC1↔DC3, per-service Intentions with explicit allow rules, and TLS credential rotation. Include concrete resource definitions, deployment steps, and a rollback plan?","answer":"Deploy a MeshGateway in DC2 to bridge DC1 API -> DC3 legacy DB. Intentions: allow api-service.dc1 to legacy-db.dc3; default deny. TLS: use Vault PKI for short-lived certs (e.g., 24h) and auto-rotate, ","explanation":"## Why This Is Asked\nTests cross-datacenter connectivity patterns, mesh gateway usage, per-service Intentions, and TLS rotation with rollback.\n\n## Key Concepts\n- MeshGateway enables cross-DC traffic without sidecars on the destination.\n- Per-service Intentions grant explicit access between api-service.dc1 and legacy-db.dc3.\n- TLS rotation ensures short-lived certificates; Vault PKI can automate issuance and revocation.\n- Rollback requires revoking certs, removing gateway/config, and validating isolation remains.\n\n## Code Example\n```yaml\n# Pseudo resource definitions (Consul Connect-style)\nMeshGateway:\n  name: dc2-dc1-dc3-gw\n  datacenters: [dc1, dc3]\n  tls:\n    issuer: vault-pki\nIntentions:\n  - source: api-service.dc1\n    destination: legacy-db.dc3\n    action: allow\n  - source: api-service.dc1\n    destination: '*'\n    action: deny\n```\n\n## Follow-up Questions\n- How would you monitor certificate expiry and rotate proactively?\n- What failure modes could break cross-DC routing and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["consul-associate"],"channel":"consul-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Salesforce","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:42:08.193Z","createdAt":"2026-01-12T18:42:08.193Z"},{"id":"consul-associate-service-discovery-1768195840079-0","question":"In a Consul-based service discovery setup, you want DNS responses to reflect only healthy instances of a service and automatically remove unhealthy instances after a failure. Which combination of checks and settings achieves this most reliably?","answer":"[{\"id\":\"a\",\"text\":\"TTL health check with TTL 15s and deregister_critical_service_after 2m\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"HTTP health check on /health with deregister_critical_service_after 1m\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"TCP health check on port 8080 with deregister_critical_service_after 2m\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Script-based health check with a 30s interval and TTL 60s\",\"isCorrect\":false}]","explanation":"## Correct Answer\nHTTP health checks tied to a real application readiness endpoint provide a reliable signal for DNS-based discovery, and configuring deregister_critical_service_after to 1m ensures unhealthy instances are removed promptly. \n\n## Why Other Options Are Wrong\n- TTL health checks require regular heartbeats; if heartbeats are delayed or missed, there can be false positives or slower removal, making discovery less reliable. \n- TCP checks only verify port availability and do not confirm application readiness, which can leave unhealthy instances discoverable. \n- Script-based checks with TTLs introduce complexity and can be brittle without explicit app-level health signals.\n\n## Key Concepts\n- Health checks affect DNS-based service discovery\n- deregister_critical_service_after controls automatic deregistration after failure\n\n## Real-World Application\n- For critical services, prefer HTTP(s) health checks on a dedicated health endpoint and set deregister_critical_service_after to quickly remove unhealthy instances from DNS results.","diagram":null,"difficulty":"intermediate","tags":["Consul","Service Discovery","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:30:40.081Z","createdAt":"2026-01-12 05:30:40"},{"id":"consul-associate-service-discovery-1768195840079-1","question":"In a Consul Connect-enabled cluster, when mTLS is enforced, how are TLS certificates managed and what is the effect on service discovery?","answer":"[{\"id\":\"a\",\"text\":\"Each client uses certificates issued by the built-in Consul CA for mTLS; discoveries remain unchanged.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Services bypass TLS for internal comms to reduce latency.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"TLS certificates are manually managed by operators and injected via sidecars.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"TLS relies on Vault-only CA integration; discovery uses reconfigured endpoints.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nWhen mTLS is enabled in Consul Connect, sidecars obtain short-lived certificates from Consul's built-in CA to establish mTLS within the mesh; service discovery itself remains unchanged from the client’s perspective.\n\n## Why Other Options Are Wrong\n- B is incorrect because mTLS is enforced; TLS is not bypassed for internal communication. \n- C is incorrect because operator-manual certificate distribution is not how Connect typically operates; it automates certificate provisioning.\n- D is incorrect because Vault integration is optional and not a requirement for mTLS to function; the built-in CA handles certificates for most use cases.\n\n## Key Concepts\n- Consul Connect mTLS uses a CA to issue short-lived certificates\n- Sidecars handle TLS termination, leaving service discovery semantics intact\n\n## Real-World Application\n- You get encrypted, identity-aware service-to-service communication without manual cert management and with seamless discovery.","diagram":null,"difficulty":"intermediate","tags":["Consul","Service Discovery","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:30:40.431Z","createdAt":"2026-01-12 05:30:40"},{"id":"consul-associate-service-discovery-1768195840079-2","question":"In an ACL-enabled Consul cluster, if a client uses an API token that lacks read permission on the service catalog and makes a request to /v1/catalog/service/web, what is the likely result?","answer":"[{\"id\":\"a\",\"text\":\"The API returns an empty list\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"The API returns 403 Forbidden due to insufficient permissions\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"The API returns 404 Not Found\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"The API returns 500 Internal Server Error due to authentication failure\",\"isCorrect\":false}]","explanation":"## Correct Answer\nIf the token does not have read permission on the service catalog, the API call is denied with a 403 Forbidden due to ACL enforcement.\n\n## Why Other Options Are Wrong\n- A is incorrect because ACLs deny access rather than silently returning no data. \n- C is incorrect because lack of permission does not imply a missing resource; it’s an authorization denial. \n- D is incorrect because the error is not a server failure but an explicit authorization failure.\n\n## Key Concepts\n- ACLs enforce permissions on API endpoints\n- /v1/catalog/service/* requires appropriate read policy\n\n## Real-World Application\n- Ensure tokens have least-privilege policies and validate via test calls before deployment to avoid unauthorized access errors.","diagram":null,"difficulty":"intermediate","tags":["Consul","Service Discovery","Kubernetes","AWS","Terraform","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:30:40.776Z","createdAt":"2026-01-12 05:30:40"},{"id":"consul-associate-service-discovery-1768293277708-0","question":"In Consul, if you register a service with an ID that already exists in the local catalog, what happens?","answer":"[{\"id\":\"a\",\"text\":\"The new registration is ignored\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"A second instance with the same ID is created\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"The existing service is updated with the new attributes\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"The registration fails due to a duplicate ID\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C is correct: registering a service with an existing ID updates that service's metadata in the catalog. The new registration replaces the attributes for that ID rather than creating a separate entry.\n\n## Why Other Options Are Wrong\n- A: The new registration is not ignored; it updates the existing service.\n- B: Consul uses unique IDs per service; it does not create a separate entry with the same ID.\n- D: The registration does not fail due to a duplicate ID; it updates the existing service.\n\n## Key Concepts\n- Service IDs must be unique within a node's catalog\n- New registration with same ID updates the existing service's metadata\n- Catalog reflects the latest attributes for a given ID\n\n## Real-World Application\nWhen deploying canary or blue-green deployments, re-registering a service with the same ID allows you to switch endpoints or ports without new clients needing to discover a new service name.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","Terraform","Consul","Envoy","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:34:37.710Z","createdAt":"2026-01-13 08:34:38"},{"id":"consul-associate-service-discovery-1768293277708-1","question":"You configure a TTL-based health check for a service in Consul, but the service is marked unhealthy despite being healthy. What is the most likely cause?","answer":"[{\"id\":\"a\",\"text\":\"The TTL heartbeat is not sent within the configured interval\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"The service's DNS entry is cached too long\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"The service isn't registered with an ID\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"TTL health checks are not supported in your Consul version\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe TTL heartbeat must be sent within the configured interval for the TTL health check to be considered healthy.\n\n## Why Other Options Are Wrong\n- B: DNS caching does not determine TTL health status; the heartbeat governs health.\n- C: The service ID is not the root cause of TTL-based issues.\n- D: TTL health checks are a supported mechanism; the problem is missing heartbeats, not version support.\n\n## Key Concepts\n- TTL checks rely on periodic heartbeats to mark health\n- Missed heartbeats lead to unhealthy status and removal from healthy service lists\n- Heartbeat frequency must align with registered TTL\n\n## Real-World Application\nEnsure each service instance runs a heartbeat at or below the TTL interval; misconfigurations can cause healthy services to appear unhealthy and be culled from discovery results.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","Terraform","Consul","Envoy","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:34:38.394Z","createdAt":"2026-01-13 08:34:38"},{"id":"consul-associate-service-discovery-1768293277708-2","question":"A service named 'web' registered in Consul with DNS interface; your app needs to discover the port used by web instances. Which DNS record should you query to obtain the port along with the IP?","answer":"[{\"id\":\"a\",\"text\":\"A\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"AAAA\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"SRV\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"CNAME\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C is correct: SRV records provide both host and port information for services in Consul DNS.\n\n## Why Other Options Are Wrong\n- A: A records give IPs only, not port numbers.\n- B: AAAA records are for IPv6 addresses, not ports.\n- D: CNAME records do not convey port information for service instances.\n\n## Key Concepts\n- SRV records include port numbers for service endpoints\n- Consul DNS can serve SRV records for services registered in Consul\n- SRV records support dynamic port discovery in clients\n\n## Real-World Application\nClients can resolve service endpoints with address and port via SRV queries, enabling robust service discovery and load balancing.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","Terraform","Consul","Envoy","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:34:38.861Z","createdAt":"2026-01-13 08:34:38"},{"id":"consul-associate-service-discovery-1768293277708-3","question":"To ensure Consul DNS queries return only healthy endpoints, which DNS configuration option must you enable on the server's DNS interface?","answer":"[{\"id\":\"a\",\"text\":\"enable_loose_mode\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"only_passing\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"include_sticky_sessions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"register_in_dns\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct: enable only_passing to return only healthy service instances in DNS responses.\n\n## Why Other Options Are Wrong\n- A: enable_loose_mode is not the standard switch for health-filtering DNS responses.\n- C: Sticky sessions are unrelated to DNS health filtering.\n- D: register_in_dns is not the mechanism to filter by health.\n\n## Key Concepts\n- only_passing filters DNS results to healthy endpoints\n- Improves reliability by avoiding unhealthy instances\n- Useful in dynamic, rapidly changing environments\n\n## Real-World Application\nConfigure DNS to return only passing services so clients don’t attempt to connect to unhealthy instances, reducing retry storms and errors.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","Terraform","Consul","Envoy","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:34:39.021Z","createdAt":"2026-01-13 08:34:39"},{"id":"consul-associate-service-discovery-1768293277708-4","question":"In Consul Connect, you want canary routing to direct 10% of traffic to version v2 of a service while 90% goes to v1. Which mechanism enables this?","answer":"[{\"id\":\"a\",\"text\":\"Intentions\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Service health checks\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Service router with weighted routes\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"MeshGateway\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C is correct: service router with weighted routes enables canary canary routing by directing a percentage of traffic to a specific version.\n\n## Why Other Options Are Wrong\n- A: Intentions control which services can talk to each other, not traffic distribution.\n- B: Health checks influence availability, not routing split.\n- D: MeshGateway is for ingress/egress, not internal in-mesh canary routing.\n\n## Key Concepts\n- Service router supports weighted routing for canary deployments\n- Weights assign traffic percentages to service variants\n- Works within the Connect mesh without external proxies\n\n## Real-World Application\nConfigure a 90/10 split between v1 and v2 to validate new behavior, enabling rapid rollback if issues are detected.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","Terraform","Consul","Envoy","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-discovery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:34:39.190Z","createdAt":"2026-01-13 08:34:39"},{"id":"consul-associate-service-mesh-1768224303018-0","question":"In a Kubernetes cluster, you want Consul Connect to automatically inject sidecars into all pods in the development namespace. Which approach is correct?","answer":"[{\"id\":\"a\",\"text\":\"Annotate the namespace with consul.hashicorp.com/inject: true\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Manually edit each Deployment to add the sidecar container\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable a global flag on the Consul server to inject sidecars globally\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely on Kubernetes default sidecar injection by default\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nAnnotate the namespace with consul.hashicorp.com/inject: true to enable automatic sidecar injection for all pods in that namespace.\n\n## Why Other Options Are Wrong\n- B: Manually editing each Deployment is unnecessary and does not scale; automatic namespace-level injection handles future deployments.\n- C: There is no global server flag to enable automatic sidecar injection across all namespaces.\n- D: Kubernetes has no built-in Consul sidecar injection by default.\n\n## Key Concepts\n- Consul Connect Kubernetes integration\n- Namespace-level sidecar injection via annotation\n\n## Real-World Application\n- Quick onboarding of new teams by enabling injection with a single namespace annotation to ensure all pods receive the sidecars.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","ConsulConnect","Terraform","AWS","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-mesh","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:03.020Z","createdAt":"2026-01-12 13:25:03"},{"id":"consul-associate-service-mesh-1768224303018-1","question":"You need to expose a service from inside a Consul Connect-enabled Kubernetes cluster to the internet. What is the recommended approach?","answer":"[{\"id\":\"a\",\"text\":\"Use an ingress gateway resource with Consul's ingress gateway to expose external traffic to the service\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Expose the service directly via a LoadBalancer service using NodePort without Consul\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Expose with a ClusterIP service and rely on external DNS to reach it\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use the sidecar proxy to directly handle external traffic without gateways\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nIngress gateway is designed for north-south ingress, providing a controlled entry point into the mesh with TLS termination and routing rules.\n\n## Why Other Options Are Wrong\n- B: Bypasses Consul mesh controls and TLS enforcement, reducing security and observability.\n- C: DNS alone does not integrate with Consul routing, TLS, or policies.\n- D: Sidecars handle east-west traffic inside the mesh; external ingress requires a gateway.\n\n## Key Concepts\n- Ingress gateway\n- North-south traffic\n- TLS termination and routing\n\n## Real-World Application\n- Expose a microservice to the internet with consistent security and policy enforcement.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","ConsulConnect","Terraform","AWS","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-mesh","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:03.540Z","createdAt":"2026-01-12 13:25:03"},{"id":"consul-associate-service-mesh-1768224303018-2","question":"Which statement about Consul Intentions is true?","answer":"[{\"id\":\"a\",\"text\":\"If there is no intention between two services, traffic is denied by default\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Intentions are configured at the data-center level and apply to all services automatically\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Intentions define allowed or denied traffic between services, with a default deny posture if not explicitly allowed\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Intentions only control HTTP traffic and ignore other protocols\",\"isCorrect\":false}]","explanation":"## Correct Answer\nC\n\nIntentions explicitly define allowed or denied traffic between services. The system follows a default deny posture unless an intention explicitly allows a connection. \n\n## Why Other Options Are Wrong\n- A: In practice, absence of an intention is treated as denial (default-deny posture) rather than automatic allow.\n- B: Intentions are defined per source-destination pair and are not inherently scoped only to a data-center; they’re defined within a mesh scope.\n- D: Intentions govern multiple protocols, not just HTTP.\n\n## Key Concepts\n- Intentions security model\n- Default-deny posture in service mesh\n\n## Real-World Application\n- Enforce least-privilege access between services in production.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","ConsulConnect","AWS","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-mesh","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:04.080Z","createdAt":"2026-01-12 13:25:04"},{"id":"consul-associate-service-mesh-1768224303018-3","question":"You are using Consul Connect with Vault-based CA provider. What happens when Vault is reachable and the TLS certificates rotate?","answer":"[{\"id\":\"a\",\"text\":\"Certificates rotate automatically; proxies refresh and renegotiate TLS\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"You must restart Consul agents to pick up new certs\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Certificates never rotate; you must manually rotate\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"TLS will fail and disable service mesh\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nWhen using Vault as the CA provider, TLS certificates are rotated automatically by the CA, and the sidecar proxies fetch and renegotiate TLS without requiring restarts.\n\n## Why Other Options Are Wrong\n- B: Automatic rotation eliminates the need for manual restarts.\n- C: Vault-backed TLS can rotate automatically; manual rotation is not required.\n- D: Rotation should not disrupt traffic if the system operates correctly.\n\n## Key Concepts\n- Vault CA provider\n- Automatic TLS certificate rotation\n\n## Real-World Application\n- Reduces maintenance and ensures short-lived certs for security.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","ConsulConnect","Terraform","AWS","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-mesh","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:04.275Z","createdAt":"2026-01-12 13:25:04"},{"id":"consul-associate-service-mesh-1768224303018-4","question":"In a multi-datacenter Consul deployment, which feature enables secure, cross-datacenter service communication with proper TLS and policy enforcement?","answer":"[{\"id\":\"a\",\"text\":\"Mesh gateway\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Ingress gateway\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"WAN federation using DNS\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"ACLs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nMesh gateway enables secure, cross-datacenter (east-west) service communication with TLS termination and policy enforcement across datacenters.\n\n## Why Other Options Are Wrong\n- B: Ingress gateway handles north-south ingress but is not primarily for cross-datacenter east-west traffic.\n- C: WAN federation mechanisms exist but mesh gateway is the correct construct for cross-datacenter service connectivity with mesh policies.\n- D: ACLs govern access but do not by themselves provide the cross-datacenter routing and TLS termination capabilities.\n\n## Key Concepts\n- Mesh gateway for cross-datacenter traffic\n- TLS termination and policy enforcement across datacenters\n\n## Real-World Application\n- Connecting services across regions/data centers with consistent security posture.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","ConsulConnect","AWS","Service Mesh","certification-mcq","domain-weight-20"],"channel":"consul-associate","subChannel":"service-mesh","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:04.459Z","createdAt":"2026-01-12 13:25:04"}],"subChannels":["consul-architecture","consul-operations","consul-security","general","service-discovery","service-mesh"],"companies":["Amazon","Anthropic","Cloudflare","DoorDash","Google","Hugging Face","LinkedIn","Microsoft","NVIDIA","PayPal","Salesforce","Snowflake","Square","Tesla","Two Sigma"],"stats":{"total":37,"beginner":1,"intermediate":33,"advanced":3,"newThisWeek":37}}