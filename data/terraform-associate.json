{"questions":[{"id":"q-1009","question":"Scenario: a single repo provisions per-tenant AWS resources for many tenants. To isolate state without workspaces, use a shared S3 backend with a DynamoDB lock table and a tenant-scoped key. Describe the backend config (bucket, region, dynamodb_table, key pattern per tenant), how you detect drift across tenants, and CI gating for dev-to-prod promotions (plan -out, tests, approve, apply)?","answer":"Configure a shared S3 backend with per-tenant keys and a single DynamoDB lock table. Backend config example: bucket=tf-backend, region=us-east-1, dynamodb_table=tf-locks, key=tenants/${TENANT_ID}/terr","explanation":"## Why This Is Asked\nTests mastery of multi-tenant state isolation, drift detection, and CI-gated promotions using Terraform remote backend.\n\n## Key Concepts\n- Remote state isolation without workspaces\n- Backend config per-tenant key patterns\n- Centralized locking with DynamoDB\n- Drift detection via plan and refresh\n- CI gating with plan/out, tests, approvals\n\n## Code Example\n```javascript\n# backend-configs/dev.tfbackend\nbucket = \"tf-backend\"\nregion = \"us-east-1\"\ndynamodb_table = \"tf-locks\"\nkey = \"tenants/${TENANT_ID}/terraform.tfstate\"\n```\n\n## Follow-up Questions\n- How would you enforce per-tenant role-based access to the backend?\n- How do you handle tenant onboarding/offboarding when state files move?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Coinbase","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T19:21:33.339Z","createdAt":"2026-01-12T19:21:33.339Z"},{"id":"q-1154","question":"In a Terraform module that provisions an AWS RDS instance, operators sometimes alter maintenance_window directly in AWS, creating drift. You want Terraform to ignore external changes to maintenance_window but still apply code-driven updates (e.g., allocated_storage). How would you implement this using a lifecycle block? Provide a minimal aws_db_instance snippet showing ignore_changes for maintenance_window and outline tradeoffs?","answer":"Use: lifecycle { ignore_changes = [maintenance_window] }. In the aws_db_instance resource, keep allocated_storage driven by config. Caveats: other fields drift remains visible only if not ignored; if ","explanation":"## Why This Is Asked\n\nShows practical drift handling with Terraform state; tests understanding of lifecycle rules and their impact on operations.\n\n## Key Concepts\n\n- Drift and state\n- lifecycle ignore_changes\n- Resource attribute scoping\n\n## Code Example\n\n```javascript\nresource \"aws_db_instance\" \"example\" {\n  identifier         = \"example\"\n  engine             = \"mysql\"\n  instance_class     = \"db.t3.micro\"\n  allocated_storage  = 20\n  maintenance_window = \"sun:23:45-sun:00:15\"\n\n  lifecycle {\n    ignore_changes = [maintenance_window]\n  }\n}\n```\n\n## Follow-up Questions\n\n- What would happen if maintenance_window is changed in code while an apply is in progress?\n- How would you revert drift if needed later?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:37:52.444Z","createdAt":"2026-01-13T01:37:52.444Z"},{"id":"q-1172","question":"In AWS us-east-1, you must provision 3 private subnets in a single VPC across 3 AZs using one module. Define a map variable with AZs and CIDRs, create the subnets with for_each, attach appropriate tags, and output the subnet IDs. Then show how to reference these IDs in a resource that requires subnet_id (eg NAT Gateway) and justify for_each vs count?","answer":"Use a map variable for subnets keyed by AZ, create aws_subnet with for_each, set az and cidr_block from the map, and TAGS. Output the IDs for reuse. Example: create a NAT gateway per subnet by iterati","explanation":"## Why This Is Asked\nAssesses practical use of for_each with maps, resource interdependencies, and stable identities across environments. Delivers hands-on pattern candidates expect in production.\n\n## Key Concepts\n- for_each with maps provides stable keys and predictable IDs\n- referencing attributes from one resource in another (subnet_id in NAT GW)\n- tagging and AZ assignment per subnet\n- outputs to surface IDs for downstream resources\n- when to prefer for_each vs count (stable keys vs positional indexing)\n\n## Code Example\n```javascript\nvariable \"subnets\" {\n  type = map(object({ cidr_block = string; az = string }))\n  default = {\n    az1 = { cidr_block = \"10.0.1.0/24\", az = \"us-east-1a\" },\n    az2 = { cidr_block = \"10.0.2.0/24\", az = \"us-east-1b\" },\n    az3 = { cidr_block = \"10.0.3.0/24\", az = \"us-east-1c\" }\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = var.subnets\n  vpc_id            = var.vpc_id\n  cidr_block        = each.value.cidr_block\n  availability_zone = each.value.az\n  tags = {\n    Name = \"private-${each.key}\"\n  }\n}\n\noutput \"private_subnet_ids\" {\n  value = [for s in aws_subnet.private : s.id]\n}\n```\n\n```javascript\nresource \"aws_nat_gateway\" \"ngw\" {\n  for_each = aws_subnet.private\n  allocation_id = aws_eip.ngw[each.key].id\n  subnet_id     = aws_subnet.private[each.key].id\n}\n```\n\n## Follow-up Questions\n- When would you choose for_each over count in real projects?\n- How would you migrate from count-based to for_each-based resources without breaking state?\n- How would you validate AZ distribution and CIDR correctness after apply?","diagram":"flowchart TD\n  S[Subnets] --> A1[Subnet us-east-1a]\n  S --> A2[Subnet us-east-1b]\n  S --> A3[Subnet us-east-1c]\n  A1 --> NGW[Per-Subnet NAT Gateway]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:37:27.209Z","createdAt":"2026-01-13T03:37:27.209Z"},{"id":"q-1202","question":"Scenario: you must bring under Terraform management a set of existing AWS S3 buckets across teams. Some buckets already exist and must be imported; you will manage encryption and versioning with a single module using for_each over a bucket map. How would you import, structure, and promote changes safely via CI?","answer":"Import existing buckets into state by address, e.g. terraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket; define a map of buckets with per-bucket flags and use for_each to create resources;","explanation":"## Why This Is Asked\n\nThis checks practical import workflows and multi-resource management with for_each, keeping data in sync and enabling safe CI-driven promotions.\n\n## Key Concepts\n\n- terraform import with for_each\n- map of per-bucket settings\n- dynamic blocks for conditional blocks\n- drift reconciliation and idempotency\n- CI/CD validation and promotion\n\n## Code Example\n\n```javascript\nvariable \"buckets\" {\n  type = map(object({\n    encryption = bool\n    versioning = bool\n  }))\n}\nresource \"aws_s3_bucket\" \"bucket\" {\n  for_each = var.buckets\n  bucket = each.key\n  acl    = \"private\"\n\n  dynamic \"versioning\" {\n    for_each = each.value.versioning ? [1] : []\n    content {\n      enabled = true\n    }\n  }\n\n  dynamic \"server_side_encryption_configuration\" {\n    for_each = each.value.encryption ? [1] : []\n    content {\n      rule {\n        apply_server_side_encryption_by_default {\n          sse_algorithm = \"AES256\"\n        }\n      }\n    }\n  }\n}\n```\n\n```javascript\nterraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket\n```\n\n## Follow-up Questions\n\n- How would you handle a bucket rename in the map without recreating?\n- How would you test encryption changes in CI without touching prod data?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","NVIDIA","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:49:50.394Z","createdAt":"2026-01-13T04:49:50.394Z"},{"id":"q-864","question":"In Terraform, you need to manage two AWS accounts in a single repo: prod (provider aws.prod) and audit (provider aws.audit). Create an S3 bucket in prod and a cross-account IAM policy in audit that grants read access to that bucket. How do you configure aliased providers, reference the prod bucket ARN from the audit module, and enforce deterministic apply order (e.g., data fetch before policy) with minimal risk? Include a minimal config outline?","answer":"Define two providers with aliases (aws.prod and aws.audit). Create the bucket using aws.prod, then fetch its ARN from prod via data.aws_s3_bucket in the audit config and craft an audit IAM policy that","explanation":"## Why This Is Asked\n\nThis question tests multi-account Terraform patterns: provider aliases, cross-account data sources, and deterministic apply order.\n\n## Key Concepts\n\n- Aliased providers\n- Cross-account data sources\n- Data referencing across providers\n- depends_on for ordering\n- Credentials management via profiles and assume_role\n\n## Code Example\n\n```hcl\nprovider \"aws\" {\n  alias   = \"prod\"\n  region  = \"us-east-1\"\n  profile = \"prod\"\n}\nprovider \"aws\" {\n  alias   = \"audit\"\n  region  = \"us-east-1\"\n  profile = \"audit\"\n}\n\ndata \"aws_caller_identity\" \"prod\" {\n  provider = aws.prod\n}\n\ndata \"aws_s3_bucket\" \"prod_bucket\" {\n  provider = aws.prod\n  bucket   = \"my-prod-bucket\"\n}\n\ndata \"aws_iam_policy_document\" \"audit\" {\n  provider = aws.audit\n  statement {\n    actions   = [\"s3:GetObject\"]\n    resources = [\"${data.aws_s3_bucket.prod_bucket.arn}/*\"]\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"arn:aws:iam::${data.aws_caller_identity.prod.account_id}:root\"]\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"audit_bucket\" {\n  provider = aws.audit\n  bucket   = \"audit-bucket\"\n}\n\nresource \"aws_iam_policy\" \"audit_policy\" {\n  provider = aws.audit\n  name     = \"CrossAccountGetObject\"\n  policy   = data.aws_iam_policy_document.audit.json\n}\n```\n\n## Follow-up Questions\n\n- How would you rotate credentials for the aliased providers safely?\n- How would you test this cross-account permission in a CI workflow?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snap","Snowflake","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:45:51.426Z","createdAt":"2026-01-12T13:45:51.426Z"},{"id":"q-960","question":"In a single Terraform repo that provisions prod, staging, and dev AWS environments, how would you configure a single S3 backend to isolate state for each environment without using separate Terraform workspaces? Provide the exact backend config (bucket, region, dynamodb_lock_table, key per env) and explain how you would promote changes from dev to prod, including drift handling and CI plan/apply steps?","answer":"Use one S3 bucket with environment-scoped keys and per-env locking: dev/terraform.tfstate with tf-lock-dev, staging/terraform.tfstate with tf-lock-staging, prod/terraform.tfstate with tf-lock-prod. Do","explanation":"## Why This Is Asked\n\nTests practical backend configuration and multi-environment isolation without relying on workspaces, which can obscure state provenance. It also covers promotion workflows and drift handling in CI.\n\n## Key Concepts\n\n- Terraform backends and per-environment state isolation\n- State locking with DynamoDB per environment\n- Promotion pipelines and drift considerations in CI/CD\n\n## Code Example\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"dev/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-dev\"\n    encrypt        = true\n  }\n}\n```\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-prod\"\n    encrypt        = true\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you handle a state drift detected in prod after a manual change?\n- What are the trade-offs of using a single bucket with per-env keys vs separate buckets per env?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Google","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:21:52.897Z","createdAt":"2026-01-12T17:21:52.897Z"},{"id":"terraform-associate-iac-concepts-1768193518666-0","question":"You are organizing a multi-team Terraform project with shared modules and a centralized remote state backend. Which approach best ensures consistent provider versions, standardized backends, and safe remote state sharing across teams?","answer":"[{\"id\":\"a\",\"text\":\"Create local copies of modules for each team and configure separate backends and provider versions per team\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Publish all resources in a single monolithic configuration with no modules and a shared backend\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Publish shared modules to a centralized module registry and configure a single remote backend with versioned providers, using a shared backend and workspace for remote state\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Duplicate infrastructure code per environment with separate state files and no module reuse\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C is correct. By publishing shared modules to a centralized registry and configuring a single remote backend with pinned provider versions, teams reuse validated configurations and share state safely, reducing drift and conflicts.\n\n## Why Other Options Are Wrong\n- A: Lacks centralization and module reuse, leading to drift and inconsistent state handling.\n- B: Removes modularity and shared state governance, increasing maintenance burden.\n- D: Duplicates code across environments and teams, causing divergence and governance problems.\n\n## Key Concepts\n- Module Registry and reuse\n- Backend configuration and remote state\n- required_providers and version pinning\n- State locking and collaboration\n\n## Real-World Application\nA large organization standardizes infrastructure by exposing common modules via a registry and using a shared remote backend to coordinate across teams during apply operations.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Module Registry","Remote-State","State-Locking","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"iac-concepts","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:58.667Z","createdAt":"2026-01-12 04:51:59"},{"id":"terraform-associate-iac-concepts-1768193518666-1","question":"You are managing an AWS S3 data lake bucket via Terraform and want to prevent accidental deletion while still allowing legitimate destroy operations when explicitly requested. Which Terraform feature best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Use a lifecycle block with prevent_destroy = true\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Set force_destroy = true on the aws_s3_bucket resource\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Attach an IAM policy that denies s3:DeleteBucket for the Terraform role\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use ignore_changes on the bucket's force_destroy attribute\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA is correct because a lifecycle block with prevent_destroy = true prevents Terraform from destroying the bucket during apply unless the block is removed or modified. This protects against accidental deletions.\n\n## Why Other Options Are Wrong\n- B would force destruction regardless of contents, which defeats safety.\n- C could be bypassed by using credentials with delete permissions or manual overrides; it does not guarantee plan-time safety.\n- D ignore_changes does not prevent delete operations and is not a safety mechanism for destructive actions.\n\n## Key Concepts\n- Lifecycle blocks\n- prevent_destroy\n- Destruction safety in Terraform\n\n## Real-World Application\nOperators protect critical data assets from accidental deletion by enforcing a lifecycle safeguard, requiring an explicit action to disable the protection before deletion.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","S3","IAM","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"iac-concepts","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:59.083Z","createdAt":"2026-01-12 04:51:59"},{"id":"terraform-associate-iac-concepts-1768193518666-2","question":"A Terraform configuration creates a VM and a bootstrap script executed via a null_resource using local-exec. The script must run only after the VM and its network resources exist. Which pattern ensures the bootstrap runs in the correct order?","answer":"[{\"id\":\"a\",\"text\":\"Use depends_on to explicitly reference the VM and network resources on the null_resource\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use a separate apply with -target to run the bootstrap after the VM creation\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Place the bootstrap script in the same resource block to create an implicit dependency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a separate module and trigger it with a separate Terraform workspace\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA is correct because explicit depends_on declarations ensure the null_resource executes only after the VM and network resources are created, establishing a clear ordering for the bootstrap.\n\n## Why Other Options Are Wrong\n- B relies on targeted applies which can be brittle and do not guarantee ordering within a single plan.\n- C cannot establish a reliable dependency since the script is a separate provisioner and not referenced directly.\n- D introduces complexity and does not guarantee ordering across workspaces.\n\n## Key Concepts\n- Depends_on and resource ordering\n- Provisioners (local-exec) caveats\n- Implicit vs explicit dependencies\n\n## Real-World Application\nEnsures bootstrap steps run only after required infrastructure components exist, preventing failures during bootstrap.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","EC2","Provisioners","Local-exec","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"iac-concepts","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:51:59.468Z","createdAt":"2026-01-12 04:51:59"},{"id":"terraform-associate-modules-1768242834073-0","question":"When using a Terraform module, you want the resources inside the module to deploy to a different AWS region than the root configuration. Which approach correctly achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Define a provider alias in the root and pass it to the module using the providers map\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Declare a provider block inside the module to override the region\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Set a variable for region and reference it inside the module\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create a separate Terraform workspace for that region\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUsing a provider alias in the root and mapping it to the module via the providers argument ensures the module's resources use the specified region.\n\n## Why Other Options Are Wrong\n- Option B: A provider block inside the module requires wiring via the providers map; this approach alone is not sufficient to route the module's resources to a different region.\n- Option C: Setting a region variable inside the module does not override the provider configuration; you still need a provider alias to switch regions.\n- Option D: Terraform workspaces affect state, not provider regions; region isolation should be handled via provider aliases, not workspaces.\n\n## Key Concepts\n- Provider aliases\n- Module blocks\n- Providers argument\n\n## Real-World Application\n- Deploy the same module across multiple AWS regions for multi-region architectures while keeping configuration DRY.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Modules","ProviderAliases","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"modules","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:33:54.074Z","createdAt":"2026-01-12 18:33:54"},{"id":"terraform-associate-modules-1768242834073-1","question":"You need to create multiple instances of the same module with different configurations (for example, multiple VPCs with different CIDRs). Which approach does Terraform support to instantiate multiple module instances from the same source?","answer":"[{\"id\":\"a\",\"text\":\"Use for_each on the module block with a map of configurations\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use count on the module block with a single configuration\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Copy-paste the module block blocks for each configuration\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a separate Terraform workspace for each configuration\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUse for_each on the module block with a map (or set) of configurations to instantiate multiple module instances from the same source.\n\n## Why Other Options Are Wrong\n- Option B: Count on module blocks is not the standard pattern for diverse configurations and can be less clear; for_each is the recommended approach for heterogeneous inputs.\n- Option C: Duplicating module blocks manually is verbose and error-prone; it defeats the purpose of iteration.\n- Option D: Workspaces do not provide per-instance configuration isolation for modules.\n\n## Key Concepts\n- for_each with modules\n- Modular reusability\n\n## Real-World Application\n- Spin up multiple isolated VPCs across environments using a single module source with per-instance inputs.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Modules","AWS","VPC","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"modules","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:33:54.749Z","createdAt":"2026-01-12 18:33:55"},{"id":"terraform-associate-modules-1768242834073-2","question":"A module named network defines an output subnets that lists subnet IDs. In the root module, you want to use this list to create an EC2 instance in those subnets. How do you reference the module output?","answer":"[{\"id\":\"a\",\"text\":\"module.network.subnets\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"module.network.outputs_subnets\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"data.aws_subnet.subnets\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"var.subnets\",\"isCorrect\":false}]","explanation":"## Correct Answer\nmodule.network.subnets references the outputs of the network module, providing the list of subnet IDs for use in the root module.\n\n## Why Other Options Are Wrong\n- Option B: outputs_subnets is not the standard syntax for module outputs.\n- Option C: data.aws_subnet would require a data source; it does not directly reference module outputs.\n- Option D: var.subnets is an input variable, not the module output.\n\n## Key Concepts\n- Referencing module outputs\n- Module outputs syntax\n\n## Real-World Application\n- Consumes network module outputs to configure dependent resources without duplicating data.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Modules","Outputs","AWS","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"modules","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:33:55.205Z","createdAt":"2026-01-12 18:33:55"},{"id":"terraform-associate-modules-1768242834073-3","question":"You're using a module from the Terraform Registry and want to keep it up to date but minimize breaking changes. Which version constraint should you use in the module block to allow only minor updates within the same major version?","answer":"[{\"id\":\"a\",\"text\":\"version = \\\"~> 2.0\\\"\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"version = \\\"~> 3.0\\\"\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"version = \\\"2.0\\\"\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"version = \\\"latest\\\"\",\"isCorrect\":false}]","explanation":"## Correct Answer\nversion = \"~> 2.0\" allows any 2.x version, providing minor/patch updates within the same major version while preventing automatic upgrades to major version 3.\n\n## Why Other Options Are Wrong\n- Option B: \"~> 3.0\" would lock to major 3 updates, not minor within the same major.\n- Option C: \"2.0\" locks to exactly 2.0 and prevents beneficial minor/patch updates.\n- Option D: \"latest\" is not a valid Terraform syntax for module version constraints and is unsafe.\n\n## Key Concepts\n- Version constraints syntax\n- Module version pinning\n\n## Real-World Application\n- Balances stability with security/feature updates for shared modules.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Modules","Registry","Versioning","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"modules","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:33:55.367Z","createdAt":"2026-01-12 18:33:55"},{"id":"terraform-associate-modules-1768242834073-4","question":"You have module network and module app. The app module needs VPC ID and subnet IDs from the network module. How should you wire this to ensure proper ordering and data flow?","answer":"[{\"id\":\"a\",\"text\":\"Pass module.network outputs as inputs to module.app\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Hardcode the IDs in module.app inputs\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Fetch IDs with a data source instead of using module outputs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a separate Terraform workspace for the app\",\"isCorrect\":false}]","explanation":"## Correct Answer\nPass module.network outputs as inputs to module.app to create an implicit dependency; the app will only apply after the network module provides the IDs.\n\n## Why Other Options Are Wrong\n- Option B: Hardcoding IDs reduces reusability and introduces drift between environments.\n- Option C: Data sources could work, but using module outputs is the intended pattern for module-to-module communication.\n- Option D: Workspaces do not enforce cross-module data flow; they affect state management.\n\n## Key Concepts\n- Module-to-module communication\n- Implicit dependencies via input variables\n\n## Real-World Application\n- Structuring multi-module deployments where infrastructure layers depend on each other.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Modules","AppDeployment","AWS","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"modules","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:33:55.529Z","createdAt":"2026-01-12 18:33:55"},{"id":"terraform-associate-terraform-basics-1768155950528-0","question":"In a team environment, you need to ensure safe concurrent Terraform operations across multiple developers and CI runs. Which backend configuration best prevents conflicting state writes?","answer":"[{\"id\":\"a\",\"text\":\"Use the local backend so state is kept in the repository alongside configuration\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use a remote backend with S3 as the state store and DynamoDB for state locking\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a remote backend with Consul as storage but without a locking mechanism\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Terraform Cloud as the backend with default locking behavior\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B. Using a remote backend with S3 and DynamoDB enables persistent state storage and locking, which prevents concurrent writes from racing each other in multiple runs. \n\n## Why Other Options Are Wrong\n- A: Local backend stores state on disk and is not suitable for collaboration or locking. \n- C: Consul backend exists but does not provide DynamoDB-style locking, which undermines concurrent safety. \n- D: Terraform Cloud is a valid remote backend option but the question specifies a classic AWS-backed setup with explicit locking via DynamoDB; Terraform Cloud is a different service and may introduce different operational considerations. \n\n## Key Concepts\n- Remote state with locking\n- Backends (S3) and locking mechanisms (DynamoDB)\n\n## Real-World Application\n- When multiple engineers and CI pipelines apply changes, this pattern prevents corrupt state by ensuring only one operation can write at a time.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","S3","DynamoDB","Backends","CI/CD","certification-mcq","domain-weight-20"],"channel":"terraform-associate","subChannel":"terraform-basics","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:25:50.531Z","createdAt":"2026-01-11 18:25:50"},{"id":"terraform-associate-terraform-basics-1768155950528-1","question":"You have a child module that outputs a database password along with the database endpoint. To avoid leaking the password in CLI output and logs, which approach should you take?","answer":"[{\"id\":\"a\",\"text\":\"Expose the password directly via a standard output value\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Mark the password output as sensitive = true\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store the password in the repository so it is versioned\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a separate data source to fetch the password at apply time\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B. Marking the output as sensitive hides the value from default CLI displays and plan output, reducing the risk of accidentally leaking secrets. \n\n## Why Other Options Are Wrong\n- A: Exposing the password defeats purpose of masking and is insecure. \n- C: Storing passwords in the repository risks credential leakage and accidental exposure. \n- D: A data source cannot inherently mask the password when surfaced as an output and adds unnecessary complexity; sensitive outputs are the standard approach for secret values output by modules. \n\n## Key Concepts\n- Outputs can be marked sensitive to prevent display\n- Secrets should not be logged or displayed by default\n\n## Real-World Application\n- In CI pipelines, marking outputs as sensitive ensures secrets like DB passwords are not printed in logs while still allowing dependent modules to consume the value programmatically.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Security","Secrets","AWS","RDS","certification-mcq","domain-weight-20"],"channel":"terraform-associate","subChannel":"terraform-basics","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:25:50.895Z","createdAt":"2026-01-11 18:25:51"},{"id":"terraform-associate-terraform-basics-1768155950528-2","question":"You manage two Kubernetes clusters (prod and dev) on AWS EKS and want to manage resources in both clusters from a single Terraform configuration. Which approach is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Create two entirely separate Terraform configurations for the two clusters\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Define multiple Kubernetes providers with different aliases and specify provider = kubernetes.prod or kubernetes.dev in resources\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a single Kubernetes provider and dynamically switch the cluster using a runtime variable in each resource\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use the same provider for both clusters and rely on separate namespaces to segregate resources\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B. Terraform supports multiple provider configurations with aliases. You can define separate Kubernetes providers for prod and dev clusters and assign them to resources using provider = kubernetes.prod or provider = kubernetes.dev. \n\n```javascript\nprovider \"kubernetes\" {\n  alias = \"prod\"\n  host = var.prod_host\n  client_certificate = var.prod_cert\n  token = var.prod_token\n}\nprovider \"kubernetes\" {\n  alias = \"dev\"\n  host = var.dev_host\n  client_certificate = var.dev_cert\n  token = var.dev_token\n}\nresource \"kubernetes_namespace\" \"prod_ns\" {\n  provider = kubernetes.prod\n  metadata { name = \"production\" }\n}\nresource \"kubernetes_namespace\" \"dev_ns\" {\n  provider = kubernetes.dev\n  metadata { name = \"development\" }\n}\n```\n\n## Why Other Options Are Wrong\n- A: Two separate configurations are valid but increases maintenance and duplication; a single config with aliases is more scalable. \n- C: A single provider cannot target multiple clusters simultaneously without prefixes/aliases. \n- D: Namespaces do not provide isolation at the provider level and wonâ€™t allow per-cluster API interactions. \n\n## Key Concepts\n- Provider aliases for multi-cluster management\n- Resource-level provider assignment\n\n## Real-World Application\n- Simplifies multi-cluster governance by centralizing configuration while keeping prod/dev isolated.","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","EKS","AWS","Provider Aliases","certification-mcq","domain-weight-20"],"channel":"terraform-associate","subChannel":"terraform-basics","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:25:51.250Z","createdAt":"2026-01-11 18:25:51"},{"id":"terraform-associate-terraform-cloud-1768282261178-0","question":"How should you store a database password for production in Terraform Cloud to ensure it is not exposed in plans or logs?","answer":"[{\"id\":\"a\",\"text\":\"Put the password directly in terraform.tfvars in the repo\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a Terraform Cloud workspace variable with the Sensitive flag enabled\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store it in a private Git submodule and require access\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Put the password in a non-sensitive regular variable defined in main.tf\",\"isCorrect\":false}]","explanation":"```markdown\n## Correct Answer\nCreate a Terraform Cloud workspace variable with the Sensitive flag enabled.\n\nThis marks the value as sensitive so it is redacted in plan outputs, the UI, and logs, while still being accessible to Terraform during runs.\n\n## Why Other Options Are Wrong\n- A: Storing in terraform.tfvars exposes the secret in the repository and can leak in logs or VCS history.\n- C: While access control helps, this still risks exposing the secret and relies on external sync.\n- D: A non-sensitive variable will appear in plans and logs, risking exposure.\n\n## Key Concepts\n- Sensitive variables in Terraform Cloud\n- Redaction of sensitive values in plans, UI, and logs\n- Separation of secrets from code\n\n## Real-World Application\n- Use sensitive workspace variables for production credentials (DB passwords, API keys) and rotate them without touching code.\n```","diagram":null,"difficulty":"intermediate","tags":["Terraform Cloud","AWS","Secrets Manager","Kubernetes","Terraform","certification-mcq","domain-weight-10"],"channel":"terraform-associate","subChannel":"terraform-cloud","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:31:01.179Z","createdAt":"2026-01-13 05:31:01"},{"id":"terraform-associate-terraform-cloud-1768282261178-1","question":"You manage multiple environments (dev, stage, prod) in Terraform Cloud and want to reuse a common set of variables across workspaces. What feature should you use?","answer":"[{\"id\":\"a\",\"text\":\"Variable precedence within each workspace\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Variable Sets\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Shared backends for state storage\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Manual naming convention for workspaces\",\"isCorrect\":false}]","explanation":"```markdown\n## Correct Answer\nVariable Sets.\n\nVariable Sets allow you to define a collection of variables once and attach them to multiple workspaces, promoting consistency across environments.\n\n## Why Other Options Are Wrong\n- A: Per-workspace precedence does not automatically share values across workspaces.\n- C: Backends manage state, not cross-workspace variable sharing.\n- D: Naming conventions do not share values and are error-prone.\n\n## Key Concepts\n- Variable Sets in Terraform Cloud\n- Cross-workspace variable sharing\n- Governance and consistency across environments\n\n## Real-World Application\n- Define region, tags, and common features in a Variable Set and attach it to dev, stage, and prod workspaces.\n```","diagram":null,"difficulty":"intermediate","tags":["Terraform Cloud","Terraform","AWS","GitHub","certification-mcq","domain-weight-10"],"channel":"terraform-associate","subChannel":"terraform-cloud","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:31:01.853Z","createdAt":"2026-01-13 05:31:02"},{"id":"terraform-associate-terraform-cloud-1768282261178-2","question":"To enforce governance checks before applying changes to prod across workspaces, you should implement?","answer":"[{\"id\":\"a\",\"text\":\"Run Tasks\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Sentinel policy sets\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Notifications only\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"API-based run triggers without policies\",\"isCorrect\":false}]","explanation":"```markdown\n## Correct Answer\nSentinel policy sets.\n\nSentinel provides policy as code to enforce governance checks on plans before they can be applied, enabling consistent compliance across environments.\n\n## Why Other Options Are Wrong\n- A: Run Tasks are pre/post steps but do not enforce governance by default.\n- C: Notifications alert teams but do not block or gate changes.\n- D: API triggers can start runs but without policy checks they do not guarantee governance.\n\n## Key Concepts\n- Sentinel policy as code\n- Policy sets for governance\n- Gatekeeping plan+apply in Terraform Cloud\n\n## Real-World Application\n- Use Sentinel to enforce allowed instance types, regions, or resource counts before prod applies.\n```","diagram":null,"difficulty":"intermediate","tags":["Terraform Cloud","Terraform","AWS","Sentinel","certification-mcq","domain-weight-10"],"channel":"terraform-associate","subChannel":"terraform-cloud","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:31:02.442Z","createdAt":"2026-01-13 05:31:02"},{"id":"terraform-associate-terraform-cloud-1768282261178-3","question":"When two teams push changes to the same workspace concurrently, which Terraform Cloud feature ensures that runs are serialized and only one plan/apply executes at a time?","answer":"[{\"id\":\"a\",\"text\":\"Run queue\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Remote state lock in S3 backend\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Workflow dependencies\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Parallel run execution\",\"isCorrect\":false}]","explanation":"```markdown\n## Correct Answer\nRun queue.\n\nTerraform Cloud serializes runs via the run queue, ensuring only one plan/apply executes at a time for a given workspace.\n\n## Why Other Options Are Wrong\n- B: While remote state backends can lock, Terraform Cloud uses its own run queue for workspace-level concurrency control.\n- C: Workflow dependencies manage task order but do not guarantee exclusive plan/apply execution.\n- D: Parallel run execution would allow concurrent plans, which Terraform Cloud avoids for correctness.\n\n## Key Concepts\n- Run queue in Terraform Cloud\n- Concurrency control for workspace runs\n\n## Real-World Application\n- Prevents race conditions when multiple teams submit changes simultaneously.\n```","diagram":null,"difficulty":"intermediate","tags":["Terraform Cloud","Terraform","AWS","GitHub","certification-mcq","domain-weight-10"],"channel":"terraform-associate","subChannel":"terraform-cloud","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:31:02.629Z","createdAt":"2026-01-13 05:31:02"},{"id":"terraform-associate-terraform-cloud-1768282261178-4","question":"You want to trigger a plan for a specific workspace programmatically using Terraform Cloud's API. Which REST endpoint would you call?","answer":"[{\"id\":\"a\",\"text\":\"POST /organizations/{org}/workspaces/{workspace}/plan\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"POST /organizations/{org}/workspaces/{workspace}/runs\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"POST /organizations/{org}/workspaces/{workspace}/variables\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"POST /organizations/{org}/workspaces/{workspace}/state-versions\",\"isCorrect\":false}]","explanation":"```markdown\n## Correct Answer\nPOST /organizations/{org}/workspaces/{workspace}/runs\n\nThis endpoint creates a new run (plan) for the specified workspace; the run can be configured to trigger a plan and subsequently an apply depending on your settings.\n\n## Why Other Options Are Wrong\n- A: There is no dedicated plan endpoint; plans are created as part of a run via the runs API.\n- C: Variables endpoint manages variables, not triggering runs.\n- D: State versions endpoint accesses historical state, not triggering runs.\n\n## Key Concepts\n- Terraform Cloud API\n- Runs endpoint for programmatic plans\n- Authentication and workspace scoping\n\n## Real-World Application\n- Automate CI pipelines to trigger plans via API instead of relying on webhooks.\n```","diagram":null,"difficulty":"intermediate","tags":["Terraform Cloud","Terraform","AWS","GitHub","certification-mcq","domain-weight-10"],"channel":"terraform-associate","subChannel":"terraform-cloud","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:31:02.822Z","createdAt":"2026-01-13 05:31:02"},{"id":"terraform-associate-terraform-state-1768224155868-0","question":"Which backend attribute enables concurrency control for Terraform remote state in an S3 backend?","answer":"[{\"id\":\"a\",\"text\":\"region\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"dynamodb_table\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"bucket\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"encrypt\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct. The dynamodb_table attribute configures a DynamoDB table to manage state locks, enabling concurrency control for remote state.\n\n## Why Other Options Are Wrong\n- A: region specifies the AWS region for the backend but does not provide locking.\n- C: bucket only defines the S3 bucket location, not locking behavior.\n- D: encrypt controls at-rest encryption, not locking.\n\n## Key Concepts\n- Remote state locking with DynamoDB\n- Backend configuration for S3\n\n## Real-World Application\n- In teams, enabling DynamoDB locking prevents conflicting Terraform runs on the same state.","diagram":null,"difficulty":"intermediate","tags":["Terraform","State","AWS","S3","DynamoDB","Remote State","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"terraform-state","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:22:35.870Z","createdAt":"2026-01-12 13:22:36"},{"id":"terraform-associate-terraform-state-1768224155868-1","question":"You are migrating a local Terraform state to a remote backend. Which command best migrates the local state to the new backend?","answer":"[{\"id\":\"a\",\"text\":\"terraform init -migrate-state\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"terraform init\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"terraform apply\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"terraform state push\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. Terraform init -migrate-state migrates an existing local state to the newly configured remote backend.\n\n## Why Other Options Are Wrong\n- B: terraform init initializes backends but does not migrate local state by itself.\n- C: terraform apply executes changes, not backend migration.\n- D: terraform state push is not the standard migration flow for moving local state to a backend and is deprecated in newer workflows.\n\n## Key Concepts\n- Migrating local to remote state\n- Backend initialization\n\n## Real-World Application\n- When reconfiguring to a remote backend after initial development.","diagram":null,"difficulty":"intermediate","tags":["Terraform","State","Backend","Migration","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"terraform-state","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:22:36.410Z","createdAt":"2026-01-12 13:22:36"},{"id":"terraform-associate-terraform-state-1768224155868-2","question":"A remote state stored in S3 becomes corrupted due to a crash during a write. What is the safest way to recover without affecting live resources?","answer":"[{\"id\":\"a\",\"text\":\"Restore the state file from a previous version in S3\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Run terraform state rm on all resources\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Manually edit the JSON state file\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Run terraform apply to re-create resources\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. If S3 versioning is enabled, restore a previous good state version to recover without modifying live infrastructure.\n\n## Why Other Options Are Wrong\n- B: Removing resources from state can orphan real resources and lose track.\n- C: Manually editing the state file is error-prone and unsafe.\n- D: Applying may fail or cause conflicts if the state is corrupted.\n\n## Key Concepts\n- State corruption recovery\n- S3 versioning and backup\n\n## Real-World Application\n- Regularly back up and version Terraform state to recover from corruption quickly.","diagram":null,"difficulty":"intermediate","tags":["Terraform","State","AWS","S3","Backups","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"terraform-state","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:22:36.928Z","createdAt":"2026-01-12 13:22:37"},{"id":"terraform-associate-terraform-state-1768224155868-3","question":"To manage an existing AWS VPC that was created outside Terraform, which action brings the resource into Terraform state?","answer":"[{\"id\":\"a\",\"text\":\"terraform import aws_vpc.example_vpc vpc-123456\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"terraform apply\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"terraform refresh\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"terraform state list\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. terraform import associates the existing AWS VPC resource with a Terraform resource in the state, enabling management.\n\n## Why Other Options Are Wrong\n- B: apply would attempt to create/modify resources per configuration, not import.\n- C: refresh is deprecated and does not import resources into state.\n- D: state list only lists resources known to the state; it does not perform import.\n\n## Key Concepts\n- Importing existing resources into state\n- Managing externally created infrastructure\n\n## Real-World Application\n- Onboarding existing environments into Terraform management.","diagram":null,"difficulty":"intermediate","tags":["Terraform","State","AWS","Import","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"terraform-state","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:22:37.108Z","createdAt":"2026-01-12 13:22:37"},{"id":"terraform-associate-terraform-state-1768224155868-4","question":"If a DynamoDB lock prevents another apply due to an unclean shutdown, which command forcibly unlocks the state lock when you are sure no one else is applying?","answer":"[{\"id\":\"a\",\"text\":\"terraform force-unlock LOCK_ID\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"terraform unlock\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"terraform state unlock\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"terraform apply -force-lock\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. terraform force-unlock LOCK_ID releases the lock forcibly when you are certain no other process is running.\n\n## Why Other Options Are Wrong\n- B: There is no terraform unlock command.\n- C: No such subcommand; state unlock does not exist.\n- D: There is no apply flag -force-lock; locking is managed by DynamoDB.\n\n## Key Concepts\n- Force unlocking remote state\n- Lock management with DynamoDB\n\n## Real-World Application\n- Resolving stalled Terraform runs after outages without impacting live resources.","diagram":null,"difficulty":"intermediate","tags":["Terraform","State","AWS","DynamoDB","Locking","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"terraform-state","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:22:37.290Z","createdAt":"2026-01-12 13:22:37"},{"id":"terraform-associate-workflow-1768256282579-0","question":"In a multi-team AWS project, you want a remote Terraform state that is shared, durable, and supports state locking to prevent concurrent applies. Which backend is most appropriate for this scenario?","answer":"[{\"id\":\"a\",\"text\":\"Local backend\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"S3 backend with DynamoDB locking\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Terraform Cloud remote backend\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Consul backend\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- B: S3 backend with DynamoDB locking\n\n## Why Other Options Are Wrong\n- Option A: Local backend stores state locally and does not provide remote locking for multiple teams.\n- Option C: Terraform Cloud remote backend does offer remote state and locking, but the question emphasizes an AWS-native locking mechanism via DynamoDB, which is characteristic of the S3 + DynamoDB approach.\n- Option D: Consul backend can provide locking, but it adds external infrastructure and is less common for standard AWS-centric workflows.\n\n## Key Concepts\n- Remote state backends\n- State locking with DynamoDB\n- AWS S3 state storage with optional versioning\n\n## Real-World Application\n- When coordinating many teams deploying AWS resources, configure an S3 backend with a DynamoDB table for lock to prevent concurrent applies and ensure auditability of state changes.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Core Workflow","S3","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"workflow","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:18:02.582Z","createdAt":"2026-01-12 22:18:02"},{"id":"terraform-associate-workflow-1768256282579-1","question":"Scenario: You want to manage separate environments (dev, staging, prod) within a single configuration without duplicating code, and you want to switch environments by selecting a different workspace. Which Terraform feature provides this capability?","answer":"[{\"id\":\"a\",\"text\":\"Multiple state files in separate directories\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Terraform Workspaces\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Modules\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Providers with alias\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- B: Terraform Workspaces\n\n## Why Other Options Are Wrong\n- Option A: Managing separate environments via directories is a common pattern but requires duplicating state files rather than using a single configuration with workspaces.\n- Option C: Modules promote reuse but do not automatically separate environments within a single state.\n- Option D: Providers with alias allow using multiple provider configurations but do not by themselves switch between environments within one state.\n\n## Key Concepts\n- Terraform workspaces for environment separation\n- Shared configuration across environments\n\n## Real-World Application\n- Use a workspace per environment to isolate state while keeping a single codebase, simplifying promoting changes from dev to prod.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Core Workflow","Workspaces","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"workflow","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:18:03.056Z","createdAt":"2026-01-12 22:18:03"},{"id":"terraform-associate-workflow-1768256282579-2","question":"Scenario: In a Terraform configuration, you have two resources that do not reference each other directly, but you need to ensure one is created before the other due to an external service dependency. Which mechanism provides an explicit ordering control?","answer":"[{\"id\":\"a\",\"text\":\"depends_on meta-argument\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Provisioner\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Module outputs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Data sources\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A: depends_on meta-argument\n\n## Why Other Options Are Wrong\n- Option B: Provisioners can impose execution order but are discouraged for core dependencies and should be avoided for critical sequencing.\n- Option C: Module outputs are used to pass data, not to enforce ordering between resources.\n- Option D: Data sources fetch information; they do not enforce creation order between separate resources.\n\n## Key Concepts\n- Explicit dependency management\n- Meta-arguments in Terraform\n\n## Real-World Application\n- Use depends_on to guarantee sequencing when implicit dependencies are not established by inputs/outputs, such as when a downstream system relies on an externally created resource.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Core Workflow","Dependencies","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"workflow","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:18:03.540Z","createdAt":"2026-01-12 22:18:03"},{"id":"terraform-associate-workflow-1768256282579-3","question":"Scenario: You want to force recreation of a resource on next apply without deleting manually, to recover after a drift. Which Terraform command marks a resource for recreation?","answer":"[{\"id\":\"a\",\"text\":\"terraform taint\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"terraform apply -auto-approve\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"terraform refresh\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"terraform state rm\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A: terraform taint\n\n## Why Other Options Are Wrong\n- Option B: apply with -auto-approve only skips the interactive confirmation, it does not mark resources for recreation.\n- Option C: terraform refresh updates state to reflect real infrastructure, not force recreation.\n- Option D: terraform state rm removes a resource from state, not mark it for recreation.\n\n## Key Concepts\n- taint operation\n- Forcing recreation on next apply\n\n## Real-World Application\n- Use taint to trigger replacement when drift is detected or after manual remediation.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Core Workflow","State management","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"workflow","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:18:03.707Z","createdAt":"2026-01-12 22:18:03"},{"id":"terraform-associate-workflow-1768256282579-4","question":"Scenario: You have a module that outputs credentials for another system, and you notice these values appear in the CLI plan output. To prevent exposing sensitive data, which attribute should you set on the output?","answer":"[{\"id\":\"a\",\"text\":\"sensitive = true\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"private = true\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"hide_output = true\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"secure = true\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A: sensitive = true\n\n## Why Other Options Are Wrong\n- Option B: private is not a valid Terraform output attribute for hiding values.\n- Option C: hide_output is not a recognized attribute for outputs in Terraform.\n- Option D: secure is not a recognized attribute for outputs in Terraform.\n\n## Key Concepts\n- Sensitive data handling in Terraform outputs\n- Output customization to mask data\n\n## Real-World Application\n- Use sensitive = true on outputs that contain secrets to prevent leaking values in plan/apply logs and CLI output.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Core Workflow","Security","certification-mcq","domain-weight-15"],"channel":"terraform-associate","subChannel":"workflow","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:18:03.873Z","createdAt":"2026-01-12 22:18:03"}],"subChannels":["general","iac-concepts","modules","terraform-basics","terraform-cloud","terraform-state","workflow"],"companies":["Amazon","Bloomberg","Coinbase","Databricks","Google","Hashicorp","NVIDIA","Netflix","Oracle","Robinhood","Salesforce","Scale Ai","Snap","Snowflake","Square","Tesla"],"stats":{"total":32,"beginner":1,"intermediate":29,"advanced":2,"newThisWeek":32}}