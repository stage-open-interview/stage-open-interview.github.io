{"questions":[{"id":"q-1009","question":"Scenario: a single repo provisions per-tenant AWS resources for many tenants. To isolate state without workspaces, use a shared S3 backend with a DynamoDB lock table and a tenant-scoped key. Describe the backend config (bucket, region, dynamodb_table, key pattern per tenant), how you detect drift across tenants, and CI gating for dev-to-prod promotions (plan -out, tests, approve, apply)?","answer":"Configure a shared S3 backend with per-tenant keys and a single DynamoDB lock table. Backend config example: bucket=tf-backend, region=us-east-1, dynamodb_table=tf-locks, key=tenants/${TENANT_ID}/terr","explanation":"## Why This Is Asked\nTests mastery of multi-tenant state isolation, drift detection, and CI-gated promotions using Terraform remote backend.\n\n## Key Concepts\n- Remote state isolation without workspaces\n- Backend config per-tenant key patterns\n- Centralized locking with DynamoDB\n- Drift detection via plan and refresh\n- CI gating with plan/out, tests, approvals\n\n## Code Example\n```javascript\n# backend-configs/dev.tfbackend\nbucket = \"tf-backend\"\nregion = \"us-east-1\"\ndynamodb_table = \"tf-locks\"\nkey = \"tenants/${TENANT_ID}/terraform.tfstate\"\n```\n\n## Follow-up Questions\n- How would you enforce per-tenant role-based access to the backend?\n- How do you handle tenant onboarding/offboarding when state files move?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Coinbase","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T19:21:33.339Z","createdAt":"2026-01-12T19:21:33.339Z"},{"id":"q-1154","question":"In a Terraform module that provisions an AWS RDS instance, operators sometimes alter maintenance_window directly in AWS, creating drift. You want Terraform to ignore external changes to maintenance_window but still apply code-driven updates (e.g., allocated_storage). How would you implement this using a lifecycle block? Provide a minimal aws_db_instance snippet showing ignore_changes for maintenance_window and outline tradeoffs?","answer":"Use: lifecycle { ignore_changes = [maintenance_window] }. In the aws_db_instance resource, keep allocated_storage driven by config. Caveats: other fields drift remains visible only if not ignored; if ","explanation":"## Why This Is Asked\n\nShows practical drift handling with Terraform state; tests understanding of lifecycle rules and their impact on operations.\n\n## Key Concepts\n\n- Drift and state\n- lifecycle ignore_changes\n- Resource attribute scoping\n\n## Code Example\n\n```javascript\nresource \"aws_db_instance\" \"example\" {\n  identifier         = \"example\"\n  engine             = \"mysql\"\n  instance_class     = \"db.t3.micro\"\n  allocated_storage  = 20\n  maintenance_window = \"sun:23:45-sun:00:15\"\n\n  lifecycle {\n    ignore_changes = [maintenance_window]\n  }\n}\n```\n\n## Follow-up Questions\n\n- What would happen if maintenance_window is changed in code while an apply is in progress?\n- How would you revert drift if needed later?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:37:52.444Z","createdAt":"2026-01-13T01:37:52.444Z"},{"id":"q-1172","question":"In AWS us-east-1, you must provision 3 private subnets in a single VPC across 3 AZs using one module. Define a map variable with AZs and CIDRs, create the subnets with for_each, attach appropriate tags, and output the subnet IDs. Then show how to reference these IDs in a resource that requires subnet_id (eg NAT Gateway) and justify for_each vs count?","answer":"Use a map variable for subnets keyed by AZ, create aws_subnet with for_each, set az and cidr_block from the map, and TAGS. Output the IDs for reuse. Example: create a NAT gateway per subnet by iterati","explanation":"## Why This Is Asked\nAssesses practical use of for_each with maps, resource interdependencies, and stable identities across environments. Delivers hands-on pattern candidates expect in production.\n\n## Key Concepts\n- for_each with maps provides stable keys and predictable IDs\n- referencing attributes from one resource in another (subnet_id in NAT GW)\n- tagging and AZ assignment per subnet\n- outputs to surface IDs for downstream resources\n- when to prefer for_each vs count (stable keys vs positional indexing)\n\n## Code Example\n```javascript\nvariable \"subnets\" {\n  type = map(object({ cidr_block = string; az = string }))\n  default = {\n    az1 = { cidr_block = \"10.0.1.0/24\", az = \"us-east-1a\" },\n    az2 = { cidr_block = \"10.0.2.0/24\", az = \"us-east-1b\" },\n    az3 = { cidr_block = \"10.0.3.0/24\", az = \"us-east-1c\" }\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = var.subnets\n  vpc_id            = var.vpc_id\n  cidr_block        = each.value.cidr_block\n  availability_zone = each.value.az\n  tags = {\n    Name = \"private-${each.key}\"\n  }\n}\n\noutput \"private_subnet_ids\" {\n  value = [for s in aws_subnet.private : s.id]\n}\n```\n\n```javascript\nresource \"aws_nat_gateway\" \"ngw\" {\n  for_each = aws_subnet.private\n  allocation_id = aws_eip.ngw[each.key].id\n  subnet_id     = aws_subnet.private[each.key].id\n}\n```\n\n## Follow-up Questions\n- When would you choose for_each over count in real projects?\n- How would you migrate from count-based to for_each-based resources without breaking state?\n- How would you validate AZ distribution and CIDR correctness after apply?","diagram":"flowchart TD\n  S[Subnets] --> A1[Subnet us-east-1a]\n  S --> A2[Subnet us-east-1b]\n  S --> A3[Subnet us-east-1c]\n  A1 --> NGW[Per-Subnet NAT Gateway]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:37:27.209Z","createdAt":"2026-01-13T03:37:27.209Z"},{"id":"q-1202","question":"Scenario: you must bring under Terraform management a set of existing AWS S3 buckets across teams. Some buckets already exist and must be imported; you will manage encryption and versioning with a single module using for_each over a bucket map. How would you import, structure, and promote changes safely via CI?","answer":"Import existing buckets into state by address, e.g. terraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket; define a map of buckets with per-bucket flags and use for_each to create resources;","explanation":"## Why This Is Asked\n\nThis checks practical import workflows and multi-resource management with for_each, keeping data in sync and enabling safe CI-driven promotions.\n\n## Key Concepts\n\n- terraform import with for_each\n- map of per-bucket settings\n- dynamic blocks for conditional blocks\n- drift reconciliation and idempotency\n- CI/CD validation and promotion\n\n## Code Example\n\n```javascript\nvariable \"buckets\" {\n  type = map(object({\n    encryption = bool\n    versioning = bool\n  }))\n}\nresource \"aws_s3_bucket\" \"bucket\" {\n  for_each = var.buckets\n  bucket = each.key\n  acl    = \"private\"\n\n  dynamic \"versioning\" {\n    for_each = each.value.versioning ? [1] : []\n    content {\n      enabled = true\n    }\n  }\n\n  dynamic \"server_side_encryption_configuration\" {\n    for_each = each.value.encryption ? [1] : []\n    content {\n      rule {\n        apply_server_side_encryption_by_default {\n          sse_algorithm = \"AES256\"\n        }\n      }\n    }\n  }\n}\n```\n\n```javascript\nterraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket\n```\n\n## Follow-up Questions\n\n- How would you handle a bucket rename in the map without recreating?\n- How would you test encryption changes in CI without touching prod data?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","NVIDIA","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:49:50.394Z","createdAt":"2026-01-13T04:49:50.394Z"},{"id":"q-1338","question":"Scenario: You maintain a Terraform repo that provisions an AWS RDS primary in us-east-1 and an optional cross-region read replica in us-west-2 controlled by a feature flag var.enable_replica. If the flag is false, Terraform should destroy the replica on apply. How would you implement the cross-region provider, conditional resource creation, and safe destruction without leaving dangling resources? Provide code patterns for the provider alias and the replica resource?","answer":"Define two AWS providers with aliases (primary us-east-1 and replica us-west-2). Create the replica resource with count = var.enable_replica ? 1 : 0 and assign provider = aws.replica; declare depends_","explanation":"## Why This Is Asked\nThis question tests practical capabilities to manage cross-region resources with provider aliases and conditional creation, ensuring safe destruction when a feature flag disables the replica, and understanding of Terraform lifecycle to avoid downtime.\n\n## Key Concepts\n- provider aliases\n- conditional resource creation with count\n- cross-region dependencies\n- lifecycle create_before_destroy\n- drift and state management\n\n## Code Example\n```javascript\nprovider \"aws\" {\n  region = \"us-east-1\"\n  alias  = \"primary\"\n}\nprovider \"aws\" {\n  region = \"us-west-2\"\n  alias  = \"replica\"\n}\n\nresource \"aws_db_instance\" \"primary\" {\n  provider = aws.primary\n  # ...\n}\n\nresource \"aws_db_instance\" \"replica\" {\n  provider   = aws.replica\n  count      = var.enable_replica ? 1 : 0\n  depends_on = [aws_db_instance.primary]\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n## Follow-up Questions\n- What are the failover considerations for cross-region replicas?\n- How would you test this pattern in CI and guard against accidental destruction?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","NVIDIA","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T11:44:40.993Z","createdAt":"2026-01-13T11:44:40.993Z"},{"id":"q-1367","question":"You\\'re managing 100 AWS subnets defined in a single Terraform module using for_each. A drift occurred in one subnet\\'s route_table_id because it was changed outside Terraform. Describe exactly how you\\'d detect the drift and fix only that resource with zero-drift impact, using Terraform CLI commands. Include the exact commands to init plan, taint the resource, apply with -target, and re-run a full plan to confirm drift-free state?","answer":"Run `terraform init`; then `terraform plan -detailed-exitcode -out=tfplan` and note the exact resource address from the diff (e.g., aws_subnet.env[\"subnet-0a1b2c\"]) . Next run `terraform taint 'aws_su","explanation":"## Why This Is Asked\nTests practical drift remediation techniques on large multi-resource deployments, emphasizing targeted changes and plan-deduplication.\n\n## Key Concepts\n- Drift detection via plan exit codes\n- Resource tainting vs. full apply\n- Targeted applies to minimize blast radius\n- For_each resource addressing\n\n## Code Example\n```bash\nterraform init\nterraform plan -detailed-exitcode -out=tfplan\n# identify address from plan output, e.g. aws_subnet.env[\"subnet-0a1b2c\"]\nterraform taint 'aws_subnet.env[\"subnet-0a1b2c\"]'\nterraform apply -auto-approve -target='aws_subnet.env[\"subnet-0a1b2c\"]'\nterraform plan\n```\n\n## Follow-up Questions\n- How would you automate this across all drifted resources in a single run?\n- How do you ensure idempotence when using -target in CI pipelines?","diagram":"flowchart TD\n  A[Detect Drift] --> B[Identify Resource Address]\n  B --> C[Taint Resource]\n  C --> D[Apply Targeted Changes]\n  D --> E[Re-run Full Plan]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","IBM","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T13:19:56.849Z","createdAt":"2026-01-13T13:19:56.849Z"},{"id":"q-1584","question":"You are refactoring a Terraform repo and moving an existing AWS S3 bucket resource from the root module into a submodule named storage. Describe exact steps and commands to relocate the resource in state without recreation, including the state mv addresses and a follow-up plan?","answer":"Initialize the configuration, identify the current resource address, and relocate it to the target module while preserving all existing data and metadata. Steps:\n- terraform init\n- terraform state list | grep aws_s3_bucket\n- terraform state mv 'aws_s3_bucket.mybucket' 'module.storage.aws_s3_bucket.mybucket'\n- terraform plan\n- terraform apply","explanation":"## Why This Is Asked\nTests knowledge of Terraform state manipulation and module boundaries, including how to relocate existing resources without destruction.\n\n## Key Concepts\n- terraform state mv\n- module addressing with for_each/count\n- plan/apply after a state relocation\n\n## Code Example\n```javascript\nterraform init\nterraform state list | grep aws_s3_bucket\nterraform state mv 'aws_s3_bucket.mybucket' 'module.storage.aws_s3_bucket.mybucket'\nterraform plan\nterraform apply\n```\n\n## Follow-up Questions\n- How would you handle relocation if the bucket name is generated by count/indexed resources?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Instacart","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:41:56.909Z","createdAt":"2026-01-13T22:51:23.435Z"},{"id":"q-1655","question":"You discover an AWS VPC and related resources created outside Terraform and want to bring them under a new network module without recreating. Describe exact steps to import the VPC, its subnets (for_each), and a peering connection into the module, including the resource addresses you’ll use, how to handle multiple subnets, and how to verify with a plan that nothing changes?","answer":"Import external VPC resources into a new module without recreating: 1) init; 2) import VPC: terraform import 'module.network.aws_vpc.vpc' vpc-0a1b2c3d4e5f6g; 3) import subnets: terraform import 'modul","explanation":"## Why This Is Asked\nTests ability to adopt existing infrastructure into a module, mapping real resources to module addresses and avoiding recreation. Also evaluates import ordering, state manipulation, and verification through plan.\n\n## Key Concepts\n- terraform import into module resources\n- addressing for subresources with for_each and modules\n- validating with plan to ensure zero-drift\n- handling cross-account/provider setups if applicable\n\n## Code Example\n```javascript\n# Example module resource blocks (illustrative)\nresource \"aws_vpc\" \"vpc\" { ... }\nresource \"aws_subnet\" \"private\" { for_each = var.private_subnets ... }\nresource \"aws_vpc_peering_connection\" \"peering\" { ... }\n```\n\n## Follow-up Questions\n- How would you map any missing attributes (tags, route tables) to existing state?\n- If some resources are in different accounts, how do you configure providers and imports to avoid conflicts?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:37:20.961Z","createdAt":"2026-01-14T05:37:20.961Z"},{"id":"q-1740","question":"Advanced cross-repo Terraform: network state is stored in a dedicated repo/backends across envs. The application repo imports VPC IDs and subnets via data terraform_remote_state. Explain how you would structure backends and modules to avoid drift, ensure isolation between dev/staging/prod, and orchestrate safe promotions from dev to prod with exact commands for init/plan/apply per environment. Include how you would test drift and rollback?","answer":"Use separate backends per environment; centralize VPC in the network repo; in app, read VPC outputs via terraform_remote_state. Promote via CI gate. Example commands for prod:\\nnetwork: terraform init","explanation":"## Why This Is Asked\n\nTests ability to coordinate Terraform state across repos, manage drift via remote state data, and implement safe promotion paths with environment isolation.\n\n## Key Concepts\n\n- Terraform remote state and data sources\n- Separate backends per environment\n- CI gating and drift testing\n- cross-repo module composition\n\n## Code Example\n\n```hcl\ndata \"terraform_remote_state\" \"network\" {\n  backend = \"s3\"\n  config = {\n    bucket = \"corp-terraform-network\"\n    key    = \"prod/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you handle a read-only remote state during prod promotion?\n- How would you implement a rollback plan if drift is detected post-merge?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T09:01:14.624Z","createdAt":"2026-01-14T09:01:14.624Z"},{"id":"q-1749","question":"You manage a single Terraform repo deploying a shared 'network' module into two AWS accounts (prod and dev) using provider aliases. Describe how you structure the provider blocks, module calls, and var-files to deploy both environments without duplicating code. Include exact commands to init, plan, and apply for each environment, ensuring isolation and no cross-env state changes?","answer":"Create two provider aliases (aws.prod, aws.dev) with distinct regions, and drive the module with for_each over environments. Use providers = { aws = aws.${each.key} } and per-env var-files. Then: terr","explanation":"## Why This Is Asked\nTests understanding of multi-environment deployments without code duplication using provider aliases and module iteration.\n\n## Key Concepts\n- Provider aliases\n- Module instantiation with for_each\n- Per-environment variable files and backends\n- Terraform plan/apply targeting to avoid cross-env changes\n\n## Code Example\n```terraform\nprovider \"aws\" {\n  alias  = \"prod\"\n  region = var.prod_region\n}\nprovider \"aws\" {\n  alias  = \"dev\"\n  region = var.dev_region\n}\nvariable \"prod_region\" { default = \"us-east-1\" }\nvariable \"dev_region\"  { default = \"us-west-2\" }\nvariable \"environments\" {\n  type = map(string)\n  default = { prod = \"prod\", dev = \"dev\" }\n}\nmodule \"network\" {\n  for_each = var.environments\n  source   = \"./modules/network\"\n  providers = { aws = aws[each.value] }\n  # inputs per env\n}\n```\n\n## Follow-up Questions\n- How would you add a new environment without touching existing state?\n- What are the trade-offs of using separate backends versus workspaces for this pattern?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Slack","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T09:38:40.289Z","createdAt":"2026-01-14T09:38:40.289Z"},{"id":"q-1805","question":"How would you implement input validation in a Terraform module to enforce that a variable instance_count is between 1 and 5 and that a string region is one of an allowed set? Provide the approach and expected Terraform behavior during plan and apply?","answer":"Implement input validation in Terraform modules by adding validation blocks inside variable definitions. Example: a number variable must be 1-5 and a string variable region must be one of allowed regi","explanation":"## Why This Is Asked\nGuardrails for input data ensure predictable plans and reduce drift due to outside changes.\n\n## Key Concepts\n- Terraform variable validation blocks\n- contains and range checks via logical expressions\n- error_message behavior on plan/apply\n- user experience when invalid inputs are provided\n\n## Code Example\n```\nvariable \"instance_count\" {\n  type = number\n  validation {\n    condition = var.instance_count >= 1 && var.instance_count <= 5\n    error_message = \"instance_count must be between 1 and 5.\"\n  }\n}\n\nvariable \"region\" {\n  type = string\n  validation {\n    condition = contains([\"us-east-1\", \"us-west-2\", \"eu-west-1\"], var.region)\n    error_message = \"region must be one of us-east-1, us-west-2, eu-west-1.\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you extend validation to a list of allowed instance_types?\n- How would you provide user-friendly error messages for multiple invalid variables?","diagram":"flowchart TD\nA[Input Variables] --> B[Validate instance_count]\nB --> C{Valid?}\nC -->|Yes| D[Proceed to plan]\nC -->|No| E[Fail with error_message]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Square","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T11:40:14.828Z","createdAt":"2026-01-14T11:40:14.828Z"},{"id":"q-1836","question":"Scenario: A Terraform repo uses a module named network that creates subnets via for_each over a map of subnet_id to name. Three subnets were created manually (subnet-aaa, subnet-bbb, subnet-ccc) and must be brought under Terraform control without changing the rest. Describe exact steps and commands to import only these existing subnets into the module state, update the for_each map to include their IDs, and verify drift with a full plan. Include init/plan/apply commands and how to handle dependent resources (route tables, tags)?","answer":"Add a map of existing IDs in the module, then import each subnet into its key: terraform import module.network.aws_subnet[ subnet-aaa ] subnet-aaa-id; terraform import module.network.aws_subnet[ subne","explanation":"## Why This Is Asked\nTests state-management finesse: migrating manual resources into modules, with map-for_each and address syntax; ensures candidate uses proper addresses and verifies drift with full plan.\n\n## Key Concepts\n- State management with terraform import\n- for_each addressing in modules\n- Handling dependencies (route tables, tags)\n\n## Code Example\n```hcl\nmodule \"network\" {\n  source = './modules/network'\n  subnets = {\n    'subnet-aaa' = 'Subnet A'\n    'subnet-bbb' = 'Subnet B'\n    'subnet-ccc' = 'Subnet C'\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test idempotence after import if the manual subnets diverge in tags?\n- What if one subnet is used in a route table association; how ensure no drift on that relation?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T13:18:57.060Z","createdAt":"2026-01-14T13:18:57.060Z"},{"id":"q-1888","question":"Scenario: You manage 120 Cloudflare DNS records in a single Terraform module with for_each. A drift occurred in one record's IP address due to a manual edit in Cloudflare. Describe a surgical plan to detect drift and fix only that resource with zero-drift impact, using Terraform CLI commands. Include the exact commands to init, plan, taint the resource, apply with -target, and re-run a full plan to confirm drift-free state?","answer":"I would run: `terraform init`, then `terraform plan -detailed-exitcode` to surface drift. Identify the address, e.g. `cloudflare_record.example[\"www.example.com\"]`. Then taint: `terraform taint 'cloud","explanation":"## Why This Is Asked\nTests the ability to perform surgical drift repair in a multi-resource Terraform config, including how to locate the exact resource address when using for_each, how to minimize disruption with a targeted apply, and how to validate state after changes.\n\n## Key Concepts\n- Drift detection with `terraform plan` and exit codes\n- Addressing resources in for_each using map keys (e.g. `cloudflare_record.example[\"domain\"]`)\n- Targeted `apply` and replan to ensure drift-free state\n\n## Code Example\n```javascript\n// Terraform snippet for Cloudflare records\nresource \"cloudflare_record\" \"example\" {\n  for_each = var.records\n  zone_id  = data.cloudflare_zones.main.id\n  name     = each.key\n  value    = each.value.ip\n  type     = \"A\"\n  proxied  = false\n}\n```\n\n## Follow-up Questions\n- What if drift affects multiple records? How would you handle batch corrections?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T15:48:22.806Z","createdAt":"2026-01-14T15:48:22.806Z"},{"id":"q-1948","question":"You’re extending a VPC Terraform module to support both a managed NAT Gateway and a NAT instance via a single input variable named nat_type with default 'gateway'. How would you implement this with conditional resources, including the variable, two resource blocks, and outputs? Provide the minimal code and explain how you’d validate with terraform plan to ensure no changes when nat_type remains 'gateway'?","answer":"Add a string variable nat_type with default 'gateway'. Create two resources with conditional counts: aws_nat_gateway { count = var.nat_type == 'gateway' ? 1 : 0 } and aws_instance nat { count = var.na","explanation":"## Why This Is Asked\n\nTests ability to add feature-flag-like behavior in modules without duplicating resources.\n\n## Key Concepts\n\n- Variable defaults and validation\n- Conditional resources with count\n- Outputs referencing conditional resources\n\n## Code Example\n\n```hcl\nvariable \"nat_type\" {\n  description = \"NAT type: gateway or instance\"\n  type        = string\n  default     = \"gateway\"\n}\nresource \"aws_nat_gateway\" \"gw\" {\n  count = var.nat_type == \"gateway\" ? 1 : 0\n  # subnet_id, allocation_id, depends_on...\n}\nresource \"aws_instance\" \"nat\" {\n  count       = var.nat_type == \"instance\" ? 1 : 0\n  # ami, instance_type, subnet_id...\n}\n```\n\n## Follow-up Questions\n\n- How would you surface the active NAT in outputs?\n- What happens if nat_type changes from gateway to instance after apply?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","PayPal","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T18:45:30.274Z","createdAt":"2026-01-14T18:45:30.274Z"},{"id":"q-1976","question":"In a monorepo, a Terraform module provisions a multi-tenant AWS VPC setup with per-tenant isolation via tenant_id. A new tenant must be added without touching existing ones. Describe exact steps and commands to add the tenant using a fresh state segment, ensure no drift to others, and verify with targeted and full plans. Include backend-key organization and apply sequencing?","answer":"Add a new tenant by isolating state with a tenant-scoped backend key and applying only that tenant. Commands:\nexport TENANT_ID=tenantA\nterraform init -backend-config=\"bucket=infra-state\" -backend-conf","explanation":"## Why This Is Asked\nTests ability to safely add a tenant with per-tenant state, avoiding cross-tenant drift in a shared repo. It also exercises precise Terraform CLI usage for init with backend-config, plan/apply sequencing, and drift verification.\n\n## Key Concepts\n- Backend segmentation per tenant via key\n- Targeted init/plan/apply for isolated changes\n- Drift verification across multiple tenants\n- Safe promotions with clear separation of state\n\n## Code Example\n```javascript\n# sample backend config for a tenant (illustrative)\nbackend \\\"s3\\\" {\n  bucket = \\\"infra-state\\\"\n  key    = \\\"tenants/${TENANT_ID}/terraform.tfstate\\\"\n  region = \\\"us-east-1\\\"\n}\n```\n\n## Follow-up Questions\n- How would you parameterize TENANT_ID in CI?\n- How would you handle removing a tenant without orphaning resources?","diagram":"flowchart TD\n  A[Add Tenant] --> B[Init with tenant key]\n  B --> C[Plan]\n  C --> D[Apply]\n  D --> E[Drift verify]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T19:30:52.979Z","createdAt":"2026-01-14T19:30:52.980Z"},{"id":"q-2037","question":"You're provisioning a private API gateway via a custom Terraform provider. Implement a blue/green deployment pattern with two gateway instances and an atomic traffic switch using a single Terraform plan. Describe the exact structure (for_each, modules, and a central traffic_split map), how to prevent unintended recreation, and the precise steps and commands to drift-check and promote from blue to green in prod with minimal blast radius?","answer":"Implement a modular blue/green deployment using a centralized traffic split configuration. Create two gateway instances using `for_each` with color variants (blue/green), managed through a single `traffic_split` map that controls traffic distribution. During promotion, atomically update the map from `{blue=100, green=0}` to `{blue=0, green=100}` and apply the changes.","explanation":"## Why This Is Asked\nTests the ability to design safe blue/green deployment patterns using Terraform with a private provider, focusing on idempotent upgrades and drift control.\n\n## Key Concepts\n- Blue/Green deployment pattern\n- for_each across color variants\n- Central traffic_split map controlling user traffic\n- Lifecycle prevent_destroy to protect active components\n- Drift detection with plan-based validation across environments\n\n## Code Example\n```hcl\nvariable \"traffic_split\" {\n  type    = map(number)\n  default = { blue = 100, green = 0 }\n}\n\nvariable \"gateway_colors\" {\n  type    = list(string)\n  default = [\"blue\", \"green\"]\n}\n\nmodule \"gateway\" {\n  source   = \"./gateway\"\n  for_each = toset(var.gateway_colors)\n  \n  color       = each.key\n  environment = var.environment\n  \n  lifecycle {\n    prevent_destroy = true\n  }\n}\n\nresource \"api_gateway_routing\" \"traffic\" {\n  for_each = var.traffic_split\n  \n  color       = each.key\n  percentage  = each.value\n  gateway_id  = module.gateway[each.key].id\n}\n```\n\n## Promotion Commands\n```bash\n# 1. Plan and validate drift\nterraform plan -var='traffic_split={blue=0,green=100}' -out=green-promotion.tfplan\n\n# 2. Apply atomic switch\nterraform apply green-promotion.tfplan\n\n# 3. Verify traffic distribution\nterraform show | grep traffic_split\n```","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T06:14:31.703Z","createdAt":"2026-01-14T21:44:05.050Z"},{"id":"q-2049","question":"You maintain a per-environment security module that provisions an AWS Security Group with environment-scoped rules (dev, stg, prod). An external admin altered prod inbound 22 to 0.0.0.0/0, causing drift. Describe exact steps to detect the drift and fix prod only, using Terraform CLI with init/plan/apply and a -target run, then re-run a full plan to confirm no drift. Provide the exact resource address to target?","answer":"Initialize the production backend, detect drift with a targeted plan for the specific security group resource, apply the targeted fix, then run a full plan to verify no drift remains. Example commands: terraform init; terraform plan -target=module.security_groups.aws_security_group.prod_sg -out drift.plan; terraform apply drift.plan; terraform plan","explanation":"## Why This Is Asked\nTests practical drift detection and focused remediation in multi-environment Terraform setups, ensuring only the affected resource is modified while maintaining infrastructure integrity.\n\n## Key Concepts\n- Drift detection and isolation across environments\n- Targeted state operations with -target flag\n- Safe verification via full plan after targeted changes\n- Resource addressing in modules (e.g., module.security_groups.aws_security_group.prod_sg)\n\n## Code Example\n```bash\nterraform init\nterraform plan -target=module.security_groups.aws_security_group.prod_sg -out drift.plan\nterraform apply drift.plan\nterraform plan\n```","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T05:53:09.738Z","createdAt":"2026-01-14T22:37:12.335Z"},{"id":"q-2079","question":"In a Terraform repo using a single VPC module across AWS prod and canary via provider aliases, a CIDR change would recreate many subnets. Describe a blue/green deployment strategy that updates production with zero downtime. Include exact commands to initialize, create/apply canary resources with targeted -target, run drift checks, then migrate canary state to prod with terraform state mv and finalize with a full plan?","answer":"Blue/green deployment using two workspaces (prod, canary) with provider aliases (aws.prod, aws.canary). 1) terraform workspace new canary; 2) terraform init; 3) plan -out canary.plan -var env=canary; 4) apply canary.plan; 5) terraform plan -detailed-exitcode to verify no drift; 6) terraform state mv -state-out=prod.tfstate module.vpc.canary module.vpc.prod; 7) terraform workspace select prod; 8) terraform plan to validate final state.","explanation":"## Why This Is Asked\n\nTests the ability to design production-grade deployments that avoid downtime while updating core networking components across multiple environments. It requires understanding of blue/green patterns, state management, and targeted applies across provider aliases.\n\n## Key Concepts\n- Blue/green deployment\n- Terraform workspaces and provider aliases\n- Targeted applies and state mv\n- Drift verification across environments\n\n## Code Example\n```text\n# Commands shown in the answer above (concise summary)\n```\n\n## Follow-up Questions\n- How would you automate the promotion flow with CI/CD pipelines?\n- What rollback strategies would you implement if the canary deployment fails?\n- How would you handle data migration between VPCs during the transition?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T05:31:59.070Z","createdAt":"2026-01-14T23:31:32.109Z"},{"id":"q-2127","question":"You manage a Terraform repo with a Google Cloud IAM bindings module using for_each over projects. A drift occurred when a member was removed in prod outside Terraform. Describe exact steps to detect the drift and fix only prod binding using Terraform CLI with init/plan/apply and a -target run, then re-run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Init and refresh providers, run plan to locate the drift, then apply only the prod binding via -target and verify with a full plan. Example: terraform init -upgrade; terraform plan -out=tfplan; terraf","explanation":"## Why This Is Asked\nTests practical drift handling for IAM bindings across multi-project setups, a common beginner challenge.\n\n## Key Concepts\n- Drift detection via terraform plan\n- Correct resource address for -target\n- Isolating changes to minimize impact\n\n## Code Example\n```javascript\nterraform init -upgrade\nterraform plan -out=tfplan\nterraform apply -target=module.bindings[\"prod\"].google_project_iam_member[\"my-project-prod\",\"roles/storage.objectAdmin\"] tfplan\nterraform plan\n```\n```\n","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Google","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T04:10:59.879Z","createdAt":"2026-01-15T04:10:59.879Z"},{"id":"q-2168","question":"You find an AWS IAM role that was created outside Terraform and you want to bring it under Terraform control without changing its attached policies—what exact steps and commands would you use to import it, reconcile the state, and apply only the intended configuration?","answer":"Create a matching aws_iam_role in Terraform, then run `terraform import aws_iam_role.example <role-name>` to link the existing role to state. Use `terraform state show aws_iam_role.example` to inspect","explanation":"## Why This Is Asked\nTests practical import and drift reconciliation, a common real-world task when adopting existing resources.\n\n## Key Concepts\n- Terraform import to bring unmanaged resources under state\n- State inspection with `state show` to avoid unintended changes\n- Plan vs apply to reconcile config with existing resources\n- Handling policies carefully to avoid accidental privilege changes\n\n## Code Example\n```hcl\nresource \"aws_iam_role\" \"example\" {\n  name = \"example-role\"\n  assume_role_policy = data.aws_iam_policy_document.example.json\n}\n```\n\n## Follow-up Questions\n- How would you handle inline policies vs attached policies during import?\n- How can you verify the role's permissions post-import without applying unintended changes?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Cloudflare","Coinbase"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T05:44:16.868Z","createdAt":"2026-01-15T05:44:16.868Z"},{"id":"q-2212","question":"Scenario: You manage a single Terraform module that provisions a Google Cloud DNS managed zone with multiple A records across environments (dev, staging, prod) using a map variable and a for_each on google_dns_record_set. A drift occurred in prod: the IP of prod A record was manually changed outside Terraform. Describe exact steps to detect drift and fix only prod's A record using Terraform CLI with init/plan/apply and a -target run, then re-run a full plan to confirm drift-free state. Include the exact resource address to target?","answer":"Init, run plan to detect drift, inspect prod with terraform state show google_dns_record_set.record[\\\"prod\\\"], update the prod IP in the config, then apply only prod: terraform apply -target=google_dn","explanation":"## Why This Is Asked\nTests drift detection and precise remediation using Terraform targets.\n\n## Key Concepts\n- drift detection with terraform plan\n- targeting with -target for minimal changes\n- google_dns_record_set and DNS records\n- state vs config reconciliation\n\n## Code Example\n```hcl\nresource \"google_dns_record_set\" \"record\" {\n  for_each = var.dns_records\n  name       = each.value.name\n  type       = 'A'\n  ttl        = 300\n  rrdatas    = [each.value.ip]\n  managed_zone = var.managed_zone\n}\n```\n\n## Follow-up Questions\n- How would you automate drift checks in CI/CD?\n- How would you handle multiple envs drift simultaneously?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Meta","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T07:41:15.205Z","createdAt":"2026-01-15T07:41:15.205Z"},{"id":"q-2238","question":"Scenario: A Terraform module manages an AWS VPC with subnets created outside Terraform. The module uses an aws_vpc.main and a for_each map aws_subnet.subnets keyed by environment (prod, staging). Provide exact commands to import the existing VPC and each subnet without recreation, including their addresses, then run terraform plan to confirm no drift and describe handling if drift is detected?","answer":"Import the VPC: terraform import aws_vpc.main vpc-0a1b2c3d. For subnets, import by for_each key: terraform import 'aws_subnet.subnets[\\\"prod\\\"]' subnet-0d1e2f3a and terraform import 'aws_subnet.subnet","explanation":"## Why This Is Asked\nTests import accuracy and state alignment when resources are managed via modules and for_each.\n\n## Key Concepts\n- terraform import, for_each keys, state alignment, drift\n\n## Code Example\n```bash\nterraform import aws_vpc.main vpc-0a1b2c3d\nterraform import 'aws_subnet.subnets[\"prod\"]' subnet-0d1e2f3a\nterraform import 'aws_subnet.subnets[\"staging\"]' subnet-0a9b8c7d\n```\n\n## Follow-up Questions\n- How would you handle a new environment added later (dev)?\n- What pitfalls exist when resources are renamed or moved in modules?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T08:56:17.020Z","createdAt":"2026-01-15T08:56:17.020Z"},{"id":"q-2337","question":"You maintain a Terraform repo that builds a multi-account AWS network using a root module with per-account submodules. In prod, a single security group rule was manually changed outside Terraform. Describe exact steps to detect drift, fix only prod with a targeted apply, and then re-run a full plan. Include the exact resource address to target and how to ensure prod drift is isolated from other accounts?","answer":"Init the repo, run a targeted plan for prod: terraform plan -target=module.network[\"prod\"].aws_security_group.sg_prod -out prod.tfplan. If drift is detected, apply only that plan: terraform apply prod","explanation":"## Why This Is Asked\nThis tests drift detection and safe, minimal-change remediation in a multi-environment Terraform setup, plus state isolation concepts.\n\n## Key Concepts\n- Terraform plan with -target for surgical fixes\n- State isolation across accounts/workspaces\n- Idempotent apply and drift verification\n- Resource addressing in for_each/module contexts\n\n## Code Example\n```bash\nterraform init\nterraform plan -target=module.network[\"prod\"].aws_security_group.sg_prod -out prod.tfplan\n# review drift via plan output\nterraform apply prod.tfplan\nterraform plan\n```\n\n## Follow-up Questions\n- How would you automate drift detection across all prod resources without -target?\n- What are risks of repeated targeted applies in a CI pipeline?","diagram":"flowchart TD\n  A[Drift Detected in prod SG] --> B[Run targeted plan for prod SG]\n  B --> C{Drift present?}\n  C -->|Yes| D[Apply prod plan]\n  C -->|No| E[Run full plan to verify]\n  D --> F[Run full plan for drift-free state]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T13:12:22.149Z","createdAt":"2026-01-15T13:12:22.149Z"},{"id":"q-2345","question":"A Terraform repo provisions a VPC, subnets, and an EC2 instance. A central tagging policy is required via a local default_tags map and an optional input var.tags, applied to all resources without duplicating tags. Describe exact steps to implement this, including how to merge tags in each resource, how to handle resources that cannot be tagged, and how to validate with a full plan before apply. Include a minimal code snippet showing how to declare the variables and apply tags to the VPC and EC2 instance?","answer":"Add an optional map variable and a local default_tags merge; apply tags via merge(local.default_tags, var.tags) in every resource. Steps: declare variable \"tags\" type = map(string) default = {}; local","explanation":"## Why This Is Asked\nTests ability to implement a centralized tagging policy across resources, a common real-world pattern to ensure consistency and compliance in Terraform configurations.\n\n## Key Concepts\n- Centralized tagging via local merges\n- Handling resources that may not support tags\n- Safe extension with optional input maps and environment variables\n- Validation through full plan/apply cycles\n\n## Code Example\n```javascript\nvariable \"environment\" { type = string }\nvariable \"tags\" { type = map(string), default = {} }\n\nlocals {\n  default_tags = merge({ Environment = var.environment, Project = \"infra\" }, var.tags)\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n  tags       = local.default_tags\n}\n\nresource \"aws_subnet\" \"public\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"10.0.1.0/24\"\n  tags       = local.default_tags\n}\n\n```\n\n## Follow-up Questions\n- How would you propagate default_tags to modules that declare their own resources?\n- What strategies exist if some resources cannot be tagged due to provider limitations?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T14:34:54.576Z","createdAt":"2026-01-15T14:34:54.576Z"},{"id":"q-2470","question":"You find an existing Google Compute Engine instance named \\\"web-1\\\" that wasn't created by Terraform but should be managed by the Terraform module at path modules/infra with a for_each over a map of instances. Describe exact steps to import that instance into state, including the resource address you would use for the import, what to add to the code to match the real-world instance, and how you verify drift with a full terraform plan after the import (no recreation)?","answer":"Use terraform import to bind the existing resource to its Terraform address, e.g., module.infra.google_compute_instance.web[\"web-1\"]. Before importing, define a matching resource block in code (name, ","explanation":"## Why This Is Asked\nTests the ability to bring existing, unmanaged resources under Terraform control and align state with configuration, a common real-world task.\n\n## Key Concepts\n- terraform import and resource addresses inside modules/for_each\n- state management and aligning code with existing resources\n- validating drift with full plan after import\n\n## Code Example\n```terraform\nresource \"google_compute_instance\" \"web\" {\n  for_each = var.instances\n  name = each.value.name\n  zone = each.value.zone\n  # other required fields must match the real instance\n}\n```\n\n## Follow-up Questions\n- What if the import reveals attributes not present in code? How would you fix?\n- How do you handle importing multiple instances efficiently with for_each?\n- How does import affect existing state locking or backend configuration?","diagram":"flowchart TD\n  A[Identify unmanaged resource] --> B[Define matching Terraform block]\n  B --> C[Run import with address]\n  C --> D[Plan and align] \n  D --> E[Plan confirms drift-free state]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T19:34:19.220Z","createdAt":"2026-01-15T19:34:19.220Z"},{"id":"q-2563","question":"You manage a Terraform repo deploying a shared AWS network module across three accounts with for_each over accounts to create security groups. In account \"acct-b\" a security group rule’s CIDR was manually changed outside Terraform. Describe exact steps to detect drift and fix only that resource with zero-drift impact, using Terraform CLI init/plan -detailed-exitcode, then a -target run, and finally a full plan. Include the exact resource address to target?","answer":"Execute `terraform init` followed by `terraform plan -detailed-exitcode` to detect drift across all accounts. Use `terraform state list` to identify the specific security group resource address for acct-b, typically formatted as `module.network[\"acct-b\"].aws_security_group.sg[\"web-internal\"]`. Then run a targeted plan and apply using `-target` to remediate only that drifted resource: `terraform plan -target=module.network[\"acct-b\"].aws_security_group.sg[\"web-internal\"]` and `terraform apply -target=module.network[\"acct-b\"].aws_security_group.sg[\"web-internal\"]`. Finally, run `terraform plan` again to confirm zero drift across all resources.","explanation":"## Why This Is Asked\nTests drift detection and surgical targeting capabilities in multi-account Terraform environments where manual changes require precise remediation without disrupting other resources.\n\n## Key Concepts\n- Drift detection using `plan -detailed-exitcode`\n- Targeted resource remediation with `-target`\n- Managing state across multiple module instances\n- Zero-diff verification after targeted fixes\n\n## Code Example\n```bash\n# Initialize and detect drift\nterraform init\nterraform plan -detailed-exitcode\n\n# Identify drifted resource\nterraform state list | grep acct-b\n\n# Targeted remediation\nterraform plan -target=module.network[\"acct-b\"].aws_security_group.sg[\"web-internal\"]\nterraform apply -target=module.network[\"acct-b\"].aws_security_group.sg[\"web-internal\"]\n\n# Verify zero drift\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle multiple drifted resources in the same account?\n- What precautions should you take before running targeted applies?\n- How can you prevent manual changes to Terraform-managed resources?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T05:22:52.052Z","createdAt":"2026-01-15T22:52:47.090Z"},{"id":"q-2610","question":"In a Terraform repo with two modules, networking (producing vpc_id and public_subnet_ids as outputs) and app (consuming them), configure and use a remote state data source to read networking's outputs from a remote backend and reference them in app. Provide exact code for data 'terraform_remote_state' and show how to use outputs.vpc_id and outputs.public_subnet_ids in the app module. Assume AWS S3 backend?","answer":"Configure a remote state data source in the app module to read networking outputs from S3. In app/main.tf, declare:\n\n```hcl\ndata \"terraform_remote_state\" \"networking\" {\n  backend = \"s3\"\n  config = {\n    bucket = \"infra-state\"\n    key    = \"networking/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  subnet_id = data.terraform_remote_state.networking.outputs.public_subnet_ids[0]\n  vpc_id    = data.terraform_remote_state.networking.outputs.vpc_id\n  # ... additional configuration\n}\n```","explanation":"## Why This Is Asked\nTests knowledge of cross-module references via remote state in multi-module Terraform repositories.\n\n## Key Concepts\n- Remote state data source for inter-module communication\n- S3 backend configuration\n- Output consumption across separate Terraform configurations\n\n## Implementation Notes\nThe `terraform_remote_state` data source enables the app module to access outputs from the networking module's state file stored in S3, facilitating loose coupling between modules while maintaining infrastructure dependencies.","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Databricks","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T05:01:42.064Z","createdAt":"2026-01-16T02:41:10.310Z"},{"id":"q-2800","question":"You maintain a Terraform repo that provisions a shared VPC, subnets, and compute instances for a LinkedIn-like service. You want to deploy dev and prod from the same codebase with isolated state using Terraform workspaces and a remote S3 backend. Describe exact backend config, workspace setup, and the precise command sequence to initialize, create/select the dev and prod workspaces, and apply environment-specific var-files without state leakage. Include sample backend config and commands?","answer":"Use a remote S3 backend with per-workspace keys (env/${terraform.workspace}/terraform.tfstate) and a DynamoDB lock. Configure bucket, region, and key in the backend. Commands: terraform init; terrafor","explanation":"## Why This Is Asked\nTests understanding of environment isolation using Terraform workspaces with a remote backend, a common pattern at scale.\n\n## Key Concepts\n- Terraform workspaces for env isolation\n- Remote backend (S3) and state locking (DynamoDB)\n- Per-workspace state keys to prevent leakage\n- Environment-specific var-files\n\n## Code Example\n```javascript\nterraform {\n  required_version = \">= 1.5\"\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"env/${terraform.workspace}/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-state-lock\"\n    encrypt        = true\n  }\n}\n```\n\n## Follow-up Questions\n- How would you migrate existing state to workspaces without loss of resources?\n- What happens if a workspace is deleted and later recreated?","diagram":"flowchart TD\n  A[Initialize] --> B[Dev workspace]\n  B --> C[Apply dev]\n  C --> D[Prod workspace]\n  D --> E[Apply prod]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T13:06:07.493Z","createdAt":"2026-01-16T13:06:07.493Z"},{"id":"q-2854","question":"You're managing a Terraform repo that provisions GCP organization policies across 30 projects using google_organization_policy with for_each on project IDs. In prod, a policy constraint was loosened manually for one project. Describe exact, repeatable steps to detect this drift, identify the impacted project, and fix only that project's policy using Terraform CLI (init/plan/apply) with a targeted -target, followed by a full plan to verify no drift. Include the exact resource address you would target?","answer":"Run terraform plan -detailed-exitcode to detect drift. Inspect the plan output to identify the impacted resource address, e.g. google_organization_policy.restrict_public_ip[\"projects/proj-123\"]. Then ","explanation":"## Why This Is Asked\nTests the candidate's ability to perform precise, surgical drift repair in a multi-resource, multi-project Terraform setup, including identifying the exact resource to fix and validating with full plan afterward.\n\n## Key Concepts\n- Terraform drift detection with plan -detailed-exitcode\n- TargetedApply for surgical state reconciliation\n- Reading resource state with terraform state show\n- Importance of idempotent, auditable changes across many projects\n\n## Code Example\n```hcl\nresource \"google_organization_policy\" \"restrict_public_ip\" {\n  constraint = \"constraints/compute.disablePublicIp\"\n  project    = \"projects/${var.project_id}\"\n  boolean_policy { enforced = true }\n}\n```\n\n## Follow-up Questions\n- How would you guard against future drift in this scenario (e.g., tooling automation, CI checks)?\n- What are the risks of using -target in a large deployment, and how to mitigate them?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","PayPal","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T14:48:47.416Z","createdAt":"2026-01-16T14:48:47.416Z"},{"id":"q-2874","question":"Context: You deploy Snowflake warehouses via Terraform provider. In prod, a manual change increased max_cluster_count from 4 to 8. How would you detect drift and fix only prod using Terraform CLI (init, plan, apply) with a -target run, then re-run a full plan to confirm drift-free state? Include the exact resource address to target: snowflake_warehouse.prod_warehouse[\\\"prod\\\"]?","answer":"Init the repo, run a targeted plan for prod: terraform plan -target snowflake_warehouse.prod_warehouse[\\\"prod\\\"] -out tfplan-prod; then terraform apply tfplan-prod. If needed, run terraform plan again","explanation":"## Why This Is Asked\nThis question tests drift detection and surgical remediation in a multi-environment Snowflake setup using Terraform, focusing on precise addressing and minimal blast radius.\n\n## Key Concepts\n- Drift detection via terraform plan\n- Targeted apply with -target\n- Correct addressing for for_each-style resources\n- Verifying state with a full plan after targeted changes\n\n## Code Example\n```terraform\n# example target address\nsnowflake_warehouse.prod_warehouse[\"prod\"] {\n  max_cluster_count = 8\n}\n```\n\n## Follow-up Questions\n- How would you extend this to handle multiple environments with -target in a single run?\n- How would you guard against drift in resources sourced from external data sources?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T15:44:11.755Z","createdAt":"2026-01-16T15:44:11.755Z"},{"id":"q-2946","question":"You manage a Terraform repo deploying a multi-region VPC via a network module applied with for_each over regions. In eu-west-1 a route in the VPC's route_table was manually changed outside Terraform. Describe exact steps to detect drift and fix only that region's route resource with zero-drift impact, using Terraform init/plan -detailed-exitcode, then terraform apply -target=module.network[\"eu-west-1\"].aws_route_table.this, and a final full plan. Include the exact resource address to target?","answer":"Run: terraform init; terraform plan -detailed-exitcode to surface drift; note drifted address (example: module.network[\"eu-west-1\"].aws_route_table.this). Then: terraform apply -target=module.network[","explanation":"## Why This Is Asked\nTests the ability to isolate region-specific drift in a for_each across regions and perform a targeted fix without impacting others.\n\n## Key Concepts\n- Drift detection via terraform plan -detailed-exitcode\n- Addressing with module.network[\"eu-west-1\"].aws_route_table.this\n- Targeted apply vs full plan\n- Verifying drift-free state with a final plan\n\n## Code Example\n```bash\nterraform init\nterraform plan -detailed-exitcode\nterraform apply -target=module.network[\"eu-west-1\"].aws_route_table.this\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle drift if there are multiple drifted entries in the same region?\n- What if -target returns non-zero due to dependency that requires recomputation?","diagram":"flowchart TD\n  A[Init] --> B[Plan -detailed-exitcode]\n  B --> C[Identify drift address]\n  C --> D[Apply -target]\n  D --> E[Full plan]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Anthropic","Cloudflare"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T18:50:52.265Z","createdAt":"2026-01-16T18:50:52.265Z"},{"id":"q-3035","question":"Across three AWS accounts (dev, staging, prod), a shared VPC module creates per-account security groups with for_each over accounts and a nested for_each over rules. In prod, an inbound rule for 203.0.113.0/24 on TCP 22 was removed via manual change. Describe exact steps to detect the drift and fix only prod binding using Terraform CLI with init/plan/apply and a -target run, then re-run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Initialize Terraform; run a targeted plan for the production rule: `terraform plan -out prod.plan -target=module.network[\"prod\"].aws_security_group_rule[\"ssh-prod-22\"]`; inspect the plan output; if it shows the missing rule needs to be created, apply it: `terraform apply prod.plan`; then run a full plan to verify no drift remains: `terraform plan`","explanation":"## Why This Is Asked\n\nTests drift detection and precise, minimal remediation in a multi-account Terraform setup, emphasizing how for_each affects resource addressing across modules.\n\n## Key Concepts\n\n- Targeted plan/apply to fix a single drifted resource\n- Correct resource address for nested for_each: `module.network[\"prod\"].aws_security_group_rule[\"ssh-prod-22\"]`\n- Verifying drift with a full plan after targeted remediation\n\n## Code Example\n\n```bash\nterraform init\nterraform plan -out prod.plan -target=module.network[\"prod\"].aws_security_group_rule[\"ssh-prod-22\"]\nterraform apply prod.plan\nterraform plan\n```","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T05:36:27.250Z","createdAt":"2026-01-16T22:29:43.977Z"},{"id":"q-3105","question":"Scenario: A Terraform repo manages multi-region Kubernetes clusters via a module using for_each over regions. In prod, a Kubernetes deployment manifest (kubernetes_manifest) was manually modified outside Terraform, creating drift only in prod. Describe exact steps to detect drift with terraform plan -detailed-exitcode, fix only prod by applying a targeted change (terraform apply -target=module.k8s[\"prod\"].kubernetes_manifest[\"app-deploy\"]), then run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Run the following commands in sequence: terraform init; terraform plan -detailed-exitcode -target=module.k8s[\"prod\"].kubernetes_manifest[\"app-deploy\"]; if the exit code is 2 (indicating drift), execute terraform apply -target=module.k8s[\"prod\"].kubernetes_manifest[\"app-deploy\"]; finally, run terraform plan -detailed-exitcode to confirm no drift across all regions.","explanation":"## Why This Is Asked\n\nThis scenario tests the ability to isolate and resolve drift in a specific environment while avoiding unintended changes across multi-region deployments. It demonstrates practical Terraform CLI skills for targeted drift detection and remediation.\n\n## Key Concepts\n\n- terraform plan -detailed-exitcode for drift detection\n- -target addressing for selective operations\n- Module and for_each addressing syntax\n- Kubernetes provider resource management\n- Exit code interpretation (0=no changes, 1=error, 2=changes+drift)\n\n## Code Example\n\n```bash\nterraform init\nterraform plan -detailed-exitcode -target=module.k8s[\"prod\"].kubernetes_manifest[\"app-deploy\"]\n# If exit code is 2 (drift detected):\nterraform apply -target=module.k8s[\"prod\"].kubernetes_manifest[\"app-deploy\"]\n# Final verification:\nterraform plan -detailed-exitcode\n```","diagram":"flowchart TD\n  Init --> PlanTargetProd\n  PlanTargetProd --> ApplyTargetProd\n  ApplyTargetProd --> PlanFull\n  PlanFull --> DriftFree","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","MongoDB","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T04:54:00.870Z","createdAt":"2026-01-17T02:23:05.379Z"},{"id":"q-3278","question":"Context: Terraform repo deploys Azure Linux VMs across regions via a module with for_each over regions. In prod, a single VM size was manually changed outside Terraform, causing drift for prod only. Describe exact steps to detect drift, identify prod VM, and fix only prod VM with a targeted change, including the exact resource address to target (e.g., module.compute[\\\"prod\\\"].azurerm_linux_virtual_machine[\\\"web01\\\"]). Also outline verification with a final full plan?","answer":"Detect drift by running terraform refresh to sync state, then terraform plan with -target=module.compute[\\\"prod\\\"].azurerm_linux_virtual_machine[\\\"web01\\\"]. Compare outputs to config. If drift appears","explanation":"## Why This Is Asked\nTests drift detection and precise targeted remediation in a real Azure VM scenario.\n\n## Key Concepts\n- drift detection via refresh and targeted plan\n- applying changes with -target to minimize blast radius\n- validating state with a final full plan\n- handling for_each across regions in modules\n\n## Code Example\n```bash\nterraform init\nterraform refresh -target=module.compute[\"prod\"].azurerm_linux_virtual_machine[\"web01\"]\nterraform plan -target=module.compute[\"prod\"].azurerm_linux_virtual_machine[\"web01\"]\nterraform apply -target=module.compute[\"prod\"].azurerm_linux_virtual_machine[\"web01\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would this scale to hundreds of prod VMs?\n- What are risks of using -target in production plans?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T09:41:01.133Z","createdAt":"2026-01-17T09:41:01.133Z"},{"id":"q-3334","question":"In a multi-env AWS deployment, a data source feeds a dynamic IP allowlist used by aws_security_group_rule resources. A drift occurs in prod when the allowlist updates. Explain how to implement lifecycle { replace_triggered_by = [data.external.allowlist.version] } in prod rules to force replacement only on allowlist changes, and show exact commands to detect drift (terraform plan -detailed-exitcode) and apply a targeted change with terraform apply -target=module.network[\"prod\"].aws_security_group_rule[\"sg-prod-https\"], then re-run a full plan to confirm no drift. Include an address pattern example?","answer":"Add lifecycle { replace_triggered_by = [data.external.allowlist.version] } to prod aws_security_group_rule blocks and fetch the allowlist with data \"external\" \"allowlist\". Run: terraform plan -detaile","explanation":"## Why This Is Asked\n\nTests understanding of safe, targeted drift remediation using Terraform's lifecycle and -target, avoiding mass changes.\n\n## Key Concepts\n\n- Lifecycle replace_triggered_by\n- Data external sources for dynamic inputs\n- Targeted applies with -target to minimize blast radius\n\n## Code Example\n\n```hcl\nresource \"aws_security_group_rule\" \"https_prod\" {\n  type              = \"ingress\"\n  from_port         = 443\n  to_port           = 443\n  protocol          = \"tcp\"\n  security_group_id = module.network[\"prod\"].aws_security_group.web.id\n  cidr_blocks       = data.external.allowlist.result\n  lifecycle {\n    replace_triggered_by = [data.external.allowlist.version]\n  }\n}\n\ndata \"external\" \"allowlist\" {\n  program = [\"bash\",\"scripts/get_allowlist.sh\"]\n}\n```\n\n## Follow-up Questions\n\n- How would you test this in canary before prod rollout?\n- How do you handle partial failures if -target changes multiple resources?\n","diagram":"flowchart TD\n  A[Detect drift] --> B[Run plan -detailed-exitcode]\n  B --> C{Drift detected?}\n  C -->|Yes| D[Apply targeted change]\n  C -->|No| E[Run full plan to confirm]\n  D --> F[Run plan -detailed-exitcode again]\n  F --> G[Confirm drift-free state]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T11:40:33.336Z","createdAt":"2026-01-17T11:40:33.336Z"},{"id":"q-3407","question":"You're maintaining a Terraform repo that uses a top-level module with for_each over environments (prod, staging) and two provider aliases (aws.prod, aws.staging). In prod, a security group rule allowing 0.0.0.0/0 ingress on port 22 was changed manually. Describe exact steps to detect drift and fix only prod drift using Terraform CLI: init, plan -detailed-exitcode, apply -target=module.network[\"prod\"].aws_security_group.this, then a full plan to confirm no drift. Include the exact resource address to target?","answer":"Run terraform init, then terraform plan -detailed-exitcode. If drift is detected, run terraform apply -target=module.network[\"prod\"].aws_security_group.this to revert prod only. Re-run terraform plan ","explanation":"## Why This Is Asked\nTests ability to reason about drift, environments, and targeted remediation without affecting other envs.\n\n## Key Concepts\n- Drift detection via plan exit codes\n- Resource targeting in multi-env modules\n- Provider aliasing and -target limitations\n\n## Code Example\n```bash\nterraform init\nterraform plan -detailed-exitcode\nterraform apply -target=module.network[\"prod\"].aws_security_group.this\n```\n\n## Follow-up Questions\n- How would you handle drift across multiple keys or rules?\n- How to automate drift checks in CI/CD?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T14:43:46.699Z","createdAt":"2026-01-17T14:43:46.699Z"},{"id":"q-3578","question":"Scenario: A Terraform repo provisions cross-account AWS IAM roles via a module named network using for_each over accounts. In prod, an IAM role tenant_access exists in AWS but drift is detected due to a manual policy change. Describe exact steps to detect drift with terraform plan -detailed-exitcode, then fix prod by importing the drifted resource into state and applying a targeted update using terraform apply -target=module.network[\"prod\"].aws_iam_role[\"tenant_access\"] followed by a full plan. Include the exact resource address to target: module.network[\"prod\"].aws_iam_role[\"tenant_access\"]?","answer":"Run `terraform plan -detailed-exitcode` to detect drift. If changes are detected, import the drifted resource into state with: `terraform import module.network[\"prod\"].aws_iam_role[\"tenant_access\"]`. Then update the configuration to match the actual state and apply the targeted fix with `terraform apply -target=module.network[\"prod\"].aws_iam_role[\"tenant_access\"]`, followed by a full `terraform plan` to verify no additional drift exists.","explanation":"## Why This Is Asked\n\nTests practical drift handling in a multi-account Terraform setup, including import-based remediation and targeted applies, plus interpreting plan exit codes for real fixes.\n\n## Key Concepts\n\n- `terraform plan -detailed-exitcode` for drift detection\n- `terraform import` for drifted resources\n- Targeted apply with `-target`\n- Cross-account state management\n\n## Code Example\n\n```bash\nterraform plan -detailed-exitcode\nterraform import module.network[\"prod\"].aws_iam_role[\"tenant_access\"]\nterraform apply -target=module.network[\"prod\"].aws_iam_role[\"tenant_access\"]\nterraform plan\n```","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Databricks","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T05:41:55.477Z","createdAt":"2026-01-17T22:29:18.324Z"},{"id":"q-3613","question":"In a Terraform repo that uses a module named network and for_each to create per-environment NAT Gateways across prod and staging, the prod NAT Gateway was created manually outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the prod NAT Gateway into the correct module address to bring it under Terraform control, run a targeted apply to refresh state, and then run a full plan to ensure no drift remains. Include the exact resource address to target?","answer":"Start with `terraform plan -detailed-exitcode` to detect drift. If it returns exit code 2, run: `terraform import 'module.network[\"prod\"].aws_nat_gateway.this' <nat-gw-id>` to bring the prod NAT Gateway under Terraform control. Then execute `terraform plan -target='module.network[\"prod\"].aws_nat_gateway.this'` followed by `terraform apply -target='module.network[\"prod\"].aws_nat_gateway.this'` to refresh state. Finally, run `terraform plan` to verify no drift remains.","explanation":"## Why This Is Asked\n\nTests practical drift repair workflows involving imports and targeted applies across modules.\n\n## Key Concepts\n\n- Terraform state management with imports\n- Addressing module resources with for_each\n- Targeted plans and zero-drift fixes\n- Remote state and plan exit codes\n\n## Code Example\n\n```bash\nterraform plan -detailed-exitcode\nterraform import 'module.network[\"prod\"].aws_nat_gateway.this' <nat-gw-id>\nterraform plan -target='module.network[\"prod\"].aws_nat_gateway.this'\nterraform apply -target='module.network[\"prod\"].aws_nat_gateway.this'\nterraform plan\n```\n\n## Follow-up","diagram":"flowchart TD\n  A[Prod NATGW drift] --> B[Plan detects drift]\n  B --> C[Import prod NATGW]\n  C --> D[Plan targeted]\n  D --> E[Apply targeted]\n  E --> F[Full plan: drift-free]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T05:15:02.419Z","createdAt":"2026-01-17T23:37:07.900Z"},{"id":"q-3727","question":"In a Terraform repo using module network with for_each over environments and provider aliases (aws, azurerm) to manage multi-cloud resources, prod Azure Virtual Network azurerm_virtual_network.prod_vnet exists outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted resource into state, then run a targeted apply to bring prod in line (terraform apply -target=module.network[\"prod\"].azurerm_virtual_network[\"prod_vnet\"]), followed by a full plan. Include the exact address to target?","answer":"1) Run terraform init; then terraform plan -detailed-exitcode to detect drift. If exit code 2, import the drifted resource: terraform import 'module.network[\"prod\"].azurerm_virtual_network[\"prod_vnet\"","explanation":"## Why This Is Asked\nTests ability to handle cross-cloud drift and state management with imports and targeted applies in a multi-provider setup.\n\n## Key Concepts\n- Terraform plan exit codes and drift detection\n- terraform import for unmanaged resources\n- Module addresses with for_each and provider aliases\n- Targeted applies to minimize risk\n\n## Code Example\n```bash\nterraform init\nterraform plan -detailed-exitcode\n# if exit code 2:\nterraform import 'module.network[\"prod\"].azurerm_virtual_network[\"prod_vnet\"]' '<AZURE_VNET_ID>'\nterraform apply -target='module.network[\"prod\"].azurerm_virtual_network[\"prod_vnet\"]'\nterraform plan\n```\n\n## Follow-up Questions\n- How would you scale this to multiple environments in parallel?\n- What are the risks of repeated state imports in CI/CD pipelines?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T07:28:32.684Z","createdAt":"2026-01-18T07:28:32.684Z"},{"id":"q-3848","question":"Scenario: A Terraform repo uses a module named dns with for_each over domains to manage Cloudflare DNS records. In prod, a CNAME record api_prod.example.com was manually added outside Terraform, causing drift. Describe exact steps to detect drift with terraform plan -detailed-exitcode, fix prod by importing the drifted Cloudflare record into the state under module.dns[\"prod\"], then run a targeted apply to refresh: terraform apply -target=module.dns[\"prod\"].cloudflare_record[\"api_prod\"], followed by a full plan to confirm no drift. Include the exact resource address to target?","answer":"Run terraform plan -detailed-exitcode to detect drift (exit 2). From plan, the address is module.dns[\"prod\"].cloudflare_record[\"api_prod\"]. Import with terraform import module.dns[\"prod\"].cloudflare_r","explanation":"## Why This Is Asked\nTests drift handling for DNS records managed by Cloudflare in a multi-domain setup, focusing on plan exit codes, state import, and targeted fixes.\n\n## Key Concepts\n- terraform plan -detailed-exitcode semantics\n- resource addressing with modules and for_each\n- terraform import for Cloudflare records\n- targeted apply and full plan verification\n\n## Code Example\n```javascript\n# Steps\nterraform plan -detailed-exitcode\n# if drift detected (exit 2)\nterraform import module.dns[\"prod\"].cloudflare_record[\"api_prod\"] <record_id>\nterraform apply -target=module.dns[\"prod\"].cloudflare_record[\"api_prod\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you scale this to multiple prod records?\n- How do you handle drift when the address is generated by for_each keys?","diagram":"flowchart TD\n  A[Start] --> B[terraform plan -detailed-exitcode]\n  B --> C{drift?}\n  C -- yes --> D[Identify resource address: module.dns[\"prod\"].cloudflare_record[\"api_prod\"]]\n  D --> E[terraform import module.dns[\"prod\"].cloudflare_record[\"api_prod\"] <record_id>]\n  E --> F[terraform apply -target=module.dns[\"prod\"].cloudflare_record[\"api_prod\"]]\n  F --> G[terraform plan]\n  C -- no --> H[Done]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Netflix","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T12:54:57.072Z","createdAt":"2026-01-18T12:54:57.075Z"},{"id":"q-3963","question":"Scenario: A Terraform repo uses a module named database with for_each over environments to create AWS RDS instances. In prod, an RDS instance was manually modified outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted RDS into state, run a targeted apply to bring prod back in line (terraform apply -target=module.database[\\\"prod\\\"].aws_db_instance[\\\"prod\\\"]), then run a full plan to confirm no drift. Include the exact address to target?","answer":"Run terraform init, then terraform plan -detailed-exitcode to detect drift. If exit code is 2, import the prod RDS into state: terraform import 'module.database[\\\"prod\\\"].aws_db_instance[\\\"prod\\\"]' <i","explanation":"## Why This Is Asked\n\nTests the ability to recover drift in a multi-environment module using precise state management, plan exit codes, and targeted applies without impacting other environments.\n\n## Key Concepts\n\n- plan -detailed-exitcode behavior\n- terraform import for for_each/module addresses\n- -target semantics for selective applies\n- difference between drift and state reconciliation\n\n## Code Example\n\n```bash\nterraform init\nterraform plan -detailed-exitcode\nterraform import 'module.database[\"prod\"].aws_db_instance[\"prod\"]' <identifier>\nterraform apply -target=module.database[\"prod\"].aws_db_instance[\"prod\"]\nterraform plan\n```\n\n## Follow-up Questions\n\n- How would you handle scattered drift across environments concurrently?\n- What are risks of frequent imports in CI pipelines?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Oracle","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T17:34:50.286Z","createdAt":"2026-01-18T17:34:50.287Z"},{"id":"q-3992","question":"Scenario: A Terraform repo uses a Cloudflare module with for_each over environments (prod, staging, dev) to manage DNS records. In prod, a DNS A record for webapp.example.com was created manually outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted record into state at the correct address, run a targeted apply to bring prod in line (terraform apply -target=module.cloudflare[\"prod\"].cloudflare_record[\"webapp\"]), and then run a full plan to verify no drift. Include the exact resource address to target?","answer":"Run terraform plan -detailed-exitcode to confirm drift. If drift is detected, import the drifted Cloudflare DNS record into state: terraform import module.cloudflare[\"prod\"].cloudflare_record[\"webapp\"","explanation":"## Why This Is Asked\nTests drift handling in multi-environment Cloudflare resources, emphasizing state import and targeted applies.\n\n## Key Concepts\n- Terraform plan exit codes and drift\n- terraform import with Cloudflare IDs\n- module addressing: module.cloudflare[\"prod\"].cloudflare_record[\"webapp\"]\n- per-environment state management\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform import module.cloudflare[\"prod\"].cloudflare_record[\"webapp\"] <zone_id>_<record_id>\nterraform apply -target=module.cloudflare[\"prod\"].cloudflare_record[\"webapp\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle a second drift in staging while keeping prod safe?\n- How would you automate drift remediation across many records?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Cloudflare","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T18:50:56.199Z","createdAt":"2026-01-18T18:50:56.199Z"},{"id":"q-4047","question":"Scenario: A Terraform repo uses a module named cloud-network with for_each over environments to manage Google Cloud firewall rules. In prod, firewall rule prod-allow-internal was manually changed outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, fix prod only via a targeted apply (module.cloud-network[\"prod\"].google_compute_firewall[\"prod-allow-internal\"]), and then run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Run `terraform plan -detailed-exitcode` in the prod workspace to detect drift (exit code 2 indicates changes). If drift is detected, apply the fix using: `terraform apply -target=module.cloud-network[\"prod\"].google_compute_firewall[\"prod-allow-internal\"]`. Then run `terraform plan` again to confirm no drift remains.","explanation":"## Why This Is Asked\nTests ability to detect and rectify drift with minimal blast radius using targeted applies. It also checks understanding of for_each addressing and workflow with plan -detailed-exitcode.\n\n## Key Concepts\n- Terraform drift detection with detailed exit codes\n- State management and targeted applies\n- Correct resource addressing in modules with for_each\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform apply -target=module.cloud-network[\"prod\"].google_compute_firewall[\"prod-allow-internal\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle multiple environments with drift?\n- What precautions would you take before running targeted applies?\n- How would you automate drift detection across environments?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T06:07:12.258Z","createdAt":"2026-01-18T21:30:27.474Z"},{"id":"q-4101","question":"A Terraform repo uses module storage with for_each over environments (dev, prod) to create S3 buckets in AWS. Prod uses a separate AWS account via provider alias aws.prod. Describe exact steps to configure provider aliases, assign the correct provider to each env, and validate changes with plan/apply so prod changes are isolated?","answer":"Create two provider blocks with aliases 'dev' and 'prod' pointing to separate AWS accounts. In the module call, bind per-environment instances using: providers = { aws = aws.dev, aws.prod = aws.prod }. Then run: terraform plan -target=module.storage[dev] to validate dev changes, followed by terraform plan -target=module.storage[prod] to validate prod changes in isolation. Apply each environment separately using the same targeting approach.","explanation":"## Why This Is Asked\nTests understanding of multi-account setups and provider aliasing in modules. It also checks proper targeting and drift-free validation.\n\n## Key Concepts\n- Terraform providers and aliases\n- Module-level provider configuration\n- For_each environment handling\n- Plan vs apply drift checks\n\n## Code Example\n```hcl\nprovider \"aws\" {\n  alias = \"dev\"\n  # credentials for dev account\n}\n\nprovider \"aws\" {\n  alias = \"prod\"\n  # credentials for prod account\n}\n\nmodule \"storage\" {\n  for_each = var.environments\n  source   = \"./modules/storage\"\n  providers = {\n    aws = aws.dev\n    aws.prod = aws.prod\n  }\n}\n```","diagram":"flowchart TD\n  A[Define two providers (dev, prod)] --> B[Bind providers to module with for_each]\n  B --> C[terraform init && plan -out plan.out]\n  C --> D[Apply prod plan only]\n  D --> E[Run full plan to confirm drift-free state]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Coinbase","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:32:48.604Z","createdAt":"2026-01-18T23:43:30.558Z"},{"id":"q-4117","question":"Scenario: A Terraform repo uses module \"network\" with for_each over environments (prod, staging) to create AWS subnets. In prod, a subnet was renamed outside Terraform from aws_subnet[\"prod_subnet\"] to aws_subnet[\"prod-private\"]. The AWS subnet remains, state holds the old address. Describe exact steps to detect drift, migrate state with terraform state mv and/or import, and a targeted apply to bring prod in line without touching staging. Include the exact addresses to target?","answer":"To resolve this issue: First, identify the drifted address by examining the state: `terraform state list | grep 'module.network.*prod'`. The old address will be `module.network[\"prod\"].aws_subnet[\"prod_subnet\"]`. Next, migrate the state using: `terraform state mv 'module.network[\"prod\"].aws_subnet[\"prod_subnet\"]' 'module.network[\"prod\"].aws_subnet[\"prod-private\"]'`. Validate the change with a targeted plan: `terraform plan -target=module.network[\"prod\"].aws_subnet[\"prod-private\"]`. Finally, apply the changes: `terraform apply -target=module.network[\"prod\"].aws_subnet[\"prod-private\"]`.","explanation":"## Why This Is Asked\nTests knowledge of Terraform state manipulation, drift detection, and targeted changes across environments without affecting others.\n\n## Key Concepts\n- Terraform state and module addressing\n- terraform state mv and import commands\n- Drift detection using plan operations\n- Targeted apply strategies and full plan validation\n\n## Code Example\n```bash\n# Find drifted address in prod\nterraform state list | grep \"module.network.*prod\"\n\n# Move old address to new address\nterraform state mv 'module.network[\"prod\"].aws_subnet[\"prod_subnet\"]' 'module.network[\"prod\"].aws_subnet[\"prod-private\"]'\n\n# Validate with targeted plan\nterraform plan -target=module.network[\"prod\"].aws_subnet[\"prod-private\"]\n\n# Apply changes to prod only\nterraform apply -target=module.network[\"prod\"].aws_subnet[\"prod-private\"]\n\n# Verify with full plan to ensure staging unaffected\nterraform plan\n```\n\n## Professional Notes\nThis approach isolates changes to the production environment while maintaining staging integrity, demonstrating advanced Terraform operational skills.","diagram":"flowchart TD\n  A[Drift Detected] --> B[Identify Old Address]\n  B --> C[Run terraform state mv]\n  C --> D[Plan -target]\n  D --> E[Apply -target]\n  E --> F[Full Plan to Verify]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:09:26.637Z","createdAt":"2026-01-19T02:50:22.097Z"},{"id":"q-4275","question":"Scenario: A Terraform repo uses module 'network' with for_each over regions and a prod account provider alias. In prod, an aws_vpc_peering_connection named \\\"prod_to_shared\\\" was created manually outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted resource into the correct module address (e.g., module.network[\\\"prod\\].aws_vpc_peering_connection[\\\"prod_to_shared\\\"]), perform a targeted apply to bring prod in line, then run a full plan. Include the exact resource address to target?","answer":"Run terraform plan -detailed-exitcode. If exit code 2, import drifted resource: terraform import 'module.network[\"prod\"].aws_vpc_peering_connection[\"prod_to_shared\"]' <peering-id>. Then apply targeted","explanation":"## Why This Is Asked\nThis tests drift handling across for_each maps and cross-account providers, requiring precise import addresses and targeted applies.\n\n## Key Concepts\n- terraform plan exit codes\n- terraform import with module addresses\n- for_each and resource addressing\n- cross-account provider alias\n\n## Code Example\n```javascript\nterraform plan -detailed-exitcode\nterraform import 'module.network[\"prod\"].aws_vpc_peering_connection[\"prod_to_shared\"]' <peering-id>\nterraform apply -target='module.network[\"prod\"].aws_vpc_peering_connection[\"prod_to_shared\"]'\nterraform plan\n```\n\n## Follow-up Questions\n- How would you verify the imported resource aligns with VPC routing tables?\n- How would you handle drift in multiple peering connections with for_each across prod and staging?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Meta","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T11:04:02.599Z","createdAt":"2026-01-19T11:04:02.599Z"},{"id":"q-4291","question":"You want to run dev and prod using a single Terraform repo with a single backend, using workspaces to isolate state. You deploy an AWS S3 bucket and a DynamoDB table for state locking. Describe the minimal steps to structure the code so that bucket name is workspace specific, how to configure backend to use the workspaces, how to switch workspaces, and how to verify that plans apply only to the active workspace?","answer":"Use a single backend with workspaces and derive the bucket name from terraform.workspace via a locals map. Example: locals { bucket_names = { dev = logs-dev, prod = logs-prod } }; bucket = local.bucke","explanation":"## Why This Is Asked\nTests understanding of Terraform workspaces, backends, and state isolation in a realistic setup.\n\n## Key Concepts\n- Terraform workspaces for environment isolation\n- Single backend strategy\n- Using terraform.workspace in configuration\n- Plan/apply isolation across workspaces\n\n## Code Example\n```hcl\nlocals {\n  bucket_names = {\n    dev  = 'logs-dev',\n    prod = 'logs-prod'\n  }\n}\n\nresource \"aws_s3_bucket\" \"logs\" {\n  bucket = local.bucket_names[terraform.workspace]\n  acl    = \"private\"\n}\n```\n\n## Follow-up Questions\n- How would you handle adding a new workspace newenv without changing code?\n- How would you verify state isolation in CI pipelines?","diagram":"flowchart TD\n  Workspace --> Backend\n  Backend --> Plan\n  Plan --> Apply\n  Apply --> Validation","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Microsoft","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T11:38:17.264Z","createdAt":"2026-01-19T11:38:17.264Z"},{"id":"q-4419","question":"In a Terraform repo with a monitoring module that creates multiple Datadog monitors per environment using a for_each over environments, prod drift exists because a monitor was created outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted monitor into the module address, run a targeted apply to refresh state, and then run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Detect drift with: terraform plan -detailed-exitcode. The drifted monitor address will look like module.monitoring[\\\"prod\\\"].datadog_monitor[\\\"cpu_alert\\\"]. Import via: terraform import 'module.monito","explanation":"## Why This Is Asked\nTests ability to recover drift without duplicating or destroying resources; validates import and targeted apply workflows.\n\n## Key Concepts\n- Terraform plan -detailed-exitcode for drift signaling\n- module address syntax with for_each: module.monitoring[\"prod\"].datadog_monitor[\"cpu_alert\"]\n- terraform import and targeted apply\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform import 'module.monitoring[\"prod\"].datadog_monitor[\"cpu_alert\"]' MONITOR_ID\nterraform apply -target=module.monitoring[\"prod\"].datadog_monitor[\"cpu_alert\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle multiple drifted monitors in prod in a single import?\n- What are potential pitfalls of using -target for drift remediation?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T18:00:12.063Z","createdAt":"2026-01-19T18:00:12.063Z"},{"id":"q-4771","question":"In a Terraform repo using a single backend with multiple workspaces (dev, staging, prod), prod has drift after a manual firewall rule change in a VPC module. Describe exact steps to detect drift with plan -detailed-exitcode, switch to the prod workspace, import the drifted resource into state if needed, perform a targeted apply to reconcile prod only (provide the exact address to target), then run a full plan to confirm no drift?","answer":"Switch to the prod workspace, run terraform plan -detailed-exitcode to reveal drift, and ensure state is isolated per workspace. If drift exists, import the drifted resource into state with terraform ","explanation":"## Why This Is Asked\nTests understanding of Terraform workspaces, drift detection, and targeted reconciliation in a real-world, beginner-friendly scenario.\n\n## Key Concepts\n- Terraform workspaces for environment isolation\n- plan -detailed-exitcode to detect drift\n- targeted apply to fix specific resources\n- terraform import to bring drifted resources into state\n- state management across environments\n\n## Code Example\n```bash\n# Switch to prod workspace\nterraform workspace select prod\n\n# Detect drift\nterraform plan -detailed-exitcode\n```\n\n```bash\n# Import if needed\nterraform import module.network[\"prod\"].aws_security_group[\"prod_sg\"] <resource-id>\n\n# Apply targeted change\nterraform apply -target=module.network[\"prod\"].aws_security_group[\"prod_sg\"] -auto-approve\n```\n\n```bash\n# Final plan to verify\nterraform plan -detailed-exitcode\n```\n\n## Follow-up Questions\n- How would you handle drift if the resource address changes across environments?\n- What are risks of relying on targeted applies in production, and how can you mitigate them?","diagram":"flowchart TD\n  A[Start] --> B[Switch to prod workspace]\n  B --> C[terraform plan -detailed-exitcode]\n  C --> D{Drift detected?}\n  D -->|Yes| E[Import drifted resource into state]\n  D -->|Yes| F[Apply targeted change]\n  E --> F\n  F --> G[terraform plan]\n  G --> H[No drift]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T11:44:42.064Z","createdAt":"2026-01-20T11:44:42.065Z"},{"id":"q-4858","question":"In a Terraform repo that provisions AWS KMS keys per region using the kms module with for_each over regions, prod drift: an externally created KMS key exists (alias 'alias/prod_key'). Describe exact steps to detect drift with terraform plan -detailed-exitcode, fix prod by importing the drifted key into state and applying a targeted update (terraform apply -target=module.kms[\"prod\"].aws_kms_key[\"prod_key\"]) followed by a full plan. Include the exact resource address to target?","answer":"Use terraform plan -detailed-exitcode to detect drift. If prod shows changes, run: terraform import 'module.kms[\"prod\"].aws_kms_key[\"prod_key\"]' <drifted_arn> to bring it under state, then terraform a","explanation":"## Why This Is Asked\nTests practical state reconciliation for per-region resources, including precise address handling and import steps.\n\n## Key Concepts\n- State import for for_each-managed resources\n- Targeted apply and subsequent full plan validation\n- Correct module/resource addressing in dynamic maps\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform import 'module.kms[\"prod\"].aws_kms_key[\"prod_key\"]' <drifted_arn>\nterraform apply -target=module.kms[\"prod\"].aws_kms_key[\"prod_key\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle cascading drift if the key is referenced by other resources?\n- How would you extend this to auto-detect drift across multiple regions in CI/CD?","diagram":"flowchart TD\n  A[Detect drift with plan -detailed-exitcode] --> B[Import drifted resource into state]\n  B --> C[Apply targeted change]\n  C --> D[Run full plan to verify]\n  D --> E[No drift confirm]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T16:46:23.078Z","createdAt":"2026-01-20T16:46:23.079Z"},{"id":"q-4925","question":"You currently maintain a Terraform repo that uses a local state file to manage a single AWS environment. The team wants to switch to a centralized remote state to prevent conflicts. Describe the exact steps to switch from local state to an S3 backend with DynamoDB locking, including the backend configuration, how to migrate the existing state, and how to verify that the migration preserved resources and did not introduce drift?","answer":"Add a backend.tf with an S3 bucket, key, region, and a DynamoDB lock table. Run terraform init -migrate-state to move the local state to S3, then approve. Run terraform plan to verify no drift. Update","explanation":"## Why This Is Asked\n\nThis question tests practical understanding of Terraform remote state migration and drift risk.\n\n## Key Concepts\n\n- Backend configuration and remote state\n- State migration with terraform init -migrate-state\n- Drift verification via terraform plan\n- CI/CD considerations for shared state\n\n## Code Example\n\n```hcl\nterraform {\n  required_version = \">= 1.0.0\"\n  backend \\\"s3\\\" {\n    bucket = \\\"my-terraform-state\\\"\n    key = \\\"env/dev/terraform.tfstate\\\"\n    region = \\\"us-east-1\\\"\n    dynamodb_table = \\\"terraform-lock\\\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- What issues could arise if the bucket policy blocks read/write during migration?\n- How would you test rollback if migration fails?","diagram":"flowchart TD\n  A[Local state] --> B[Configure backend]\n  B --> C[terraform init -migrate-state]\n  C --> D[Remote state]\n  D --> E[terraform plan]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T19:22:07.393Z","createdAt":"2026-01-20T19:22:07.393Z"},{"id":"q-4966","question":"Scenario: Terraform repo refactors module.network from environment-scoped for_each to a nested map, changing address from module.network[\\\"prod\\\"].aws_security_group[\\\"prod_sg\\\"] to module.network[\\\"prod\\\"][\\\"aws_security_group\\\"][\\\"prod_sg\\\"]. In prod, the SG exists in AWS but is not in state under the new address. Describe exact steps to reconcile: (1) verify old resource in state, (2) run terraform state mv to the new address, e.g. 'module.network[\\\"prod\\\"].aws_security_group[\\\"prod_sg\\\"]' to 'module.network[\\\"prod\\\"][\\\"aws_security_group\\\"][\\\"prod_sg\\\"]', (3) run plan -detailed-exitcode, (4) apply if changes surfaced, (5) run a full plan. Include the exact addresses to target?","answer":"Move the state entry from the old address to the new one using terraform state mv, then run plan -detailed-exitcode to verify drift. If needed, apply the change, and finally run a full plan to confirm.","explanation":"## Why This Is Asked\nTests ability to handle state address changes from refactors using terraform state mv.\n\n## Key Concepts\n- State addressing after module refactors\n- terraform state mv to preserve resources\n- drift verification with plan -detailed-exitcode\n\n## Code Example\n```javascript\nterraform state mv 'module.network[\"prod\"].aws_security_group[\"prod_sg\"]' 'module.network[\"prod\"][\"aws_security_group\"][\"prod_sg\"]'\n```\n\n## Follow-up Questions\n- How would you scale this approach to dozens of resources across many environments?\n- What are the risks if dependencies are outside Terraform during this process?","diagram":"flowchart TD\n  A[Old Address] --> B[New Address]\n  B --> C[Plan -detailed-exitcode]\n  C --> D[Apply/Refresh]\n  D --> E[Full Plan]\n","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T06:05:53.732Z","createdAt":"2026-01-20T21:47:20.297Z"},{"id":"q-5156","question":"Scenario: A Terraform repo uses a module infra that provisions resources across AWS and GCP with provider aliases. In prod, a GCP firewall rule prod-allow-ssh was manually changed to allow 0.0.0.0/0 on port 22. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted resource into the correct state address, and run a targeted apply to restore Terraform control (e.g., terraform apply -target=module.infra[\\\"prod\\\"].google_compute_firewall[\\\"prod-allow-ssh\\\"]). Then run a full plan to confirm no drift, including the exact resource address you target?","answer":"Run terraform plan -detailed-exitcode to detect drift. If non-zero, import the drifted GCP firewall: terraform import 'module.infra[\"prod\"].google_compute_firewall[\"prod-allow-ssh\"]' 'projects/PROJECT","explanation":"## Why This Is Asked\n\nTests practical drift remediation across clouds, including correct addressing and import workflow, and evaluating risks of targeted applies vs full plan.\n\n## Key Concepts\n\n- Terraform plan -detailed-exitcode for drift detection\n- terraform import for bringing externally modified resources under control\n- Targeted apply to a specific resource address\n- Maintaining correct module/provider addresses in multi-cloud setups\n\n## Code Example\n\n```bash\nterraform plan -detailed-exitcode\n\n# If drift detected (exit code 2):\nterraform import 'module.infra[\"prod\"].google_compute_firewall[\"prod-allow-ssh\"]' 'projects/PROJECT/global/firewalls/prod-allow-ssh'\n\nterraform apply -target='module.infra[\"prod\"].google_compute_firewall[\"prod-allow-ssh\"]'\n\nterraform plan\n```\n\n## Follow-up Questions\n\n- How would you automate this drift remediation in CI/CD?\n- What risks exist with -target and how can you mitigate drift in large graphs?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T08:48:31.055Z","createdAt":"2026-01-21T08:48:31.056Z"},{"id":"q-5226","question":"Scenario: You manage a Terraform repo provisioning a data lake via a module named lake that uses for_each over environments and cloud_providers (aws, gcp). In prod, a resource within the prod gcp submodule storage_bucket prod_bucket was modified outside Terraform, causing drift only in prod. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted resource into the correct module path, and perform a targeted apply to bring prod in line, including the exact module and resource addresses to target for both providers?","answer":"Run terraform plan -detailed-exitcode to detect drift. Import drifted resources into state, e.g.: terraform import 'module.lake[\"prod\"].gcp_storage_bucket[\"prod_bucket\"]' and, if applicable, 'module.l","explanation":"## Why This Is Asked\n\nTests practical drift repair across multi-cloud modules with for_each, focusing on exact state manipulation and precise addressing.\n\n## Key Concepts\n- Terraform state import for drift repair\n- Nested module addressing with for_each over environments and providers\n- Targeted applies vs full plan for production safety\n\n## Code Example\n\n```hcl\n# conceptual addresses\nmodule.lake[\"prod\"].gcp_storage_bucket[\"prod_bucket\"]\nmodule.lake[\"prod\"].aws_s3_bucket[\"prod_bucket\"]\n```\n\n## Follow-up Questions\n- How would you automate drift repairs in CI/CD?\n- How do you handle drift when the resource is re-created due to provider changes?","diagram":"flowchart TD\n  A[Start] --> B[Run terraform plan -detailed-exitcode]\n  B --> C{Drift detected?}\n  C -->|Yes| D[Identify drifted addresses: module.lake[\"prod\"].gcp_storage_bucket[\"prod_bucket\"] and module.lake[\"prod\"].aws_s3_bucket[\"prod_bucket\"]]\n  D --> E[Import drifted resources into state]\n  E --> F[Apply targeted changes]\n  F --> G[Run full plan to verify drift-free]\n  C -->|No| H[Done]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","OpenAI","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:36:30.688Z","createdAt":"2026-01-21T11:36:30.689Z"},{"id":"q-5360","question":"Scenario: A Terraform repo uses module dns with for_each over environments to create per-env Route53 private hosted zones and records in prod and staging. In prod, an A-record app_prod.example.internal was created manually outside Terraform, causing drift. Describe exact steps to detect drift with terraform plan -detailed-exitcode, then fix prod by importing the drifted Route53 record into state and applying a targeted update using terraform apply -target=module.dns[\"prod\"].aws_route53_record[\"app_prod\"], followed by a full plan to confirm no drift. Include the exact resource address to target: module.dns[\"prod\"].aws_route53_record[\"app_prod\"]?","answer":"Run terraform plan -detailed-exitcode to detect drift. If exit code is 2, import the prod drifted Route53 record into the state at module.dns[\"prod\"].aws_route53_record[\"app_prod\"] using terraform imp","explanation":"## Why This Is Asked\nTests drift handling across modules using for_each across environments, emphasizing exact resource addressing, import, and targeted apply.\n\n## Key Concepts\n- plan -detailed-exitcode for drift detection\n- terraform import with module addressing and for_each\n- -target semantics for precise reconciliation\n- AWS Route53 resource addressing in modules\n- multi-env state discipline\n\n## Code Example\n```hcl\n# Example module usage with for_each\nmodule \"dns\" {\n  source = \"./modules/dns\"\n  envs   = [\"prod\", \"staging\"]\n}\n```\n\n```bash\nterraform plan -detailed-exitcode\n# if exit code 2 (drift)\nterraform import 'module.dns[\"prod\"].aws_route53_record[\"app_prod\"]' ZONEID_app_prod_A\nterraform apply -target='module.dns[\"prod\"].aws_route53_record[\"app_prod\"]'\nterraform plan\n``` \n\n## Follow-up Questions\n- How would you automate this drift remediation across environments?\n- What are risks of importing during ongoing changes by CI/CD?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T19:12:28.222Z","createdAt":"2026-01-21T19:12:28.222Z"},{"id":"q-5449","question":"Scenario: A Terraform repo uses a module named net with for_each over environments (dev, prod). In prod, a VPC security group prod_sg was manually modified in AWS outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, identify the resource address for the prod SG, import the drifted resource if needed, perform a targeted apply to restore prod (terraform apply -target=module.net[\\\"prod\\\"].aws_security_group[\\\"prod_sg\\\"]), and then run a full plan to confirm no drift. Include the exact address to target?","answer":"Run `terraform plan -detailed-exitcode` to detect drift. The production resource address is `module.net[\"prod\"].aws_security_group[\"prod_sg\"]`. If drift is detected, import the drifted security group: `terraform import module.net[\"prod\"].aws_security_group[\"prod_sg\"] sg-0123456789`, then apply the targeted fix: `terraform apply -target=module.net[\"prod\"].aws_security_group[\"prod_sg\"]`, and finally run `terraform plan` to confirm no drift.","explanation":"## Why This Is Asked\nTests understanding of state drift, targeted updates, and module addressing.\n\n## Key Concepts\n- Drift detection with `plan -detailed-exitcode`\n- Resource addressing in modules with `for_each`\n- `terraform import` for bringing external changes under state\n- Targeted apply and full plan verification\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\n# if drift detected\nterraform import module.net[\"prod\"].aws_security_group[\"prod_sg\"] sg-0123456789\nterraform apply -target=module.net[\"prod\"].aws_security_group[\"prod_sg\"]\nterraform plan\n```\n\n## Follow-up Questions\n- What happens if the import fails?\n- How would you handle multiple drifted resources?\n- When would you use `terraform state pull` instead of import?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Salesforce","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T05:58:54.391Z","createdAt":"2026-01-21T22:51:48.708Z"},{"id":"q-5632","question":"Describe exact steps a beginner should take to diagnose and safely recover from a stale Terraform state lock when a remote backend (S3 with DynamoDB lock) blocks plan or apply. Include how to inspect the DynamoDB lock entry, decide if it's stale, when to use terraform force-unlock, how to reinitialize, switch to the correct workspace, and how to verify no drift after applying?","answer":"Begin by confirming the lock in DynamoDB and whether a process is actually running. If no active operation exists, release the lock with terraform force-unlock <LOCK_ID>, then re-run terraform init -r","explanation":"## Why This Is Asked\nTests understanding of remote state lock management, safe unlocking, and workspace handling in real workflows.\n\n## Key Concepts\n- Remote state locking\n- DynamoDB lock entry inspection\n- terraform force-unlock safety\n- Workspace management\n\n## Code Example\n```javascript\n# Examples - AWS DynamoDB and Terraform unlock flow (pseudo)\naws dynamodb get-item --table-name terraform_lock --key '{\"LockID\":{\"S\":\"lock-01\"}}'\nterraform force-unlock lock-01\nterraform init -reconfigure\nterraform workspace select prod\nterraform plan\nterraform apply\n```\n\n## Follow-up Questions\n- What are risks of force-unlock and how to mitigate?\n- How would you handle multiple environments with CI pipelines?","diagram":"flowchart TD\n  A[Start] --> B[Check DynamoDB lock entry]\n  B --> C{Is operation active?}\n  C -->|Yes| D[Wait or escalate]\n  C -->|No| E[terraform force-unlock]\n  E --> F[terraform init -reconfigure]\n  F --> G[Select workspace]\n  G --> H[terraform plan]\n  H --> I[terraform apply]\n  I --> J[terraform plan]\n  J --> K[Done]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Microsoft","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T09:05:47.492Z","createdAt":"2026-01-22T09:05:47.492Z"},{"id":"q-5653","question":"In a Terraform repo using module iam with for_each over accounts prod and staging to manage AWS IAM roles, prod role has an extra inline policy attached outside Terraform. Describe exact steps to detect drift with plan -detailed-exitcode, import or align the drifted role into the module's state, and apply-only the prod target to reconcile, then re-run a full plan and verify no drift remains?","answer":"Run terraform init and plan -detailed-exitcode to detect drift. Use terraform state show to inspect prod role; if not in state, import it: terraform import 'module.iam[\"prod\"].aws_iam_role[\"prod_role\"","explanation":"## Why This Is Asked\nTests drift handling in multi-account Terraform with module addressing and targeted reconciliation.\n\n## Key Concepts\n- Drift detection with plan -detailed-exitcode\n- Importing drifted resources into module addresses with for_each\n- Targeted apply and full plan validation across accounts\n- Verifying no drift post-reconciliation\n\n## Code Example\n```javascript\nterraform init\nterraform plan -detailed-exitcode\nterraform import 'module.iam[\"prod\"].aws_iam_role[\"prod_role\"]' arn:aws:iam::PROD:role/app-user\n# align code to desired policies\nterraform apply -target=module.iam[\"prod\"].aws_iam_role[\"prod_role\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle similar drift for managed policies attached to the same role?\n- How would you automate this drift reconciliation across environments?","diagram":"flowchart TD\n  A[Identify drift with plan -detailed-exitcode] --> B{In state?}\n  B -- Yes --> C[Check policy diff]\n  B -- No --> D[Import resource]\n  C --> E[Apply target to prod]\n  D --> E\n  E --> F[Run full plan to verify drift-free]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Stripe","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T10:07:02.902Z","createdAt":"2026-01-22T10:07:02.902Z"},{"id":"q-5724","question":"In a Terraform repo using a module named network with for_each over environments prod and staging, a VPC peering connection was created manually in prod. Terraform plan shows drift. Describe exact steps to detect drift with plan -detailed-exitcode, import the drifted resource into the correct module address module.network[\"prod\"].aws_vpc_peering_connection.prod_peering, then run a targeted apply to bring prod in line (terraform apply -target=module.network[\"prod\"].aws_vpc_peering_connection.prod_peering), followed by a full plan to confirm no drift. Include the exact resource address to target and the commands for provider/alias context if multiple regions exist?","answer":"Run terraform plan -detailed-exitcode to confirm drift. If non-zero, import drifted prod resource: terraform import module.network[\"prod\"].aws_vpc_peering_connection.prod_peering <peering-id>. Then fi","explanation":"## Why This Is Asked\nTests drift handling, state reconciliation, and targeted fixes across module addresses, mirroring real-world multi-environment Terraform work.\n\n## Key Concepts\n- Drift detection with detailed exit codes\n- Importing drifted resources into the correct module address\n- Targeted apply versus full plan\n- Accurate module/resource addressing in for_each scenarios\n\n## Code Example\n```bash\n# Detect drift\nterraform plan -detailed-exitcode\n\n# Import drifted resource (prod peering)\nterraform import module.network[\"prod\"].aws_vpc_peering_connection.prod_peering <peering-id>\n\n# Reconcile state for the drifted resource\nterraform apply -target=module.network[\"prod\"].aws_vpc_peering_connection.prod_peering\n\n# Full plan to verify no drift\nterraform plan\n```\n```\n\n## Follow-up Questions\n- How would you handle multiple drifted resources across environments?\n- What are the risks of importing resources with partial attribute matches, and how do you mitigate them?","diagram":"flowchart TD\n  A[Plan detects drift] --> B[Import drifted resource]\n  B --> C[Apply targeted]\n  C --> D[Full plan to verify drift]\n  D --> E[Done]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Hashicorp","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T13:19:10.430Z","createdAt":"2026-01-22T13:19:10.430Z"},{"id":"q-5856","question":"Scenario: In prod env, the S3 bucket policy for prod-logs drifted in a Terraform repo that uses a storage module with for_each over environments. Outline exact steps: detect drift with terraform plan -detailed-exitcode, import the drifted policy into state at address module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"], then apply a targeted change with terraform apply -target=module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"]. Finally run a full plan. Use the exact address: module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"]?","answer":"Run a plan with DetailedExitCode to detect drift; if exit code is 2, import the drifted policy into state: terraform import 'module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"]' prod-logs-","explanation":"## Why This Is Asked\nTests ability to handle drift in a per-environment policy resource inside a module using for_each. It verifies precise state manipulation and targeted changes without full re-apply.\n\n## Key Concepts\n- terraform plan -detailed-exitcode behavior\n- terraform import for moduleed resources\n- resource address syntax with for_each and modules\n- targeted apply vs full plan\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\n# if exit code 2 (drift)\nterraform import 'module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"]' prod-logs-bucket\nterraform apply -target=module.storage[\"prod\"].aws_s3_bucket_policy[\"prod_logs_policy\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle drift if the resource is recreated outside Terraform?\n- What changes are needed to ensure idempotence across environments after reconciliation?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T19:36:28.595Z","createdAt":"2026-01-22T19:36:28.595Z"},{"id":"q-5934","question":"In a Terraform repo refactoring a multi-env setup, prod AWS VPC was created outside Terraform after splitting module.network into per-env blocks. Describe exact steps to detect drift with terraform plan -detailed-exitcode, relocate the drifted resource into the correct module address, then run a targeted apply to converge prod before performing a full plan. Include the exact resource address to target?","answer":"Execute `terraform plan -detailed-exitcode` to detect drift. Use `terraform state list` to identify the drifted resource address, then relocate it with `terraform state mv <old_address> module.network[\"prod\"].aws_vpc[\"prod_vpc\"]`. Finally, run `terraform apply -target=module.network[\"prod\"].aws_vpc[\"prod_vpc\"]` to converge the prod environment before performing a full plan.","explanation":"## Why This Is Asked\nTests practical drift resolution after module refactoring and cross-environment state management.\n\n## Key Concepts\n- State management across modules\n- Terraform state manipulation (mv and import)\n- Targeted apply and full plan validation\n\n## Code Example\n```bash\n# Detect drift\nterraform plan -detailed-exitcode\n\n# Relocate drifted resource\nterraform state mv <old_address> module.network[\"prod\"].aws_vpc[\"prod_vpc\"]\n\n# Apply targeted fix\nterraform apply -target=module.network[\"prod\"].aws_vpc[\"prod_vpc\"]\n\n# Validate full configuration\nterraform plan\n```\n\n## Follow-up Questions","diagram":"flowchart TD\n  A[Drift detected] --> B[Find old address]\n  B --> C[move state]\n  C --> D[targeted apply]\n  D --> E[full plan verify]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T05:41:30.949Z","createdAt":"2026-01-22T22:40:58.919Z"},{"id":"q-5949","question":"You are maintaining a Terraform repo for multi-environment AWS deployments (dev, staging, prod) using S3 + DynamoDB. Vault-based per-environment secrets rotation is required, but Vault endpoints are reachable only from prod. Describe a concrete plan to implement rotation without drift, using provider aliasing, per-env data sources, and a separate secrets module/state. Include exact commands to test drift with terraform plan -detailed-exitcode, target rotation with -target, and validate post-rotate state?","answer":"Architect a Vault-backed secrets module with a prod-only provider alias, expose only Vault data references in the main module, and maintain secret content exclusively in Vault to prevent state storage. For rotation, target the specific secrets module using `-target=module.secrets` and validate with `terraform plan -detailed-exitcode` to detect drift.","explanation":"## Why This Is Asked\n\nThis question evaluates your ability to design secure secret rotation across environments while preventing secrets from being stored in Terraform state, avoiding drift, and maintaining a single source of truth.\n\n## Key Concepts\n\n- Provider aliasing per environment\n- Vault-backed data sources versus stored state\n- Targeted plan/apply operations for rotation\n- Drift validation using terraform state pull and Vault inventory\n\n## Code Example\n\n```hcl\nprovider \"vault\" {\n  alias   = \"prod\"\n  address = \"https://vault.prod.example.com\"\n  token   = var.vault_prod_token\n}\n\ndata \"vault_generic_secret\" \"prod_app\" {\n  provider = vault.prod\n  path     = \"secret/data/prod/app\"\n}\n\nmodule \"secrets\" {\n  source   = \"./modules/secrets\"\n  providers = {\n    vault = vault.prod\n  }\n  environment = var.environment\n}\n```\n\n## Testing Commands\n\n```bash\n# Check for drift before rotation\nterraform plan -detailed-exitcode\n\n# Target only secrets module for rotation\nterraform apply -target=module.secrets\n\n# Validate no drift exists post-rotation\nterraform plan -detailed-exitcode\n```","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","OpenAI","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T05:30:07.073Z","createdAt":"2026-01-22T23:34:39.263Z"},{"id":"q-6176","question":"Scenario: A Terraform repo uses module network with for_each over environments (prod, staging, dev) to create VPCs and a VPN attachment. In prod, a manual change removed an aws_route_table_association that links the VPC's main route table to the VPN attachment, causing traffic to fail. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted resource into the correct module address, then run a targeted apply to re-create the association using the proper address (e.g., module.network[\"prod\"].aws_route_table_association[\"vpn_attach_prod\"]), followed by a full plan. Include the precise resource address to target and how to verify no drift remains?","answer":"1) Run terraform plan -detailed-exitcode for prod to surface drift. 2) Inspect drifted address via terraform state list/show for module.network[\"prod\"].aws_route_table_association[\"vpn_attach_prod\"]. ","explanation":"## Why This Is Asked\nThis probes drift detection, import/move of drifted resources, and targeted vs full apply in a multi-environment setup using module for_each. It tests practical state hygiene and how to safely reconcile drift without touching other environments.\n\n## Key Concepts\n- Drift detection with detailed exit codes\n- terraform state import and state mv for correct module addresses\n- Targeted apply vs full plan to minimize blast radius\n- Handling for_each with nested resource addresses\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform state show \"module.network[\\\"prod\\\"].aws_route_table_association[\\\"vpn_attach_prod\\\"]\"\nterraform import 'module.network[\\\"prod\\\"].aws_route_table_association[\\\"vpn_attach_prod\\\"]' <RT_ASSOC_ID>\nterraform apply -target=module.network[\\\"prod\\\"].aws_route_table_association[\\\"vpn_attach_prod\\\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle a similar drift in a region where the VPN attachment is managed by a separate provider alias?\n- What risks exist when performing state mv or import in a shared state file?","diagram":"flowchart TD\n  A[Plan detects drift] --> B[Import/Move drifted resource] \n  B --> C[Targeted apply] \n  C --> D[Full plan to verify] \n  D --> E[No drift remains]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T11:50:01.774Z","createdAt":"2026-01-23T11:50:01.774Z"},{"id":"q-6302","question":"Scenario: A Terraform repo uses a single remote backend (S3 with DynamoDB) and a shared module to provision networking and compute. A new environment named staging must be added without touching existing prod. Describe the exact, beginner-friendly steps to create and select a staging workspace, supply environment-specific variables, run init and plan, and verify no cross-env drift before applying?","answer":"Create and switch to a new workspace and initialize with the remote backend, then apply. Steps: terraform workspace new staging; export TF_VAR_region=us-east-1; export TF_VAR_env=staging; terraform in","explanation":"## Why This Is Asked\n\nTests understanding of Terraform workspaces and backend usage to isolate environments, a common beginner task. It also checks env var handling, init flow, plan/apply sequencing, and drift verification across workspaces.\n\n## Key Concepts\n\n- Terraform workspaces\n- Remote backend and init\n- Environment variables (TF_VAR_*)\n- Drift verification\n\n## Code Example\n\n```bash\nterraform workspace new staging\nterraform workspace select staging\nexport TF_VAR_region=us-east-1\nexport TF_VAR_env=staging\nterraform init -reconfigure\nterraform plan -out=tfplan\nterraform apply tfplan\n```\n\n## Follow-up Questions\n\n- How would you handle secrets in this workflow?\n- What are the differences between workspaces and per-env backend overrides?\n","diagram":"flowchart TD\n  A[Init] --> B[Workspace new staging]\n  B --> C[Set env vars]\n  C --> D[Terraform init -reconfigure]\n  D --> E[Terraform plan -out]\n  E --> F[Terraform apply]\n  F --> G[Verify state/workspace]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T18:46:23.323Z","createdAt":"2026-01-23T18:46:23.323Z"},{"id":"q-6329","question":"In a Terraform project deploying an AWS ECS service via a module, you want to ignore external changes to the service's desired_count so manual scaling won't drift the plan. How would you configure the ecs_service resource to ignore changes to desired_count, and what are the practical caveats of this approach? Include a minimal code snippet showing the lifecycle block?","answer":"Add a lifecycle block with ignore_changes = [ 'desired_count' ] on the aws_ecs_service resource. This prevents Terraform plan/apply from reconciling manual changes to desired_count. Caveats: drift can","explanation":"## Why This Is Asked\nDrift and ignoring updates are common in productionTerraform setups; this tests practical handling.\n\n## Key Concepts\n- lifecycle ignore_changes\n- drift versus desired state\n- caveats of ignoring changes\n\n## Code Example\n```javascript\nresource \\\"aws_ecs_service\\\" \\\"app\\\" {\n  name            = var.service_name\n  cluster         = aws_ecs_cluster.main.id\n  task_definition = aws_ecs_task_definition.main.arn\n  desired_count   = var.desired_count\n\n  lifecycle {\n    ignore_changes = [ \\\"desired_count\\\" ]\n  }\n}\n```\n\n## Follow-up Questions\n- What happens if the underlying scaling policy changes other attributes?\n- How would you validate that the ignore_changes rule doesn't hide other issues?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","NVIDIA","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T19:40:00.195Z","createdAt":"2026-01-23T19:40:00.196Z"},{"id":"q-6387","question":"In a Terraform repo, the network module uses for_each over environments (dev, prod) to create an AWS VPC and two subnets per env. Prod drift exists because a subnet CIDR was changed outside Terraform. Describe exact steps to detect drift using terraform plan -detailed-exitcode, identify the drifted resource address, decide whether to import into state, then run a targeted apply to revert prod drift (e.g., terraform apply -target=module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"]), followed by a full plan to confirm no drift. Include the exact resource address?","answer":"Use `terraform plan -detailed-exitcode` to detect drift; inspect the plan output for changes to `module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"]`. If the subnet exists but isn't tracked in state, import it using `terraform import module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"] <subnet-id>`. Then run a targeted apply to revert drift: `terraform apply -target=module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"]`. Finally, run a full plan to confirm no drift remains: `terraform plan -detailed-exitcode`.","explanation":"## Why This Is Asked\nTests practical drift handling in a multi-environment setup using for_each and subnets, plus targeted applies and optional import, which is a common real-world task.\n\n## Key Concepts\n- Terraform plan -detailed-exitcode to detect changes\n- Resource addressing with for_each: module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"]\n- When to import vs. rely on drift backfill\n- Safety: targeted apply vs full apply to minimize drift risk\n- Verification: run plan after apply\n\n## Code Example\n```bash\n# Detect drift\nterraform plan -detailed-exitcode -out=plan.out\n\n# Show differences\nterraform show plan.out\n\n# Import if needed (when resource exists but not in state)\nterraform import module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"] subnet-12345678\n\n# Targeted apply to fix drift\nterraform apply -target=module.network[\"prod\"].aws_subnet[\"prod_subnet_2\"]\n\n# Verify no drift\nterraform plan -detailed-exitcode\n```","diagram":"flowchart TD\n  A[Drift detected] --> B[Identify resource address]\n  B --> C{Import required?}\n  C -- Yes --> D[Import into state]\n  C -- No --> E[Targeted apply]\n  E --> F[Run full plan to verify drift-free]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T05:33:00.152Z","createdAt":"2026-01-23T21:50:46.349Z"},{"id":"q-6419","question":"Beginner Terraform problem: manage two AWS regions from a single repo. Create a VPC in us-east-1 and a NAT Gateway in us-west-2 using provider aliases. Show the configuration: two provider blocks (default and alias), resource blocks assigned to each provider, and how to run plan/apply to validate both regions. Include the exact resource addresses?","answer":"Configure two AWS providers with one default and one alias, then bind resources to the appropriate provider. Define the providers: `provider \"aws\" { region = \"us-east-1\" }` and `provider \"aws\" { alias = \"west\"; region = \"us-west-2\" }`. Create region-specific resources: `aws_vpc \"east_vpc\" { cidr_block = \"10.0.0.0/16\" }` for the default provider and `aws_nat_gateway \"west_nat\" { provider = aws.west; allocation_id = aws_eip.nat_eip.id; subnet_id = aws_subnet.west_subnet.id }` for the aliased provider. Execute `terraform plan` to validate both regions, then `terraform apply` to deploy. Resource addresses: `aws_vpc.east_vpc` and `aws_nat_gateway.west_nat`.","explanation":"## Why This Is Asked\nTests understanding of multi-region AWS deployments using Terraform provider aliases and proper resource binding to specific providers.\n\n## Key Concepts\n- Terraform provider aliases for multiple AWS regions\n- Resource addressing with provider assignments\n- Cross-region planning and deployment validation\n\n## Code Example\n```hcl\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nprovider \"aws\" {\n  alias  = \"west\"\n  region = \"us-west-2\"\n}\n\nresource \"aws_vpc\" \"east_vpc\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_nat_gateway\" \"west_nat\" {\n  provider     = aws.west\n  allocation_id = aws_eip.nat_eip.id\n  subnet_id    = aws_subnet.west_subnet.id\n}\n```","diagram":"flowchart TD\n  A[Configure Providers] --> B[East Resources]\n  A --> C[West Resources]\n  B --> D[Plan & Verify]\n  C --> D","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Coinbase","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T05:06:02.400Z","createdAt":"2026-01-23T23:31:43.209Z"},{"id":"q-6579","question":"In a single repo, two environments (prod and staging) deploy AWS resources using provider aliases aws and aws.prod, with a root module that uses for_each over environments to instantiate a VPC module. If prod and staging both apply, a coworker accidentally ran terraform apply without the prod provider alias, altering the wrong account. Describe exact steps to ensure prod uses the correct alias for plan and apply, including: provider alias declarations, env-to-alias mapping, initialization, commands to plan/apply with prod, and verification checks with explicit resource addresses to confirm the correct account touched?","answer":"Declare AWS providers with aliases prod and dev. Map each environment to the correct alias in the module: providers = { aws = each.key == \\\"prod\\\" ? aws.prod : aws.dev }. Run: terraform init -upgrade;","explanation":"## Why This Is Asked\nTests understanding of provider aliases and per-environment module instantiation in Terraform.\n\n## Key Concepts\n- Provider aliases and module-level provider mappings\n- For_each environment deployment and target verification\n- Safe plan/apply separation per environment\n\n## Code Example\n```javascript\nprovider \"aws\" {\n  alias = \\\"dev\\\"\n  region = \\\"us-west-2\\\"\n}\nprovider \"aws\" {\n  alias = \\\"prod\\\"\n  region = \\\"us-east-1\\\"\n}\nvariable \\\"environments\\\" { type = \\\"map(string)\\\"; default = { prod = \\\"prod\\\"; staging = \\\"staging\\\" } }\n\nmodule \\\"vpc\\\" {\n  for_each = var.environments\n  source   = \\\"./modules/vpc\\\"\n  providers = {\n    aws = each.key == \\\"prod\\\" ? aws.prod : aws.dev\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test rollback if prod plan uses the wrong alias?\n- How can you enforce alias usage at plan time to prevent mix-ups?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T08:50:52.434Z","createdAt":"2026-01-24T08:50:52.435Z"},{"id":"q-6652","question":"Scenario: A Terraform repo provisions an AWS VPC, two subnets, and a small EC2 fleet. Prod uses remote backend (S3 + DynamoDB); Dev uses local backend. A developer accidentally runs terraform init with the prod backend while in the dev directory, risking state leakage. Describe exact steps to safely revert dev to local, migrate dev state to a dedicated local backend, reinitialize, and verify no drift by running a targeted plan?","answer":"Isolate dev state by ensuring you revert to a local backend and verify drift with plan. Steps: 1) confirm in dev; 2) terraform init -backend=local -migrate-state (or reconfigure to dev-backend.conf an","explanation":"## Why This Is Asked\nTests practical backend isolation and safe state migrations for beginners.\n\n## Key Concepts\n- Backend configuration\n- State migration\n- Drift detection\n\n## Code Example\n```javascript\nterraform init -backend-config=dev-backend.conf -migrate-state\nterraform refresh\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle a failed migrate-state operation?\n- How can you automate per-environment backend selection?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Google","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T11:42:49.256Z","createdAt":"2026-01-24T11:42:49.256Z"},{"id":"q-6728","question":"In a Terraform repo using module security with for_each over environments to create per-environment aws_security_group_rule entries, prod has an inbound rule added outside Terraform. Explain exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted rule into state under module.security[\"prod\"].aws_security_group_rule[\"ssh-ingress\"] (provide the exact address), run a targeted apply to fix prod (e.g., -target=module.security[\"prod\"].aws_security_group_rule[\"ssh-ingress\"]), then a full plan to confirm no drift. Also discuss how to prevent future drift?","answer":"Identify drift with terraform plan -detailed-exitcode; if exit code 2, import the drifted rule into prod state: terraform import 'module.security[\"prod\"].aws_security_group_rule[\"ssh-ingress\"]' Then a","explanation":"## Why This Is Asked\nTests ability to detect drift, bring resources under Terraform, and perform targeted fixes without impacting other environments.\n\n## Key Concepts\n- Terraform plan exit codes; terraform import; -target; lifecycle guards.\n\n## Code Example\n```text\nterraform plan -detailed-exitcode\nif [ $? -eq 2 ]; then\n  terraform import 'module.security[\"prod\"].aws_security_group_rule[\"ssh-ingress\"]'\n  terraform apply -target='module.security[\"prod\"].aws_security_group_rule[\"ssh-ingress\"]'\nfi\n```\n\n## Follow-up Questions\n- How would you automate drift remediation across many environments?\n- What are risks of using -target in production pipelines?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Goldman Sachs","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T14:47:40.074Z","createdAt":"2026-01-24T14:47:40.075Z"},{"id":"q-6825","question":"Scenario: A Terraform repo migrates a per-env database deployment from count to for_each over environments. In prod, a single aws_db_instance drifted after the refactor. Describe exact steps to detect drift with terraform plan -detailed-exitcode, then reconcile prod by migrating the drifted address from the old count-based address to the new for_each address and applying a targeted change, followed by a full plan. Include the exact resource address to target: module.db[\"prod\"].aws_db_instance[\"db-prod\"]?","answer":"Run terraform plan -detailed-exitcode in prod; if it returns 2, switch to the prod workspace. List drifted addresses (terraform state list | grep 'module.db[\"prod\"].aws_db_instance'). Move from count ","explanation":"Plan exit code 2 indicates drift. Use state mv to align addresses after for_each refactor, limiting changes to prod. A targeted apply reconciles the drift, followed by a full plan to confirm drift-free state.","diagram":"flowchart TD\n  A[Start] --> B[Plan drift in prod]\n  B --> C[State mv to new address]\n  C --> D[Apply targeted change]\n  D --> E[Full plan verify]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T18:59:15.225Z","createdAt":"2026-01-24T18:59:15.225Z"},{"id":"q-6830","question":"Scenario: A Terraform repo uses a module 'network' with for_each over environments to provision per-environment AWS VPCs and subnets. In production, a subnet CIDR overlapped with an existing VPC due to manual changes outside Terraform. Describe the exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted subnet into state under module.network[\"prod\"].aws_subnet[\"prod_subnet\"], then run a targeted apply to bring prod in line (terraform apply -target=module.network[\"prod\"].aws_subnet[\"prod_subnet\"]), followed by a full plan to confirm no drift and ensure the CIDR remains valid. Include the exact resource address to target and how to handle dependencies if subnets must be re-associated?","answer":"Run terraform plan -detailed-exitcode to detect drift. If exit code is 2, parse plan output to locate prod subnet drift. Import drifted resource into the correct path: terraform import 'module.network","explanation":"## Why This Is Asked\nTests drift detection and correct import of nested module resources across environments.\n\n## Key Concepts\n- terraform plan -detailed-exitcode drift detection\n- terraform import with nested module addresses\n- targeted apply and dependency ordering for subresources\n- CIDR overlap considerations in multi-subnet VPCs\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform import 'module.network[\"prod\"].aws_subnet[\"prod_subnet\"]' <subnet-id>\nterraform apply -target=module.network[\"prod\"].aws_subnet[\"prod_subnet\"]\n```\n\n## Follow-up Questions\n- How to handle multiple drifted subnets?\n- How to validate post-apply with a full plan across all environments?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T19:23:12.100Z","createdAt":"2026-01-24T19:23:12.102Z"},{"id":"q-6857","question":"Your Terraform repo uses a module called apps to deploy RDS instances per environment via for_each on environments (prod, staging, dev). A prod RDS instance was created manually and the resource address changed after a repo refactor to module.apps[\"prod\"].aws_db_instance.prod_db. Describe exact steps to detect drift with terraform plan -detailed-exitcode, move the existing prod resource from its old address to the new module address using terraform state mv, run a targeted apply to bring prod in line (e.g., terraform apply -target=module.apps[\"prod\"].aws_db_instance.prod_db), then re-run a full plan to confirm no drift. Include the exact addresses in your commands?","answer":"Run terraform plan -detailed-exitcode to detect drift. Note old address (e.g., module.network.aws_db_instance.prod_db) and new address (module.apps[\"prod\"].aws_db_instance.prod_db). Move state: terraf","explanation":"## Why This Is Asked\n\nReason: ensure candidate can handle state migration after refactors, including addressing old vs new module paths, and using terraform state mv safely to avoid data loss.\n\n## Key Concepts\n\n- terraform state mv\n- address translation for for_each modules\n- drift detection with plan -detailed-exitcode\n- targeted apply risk management\n\n## Code Example\n\n```bash\n# Detect drift\nterraform plan -detailed-exitcode\n\n# Move state\nterraform state mv 'module.network.aws_db_instance.prod_db' 'module.apps[\"prod\"].aws_db_instance.prod_db'\n\n# Apply targeted change\nterraform apply -target=module.apps[\"prod\"].aws_db_instance.prod_db\n\n# Full plan to verify\nterraform plan\n```\n\n## Follow-up Questions\n\n- What are potential pitfalls when moving state across modules? \n- How would you handle multiple environments migrating simultaneously?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T20:36:43.495Z","createdAt":"2026-01-24T20:36:43.496Z"},{"id":"q-6881","question":"Scenario: A Terraform repo uses module compute with for_each over environments. In prod, the AWS EC2 instance address was renamed during a refactor from module.compute[\"prod\"].aws_instance[\"web-server\"] to module.compute[\"prod\"].aws_instance[\"app-server\"]. The real instance exists but drift is detected. Describe exact steps to detect drift with terraform plan -detailed-exitcode, move the drifted resource within state with terraform state mv, then apply a targeted fix using terraform apply -target=module.compute[\"prod\"].aws_instance[\"app-server\"], followed by a full plan to verify no drift. Include the exact resource addresses to move?","answer":"First, run `terraform plan -detailed-exitcode` to detect drift and confirm the address mismatch. Then inspect the current state with `terraform state list` to verify the old address exists. Next, migrate the resource: `terraform state mv 'module.compute[\"prod\"].aws_instance[\"web-server\"]' 'module.compute[\"prod\"].aws_instance[\"app-server\"]'`. Apply the targeted fix: `terraform apply -target=module.compute[\"prod\"].aws_instance[\"app-server\"]`. Finally, run a full `terraform plan` to verify no drift remains.","explanation":"## Why This Is Asked\nTests proficiency with Terraform state manipulation after module refactors and drift scenarios in production environments.\n\n## Key Concepts\n- Terraform state addresses and refactoring workflows\n- `terraform state mv` for address migrations\n- Targeted apply vs full plan for drift resolution\n- Drift detection via plan exit codes\n\n## Code Example\n```bash\n# Detect drift\nterraform plan -detailed-exitcode\n\n# Verify current state\nterraform state list\n\n# Move resource to new address\nterraform state mv 'module.compute[\"prod\"].aws_instance[\"web-server\"]' 'module.compute[\"prod\"].aws_instance[\"app-server\"]'\n\n# Apply targeted fix\nterraform apply -target=module.compute[\"prod\"].aws_instance[\"app-server\"]\n\n# Verify no drift\nterraform plan\n```","diagram":"flowchart TD\n  A[Start] --> B[Plan drift]\n  B --> C[State list]\n  C --> D[State mv]\n  D --> E[Apply targeted]\n  E --> F[Plan full]\n  F --> G[Done]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","IBM","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T06:17:53.702Z","createdAt":"2026-01-24T21:33:25.872Z"},{"id":"q-7015","question":"A monorepo reorganizes a Terraform module path: resources previously addressed as module.network[env] are now under module.infra.network[env]. Describe exact steps to migrate state safely for all environments with minimal downtime, including how to script state mv across addresses, how to handle resources that can't be renamed, and how to verify with a final plan to confirm no drift?","answer":"Scripted migration approach: (a) enumerate old addresses: terraform state list module.network[env].* for all envs; (b) map to new addresses under module.infra.network[env].*; (c) run terraform state m","explanation":"## Why This Is Asked\nTests state-management discipline in module refactors, multi-env migrations, and non-disruptive tactics.\n\n## Key Concepts\n- terraform state mv and address rewrites across module paths\n- Handling for_each keys and nested resource addresses\n- Safe import/migrate paths for unmappable resources\n- Validation: deterministic plan, detailed-exitcode behavior, drift checks\n\n## Code Example\n```bash\n#!/usr/bin/env bash\nfor env in prod staging dev; do\n  terraform state mv \"module.network[\\\"${env}\\\"].aws_vpc.main\" \"module.infra.network[\\\"${env}\\\"].aws_vpc.main\"\n  # add additional resource mappings as needed\ndone\n```\n\n## Follow-up Questions\n- How to extend this to resources with dynamic keys or non-renamable types?\n- How would you rollback if a migration step introduces drift or failures in a non-prod environment?","diagram":"flowchart TD\n  A[Identify old addresses] --> B[Create address mapping to new paths]\n  B --> C[Execute terraform state mv for each pair]\n  C --> D[Handle unmapped or renamed resources via import/mv]\n  D --> E[Plan -out plan] --> F[Apply plan]\n  F --> G[Run final plan to verify no drift]","difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","DoorDash","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:48:44.539Z","createdAt":"2026-01-25T05:48:44.539Z"},{"id":"q-7181","question":"In a Terraform repo, protect a production S3 bucket from accidental deletion while allowing non-destructive updates (policy, tags). Show how to use lifecycle blocks with prevent_destroy and ignore_changes on the aws_s3_bucket resource. Include a minimal code snippet and explain how to verify with terraform plan and apply that destroy is blocked and policy updates apply?","answer":"Add a lifecycle { prevent_destroy = true; ignore_changes = [policy, tags] } to the production bucket resource. Run terraform plan to confirm destroy is blocked; run terraform apply to apply non-destru","explanation":"## Why This Is Asked\nTests practical understanding of Terraform lifecycle, protecting critical resources, and how plan/apply reveal or enforce protections.\n\n## Key Concepts\n- lifecycle meta-arguments\n- prevent_destroy\n- ignore_changes\n- drift testing via plan/apply\n- safe updates of sensitive resources\n\n## Code Example\n```javascript\nresource \"aws_s3_bucket\" \"prod_bucket\" {\n  bucket = \"prod-bucket-name\"\n\n  lifecycle {\n    prevent_destroy = true\n    ignore_changes  = [\"policy\", \"tags\"]\n  }\n}\n```\n\n## Follow-up Questions\n- How to safely remove prevent_destroy when maintenance is required?\n- What are risks of ignore_changes and how to audit ignored attributes?\n- How would you apply similar protections to other critical resources in a multi-environment setup?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Meta","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T13:11:53.483Z","createdAt":"2026-01-25T13:11:53.483Z"},{"id":"q-7237","question":"In a repo with a root module that provisions a VPC and a child module for an EC2 instance, you want to upgrade the child module version in a feature branch without touching prod. Describe exact steps to pin the new module version, initialize with upgrade, create a dedicated test workspace, run plan and apply in that workspace, and verify no drift before merging. Include exact commands and a sample module address you would reference?","answer":"Pin the module: module \"network\" { source = \"git::https://repo/.../vpc.git?ref=v1.2.0\" }. Initialize: terraform init -upgrade. Create test workspace: terraform workspace new feature-branch; terraform ","explanation":"Why This Is Asked\n- Tests module upgrades in isolation, preventing prod impact.\n- Demonstrates safe use of workspaces and module pinning.\n\nKey Concepts\n- Module sources and ref pinning\n- terraform init -upgrade\n- Workspaces for isolated testing\n- plan + apply flow and drift verification\n\nCode Example\n```terraform\nmodule \"network\" {\n  source = \"git::https://repo/.../vpc.git?ref=v1.2.0\"\n  # inputs here\n}\n```\n\nFollow-up Questions\n- How would you rollback if the upgrade introduces breaking changes?\n- How would you automate this test in CI for every MR?","diagram":"flowchart TD\n  A[Pin Module Version] --> B[terraform init -upgrade]\n  B --> C[Create Test Workspace]\n  C --> D[Plan/Apply in Test]\n  D --> E[Review Drift/Outputs]\n  E --> F[Merge to Main]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T14:51:25.990Z","createdAt":"2026-01-25T14:51:25.990Z"},{"id":"q-7263","question":"In a multi-repo Terraform setup, an upstream network root stores outputs including a database_endpoint in a remote S3 state; a downstream app root consumes that endpoint via a data source. Describe exact steps to configure and use a data source terraform_remote_state to fetch upstream outputs, initialize the downstream workspace, and run a plan that correctly applies changes without breaking isolation, including how to handle upstream endpoint changes?","answer":"Configure data terraform_remote_state in the downstream root with backend = 's3' and the upstream bucket/key/region. Reference data.terraform_remote_state.upstream.outputs.database_endpoint in downstr","explanation":"## Why This Is Asked\nTests ability to compose configurations across repos using remote state and data sources while maintaining isolation.\n\n## Key Concepts\n- terraform_remote_state\n- data sources and outputs\n- remote backend (S3)\n- init, plan, apply sequencing\n- drift propagation and isolation\n\n## Code Example\n```javascript\ndata \"terraform_remote_state\" \"upstream\" {\n  backend = \"s3\"\n  config = {\n    bucket = \"tfstate-bucket\"\n    key    = \"network/upstream/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\nresource \"aws_rds_cluster\" \"app_db\" {\n  # uses downstream config; endpoint comes from:\n  # data.terraform_remote_state.upstream.outputs.database_endpoint\n}\n```\n\n## Follow-up Questions\n- How would you handle upstream outputs changing schema?\n- What changes would you make to ensure downstream plans remain stable across envs?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T15:45:06.020Z","createdAt":"2026-01-25T15:45:06.021Z"},{"id":"q-7301","question":"Scenario: In a Terraform repo, module 'infra' uses for_each over accounts to provision per-account AWS resources, including a DynamoDB table named 'state_table'. In prod, the table's read_capacity_units was manually increased causing drift only in prod. Describe exact steps to detect drift with terraform plan -detailed-exitcode, then fix prod by importing the drifted resource into the correct module address (module.infra[\"prod\"].aws_dynamodb_table[\"state_table\"]) and applying a targeted update, then run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Run terraform plan -detailed-exitcode in prod. If exit code 2 (drift), import the drifted DynamoDB table into state at address module.infra[\"prod\"].aws_dynamodb_table[\"state_table\"] using its name, th","explanation":"## Why This Is Asked\nTests practical drift handling in multi-account setups.\n\n## Key Concepts\n- plan exit codes, import, targeted apply, module addresses, drift.\n\n## Code Example\n```bash\n# Example import and targeted apply\nterraform import 'module.infra[\"prod\"].aws_dynamodb_table[\"state_table\"]' prod-state-table\nterraform apply -target='module.infra[\"prod\"].aws_dynamodb_table[\"state_table\"]'\n```\n\n## Follow-up Questions\n- How would you verify no drift after? What if the resource is nested?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Meta","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T17:30:34.899Z","createdAt":"2026-01-25T17:30:34.899Z"},{"id":"q-7337","question":"In a Terraform repo with a root module orchestrating two child modules: network (VPCs/subnets) and app (EC2 instances). Prod environment has a subnet drift caused by a manual change outside Terraform. Describe exact steps to detect drift with terraform plan -detailed-exitcode, identify the drifted resource address (module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"]), import the drifted subnet into state, and then perform a targeted apply to reconcile (terraform apply -target=module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"]), followed by a full plan to verify no drift remains. Include the exact commands and addresses to target?","answer":"Run terraform plan -detailed-exitcode to detect drift. List drifted resources with terraform state list; target the prod subnet: module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"]. If present in AWS b","explanation":"## Why This Is Asked\n\nThis question tests practical drift detection and remediation across modules, including identifying resource addresses, handling imports, and applying precise targeted changes without disturbing other resources.\n\n## Key Concepts\n\n- Drift detection with plan -detailed-exitcode\n- Cross-module resource addressing (module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"])\n- Importing drifted resources into state\n- Targeted apply for minimal blast radius\n\n## Code Example\n\n```bash\n# Detect drift\nterraform plan -detailed-exitcode\n\n# Identify drifted resource address (from plan output/state)\n# Import drifted subnet into state if missing\nterraform import module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"] <subnet-id>\n\n# Apply targeted change to reconcile drift\nterraform apply -target=module.network[\"prod\"].aws_subnet[\"prod-subnet-1\"]\n\n# Full plan to verify no drift remains\nterraform plan\n```\n\n## Follow-up Questions\n\n- How would you handle multiple drifted subnets in the same environment?\n- What if the drifted resource had been renamed in the code—how would you correct the addresses?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T19:07:16.213Z","createdAt":"2026-01-25T19:07:16.213Z"},{"id":"q-7355","question":"Scenario: A Terraform repo uses module network with for_each over environments to create AWS VPCs and route tables. In prod, a manual AWS console change added a route not present in code, causing drift. Describe exact steps to detect drift with terraform plan -detailed-exitcode, import the drifted route into the module address, run a targeted apply to restore prod (terraform apply -target=module.network[\\\"prod\\\"].aws_route[\\\"prod_route\\\"]), then run a full plan to confirm no drift. Include the exact resource address to target?","answer":"Outline the steps: run terraform plan -detailed-exitcode to show drift; if non-zero, run terraform import to bring prod route into state at module.network[\\\"prod\\\"].aws_route[\\\"prod_route\\\"], ensuring","explanation":"## Why This Is Asked\n\nTests the ability to safely reconcile state for environment-specific drift in a module with for_each.\n\n## Key Concepts\n\n- Drift detection via terraform plan -detailed-exitcode\n- Importing drifted resources into the state at the exact module address\n- Targeted apply to minimize blast radius\n- Verifying no drift with a full plan\n\n## Code Example\n\nterraform plan -detailed-exitcode\nterraform import module.network[\\\"prod\\\"].aws_route[\\\"prod_route\\\"] <id>\nterraform apply -target=module.network[\\\"prod\\\"].aws_route[\\\"prod_route\\\"]\nterraform plan\n\n## Follow-up Questions\n\n- How would you handle dynamic resource names in the module?\n- What safeguards ensure idempotence when manual changes occur often?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","IBM","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T19:44:35.050Z","createdAt":"2026-01-25T19:44:35.050Z"},{"id":"q-7500","question":"Scenario: A Terraform repo uses a single module 'web' that provisions an ALB-backed service in two environments, blue and green, each as its own Terraform workspace. Blue is live; you need to deploy a non-breaking upgrade to green, validate it in isolation, then switch production traffic via Route53 with minimal downtime. Describe exact steps to provision green in parallel, run drift checks, promote green by updating the DNS record, and roll back if issues arise, including the precise addresses to target and commands for workspace, plan, apply, and state moves?","answer":"Deploy green in its own workspace; select green, plan with -out green.plan and -target to green resources, then apply. Run drift check: terraform plan -detailed-exitcode. If green passes, flip DNS to ","explanation":"## Why This Is Asked\nTests blue/green rollout, DNS cutover, drift checks, and targeting resources for minimal downtime.\n\n## Key Concepts\n- Blue/green deployments in Terraform workspaces\n- Drift detection and targeted applies with -detailed-exitcode and -target\n- Route53 DNS cutover and health-check verification\n- Rollback strategies with DNS reversion\n\n## Code Example\n```bash\nterraform workspace select green\nterraform plan -out green.plan -target=module.web[\"green\"].aws_lb.frontend\nterraform apply green.plan\n```\n\n## Follow-up Questions\n- How would you automate the DNS switch and rollback in CI/CD?\n- How would you handle state in case the green deployment partially applies?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T04:38:24.494Z","createdAt":"2026-01-26T04:38:24.494Z"},{"id":"q-7643","question":"You manage a Terraform repo provisioning networks across three AWS regions using a single S3 backend with DynamoDB locks. A new region and a canary environment must be added without cross‑region drift. Describe exactly how you would isolate state by region/environment using backend key interpolation, migrate existing state safely, and run a plan that proves no cross‑region drift. Include concrete key strings, workspace naming, and commands?","answer":"Configure the S3 backend with key = 'state/${terraform.workspace}/network.tfstate'. Create workspaces per region and env (e.g., prod-us, prod-eu, canary-us). Run terraform init -migrate-state. For eac","explanation":"## Why This Is Asked\nThis question probes real-world state isolation across regions, migration safety, and drift detection. It tests familiarity with S3 backend, DynamoDB locks, and workspace-based state separation.\n\n## Key Concepts\n- Backend key interpolation with terraform.workspace\n- terraform init -migrate-state for safe migration\n- Per-region planning and drift verification\n\n## Code Example\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"my-terraform-state\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"terraform-locks\"\n    key            = \"state/${terraform.workspace}/network.tfstate\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you automate workspace creation and drift checks in CI?\n- How would you handle conflicting changes if two regions modify the same resource?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Plaid","Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T10:57:26.334Z","createdAt":"2026-01-26T10:57:26.334Z"},{"id":"q-7807","question":"Scenario: A Terraform repo uses a single remote backend (S3 + DynamoDB) for all environments with per-env workspaces dev/staging/prod. A misconfigured backend config in prod causes plan/apply to fail there but pass elsewhere. Describe exact steps to diagnose the backend misconfiguration, verify the current workspace, migrate the prod state if needed, reinitialize, switch to prod, and run a targeted plan/apply to bring prod in sync without touching other environments. Include the exact commands and checkpoints?","answer":"Validate backend for prod and confirm the active workspace, migrate state if needed, reinitialize, switch to prod, then run a targeted plan and apply to bring prod in sync without touching other envir","explanation":"## Why This Is Asked\n\nTests understanding of backend and workspace interplay in real-world CI/CD.\n\n## Key Concepts\n\n- Terraform backends\n- Remote state\n- Workspaces\n- migrate-state\n- plan/apply workflow per environment\n\n## Code Example\n\n```hcl\n# backend-prod.tfvars\nbucket = \\\"tf-prod-state\\\"\nkey    = \\\"prod/terraform.tfstate\\\"\nregion = \\\"us-east-1\\\"\n```\n\n```hcl\n# Minimal backend block (simplified)\nbackend \\\"s3\\\" { }\n```\n\n## Follow-up Questions\n\n- What are the risks of migrating state between backends?\n- How would you automate per-env backend config in CI/CD?\n","diagram":"flowchart TD\n  A[Check backend config] --> B[Validate workspace]\n  B --> C[Migrate state if needed]\n  C --> D[Select prod]\n  D --> E[Reinitialize]\n  E --> F[Plan prod]\n  F --> G[Apply prod]\n  G --> H[Verify no drift]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T18:58:22.126Z","createdAt":"2026-01-26T18:58:22.126Z"},{"id":"q-7837","question":"In a multi-environment Terraform setup, a downstream app module consumes NAT_SUBNET_IDS from a central network module. After a refactor, NAT_SUBNET_IDS moved from a set(string) to a list(object) causing drift in prod. Describe exact steps to detect drift with plan -detailed-exitcode, migrate the drifted resource with state mv from addresses 'module.app[\"prod\"].aws_nat_binding[\"nat_binding_prod_old\"]' to 'module.app[\"prod\"].aws_nat_binding[\"nat_bind_prod\"]', run a targeted apply, then a full plan. Include the exact addresses you would touch?","answer":"Start with terraform plan -detailed-exitcode to surface drift between old for_each keys and new NAT binding addresses. Move resources with terraform state mv to the new addresses, e.g. 'module.app[\"pr","explanation":"Why This Is Asked\nTests ability to detect cross-module drift and perform precise state moves. Key: plan exit codes, state mv semantics, and targeted applies across module boundaries.\n\n## Key Concepts\n- terraform plan -detailed-exitcode\n- terraform state mv\n- targeted apply\n- cross-module addresses\n\n## Code Example\n```bash\nterraform plan -detailed-exitcode\nterraform state mv 'module.app[\"prod\"].aws_nat_binding[\"nat_binding_prod_old\"]' 'module.app[\"prod\"].aws_nat_binding[\"nat_bind_prod\"]'\nterraform apply -target=module.app[\"prod\"].aws_nat_binding[\"nat_bind_prod\"]\nterraform plan\n```\n\n## Follow-up Questions\n- How would you handle multiple environments in a single run?\n- What are risks if the plan shows drift but state mv fails for one resource?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Instacart","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T19:45:34.819Z","createdAt":"2026-01-26T19:45:34.819Z"},{"id":"q-7890","question":"You have a Terraform project that previously stored state locally. You want to migrate to a remote S3 backend with a DynamoDB lock to prevent concurrent applies. Describe exact, reproducible steps to migrate the state safely: update the backend configuration, perform the migration, verify that remote state contains all resources, switch workspaces if necessary, and validate no drift by running a full plan and a safe apply in a non-production environment. Include specific commands and checks?","answer":"Create S3 bucket and DynamoDB lock table; update backend config in the repo. Run: terraform init -migrate-state; terraform state list > /tmp/state; terraform plan -out=plan.out; terraform apply plan.o","explanation":"## Why This Is Asked\nTests understanding of Terraform state backends and safe migration.\n\n## Key Concepts\n- Remote state backends and locking\n- migrate-state workflow\n- Drift verification\n\n## Code Example\n```javascript\nterraform {\n  backend \"s3\" {\n    bucket = \"my-terraform-state\"\n    key = \"prod/terraform.tfstate\"\n    region = \"us-east-1\"\n    dynamodb_table = \"terraform-lock\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you migrate multiple environments?\n- How do you handle secrets in state backends?","diagram":"flowchart TD\n  A[Local state] --> B[Migrate to S3 backend]\n  B --> C{Remote state verified?}\n  C -->|Yes| D[Plan no-drift]\n  C -->|No| E[Fix drift]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Google","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T21:45:32.372Z","createdAt":"2026-01-26T21:45:32.372Z"},{"id":"q-864","question":"In Terraform, you need to manage two AWS accounts in a single repo: prod (provider aws.prod) and audit (provider aws.audit). Create an S3 bucket in prod and a cross-account IAM policy in audit that grants read access to that bucket. How do you configure aliased providers, reference the prod bucket ARN from the audit module, and enforce deterministic apply order (e.g., data fetch before policy) with minimal risk? Include a minimal config outline?","answer":"Define two providers with aliases (aws.prod and aws.audit). Create the bucket using aws.prod, then fetch its ARN from prod via data.aws_s3_bucket in the audit config and craft an audit IAM policy that","explanation":"## Why This Is Asked\n\nThis question tests multi-account Terraform patterns: provider aliases, cross-account data sources, and deterministic apply order.\n\n## Key Concepts\n\n- Aliased providers\n- Cross-account data sources\n- Data referencing across providers\n- depends_on for ordering\n- Credentials management via profiles and assume_role\n\n## Code Example\n\n```hcl\nprovider \"aws\" {\n  alias   = \"prod\"\n  region  = \"us-east-1\"\n  profile = \"prod\"\n}\nprovider \"aws\" {\n  alias   = \"audit\"\n  region  = \"us-east-1\"\n  profile = \"audit\"\n}\n\ndata \"aws_caller_identity\" \"prod\" {\n  provider = aws.prod\n}\n\ndata \"aws_s3_bucket\" \"prod_bucket\" {\n  provider = aws.prod\n  bucket   = \"my-prod-bucket\"\n}\n\ndata \"aws_iam_policy_document\" \"audit\" {\n  provider = aws.audit\n  statement {\n    actions   = [\"s3:GetObject\"]\n    resources = [\"${data.aws_s3_bucket.prod_bucket.arn}/*\"]\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"arn:aws:iam::${data.aws_caller_identity.prod.account_id}:root\"]\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"audit_bucket\" {\n  provider = aws.audit\n  bucket   = \"audit-bucket\"\n}\n\nresource \"aws_iam_policy\" \"audit_policy\" {\n  provider = aws.audit\n  name     = \"CrossAccountGetObject\"\n  policy   = data.aws_iam_policy_document.audit.json\n}\n```\n\n## Follow-up Questions\n\n- How would you rotate credentials for the aliased providers safely?\n- How would you test this cross-account permission in a CI workflow?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snap","Snowflake","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:45:51.426Z","createdAt":"2026-01-12T13:45:51.426Z"},{"id":"q-960","question":"In a single Terraform repo that provisions prod, staging, and dev AWS environments, how would you configure a single S3 backend to isolate state for each environment without using separate Terraform workspaces? Provide the exact backend config (bucket, region, dynamodb_lock_table, key per env) and explain how you would promote changes from dev to prod, including drift handling and CI plan/apply steps?","answer":"Use one S3 bucket with environment-scoped keys and per-env locking: dev/terraform.tfstate with tf-lock-dev, staging/terraform.tfstate with tf-lock-staging, prod/terraform.tfstate with tf-lock-prod. Do","explanation":"## Why This Is Asked\n\nTests practical backend configuration and multi-environment isolation without relying on workspaces, which can obscure state provenance. It also covers promotion workflows and drift handling in CI.\n\n## Key Concepts\n\n- Terraform backends and per-environment state isolation\n- State locking with DynamoDB per environment\n- Promotion pipelines and drift considerations in CI/CD\n\n## Code Example\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"dev/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-dev\"\n    encrypt        = true\n  }\n}\n```\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-prod\"\n    encrypt        = true\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you handle a state drift detected in prod after a manual change?\n- What are the trade-offs of using a single bucket with per-env keys vs separate buckets per env?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Google","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:21:52.897Z","createdAt":"2026-01-12T17:21:52.897Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":88,"beginner":32,"intermediate":29,"advanced":27,"newThisWeek":38}}