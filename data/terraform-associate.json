{"questions":[{"id":"q-1009","question":"Scenario: a single repo provisions per-tenant AWS resources for many tenants. To isolate state without workspaces, use a shared S3 backend with a DynamoDB lock table and a tenant-scoped key. Describe the backend config (bucket, region, dynamodb_table, key pattern per tenant), how you detect drift across tenants, and CI gating for dev-to-prod promotions (plan -out, tests, approve, apply)?","answer":"Configure a shared S3 backend with per-tenant keys and a single DynamoDB lock table. Backend config example: bucket=tf-backend, region=us-east-1, dynamodb_table=tf-locks, key=tenants/${TENANT_ID}/terr","explanation":"## Why This Is Asked\nTests mastery of multi-tenant state isolation, drift detection, and CI-gated promotions using Terraform remote backend.\n\n## Key Concepts\n- Remote state isolation without workspaces\n- Backend config per-tenant key patterns\n- Centralized locking with DynamoDB\n- Drift detection via plan and refresh\n- CI gating with plan/out, tests, approvals\n\n## Code Example\n```javascript\n# backend-configs/dev.tfbackend\nbucket = \"tf-backend\"\nregion = \"us-east-1\"\ndynamodb_table = \"tf-locks\"\nkey = \"tenants/${TENANT_ID}/terraform.tfstate\"\n```\n\n## Follow-up Questions\n- How would you enforce per-tenant role-based access to the backend?\n- How do you handle tenant onboarding/offboarding when state files move?","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Coinbase","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T19:21:33.339Z","createdAt":"2026-01-12T19:21:33.339Z"},{"id":"q-1154","question":"In a Terraform module that provisions an AWS RDS instance, operators sometimes alter maintenance_window directly in AWS, creating drift. You want Terraform to ignore external changes to maintenance_window but still apply code-driven updates (e.g., allocated_storage). How would you implement this using a lifecycle block? Provide a minimal aws_db_instance snippet showing ignore_changes for maintenance_window and outline tradeoffs?","answer":"Use: lifecycle { ignore_changes = [maintenance_window] }. In the aws_db_instance resource, keep allocated_storage driven by config. Caveats: other fields drift remains visible only if not ignored; if ","explanation":"## Why This Is Asked\n\nShows practical drift handling with Terraform state; tests understanding of lifecycle rules and their impact on operations.\n\n## Key Concepts\n\n- Drift and state\n- lifecycle ignore_changes\n- Resource attribute scoping\n\n## Code Example\n\n```javascript\nresource \"aws_db_instance\" \"example\" {\n  identifier         = \"example\"\n  engine             = \"mysql\"\n  instance_class     = \"db.t3.micro\"\n  allocated_storage  = 20\n  maintenance_window = \"sun:23:45-sun:00:15\"\n\n  lifecycle {\n    ignore_changes = [maintenance_window]\n  }\n}\n```\n\n## Follow-up Questions\n\n- What would happen if maintenance_window is changed in code while an apply is in progress?\n- How would you revert drift if needed later?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:37:52.444Z","createdAt":"2026-01-13T01:37:52.444Z"},{"id":"q-1172","question":"In AWS us-east-1, you must provision 3 private subnets in a single VPC across 3 AZs using one module. Define a map variable with AZs and CIDRs, create the subnets with for_each, attach appropriate tags, and output the subnet IDs. Then show how to reference these IDs in a resource that requires subnet_id (eg NAT Gateway) and justify for_each vs count?","answer":"Use a map variable for subnets keyed by AZ, create aws_subnet with for_each, set az and cidr_block from the map, and TAGS. Output the IDs for reuse. Example: create a NAT gateway per subnet by iterati","explanation":"## Why This Is Asked\nAssesses practical use of for_each with maps, resource interdependencies, and stable identities across environments. Delivers hands-on pattern candidates expect in production.\n\n## Key Concepts\n- for_each with maps provides stable keys and predictable IDs\n- referencing attributes from one resource in another (subnet_id in NAT GW)\n- tagging and AZ assignment per subnet\n- outputs to surface IDs for downstream resources\n- when to prefer for_each vs count (stable keys vs positional indexing)\n\n## Code Example\n```javascript\nvariable \"subnets\" {\n  type = map(object({ cidr_block = string; az = string }))\n  default = {\n    az1 = { cidr_block = \"10.0.1.0/24\", az = \"us-east-1a\" },\n    az2 = { cidr_block = \"10.0.2.0/24\", az = \"us-east-1b\" },\n    az3 = { cidr_block = \"10.0.3.0/24\", az = \"us-east-1c\" }\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = var.subnets\n  vpc_id            = var.vpc_id\n  cidr_block        = each.value.cidr_block\n  availability_zone = each.value.az\n  tags = {\n    Name = \"private-${each.key}\"\n  }\n}\n\noutput \"private_subnet_ids\" {\n  value = [for s in aws_subnet.private : s.id]\n}\n```\n\n```javascript\nresource \"aws_nat_gateway\" \"ngw\" {\n  for_each = aws_subnet.private\n  allocation_id = aws_eip.ngw[each.key].id\n  subnet_id     = aws_subnet.private[each.key].id\n}\n```\n\n## Follow-up Questions\n- When would you choose for_each over count in real projects?\n- How would you migrate from count-based to for_each-based resources without breaking state?\n- How would you validate AZ distribution and CIDR correctness after apply?","diagram":"flowchart TD\n  S[Subnets] --> A1[Subnet us-east-1a]\n  S --> A2[Subnet us-east-1b]\n  S --> A3[Subnet us-east-1c]\n  A1 --> NGW[Per-Subnet NAT Gateway]","difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T03:37:27.209Z","createdAt":"2026-01-13T03:37:27.209Z"},{"id":"q-1202","question":"Scenario: you must bring under Terraform management a set of existing AWS S3 buckets across teams. Some buckets already exist and must be imported; you will manage encryption and versioning with a single module using for_each over a bucket map. How would you import, structure, and promote changes safely via CI?","answer":"Import existing buckets into state by address, e.g. terraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket; define a map of buckets with per-bucket flags and use for_each to create resources;","explanation":"## Why This Is Asked\n\nThis checks practical import workflows and multi-resource management with for_each, keeping data in sync and enabling safe CI-driven promotions.\n\n## Key Concepts\n\n- terraform import with for_each\n- map of per-bucket settings\n- dynamic blocks for conditional blocks\n- drift reconciliation and idempotency\n- CI/CD validation and promotion\n\n## Code Example\n\n```javascript\nvariable \"buckets\" {\n  type = map(object({\n    encryption = bool\n    versioning = bool\n  }))\n}\nresource \"aws_s3_bucket\" \"bucket\" {\n  for_each = var.buckets\n  bucket = each.key\n  acl    = \"private\"\n\n  dynamic \"versioning\" {\n    for_each = each.value.versioning ? [1] : []\n    content {\n      enabled = true\n    }\n  }\n\n  dynamic \"server_side_encryption_configuration\" {\n    for_each = each.value.encryption ? [1] : []\n    content {\n      rule {\n        apply_server_side_encryption_by_default {\n          sse_algorithm = \"AES256\"\n        }\n      }\n    }\n  }\n}\n```\n\n```javascript\nterraform import 'aws_s3_bucket.bucket[\"team-a\"]' team-a-bucket\n```\n\n## Follow-up Questions\n\n- How would you handle a bucket rename in the map without recreating?\n- How would you test encryption changes in CI without touching prod data?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","NVIDIA","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T04:49:50.394Z","createdAt":"2026-01-13T04:49:50.394Z"},{"id":"q-1338","question":"Scenario: You maintain a Terraform repo that provisions an AWS RDS primary in us-east-1 and an optional cross-region read replica in us-west-2 controlled by a feature flag var.enable_replica. If the flag is false, Terraform should destroy the replica on apply. How would you implement the cross-region provider, conditional resource creation, and safe destruction without leaving dangling resources? Provide code patterns for the provider alias and the replica resource?","answer":"Define two AWS providers with aliases (primary us-east-1 and replica us-west-2). Create the replica resource with count = var.enable_replica ? 1 : 0 and assign provider = aws.replica; declare depends_","explanation":"## Why This Is Asked\nThis question tests practical capabilities to manage cross-region resources with provider aliases and conditional creation, ensuring safe destruction when a feature flag disables the replica, and understanding of Terraform lifecycle to avoid downtime.\n\n## Key Concepts\n- provider aliases\n- conditional resource creation with count\n- cross-region dependencies\n- lifecycle create_before_destroy\n- drift and state management\n\n## Code Example\n```javascript\nprovider \"aws\" {\n  region = \"us-east-1\"\n  alias  = \"primary\"\n}\nprovider \"aws\" {\n  region = \"us-west-2\"\n  alias  = \"replica\"\n}\n\nresource \"aws_db_instance\" \"primary\" {\n  provider = aws.primary\n  # ...\n}\n\nresource \"aws_db_instance\" \"replica\" {\n  provider   = aws.replica\n  count      = var.enable_replica ? 1 : 0\n  depends_on = [aws_db_instance.primary]\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n## Follow-up Questions\n- What are the failover considerations for cross-region replicas?\n- How would you test this pattern in CI and guard against accidental destruction?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","NVIDIA","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T11:44:40.993Z","createdAt":"2026-01-13T11:44:40.993Z"},{"id":"q-1367","question":"You\\'re managing 100 AWS subnets defined in a single Terraform module using for_each. A drift occurred in one subnet\\'s route_table_id because it was changed outside Terraform. Describe exactly how you\\'d detect the drift and fix only that resource with zero-drift impact, using Terraform CLI commands. Include the exact commands to init plan, taint the resource, apply with -target, and re-run a full plan to confirm drift-free state?","answer":"Run `terraform init`; then `terraform plan -detailed-exitcode -out=tfplan` and note the exact resource address from the diff (e.g., aws_subnet.env[\"subnet-0a1b2c\"]) . Next run `terraform taint 'aws_su","explanation":"## Why This Is Asked\nTests practical drift remediation techniques on large multi-resource deployments, emphasizing targeted changes and plan-deduplication.\n\n## Key Concepts\n- Drift detection via plan exit codes\n- Resource tainting vs. full apply\n- Targeted applies to minimize blast radius\n- For_each resource addressing\n\n## Code Example\n```bash\nterraform init\nterraform plan -detailed-exitcode -out=tfplan\n# identify address from plan output, e.g. aws_subnet.env[\"subnet-0a1b2c\"]\nterraform taint 'aws_subnet.env[\"subnet-0a1b2c\"]'\nterraform apply -auto-approve -target='aws_subnet.env[\"subnet-0a1b2c\"]'\nterraform plan\n```\n\n## Follow-up Questions\n- How would you automate this across all drifted resources in a single run?\n- How do you ensure idempotence when using -target in CI pipelines?","diagram":"flowchart TD\n  A[Detect Drift] --> B[Identify Resource Address]\n  B --> C[Taint Resource]\n  C --> D[Apply Targeted Changes]\n  D --> E[Re-run Full Plan]","difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","IBM","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:19:56.849Z","createdAt":"2026-01-13T13:19:56.849Z"},{"id":"q-1584","question":"You are refactoring a Terraform repo and moving an existing AWS S3 bucket resource from the root module into a submodule named storage. Describe exact steps and commands to relocate the resource in state without recreation, including the state mv addresses and a follow-up plan?","answer":"Initialize the configuration, identify the current resource address, and relocate it to the target module while preserving all existing data and metadata. Steps:\n- terraform init\n- terraform state list | grep aws_s3_bucket\n- terraform state mv 'aws_s3_bucket.mybucket' 'module.storage.aws_s3_bucket.mybucket'\n- terraform plan\n- terraform apply","explanation":"## Why This Is Asked\nTests knowledge of Terraform state manipulation and module boundaries, including how to relocate existing resources without destruction.\n\n## Key Concepts\n- terraform state mv\n- module addressing with for_each/count\n- plan/apply after a state relocation\n\n## Code Example\n```javascript\nterraform init\nterraform state list | grep aws_s3_bucket\nterraform state mv 'aws_s3_bucket.mybucket' 'module.storage.aws_s3_bucket.mybucket'\nterraform plan\nterraform apply\n```\n\n## Follow-up Questions\n- How would you handle relocation if the bucket name is generated by count/indexed resources?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Instacart","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:41:56.909Z","createdAt":"2026-01-13T22:51:23.435Z"},{"id":"q-1655","question":"You discover an AWS VPC and related resources created outside Terraform and want to bring them under a new network module without recreating. Describe exact steps to import the VPC, its subnets (for_each), and a peering connection into the module, including the resource addresses youâ€™ll use, how to handle multiple subnets, and how to verify with a plan that nothing changes?","answer":"Import external VPC resources into a new module without recreating: 1) init; 2) import VPC: terraform import 'module.network.aws_vpc.vpc' vpc-0a1b2c3d4e5f6g; 3) import subnets: terraform import 'modul","explanation":"## Why This Is Asked\nTests ability to adopt existing infrastructure into a module, mapping real resources to module addresses and avoiding recreation. Also evaluates import ordering, state manipulation, and verification through plan.\n\n## Key Concepts\n- terraform import into module resources\n- addressing for subresources with for_each and modules\n- validating with plan to ensure zero-drift\n- handling cross-account/provider setups if applicable\n\n## Code Example\n```javascript\n# Example module resource blocks (illustrative)\nresource \"aws_vpc\" \"vpc\" { ... }\nresource \"aws_subnet\" \"private\" { for_each = var.private_subnets ... }\nresource \"aws_vpc_peering_connection\" \"peering\" { ... }\n```\n\n## Follow-up Questions\n- How would you map any missing attributes (tags, route tables) to existing state?\n- If some resources are in different accounts, how do you configure providers and imports to avoid conflicts?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:37:20.961Z","createdAt":"2026-01-14T05:37:20.961Z"},{"id":"q-1740","question":"Advanced cross-repo Terraform: network state is stored in a dedicated repo/backends across envs. The application repo imports VPC IDs and subnets via data terraform_remote_state. Explain how you would structure backends and modules to avoid drift, ensure isolation between dev/staging/prod, and orchestrate safe promotions from dev to prod with exact commands for init/plan/apply per environment. Include how you would test drift and rollback?","answer":"Use separate backends per environment; centralize VPC in the network repo; in app, read VPC outputs via terraform_remote_state. Promote via CI gate. Example commands for prod:\\nnetwork: terraform init","explanation":"## Why This Is Asked\n\nTests ability to coordinate Terraform state across repos, manage drift via remote state data, and implement safe promotion paths with environment isolation.\n\n## Key Concepts\n\n- Terraform remote state and data sources\n- Separate backends per environment\n- CI gating and drift testing\n- cross-repo module composition\n\n## Code Example\n\n```hcl\ndata \"terraform_remote_state\" \"network\" {\n  backend = \"s3\"\n  config = {\n    bucket = \"corp-terraform-network\"\n    key    = \"prod/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you handle a read-only remote state during prod promotion?\n- How would you implement a rollback plan if drift is detected post-merge?\n","diagram":null,"difficulty":"advanced","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:01:14.624Z","createdAt":"2026-01-14T09:01:14.624Z"},{"id":"q-1749","question":"You manage a single Terraform repo deploying a shared 'network' module into two AWS accounts (prod and dev) using provider aliases. Describe how you structure the provider blocks, module calls, and var-files to deploy both environments without duplicating code. Include exact commands to init, plan, and apply for each environment, ensuring isolation and no cross-env state changes?","answer":"Create two provider aliases (aws.prod, aws.dev) with distinct regions, and drive the module with for_each over environments. Use providers = { aws = aws.${each.key} } and per-env var-files. Then: terr","explanation":"## Why This Is Asked\nTests understanding of multi-environment deployments without code duplication using provider aliases and module iteration.\n\n## Key Concepts\n- Provider aliases\n- Module instantiation with for_each\n- Per-environment variable files and backends\n- Terraform plan/apply targeting to avoid cross-env changes\n\n## Code Example\n```terraform\nprovider \"aws\" {\n  alias  = \"prod\"\n  region = var.prod_region\n}\nprovider \"aws\" {\n  alias  = \"dev\"\n  region = var.dev_region\n}\nvariable \"prod_region\" { default = \"us-east-1\" }\nvariable \"dev_region\"  { default = \"us-west-2\" }\nvariable \"environments\" {\n  type = map(string)\n  default = { prod = \"prod\", dev = \"dev\" }\n}\nmodule \"network\" {\n  for_each = var.environments\n  source   = \"./modules/network\"\n  providers = { aws = aws[each.value] }\n  # inputs per env\n}\n```\n\n## Follow-up Questions\n- How would you add a new environment without touching existing state?\n- What are the trade-offs of using separate backends versus workspaces for this pattern?","diagram":null,"difficulty":"beginner","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Slack","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:38:40.289Z","createdAt":"2026-01-14T09:38:40.289Z"},{"id":"q-864","question":"In Terraform, you need to manage two AWS accounts in a single repo: prod (provider aws.prod) and audit (provider aws.audit). Create an S3 bucket in prod and a cross-account IAM policy in audit that grants read access to that bucket. How do you configure aliased providers, reference the prod bucket ARN from the audit module, and enforce deterministic apply order (e.g., data fetch before policy) with minimal risk? Include a minimal config outline?","answer":"Define two providers with aliases (aws.prod and aws.audit). Create the bucket using aws.prod, then fetch its ARN from prod via data.aws_s3_bucket in the audit config and craft an audit IAM policy that","explanation":"## Why This Is Asked\n\nThis question tests multi-account Terraform patterns: provider aliases, cross-account data sources, and deterministic apply order.\n\n## Key Concepts\n\n- Aliased providers\n- Cross-account data sources\n- Data referencing across providers\n- depends_on for ordering\n- Credentials management via profiles and assume_role\n\n## Code Example\n\n```hcl\nprovider \"aws\" {\n  alias   = \"prod\"\n  region  = \"us-east-1\"\n  profile = \"prod\"\n}\nprovider \"aws\" {\n  alias   = \"audit\"\n  region  = \"us-east-1\"\n  profile = \"audit\"\n}\n\ndata \"aws_caller_identity\" \"prod\" {\n  provider = aws.prod\n}\n\ndata \"aws_s3_bucket\" \"prod_bucket\" {\n  provider = aws.prod\n  bucket   = \"my-prod-bucket\"\n}\n\ndata \"aws_iam_policy_document\" \"audit\" {\n  provider = aws.audit\n  statement {\n    actions   = [\"s3:GetObject\"]\n    resources = [\"${data.aws_s3_bucket.prod_bucket.arn}/*\"]\n    principals {\n      type        = \"AWS\"\n      identifiers = [\"arn:aws:iam::${data.aws_caller_identity.prod.account_id}:root\"]\n    }\n  }\n}\n\nresource \"aws_s3_bucket\" \"audit_bucket\" {\n  provider = aws.audit\n  bucket   = \"audit-bucket\"\n}\n\nresource \"aws_iam_policy\" \"audit_policy\" {\n  provider = aws.audit\n  name     = \"CrossAccountGetObject\"\n  policy   = data.aws_iam_policy_document.audit.json\n}\n```\n\n## Follow-up Questions\n\n- How would you rotate credentials for the aliased providers safely?\n- How would you test this cross-account permission in a CI workflow?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snap","Snowflake","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:45:51.426Z","createdAt":"2026-01-12T13:45:51.426Z"},{"id":"q-960","question":"In a single Terraform repo that provisions prod, staging, and dev AWS environments, how would you configure a single S3 backend to isolate state for each environment without using separate Terraform workspaces? Provide the exact backend config (bucket, region, dynamodb_lock_table, key per env) and explain how you would promote changes from dev to prod, including drift handling and CI plan/apply steps?","answer":"Use one S3 bucket with environment-scoped keys and per-env locking: dev/terraform.tfstate with tf-lock-dev, staging/terraform.tfstate with tf-lock-staging, prod/terraform.tfstate with tf-lock-prod. Do","explanation":"## Why This Is Asked\n\nTests practical backend configuration and multi-environment isolation without relying on workspaces, which can obscure state provenance. It also covers promotion workflows and drift handling in CI.\n\n## Key Concepts\n\n- Terraform backends and per-environment state isolation\n- State locking with DynamoDB per environment\n- Promotion pipelines and drift considerations in CI/CD\n\n## Code Example\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"dev/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-dev\"\n    encrypt        = true\n  }\n}\n```\n\n```hcl\nterraform {\n  backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    dynamodb_table = \"tf-lock-prod\"\n    encrypt        = true\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you handle a state drift detected in prod after a manual change?\n- What are the trade-offs of using a single bucket with per-env keys vs separate buckets per env?","diagram":null,"difficulty":"intermediate","tags":["terraform-associate"],"channel":"terraform-associate","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Google","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:21:52.897Z","createdAt":"2026-01-12T17:21:52.897Z"}],"subChannels":["general"],"companies":["Adobe","Amazon","Bloomberg","Coinbase","Databricks","Google","Hashicorp","Hugging Face","IBM","Instacart","Lyft","Meta","NVIDIA","Netflix","Oracle","PayPal","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Tesla","Zoom"],"stats":{"total":12,"beginner":2,"intermediate":7,"advanced":3,"newThisWeek":12}}