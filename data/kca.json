{"questions":[{"id":"q-844","question":"You have a CSV log with columns: user_id, event_timestamp (ISO 8601), and event_type. Write a Python function using pandas to compute the number of unique active users per day for a given timezone, returning a dict mapping 'YYYY-MM-DD' to count. Explain how you handle timezone normalization and missing data. Provide sample usage?","answer":"Drop rows with missing user_id or event_timestamp; parse as UTC, convert to the target tz, then map to date and count unique user_id per day. Example: import pandas as pd\n\ndef daily_active_users(df, t","explanation":"## Why This Is Asked\nTests practical pandas data munging, timezone handling, and edge cases.\n\n## Key Concepts\n- Timezone normalization\n- Grouping and nunique aggregation\n- Data cleansing\n\n## Code Example\n```python\nimport pandas as pd\n\ndef daily_active_users(df, tz='America/Los_Angeles'):\n    df = df.dropna(subset=['user_id','event_timestamp'])\n    d = pd.to_datetime(df['event_timestamp'], utc=True).dt.tz_convert(tz).dt.date\n    return df.assign(_d=d).groupby('_d')['user_id'].nunique().to_dict()\n```\n\n## Follow-up Questions\n- How would you handle recent DST transitions?\n- How would you optimize for a 100M-row dataset?","diagram":"flowchart TD\n  A[Input: df with event_timestamp] --> B[Drop missing] \n  B --> C[Parse as UTC]\n  C --> D[Convert to tz]\n  D --> E[Extract date]\n  E --> F[Group by date and nunique(user_id)]\n  F --> G[Return dict]","difficulty":"beginner","tags":["kca"],"channel":"kca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:27:59.168Z","createdAt":"2026-01-12T13:27:59.169Z"},{"id":"q-884","question":"You're operating a Kafka-to-Spark streaming job in production and observe sporadic latency spikes; detail a concrete diagnostic plan to identify bottlenecks and a remediation strategy, including metrics, tooling (OpenTelemetry, Prometheus, Grafana), and validation steps?","answer":"Outline a diagnostic plan for a Kafka-to-Spark streaming job with sporadic latency spikes. Specify metrics (partition skew, consumer lag, per-stage latency, GC pauses), tooling (OpenTelemetry, Prometh","explanation":"## Why This Is Asked\nAssesss the candidate's ability to diagnose production latency issues in streaming pipelines, balancing observability, data correctness, and performance. Tests familiarity with distributed systems, tracing, and practical fixes.\n\n## Key Concepts\n- Distributed streaming latency diagnosis\n- Observability stack and metrics\n- Remediation strategies and validation\n- Trade-offs between throughput and consistency\n\n## Code Example\n```python\n# pseudo-checkpoint restart example\nif lag > THRESHOLD:\n    rebalance_partitions()\n    adjust_batch_size()\n    restart_stream()\n```\n\n## Follow-up Questions\n- How would you validate no data loss after replay?\n- What monitoring dashboards would you set up and why?","diagram":"flowchart TD\n  A[Client] --> B[Kafka Topic]\n  B --> C[Kafka Consumer]\n  C --> D[Spark Structured Streaming]\n  D --> E[Sink]\n  E --> F[Backpressure/Latency Alerts]","difficulty":"intermediate","tags":["kca"],"channel":"kca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","DoorDash","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:01:44.365Z","createdAt":"2026-01-12T14:01:44.365Z"},{"id":"q-889","question":"**How would you design a scalable KCA integration** for a multi-tenant SaaS using short-lived client certificates? Central CA in an HSM issues per-tenant CSRs, rotates certificates every 24h, and supports revocation via OCSP stapling and short CRLs with edge caching. Include audit trails, MFA for CA access, and clear renewal, compromise, and revocation workflows?","answer":"Design a scalable KCA integration for a multi-tenant SaaS using short-lived client certificates. Central CA in an HSM issues per-tenant CSRs, rotates certificates every 24h, and supports revocation vi","explanation":"## Why This Is Asked\n\nTests ability to design a cryptographic lifecycle with multi-tenant isolation, operational resilience, and security governance in production.\n\n## Key Concepts\n\n- PKI and CA lifecycle\n- HSM/KMS usage and access control\n- Certificate rotation strategies\n- Revocation mechanisms: OCSP, CRLs\n- Edge caching for performance\n- Auditing and incident response\n\n## Code Example\n\n```javascript\n// Pseudocode: issue cert\nfunction issueCert(tenantId, durationHours) {\n  const csr = createCSR(tenantId);\n  const cert = caSignInHSM(csr, durationHours);\n  return cert;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle CA compromise?\n- How to observe revocation latency at edge proxies?","diagram":"flowchart TD\n  A[Tenant Onboard] --> B[CSR Generated]\n  B --> C[CA Signs in HSM]\n  C --> D[Cert Issued to Tenant]\n  D --> E[Edge Proxy Caches Revocation]\n  E --> F[Audit Logs Persist]","difficulty":"advanced","tags":["kca"],"channel":"kca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:29:11.527Z","createdAt":"2026-01-12T14:29:11.527Z"}],"subChannels":["general"],"companies":["Anthropic","Cloudflare","Coinbase","Databricks","DoorDash","Google","Microsoft","Plaid"],"stats":{"total":3,"beginner":1,"intermediate":1,"advanced":1,"newThisWeek":3}}