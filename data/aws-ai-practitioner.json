{"questions":[{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-0","question":"A data privacy scenario: A media company wants to deploy an FM-based customer support assistant that processes sensitive customer queries in multiple languages. They require strict data privacy and low latency. Which approach best meets these requirements?","answer":"[{\"id\":\"a\",\"text\":\"Use the Bedrock public endpoint and send queries over the public internet for inference.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy a dedicated SageMaker endpoint hosting a foundation model inside a private VPC with encryption and access control.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run a public EC2 instance with a foundation model and expose it behind a load balancer.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Route data to a third-party API with custom encryption but without network isolation.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Deploy a dedicated SageMaker endpoint hosting a foundation model inside a private VPC with encryption at rest and in transit, and access controlled by IAM. This keeps data private and minimizes exposure while still enabling low latency in-region inference.\n\n## Why Other Options Are Wrong\n- Option A is incorrect because public Bedrock endpoints can expose data to potential model-training opt-ins and do not guarantee private handling.\n- Option C is incorrect due to public exposure and higher operational risk and maintenance burden.\n- Option D is incorrect because routing data to a third-party API introduces privacy and data-residency concerns and lacks direct control over data-handling policies.\n\n## Key Concepts\n- Data locality and privacy controls for foundation models\n- In-region private endpoints (VPC) and encryption\n- IAM-based access management for inference\n\n## Real-World Application\n- Use case: multilingual customer support with strict data privacy requirements in regulated industries.","diagram":null,"difficulty":"intermediate","tags":["AWS Bedrock","Amazon SageMaker","VPC","IAM","Encryption","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:07.203Z","createdAt":"2026-01-11 17:16:07"},{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-1","question":"You are building an internal knowledge assistant for engineering docs. You need to provide up-to-date information with fast responses. Which architecture is most suitable?","answer":"[{\"id\":\"a\",\"text\":\"Use a single foundation model without retrieval and rely on its training data.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Build a retrieval augmented generation pipeline using a vector store (SageMaker Embeddings to OpenSearch or Kendra) to fetch relevant docs and then generate answers with a foundation model.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Preload the entire knowledge base into the model prompt and hope it covers all documents.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a static FAQ index and avoid any dynamic retrieval.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Build a retrieval augmented generation pipeline that embeds documents into a vector store (via SageMaker Embeddings, Kendra, or OpenSearch) and uses a foundation model to generate answers from the retrieved context. This delivers up-to-date information with low latency and scales to thousands of docs.\n\n## Why Other Options Are Wrong\n- Option A lacks retrieval and can become stale and less reliable for new docs.\n- Option C is impractical due to prompt-length limits and frequent updates.\n- Option D provides only a static path that cannot surface new or varied knowledge.\n\n## Key Concepts\n- Retrieval augmented generation (RAG)\n- Vector stores and embeddings\n- Real-time knowledge access for FM-powered assistants\n\n## Real-World Application\n- Engineering knowledge base chatbot that answers tech questions using the latest docs from internal repositories.","diagram":null,"difficulty":"intermediate","tags":["Amazon SageMaker","Amazon Kendra","OpenSearch","SageMaker Embeddings","RAG","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:07.673Z","createdAt":"2026-01-11 17:16:08"},{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-2","question":"An AI product team wants to ensure safety and governance of FM outputs in a regulated domain (healthcare). Which AWS services best support monitoring, bias detection, and auditing?","answer":"[{\"id\":\"a\",\"text\":\"Rely on Bedrock safety settings alone with no monitoring.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use SageMaker Model Monitor and SageMaker Clarify for monitoring and bias detection, plus CloudTrail for auditing API calls.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on AWS Config and CloudWatch alone for governance of model outputs.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely on KMS and IAM to ensure governance of outputs.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Use SageMaker Model Monitor for detecting data drift and anomalies, SageMaker Clarify for bias and fairness checks, and CloudTrail to log and audit API calls to model endpoints. This combination provides ongoing governance, auditing, and risk mitigation for healthcare use.\n\n## Why Other Options Are Wrong\n- Option A lacks ongoing monitoring and bias checks, leaving safety gaps.\n- Option C focuses on infrastructure monitoring but not model-specific outputs or bias detection.\n- Option D addresses encryption and access control but not monitoring or auditing of outputs.\n\n## Key Concepts\n- Model monitoring, bias detection, and auditing\n- Compliance-friendly workflows with SageMaker\n- Auditing API activity with CloudTrail\n\n## Real-World Application\n- Healthcare chat assistant with automated drift alerts and audit trails for compliance reviews.","diagram":null,"difficulty":"intermediate","tags":["SageMaker Model Monitor","SageMaker Clarify","CloudTrail","AWS Security","Healthcare Compliance","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:08.120Z","createdAt":"2026-01-11 17:16:08"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-0","question":"You are building a chat assistant that uses retrieval augmented generation over a large document set stored in S3. You want to minimize operational overhead and stay within the AWS ecosystem. Which combination most closely aligns with best-practice RAG on AWS?","answer":"[{\"id\":\"a\",\"text\":\"Use a SageMaker hosted endpoint with a custom retrieval layer on OpenSearch\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use AWS Bedrock with a Titan model and AWS Kendra for retrieval\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a Lambda function calling a third-party LLM and store embeddings in DynamoDB\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a self-hosted OpenAI model on EC2 with a separate vector store\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because AWS Bedrock hosts foundation models and integrates with AWS Kendra for retrieval-augmented generation (RAG) within AWS, enabling scalable, low-ops RAG.\n\n## Why Other Options Are Wrong\n- A relies on SageMaker host with a separate vector store and does not provide the native retrieval integration that Bedrock+Kendra offers.\n- C relies on a third-party LLM via Lambda, adding latency and data-ownership concerns without native AWS retrieval integration.\n- D requires self-hosting a model outside AWS-managed services and separate vector storage, increasing operational burden.\n\n## Key Concepts\n- Retrieval Augmented Generation (RAG)\n- AWS Bedrock\n- Amazon SageMaker\n- Amazon Kendra\n\n## Real-World Application\nUsed for enterprise knowledge bases where agents must fetch relevant documents from S3 and generate concise, accurate responses via Bedrock-backed models while keeping data within AWS.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","Bedrock","Kendra","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:47.718Z","createdAt":"2026-01-12 03:50:48"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-1","question":"You need to deploy a sensitive generative AI feature that processes customer PII and must ensure data never leaves your AWS environment. Which architecture best meets this requirement?","answer":"[{\"id\":\"a\",\"text\":\"Deploy a Bedrock model using public endpoints with data logging enabled\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy a private SageMaker Inference endpoint inside a VPC with no internet egress and encryption at rest/in transit\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run prompts from Lambda that forward requests to a public API\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Expose a local model on EC2 via a public API gateway\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because a private SageMaker Inference endpoint within a VPC ensures data never leaves the VPC; traffic is encrypted at rest and in transit, and access is controlled via IAM.\n\n## Why Other Options Are Wrong\n- A would expose data to public Bedrock endpoints and may log data externally.\n- C sends data to a public API, creating egress risk.\n- D creates a public surface area and increases data exposure.\n\n## Key Concepts\n- Private inference\n- VPC endpoints\n- Encryption at rest and in transit\n- Data privacy and compliance\n\n## Real-World Application\nUse case: processing PII in a regulated environment where data residency and isolation are mandatory.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","EC2","VPC","KMS","IAM","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:48.147Z","createdAt":"2026-01-12 03:50:48"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-2","question":"Your generative AI feature is served via an API and you want to continuously detect data drift in input features and trigger alerts when drift exceeds a threshold. Which AWS service combination best supports this requirement?","answer":"[{\"id\":\"a\",\"text\":\"Use SageMaker Model Monitor to detect data drift and configure CloudWatch alarms\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use AWS Config rules to monitor data format\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Build a custom Lambda drift detector by comparing historical distributions in S3\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use CloudWatch Logs Insights to analyze logs after inference\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because SageMaker Model Monitor can automatically detect data drift in input features and CloudWatch alarms can alert on thresholds, enabling proactive monitoring of production endpoints.\n\n## Why Other Options Are Wrong\n- B is for configuration compliance, not data drift detection.\n- C could work but requires building and maintaining a custom solution, not as scalable as SageMaker Monitor.\n- D only analyzes logs post hoc and does not provide proactive drift detection.\n\n## Key Concepts\n- Data drift\n- Model Monitor\n- CloudWatch alarms\n- Inference endpoints\n\n## Real-World Application\nImplementing Model Monitor avoids silent performance degradation by alerting teams when input data distribution shifts beyond tolerance.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","CloudWatch","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:48.556Z","createdAt":"2026-01-12 03:50:48"}],"subChannels":["ai-ml-applications","generative-ai-fundamentals"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}