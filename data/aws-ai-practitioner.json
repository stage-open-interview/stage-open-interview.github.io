{"questions":[{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-0","question":"A data privacy scenario: A media company wants to deploy an FM-based customer support assistant that processes sensitive customer queries in multiple languages. They require strict data privacy and low latency. Which approach best meets these requirements?","answer":"[{\"id\":\"a\",\"text\":\"Use the Bedrock public endpoint and send queries over the public internet for inference.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy a dedicated SageMaker endpoint hosting a foundation model inside a private VPC with encryption and access control.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run a public EC2 instance with a foundation model and expose it behind a load balancer.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Route data to a third-party API with custom encryption but without network isolation.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Deploy a dedicated SageMaker endpoint hosting a foundation model inside a private VPC with encryption at rest and in transit, and access controlled by IAM. This keeps data private and minimizes exposure while still enabling low latency in-region inference.\n\n## Why Other Options Are Wrong\n- Option A is incorrect because public Bedrock endpoints can expose data to potential model-training opt-ins and do not guarantee private handling.\n- Option C is incorrect due to public exposure and higher operational risk and maintenance burden.\n- Option D is incorrect because routing data to a third-party API introduces privacy and data-residency concerns and lacks direct control over data-handling policies.\n\n## Key Concepts\n- Data locality and privacy controls for foundation models\n- In-region private endpoints (VPC) and encryption\n- IAM-based access management for inference\n\n## Real-World Application\n- Use case: multilingual customer support with strict data privacy requirements in regulated industries.","diagram":null,"difficulty":"intermediate","tags":["AWS Bedrock","Amazon SageMaker","VPC","IAM","Encryption","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:07.203Z","createdAt":"2026-01-11 17:16:07"},{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-1","question":"You are building an internal knowledge assistant for engineering docs. You need to provide up-to-date information with fast responses. Which architecture is most suitable?","answer":"[{\"id\":\"a\",\"text\":\"Use a single foundation model without retrieval and rely on its training data.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Build a retrieval augmented generation pipeline using a vector store (SageMaker Embeddings to OpenSearch or Kendra) to fetch relevant docs and then generate answers with a foundation model.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Preload the entire knowledge base into the model prompt and hope it covers all documents.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a static FAQ index and avoid any dynamic retrieval.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Build a retrieval augmented generation pipeline that embeds documents into a vector store (via SageMaker Embeddings, Kendra, or OpenSearch) and uses a foundation model to generate answers from the retrieved context. This delivers up-to-date information with low latency and scales to thousands of docs.\n\n## Why Other Options Are Wrong\n- Option A lacks retrieval and can become stale and less reliable for new docs.\n- Option C is impractical due to prompt-length limits and frequent updates.\n- Option D provides only a static path that cannot surface new or varied knowledge.\n\n## Key Concepts\n- Retrieval augmented generation (RAG)\n- Vector stores and embeddings\n- Real-time knowledge access for FM-powered assistants\n\n## Real-World Application\n- Engineering knowledge base chatbot that answers tech questions using the latest docs from internal repositories.","diagram":null,"difficulty":"intermediate","tags":["Amazon SageMaker","Amazon Kendra","OpenSearch","SageMaker Embeddings","RAG","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:07.673Z","createdAt":"2026-01-11 17:16:08"},{"id":"aws-ai-practitioner-ai-ml-applications-1768151767199-2","question":"An AI product team wants to ensure safety and governance of FM outputs in a regulated domain (healthcare). Which AWS services best support monitoring, bias detection, and auditing?","answer":"[{\"id\":\"a\",\"text\":\"Rely on Bedrock safety settings alone with no monitoring.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use SageMaker Model Monitor and SageMaker Clarify for monitoring and bias detection, plus CloudTrail for auditing API calls.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on AWS Config and CloudWatch alone for governance of model outputs.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely on KMS and IAM to ensure governance of outputs.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Use SageMaker Model Monitor for detecting data drift and anomalies, SageMaker Clarify for bias and fairness checks, and CloudTrail to log and audit API calls to model endpoints. This combination provides ongoing governance, auditing, and risk mitigation for healthcare use.\n\n## Why Other Options Are Wrong\n- Option A lacks ongoing monitoring and bias checks, leaving safety gaps.\n- Option C focuses on infrastructure monitoring but not model-specific outputs or bias detection.\n- Option D addresses encryption and access control but not monitoring or auditing of outputs.\n\n## Key Concepts\n- Model monitoring, bias detection, and auditing\n- Compliance-friendly workflows with SageMaker\n- Auditing API activity with CloudTrail\n\n## Real-World Application\n- Healthcare chat assistant with automated drift alerts and audit trails for compliance reviews.","diagram":null,"difficulty":"intermediate","tags":["SageMaker Model Monitor","SageMaker Clarify","CloudTrail","AWS Security","Healthcare Compliance","certification-mcq","domain-weight-28"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-applications","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:16:08.120Z","createdAt":"2026-01-11 17:16:08"},{"id":"aws-ai-practitioner-ai-ml-fundamentals-1768221720127-0","question":"A data science team is deploying a real-time fraud detection model in AWS. They have streaming events arriving via Kinesis and require sub-second latency to return decisions. They want to minimize operational overhead. Which approach best meets these requirements?","answer":"[{\"id\":\"a\",\"text\":\"Train a model using SageMaker, deploy Batch Transform endpoint, and run inference in batch every 5 minutes\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy a SageMaker real-time endpoint from the trained model and autoscale instance types to handle traffic\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use SageMaker Ground Truth to label streaming events and retrain every hour\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Package the model into a Lambda function and call it synchronously from API Gateway\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because real-time endpoints provide sub-second latency and can be autoscaled to handle varying traffic, aligning with the requirement for low latency and reduced operational overhead.\n\n## Why Other Options Are Wrong\n- Option A: Batch Transform processes data offline and introduces higher latency; not suitable for real-time decisions.\n- Option C: Ground Truth is for labeling data, not inference or deployment; does not address latency or throughput.\n- Option D: Lambda is unsuitable for large ML models due to memory/time limits and cold starts, leading to higher latency and maintenance overhead.\n\n## Key Concepts\n- Real-time inference with SageMaker endpoints\n- Auto-scaling and endpoint hosting considerations\n- Streaming data integration (Kinesis) vs batch inference\n\n## Real-World Application\n- Deploys a scalable real-time inference service for fraud detection, ensuring timely decisions and manageable ops load.","diagram":null,"difficulty":"intermediate","tags":["AWS SageMaker","Amazon Kinesis","ML Inference","Auto Scaling","certification-mcq","domain-weight-20"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:42:00.128Z","createdAt":"2026-01-12 12:42:00"},{"id":"aws-ai-practitioner-ai-ml-fundamentals-1768221720127-1","question":"You are building a taxonomy classifier for customer support tickets using SageMaker. You must monitor and mitigate bias in predictions across different customer segments (e.g., age groups, regions). Which AWS service helps you detect and explain potential model bias during the ML lifecycle?","answer":"[{\"id\":\"a\",\"text\":\"SageMaker Ground Truth\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"SageMaker Clarify\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"AWS Data Pipeline\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Amazon Macie\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because SageMaker Clarify provides bias detection, explanations, and debugging capabilities across data and model predictions.\n\n## Why Other Options Are Wrong\n- Option A: Ground Truth is for labeling and data labeling workflows, not bias detection.\n- Option C: Data Pipeline is for data workflow orchestration, not model explainability.\n- Option D: Macie focuses on data security and data discovery, not ML bias or explainability.\n\n## Key Concepts\n- Bias detection and explainability in ML\n- Tools for model governance in SageMaker\n- Impact on model fairness and compliance\n\n## Real-World Application\n- Integrates Clarify into model training pipelines to routinely assess fairness across segments.","diagram":null,"difficulty":"intermediate","tags":["AWS SageMaker","Model Explainability","Bias Detection","SageMaker Clarify","certification-mcq","domain-weight-20"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:42:00.587Z","createdAt":"2026-01-12 12:42:00"},{"id":"aws-ai-practitioner-ai-ml-fundamentals-1768221720127-2","question":"During an ML workflow, a team stores training data and artifacts in an S3 bucket. To ensure encryption at rest for all data stored in the bucket without changing client code, which configuration should be enabled?","answer":"[{\"id\":\"a\",\"text\":\"Enable S3 bucket versioning and object locking\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable S3 default encryption with SSE-S3 (AES-256) on the bucket\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Require client-side encryption before uploading objects\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create a KMS key and enable SSE-KMS with a bucket policy\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because enabling default server-side encryption with SSE-S3 ensures new objects are encrypted at rest automatically, without changing client code.\n\n## Why Other Options Are Wrong\n- Option A: Versioning/object locking do not provide encryption at rest.\n- Option C: Client-side encryption requires changes at the producer side, not automatic server-side encryption.\n- Option D: SSE-KMS is valid but adds key management complexity; SSE-S3 default encryption achieves the requirement with less overhead.\n\n## Key Concepts\n- S3 default encryption (SSE-S3) vs SSE-KMS\n- Automatic encryption at rest in storage\n- Minimizing changes to client applications\n\n## Real-World Application\n- Simplifies compliance by ensuring all uploaded artifacts are encrypted without modifying producers.","diagram":null,"difficulty":"intermediate","tags":["AWS S3","Server-Side Encryption","SSE-S3","AWS KMS","certification-mcq","domain-weight-20"],"channel":"aws-ai-practitioner","subChannel":"ai-ml-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:42:01.067Z","createdAt":"2026-01-12 12:42:01"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-0","question":"You are building a chat assistant that uses retrieval augmented generation over a large document set stored in S3. You want to minimize operational overhead and stay within the AWS ecosystem. Which combination most closely aligns with best-practice RAG on AWS?","answer":"[{\"id\":\"a\",\"text\":\"Use a SageMaker hosted endpoint with a custom retrieval layer on OpenSearch\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use AWS Bedrock with a Titan model and AWS Kendra for retrieval\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a Lambda function calling a third-party LLM and store embeddings in DynamoDB\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a self-hosted OpenAI model on EC2 with a separate vector store\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because AWS Bedrock hosts foundation models and integrates with AWS Kendra for retrieval-augmented generation (RAG) within AWS, enabling scalable, low-ops RAG.\n\n## Why Other Options Are Wrong\n- A relies on SageMaker host with a separate vector store and does not provide the native retrieval integration that Bedrock+Kendra offers.\n- C relies on a third-party LLM via Lambda, adding latency and data-ownership concerns without native AWS retrieval integration.\n- D requires self-hosting a model outside AWS-managed services and separate vector storage, increasing operational burden.\n\n## Key Concepts\n- Retrieval Augmented Generation (RAG)\n- AWS Bedrock\n- Amazon SageMaker\n- Amazon Kendra\n\n## Real-World Application\nUsed for enterprise knowledge bases where agents must fetch relevant documents from S3 and generate concise, accurate responses via Bedrock-backed models while keeping data within AWS.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","Bedrock","Kendra","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:47.718Z","createdAt":"2026-01-12 03:50:48"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-1","question":"You need to deploy a sensitive generative AI feature that processes customer PII and must ensure data never leaves your AWS environment. Which architecture best meets this requirement?","answer":"[{\"id\":\"a\",\"text\":\"Deploy a Bedrock model using public endpoints with data logging enabled\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy a private SageMaker Inference endpoint inside a VPC with no internet egress and encryption at rest/in transit\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run prompts from Lambda that forward requests to a public API\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Expose a local model on EC2 via a public API gateway\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because a private SageMaker Inference endpoint within a VPC ensures data never leaves the VPC; traffic is encrypted at rest and in transit, and access is controlled via IAM.\n\n## Why Other Options Are Wrong\n- A would expose data to public Bedrock endpoints and may log data externally.\n- C sends data to a public API, creating egress risk.\n- D creates a public surface area and increases data exposure.\n\n## Key Concepts\n- Private inference\n- VPC endpoints\n- Encryption at rest and in transit\n- Data privacy and compliance\n\n## Real-World Application\nUse case: processing PII in a regulated environment where data residency and isolation are mandatory.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","EC2","VPC","KMS","IAM","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:48.147Z","createdAt":"2026-01-12 03:50:48"},{"id":"aws-ai-practitioner-generative-ai-fundamentals-1768189847717-2","question":"Your generative AI feature is served via an API and you want to continuously detect data drift in input features and trigger alerts when drift exceeds a threshold. Which AWS service combination best supports this requirement?","answer":"[{\"id\":\"a\",\"text\":\"Use SageMaker Model Monitor to detect data drift and configure CloudWatch alarms\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use AWS Config rules to monitor data format\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Build a custom Lambda drift detector by comparing historical distributions in S3\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use CloudWatch Logs Insights to analyze logs after inference\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because SageMaker Model Monitor can automatically detect data drift in input features and CloudWatch alarms can alert on thresholds, enabling proactive monitoring of production endpoints.\n\n## Why Other Options Are Wrong\n- B is for configuration compliance, not data drift detection.\n- C could work but requires building and maintaining a custom solution, not as scalable as SageMaker Monitor.\n- D only analyzes logs post hoc and does not provide proactive drift detection.\n\n## Key Concepts\n- Data drift\n- Model Monitor\n- CloudWatch alarms\n- Inference endpoints\n\n## Real-World Application\nImplementing Model Monitor avoids silent performance degradation by alerting teams when input data distribution shifts beyond tolerance.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","SageMaker","CloudWatch","Kubernetes","Terraform","certification-mcq","domain-weight-24"],"channel":"aws-ai-practitioner","subChannel":"generative-ai-fundamentals","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:50:48.556Z","createdAt":"2026-01-12 03:50:48"}],"subChannels":["ai-ml-applications","ai-ml-fundamentals","generative-ai-fundamentals"],"companies":[],"stats":{"total":9,"beginner":0,"intermediate":9,"advanced":0,"newThisWeek":9}}