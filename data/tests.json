[{"id":"test-aws","channelId":"aws","channelName":"AWS","title":"AWS Knowledge Test","description":"Test your AWS knowledge.","questions":[{"id":"tq-q-216","questionId":"q-216","question":"How would you implement eventual consistency in a multi-region DynamoDB application with write conflicts?","type":"single","options":[{"id":"opt-0","text":"Use DynamoDB Global Tables with conditional writes and version numbers/timestamps for conflict resolution","isCorrect":true},{"id":"opt-1","text":"Use single-region DynamoDB with manual replication","isCorrect":false},{"id":"opt-2","text":"Use DynamoDB Streams with Lambda functions for conflict resolution","isCorrect":false},{"id":"opt-3","text":"Use DynamoDB Accelerator (DAX) for caching","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-220","questionId":"q-220","question":"How would you design a multi-AZ VPC architecture with Route53 latency-based routing to CloudFront?","type":"single","options":[{"id":"opt-0","text":"Use Route53 latency records with health checks, CloudFront with origin failover, ALB across AZs, and cross-AZ private subnets with NAT gateways","isCorrect":true},{"id":"opt-1","text":"Use single AZ deployment with direct CloudFront integration","isCorrect":false},{"id":"opt-2","text":"Use Route53 geolocation routing without health checks","isCorrect":false},{"id":"opt-3","text":"Use CloudFront only without Route53","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-57","questionId":"gh-57","question":"What is Cloud Cost Optimization and what are the key strategies?","type":"single","options":[{"id":"opt-0","text":"Cloud Cost Optimization reduces cloud spend by identifying waste, right-sizing resources, using reserved instances, implementing auto-scaling, and monitoring","isCorrect":true},{"id":"opt-1","text":"Cloud Cost Optimization only involves using cheaper cloud providers","isCorrect":false},{"id":"opt-2","text":"Cloud Cost Optimization is about maximizing resource usage regardless of cost","isCorrect":false},{"id":"opt-3","text":"Cloud Cost Optimization requires manual intervention for all resources","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-13","questionId":"gh-13","question":"What is AWS (Amazon Web Services)?","type":"single","options":[{"id":"opt-0","text":"AWS is a comprehensive and widely adopted cloud platform, offering over 200 fully featured services from data centers globally","isCorrect":true},{"id":"opt-1","text":"AWS is only a database service provider","isCorrect":false},{"id":"opt-2","text":"AWS is a single-region hosting service","isCorrect":false},{"id":"opt-3","text":"AWS is primarily a content delivery network","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-292","questionId":"q-292","question":"How would you design a data lifecycle strategy for a media company storing petabytes of video content?","type":"single","options":[{"id":"opt-0","text":"Use S3 Standard for active videos, S3 IA for infrequent access, and Glacier for deep archive with lifecycle policies for automated transitions","isCorrect":true},{"id":"opt-1","text":"Store all videos permanently in S3 Standard","isCorrect":false},{"id":"opt-2","text":"Use only Glacier for all video storage","isCorrect":false},{"id":"opt-3","text":"Use on-premises storage for all video content","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-15","questionId":"gh-15","question":"What are the different types of cloud services?","type":"single","options":[{"id":"opt-0","text":"IaaS, PaaS, SaaS","isCorrect":true},{"id":"opt-1","text":"Public, Private, Hybrid","isCorrect":false},{"id":"opt-2","text":"Compute, Storage, Network","isCorrect":false},{"id":"opt-3","text":"Frontend, Backend, Database","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-12","questionId":"gh-12","question":"Which statement best describes the three main cloud service models?","type":"single","options":[{"id":"opt-0","text":"IaaS provides infrastructure, PaaS offers platforms for development, and SaaS delivers ready-to-use software","isCorrect":true},{"id":"opt-1","text":"IaaS manages applications, PaaS handles infrastructure, and SaaS provides development tools","isCorrect":false},{"id":"opt-2","text":"All three models provide the same level of management","isCorrect":false},{"id":"opt-3","text":"IaaS is only for storage, PaaS is only for computing, and SaaS is only for networking","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-58","questionId":"gh-58","question":"What is the main benefit of AWS Reserved Instances compared to On-Demand pricing?","type":"single","options":[{"id":"opt-0","text":"Up to 75% discount with 1-3 year commitment","isCorrect":true},{"id":"opt-1","text":"No commitment required with lower costs","isCorrect":false},{"id":"opt-2","text":"Free tier with unlimited usage","isCorrect":false},{"id":"opt-3","text":"Pay-as-you-go with no long-term contracts","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-87","questionId":"gh-87","question":"How does FinOps implement cost allocation in multi-cloud environments?","type":"single","options":[{"id":"opt-0","text":"Using tagging, showback, and chargeback mechanisms","isCorrect":true},{"id":"opt-1","text":"By manually splitting costs evenly","isCorrect":false},{"id":"opt-2","text":"Through random distribution methods","isCorrect":false},{"id":"opt-3","text":"By ignoring cost allocation completely","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-34","questionId":"gh-34","question":"What is Auto Scaling in cloud computing?","type":"single","options":[{"id":"opt-0","text":"A feature that automatically adjusts compute resources based on demand","isCorrect":true},{"id":"opt-1","text":"A manual process for adding more servers","isCorrect":false},{"id":"opt-2","text":"A fixed-size infrastructure setup","isCorrect":false},{"id":"opt-3","text":"A backup and recovery system","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-174","questionId":"q-174","question":"You have an EC2 instance that suddenly becomes unresponsive. What is the first step you should take?","type":"single","options":[{"id":"opt-0","text":"Check CloudWatch metrics","isCorrect":true},{"id":"opt-1","text":"Use EC2 Serial Console","isCorrect":false},{"id":"opt-2","text":"Examine system logs","isCorrect":false},{"id":"opt-3","text":"Verify security group/network ACLs","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-246","questionId":"q-246","question":"What AWS service would you use to coordinate Lambda functions in a serverless workflow?","type":"single","options":[{"id":"opt-0","text":"AWS Step Functions","isCorrect":true},{"id":"opt-1","text":"AWS Lambda","isCorrect":false},{"id":"opt-2","text":"Amazon SQS","isCorrect":false},{"id":"opt-3","text":"Amazon EventBridge","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-83","questionId":"gh-83","question":"How does the Cloud Adoption Framework perform cloud service assessment?","type":"single","options":[{"id":"opt-0","text":"By evaluating cloud services against business requirements using structured methodology","isCorrect":true},{"id":"opt-1","text":"By automatically selecting the cheapest cloud services","isCorrect":false},{"id":"opt-2","text":"By migrating all services to cloud immediately","isCorrect":false},{"id":"opt-3","text":"By using only AWS services","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-66","questionId":"gh-66","question":"What is a key characteristic of serverless computing execution?","type":"single","options":[{"id":"opt-0","text":"Event-driven functions that auto-scale with pay-per-use billing","isCorrect":true},{"id":"opt-1","text":"Manual server management with fixed capacity","isCorrect":false},{"id":"opt-2","text":"Always-on servers with hourly billing","isCorrect":false},{"id":"opt-3","text":"Container-based deployment with manual scaling","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-220","questionId":"q-220","question":"How would you design a multi-AZ VPC architecture with Route53 latency-based routing to CloudFront?","type":"single","options":[{"id":"opt-0","text":"Use Route53 latency records with health checks, CloudFront with origin failover, ALB across AZs, and cross-AZ private subnets with NAT gateways","isCorrect":true},{"id":"opt-1","text":"Deploy single-AZ architecture with direct CloudFront integration","isCorrect":false},{"id":"opt-2","text":"Use Route53 geolocation routing without health checks","isCorrect":false},{"id":"opt-3","text":"Implement CloudFront only without Route53 routing","isCorrect":false}],"explanation":"Multi-AZ architecture requires latency-based routing, health checks, and cross-AZ redundancy for high availability.","difficulty":"intermediate"},{"id":"tq-gh-13","questionId":"gh-13","question":"What is AWS (Amazon Web Services)?","type":"single","options":[{"id":"opt-0","text":"A comprehensive cloud platform offering over 200 fully featured services from global data centers","isCorrect":true},{"id":"opt-1","text":"A single-purpose hosting service for websites only","isCorrect":false},{"id":"opt-2","text":"A local server management tool","isCorrect":false},{"id":"opt-3","text":"A database-only service provider","isCorrect":false}],"explanation":"AWS is a comprehensive cloud platform with extensive service offerings across computing, storage, networking, and more.","difficulty":"beginner"},{"id":"tq-q-321","questionId":"q-321","question":"When would you choose ECS Fargate versus EKS for containerized applications?","type":"single","options":[{"id":"opt-0","text":"ECS Fargate for simpler workloads with less operational overhead, EKS for complex microservices needing Kubernetes features","isCorrect":true},{"id":"opt-1","text":"Always choose EKS regardless of workload complexity","isCorrect":false},{"id":"opt-2","text":"Use ECS Fargate only for large enterprise applications","isCorrect":false},{"id":"opt-3","text":"EKS is better for simple, single-container applications","isCorrect":false}],"explanation":"The choice depends on workload complexity and operational requirements - Fargate for simplicity, EKS for Kubernetes features.","difficulty":"beginner"},{"id":"tq-gh-83","questionId":"gh-83","question":"How do you evaluate cloud services for business needs?","type":"single","options":[{"id":"opt-0","text":"Cloud assessment matches services to requirements using cost, performance, security, and compliance criteria","isCorrect":true},{"id":"opt-1","text":"Choose the cheapest available service regardless of requirements","isCorrect":false},{"id":"opt-2","text":"Select services based on vendor popularity only","isCorrect":false},{"id":"opt-3","text":"Use a single evaluation criterion like cost alone","isCorrect":false}],"explanation":"Comprehensive evaluation requires multiple criteria including cost, performance, security, and compliance to ensure proper service selection.","difficulty":"advanced"},{"id":"tq-gh-66","questionId":"gh-66","question":"How does serverless computing abstract infrastructure management?","type":"single","options":[{"id":"opt-0","text":"Through event-driven functions that auto-scale with pay-per-use billing and zero server maintenance","isCorrect":true},{"id":"opt-1","text":"By requiring manual server configuration and management","isCorrect":false},{"id":"opt-2","text":"Using fixed-capacity virtual machines","isCorrect":false},{"id":"opt-3","text":"Through traditional container orchestration","isCorrect":false}],"explanation":"Serverless computing provides automatic scaling, event-driven execution, and eliminates the need for server management.","difficulty":"beginner"},{"id":"tq-gh-57","questionId":"gh-57","question":"What is Cloud Cost Optimization and which strategy helps reduce cloud spending by committing to long-term usage?","type":"single","options":[{"id":"opt-0","text":"Using reserved instances for predictable workloads","isCorrect":true},{"id":"opt-1","text":"Implementing auto-scaling for variable demand","isCorrect":false},{"id":"opt-2","text":"Right-sizing resources based on actual usage","isCorrect":false},{"id":"opt-3","text":"Monitoring and identifying resource waste","isCorrect":false}],"explanation":"Reserved instances provide significant discounts (up to 75%) for committing to 1-3 year terms, making them the most effective cost optimization strategy.","difficulty":"beginner"},{"id":"tq-q-174","questionId":"q-174","question":"Your EC2 instance becomes unresponsive. What should be your first troubleshooting step?","type":"single","options":[{"id":"opt-0","text":"Check CloudWatch metrics for CPU/memory utilization","isCorrect":true},{"id":"opt-1","text":"Use EC2 Serial Console for direct access","isCorrect":false},{"id":"opt-2","text":"Examine system logs for errors","isCorrect":false},{"id":"opt-3","text":"Verify security group and network ACL configurations","isCorrect":false}],"explanation":"CloudWatch metrics provide immediate visibility into resource utilization issues that commonly cause unresponsiveness, making it the logical first diagnostic step.","difficulty":"intermediate"},{"id":"tq-q-216","questionId":"q-216","question":"How would you handle write conflicts in a multi-region DynamoDB application requiring eventual consistency?","type":"single","options":[{"id":"opt-0","text":"Use DynamoDB Global Tables with conditional writes and version numbers","isCorrect":true},{"id":"opt-1","text":"Implement strong consistency reads across all regions","isCorrect":false},{"id":"opt-2","text":"Use a single-region write pattern with cross-region replication","isCorrect":false},{"id":"opt-3","text":"Apply custom conflict resolution logic in application code","isCorrect":false}],"explanation":"DynamoDB Global Tables automatically replicate data across regions while conditional writes with version numbers provide built-in conflict resolution for eventual consistency.","difficulty":"intermediate"},{"id":"tq-q-307","questionId":"q-307","question":"Which AWS storage service offers unlimited scale with 99.999999999% durability for object storage?","type":"single","options":[{"id":"opt-0","text":"S3 Standard for object storage","isCorrect":true},{"id":"opt-1","text":"EBS for block storage attached to EC2","isCorrect":false},{"id":"opt-2","text":"EFS for shared file storage across multiple AZs","isCorrect":false},{"id":"opt-3","text":"S3 Glacier Deep Archive for long-term archival","isCorrect":false}],"explanation":"S3 provides object storage with unlimited scalability and the highest durability (11 nines), making it ideal for storing design assets and other objects.","difficulty":"intermediate"},{"id":"tq-q-370","questionId":"q-370","question":"For Canva's large PSD files (up to 10GB), what's the most cost-effective storage strategy?","type":"single","options":[{"id":"opt-0","text":"S3 Standard for active files, S3 Standard-IA for older versions, Glacier Deep Archive for archival","isCorrect":true},{"id":"opt-1","text":"EBS volumes for all files with regular snapshots","isCorrect":false},{"id":"opt-2","text":"EFS for shared access with automatic versioning","isCorrect":false},{"id":"opt-3","text":"S3 Intelligent-Tiering to automatically optimize storage class","isCorrect":false}],"explanation":"A lifecycle policy approach using different S3 storage classes based on access patterns provides the best balance of performance and cost for large design files.","difficulty":"intermediate"},{"id":"tq-gh-15","questionId":"gh-15","question":"What are the main categories of cloud computing services?","type":"single","options":[{"id":"opt-0","text":"Infrastructure, Platform, and Software as a Service","isCorrect":true},{"id":"opt-1","text":"Public, Private, and Hybrid Cloud","isCorrect":false},{"id":"opt-2","text":"Compute, Storage, and Networking","isCorrect":false},{"id":"opt-3","text":"Development, Testing, and Production","isCorrect":false}],"explanation":"Cloud services are primarily categorized into IaaS, PaaS, and SaaS, representing different levels of managed services.","difficulty":"intermediate"},{"id":"tq-gh-34","questionId":"gh-34","question":"What is the primary purpose of Auto Scaling in cloud environments?","type":"single","options":[{"id":"opt-0","text":"To automatically backup data at regular intervals","isCorrect":false},{"id":"opt-1","text":"To adjust compute resources based on demand fluctuations","isCorrect":true},{"id":"opt-2","text":"To monitor application performance metrics","isCorrect":false},{"id":"opt-3","text":"To distribute traffic across multiple servers","isCorrect":false}],"explanation":"Auto Scaling dynamically modifies resource capacity to match current workload demands, optimizing cost and performance.","difficulty":"advanced"},{"id":"tq-q-292","questionId":"q-292","question":"How should a media company implement a cost-effective storage strategy for petabytes of video content?","type":"single","options":[{"id":"opt-0","text":"Store all videos in S3 Standard for consistent performance","isCorrect":false},{"id":"opt-1","text":"Use S3 Standard for active content, S3 IA for infrequent access, and Glacier for archival","isCorrect":true},{"id":"opt-2","text":"Implement on-premises storage with cloud backup","isCorrect":false},{"id":"opt-3","text":"Use a single storage tier with lifecycle policies","isCorrect":false}],"explanation":"A tiered storage approach using different S3 classes optimizes costs by matching storage performance to access patterns.","difficulty":"advanced"},{"id":"tq-gh-58","questionId":"gh-58","question":"What is the main advantage of AWS Reserved Instances compared to On-Demand pricing?","type":"single","options":[{"id":"opt-0","text":"They provide automatic scaling capabilities","isCorrect":false},{"id":"opt-1","text":"They offer up to 75% cost savings in exchange for commitment","isCorrect":true},{"id":"opt-2","text":"They include free data transfer between regions","isCorrect":false},{"id":"opt-3","text":"They guarantee 100% uptime SLA","isCorrect":false}],"explanation":"Reserved Instances provide significant discounts (up to 75%) when committing to 1-3 year terms for specific instance configurations.","difficulty":"intermediate"},{"id":"tq-gh-87","questionId":"gh-87","question":"How does FinOps typically handle cost allocation in multi-cloud environments?","type":"single","options":[{"id":"opt-0","text":"By using a single billing account across all clouds","isCorrect":false},{"id":"opt-1","text":"Through tagging, showback, and chargeback mechanisms","isCorrect":true},{"id":"opt-2","text":"By implementing fixed cost sharing percentages","isCorrect":false},{"id":"opt-3","text":"With manual spreadsheet tracking","isCorrect":false}],"explanation":"FinOps employs tagging strategies and showback/chargeback models to accurately allocate and communicate cloud costs.","difficulty":"advanced"},{"id":"tq-gh-12","questionId":"gh-12","question":"What distinguishes IaaS, PaaS, and SaaS cloud service models?","type":"single","options":[{"id":"opt-0","text":"Their pricing models and billing cycles","isCorrect":false},{"id":"opt-1","text":"The level of infrastructure management responsibility","isCorrect":true},{"id":"opt-2","text":"Their geographic availability and regions","isCorrect":false},{"id":"opt-3","text":"Their security compliance certifications","isCorrect":false}],"explanation":"The key difference is management responsibility: IaaS provides infrastructure, PaaS offers development platforms, and SaaS delivers complete software solutions.","difficulty":"beginner"},{"id":"tq-q-357","questionId":"q-357","question":"What database architecture is optimal for storing 10M+ daily security events with millisecond access requirements?","type":"single","options":[{"id":"opt-0","text":"Relational database with horizontal sharding","isCorrect":false},{"id":"opt-1","text":"DynamoDB with time-based partitioning and hot partitioning","isCorrect":true},{"id":"opt-2","text":"Document database with geospatial indexing","isCorrect":false},{"id":"opt-3","text":"Graph database for relationship analysis","isCorrect":false}],"explanation":"DynamoDB's partitioning strategy combined with hot partitioning for recent data provides the required scalability and performance.","difficulty":"intermediate"},{"id":"tq-q-246","questionId":"q-246","question":"How would you implement error handling in a serverless AWS Step Functions workflow?","type":"single","options":[{"id":"opt-0","text":"Using try-catch blocks in Lambda functions","isCorrect":false},{"id":"opt-1","text":"With Choice states for branching and Retry/Catch policies","isCorrect":true},{"id":"opt-2","text":"Through CloudWatch alarms and notifications","isCorrect":false},{"id":"opt-3","text":"By implementing circuit breaker patterns","isCorrect":false}],"explanation":"Step Functions provides built-in error handling through Choice states for conditional logic and Retry/Catch policies for failure recovery.","difficulty":"intermediate"},{"id":"tq-q-384","questionId":"q-384","question":"What architecture best serves a multi-region SaaS application with users in North America and Europe?","type":"single","options":[{"id":"opt-0","text":"Single region deployment with CDN","isCorrect":false},{"id":"opt-1","text":"Route53 latency routing to CloudFront edges with regional ALBs","isCorrect":true},{"id":"opt-2","text":"Multi-region active-active database replication","isCorrect":false},{"id":"opt-3","text":"Geographic DNS routing with regional load balancers","isCorrect":false}],"explanation":"Latency-based routing through CloudFront edge locations provides optimal performance while regional ALBs handle traffic distribution.","difficulty":"intermediate"},{"id":"tq-q-401","questionId":"q-401","question":"Why is DynamoDB with DAX recommended for high-throughput real-time analytics dashboards?","type":"single","options":[{"id":"opt-0","text":"It provides automatic data compression","isCorrect":false},{"id":"opt-1","text":"It offers predictable performance with lower operational overhead","isCorrect":true},{"id":"opt-2","text":"It includes built-in machine learning capabilities","isCorrect":false},{"id":"opt-3","text":"It supports complex SQL queries natively","isCorrect":false}],"explanation":"DynamoDB with DAX delivers consistent performance at scale while minimizing operational complexity and costs for high-throughput scenarios.","difficulty":"intermediate"},{"id":"tq-q-413","questionId":"q-413","question":"You're designing a real-time analytics dashboard for an IoT application that receives 10,000 events per second. What's the optimal architecture?","type":"single","options":[{"id":"opt-0","text":"Use DynamoDB for event ingestion with time-based partitioning, Aurora for analytical queries, and ElastiCache Redis for real-time dashboard caching","isCorrect":true},{"id":"opt-1","text":"Use a single RDS PostgreSQL instance for both ingestion and analytics","isCorrect":false},{"id":"opt-2","text":"Store all events in S3 and run Athena queries for real-time dashboard","isCorrect":false},{"id":"opt-3","text":"Use MongoDB with sharding for event storage and direct queries for the dashboard","isCorrect":false}],"explanation":"DynamoDB handles high-volume write throughput efficiently, Aurora provides complex analytical query capabilities, and Redis offers sub-millisecond response times for real-time dashboard data.","difficulty":"intermediate"},{"id":"tq-gh-85","questionId":"gh-85","question":"How do cloud migration tools automate the transfer of applications and data between on-premise and cloud environments?","type":"single","options":[{"id":"opt-0","text":"They only provide manual migration scripts and templates","isCorrect":false},{"id":"opt-1","text":"They automate discovery, planning, replication, and cutover while maintaining data consistency","isCorrect":true},{"id":"opt-2","text":"They require complete application rewrite before migration","isCorrect":false},{"id":"opt-3","text":"They only support database migration without application components","isCorrect":false}],"explanation":"Cloud migration tools like AWS Migration Hub and Azure Migrate automate the entire migration process including discovery, planning, replication, and cutover while ensuring data consistency through continuous replication.","difficulty":"intermediate"},{"id":"tq-q-454","questionId":"q-454","question":"What is the recommended approach for hosting a static website with high availability and low latency globally?","type":"single","options":[{"id":"opt-0","text":"Use a single EC2 instance with Apache web server","isCorrect":false},{"id":"opt-1","text":"Configure S3 bucket with static hosting, enable CloudFront distribution with OAI","isCorrect":true},{"id":"opt-2","text":"Deploy to multiple regional load balancers manually","isCorrect":false},{"id":"opt-3","text":"Use only S3 bucket without CDN for simplicity","isCorrect":false}],"explanation":"The best practice is to use S3 for static website hosting with versioning and security controls, combined with CloudFront CDN for global low latency and high availability, using OAI for secure access.","difficulty":"beginner"},{"id":"tq-q-484","questionId":"q-484","question":"You're designing a real-time ML inference pipeline on AWS that must process 10,000 requests/second with consistent performance. What's the optimal architecture?","type":"single","options":[{"id":"opt-0","text":"API Gateway + Lambda with provisioned concurrency + ECS for GPU workloads","isCorrect":true},{"id":"opt-1","text":"Direct API calls to EC2 instances with auto-scaling","isCorrect":false},{"id":"opt-2","text":"API Gateway + Step Functions + SageMaker endpoints","isCorrect":false},{"id":"opt-3","text":"Application Load Balancer + Fargate + RDS database","isCorrect":false}],"explanation":"API Gateway with provisioned concurrency provides consistent performance for high-throughput ML inference, while ECS handles GPU workloads effectively.","difficulty":"advanced"},{"id":"tq-q-514","questionId":"q-514","question":"You're building a serverless application that needs to process user uploads. How would you design an optimal architecture?","type":"single","options":[{"id":"opt-0","text":"Use API Gateway with Lambda authorizer for authentication, generate presigned S3 URLs for direct uploads to avoid proxying through Lambda. Trigger Lambda functions for post-processing","isCorrect":true},{"id":"opt-1","text":"Proxy all file uploads through Lambda functions to handle authentication and storage in S3","isCorrect":false},{"id":"opt-2","text":"Use EC2 instances with load balancers to handle file uploads and processing","isCorrect":false},{"id":"opt-3","text":"Implement a monolithic application on Elastic Beanstalk to handle uploads and processing","isCorrect":false}],"explanation":"Presigned S3 URLs enable direct uploads, reducing Lambda costs and improving performance while maintaining security through API Gateway authentication.","difficulty":"beginner"},{"id":"tq-q-543","questionId":"q-543","question":"You're deploying a microservices application on AWS ECS. One service is experiencing intermittent 502 errors. What should be your first step in troubleshooting?","type":"single","options":[{"id":"opt-0","text":"Check ECS service metrics for CPU/memory throttling, examine ALB health checks and target group deregistrations. Review CloudWatch logs for container restarts","isCorrect":true},{"id":"opt-1","text":"Immediately scale up the service to handle increased load","isCorrect":false},{"id":"opt-2","text":"Redeploy the entire application stack to clear any cached issues","isCorrect":false},{"id":"opt-3","text":"Switch from Fargate to EC2 launch type for better performance","isCorrect":false}],"explanation":"The systematic approach of checking service metrics, health checks, and logs provides the most comprehensive initial diagnosis for 502 errors in ECS.","difficulty":"intermediate"}],"passingScore":70,"createdAt":"2025-12-18T10:04:41.223Z","lastUpdated":"2025-12-26T20:24:39.517Z","version":8},{"id":"test-algorithms","channelId":"algorithms","channelName":"Algorithms","title":"Algorithms Knowledge Test","description":"Test your Algorithms knowledge.","questions":[{"id":"tq-q-187","questionId":"q-187","question":"How would you implement a thread-safe LRU cache using a HashMap and DoublyLinkedList?","type":"single","options":[{"id":"opt-0","text":"Use HashMap for O(1) key lookup and DoublyLinkedList for O(1) insertion/removal. Synchronize access with ReentrantReadWriteLock for thread safety.","isCorrect":true},{"id":"opt-1","text":"Use HashMap for O(1) key lookup and ArrayList for O(1) insertion/removal. Synchronize access with synchronized keyword.","isCorrect":false},{"id":"opt-2","text":"Use TreeMap for O(log n) key lookup and DoublyLinkedList for O(1) insertion/removal. Synchronize access with ReentrantLock.","isCorrect":false},{"id":"opt-3","text":"Use HashMap for O(1) key lookup and SinglyLinkedList for O(1) insertion/removal. Synchronize access with volatile variables.","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-170","questionId":"al-170","question":"Given an array of integers where each element represents the maximum number of steps you can jump forward, what's the optimal approach?","type":"single","options":[{"id":"opt-0","text":"Use greedy approach tracking current range and furthest reachable position in O(n) time.","isCorrect":true},{"id":"opt-1","text":"Use dynamic programming with memoization in O(n²) time.","isCorrect":false},{"id":"opt-2","text":"Use backtracking to explore all possible paths in O(2ⁿ) time.","isCorrect":false},{"id":"opt-3","text":"Use binary search to find optimal jump points in O(n log n) time.","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-al-163","questionId":"al-163","question":"You have an array where each element appears twice except one element that appears once. How would you sort the array efficiently?","type":"single","options":[{"id":"opt-0","text":"Use XOR to find the unique element first, then partition array around it using modified counting sort with bit manipulation.","isCorrect":true},{"id":"opt-1","text":"Use quicksort to sort the entire array in O(n log n) time.","isCorrect":false},{"id":"opt-2","text":"Use hash map to count frequencies, then reconstruct sorted array in O(n) time.","isCorrect":false},{"id":"opt-3","text":"Use bubble sort to identify the unique element during sorting in O(n²) time.","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-167","questionId":"al-167","question":"Count the number of ways to reach target sum using dice rolls where each roll can be 1-6?","type":"single","options":[{"id":"opt-0","text":"DP where dp[i] = sum(dp[i-1] to dp[i-6]) with base case dp[0] = 1","isCorrect":true},{"id":"opt-1","text":"DP where dp[i] = dp[i-1] + dp[i-2] with base case dp[0] = 1","isCorrect":false},{"id":"opt-2","text":"DP where dp[i] = dp[i-1] * 6 with base case dp[0] = 1","isCorrect":false},{"id":"opt-3","text":"DP where dp[i] = max(dp[i-1] to dp[i-6]) with base case dp[0] = 1","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-152","questionId":"al-152","question":"You have a staircase with n steps. You can climb 1, 2, or 3 steps at a time. How many distinct ways can you reach the top?","type":"single","options":[{"id":"opt-0","text":"Use DP with 3 variables tracking last 3 positions. dp[i] = dp[i-1] + dp[i-2] + dp[i-3]. Base: dp[0]=1, dp[1]=1, dp[2]=2","isCorrect":true},{"id":"opt-1","text":"Use DP with 2 variables tracking last 2 positions. dp[i] = dp[i-1] + dp[i-2]. Base: dp[0]=1, dp[1]=1","isCorrect":false},{"id":"opt-2","text":"Use DP with 4 variables tracking last 4 positions. dp[i] = dp[i-1] + dp[i-2] + dp[i-3] + dp[i-4]. Base: dp[0]=1, dp[1]=1, dp[2]=2, dp[3]=4","isCorrect":false},{"id":"opt-3","text":"Use DP with single variable. dp[i] = dp[i-1] * 3. Base: dp[0]=1","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-166","questionId":"al-166","question":"Given a string, what approach is used to find the minimum number of insertions and deletions to make it a palindrome?","type":"single","options":[{"id":"opt-0","text":"Greedy algorithm with two pointers","isCorrect":false},{"id":"opt-1","text":"DP with states (i,j) representing substring s[i..j]","isCorrect":true},{"id":"opt-2","text":"BFS exploring all possible palindromes","isCorrect":false},{"id":"opt-3","text":"Hash map storing palindrome substrings","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-286","questionId":"q-286","question":"What is the key difference between BFS and DFS?","type":"single","options":[{"id":"opt-0","text":"BFS uses recursion, DFS uses iteration","isCorrect":false},{"id":"opt-1","text":"BFS explores level by level, DFS goes deep first","isCorrect":true},{"id":"opt-2","text":"BFS requires more memory than DFS","isCorrect":false},{"id":"opt-3","text":"DFS finds shortest paths, BFS finds all paths","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-167","questionId":"q-167","question":"How do you find the maximum depth of a binary tree?","type":"single","options":[{"id":"opt-0","text":"Iterative BFS counting levels","isCorrect":false},{"id":"opt-1","text":"Recursive DFS: return 1 + max(depth(left), depth(right))","isCorrect":true},{"id":"opt-2","text":"Dynamic programming with memoization","isCorrect":false},{"id":"opt-3","text":"In-order traversal with counter","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-al-165","questionId":"al-165","question":"What is the main advantage of a Trie over a hash map for prefix search?","type":"single","options":[{"id":"opt-0","text":"Faster insertion operations","isCorrect":false},{"id":"opt-1","text":"O(k) prefix search, space-efficient for common prefixes","isCorrect":true},{"id":"opt-2","text":"Better memory utilization for sparse data","isCorrect":false},{"id":"opt-3","text":"Simpler implementation","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-164","questionId":"al-164","question":"How do you find the number of ways to reach a target sum using array elements where each element can be used multiple times?","type":"single","options":[{"id":"opt-0","text":"Recursive backtracking with memoization","isCorrect":false},{"id":"opt-1","text":"DP with unbounded knapsack: dp[i] = sum(dp[i - nums[j]])","isCorrect":true},{"id":"opt-2","text":"BFS exploring all sum combinations","isCorrect":false},{"id":"opt-3","text":"Binary search on possible sums","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-2","questionId":"al-2","question":"Which sorting algorithm is generally faster in practice due to better cache locality but is unstable?","type":"single","options":[{"id":"opt-0","text":"QuickSort","isCorrect":true},{"id":"opt-1","text":"MergeSort","isCorrect":false},{"id":"opt-2","text":"HeapSort","isCorrect":false},{"id":"opt-3","text":"BubbleSort","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-al-3","questionId":"al-3","question":"What is the key difference between Dynamic Programming and plain recursion?","type":"single","options":[{"id":"opt-0","text":"DP uses more memory","isCorrect":false},{"id":"opt-1","text":"DP stores results to avoid redundant computations","isCorrect":true},{"id":"opt-2","text":"DP is always faster","isCorrect":false},{"id":"opt-3","text":"DP only works with trees","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-214","questionId":"q-214","question":"For a directed weighted graph with 10^6 edges and frequent updates, what algorithm maintains O(log n) per update?","type":"single","options":[{"id":"opt-0","text":"Standard Dijkstra","isCorrect":false},{"id":"opt-1","text":"Bellman-Ford","isCorrect":false},{"id":"opt-2","text":"Dynamic Dijkstra with incremental updates","isCorrect":true},{"id":"opt-3","text":"Floyd-Warshall","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-al-1","questionId":"al-1","question":"When would you choose a Linked List over an Array?","type":"single","options":[{"id":"opt-0","text":"When you need O(1) random access","isCorrect":false},{"id":"opt-1","text":"When you have frequent insertions/deletions","isCorrect":true},{"id":"opt-2","text":"When cache locality is critical","isCorrect":false},{"id":"opt-3","text":"When memory usage must be minimal","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-al-165","questionId":"al-165","question":"What is the main advantage of using a Trie data structure over a hash map for prefix search operations?","type":"single","options":[{"id":"opt-0","text":"O(k) time complexity for prefix search with space efficiency for common prefixes","isCorrect":true},{"id":"opt-1","text":"O(1) time complexity for all operations with constant space usage","isCorrect":false},{"id":"opt-2","text":"O(log n) time complexity with balanced tree structure","isCorrect":false},{"id":"opt-3","text":"O(n) time complexity but with minimal memory overhead","isCorrect":false}],"explanation":"Trie provides O(k) prefix search where k is prefix length, and shares storage for common prefixes making it space-efficient.","difficulty":"intermediate"},{"id":"tq-al-152","questionId":"al-152","question":"How would you calculate the number of distinct ways to climb a staircase with n steps if you can take 1, 2, or 3 steps at a time?","type":"single","options":[{"id":"opt-0","text":"Use DP with dp[i] = dp[i-1] + dp[i-2] + dp[i-3], base cases dp[0]=1, dp[1]=1, dp[2]=2","isCorrect":true},{"id":"opt-1","text":"Use recursion with memoization and return 2^n for any n","isCorrect":false},{"id":"opt-2","text":"Use mathematical formula n! / (n-3)! to calculate combinations","isCorrect":false},{"id":"opt-3","text":"Use greedy algorithm always taking maximum steps (3) until remaining steps < 3","isCorrect":false}],"explanation":"Dynamic programming tracks ways to reach each position by summing ways from previous 3 positions, with proper base cases.","difficulty":"intermediate"},{"id":"tq-q-314","questionId":"q-314","question":"Which approach is most efficient for finding the kth smallest element in a Binary Search Tree?","type":"single","options":[{"id":"opt-0","text":"Inorder traversal with counter or Morris traversal for O(1) space","isCorrect":true},{"id":"opt-1","text":"Level-order traversal with priority queue for O(k log n)","isCorrect":false},{"id":"opt-2","text":"Post-order traversal with stack for O(n) space","isCorrect":false},{"id":"opt-3","text":"Pre-order traversal with recursion for O(h) space","isCorrect":false}],"explanation":"Inorder traversal visits nodes in sorted order naturally, and Morris traversal achieves this with O(1) auxiliary space.","difficulty":"beginner"},{"id":"tq-al-2","questionId":"al-2","question":"When comparing QuickSort and MergeSort, which statement accurately describes their trade-offs?","type":"single","options":[{"id":"opt-0","text":"QuickSort is generally faster due to cache locality but unstable, while MergeSort is stable but uses O(n) space","isCorrect":true},{"id":"opt-1","text":"QuickSort is always O(n log n) while MergeSort can degrade to O(n²) in worst cases","isCorrect":false},{"id":"opt-2","text":"MergeSort is faster in practice but QuickSort guarantees stability","isCorrect":false},{"id":"opt-3","text":"Both algorithms have identical performance characteristics and space requirements","isCorrect":false}],"explanation":"QuickSort's in-place nature and cache efficiency make it faster practically, but it's unstable. MergeSort maintains stability at the cost of O(n) auxiliary space.","difficulty":"intermediate"},{"id":"tq-q-350","questionId":"q-350","question":"For finding the shortest path in a directed graph representing city intersections, what algorithm would be most appropriate?","type":"single","options":[{"id":"opt-0","text":"BFS with queue tracking visited nodes and distances, returning distance or -1 if unreachable","isCorrect":true},{"id":"opt-1","text":"DFS with recursion exploring all paths and finding minimum distance","isCorrect":false},{"id":"opt-2","text":"Dijkstra's algorithm with priority queue for weighted edges","isCorrect":false},{"id":"opt-3","text":"A* algorithm with heuristic for optimal pathfinding","isCorrect":false}],"explanation":"BFS naturally finds shortest paths in unweighted graphs by exploring level by level, using a queue and tracking visited nodes with distances.","difficulty":"beginner"},{"id":"tq-q-377","questionId":"q-377","question":"What is the most efficient way to implement a min-heap using an array that supports insert, extractMin, and peek operations?","type":"single","options":[{"id":"opt-0","text":"Use array representation where parent at i has children at 2i+1 and 2i+2, bubble up/down to maintain heap property","isCorrect":true},{"id":"opt-1","text":"Use a binary search tree with array indexing","isCorrect":false},{"id":"opt-2","text":"Use a linked list with priority queue implementation","isCorrect":false},{"id":"opt-3","text":"Use a hash table with min-tracking","isCorrect":false}],"explanation":"Array representation with parent-child relationships at indices 2i+1 and 2i+2 allows O(log n) operations through bubble up/down algorithms.","difficulty":"beginner"},{"id":"tq-al-164","questionId":"al-164","question":"How would you solve the unbounded knapsack problem to count ways to reach a target sum using array elements?","type":"single","options":[{"id":"opt-0","text":"Use DP with unbounded knapsack: dp[i] = sum(dp[i - nums[j]]) for all valid j","isCorrect":true},{"id":"opt-1","text":"Use recursive backtracking with memoization","isCorrect":false},{"id":"opt-2","text":"Use greedy algorithm selecting largest elements first","isCorrect":false},{"id":"opt-3","text":"Use binary search to find valid combinations","isCorrect":false}],"explanation":"Dynamic programming with unbounded knapsack efficiently counts all combinations by building up solutions from smaller subproblems.","difficulty":"intermediate"},{"id":"tq-al-1","questionId":"al-1","question":"When should you prefer a Linked List over an Array data structure?","type":"single","options":[{"id":"opt-0","text":"Linked Lists excel at frequent insertions/deletions, Arrays excel at O(1) random access and cache locality","isCorrect":true},{"id":"opt-1","text":"Linked Lists are always faster for all operations","isCorrect":false},{"id":"opt-2","text":"Arrays are better for memory management and dynamic sizing","isCorrect":false},{"id":"opt-3","text":"Linked Lists provide better performance for search operations","isCorrect":false}],"explanation":"Linked Lists offer O(1) insertions/deletions at any position, while Arrays provide O(1) random access and better cache performance.","difficulty":"beginner"},{"id":"tq-q-300","questionId":"q-300","question":"What are the key differences between quicksort and mergesort algorithms?","type":"single","options":[{"id":"opt-0","text":"Quicksort: O(n log n) avg, O(n²) worst, O(log n) space. Mergesort: O(n log n) always, O(n) space. Quicksort is in-place, mergesort is stable","isCorrect":true},{"id":"opt-1","text":"Both have identical time and space complexities","isCorrect":false},{"id":"opt-2","text":"Quicksort is always O(n log n) while mergesort can be O(n²)","isCorrect":false},{"id":"opt-3","text":"Mergesort is in-place while quicksort requires O(n) extra space","isCorrect":false}],"explanation":"Quicksort offers better average performance with in-place sorting, while mergesort guarantees O(n log n) time and stability at the cost of extra space.","difficulty":"beginner"},{"id":"tq-q-214","questionId":"q-214","question":"For a directed weighted graph with frequent edge weight updates, what data structure would be most efficient?","type":"single","options":[{"id":"opt-0","text":"Use a dynamic Dijkstra variant with incremental updates and hierarchical decomposition","isCorrect":true},{"id":"opt-1","text":"Use Floyd-Warshall algorithm for all pairs shortest paths","isCorrect":false},{"id":"opt-2","text":"Use Bellman-Ford algorithm with edge relaxation","isCorrect":false},{"id":"opt-3","text":"Use static Dijkstra with complete recomputation","isCorrect":false}],"explanation":"Dynamic Dijkstra with incremental updates maintains O(log n) per operation, making it ideal for graphs with frequent edge weight modifications.","difficulty":"advanced"},{"id":"tq-q-167","questionId":"q-167","question":"What is the most efficient approach to find the maximum depth of a binary tree?","type":"single","options":[{"id":"opt-0","text":"Use recursive DFS: return 1 + max(depth(left), depth(right))","isCorrect":true},{"id":"opt-1","text":"Use iterative BFS with queue","isCorrect":false},{"id":"opt-2","text":"Use Morris traversal for O(1) space","isCorrect":false},{"id":"opt-3","text":"Use post-order traversal with stack","isCorrect":false}],"explanation":"Recursive DFS naturally explores tree depth by adding 1 for each level and taking the maximum of left and right subtrees.","difficulty":"beginner"},{"id":"tq-al-163","questionId":"al-163","question":"How would you efficiently sort an array where each element appears twice except one unique element?","type":"single","options":[{"id":"opt-0","text":"Use XOR to find unique element, then partition with counting sort","isCorrect":true},{"id":"opt-1","text":"Use hash map to count frequencies, then sort","isCorrect":false},{"id":"opt-2","text":"Use quicksort and then scan for unique element","isCorrect":false},{"id":"opt-3","text":"Use merge sort with custom comparator","isCorrect":false}],"explanation":"XOR finds the unique element in O(n), then modified counting sort with bit manipulation efficiently partitions the array.","difficulty":"intermediate"},{"id":"tq-q-362","questionId":"q-362","question":"Why does quicksort have O(n log n) average case but O(n²) worst case, and when should you avoid it?","type":"single","options":[{"id":"opt-0","text":"Average O(n log n) due to random pivots, worst O(n²) with poor pivots; avoid with nearly sorted data","isCorrect":true},{"id":"opt-1","text":"Always O(n log n) regardless of input; never avoid","isCorrect":false},{"id":"opt-2","text":"O(n²) average case due to partitioning; avoid with large datasets","isCorrect":false},{"id":"opt-3","text":"O(n log n) worst case; avoid when memory is limited","isCorrect":false}],"explanation":"Quicksort's performance depends on pivot selection. Poor pivots (like in sorted data) cause O(n²) worst case, making mergesort better for such inputs.","difficulty":"beginner"},{"id":"tq-q-328","questionId":"q-328","question":"What is the optimal DP approach for finding the minimum path sum in an m x n grid?","type":"single","options":[{"id":"opt-0","text":"DP with tabulation: O(mn) time, O(mn) space, optimizable to O(n) space","isCorrect":true},{"id":"opt-1","text":"Recursive memoization: O(mn) time, O(mn) space","isCorrect":false},{"id":"opt-2","text":"BFS with priority queue: O(mn log mn) time","isCorrect":false},{"id":"opt-3","text":"Greedy approach: O(mn) time, O(1) space","isCorrect":false}],"explanation":"DP tabulation efficiently computes minimum path sums. Space can be optimized to O(n) by storing only the previous row since each cell depends only on the row above.","difficulty":"intermediate"},{"id":"tq-q-340","questionId":"q-340","question":"How do you find the kth smallest element in a BST with possible duplicates?","type":"single","options":[{"id":"opt-0","text":"Inorder traversal with counter, O(n) time worst case","isCorrect":true},{"id":"opt-1","text":"Preorder traversal with min-heap, O(n log k) time","isCorrect":false},{"id":"opt-2","text":"Level-order traversal, O(n) time","isCorrect":false},{"id":"opt-3","text":"Post-order traversal with stack, O(n) time","isCorrect":false}],"explanation":"Inorder traversal naturally visits nodes in sorted order. With a counter, we can stop when reaching the kth element, handling duplicates correctly.","difficulty":"intermediate"},{"id":"tq-al-3","questionId":"al-3","question":"What is the key difference between Dynamic Programming and plain recursion?","type":"single","options":[{"id":"opt-0","text":"DP stores results to avoid redundant computations, trading space for time","isCorrect":true},{"id":"opt-1","text":"DP uses iteration instead of recursion","isCorrect":false},{"id":"opt-2","text":"DP always has better time complexity","isCorrect":false},{"id":"opt-3","text":"DP only works with tree structures","isCorrect":false}],"explanation":"DP optimizes recursion through memoization or tabulation, storing intermediate results to eliminate redundant calculations at the cost of additional memory.","difficulty":"advanced"},{"id":"tq-q-187","questionId":"q-187","question":"How would you implement a thread-safe LRU cache efficiently?","type":"single","options":[{"id":"opt-0","text":"HashMap for O(1) lookup + DoublyLinkedList for O(1) operations + ReentrantReadWriteLock","isCorrect":true},{"id":"opt-1","text":"ArrayList for storage + synchronized methods","isCorrect":false},{"id":"opt-2","text":"ConcurrentHashMap + priority queue","isCorrect":false},{"id":"opt-3","text":"HashMap + synchronized blocks","isCorrect":false}],"explanation":"HashMap provides O(1) key access, DoublyLinkedList enables O(1) insertion/removal, and ReentrantReadWriteLock ensures thread safety with optimal concurrency.","difficulty":"intermediate"},{"id":"tq-al-170","questionId":"al-170","question":"What is the most efficient algorithm for the jump game problem?","type":"single","options":[{"id":"opt-0","text":"Greedy approach tracking current range and furthest position, O(n) time","isCorrect":true},{"id":"opt-1","text":"DP with O(n²) time","isCorrect":false},{"id":"opt-2","text":"BFS with O(n²) time","isCorrect":false},{"id":"opt-3","text":"Recursive backtracking with O(2ⁿ) time","isCorrect":false}],"explanation":"The greedy approach efficiently tracks the current jump range and furthest reachable position in a single pass, achieving optimal O(n) time complexity.","difficulty":"advanced"},{"id":"tq-q-394","questionId":"q-394","question":"How do you find minimum completion time for tasks in a DAG dependency graph?","type":"single","options":[{"id":"opt-0","text":"Topological sort with priority queue, O(V+E) time","isCorrect":true},{"id":"opt-1","text":"DFS with memoization, O(V+E) time","isCorrect":false},{"id":"opt-2","text":"BFS with level tracking, O(V+E) time","isCorrect":false},{"id":"opt-3","text":"Dijkstra's algorithm, O((V+E) log V) time","isCorrect":false}],"explanation":"Topological sort processes tasks in dependency order, while a priority queue optimally schedules available tasks across workers for minimum completion time.","difficulty":"advanced"},{"id":"tq-al-167","questionId":"al-167","question":"What is the correct DP formulation for dice roll sum counting?","type":"single","options":[{"id":"opt-0","text":"dp[i] = sum(dp[i-1] to dp[i-6]) with dp[0] = 1","isCorrect":true},{"id":"opt-1","text":"dp[i] = dp[i-1] + dp[i-2] + dp[i-3]","isCorrect":false},{"id":"opt-2","text":"dp[i] = 6 * dp[i-1]","isCorrect":false},{"id":"opt-3","text":"dp[i] = dp[i-6] with dp[0] = 1","isCorrect":false}],"explanation":"Each position i can be reached by rolling a 1-6 from positions i-1 to i-6, so we sum all those possibilities with dp[0] = 1 as the base case.","difficulty":"intermediate"},{"id":"tq-q-286","questionId":"q-286","question":"What is the key difference between BFS and DFS graph traversal algorithms?","type":"single","options":[{"id":"opt-0","text":"BFS explores level by level while DFS goes deep first","isCorrect":true},{"id":"opt-1","text":"BFS uses less memory than DFS","isCorrect":false},{"id":"opt-2","text":"DFS finds shortest paths while BFS uses less memory","isCorrect":false},{"id":"opt-3","text":"BFS and DFS have identical behavior","isCorrect":false}],"explanation":"BFS explores nodes level by level and is ideal for finding shortest paths, while DFS goes deep first and uses less memory for exhaustive search.","difficulty":"intermediate"},{"id":"tq-q-407","questionId":"q-407","question":"Which algorithm is most efficient for finding the top K most frequent errors in a streaming log?","type":"single","options":[{"id":"opt-0","text":"Sort all errors by frequency and take top K","isCorrect":false},{"id":"opt-1","text":"Use a sliding window with hashmap and min-heap","isCorrect":true},{"id":"opt-2","text":"Maintain a fixed-size array of all errors","isCorrect":false},{"id":"opt-3","text":"Use binary search on sorted timestamps","isCorrect":false}],"explanation":"A sliding window with hashmap for counting and min-heap of size K provides optimal O(n log K) time complexity for streaming data.","difficulty":"intermediate"},{"id":"tq-q-418","questionId":"q-418","question":"What data structure provides O(log n) time for both range sum queries and point updates?","type":"single","options":[{"id":"opt-0","text":"Binary search tree","isCorrect":false},{"id":"opt-1","text":"Hash map","isCorrect":false},{"id":"opt-2","text":"Segment tree","isCorrect":true},{"id":"opt-3","text":"Linked list","isCorrect":false}],"explanation":"Segment trees store sum information in each node, enabling O(log n) point updates and range sum queries on dynamic arrays.","difficulty":"advanced"},{"id":"tq-al-166","questionId":"al-166","question":"How would you find the minimum cost to transform a string into a palindrome with given insertion/deletion costs?","type":"single","options":[{"id":"opt-0","text":"Use two-pointer approach from both ends","isCorrect":false},{"id":"opt-1","text":"Apply greedy algorithm based on character frequency","isCorrect":false},{"id":"opt-2","text":"Use dynamic programming with dp[i][j] for substring costs","isCorrect":true},{"id":"opt-3","text":"Sort characters and rebuild symmetrically","isCorrect":false}],"explanation":"Dynamic programming where dp[i][j] represents minimum cost for substring s[i..j] efficiently handles the palindrome transformation problem.","difficulty":"intermediate"},{"id":"tq-q-433","questionId":"q-433","question":"What is the average time complexity of quicksort and when would you prefer it over mergesort?","type":"single","options":[{"id":"opt-0","text":"O(n log n) average, choose for in-place sorting with better cache performance","isCorrect":true},{"id":"opt-1","text":"O(n log n) average, choose when stability is required","isCorrect":false},{"id":"opt-2","text":"O(n²) average, choose when memory is constrained","isCorrect":false},{"id":"opt-3","text":"O(n) average, choose for nearly sorted data","isCorrect":false}],"explanation":"Quicksort has O(n log n) average time complexity and is preferred for in-place sorting with better cache performance compared to mergesort.","difficulty":"beginner"},{"id":"tq-q-425","questionId":"q-425","question":"What is the most efficient approach to find two numbers in an array that sum to a target value?","type":"single","options":[{"id":"opt-0","text":"Use nested loops to check all pairs - O(n²) time","isCorrect":false},{"id":"opt-1","text":"Sort the array and use two pointers - O(n log n) time","isCorrect":false},{"id":"opt-2","text":"Use a hash map to store numbers and check complements - O(n) time","isCorrect":true},{"id":"opt-3","text":"Use binary search for each element - O(n log n) time","isCorrect":false}],"explanation":"Using a hash map provides O(n) time complexity by storing numbers and checking if the complement (target - current) exists in the map.","difficulty":"beginner"},{"id":"tq-q-440","questionId":"q-440","question":"What is the time and space complexity of the optimal solution for word break II that returns all possible sentences?","type":"single","options":[{"id":"opt-0","text":"O(n²) time, O(n) space using DP only","isCorrect":false},{"id":"opt-1","text":"O(n³) time, O(n²) space using DP with memoization","isCorrect":true},{"id":"opt-2","text":"O(2ⁿ) time, O(n) space using brute force recursion","isCorrect":false},{"id":"opt-3","text":"O(n log n) time, O(n) space using greedy approach","isCorrect":false}],"explanation":"The optimal solution uses DP with memoization, achieving O(n³) time complexity in worst case and O(n²) space for the memo table.","difficulty":"advanced"},{"id":"tq-q-451","questionId":"q-451","question":"What is the most efficient approach to find the kth smallest element in a Binary Search Tree using O(h) space and O(n) time?","type":"single","options":[{"id":"opt-0","text":"Use inorder traversal with a counter","isCorrect":true},{"id":"opt-1","text":"Use level-order traversal","isCorrect":false},{"id":"opt-2","text":"Use post-order traversal","isCorrect":false},{"id":"opt-3","text":"Use preorder traversal","isCorrect":false}],"explanation":"Inorder traversal of a BST yields elements in sorted order. By traversing left-root-right recursively and decrementing a counter when visiting each node, we can find the kth smallest element efficiently.","difficulty":"beginner"},{"id":"tq-q-442","questionId":"q-442","question":"Which system design pattern is most suitable for finding the top K most frequent actions from a stream of user actions with timestamps?","type":"single","options":[{"id":"opt-0","text":"Sliding window with deque and hash map plus max-heap","isCorrect":true},{"id":"opt-1","text":"Fixed-size array with linear scan","isCorrect":false},{"id":"opt-2","text":"Circular buffer with binary search","isCorrect":false},{"id":"opt-3","text":"Linked list with frequency counting","isCorrect":false}],"explanation":"A sliding window with deque manages timestamps efficiently, while a hash map tracks frequency counts. A max-heap enables O(log K) queries for top K elements, making this the optimal solution for streaming data.","difficulty":"intermediate"},{"id":"tq-q-540","questionId":"q-540","question":"What is the optimal approach to find all possible sentences by inserting spaces into a string using a given dictionary?","type":"single","options":[{"id":"opt-0","text":"Use DP with memoization: dp[i] stores all valid sentences from s[i:], trying all matching words recursively","isCorrect":true},{"id":"opt-1","text":"Apply greedy algorithm: always choose the longest matching word from the current position","isCorrect":false},{"id":"opt-2","text":"Implement BFS: explore all possible word combinations level by level","isCorrect":false},{"id":"opt-3","text":"Use backtracking: try all possible space combinations without memoization","isCorrect":false}],"explanation":"DP with memoization efficiently stores results for subproblems, avoiding redundant computations while exploring all valid word combinations.","difficulty":"advanced"},{"id":"tq-q-277","questionId":"q-277","question":"Which techniques are essential for efficiently processing a 50GB log file to extract top 10 most frequent IP addresses?","type":"multiple","options":[{"id":"opt-0","text":"Implement streaming solution with buffered I/O using Go's bufio.Scanner","isCorrect":true},{"id":"opt-1","text":"Process in chunks (1GB) to manage memory constraints","isCorrect":true},{"id":"opt-2","text":"Use a min-heap to maintain top 10 frequencies","isCorrect":true},{"id":"opt-3","text":"Load entire file into memory for faster processing","isCorrect":false}],"explanation":"Streaming with buffered I/O, chunked processing, and min-heap optimization are key for handling large files efficiently while maintaining memory constraints.","difficulty":"advanced"}],"passingScore":70,"createdAt":"2025-12-18T10:03:45.698Z","lastUpdated":"2025-12-26T20:24:34.339Z","version":7},{"id":"test-backend","channelId":"backend","channelName":"Backend","title":"Backend Knowledge Test","description":"Test your Backend knowledge.","questions":[{"id":"tq-q-267","questionId":"q-267","question":"What's the difference between REST, GraphQL, and gRPC in terms of protocol and data format?","type":"single","options":[{"id":"opt-0","text":"REST uses HTTP/1.1 with JSON/XML, GraphQL uses HTTP with JSON, and gRPC uses HTTP/2 with Protocol Buffers","isCorrect":true},{"id":"opt-1","text":"REST uses HTTP/2 with JSON, GraphQL uses HTTP/1.1 with XML, and gRPC uses HTTP with Protocol Buffers","isCorrect":false},{"id":"opt-2","text":"REST uses HTTP with Protocol Buffers, GraphQL uses HTTP/2 with JSON, and gRPC uses HTTP/1.1 with XML","isCorrect":false},{"id":"opt-3","text":"REST uses HTTP with JSON, GraphQL uses HTTP/2 with Protocol Buffers, and gRPC uses HTTP/1.1 with XML","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-352","questionId":"q-352","question":"How would you design a distributed order processing system using Saga pattern for a high-frequency trading platform?","type":"single","options":[{"id":"opt-0","text":"Implement choreography-based Saga with compensating actions, event sourcing for state recovery and idempotent compensators with retry policies","isCorrect":true},{"id":"opt-1","text":"Implement orchestration-based Saga with synchronous transactions and database locks","isCorrect":false},{"id":"opt-2","text":"Implement monolithic architecture with two-phase commit protocol","isCorrect":false},{"id":"opt-3","text":"Implement event-driven architecture without compensating transactions","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-342","questionId":"q-342","question":"A user reports their OAuth2 access token works but refresh token doesn't. What should you check?","type":"single","options":[{"id":"opt-0","text":"Token expiration, scope mismatch, and refresh token revocation","isCorrect":true},{"id":"opt-1","text":"Only token expiration","isCorrect":false},{"id":"opt-2","text":"Only client configuration","isCorrect":false},{"id":"opt-3","text":"Only user permissions","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-330","questionId":"q-330","question":"How would you handle real-time updates in a collaborative whiteboard app when a user drags a shape?","type":"single","options":[{"id":"opt-0","text":"Separate commands (update shape position) from queries (get shape data). Use command handler to validate and persist, then emit event for UI update","isCorrect":true},{"id":"opt-1","text":"Directly update the database and push changes to all clients","isCorrect":false},{"id":"opt-2","text":"Use WebSocket to broadcast raw mouse movements","isCorrect":false},{"id":"opt-3","text":"Implement polling mechanism for shape position updates","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-46","questionId":"gh-46","question":"What are the key components of comprehensive API documentation?","type":"single","options":[{"id":"opt-0","text":"Endpoints, request/response schemas, authentication, and usage examples","isCorrect":true},{"id":"opt-1","text":"Only endpoint descriptions","isCorrect":false},{"id":"opt-2","text":"Only code examples","isCorrect":false},{"id":"opt-3","text":"Only authentication methods","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-316","questionId":"q-316","question":"How would you design a database architecture to handle 10 million users with 99.99% uptime?","type":"single","options":[{"id":"opt-0","text":"Horizontal sharding by user ID, multi-region replication with leader-follower setup, and read replicas for load distribution","isCorrect":true},{"id":"opt-1","text":"Single database with vertical scaling","isCorrect":false},{"id":"opt-2","text":"Master-slave replication without sharding","isCorrect":false},{"id":"opt-3","text":"In-memory database with persistence","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-249","questionId":"q-249","question":"How would you implement a connection pool manager for aiohttp with graceful degradation?","type":"single","options":[{"id":"opt-0","text":"Semaphore limiting, exponential backoff, and health checks with circuit breaker pattern","isCorrect":true},{"id":"opt-1","text":"Unlimited connections with retry only","isCorrect":false},{"id":"opt-2","text":"Fixed connection pool without health checks","isCorrect":false},{"id":"opt-3","text":"Single connection with timeout","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-302","questionId":"q-302","question":"What is the difference between OAuth 2.0 and OpenID Connect (OIDC)?","type":"single","options":[{"id":"opt-0","text":"OAuth 2.0 is for authorization, OIDC adds identity layer on top for authentication with ID tokens","isCorrect":true},{"id":"opt-1","text":"OAuth 2.0 is for authentication, OIDC is for authorization","isCorrect":false},{"id":"opt-2","text":"OAuth 2.0 and OIDC are the same protocol","isCorrect":false},{"id":"opt-3","text":"OAuth 2.0 uses JWT, OIDC uses opaque tokens","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-364","questionId":"q-364","question":"How would you handle command failures in a CQRS order management system?","type":"single","options":[{"id":"opt-0","text":"Implement idempotent event handlers and use compensating transactions to rollback read model state when command failures occur","isCorrect":true},{"id":"opt-1","text":"Ignore failures and continue processing","isCorrect":false},{"id":"opt-2","text":"Retry commands indefinitely without rollback","isCorrect":false},{"id":"opt-3","text":"Use synchronous transactions to prevent failures","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-249","questionId":"q-249","question":"How would you implement a connection pool manager for aiohttp that handles graceful degradation under high load?","type":"single","options":[{"id":"opt-0","text":"Use semaphore limiting, exponential backoff, and health checks with circuit breaker pattern","isCorrect":true},{"id":"opt-1","text":"Implement unlimited connections with basic retry logic","isCorrect":false},{"id":"opt-2","text":"Create a simple queue without health monitoring","isCorrect":false},{"id":"opt-3","text":"Use synchronous connections with timeout handling","isCorrect":false}],"explanation":"Circuit breaker pattern with semaphores and health checks provides resilient connection pooling that degrades gracefully.","difficulty":"advanced"},{"id":"tq-q-379","questionId":"q-379","question":"How would you handle compensation in a distributed order processing system using the Saga pattern?","type":"single","options":[{"id":"opt-0","text":"Implement compensating transactions: release inventory, refund payment, notify customer, and log failures","isCorrect":true},{"id":"opt-1","text":"Retry the failed transaction until it succeeds","isCorrect":false},{"id":"opt-2","text":"Ignore the failure and continue processing","isCorrect":false},{"id":"opt-3","text":"Roll back the entire system immediately","isCorrect":false}],"explanation":"Compensating transactions ensure system consistency by reversing completed operations and maintaining audit trails.","difficulty":"beginner"},{"id":"tq-q-267","questionId":"q-267","question":"What's the difference between REST, GraphQL, and gRPC in terms of protocol and data format?","type":"single","options":[{"id":"opt-0","text":"REST uses HTTP/1.1 with JSON/XML, GraphQL uses HTTP with JSON, and gRPC uses HTTP/2 with Protocol Buffers","isCorrect":true},{"id":"opt-1","text":"All use HTTP/1.1 with JSON format","isCorrect":false},{"id":"opt-2","text":"REST uses HTTP/2, GraphQL uses TCP, gRPC uses UDP","isCorrect":false},{"id":"opt-3","text":"All use Protocol Buffers with different protocols","isCorrect":false}],"explanation":"Each API style uses different protocols and data formats optimized for their specific use cases and performance requirements.","difficulty":"beginner"},{"id":"tq-q-316","questionId":"q-316","question":"How would you design a database architecture to handle 10 million users with 99.99% uptime?","type":"single","options":[{"id":"opt-0","text":"Use horizontal sharding by user ID, multi-region replication with leader-follower setup, and read replicas","isCorrect":true},{"id":"opt-1","text":"Use a single monolithic database with daily backups","isCorrect":false},{"id":"opt-2","text":"Implement vertical scaling only","isCorrect":false},{"id":"opt-3","text":"Use file-based storage with redundancy","isCorrect":false}],"explanation":"Horizontal sharding with multi-region replication distributes load and provides high availability for large-scale systems.","difficulty":"beginner"},{"id":"tq-q-352","questionId":"q-352","question":"How would you design a distributed order processing system using Saga pattern for high-frequency trading?","type":"single","options":[{"id":"opt-0","text":"Implement choreography-based Saga with compensating actions, event sourcing, and idempotent compensators","isCorrect":true},{"id":"opt-1","text":"Use centralized orchestration with simple retries","isCorrect":false},{"id":"opt-2","text":"Implement synchronous processing with locks","isCorrect":false},{"id":"opt-3","text":"Use batch processing without compensation","isCorrect":false}],"explanation":"Choreography-based Saga with event sourcing provides the resilience and state recovery needed for high-frequency trading systems.","difficulty":"advanced"},{"id":"tq-q-396","questionId":"q-396","question":"What's the best approach for building a microservice that needs to expose both REST and GraphQL endpoints for the same data?","type":"single","options":[{"id":"opt-0","text":"Use separate databases for each API type","isCorrect":false},{"id":"opt-1","text":"Implement a shared service layer with separate resolvers/controllers","isCorrect":true},{"id":"opt-2","text":"Create duplicate business logic for each endpoint","isCorrect":false},{"id":"opt-3","text":"Use GraphQL only and convert REST calls to GraphQL queries","isCorrect":false}],"explanation":"A shared service layer with separate resolvers/controllers allows code reuse while handling the specific needs of each API type, including data loaders for GraphQL N+1 problems and REST-specific caching.","difficulty":"intermediate"},{"id":"tq-q-364","questionId":"q-364","question":"How should you handle command failures in a CQRS-based order management system when a command fails but events have already been processed?","type":"single","options":[{"id":"opt-0","text":"Ignore the failure and continue processing","isCorrect":false},{"id":"opt-1","text":"Implement idempotent event handlers and use compensating transactions","isCorrect":true},{"id":"opt-2","text":"Retry the command indefinitely","isCorrect":false},{"id":"opt-3","text":"Manually rollback all database changes","isCorrect":false}],"explanation":"Idempotent event handlers ensure safe reprocessing, while compensating transactions can rollback read model state when command failures occur, maintaining system consistency.","difficulty":"beginner"},{"id":"tq-q-302","questionId":"q-302","question":"What is the fundamental difference between OAuth 2.0 and OpenID Connect (OIDC)?","type":"single","options":[{"id":"opt-0","text":"OIDC is deprecated while OAuth 2.0 is current","isCorrect":false},{"id":"opt-1","text":"OAuth 2.0 handles authentication while OIDC handles authorization","isCorrect":false},{"id":"opt-2","text":"OAuth 2.0 is for authorization, OIDC adds identity layer for authentication","isCorrect":true},{"id":"opt-3","text":"They are identical protocols with different names","isCorrect":false}],"explanation":"OAuth 2.0 focuses solely on authorization (what you can access), while OIDC builds on OAuth 2.0 to add authentication (who you are) through ID tokens.","difficulty":"beginner"},{"id":"tq-q-342","questionId":"q-342","question":"A user reports their OAuth2 access token works but refresh token fails. What should you investigate first?","type":"single","options":[{"id":"opt-0","text":"Check if the user's internet connection is stable","isCorrect":false},{"id":"opt-1","text":"Verify token expiration, scope mismatch, and refresh token revocation","isCorrect":true},{"id":"opt-2","text":"Recreate the entire OAuth2 flow from scratch","isCorrect":false},{"id":"opt-3","text":"Disable refresh tokens and require re-authentication","isCorrect":false}],"explanation":"Token expiration, scope mismatch, and refresh token revocation are the most common causes. Debug by validating token claims, checking client configuration, and reviewing token lifecycle.","difficulty":"intermediate"},{"id":"tq-q-330","questionId":"q-330","question":"How should you handle real-time updates in a collaborative whiteboard app when a user drags a shape?","type":"single","options":[{"id":"opt-0","text":"Update the database directly and broadcast changes","isCorrect":false},{"id":"opt-1","text":"Separate commands (update position) from queries (get data), use command handler to validate and persist","isCorrect":true},{"id":"opt-2","text":"Use WebSockets to bypass the command layer","isCorrect":false},{"id":"opt-3","text":"Implement optimistic locking on the client side only","isCorrect":false}],"explanation":"Separating commands from queries follows CQRS principles. The command handler validates and persists changes, then emits events for UI updates, ensuring consistency and proper validation.","difficulty":"beginner"},{"id":"tq-gh-46","questionId":"gh-46","question":"What components should be included in comprehensive API documentation to ensure smooth developer integration?","type":"single","options":[{"id":"opt-0","text":"Endpoints and schemas only","isCorrect":false},{"id":"opt-1","text":"Authentication, examples, and error handling","isCorrect":false},{"id":"opt-2","text":"Complete documentation including endpoints, schemas, auth, examples, error handling, rate limits, versioning, SDKs, and testing tools","isCorrect":true},{"id":"opt-3","text":"Just basic API reference","isCorrect":false}],"explanation":"Comprehensive API documentation requires all components including endpoints, schemas, authentication, examples, error handling, rate limits, versioning, SDKs, and testing tools to enable seamless integration.","difficulty":"beginner"},{"id":"tq-gh-38","questionId":"gh-38","question":"How would you best define microservices architecture?","type":"single","options":[{"id":"opt-0","text":"A monolithic application structure","isCorrect":false},{"id":"opt-1","text":"A single large service handling all business functions","isCorrect":false},{"id":"opt-2","text":"An architectural style that structures an application as a collection of small autonomous services, modeled around a business domain","isCorrect":true},{"id":"opt-3","text":"A database design pattern","isCorrect":false}],"explanation":"Microservices architecture breaks down applications into small, autonomous services that are organized around specific business domains, allowing for independent development and deployment.","difficulty":"intermediate"},{"id":"tq-q-427","questionId":"q-427","question":"You're building a user profile service that caches frequently accessed profiles. What's the most effective caching strategy to implement?","type":"single","options":[{"id":"opt-0","text":"Implement write-through caching with TTL-based expiration","isCorrect":true},{"id":"opt-1","text":"Use read-through caching with lazy loading","isCorrect":false},{"id":"opt-2","text":"Apply cache-aside pattern with manual invalidation","isCorrect":false},{"id":"opt-3","text":"Deploy write-behind caching with periodic sync","isCorrect":false}],"explanation":"Write-through caching with TTL ensures data consistency by updating both cache and database simultaneously while automatically expiring stale data.","difficulty":"beginner"},{"id":"tq-q-443","questionId":"q-443","question":"You're building a user profile API that caches user data in Redis. What's the best approach for cache invalidation when users update their profiles?","type":"single","options":[{"id":"opt-0","text":"Use cache-aside pattern with explicit invalidation by deleting cache key immediately","isCorrect":true},{"id":"opt-1","text":"Implement write-through caching to update Redis and database simultaneously","isCorrect":false},{"id":"opt-2","text":"Use TTL-based expiration and let cache expire naturally","isCorrect":false},{"id":"opt-3","text":"Apply read-through pattern with lazy loading on next request","isCorrect":false}],"explanation":"Cache-aside with explicit invalidation ensures data consistency by immediately removing stale cache when updates occur.","difficulty":"beginner"},{"id":"tq-q-455","questionId":"q-455","question":"When designing a secure authentication system for microservices with JWT, OAuth2, and session management, what architecture provides optimal security and performance?","type":"single","options":[{"id":"opt-0","text":"Centralized auth service with JWT access tokens (15 min) + refresh tokens (7 days) using Redis for session state","isCorrect":true},{"id":"opt-1","text":"Distributed auth with individual JWT validation in each microservice","isCorrect":false},{"id":"opt-2","text":"OAuth2-only approach with stateless tokens and no session storage","isCorrect":false},{"id":"opt-3","text":"Hybrid system with JWT for API calls and traditional sessions for web interfaces","isCorrect":false}],"explanation":"Centralized auth service balances security with performance by using short-lived access tokens, longer refresh tokens, and Redis for efficient session management.","difficulty":"advanced"},{"id":"tq-q-485","questionId":"q-485","question":"You're designing a distributed database for a fintech platform handling 10M transactions/day. How would you ensure high availability and data consistency across multiple regions?","type":"single","options":[{"id":"opt-0","text":"Implement consistent hashing for sharding across multiple regions with primary-replica replication and synchronous writes","isCorrect":true},{"id":"opt-1","text":"Use a single master database with asynchronous replication to secondary regions","isCorrect":false},{"id":"opt-2","text":"Deploy separate databases per region with eventual consistency and conflict resolution","isCorrect":false},{"id":"opt-3","text":"Implement a blockchain-based distributed ledger with consensus mechanisms","isCorrect":false}],"explanation":"Consistent hashing provides even distribution, primary-replica ensures availability, and synchronous writes maintain consistency for critical financial data.","difficulty":"advanced"},{"id":"tq-q-539","questionId":"q-539","question":"What is dependency injection in Spring and how does it benefit application design?","type":"single","options":[{"id":"opt-0","text":"A design pattern where Spring container injects dependencies into objects, promoting loose coupling and easier testing","isCorrect":true},{"id":"opt-1","text":"A process where objects create their own dependencies manually","isCorrect":false},{"id":"opt-2","text":"A technique for caching database queries in Spring applications","isCorrect":false},{"id":"opt-3","text":"A method for handling HTTP requests in Spring controllers","isCorrect":false}],"explanation":"DI is a design pattern where Spring container injects dependencies into objects, promoting loose coupling and easier testing.","difficulty":"intermediate"},{"id":"tq-q-515","questionId":"q-515","question":"When designing a REST API endpoint for processing payments, what is the most appropriate HTTP method and response pattern?","type":"single","options":[{"id":"opt-0","text":"GET /payments with 200 OK and payment details","isCorrect":false},{"id":"opt-1","text":"POST /payments with 201 Created and payment_id in response","isCorrect":true},{"id":"opt-2","text":"PUT /payments with 200 OK and payment confirmation","isCorrect":false},{"id":"opt-3","text":"DELETE /payments with 204 No Content and payment voided","isCorrect":false}],"explanation":"POST is used for creating resources, and 201 Created with the payment_id is the standard REST pattern for successful payment processing.","difficulty":"beginner"}],"passingScore":70,"createdAt":"2025-12-20T20:23:38.692Z","lastUpdated":"2025-12-27T02:23:47.303Z","version":8},{"id":"test-behavioral","channelId":"behavioral","channelName":"Behavioral","title":"Behavioral Knowledge Test","description":"Test your Behavioral knowledge with randomly selected questions.","questions":[{"id":"tq-q-262","questionId":"q-262","question":"How quickly was the hotfix deployed during the critical production outage?","type":"single","options":[{"id":"opt-0","text":"Within 15 minutes","isCorrect":true},{"id":"opt-1","text":"Within 1 hour","isCorrect":false},{"id":"opt-2","text":"Within 4 hours","isCorrect":false},{"id":"opt-3","text":"Within 24 hours","isCorrect":false}],"explanation":"The candidate led incident response and deployed a hotfix within 15 minutes during peak traffic.","difficulty":"advanced"},{"id":"tq-q-212","questionId":"q-212","question":"What was the technical conflict described in the STAR method example?","type":"single","options":[{"id":"opt-0","text":"Frontend wanted nested data while backend preferred flat endpoints","isCorrect":true},{"id":"opt-1","text":"Frontend and backend disagreed on programming language","isCorrect":false},{"id":"opt-2","text":"Database team wanted NoSQL while application team wanted SQL","isCorrect":false},{"id":"opt-3","text":"DevOps and security team disagreed on deployment strategy","isCorrect":false}],"explanation":"The conflict was between frontend wanting nested data and backend preferring flat endpoints.","difficulty":"beginner"},{"id":"tq-q-446","questionId":"q-446","question":"Tell me about a time you had a disagreement with a teammate about how to approach a project. How did you handle it?","type":"single","options":[{"id":"opt-0","text":"I scheduled a 1:1 to understand their perspective and find common ground","isCorrect":true},{"id":"opt-1","text":"I escalated to management immediately","isCorrect":false},{"id":"opt-2","text":"I ignored their concerns and proceeded with my approach","isCorrect":false},{"id":"opt-3","text":"I insisted on using the new framework regardless of their input","isCorrect":false}],"explanation":"The best approach is to communicate directly with the teammate to understand their viewpoint and work toward a mutually agreeable solution.","difficulty":"beginner"},{"id":"tq-q-486","questionId":"q-486","question":"What is the most effective approach for mediating a technical conflict between senior engineers?","type":"single","options":[{"id":"opt-0","text":"Let the engineers debate until they reach consensus","isCorrect":false},{"id":"opt-1","text":"Facilitate a structured discussion where each presents pros/cons","isCorrect":true},{"id":"opt-2","text":"Choose the solution with the most senior backing","isCorrect":false},{"id":"opt-3","text":"Implement both solutions and test which performs better","isCorrect":false}],"explanation":"A structured debate allows both engineers to present their approaches objectively, helping identify shared goals and find a hybrid solution.","difficulty":"advanced"},{"id":"tq-q-516","questionId":"q-516","question":"How would you handle a critical production incident affecting 30% of users when you have incomplete data?","type":"single","options":[{"id":"opt-0","text":"Make a data-driven decision and temporarily rollback the problematic feature","isCorrect":true},{"id":"opt-1","text":"Wait for complete data before taking any action","isCorrect":false},{"id":"opt-2","text":"Escalate to senior management immediately","isCorrect":false},{"id":"opt-3","text":"Deploy a hotfix without testing","isCorrect":false}],"explanation":"Making a data-driven rollback decision balances risk mitigation with user protection when facing incomplete information.","difficulty":"intermediate"}],"passingScore":70,"createdAt":"2025-12-23T20:25:57.579Z","lastUpdated":"2025-12-27T02:20:28.873Z","version":3},{"id":"test-database","channelId":"database","channelName":"Database","title":"Database Knowledge Test","description":"Test your Database knowledge.","questions":[{"id":"tq-q-268","questionId":"q-268","question":"How would you optimize a time-series analytics query that scans 100M+ rows across multiple date partitions?","type":"single","options":[{"id":"opt-0","text":"Use composite partitioning, materialized views, and columnar storage with query plan hints","isCorrect":true},{"id":"opt-1","text":"Add more indexes to all columns","isCorrect":false},{"id":"opt-2","text":"Use simple SELECT * without optimization","isCorrect":false},{"id":"opt-3","text":"Increase memory allocation only","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-db-2","questionId":"db-2","question":"How do ACID properties ensure data integrity in a banking transaction where $100 is transferred?","type":"single","options":[{"id":"opt-0","text":"Atomicity ensures all-or-nothing execution, Consistency maintains valid states, Isolation prevents interference, Durability guarantees persistence","isCorrect":true},{"id":"opt-1","text":"Only Atomicity matters for transactions","isCorrect":false},{"id":"opt-2","text":"ACID properties are optional for banking","isCorrect":false},{"id":"opt-3","text":"Only Consistency and Durability are required","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-170","questionId":"q-170","question":"When would you choose a composite index over multiple single-column indexes in a relational database?","type":"single","options":[{"id":"opt-0","text":"For queries filtering on multiple columns together, composite indexes are more efficient than separate single-column indexes","isCorrect":true},{"id":"opt-1","text":"Never use composite indexes","isCorrect":false},{"id":"opt-2","text":"Only for single column queries","isCorrect":false},{"id":"opt-3","text":"Composite indexes are always slower","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-190","questionId":"q-190","question":"What is the difference between READ COMMITTED and REPEATABLE READ isolation levels in database transactions?","type":"single","options":[{"id":"opt-0","text":"READ COMMITTED sees only committed data, while REPEATABLE READ guarantees consistent reads within a transaction","isCorrect":true},{"id":"opt-1","text":"Both isolation levels are identical","isCorrect":false},{"id":"opt-2","text":"READ COMMITTED allows dirty reads","isCorrect":false},{"id":"opt-3","text":"REPEATABLE READ sees uncommitted data","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-da-156","questionId":"da-156","question":"What is the difference between DELETE and TRUNCATE commands in SQL?","type":"single","options":[{"id":"opt-0","text":"DELETE removes rows one by one and can use WHERE; TRUNCATE removes all rows at once, faster but can't be filtered","isCorrect":true},{"id":"opt-1","text":"DELETE and TRUNCATE are identical commands","isCorrect":false},{"id":"opt-2","text":"DELETE is faster than TRUNCATE","isCorrect":false},{"id":"opt-3","text":"TRUNCATE can use WHERE conditions","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-da-134","questionId":"da-134","question":"What is the main difference between B-tree and hash index in terms of range query performance?","type":"single","options":[{"id":"opt-0","text":"B-trees support efficient range queries with sorted data; hash indexes only support equality lookups and cannot scan ranges efficiently","isCorrect":true},{"id":"opt-1","text":"Hash indexes support efficient range queries with sorted data; B-trees only support equality lookups and cannot scan ranges efficiently","isCorrect":false},{"id":"opt-2","text":"Both B-trees and hash indexes support range queries equally well","isCorrect":false},{"id":"opt-3","text":"Neither B-trees nor hash indexes support range queries efficiently","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-288","questionId":"q-288","question":"How do you handle Database Sharding? What are the downsides?","type":"single","options":[{"id":"opt-0","text":"Sharding splits a large database into smaller, faster, easily managed parts called data shards","isCorrect":true},{"id":"opt-1","text":"Sharding combines multiple small databases into one large database","isCorrect":false},{"id":"opt-2","text":"Sharding encrypts database data for security purposes","isCorrect":false},{"id":"opt-3","text":"Sharding creates backup copies of the database","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-da-128","questionId":"da-128","question":"How does MongoDB's document structure differ from SQL's table rows for storing user data?","type":"single","options":[{"id":"opt-0","text":"MongoDB stores flexible JSON-like documents with varying schemas, while SQL uses fixed table rows with predefined columns","isCorrect":true},{"id":"opt-1","text":"SQL stores flexible JSON-like documents with varying schemas, while MongoDB uses fixed table rows with predefined columns","isCorrect":false},{"id":"opt-2","text":"Both MongoDB and SQL use the same fixed schema structure","isCorrect":false},{"id":"opt-3","text":"Both MongoDB and SQL use the same flexible document structure","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-sd-4","questionId":"sd-4","question":"You have a banking system where Account A transfers $100 to Account B, but during the transaction, A's account is deleted. What should you use to prevent this issue?","type":"single","options":[{"id":"opt-0","text":"Use SELECT FOR UPDATE or SERIALIZABLE isolation to prevent phantom reads and ensure referential integrity","isCorrect":true},{"id":"opt-1","text":"Use simple SELECT statements without locking","isCorrect":false},{"id":"opt-2","text":"Use NOLOCK hints for better performance","isCorrect":false},{"id":"opt-3","text":"Use READ UNCOMMITTED isolation level","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-242","questionId":"q-242","question":"You have a banking system where users can transfer money between accounts. What is the best approach to design a transaction?","type":"single","options":[{"id":"opt-0","text":"Use database transactions with ACID properties. Wrap both operations in a single transaction that either commits both or rolls back both","isCorrect":true},{"id":"opt-1","text":"Execute each operation separately without transactions","isCorrect":false},{"id":"opt-2","text":"Use optimistic locking without explicit transactions","isCorrect":false},{"id":"opt-3","text":"Use stored procedures only for the debit operation","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-da-145","questionId":"da-145","question":"You have a table `orders` with columns (id, user_id, amount, created_at) and need to find users who...","type":"single","options":[{"id":"opt-0","text":"Use window functions with ROW_NUMBER() to find first purchases, COUNT() for total orders, and subqueries for average comparisons with proper indexing","isCorrect":true},{"id":"opt-1","text":"Use simple GROUP BY with HAVING clause to filter users based on order amounts","isCorrect":false},{"id":"opt-2","text":"Create temporary tables to store intermediate results before joining","isCorrect":false},{"id":"opt-3","text":"Use nested cursors to process each user's orders individually","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-397","questionId":"q-397","question":"In a high-transaction payment system using PostgreSQL, what transaction isolation strategy would you implement to prevent lost updates while maintaining concurrency?","type":"single","options":[{"id":"opt-0","text":"Use SERIALIZABLE isolation with explicit row-level locking and retry logic","isCorrect":true},{"id":"opt-1","text":"Use READ COMMITTED isolation with optimistic locking","isCorrect":false},{"id":"opt-2","text":"Use REPEATABLE READ isolation without additional locking","isCorrect":false},{"id":"opt-3","text":"Use NO isolation for maximum performance","isCorrect":false}],"explanation":"SERIALIZABLE isolation with row-level locking prevents lost updates while retry logic handles serialization failures, maintaining both data integrity and concurrency.","difficulty":"advanced"},{"id":"tq-q-288","questionId":"q-288","question":"What is the main difference between B-tree and hash index performance characteristics for range queries?","type":"single","options":[{"id":"opt-0","text":"B-trees support efficient range queries with sorted data; hash indexes only support equality lookups","isCorrect":true},{"id":"opt-1","text":"Hash indexes are better for range queries due to faster key distribution","isCorrect":false},{"id":"opt-2","text":"B-trees are only suitable for equality lookups while hash indexes excel at ranges","isCorrect":false},{"id":"opt-3","text":"Both index types perform equally well for range queries","isCorrect":false}],"explanation":"B-trees maintain sorted data structure enabling efficient range scans, while hash indexes provide only O(1) equality lookups without ordered traversal capability.","difficulty":"beginner"},{"id":"tq-da-170","questionId":"da-170","question":"How would you design a banking system to ensure atomic money transfers between accounts?","type":"single","options":[{"id":"opt-0","text":"Use ACID transactions with BEGIN, UPDATE accounts, COMMIT/ROLLBACK","isCorrect":true},{"id":"opt-1","text":"Implement separate debit and credit operations with eventual consistency","isCorrect":false},{"id":"opt-2","text":"Use message queues for asynchronous transfer processing","isCorrect":false},{"id":"opt-3","text":"Apply optimistic concurrency control without explicit transactions","isCorrect":false}],"explanation":"ACID transactions ensure atomicity by debiting source and crediting destination in single transaction, with COMMIT/ROLLBACK guaranteeing all-or-nothing execution.","difficulty":"intermediate"},{"id":"tq-db-2","questionId":"db-2","question":"How do ACID properties specifically protect a $100 banking transfer from account A to account B?","type":"single","options":[{"id":"opt-0","text":"Atomicity ensures all-or-nothing execution, Consistency maintains valid states, Isolation prevents interference, Durability guarantees persistence","isCorrect":true},{"id":"opt-1","text":"ACID only provides backup and recovery capabilities","isCorrect":false},{"id":"opt-2","text":"ACID properties mainly improve query performance","isCorrect":false},{"id":"opt-3","text":"ACID is primarily for data compression and storage optimization","isCorrect":false}],"explanation":"ACID properties work together: Atomicity prevents partial transfers, Consistency maintains valid balances, Isolation prevents concurrent interference, and Durability ensures the transfer persists.","difficulty":"intermediate"},{"id":"tq-db-1","questionId":"db-1","question":"What is the fundamental difference between Clustered and Non-Clustered Indexes?","type":"single","options":[{"id":"opt-0","text":"Clustered Index determines physical data order (1 per table). Non-Clustered is separate lookup structure (many per table)","isCorrect":true},{"id":"opt-1","text":"Clustered indexes are faster for writes, non-clustered for reads","isCorrect":false},{"id":"opt-2","text":"Clustered indexes store only pointers, non-clustered store actual data","isCorrect":false},{"id":"opt-3","text":"Both index types are identical in structure and performance","isCorrect":false}],"explanation":"Clustered indexes reorder physical data storage (limited to 1 per table), while non-clustered indexes create separate lookup structures allowing multiple indexes per table.","difficulty":"beginner"},{"id":"tq-q-365","questionId":"q-365","question":"How would you optimize a real-time Discord analytics system processing millions of message events?","type":"single","options":[{"id":"opt-0","text":"Use declarative partitioning by time with BRIN indexes for timestamp ranges and B-tree indexes on user_id","isCorrect":true},{"id":"opt-1","text":"Create a single massive table with hash indexes on all columns","isCorrect":false},{"id":"opt-2","text":"Use NoSQL document storage without indexing","isCorrect":false},{"id":"opt-3","text":"Implement in-memory processing without database persistence","isCorrect":false}],"explanation":"Time-based partitioning with BRIN indexes efficiently handles timestamp ranges, while B-tree indexes on user_id enable fast user-specific queries in high-volume message processing.","difficulty":"advanced"},{"id":"tq-q-190","questionId":"q-190","question":"What distinguishes READ COMMITTED from REPEATABLE READ isolation levels?","type":"single","options":[{"id":"opt-0","text":"READ COMMITTED sees only committed data, while REPEATABLE READ guarantees consistent reads within a transaction","isCorrect":true},{"id":"opt-1","text":"READ COMMITTED allows dirty reads, REPEATABLE READ prevents them","isCorrect":false},{"id":"opt-2","text":"READ COMMITTED is always faster than REPEATABLE READ","isCorrect":false},{"id":"opt-3","text":"Both isolation levels provide identical consistency guarantees","isCorrect":false}],"explanation":"READ COMMITTED returns latest committed data per query, while REPEATABLE READ maintains a consistent snapshot throughout the entire transaction, preventing non-repeatable reads.","difficulty":"beginner"},{"id":"tq-q-268","questionId":"q-268","question":"How would you optimize a time-series analytics query scanning 100M+ rows across multiple date partitions?","type":"single","options":[{"id":"opt-0","text":"Implement composite partitioning by date + user_id with BRIN indexes, create materialized views for common aggregations, use columnar storage","isCorrect":true},{"id":"opt-1","text":"Use a single unpartitioned table with hash indexes","isCorrect":false},{"id":"opt-2","text":"Apply full-text search indexes for time-series data","isCorrect":false},{"id":"opt-3","text":"Implement in-memory caching without database optimization","isCorrect":false}],"explanation":"Composite partitioning reduces scan scope, BRIN indexes efficiently handle range queries, materialized views pre-compute aggregations, and columnar storage minimizes I/O for analytical workloads.","difficulty":"advanced"},{"id":"tq-da-129","questionId":"da-129","question":"What is the primary structural difference between SQL and NoSQL databases?","type":"single","options":[{"id":"opt-0","text":"SQL uses structured tables with fixed schemas, NoSQL uses flexible document/key-value/graph structures without fixed schemas","isCorrect":true},{"id":"opt-1","text":"SQL databases are always faster than NoSQL","isCorrect":false},{"id":"opt-2","text":"NoSQL databases cannot handle relationships between data","isCorrect":false},{"id":"opt-3","text":"SQL databases only support text data while NoSQL supports multimedia","isCorrect":false}],"explanation":"SQL databases enforce rigid table schemas with predefined columns and types, while NoSQL databases offer flexible schemas allowing varied document structures, key-value pairs, or graph relationships.","difficulty":"beginner"},{"id":"tq-da-134","questionId":"da-134","question":"What happens in a banking transfer when Account A sends $100 to Account B, but Account B is deleted during the transaction?","type":"single","options":[{"id":"opt-0","text":"Money disappears into deleted account. Use SELECT FOR UPDATE or SERIALIZABLE isolation to prevent phantom reads","isCorrect":true},{"id":"opt-1","text":"Transfer completes successfully with money appearing in void space","isCorrect":false},{"id":"opt-2","text":"System automatically rolls back the entire transfer","isCorrect":false},{"id":"opt-3","text":"Money is returned to Account A after timeout period","isCorrect":false}],"explanation":"Without proper isolation, money can be lost to deleted accounts. SELECT FOR UPDATE or SERIALIZABLE isolation prevents phantom reads and ensures referential integrity throughout the transaction.","difficulty":"advanced"},{"id":"tq-sd-4","questionId":"sd-4","question":"What's the best sharding strategy for a social media platform with 100M+ users?","type":"single","options":[{"id":"opt-0","text":"Range-based sharding on user_id with consistent hashing for hot data","isCorrect":true},{"id":"opt-1","text":"Hash-based sharding on all columns evenly","isCorrect":false},{"id":"opt-2","text":"Random sharding across all tables","isCorrect":false},{"id":"opt-3","text":"No sharding needed for 100M users","isCorrect":false}],"explanation":"Range-based sharding on user_id handles write patterns well, while consistent hashing manages hot data distribution effectively.","difficulty":"advanced"},{"id":"tq-q-170","questionId":"q-170","question":"When are composite indexes more efficient than multiple single-column indexes?","type":"single","options":[{"id":"opt-0","text":"For queries filtering on multiple columns together","isCorrect":true},{"id":"opt-1","text":"For single column queries only","isCorrect":false},{"id":"opt-2","text":"For all database operations","isCorrect":false},{"id":"opt-3","text":"Never use composite indexes","isCorrect":false}],"explanation":"Composite indexes are optimized for queries that filter on multiple columns simultaneously, providing better performance than separate single-column indexes.","difficulty":"intermediate"},{"id":"tq-da-125","questionId":"da-125","question":"What is the primary trade-off of using database indexes?","type":"single","options":[{"id":"opt-0","text":"Faster queries at the cost of slower writes","isCorrect":true},{"id":"opt-1","text":"Slower queries but faster writes","isCorrect":false},{"id":"opt-2","text":"No impact on performance","isCorrect":false},{"id":"opt-3","text":"Only affects storage space","isCorrect":false}],"explanation":"Indexes improve query speed by maintaining sorted references, but they increase write overhead as indexes must be updated when data changes.","difficulty":"intermediate"},{"id":"tq-q-353","questionId":"q-353","question":"How should you handle concurrent editing in a collaborative design tool?","type":"single","options":[{"id":"opt-0","text":"MVCC with READ COMMITTED isolation and optimistic locking","isCorrect":true},{"id":"opt-1","text":"Pessimistic locking for all operations","isCorrect":false},{"id":"opt-2","text":"No concurrency control needed","isCorrect":false},{"id":"opt-3","text":"Only allow one user at a time","isCorrect":false}],"explanation":"MVCC with READ COMMITTED isolation allows concurrent reads, while optimistic locking with version columns handles write conflicts efficiently.","difficulty":"beginner"},{"id":"tq-da-156","questionId":"da-156","question":"What's the key difference between DELETE and TRUNCATE in SQL?","type":"single","options":[{"id":"opt-0","text":"DELETE removes rows individually with WHERE support; TRUNCATE removes all rows at once without filtering","isCorrect":true},{"id":"opt-1","text":"DELETE is faster; TRUNCATE is slower","isCorrect":false},{"id":"opt-2","text":"DELETE can't use WHERE; TRUNCATE can","isCorrect":false},{"id":"opt-3","text":"No difference in functionality","isCorrect":false}],"explanation":"DELETE removes rows one by one and supports WHERE clauses, while TRUNCATE removes all rows simultaneously but cannot be filtered.","difficulty":"beginner"},{"id":"tq-q-458","questionId":"q-458","question":"You have a PostgreSQL database with orders (10M rows) and customers (1M rows). A query joining these tables is performing poorly. What's the best optimization approach?","type":"single","options":[{"id":"opt-0","text":"Add indexes on foreign keys (customer_id), use EXPLAIN ANALYZE to identify bottlenecks, consider denormalization for frequently accessed data","isCorrect":true},{"id":"opt-1","text":"Increase the database memory allocation and disable all indexes for faster full table scans","isCorrect":false},{"id":"opt-2","text":"Convert the tables to NoSQL document storage to eliminate the need for joins","isCorrect":false},{"id":"opt-3","text":"Create materialized views for all possible query combinations and update them hourly","isCorrect":false}],"explanation":"Proper indexing on join columns and analyzing query execution plans are fundamental optimization techniques for large PostgreSQL tables.","difficulty":"intermediate"},{"id":"tq-q-331","questionId":"q-331","question":"You're designing a multi-region e-commerce platform using DynamoDB. Your product catalog needs to support high read throughput with occasional hot items. What's the optimal strategy?","type":"single","options":[{"id":"opt-0","text":"Use composite partition keys with sharding (product_id#hash) and adaptive capacity for hot items, trading some read latency for write scalability","isCorrect":true},{"id":"opt-1","text":"Use a single partition key based on product category to ensure even distribution across all regions","isCorrect":false},{"id":"opt-2","text":"Implement strong consistency reads for all operations to guarantee data freshness","isCorrect":false},{"id":"opt-3","text":"Use global secondary indexes for all queries to avoid hot partition issues","isCorrect":false}],"explanation":"Composite partition keys with sharding help distribute load evenly, while adaptive capacity handles temporary hot items in DynamoDB.","difficulty":"advanced"},{"id":"tq-da-145","questionId":"da-145","question":"You have a table `orders` with columns (id, user_id, amount, created_at) and need to find users who made their first purchase recently and calculate their average order value. Which SQL approach is most efficient?","type":"single","options":[{"id":"opt-0","text":"Use window functions with ROW_NUMBER() to find first purchases, COUNT() for total orders, and subqueries for average comparisons with proper indexing","isCorrect":true},{"id":"opt-1","text":"Create temporary tables for each calculation step and join them at the end","isCorrect":false},{"id":"opt-2","text":"Use multiple separate queries and combine results in application code","isCorrect":false},{"id":"opt-3","text":"Implement cursor-based processing to handle each user sequentially","isCorrect":false}],"explanation":"Window functions provide the most efficient way to perform complex analytical operations like finding first purchases in a single query.","difficulty":"advanced"},{"id":"tq-q-317","questionId":"q-317","question":"Explain how MVCC (Multi-Version Concurrency Control) works and how it prevents lost updates in a database system.","type":"single","options":[{"id":"opt-0","text":"MVCC creates multiple versions of data rows, allowing reads to proceed without blocking writes and preventing lost updates through version comparison","isCorrect":true},{"id":"opt-1","text":"MVCC uses table-level locks to serialize all transactions and prevent concurrent access","isCorrect":false},{"id":"opt-2","text":"MVCC implements a two-phase commit protocol to ensure all transactions complete successfully","isCorrect":false},{"id":"opt-3","text":"MVCC stores transaction logs and uses them to replay conflicting operations in the correct order","isCorrect":false}],"explanation":"MVCC's versioning approach allows concurrent reads and writes while maintaining data consistency through version comparison.","difficulty":"intermediate"},{"id":"tq-q-519","questionId":"q-519","question":"You're designing a high-frequency trading system where transactions must see consistent data snapshots. What's the best implementation approach?","type":"single","options":[{"id":"opt-0","text":"Implement MVCC with tuple versioning using transaction IDs and visibility rules. Choose REPEATABLE READ or SERIALIZABLE isolation. Use snapshot timestamps","isCorrect":true},{"id":"opt-1","text":"Use pessimistic locking with table-level locks for all transactions to ensure complete data consistency","isCorrect":false},{"id":"opt-2","text":"Implement eventual consistency with conflict resolution through application-level logic","isCorrect":false},{"id":"opt-3","text":"Use read committed isolation level with manual version checking in application code","isCorrect":false}],"explanation":"MVCC with appropriate isolation levels provides the consistency needed for high-frequency trading while maintaining performance.","difficulty":"advanced"},{"id":"tq-q-428","questionId":"q-428","question":"You're building a booking system for Airbnb where multiple users can reserve the same property simultaneously. Which concurrency control approach is most appropriate?","type":"single","options":[{"id":"opt-0","text":"Use SERIALIZABLE isolation with optimistic concurrency control. Implement row-level locks on property availability tables, use MVCC snapshot reads for consistency","isCorrect":true},{"id":"opt-1","text":"Use READ COMMITTED isolation with application-level checks for double bookings","isCorrect":false},{"id":"opt-2","text":"Implement queue-based processing where all booking requests are handled sequentially","isCorrect":false},{"id":"opt-3","text":"Use distributed locks with a separate coordination service for all booking operations","isCorrect":false}],"explanation":"SERIALIZABLE isolation with optimistic concurrency provides the strongest consistency guarantees for booking systems while maintaining good performance.","difficulty":"intermediate"},{"id":"tq-q-409","questionId":"q-409","question":"You're designing a database for an e-commerce platform with frequent queries on (user_id, order_date) and (product_id, category). What's the optimal indexing strategy?","type":"single","options":[{"id":"opt-0","text":"Use B-tree composite indexes: (user_id, order_date) for range queries and (product_id, category) for exact matches. Hash indexes only support equality","isCorrect":true},{"id":"opt-1","text":"Create separate single-column indexes on each column for maximum flexibility","isCorrect":false},{"id":"opt-2","text":"Use hash indexes for all queries since they provide faster lookups than B-tree indexes","isCorrect":false},{"id":"opt-3","text":"Implement full-text search indexes to handle all query types including range queries","isCorrect":false}],"explanation":"B-tree composite indexes are optimal for the mixed query patterns described, providing efficient range queries and exact matches.","difficulty":"intermediate"},{"id":"tq-da-128","questionId":"da-128","question":"You have a banking system where users can transfer money between accounts. Design a transaction to handle a transfer from account A to account B. What's the correct approach?","type":"single","options":[{"id":"opt-0","text":"Use database transactions with ACID properties. Wrap both operations in a single transaction that either commits both or rolls back both","isCorrect":true},{"id":"opt-1","text":"Execute the debit operation first, then the credit operation separately with application-level compensation if the credit fails","isCorrect":false},{"id":"opt-2","text":"Use stored procedures with manual error handling and compensation logic","isCorrect":false},{"id":"opt-3","text":"Implement eventual consistency where transfers are processed asynchronously with reconciliation","isCorrect":false}],"explanation":"ACID transactions ensure that money transfers are atomic - both the debit and credit must complete successfully or neither does.","difficulty":"intermediate"},{"id":"tq-q-242","questionId":"q-242","question":"How does MongoDB's document structure differ from SQL's table rows for storing user data?","type":"single","options":[{"id":"opt-0","text":"MongoDB stores flexible JSON-like documents with varying schemas, while SQL uses fixed table rows with predefined columns","isCorrect":true},{"id":"opt-1","text":"MongoDB uses relational tables with foreign keys, while SQL stores everything in a single collection","isCorrect":false},{"id":"opt-2","text":"MongoDB requires strict schema validation, while SQL allows dynamic column addition","isCorrect":false},{"id":"opt-3","text":"MongoDB stores data in columnar format, while SQL uses row-based storage","isCorrect":false}],"explanation":"MongoDB's document model provides schema flexibility, unlike SQL's rigid table structure with predefined columns.","difficulty":"beginner"},{"id":"tq-q-380","questionId":"q-380","question":"You're optimizing a query that's slow due to a large time-series table. The query filters by timestamp and device_id. What's the best optimization strategy?","type":"single","options":[{"id":"opt-0","text":"Analyze the EXPLAIN plan to identify full table scans, then implement timestamp-based partitioning with a composite index on (timestamp, device_id)","isCorrect":true},{"id":"opt-1","text":"Create separate indexes on timestamp and device_id columns individually for maximum flexibility","isCorrect":false},{"id":"opt-2","text":"Convert the table to a columnar storage format and use bitmap indexes for all queries","isCorrect":false},{"id":"opt-3","text":"Implement query caching and increase the database buffer pool size","isCorrect":false}],"explanation":"Partitioning combined with a properly ordered composite index addresses both the data volume and query pattern for time-series data.","difficulty":"intermediate"},{"id":"tq-q-489","questionId":"q-489","question":"You're designing a database for LinkedIn's feed system. Posts can be queried by user_id, created_at, and engagement_score. What's the optimal indexing strategy?","type":"single","options":[{"id":"opt-0","text":"Composite B-tree index on (user_id, created_at DESC) with separate index on engagement_score","isCorrect":true},{"id":"opt-1","text":"Single index on user_id only","isCorrect":false},{"id":"opt-2","text":"Hash index on all three columns","isCorrect":false},{"id":"opt-3","text":"No indexes needed for feed queries","isCorrect":false}],"explanation":"Composite B-tree index supports primary feed queries efficiently, while separate engagement_score index handles trending posts.","difficulty":"advanced"},{"id":"tq-da-172","questionId":"da-172","question":"In a distributed database system, how would you implement a two-phase commit protocol to ensure atomicity across multiple nodes?","type":"single","options":[{"id":"opt-0","text":"Use coordinator with prepare/commit phases, handle node failures with recovery protocols","isCorrect":true},{"id":"opt-1","text":"Commit immediately on all nodes without coordination","isCorrect":false},{"id":"opt-2","text":"Use eventual consistency model instead","isCorrect":false},{"id":"opt-3","text":"Only commit on the primary node","isCorrect":false}],"explanation":"Two-phase commit uses coordinator to ensure all nodes either commit or rollback together, with recovery mechanisms for failures.","difficulty":"advanced"},{"id":"tq-q-303","questionId":"q-303","question":"How would you optimize a slow PostgreSQL query that joins 5 tables with millions of rows? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"Add appropriate indexes on foreign keys and join columns","isCorrect":true},{"id":"opt-1","text":"Use EXPLAIN ANALYZE to identify bottlenecks","isCorrect":true},{"id":"opt-2","text":"Consider query rewriting","isCorrect":true},{"id":"opt-3","text":"Remove all indexes to improve performance","isCorrect":false}],"explanation":"Proper indexing, query analysis, and rewriting are key optimization strategies. Removing indexes would worsen performance.","difficulty":"advanced"},{"id":"tq-q-420","questionId":"q-420","question":"You're designing a user database for a chat application with 10M users. When would you choose a B-tree index over a hash index for email lookups?","type":"single","options":[{"id":"opt-0","text":"When you need range queries and prefix searches","isCorrect":true},{"id":"opt-1","text":"When you only need exact equality matches","isCorrect":false},{"id":"opt-2","text":"When storage space is the primary concern","isCorrect":false},{"id":"opt-3","text":"Never - hash indexes are always better","isCorrect":false}],"explanation":"B-tree indexes support range queries, ORDER BY, and prefix searches like 'user%@domain.com', while hash indexes only handle exact equality.","difficulty":"beginner"},{"id":"tq-q-436","questionId":"q-436","question":"You have a 100M row orders table with slow queries. The query plan shows sequential scans despite having indexes. What should you investigate? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"Index usage with EXPLAIN ANALYZE","isCorrect":true},{"id":"opt-1","text":"Partitioning by date ranges or customer_id","isCorrect":true},{"id":"opt-2","text":"Composite indexes for common query patterns","isCorrect":true},{"id":"opt-3","text":"Increasing table size to improve performance","isCorrect":false}],"explanation":"Check why indexes aren't being used, consider partitioning for large tables, and create composite indexes for multi-column queries.","difficulty":"advanced"}],"passingScore":70,"createdAt":"2025-12-18T10:05:10.586Z","lastUpdated":"2025-12-27T02:23:46.778Z","version":3},{"id":"test-devops","channelId":"devops","channelName":"DevOps","title":"DevOps Knowledge Test","description":"Test your DevOps knowledge.","questions":[{"id":"tq-gh-68","questionId":"gh-68","question":"What security practices should be integrated into DevOps pipelines?","type":"single","options":[{"id":"opt-0","text":"Automated security testing, network segmentation, and continuous monitoring","isCorrect":true},{"id":"opt-1","text":"Manual security reviews and quarterly audits","isCorrect":false},{"id":"opt-2","text":"Basic firewall configuration only","isCorrect":false},{"id":"opt-3","text":"Security testing after deployment only","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-171","questionId":"q-171","question":"How would you debug a Docker container that keeps crashing and restarting?","type":"single","options":[{"id":"opt-0","text":"Restart the entire Docker daemon","isCorrect":false},{"id":"opt-1","text":"Use docker logs, inspect, exec, and check resource limits","isCorrect":true},{"id":"opt-2","text":"Delete and recreate the container immediately","isCorrect":false},{"id":"opt-3","text":"Ignore the issue as it will resolve itself","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-6","questionId":"gh-6","question":"What is a Dockerfile and how does it enable containerized application deployment?","type":"single","options":[{"id":"opt-0","text":"A runtime configuration file for running containers","isCorrect":false},{"id":"opt-1","text":"A text file containing instructions to build Docker images, defining environment and dependencies","isCorrect":true},{"id":"opt-2","text":"A database schema file for container data","isCorrect":false},{"id":"opt-3","text":"A network configuration file for container communication","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-77","questionId":"gh-77","question":"What are common monitoring tools used in DevOps?","type":"single","options":[{"id":"opt-0","text":"Text editors and IDEs only","isCorrect":false},{"id":"opt-1","text":"Version control systems like Git","isCorrect":false},{"id":"opt-2","text":"Prometheus, Grafana, Nagios, and Datadog","isCorrect":true},{"id":"opt-3","text":"Container runtime tools","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-75","questionId":"gh-75","question":"What DevOps practices are essential for implementing continuous delivery and fostering team collaboration?","type":"single","options":[{"id":"opt-0","text":"CI/CD pipelines, Infrastructure as Code, automated testing, monitoring/logging, microservices, and DevSecOps","isCorrect":true},{"id":"opt-1","text":"Manual deployment processes, waterfall methodology, isolated teams","isCorrect":false},{"id":"opt-2","text":"Traditional IT operations, manual configuration, siloed development","isCorrect":false},{"id":"opt-3","text":"Agile development only, manual testing, monolithic architecture","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-74","questionId":"gh-74","question":"How does DevOps culture transform traditional siloed development and operations into collaborative workflows?","type":"single","options":[{"id":"opt-0","text":"Breaks down silos through shared responsibility, automation, and continuous feedback loops","isCorrect":true},{"id":"opt-1","text":"Maintains strict separation between dev and ops teams","isCorrect":false},{"id":"opt-2","text":"Uses waterfall methodology with clear handoffs","isCorrect":false},{"id":"opt-3","text":"Implements manual processes with minimal automation","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-3","questionId":"gh-3","question":"What is Continuous Integration and how does it improve software development quality?","type":"single","options":[{"id":"opt-0","text":"Automates building and testing code changes frequently to catch bugs early","isCorrect":true},{"id":"opt-1","text":"Manually tests code after long development cycles","isCorrect":false},{"id":"opt-2","text":"Deploys code directly to production without testing","isCorrect":false},{"id":"opt-3","text":"Only works for solo developers, not teams","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-do-2","questionId":"do-2","question":"What are the key differences between Blue/Green and Canary deployment strategies?","type":"single","options":[{"id":"opt-0","text":"Blue/Green enables instant switching between environments, while Canary gradually shifts traffic","isCorrect":true},{"id":"opt-1","text":"Both strategies are identical in practice","isCorrect":false},{"id":"opt-2","text":"Canary enables instant switching while Blue/Green gradually shifts traffic","isCorrect":false},{"id":"opt-3","text":"Neither strategy supports traffic management","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-16","questionId":"gh-16","question":"What is Infrastructure as Code and why has it become essential for modern DevOps practices?","type":"single","options":[{"id":"opt-0","text":"Manages and provisions infrastructure through version-controlled definition files","isCorrect":true},{"id":"opt-1","text":"Uses manual configuration through GUI interfaces","isCorrect":false},{"id":"opt-2","text":"Requires physical hardware setup for each deployment","isCorrect":false},{"id":"opt-3","text":"Only works with cloud providers, not on-premises systems","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-1","questionId":"gh-1","question":"What are the core principles and practices of DevOps?","type":"single","options":[{"id":"opt-0","text":"Automation and continuous integration/delivery","isCorrect":true},{"id":"opt-1","text":"Separate development and operations teams","isCorrect":false},{"id":"opt-2","text":"Manual deployment processes","isCorrect":false},{"id":"opt-3","text":"Siloed responsibility for software lifecycle","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-243","questionId":"q-243","question":"How would you implement zero-downtime deployment using blue-green strategy with Ansible?","type":"single","options":[{"id":"opt-0","text":"Use rolling updates with health checks and traffic switching","isCorrect":true},{"id":"opt-1","text":"Deploy all changes at once without checks","isCorrect":false},{"id":"opt-2","text":"Use manual rollback procedures","isCorrect":false},{"id":"opt-3","text":"Skip health checks for faster deployment","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-de-136","questionId":"de-136","question":"What happens in a GitOps workflow when code is pushed to a separate config repository?","type":"single","options":[{"id":"opt-0","text":"CI builds image, updates config repo, ArgoCD deploys based on config changes","isCorrect":true},{"id":"opt-1","text":"Code is directly deployed to production","isCorrect":false},{"id":"opt-2","text":"Config repository is ignored","isCorrect":false},{"id":"opt-3","text":"Manual deployment is required","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-29","questionId":"gh-29","question":"What is Configuration Management?","type":"single","options":[{"id":"opt-0","text":"Process of maintaining systems in a desired state","isCorrect":true},{"id":"opt-1","text":"Method for manual system updates","isCorrect":false},{"id":"opt-2","text":"Technique for ignoring system states","isCorrect":false},{"id":"opt-3","text":"Approach for random system changes","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-30","questionId":"gh-30","question":"What is Puppet and how does it manage infrastructure configuration?","type":"single","options":[{"id":"opt-0","text":"A declarative configuration management tool that automates infrastructure provisioning","isCorrect":true},{"id":"opt-1","text":"An agentless automation tool using SSH","isCorrect":false},{"id":"opt-2","text":"A GitOps continuous delivery tool for Kubernetes","isCorrect":false},{"id":"opt-3","text":"A container orchestration platform","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-36","questionId":"gh-36","question":"How do different backup strategies balance storage efficiency, backup speed, and recovery time?","type":"single","options":[{"id":"opt-0","text":"Full backups copy everything, incremental saves changes since last backup, differential saves changes since last full backup","isCorrect":true},{"id":"opt-1","text":"Incremental backups copy everything, full saves only changes, differential saves changes since last incremental","isCorrect":false},{"id":"opt-2","text":"Differential backups copy everything, full saves changes since last backup, incremental saves changes since last differential","isCorrect":false},{"id":"opt-3","text":"All backup strategies have the same storage efficiency and recovery time","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-269","questionId":"q-269","question":"What is the primary difference between Ansible, Puppet, and Chef in configuration management?","type":"single","options":[{"id":"opt-0","text":"Ansible is agentless using SSH, while Puppet and Chef require agents","isCorrect":true},{"id":"opt-1","text":"Puppet is agentless using SSH, while Ansible and Chef require agents","isCorrect":false},{"id":"opt-2","text":"Chef is agentless using SSH, while Ansible and Puppet require agents","isCorrect":false},{"id":"opt-3","text":"All three are agentless and use SSH","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-18","questionId":"gh-18","question":"What is Ansible and how does it work for infrastructure automation?","type":"single","options":[{"id":"opt-0","text":"An agentless automation tool that uses SSH and YAML playbooks","isCorrect":true},{"id":"opt-1","text":"A declarative configuration management tool requiring agents","isCorrect":false},{"id":"opt-2","text":"A GitOps continuous delivery tool for Kubernetes","isCorrect":false},{"id":"opt-3","text":"A container orchestration platform","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-67","questionId":"gh-67","question":"How does Database DevOps integrate schema changes into CI/CD?","type":"single","options":[{"id":"opt-0","text":"Manual database updates","isCorrect":false},{"id":"opt-1","text":"Version-controlled migrations with automated testing","isCorrect":true},{"id":"opt-2","text":"Direct production database modifications","isCorrect":false},{"id":"opt-3","text":"Using only backup and restore","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-276","questionId":"q-276","question":"How would you ensure proper execution of systemd timers and cron jobs in production?","type":"single","options":[{"id":"opt-0","text":"Run everything as root user","isCorrect":false},{"id":"opt-1","text":"Use systemd timers with sandboxing and permission audits","isCorrect":true},{"id":"opt-2","text":"Disable all logging for performance","isCorrect":false},{"id":"opt-3","text":"Use only cron jobs without monitoring","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-4","questionId":"gh-4","question":"What is Docker and how does it differ from traditional virtualization?","type":"single","options":[{"id":"opt-0","text":"A hypervisor for creating VMs","isCorrect":false},{"id":"opt-1","text":"A containerization platform sharing host OS kernel","isCorrect":true},{"id":"opt-2","text":"A database management system","isCorrect":false},{"id":"opt-3","text":"A cloud storage service","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-31","questionId":"gh-31","question":"What is Scalability in DevOps?","type":"single","options":[{"id":"opt-0","text":"The ability to handle growing workloads by adding resources","isCorrect":true},{"id":"opt-1","text":"The process of reducing system resources","isCorrect":false},{"id":"opt-2","text":"A security compliance framework","isCorrect":false},{"id":"opt-3","text":"A backup and recovery strategy","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-490","questionId":"q-490","question":"You're migrating a 500-server fleet from Puppet to Ansible with zero downtime. What's the best approach?","type":"single","options":[{"id":"opt-0","text":"Implement phased migration using Ansible's puppet_facts module starting with non-production","isCorrect":true},{"id":"opt-1","text":"Replace all Puppet configurations immediately with Ansible playbooks","isCorrect":false},{"id":"opt-2","text":"Use Ansible Tower to orchestrate a complete overnight migration","isCorrect":false},{"id":"opt-3","text":"Maintain both systems indefinitely and manually sync configurations","isCorrect":false}],"explanation":"Phased migration with puppet_facts maintains existing configurations while gradually transitioning to Ansible","difficulty":"advanced"},{"id":"tq-gh-90","questionId":"gh-90","question":"What is Blue/Green Deployment?","type":"single","options":[{"id":"opt-0","text":"A deployment strategy maintaining two identical production environments to minimize downtime","isCorrect":true},{"id":"opt-1","text":"A testing approach using blue and green environments for A/B testing","isCorrect":false},{"id":"opt-2","text":"A monitoring strategy using color-coded dashboards for deployment status","isCorrect":false},{"id":"opt-3","text":"A backup strategy maintaining blue and green copies of production data","isCorrect":false}],"explanation":"Blue/Green Deployment minimizes downtime and risk by maintaining two identical production environments","difficulty":"advanced"},{"id":"tq-gh-18","questionId":"gh-18","question":"What is Ansible and how does it work for infrastructure automation?","type":"single","options":[{"id":"opt-0","text":"An agentless automation tool using SSH and YAML playbooks for configuration management","isCorrect":true},{"id":"opt-1","text":"A container orchestration platform using Docker and Kubernetes","isCorrect":false},{"id":"opt-2","text":"A monitoring tool that tracks infrastructure performance metrics","isCorrect":false},{"id":"opt-3","text":"A cloud platform that provides virtual machines and storage","isCorrect":false}],"explanation":"Ansible is agentless, uses SSH for communication, and YAML playbooks for defining automation tasks","difficulty":"beginner"},{"id":"tq-gh-4","questionId":"gh-4","question":"How does Docker containerization differ from traditional virtualization?","type":"single","options":[{"id":"opt-0","text":"Docker containers share the host OS kernel while VMs have separate OS instances","isCorrect":true},{"id":"opt-1","text":"Docker requires more resources than traditional virtualization","isCorrect":false},{"id":"opt-2","text":"Docker containers are completely isolated from the host system","isCorrect":false},{"id":"opt-3","text":"Docker only works on Linux while VMs work on all platforms","isCorrect":false}],"explanation":"Docker containers are lightweight because they share the host OS kernel, unlike VMs which require full OS instances","difficulty":"beginner"},{"id":"tq-q-304","questionId":"q-304","question":"How would you design a multi-environment configuration management strategy using Ansible? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"Use inventory groups for different environments","isCorrect":true},{"id":"opt-1","text":"Implement environment-specific variables","isCorrect":true},{"id":"opt-2","text":"Use Ansible Vault for secrets management","isCorrect":true},{"id":"opt-3","text":"Store all configurations in a single monolithic file","isCorrect":false}],"explanation":"Multi-environment strategy requires inventory groups, environment-specific variables, and secure secrets management","difficulty":"advanced"},{"id":"tq-q-444","questionId":"q-444","question":"Your GitHub Actions workflow is failing intermittently due to rate limiting. What's the best solution?","type":"single","options":[{"id":"opt-0","text":"Implement exponential backoff with jitter and use GitHub Actions cache","isCorrect":true},{"id":"opt-1","text":"Increase the rate limit by upgrading to GitHub Enterprise","isCorrect":false},{"id":"opt-2","text":"Run workflows less frequently to avoid rate limits","isCorrect":false},{"id":"opt-3","text":"Move all workflows to a different CI/CD platform","isCorrect":false}],"explanation":"Exponential backoff with jitter handles rate limiting gracefully while caching reduces API calls","difficulty":"intermediate"},{"id":"tq-q-298","questionId":"q-298","question":"Design a large-scale enterprise CI/CD system for AWS. Which components would you include? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"CodePipeline for orchestration","isCorrect":true},{"id":"opt-1","text":"CodeBuild for compilation","isCorrect":true},{"id":"opt-2","text":"CodeDeploy for deployment","isCorrect":true},{"id":"opt-3","text":"Manual deployment processes for critical applications","isCorrect":false}],"explanation":"AWS CI/CD requires CodePipeline for orchestration, CodeBuild for building, and CodeDeploy for automated deployment","difficulty":"advanced"},{"id":"tq-gh-27","questionId":"gh-27","question":"How does Git enable collaboration for distributed teams?","type":"single","options":[{"id":"opt-0","text":"As a distributed VCS using branching, merging, and conflict resolution","isCorrect":true},{"id":"opt-1","text":"As a centralized system requiring constant network connectivity","isCorrect":false},{"id":"opt-2","text":"As a file sharing platform with manual version control","isCorrect":false},{"id":"opt-3","text":"As a real-time collaboration tool like Google Docs","isCorrect":false}],"explanation":"Git's distributed nature allows offline work and enables parallel development through branching and merging","difficulty":"advanced"},{"id":"tq-gh-54","questionId":"gh-54","question":"What is ArgoCD and how does it implement GitOps?","type":"single","options":[{"id":"opt-0","text":"A declarative GitOps tool that syncs Kubernetes applications from Git","isCorrect":true},{"id":"opt-1","text":"A CI/CD pipeline tool for building container images","isCorrect":false},{"id":"opt-2","text":"A monitoring tool for Kubernetes clusters","isCorrect":false},{"id":"opt-3","text":"A security scanning tool for container vulnerabilities","isCorrect":false}],"explanation":"ArgoCD is a GitOps tool that continuously syncs Kubernetes cluster state with Git repository definitions","difficulty":"beginner"},{"id":"tq-gh-16","questionId":"gh-16","question":"What is Infrastructure as Code and why has it become essential for modern DevOps practices?","type":"single","options":[{"id":"opt-0","text":"Managing infrastructure through version-controlled code files for reproducible deployments","isCorrect":true},{"id":"opt-1","text":"Using manual configuration scripts for one-time infrastructure setup","isCorrect":false},{"id":"opt-2","text":"Deploying applications without any infrastructure management","isCorrect":false},{"id":"opt-3","text":"Creating infrastructure diagrams without automation","isCorrect":false}],"explanation":"IaC manages infrastructure through version-controlled code files, enabling reproducible, consistent deployments and automated provisioning.","difficulty":"beginner"},{"id":"tq-q-194","questionId":"q-194","question":"How would you design a Terragrunt + Atlantis workflow to prevent state lock contention across 50+ environments?","type":"single","options":[{"id":"opt-0","text":"Use hierarchical Terragrunt config with remote state locking and Atlantis project-based queuing","isCorrect":true},{"id":"opt-1","text":"Deploy all environments simultaneously without state management","isCorrect":false},{"id":"opt-2","text":"Use local state files for each environment","isCorrect":false},{"id":"opt-3","text":"Disable state locking completely for faster deployments","isCorrect":false}],"explanation":"Hierarchical Terragrunt config with remote state locking, Atlantis project-based queuing, and environment-specific workspaces prevents contention.","difficulty":"advanced"},{"id":"tq-q-344","questionId":"q-344","question":"You're deploying a Node.js microservice to production and notice the Docker image is 850MB. What's the best optimization approach?","type":"single","options":[{"id":"opt-0","text":"Use multi-stage builds with alpine base and copy only compiled artifacts","isCorrect":true},{"id":"opt-1","text":"Remove all dependencies to reduce image size","isCorrect":false},{"id":"opt-2","text":"Use the full Node.js image for better compatibility","isCorrect":false},{"id":"opt-3","text":"Compress the final image after building","isCorrect":false}],"explanation":"Multi-stage builds with build stage using full Node.js and runtime stage with alpine base, copying only compiled artifacts and dependencies.","difficulty":"intermediate"},{"id":"tq-q-421","questionId":"q-421","question":"You're managing infrastructure at scale with Ansible, Puppet, and Chef. Which components should be included in your configuration management design?","type":"single","options":[{"id":"opt-0","text":"Vault for centralized secrets and rolling updates with health checks","isCorrect":true},{"id":"opt-1","text":"Manual configuration updates for better control","isCorrect":false},{"id":"opt-2","text":"Single tool approach to avoid complexity","isCorrect":false},{"id":"opt-3","text":"Local configuration files without automation","isCorrect":false}],"explanation":"Use Vault for centralized secrets, implement rolling updates with health checks, and leverage idempotent configurations with proper rollback mechanism.","difficulty":"intermediate"},{"id":"tq-q-243","questionId":"q-243","question":"How would you design a zero-downtime deployment strategy using Ansible for blue-green infrastructure?","type":"single","options":[{"id":"opt-0","text":"Implement blue-green deployment with Ansible playbooks and traffic switching via load balancer","isCorrect":true},{"id":"opt-1","text":"Deploy directly to production without backup infrastructure","isCorrect":false},{"id":"opt-2","text":"Use manual traffic switching for better control","isCorrect":false},{"id":"opt-3","text":"Deploy during maintenance windows to avoid downtime","isCorrect":false}],"explanation":"Blue-green deployment with Ansible playbooks for infrastructure provisioning, traffic switching via load balancer, and automated rollback.","difficulty":"intermediate"},{"id":"tq-gh-96","questionId":"gh-96","question":"What is a Runbook in DevOps operations?","type":"single","options":[{"id":"opt-0","text":"A detailed document outlining steps for operational tasks or incident response","isCorrect":true},{"id":"opt-1","text":"A code repository for infrastructure automation","isCorrect":false},{"id":"opt-2","text":"A monitoring dashboard for system health","isCorrect":false},{"id":"opt-3","text":"A deployment pipeline configuration file","isCorrect":false}],"explanation":"A Runbook is a detailed document or collection of procedures that outlines steps required to perform specific operational tasks or respond to incidents.","difficulty":"advanced"},{"id":"tq-gh-104","questionId":"gh-104","question":"What is Canary Analysis and how does it work in production deployments?","type":"single","options":[{"id":"opt-0","text":"A deployment strategy releasing changes to a small subset before full rollout","isCorrect":true},{"id":"opt-1","text":"A testing framework for unit tests","isCorrect":false},{"id":"opt-2","text":"A monitoring tool for application performance","isCorrect":false},{"id":"opt-3","text":"A backup strategy for disaster recovery","isCorrect":false}],"explanation":"Canary Analysis releases changes to a small subset of users or servers before rolling out to the entire infrastructure, allowing safe testing.","difficulty":"advanced"},{"id":"tq-q-354","questionId":"q-354","question":"You need to deploy a Node.js microservice to SAP's production environment. What's the optimal Dockerfile strategy?","type":"single","options":[{"id":"opt-0","text":"Use multi-stage builds with Node.js + dev dependencies in build stage, slim base + only artifacts in production","isCorrect":true},{"id":"opt-1","text":"Use the full Node.js image for all stages","isCorrect":false},{"id":"opt-2","text":"Deploy without Docker for better performance","isCorrect":false},{"id":"opt-3","text":"Use a single-stage build with all dependencies","isCorrect":false}],"explanation":"Multi-stage builds with build stage using Node.js + dev dependencies, production stage with slim base + only built artifacts and runtime dependencies.","difficulty":"beginner"},{"id":"tq-gh-10","questionId":"gh-10","question":"What is a CI/CD pipeline and how does it automate software delivery?","type":"single","options":[{"id":"opt-0","text":"Automates building, testing, and deploying code through commit, build, test, and deploy stages","isCorrect":true},{"id":"opt-1","text":"Manually coordinates deployment processes","isCorrect":false},{"id":"opt-2","text":"Only runs unit tests without deployment","isCorrect":false},{"id":"opt-3","text":"Creates documentation automatically","isCorrect":false}],"explanation":"CI/CD pipeline automates building, testing, and deploying code changes through stages like commit, build, test, and deploy.","difficulty":"beginner"},{"id":"tq-gh-64","questionId":"gh-64","question":"Which of the following are the four key DORA metrics for measuring DevOps performance? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"Deployment Frequency (deployments per week)","isCorrect":true},{"id":"opt-1","text":"Lead Time for Changes (time from commit to deploy)","isCorrect":true},{"id":"opt-2","text":"Code coverage percentage","isCorrect":false},{"id":"opt-3","text":"Number of developers on team","isCorrect":false}],"explanation":"DORA metrics include Deployment Frequency and Lead Time for Changes, along with Change Failure Rate and Time to Restore Service.","difficulty":"intermediate"},{"id":"tq-gh-11","questionId":"gh-11","question":"What is Jenkins and how does it facilitate CI/CD processes?","type":"single","options":[{"id":"opt-0","text":"An open-source automation server that automates build, test, and deployment through plugins","isCorrect":true},{"id":"opt-1","text":"A container orchestration platform for microservices management","isCorrect":false},{"id":"opt-2","text":"A version control system for tracking code changes","isCorrect":false},{"id":"opt-3","text":"A monitoring tool for application performance metrics","isCorrect":false}],"explanation":"Jenkins is an automation server that enables CI/CD by automating build, test, and deployment processes through extensible plugins","difficulty":"advanced"},{"id":"tq-gh-53","questionId":"gh-53","question":"What is GitOps and how does it work in practice?","type":"single","options":[{"id":"opt-0","text":"A declarative approach where Git is the single source of truth for system state","isCorrect":true},{"id":"opt-1","text":"A continuous integration tool for automated testing","isCorrect":false},{"id":"opt-2","text":"A container runtime for application deployment","isCorrect":false},{"id":"opt-3","text":"A monitoring system for infrastructure health","isCorrect":false}],"explanation":"GitOps uses Git as the single source of truth for system state with automated deployment and configuration management","difficulty":"beginner"},{"id":"tq-gh-2","questionId":"gh-2","question":"Which of the following components would you include in a DevOps pipeline designed to reduce deployment time by 60% while improving reliability?","type":"multiple","options":[{"id":"opt-0","text":"GitHub Actions for CI","isCorrect":true},{"id":"opt-1","text":"ArgoCD for CD","isCorrect":true},{"id":"opt-2","text":"Terraform for IaC","isCorrect":true},{"id":"opt-3","text":"Manual deployment scripts","isCorrect":false}],"explanation":"A GitOps pipeline with GitHub Actions, ArgoCD, and Terraform provides automated, reliable deployments while reducing time","difficulty":"beginner"},{"id":"tq-q-269","questionId":"q-269","question":"How do Ansible, Puppet, and Chef differ in their configuration management approaches?","type":"multiple","options":[{"id":"opt-0","text":"Ansible uses agentless SSH with push-based imperative YAML","isCorrect":true},{"id":"opt-1","text":"Puppet employs agent-based pull with declarative DSL","isCorrect":true},{"id":"opt-2","text":"Chef uses Ruby-based recipes with agent-based push model","isCorrect":true},{"id":"opt-3","text":"All three use the same agent-based pull architecture","isCorrect":false}],"explanation":"Each tool has distinct architecture: Ansible is agentless SSH, Puppet uses agent-based pull, and Chef uses Ruby-based recipes","difficulty":"beginner"},{"id":"tq-q-332","questionId":"q-332","question":"How would you fix intermittent GitHub Actions workflow failures due to race conditions in multi-deployment scenarios?","type":"single","options":[{"id":"opt-0","text":"Use GitHub Actions concurrency control with deployment environments","isCorrect":true},{"id":"opt-1","text":"Increase workflow timeout values","isCorrect":false},{"id":"opt-2","text":"Add more parallel runners to the workflow","isCorrect":false},{"id":"opt-3","text":"Disable all automated deployments","isCorrect":false}],"explanation":"Concurrency control with deployment environments prevents race conditions by managing sequential deployments","difficulty":"intermediate"}],"passingScore":70,"createdAt":"2025-12-18T10:05:45.574Z","lastUpdated":"2025-12-25T20:27:11.233Z","version":2},{"id":"test-frontend","channelId":"frontend","channelName":"Frontend","title":"Frontend Knowledge Test","description":"Test your Frontend knowledge.","questions":[{"id":"tq-fr-173","questionId":"fr-173","question":"What is the output of this code and explain the event loop behavior: console.log('A'); setTimeout(() => console.log('B'), 0); Promise.resolve().then(() => console.log('C')); console.log('D');","type":"single","options":[{"id":"opt-0","text":"A, E, C, D, B","isCorrect":true},{"id":"opt-1","text":"A, D, C, B, E","isCorrect":false},{"id":"opt-2","text":"A, D, B, C, E","isCorrect":false},{"id":"opt-3","text":"A, C, D, B, E","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-168","questionId":"q-168","question":"What are the four main components of the CSS box model?","type":"single","options":[{"id":"opt-0","text":"content, padding, border, margin","isCorrect":true},{"id":"opt-1","text":"width, height, padding, margin","isCorrect":false},{"id":"opt-2","text":"content, border, margin, outline","isCorrect":false},{"id":"opt-3","text":"element, padding, border, spacing","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-fr-162","questionId":"fr-162","question":"How does JavaScript's event loop handle microtasks vs macrotasks?","type":"single","options":[{"id":"opt-0","text":"Microtasks execute before next macrotask","isCorrect":true},{"id":"opt-1","text":"Macrotasks execute before microtasks","isCorrect":false},{"id":"opt-2","text":"They execute simultaneously","isCorrect":false},{"id":"opt-3","text":"Order depends on browser implementation","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-215","questionId":"q-215","question":"How would you implement a custom useDebounce hook for React's concurrent features?","type":"single","options":[{"id":"opt-0","text":"Use useRef for latest value, useEffect with cleanup, and useCallback","isCorrect":true},{"id":"opt-1","text":"Use useState and setTimeout directly","isCorrect":false},{"id":"opt-2","text":"Use useMemo and clearTimeout","isCorrect":false},{"id":"opt-3","text":"Use useReducer with debounce logic","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-fr-157","questionId":"fr-157","question":"What is the difference between `let`, `const`, and `var` in JavaScript?","type":"single","options":[{"id":"opt-0","text":"var is function-scoped and hoisted; let/const are block-scoped","isCorrect":true},{"id":"opt-1","text":"All are block-scoped with different reassignment rules","isCorrect":false},{"id":"opt-2","text":"var is block-scoped; let/const are function-scoped","isCorrect":false},{"id":"opt-3","text":"They are identical except for naming convention","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-fr-172","questionId":"fr-172","question":"How would you optimize the rendering performance of a React component that displays a large list?","type":"single","options":[{"id":"opt-0","text":"Use virtualization, memoization, and debounced updates to minimize re-renders and DOM nodes","isCorrect":true},{"id":"opt-1","text":"Increase the component's state update frequency","isCorrect":false},{"id":"opt-2","text":"Remove all memoization and let React handle optimization automatically","isCorrect":false},{"id":"opt-3","text":"Use setTimeout to delay rendering of list items","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-188","questionId":"q-188","question":"How would you implement a performance budget system that automatically detects bundle regressions?","type":"single","options":[{"id":"opt-0","text":"Use webpack-bundle-analyzer with performance budgets, implement dynamic imports with React.lazy, and set up CI checks to enforce bundle size limits","isCorrect":true},{"id":"opt-1","text":"Manually check bundle sizes after each deployment","isCorrect":false},{"id":"opt-2","text":"Disable all code splitting to reduce complexity","isCorrect":false},{"id":"opt-3","text":"Use only console.log statements to track bundle size","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-239","questionId":"q-239","question":"How would you implement a React useMemo hook to optimize a recursive Fibonacci function?","type":"single","options":[{"id":"opt-0","text":"Use useMemo to cache expensive Fibonacci calculations, memoizing results to prevent O(2^n) recursion","isCorrect":true},{"id":"opt-1","text":"Remove useMemo and let the function run without optimization","isCorrect":false},{"id":"opt-2","text":"Use useState instead of useMemo for better performance","isCorrect":false},{"id":"opt-3","text":"Implement the function without memoization to keep it simple","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-287","questionId":"q-287","question":"How does a Service Worker intercept network requests and implement offline caching strategies?","type":"single","options":[{"id":"opt-0","text":"Service Workers register event listeners on 'fetch' events to intercept network requests and can return cached responses using the Cache API","isCorrect":true},{"id":"opt-1","text":"Service Workers modify the browser's network stack directly","isCorrect":false},{"id":"opt-2","text":"Service Workers only work when the application is online","isCorrect":false},{"id":"opt-3","text":"Service Workers use localStorage for all caching operations","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-fr-161","questionId":"fr-161","question":"How would you implement a React hook that tracks component render count and warns when it exceeds a threshold?","type":"single","options":[{"id":"opt-0","text":"Use useRef to persist count across renders and useEffect with no deps to increment. Check threshold and warn without triggering re-render","isCorrect":true},{"id":"opt-1","text":"Use useState to track render count and update it on every render","isCorrect":false},{"id":"opt-2","text":"Use console.log in the render function to track renders","isCorrect":false},{"id":"opt-3","text":"Use useCallback to track render count instead of useRef","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-fr-154","questionId":"fr-154","question":"What happens when you load a large image without specifying width and height attributes in the HTML?","type":"single","options":[{"id":"opt-0","text":"The browser causes layout shift (CLS) as it reflows the page once the image dimensions are known after loading","isCorrect":true},{"id":"opt-1","text":"The image fails to load completely","isCorrect":false},{"id":"opt-2","text":"The browser automatically sets default dimensions","isCorrect":false},{"id":"opt-3","text":"The image loads instantly without any layout issues","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-fr-163","questionId":"fr-163","question":"You have a React app rendering a list of 10,000 items. Each item has a complex component with multiple performance bottlenecks. What is the best approach?","type":"single","options":[{"id":"opt-0","text":"Use only React.memo for all components","isCorrect":false},{"id":"opt-1","text":"Use virtualization (react-window), memoization (React.memo/useMemo), and code splitting","isCorrect":true},{"id":"opt-2","text":"Remove all complex components from the list","isCorrect":false},{"id":"opt-3","text":"Load all items at once without optimization","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-240","questionId":"q-240","question":"What is a closure in JavaScript and how does it enable data encapsulation?","type":"single","options":[{"id":"opt-0","text":"A closure is when a function remembers and accesses variables from its outer lexical scope, even after the outer function has finished executing","isCorrect":true},{"id":"opt-1","text":"A closure is a type of loop in JavaScript","isCorrect":false},{"id":"opt-2","text":"A closure is a method for DOM manipulation","isCorrect":false},{"id":"opt-3","text":"A closure is a built-in JavaScript object","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-fe-2","questionId":"fe-2","question":"What is the Event Loop in JavaScript?","type":"single","options":[{"id":"opt-0","text":"A type of for loop construct","isCorrect":false},{"id":"opt-1","text":"The Event Loop coordinates the Call Stack, Web APIs, and Callback Queues","isCorrect":true},{"id":"opt-2","text":"A method for handling HTTP requests","isCorrect":false},{"id":"opt-3","text":"A debugging tool for JavaScript","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-fe-3","questionId":"fe-3","question":"Explain JavaScript closures with a practical use case","type":"single","options":[{"id":"opt-0","text":"A closure is a function that retains access to its lexical scope, allowing it to use variables from its outer function even after that function has returned","isCorrect":true},{"id":"opt-1","text":"A closure is a type of array method","isCorrect":false},{"id":"opt-2","text":"A closure is a CSS styling technique","isCorrect":false},{"id":"opt-3","text":"A closure is a database connection method","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-fe-1","questionId":"fe-1","question":"How does React's Virtual DOM diffing algorithm work during reconciliation, and what role do keys play?","type":"single","options":[{"id":"opt-0","text":"React compares新旧VDOM trees using a heuristic O(n) algorithm, calculating minimal DOM patches. Keys enable stable element identity for efficient list updates","isCorrect":true},{"id":"opt-1","text":"React uses a brute-force O(n²) comparison algorithm to find all differences between VDOM trees","isCorrect":false},{"id":"opt-2","text":"React completely rebuilds the VDOM tree on every render and applies all changes to the DOM","isCorrect":false},{"id":"opt-3","text":"React ignores keys during reconciliation and only uses element types for comparison","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-493","questionId":"q-493","question":"You're building a real-time grocery delivery tracking app for Instacart. What approach would you implement for offline functionality?","type":"single","options":[{"id":"opt-0","text":"Service worker caches critical UI shell and order data, uses background sync API for offline actions, maintains WebSocket connection with exponential backoff","isCorrect":true},{"id":"opt-1","text":"Use localStorage for all data storage and implement manual refresh for offline mode","isCorrect":false},{"id":"opt-2","text":"Rely on browser's built-in caching mechanisms without additional implementation","isCorrect":false},{"id":"opt-3","text":"Implement server-side rendering with no client-side caching","isCorrect":false}],"explanation":"A multi-layered approach with service workers, background sync, and WebSocket management provides the most robust offline experience.","difficulty":"advanced"},{"id":"tq-q-419","questionId":"q-419","question":"How would you implement a WebSocket connection for a real-time food delivery tracking app?","type":"single","options":[{"id":"opt-0","text":"WebSocket with exponential backoff retry, service worker for offline caching, and IndexedDB for local state persistence","isCorrect":true},{"id":"opt-1","text":"Simple WebSocket connection without error handling or offline support","isCorrect":false},{"id":"opt-2","text":"HTTP polling every 5 seconds as a fallback mechanism","isCorrect":false},{"id":"opt-3","text":"Use only service workers without WebSocket implementation","isCorrect":false}],"explanation":"Combining WebSocket with retry logic, service workers, and IndexedDB ensures reliable real-time updates with offline resilience.","difficulty":"intermediate"},{"id":"tq-q-426","questionId":"q-426","question":"Which of the following technologies would you use to implement offline functionality in a real-time chat application? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"Service worker with cache-first strategy for messages","isCorrect":true},{"id":"opt-1","text":"IndexedDB for offline storage","isCorrect":true},{"id":"opt-2","text":"Background sync API","isCorrect":true},{"id":"opt-3","text":"WebSockets only without caching","isCorrect":false}],"explanation":"Service workers handle caching, IndexedDB stores data locally, and background sync manages offline actions - all essential for robust chat functionality.","difficulty":"beginner"},{"id":"tq-q-434","questionId":"q-434","question":"When should you use Context API versus Redux for state management in React applications?","type":"single","options":[{"id":"opt-0","text":"Context API for simple, localized state like authentication; Redux for complex state with many interactions","isCorrect":true},{"id":"opt-1","text":"Always use Redux regardless of application complexity","isCorrect":false},{"id":"opt-2","text":"Context API is better for large-scale applications with complex state","isCorrect":false},{"id":"opt-3","text":"Neither - use local component state only","isCorrect":false}],"explanation":"Context API excels for simple, infrequently changing state while Redux handles complex state management scenarios more effectively.","difficulty":"intermediate"},{"id":"tq-q-287","questionId":"q-287","question":"How do Service Workers implement offline caching strategies?","type":"single","options":[{"id":"opt-0","text":"Register event listeners on 'fetch' events to intercept requests and return cached responses using Cache API","isCorrect":true},{"id":"opt-1","text":"Modify the browser's native networking stack directly","isCorrect":false},{"id":"opt-2","text":"Use localStorage to cache all network responses","isCorrect":false},{"id":"opt-3","text":"Implement server-side caching only","isCorrect":false}],"explanation":"Service Workers intercept fetch events and can serve cached responses, enabling sophisticated offline caching strategies.","difficulty":"intermediate"},{"id":"tq-fr-172","questionId":"fr-172","question":"Which of the following techniques would optimize rendering performance for a React component displaying a large list (10,000+ items)? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"react-window for virtualization","isCorrect":true},{"id":"opt-1","text":"useMemo for expensive calculations","isCorrect":true},{"id":"opt-2","text":"useCallback for stable function references","isCorrect":true},{"id":"opt-3","text":"Render all items at once without optimization","isCorrect":false}],"explanation":"Virtualization, memoization, and stable references work together to optimize large list rendering performance.","difficulty":"intermediate"},{"id":"tq-q-240","questionId":"q-240","question":"What is a closure in JavaScript and how does it enable data encapsulation?","type":"single","options":[{"id":"opt-0","text":"A function remembers and accesses variables from its outer lexical scope, even after the outer function has finished executing","isCorrect":true},{"id":"opt-1","text":"A way to hide implementation details from other parts of the program","isCorrect":false},{"id":"opt-2","text":"A method for creating private variables in classes","isCorrect":false},{"id":"opt-3","text":"A design pattern for organizing code modules","isCorrect":false}],"explanation":"Closures allow functions to maintain access to their outer scope variables, creating natural data encapsulation.","difficulty":"beginner"},{"id":"tq-fe-1","questionId":"fe-1","question":"How does React's Virtual DOM diffing algorithm work during reconciliation?","type":"single","options":[{"id":"opt-0","text":"Compares new and old VDOM trees using O(n) algorithm, calculating minimal DOM patches","isCorrect":true},{"id":"opt-1","text":"Recreates the entire DOM tree on every render","isCorrect":false},{"id":"opt-2","text":"Uses a brute-force comparison of all DOM nodes","isCorrect":false},{"id":"opt-3","text":"Relies on browser's native diffing algorithms","isCorrect":false}],"explanation":"React's efficient O(n) diffing algorithm identifies minimal changes needed to update the actual DOM.","difficulty":"intermediate"},{"id":"tq-fr-157","questionId":"fr-157","question":"Which of the following statements about JavaScript variable declarations are correct? Select all that apply.","type":"multiple","options":[{"id":"opt-0","text":"`var` is function-scoped and hoisted with `undefined` initialization","isCorrect":true},{"id":"opt-1","text":"`let` and `const` are block-scoped with temporal dead zone","isCorrect":true},{"id":"opt-2","text":"`const` variables can be reassigned after declaration","isCorrect":false},{"id":"opt-3","text":"`let` allows redeclaration in the same scope","isCorrect":false}],"explanation":"var has function scope and hoisting behavior, while let/const have block scope with temporal dead zone restrictions.","difficulty":"beginner"},{"id":"tq-fr-161","questionId":"fr-161","question":"How would you implement a React hook that tracks component render count and warns when it exceeds a threshold?","type":"single","options":[{"id":"opt-0","text":"Use useRef to persist count across renders and useEffect with no deps to increment","isCorrect":true},{"id":"opt-1","text":"Use useState to track render count and increment in render function","isCorrect":false},{"id":"opt-2","text":"Use localStorage to store render count across sessions","isCorrect":false},{"id":"opt-3","text":"Implement a class component with render counting","isCorrect":false}],"explanation":"useRef persists values without triggering re-renders, while useEffect with no dependencies runs after every render.","difficulty":"advanced"},{"id":"tq-fe-3","questionId":"fe-3","question":"What is a JavaScript closure and how is it commonly used in real-world applications?","type":"single","options":[{"id":"opt-0","text":"A function that retains access to its lexical scope even after the outer function returns","isCorrect":true},{"id":"opt-1","text":"A built-in JavaScript method for creating private variables","isCorrect":false},{"id":"opt-2","text":"A type of loop that iterates over object properties","isCorrect":false},{"id":"opt-3","text":"A syntax for defining arrow functions","isCorrect":false}],"explanation":"Closures allow functions to maintain access to variables from their outer scope, enabling patterns like private variables and function factories.","difficulty":"intermediate"},{"id":"tq-q-168","questionId":"q-168","question":"How does the CSS box-sizing property affect layout calculations?","type":"single","options":[{"id":"opt-0","text":"content-box includes padding and border in width calculations","isCorrect":false},{"id":"opt-1","text":"border-box includes padding and border in width calculations","isCorrect":true},{"id":"opt-2","text":"padding-box excludes margin from calculations","isCorrect":false},{"id":"opt-3","text":"margin-box includes all dimensions","isCorrect":false}],"explanation":"With box-sizing: border-box, width and height include content, padding, and border, making layout calculations more intuitive.","difficulty":"beginner"},{"id":"tq-fr-173","questionId":"fr-173","question":"What is the output of this code and why: console.log('A'); setTimeout(() => console.log('B'), 0); Promise.resolve().then(() => console.log('C')); console.log('D');","type":"single","options":[{"id":"opt-0","text":"A, B, C, D","isCorrect":false},{"id":"opt-1","text":"A, D, C, B","isCorrect":false},{"id":"opt-2","text":"A, C, D, B","isCorrect":true},{"id":"opt-3","text":"A, E, C, D, B","isCorrect":false}],"explanation":"The event loop processes synchronous code first, then microtasks (Promise), then macrotasks (setTimeout).","difficulty":"advanced"},{"id":"tq-q-378","questionId":"q-378","question":"Which techniques would you use to optimize a real-time dashboard displaying 1000+ rapidly updating elements?","type":"multiple","options":[{"id":"opt-0","text":"CSS containment and GPU acceleration","isCorrect":true},{"id":"opt-1","text":"Virtualized rendering with requestAnimationFrame","isCorrect":true},{"id":"opt-2","text":"Inline styles and synchronous updates","isCorrect":false},{"id":"opt-3","text":"DOM manipulation without batching","isCorrect":false}],"explanation":"CSS containment limits browser reflow scope, while virtualization and requestAnimationFrame maintain smooth 60fps performance.","difficulty":"advanced"},{"id":"tq-fe-2","questionId":"fe-2","question":"How do microtasks and macrotasks differ in the JavaScript Event Loop?","type":"single","options":[{"id":"opt-0","text":"Microtasks run between each macrotask","isCorrect":true},{"id":"opt-1","text":"Macrotasks have higher priority than microtasks","isCorrect":false},{"id":"opt-2","text":"Microtasks include setTimeout and DOM events","isCorrect":false},{"id":"opt-3","text":"Macrotasks include Promise callbacks","isCorrect":false}],"explanation":"The Event Loop processes all microtasks (Promises, async/await) before executing the next macrotask (setTimeout, DOM events).","difficulty":"beginner"},{"id":"tq-q-351","questionId":"q-351","question":"How would you implement a robust file upload component that handles multiple files in parallel?","type":"single","options":[{"id":"opt-0","text":"Use a queue system with Promise.allSettled","isCorrect":true},{"id":"opt-1","text":"Upload files sequentially with async/await","isCorrect":false},{"id":"opt-2","text":"Use XMLHttpRequest without error handling","isCorrect":false},{"id":"opt-3","text":"Process all files with Promise.all","isCorrect":false}],"explanation":"A queue system with Promise.allSettled allows tracking active uploads and handling partial failures gracefully.","difficulty":"intermediate"},{"id":"tq-q-395","questionId":"q-395","question":"Which approaches would you use to build a responsive grid dashboard with dynamic columns that maintains 60fps?","type":"multiple","options":[{"id":"opt-0","text":"CSS Grid with virtual scrolling","isCorrect":true},{"id":"opt-1","text":"RequestAnimationFrame for DOM updates","isCorrect":true},{"id":"opt-2","text":"Inline styles for each grid item","isCorrect":false},{"id":"opt-3","text":"Synchronous DOM manipulation","isCorrect":false}],"explanation":"CSS Grid provides flexible layouts, while virtual scrolling and requestAnimationFrame ensure smooth performance.","difficulty":"advanced"},{"id":"tq-q-363","questionId":"q-363","question":"How would you evenly space 3 navigation items with the middle item centered?","type":"single","options":[{"id":"opt-0","text":"justify-content: space-between with margin: 0 auto on middle item","isCorrect":true},{"id":"opt-1","text":"display: flex with justify-content: center","isCorrect":false},{"id":"opt-2","text":"float: left with equal widths","isCorrect":false},{"id":"opt-3","text":"position: absolute on all items","isCorrect":false}],"explanation":"Space-between pushes outer items to edges, while margin: 0 auto centers the middle item.","difficulty":"beginner"},{"id":"tq-q-390","questionId":"q-390","question":"Which specific optimizations would improve a React app with a Lighthouse score of 45?","type":"multiple","options":[{"id":"opt-0","text":"Code splitting with React.lazy()","isCorrect":true},{"id":"opt-1","text":"Bundle analysis and image optimization","isCorrect":true},{"id":"opt-2","text":"Remove all async operations","isCorrect":false},{"id":"opt-3","text":"Increase bundle size for better caching","isCorrect":false}],"explanation":"Code splitting reduces initial bundle size, while bundle analysis and image optimization address specific performance bottlenecks.","difficulty":"beginner"},{"id":"tq-q-188","questionId":"q-188","question":"How would you implement a performance budget system to detect bundle regressions?","type":"multiple","options":[{"id":"opt-0","text":"webpack-bundle-analyzer with CI checks","isCorrect":true},{"id":"opt-1","text":"Dynamic imports with React.lazy","isCorrect":true},{"id":"opt-2","text":"Remove all performance monitoring","isCorrect":false},{"id":"opt-3","text":"Increase bundle size limits","isCorrect":false}],"explanation":"Bundle analysis with automated CI enforcement prevents regressions, while dynamic imports keep the initial bundle small.","difficulty":"advanced"},{"id":"tq-q-329","questionId":"q-329","question":"What's the most effective approach to improve a React app's Lighthouse performance score from 65 to 90+?","type":"single","options":[{"id":"opt-0","text":"Implement code splitting with React.lazy(), analyze bundle with webpack-bundle-analyzer, remove unused dependencies, add dynamic imports for heavy components","isCorrect":true},{"id":"opt-1","text":"Add more caching headers and enable service workers for offline support","isCorrect":false},{"id":"opt-2","text":"Increase server response time by upgrading hosting infrastructure","isCorrect":false},{"id":"opt-3","text":"Add more meta tags and improve SEO markup","isCorrect":false}],"explanation":"Code splitting and bundle optimization directly address the main performance bottlenecks that Lighthouse measures.","difficulty":"intermediate"},{"id":"tq-q-301","questionId":"q-301","question":"Which of the following techniques are essential for optimizing React app bundle size to achieve Lighthouse scores above 90?","type":"multiple","options":[{"id":"opt-0","text":"Implement code splitting with React.lazy() and Suspense","isCorrect":true},{"id":"opt-1","text":"Configure webpack bundle analyzer for visualization","isCorrect":true},{"id":"opt-2","text":"Use dynamic imports for vendor chunks","isCorrect":true},{"id":"opt-3","text":"Add more CSS animations for better UX","isCorrect":false}],"explanation":"Code splitting, bundle analysis, and dynamic imports are core techniques for reducing bundle size and improving performance metrics.","difficulty":"beginner"},{"id":"tq-fr-154","questionId":"fr-154","question":"What are the primary performance consequences of loading large images without specified dimensions?","type":"single","options":[{"id":"opt-0","text":"Causes Cumulative Layout Shift (CLS) as browsers reflow content once image metadata loads","isCorrect":true},{"id":"opt-1","text":"Increases First Contentful Paint (FCP) due to larger file sizes","isCorrect":false},{"id":"opt-2","text":"Improves accessibility by allowing screen readers to describe images better","isCorrect":false},{"id":"opt-3","text":"Reduces server load by deferring image loading","isCorrect":false}],"explanation":"Missing image dimensions force browsers to reflow the layout when images load, directly impacting CLS scores in Core Web Vitals.","difficulty":"beginner"},{"id":"tq-q-408","questionId":"q-408","question":"How would you implement a responsive dashboard with complex grid layout that supports dynamic widget resizing?","type":"single","options":[{"id":"opt-0","text":"Use CSS Grid with CSS custom properties for dynamic sizing, CSS transforms for animations, and virtualization for performance","isCorrect":true},{"id":"opt-1","text":"Use Bootstrap grid system with jQuery for dynamic resizing","isCorrect":false},{"id":"opt-2","text":"Implement everything with absolute positioning and JavaScript calculations","isCorrect":false},{"id":"opt-3","text":"Use flexbox exclusively and avoid CSS Grid for better browser support","isCorrect":false}],"explanation":"CSS Grid provides the most powerful layout system for complex grids, while custom properties enable dynamic sizing and transforms ensure smooth animations.","difficulty":"advanced"},{"id":"tq-fr-163","questionId":"fr-163","question":"Select all that apply: What are the key optimization strategies for rendering a list of 10,000 complex React items?","type":"multiple","options":[{"id":"opt-0","text":"Use virtualization (react-window) to only render visible items","isCorrect":true},{"id":"opt-1","text":"Apply memoization (React.memo/useMemo) to prevent unnecessary re-renders","isCorrect":true},{"id":"opt-2","text":"Implement code splitting for individual item components","isCorrect":true},{"id":"opt-3","text":"Use setTimeout to stagger rendering of items","isCorrect":false}],"explanation":"Virtualization, memoization, and code splitting address different performance bottlenecks: rendering count, re-renders, and bundle size respectively.","difficulty":"advanced"}],"passingScore":70,"createdAt":"2025-12-18T10:06:19.740Z","lastUpdated":"2025-12-25T20:27:47.499Z","version":2},{"id":"test-kubernetes","channelId":"kubernetes","channelName":"Kubernetes","title":"Kubernetes Knowledge Test","description":"Test your Kubernetes knowledge.","questions":[{"id":"tq-gh-7","questionId":"gh-7","question":"What is Kubernetes and how does it orchestrate containerized applications at scale?","type":"single","options":[{"id":"opt-0","text":"An open-source container orchestration platform that automates deployment, scaling, and management of containerized applications across clusters","isCorrect":true},{"id":"opt-1","text":"A virtualization technology for creating virtual machines","isCorrect":false},{"id":"opt-2","text":"A container runtime for Docker containers","isCorrect":false},{"id":"opt-3","text":"A monitoring tool for containerized applications","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-50","questionId":"gh-50","question":"How does Istio implement service mesh architecture using sidecar proxies?","type":"single","options":[{"id":"opt-0","text":"By deploying Envoy sidecar proxies alongside each service to handle traffic management, security, and observability","isCorrect":true},{"id":"opt-1","text":"By using Kubernetes built-in service discovery","isCorrect":false},{"id":"opt-2","text":"By implementing direct service-to-service communication","isCorrect":false},{"id":"opt-3","text":"By using API gateways for routing","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-245","questionId":"q-245","question":"How do init containers differ from sidecar containers in a Kubernetes pod?","type":"single","options":[{"id":"opt-0","text":"Init containers run sequentially before app starts and complete; sidecars run alongside the main app continuously","isCorrect":true},{"id":"opt-1","text":"Init containers run continuously; sidecars run once at startup","isCorrect":false},{"id":"opt-2","text":"Init containers handle networking; sidecars handle storage","isCorrect":false},{"id":"opt-3","text":"There is no difference between them","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-101","questionId":"gh-101","question":"What is a Service Mesh Control Plane?","type":"single","options":[{"id":"opt-0","text":"The centralized component responsible for configuring, managing, and monitoring the behavior of the service mesh","isCorrect":true},{"id":"opt-1","text":"The data plane that handles actual traffic routing","isCorrect":false},{"id":"opt-2","text":"The application layer that runs business logic","isCorrect":false},{"id":"opt-3","text":"The storage layer for service mesh data","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-q-173","questionId":"q-173","question":"What is a Kubernetes Pod and what is its primary purpose?","type":"single","options":[{"id":"opt-0","text":"The smallest deployable unit in Kubernetes that contains one or more containers with shared storage and network","isCorrect":true},{"id":"opt-1","text":"A collection of services that manage container networking","isCorrect":false},{"id":"opt-2","text":"A virtual machine that runs containerized applications","isCorrect":false},{"id":"opt-3","text":"A storage system for container images","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-193","questionId":"q-193","question":"What is the role of a Custom Resource Definition (CRD) in a Kubernetes Operator?","type":"single","options":[{"id":"opt-0","text":"To define custom API resources that operators manage, extending Kubernetes with domain-specific objects and their desired state","isCorrect":true},{"id":"opt-1","text":"To create new container runtime environments","isCorrect":false},{"id":"opt-2","text":"To configure network policies for services","isCorrect":false},{"id":"opt-3","text":"To manage storage volumes for pods","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-271","questionId":"q-271","question":"How would you design a multi-container pod with init containers and sidecars to implement a zero-downtime migration?","type":"single","options":[{"id":"opt-0","text":"Use init container for schema validation, sidecar for migration execution, and shared volumes for coordination","isCorrect":true},{"id":"opt-1","text":"Deploy multiple pods with different container configurations","isCorrect":false},{"id":"opt-2","text":"Use a single container with all migration logic built-in","isCorrect":false},{"id":"opt-3","text":"Create separate services for each migration step","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-q-219","questionId":"q-219","question":"How would you design a zero-downtime service migration strategy using Kubernetes Service selectors?","type":"single","options":[{"id":"opt-0","text":"Use dual-service approach with overlapping selectors and gradual traffic shifting via EndpointsSlice API while maintaining connection affinity","isCorrect":true},{"id":"opt-1","text":"Replace the service selector immediately to point to new pods","isCorrect":false},{"id":"opt-2","text":"Create multiple services with different ports for migration","isCorrect":false},{"id":"opt-3","text":"Use a rolling restart strategy without service selector changes","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-51","questionId":"gh-51","question":"What is Container Runtime Interface (CRI) and why is it important in Kubernetes?","type":"single","options":[{"id":"opt-0","text":"A Kubernetes API that lets Kubelet communicate with various container runtimes","isCorrect":true},{"id":"opt-1","text":"A container runtime like containerd or CRI-O","isCorrect":false},{"id":"opt-2","text":"A Docker interface for Kubernetes","isCorrect":false},{"id":"opt-3","text":"A networking component in Kubernetes","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-9","questionId":"gh-9","question":"What is a Pod in Kubernetes and why is it considered the smallest deployable unit?","type":"single","options":[{"id":"opt-0","text":"Kubernetes' smallest deployable unit that encapsulates one or more containers with shared resources","isCorrect":true},{"id":"opt-1","text":"A single container in Kubernetes","isCorrect":false},{"id":"opt-2","text":"A virtual machine in Kubernetes","isCorrect":false},{"id":"opt-3","text":"A storage unit in Kubernetes","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-q-291","questionId":"q-291","question":"What is the role of a reconciliation loop in a Kubernetes operator controller?","type":"single","options":[{"id":"opt-0","text":"Continuously compares desired state with actual state, taking actions to achieve convergence","isCorrect":true},{"id":"opt-1","text":"Creates new containers when needed","isCorrect":false},{"id":"opt-2","text":"Manages networking between pods","isCorrect":false},{"id":"opt-3","text":"Monitors resource usage","isCorrect":false}],"explanation":"","difficulty":"beginner"},{"id":"tq-gh-8","questionId":"gh-8","question":"What are the main components of Kubernetes architecture?","type":"single","options":[{"id":"opt-0","text":"Control plane, worker nodes, etcd, kubelet, kube-proxy","isCorrect":true},{"id":"opt-1","text":"Master node, slave nodes, containers","isCorrect":false},{"id":"opt-2","text":"API server, scheduler, controller manager only","isCorrect":false},{"id":"opt-3","text":"Docker, containerd, CRI-O","isCorrect":false}],"explanation":"","difficulty":"intermediate"},{"id":"tq-gh-49","questionId":"gh-49","question":"What is Helm in the context of Kubernetes?","type":"single","options":[{"id":"opt-0","text":"A package manager for Kubernetes applications","isCorrect":true},{"id":"opt-1","text":"A container runtime for Kubernetes","isCorrect":false},{"id":"opt-2","text":"A monitoring tool for Kubernetes clusters","isCorrect":false},{"id":"opt-3","text":"A network plugin for Kubernetes","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-gh-48","questionId":"gh-48","question":"How do DaemonSets work in Kubernetes?","type":"single","options":[{"id":"opt-0","text":"They run pods only on specific nodes","isCorrect":false},{"id":"opt-1","text":"They ensure all nodes run a pod copy","isCorrect":true},{"id":"opt-2","text":"They run pods based on resource availability","isCorrect":false},{"id":"opt-3","text":"They run pods only on master nodes","isCorrect":false}],"explanation":"","difficulty":"advanced"},{"id":"tq-de-135","questionId":"de-135","question":"How would you deploy different configurations for staging and production environments using Helm?","type":"single","options":[{"id":"opt-0","text":"Use separate Helm charts for each environment","isCorrect":false},{"id":"opt-1","text":"Use values-staging.yaml and values-production.yaml files with helm install -f","isCorrect":true},{"id":"opt-2","text":"Modify the chart templates directly for each environment","isCorrect":false},{"id":"opt-3","text":"Use environment variables in the deployment command","isCorrect":false}],"explanation":"","difficulty":"intermediate"}],"passingScore":70,"createdAt":"2025-12-18T10:06:46.302Z","lastUpdated":"2025-12-27T02:23:46.055Z","version":1},{"id":"test-sre","channelId":"sre","channelName":"SRE","title":"SRE Knowledge Test","description":"Test your SRE knowledge.","questions":[{"id":"tq-gh-65","questionId":"gh-65","question":"What is Mean Time to Recovery (MTTR) and why is it critical for SRE teams?","type":"single","options":[{"id":"opt-0","text":"The average time to detect system failures","isCorrect":false},{"id":"opt-1","text":"The average time to recover from system failures","isCorrect":true},{"id":"opt-2","text":"The maximum time allowed for recovery","isCorrect":false},{"id":"opt-3","text":"The time between system deployments","isCorrect":false}],"explanation":"MTTR measures the average time to recover from system failures, indicating team efficiency in incident resolution.","difficulty":"beginner"},{"id":"tq-sr-126","questionId":"sr-126","question":"What makes a good blameless postmortem?","type":"single","options":[{"id":"opt-0","text":"Focus on identifying individuals responsible for failures","isCorrect":false},{"id":"opt-1","text":"Focus on systems and processes, not individuals","isCorrect":true},{"id":"opt-2","text":"Only document what went wrong without solutions","isCorrect":false},{"id":"opt-3","text":"Skip root cause analysis to save time","isCorrect":false}],"explanation":"A good blameless postmortem focuses on systems and processes, identifying root causes and actionable improvements.","difficulty":"advanced"},{"id":"tq-q-290","questionId":"q-290","question":"What is the difference between SLI, SLO, and SLA in reliability engineering?","type":"single","options":[{"id":"opt-0","text":"SLI: Service Level Agreement, SLO: Service Level Indicator, SLA: Service Level Objective","isCorrect":false},{"id":"opt-1","text":"SLI: Service Level Indicator, SLO: Service Level Objective, SLA: Service Level Agreement","isCorrect":true},{"id":"opt-2","text":"SLI: Service Level Objective, SLO: Service Level Agreement, SLA: Service Level Indicator","isCorrect":false},{"id":"opt-3","text":"All three terms mean the same thing","isCorrect":false}],"explanation":"SLI measures service performance, SLO defines target reliability, and SLA is a formal agreement with customers.","difficulty":"beginner"},{"id":"tq-gh-77","questionId":"gh-77","question":"What is an Error Budget and how does it impact SRE decision-making?","type":"single","options":[{"id":"opt-0","text":"The total budget allocated for monitoring tools","isCorrect":false},{"id":"opt-1","text":"The allowable downtime for a service based on its SLO","isCorrect":true},{"id":"opt-2","text":"The budget for hiring SRE team members","isCorrect":false},{"id":"opt-3","text":"The cost of implementing monitoring solutions","isCorrect":false}],"explanation":"An Error Budget is the allowable downtime for a service based on its SLO, balancing reliability with feature development velocity.","difficulty":"intermediate"},{"id":"tq-gh-62","questionId":"gh-62","question":"What's the difference between logs, metrics, and traces in observability?","type":"single","options":[{"id":"opt-0","text":"Logs: numbers over time, Metrics: events, Traces: request journeys","isCorrect":false},{"id":"opt-1","text":"Logs: events, Metrics: numbers over time, Traces: request journeys","isCorrect":true},{"id":"opt-2","text":"Logs: request journeys, Metrics: events, Traces: numbers over time","isCorrect":false},{"id":"opt-3","text":"All three serve the same purpose","isCorrect":false}],"explanation":"Logs capture events, metrics track numbers over time, and traces follow request journeys through systems.","difficulty":"beginner"},{"id":"tq-sr-133","questionId":"sr-133","question":"Your SLO is 99.9% for API latency (p95 < 200ms). You're at 99.85% and have 15% error budget remaining. What should you do?","type":"single","options":[{"id":"opt-0","text":"Continue normal operations","isCorrect":false},{"id":"opt-1","text":"Request temporary SLO exception, increase capacity, monitor p95 latency, rollback if budget exhausted","isCorrect":true},{"id":"opt-2","text":"Immediately rollback all changes","isCorrect":false},{"id":"opt-3","text":"Ignore the SLO and focus on features","isCorrect":false}],"explanation":"Request temporary SLO exception, increase capacity, monitor p95 latency, and rollback if error budget is exhausted.","difficulty":"beginner"},{"id":"tq-q-355","questionId":"q-355","question":"How do Incident Response Playbooks automate security incident workflows?","type":"single","options":[{"id":"opt-0","text":"By requiring manual intervention for every step","isCorrect":false},{"id":"opt-1","text":"Through predefined procedures with role-based actions, decision trees, and escalation paths","isCorrect":true},{"id":"opt-2","text":"By eliminating all human involvement","isCorrect":false},{"id":"opt-3","text":"Through random response patterns","isCorrect":false}],"explanation":"Incident Response Playbooks use predefined procedures to automate workflows with role-based actions, decision trees, and escalation paths.","difficulty":"advanced"},{"id":"tq-gh-97","questionId":"gh-97","question":"Your SLO for API response time is 99.9% with a 500ms threshold. You're at 99.7% and the error budget is nearly exhausted. What's your approach?","type":"single","options":[{"id":"opt-0","text":"Continue deploying new features","isCorrect":false},{"id":"opt-1","text":"Implement feature freeze, analyze bottlenecks, optimize services, then gradual canary deployment","isCorrect":true},{"id":"opt-2","text":"Increase the SLO threshold","isCorrect":false},{"id":"opt-3","text":"Ignore the performance issues","isCorrect":false}],"explanation":"Implement feature freeze, analyze performance bottlenecks, optimize existing services, then gradually roll out features with canary deployment.","difficulty":"advanced"},{"id":"tq-q-333","questionId":"q-333","question":"What is a Service Level Objective (SLO) and how does it differ from an SLA?","type":"single","options":[{"id":"opt-0","text":"SLO: Customer-facing agreement, SLA: Internal target","isCorrect":false},{"id":"opt-1","text":"SLO: Internal reliability target, SLA: Customer-facing agreement","isCorrect":true},{"id":"opt-2","text":"SLO and SLA are identical","isCorrect":false},{"id":"opt-3","text":"SLO: Legal document, SLA: Technical metric","isCorrect":false}],"explanation":"An SLO is an internal reliability target defining expected service levels, while an SLA is a customer-facing formal agreement.","difficulty":"intermediate"},{"id":"tq-sr-146","questionId":"sr-146","question":"How would you design a chaos engineering experiment to test database failover while maintaining transactions?","type":"single","options":[{"id":"opt-0","text":"Use uncontrolled pod termination without safeguards","isCorrect":false},{"id":"opt-1","text":"Use controlled pod termination with circuit breakers, distributed transactions, and health checks","isCorrect":true},{"id":"opt-2","text":"Skip testing and hope for the best","isCorrect":false},{"id":"opt-3","text":"Test only during production hours","isCorrect":false}],"explanation":"Use controlled pod termination with circuit breakers, distributed transactions, and health checks to verify ACID compliance during failover.","difficulty":"advanced"},{"id":"tq-sr-147","questionId":"sr-147","question":"Your API service has an SLO of 99.9% availability. If you have 5 incidents this month with downtimes of 10, 8, 12, 15, and 5 minutes respectively, have you met your SLO?","type":"single","options":[{"id":"opt-0","text":"Yes, total downtime is acceptable","isCorrect":false},{"id":"opt-1","text":"No, total downtime violates SLO","isCorrect":true},{"id":"opt-2","text":"Maybe, need more data","isCorrect":false},{"id":"opt-3","text":"SLO doesn't apply to downtime","isCorrect":false}],"explanation":"No. Total downtime: 50min out of 43,200min = 99.88% availability, which violates the 99.9% SLO.","difficulty":"advanced"},{"id":"tq-gh-35","questionId":"gh-35","question":"What are Service Level Objectives (SLOs)?","type":"single","options":[{"id":"opt-0","text":"Legal agreements with customers","isCorrect":false},{"id":"opt-1","text":"Tools for monitoring system performance","isCorrect":false},{"id":"opt-2","text":"Specific, measurable targets for service performance","isCorrect":true},{"id":"opt-3","text":"Documentation of system architecture","isCorrect":false}],"explanation":"Service Level Objectives (SLOs) are specific, measurable targets for service performance that teams agree to meet.","difficulty":"beginner"},{"id":"tq-gh-94","questionId":"gh-94","question":"What are Service Level Indicators (SLIs) and how do they differ from SLOs?","type":"single","options":[{"id":"opt-0","text":"SLIs are targets, SLOs are measurements","isCorrect":false},{"id":"opt-1","text":"SLIs are quantitative measures of service performance, SLOs are targets","isCorrect":true},{"id":"opt-2","text":"SLIs and SLOs are identical","isCorrect":false},{"id":"opt-3","text":"SLIs are customer agreements, SLOs are internal metrics","isCorrect":false}],"explanation":"SLIs are quantitative measures of service performance like latency, error rate, or throughput, while SLOs are the targets for those metrics.","difficulty":"advanced"},{"id":"tq-q-391","questionId":"q-391","question":"Explain the key differences between monitoring and logging in DevOps","type":"single","options":[{"id":"opt-0","text":"Monitoring records events, logging tracks metrics","isCorrect":false},{"id":"opt-1","text":"Monitoring tracks real-time metrics, logging records discrete events","isCorrect":true},{"id":"opt-2","text":"Both serve identical purposes","isCorrect":false},{"id":"opt-3","text":"Monitoring is for security, logging is for performance","isCorrect":false}],"explanation":"Monitoring tracks system health and performance metrics in real-time, while logging records discrete events for troubleshooting and analysis.","difficulty":"intermediate"},{"id":"tq-q-218","questionId":"q-218","question":"What is Application Performance Monitoring?","type":"single","options":[{"id":"opt-0","text":"Security monitoring for applications","isCorrect":false},{"id":"opt-1","text":"Collecting and analyzing application performance data to improve user experience","isCorrect":true},{"id":"opt-2","text":"Database backup and recovery","isCorrect":false},{"id":"opt-3","text":"Network traffic analysis","isCorrect":false}],"explanation":"Application Performance Monitoring (APM) collects and analyzes data about application performance and stability to improve user experience.","difficulty":"advanced"},{"id":"tq-sr-169","questionId":"sr-169","question":"What are the four golden signals of monitoring?","type":"single","options":[{"id":"opt-0","text":"CPU, Memory, Disk, Network","isCorrect":false},{"id":"opt-1","text":"Latency, Traffic, Errors, Saturation","isCorrect":true},{"id":"opt-2","text":"Availability, Performance, Security, Scalability","isCorrect":false},{"id":"opt-3","text":"Logs, Metrics, Traces, Alerts","isCorrect":false}],"explanation":"The four golden signals of monitoring are Latency, Traffic, Errors, and Saturation - key metrics for service health.","difficulty":"beginner"},{"id":"tq-sr-131","questionId":"sr-131","question":"What makes a good monitoring strategy in DevOps?","type":"single","options":[{"id":"opt-0","text":"Focus only on system uptime","isCorrect":false},{"id":"opt-1","text":"Monitor everything equally","isCorrect":false},{"id":"opt-2","text":"Balance coverage with relevance, focus on business-critical metrics","isCorrect":true},{"id":"opt-3","text":"Use only one monitoring tool","isCorrect":false}],"explanation":"A good monitoring strategy balances coverage with relevance, focusing on business-critical metrics that matter most.","difficulty":"advanced"},{"id":"tq-gh-60","questionId":"gh-60","question":"How do you determine appropriate SLO targets?","type":"single","options":[{"id":"opt-0","text":"Always aim for 100% regardless of cost","isCorrect":false},{"id":"opt-1","text":"Base targets on business requirements, user experience, and technical feasibility","isCorrect":true},{"id":"opt-2","text":"Use the same targets for all services","isCorrect":false},{"id":"opt-3","text":"Set targets without measuring current performance","isCorrect":false}],"explanation":"SLO targets should be based on business requirements, user experience needs, and technical feasibility rather than arbitrary perfection.","difficulty":"intermediate"},{"id":"tq-gh-61","questionId":"gh-61","question":"What is the primary purpose of error budgets?","type":"single","options":[{"id":"opt-0","text":"To track team performance metrics","isCorrect":false},{"id":"opt-1","text":"To balance reliability with innovation velocity","isCorrect":true},{"id":"opt-2","text":"To document all system failures","isCorrect":false},{"id":"opt-3","text":"To allocate budget for monitoring tools","isCorrect":false}],"explanation":"Error budgets balance reliability with innovation velocity by allowing controlled failures while maintaining overall service quality.","difficulty":"intermediate"},{"id":"tq-gh-23","questionId":"gh-23","question":"How should teams approach incident response?","type":"single","options":[{"id":"opt-0","text":"Blame individuals for failures","isCorrect":false},{"id":"opt-1","text":"Focus on learning and system improvements","isCorrect":true},{"id":"opt-2","text":"Hide incidents from stakeholders","isCorrect":false},{"id":"opt-3","text":"Skip documentation to save time","isCorrect":false}],"explanation":"Teams should focus on learning and system improvements rather than blaming individuals when responding to incidents.","difficulty":"intermediate"},{"id":"tq-sr-153","questionId":"sr-153","question":"What role does automation play in modern monitoring?","type":"single","options":[{"id":"opt-0","text":"Automation should be avoided in monitoring","isCorrect":false},{"id":"opt-1","text":"Automation enables scalable, consistent monitoring and alerting","isCorrect":true},{"id":"opt-2","text":"Manual monitoring is more reliable than automation","isCorrect":false},{"id":"opt-3","text":"Automation is only useful for large systems","isCorrect":false}],"explanation":"Automation enables scalable, consistent monitoring and alerting that can handle complex systems at scale.","difficulty":"intermediate"},{"id":"tq-gh-79","questionId":"gh-79","question":"How do you ensure monitoring provides actionable insights?","type":"single","options":[{"id":"opt-0","text":"Monitor everything without filtering","isCorrect":false},{"id":"opt-1","text":"Focus on metrics that drive meaningful actions and improvements","isCorrect":true},{"id":"opt-2","text":"Use complex dashboards with many metrics","isCorrect":false},{"id":"opt-3","text":"Monitor only during business hours","isCorrect":false}],"explanation":"Focus on metrics that drive meaningful actions and improvements rather than collecting data without purpose.","difficulty":"beginner"},{"id":"tq-sr-124","questionId":"sr-124","question":"What is the relationship between observability and monitoring?","type":"single","options":[{"id":"opt-0","text":"Observability replaces monitoring entirely","isCorrect":false},{"id":"opt-1","text":"Monitoring is a subset of observability","isCorrect":true},{"id":"opt-2","text":"They are unrelated concepts","isCorrect":false},{"id":"opt-3","text":"Observability is only for debugging, monitoring is for operations","isCorrect":false}],"explanation":"Monitoring is a subset of observability - while monitoring tracks known metrics, observability provides the ability to understand any system state through collected data.","difficulty":"beginner"}],"passingScore":70,"createdAt":"2025-12-21T09:17:23.066Z","lastUpdated":"2025-12-27T02:23:46.227Z","version":1},{"id":"test-system-design","channelId":"system-design","channelName":"System Design","title":"System Design Knowledge Test","description":"Test your System Design knowledge.","questions":[{"id":"tq-sd-5","questionId":"sd-5","question":"What is the primary purpose of Rate Limiting in network systems?","type":"single","options":[{"id":"opt-0","text":"To control the amount of traffic sent or received","isCorrect":true},{"id":"opt-1","text":"To encrypt network communications","isCorrect":false},{"id":"opt-2","text":"To balance load across servers","isCorrect":false},{"id":"opt-3","text":"To cache frequently accessed data","isCorrect":false}],"explanation":"Rate Limiting controls the amount of traffic sent or received by a network interface controller.","difficulty":"advanced"},{"id":"tq-sd-2","questionId":"sd-2","question":"How does Consistent Hashing minimize data movement when scaling distributed caches?","type":"single","options":[{"id":"opt-0","text":"By mapping keys to a ring of nodes","isCorrect":true},{"id":"opt-1","text":"By using random key distribution","isCorrect":false},{"id":"opt-2","text":"By replicating all data to all nodes","isCorrect":false},{"id":"opt-3","text":"By hashing only node identifiers","isCorrect":false}],"explanation":"Consistent Hashing maps keys to a ring of nodes to minimize data movement when scaling.","difficulty":"advanced"},{"id":"tq-q-339","questionId":"q-339","question":"Which HTTP method would you use to create a new task in a REST API?","type":"single","options":[{"id":"opt-0","text":"POST /tasks","isCorrect":true},{"id":"opt-1","text":"GET /tasks","isCorrect":false},{"id":"opt-2","text":"PUT /tasks","isCorrect":false},{"id":"opt-3","text":"DELETE /tasks","isCorrect":false}],"explanation":"Use REST: GET /tasks (list), POST /tasks (create), GET /tasks/:id (read), PUT /tasks/:id (update), DELETE /tasks/:id (delete).","difficulty":"beginner"},{"id":"tq-q-189","questionId":"q-189","question":"How does the Saga pattern handle failures in distributed transactions?","type":"single","options":[{"id":"opt-0","text":"By using compensating actions to rollback","isCorrect":true},{"id":"opt-1","text":"By retrying failed operations indefinitely","isCorrect":false},{"id":"opt-2","text":"By ignoring failed operations","isCorrect":false},{"id":"opt-3","text":"By using two-phase commit protocol","isCorrect":false}],"explanation":"Saga breaks transactions into local operations with compensating actions to rollback if any step fails.","difficulty":"beginner"},{"id":"tq-sy-158","questionId":"sy-158","question":"What algorithm is recommended for a distributed rate limiter handling 1M requests/second?","type":"single","options":[{"id":"opt-0","text":"Sliding window with token bucket","isCorrect":true},{"id":"opt-1","text":"Fixed window counter","isCorrect":false},{"id":"opt-2","text":"Leaky bucket algorithm","isCorrect":false},{"id":"opt-3","text":"Simple counter with mutex","isCorrect":false}],"explanation":"Use local counters with async gossip protocol, sliding window algorithm, and token bucket with eventual consistency guarantees.","difficulty":"advanced"},{"id":"tq-q-169","questionId":"q-169","question":"What is the key difference between cache-aside and read-through caching patterns?","type":"single","options":[{"id":"opt-0","text":"Application manages cache vs automatic cache handling","isCorrect":true},{"id":"opt-1","text":"Cache location differences","isCorrect":false},{"id":"opt-2","text":"Cache size differences","isCorrect":false},{"id":"opt-3","text":"Cache invalidation strategies","isCorrect":false}],"explanation":"Cache-aside requires app to manage cache, while read-through handles cache automatically.","difficulty":"beginner"},{"id":"tq-q-282","questionId":"q-282","question":"What is the main benefit of event sourcing in distributed systems?","type":"single","options":[{"id":"opt-0","text":"Immutable events enable audit trails and replayability","isCorrect":true},{"id":"opt-1","text":"Faster database writes","isCorrect":false},{"id":"opt-2","text":"Reduced network latency","isCorrect":false},{"id":"opt-3","text":"Simplified database schema","isCorrect":false}],"explanation":"Event sourcing stores state changes as immutable events, enabling audit trails, replayability, and temporal queries.","difficulty":"intermediate"},{"id":"tq-sy-151","questionId":"sy-151","question":"Which algorithm is best for multi-tenant rate limiting with different customer limits?","type":"single","options":[{"id":"opt-0","text":"Token bucket with Redis","isCorrect":true},{"id":"opt-1","text":"Fixed window counter","isCorrect":false},{"id":"opt-2","text":"Sliding window with local storage","isCorrect":false},{"id":"opt-3","text":"Rate limiting by IP only","isCorrect":false}],"explanation":"Use token bucket algorithm with Redis, API key middleware, and tiered limit configs stored in DB with in-memory cache for fast lookups.","difficulty":"intermediate"},{"id":"tq-gh-33","questionId":"gh-33","question":"Which load balancing algorithm distributes requests sequentially to each server?","type":"single","options":[{"id":"opt-0","text":"Round-robin","isCorrect":true},{"id":"opt-1","text":"Least connections","isCorrect":false},{"id":"opt-2","text":"Weighted round-robin","isCorrect":false},{"id":"opt-3","text":"Random","isCorrect":false}],"explanation":"Load balancing algorithms distribute client requests across multiple servers using different strategies like round-robin, least connections, or weight.","difficulty":"advanced"},{"id":"tq-sy-140","questionId":"sy-140","question":"What architecture is recommended for handling 10 million requests per second with rate limiting?","type":"single","options":[{"id":"opt-0","text":"Redis Cluster with Consistent Hashing + Local Caching","isCorrect":true},{"id":"opt-1","text":"Single Redis instance","isCorrect":false},{"id":"opt-2","text":"Database-backed rate limiting","isCorrect":false},{"id":"opt-3","text":"In-memory only rate limiting","isCorrect":false}],"explanation":"Use Redis Cluster with Consistent Hashing + Local Caching + Adaptive Rate Limiting with Hierarchical Rate Limiting (user → API → global).","difficulty":"advanced"},{"id":"tq-q-231","questionId":"q-231","question":"How should cache purging be handled for multi-region CDN content updates?","type":"single","options":[{"id":"opt-0","text":"Invalidation API with distributed cache headers","isCorrect":true},{"id":"opt-1","text":"Manual cache clearing","isCorrect":false},{"id":"opt-2","text":"Time-based expiration only","isCorrect":false},{"id":"opt-3","text":"Database-triggered purging","isCorrect":false}],"explanation":"Use invalidation API with distributed cache headers and edge compute for coordinated purging across regions.","difficulty":"intermediate"},{"id":"tq-sd-3","questionId":"sd-3","question":"According to CAP Theorem, what must distributed systems handle in reality?","type":"single","options":[{"id":"opt-0","text":"Network partitions","isCorrect":true},{"id":"opt-1","text":"Consistency requirements","isCorrect":false},{"id":"opt-2","text":"Availability guarantees","isCorrect":false},{"id":"opt-3","text":"All three simultaneously","isCorrect":false}],"explanation":"CAP states distributed systems can only guarantee 2 of 3: Consistency, Availability, Partition Tolerance. In reality, you must handle partitions, so i","difficulty":"advanced"},{"id":"tq-sy-171","questionId":"sy-171","question":"What provides strong consistency in globally distributed database systems?","type":"single","options":[{"id":"opt-0","text":"Consensus-based replication with quorum writes","isCorrect":true},{"id":"opt-1","text":"Eventual consistency","isCorrect":false},{"id":"opt-2","text":"Master-slave replication","isCorrect":false},{"id":"opt-3","text":"Sharding without replication","isCorrect":false}],"explanation":"Use consensus-based replication with quorum writes, geo-distributed nodes, and intelligent routing with local read caches.","difficulty":"advanced"},{"id":"tq-q-223","questionId":"q-223","question":"What enables dynamic metric adjustment in production-scale evaluation pipelines?","type":"single","options":[{"id":"opt-0","text":"Multi-metric streaming pipeline with adaptive weighting","isCorrect":true},{"id":"opt-1","text":"Static metric definitions","isCorrect":false},{"id":"opt-2","text":"Single metric evaluation","isCorrect":false},{"id":"opt-3","text":"Manual metric tuning","isCorrect":false}],"explanation":"Implement a multi-metric streaming pipeline with adaptive weighting, using precomputed confusion matrices and metric caching for real-time evaluation.","difficulty":"advanced"},{"id":"tq-sy-137","questionId":"sy-137","question":"What provides exactly-once processing guarantees for event streams?","type":"single","options":[{"id":"opt-0","text":"Vector clocks with deterministic IDs and idempotent processors","isCorrect":true},{"id":"opt-1","text":"At-least-once delivery","isCorrect":false},{"id":"opt-2","text":"Best-effort delivery","isCorrect":false},{"id":"opt-3","text":"Simple message queuing","isCorrect":false}],"explanation":"Use vector clocks for causal ordering, deterministic IDs for deduplication, and idempotent processors with write-ahead logs.","difficulty":"advanced"},{"id":"tq-sy-169","questionId":"sy-169","question":"What are the essential components for a URL shortening service?","type":"single","options":[{"id":"opt-0","text":"Database, API server, web interface, cache","isCorrect":true},{"id":"opt-1","text":"Only database and API server","isCorrect":false},{"id":"opt-2","text":"Web interface only","isCorrect":false},{"id":"opt-3","text":"Cache only","isCorrect":false}],"explanation":"Database for mappings, API server for redirects, web interface for users, cache for performance.","difficulty":"beginner"},{"id":"tq-q-313","questionId":"q-313","question":"What enables conflict resolution in distributed chat systems?","type":"single","options":[{"id":"opt-0","text":"Event sourcing with CRDTs","isCorrect":true},{"id":"opt-1","text":"Centralized database","isCorrect":false},{"id":"opt-2","text":"Simple message broadcasting","isCorrect":false},{"id":"opt-3","text":"No conflict resolution needed","isCorrect":false}],"explanation":"Use event sourcing with CRDTs for conflict resolution, partition by channel, and implement leader election for consensus.","difficulty":"advanced"},{"id":"tq-q-299","questionId":"q-299","question":"What is the recommended caching strategy for high-traffic e-commerce websites?","type":"single","options":[{"id":"opt-0","text":"Multi-tier: CDN + Redis + application cache","isCorrect":true},{"id":"opt-1","text":"Single cache layer","isCorrect":false},{"id":"opt-2","text":"Database only","isCorrect":false},{"id":"opt-3","text":"Client-side caching only","isCorrect":false}],"explanation":"Use multi-tier caching: CDN for static assets, Redis for session data, and application-level cache for database queries with TTL-based invalidation.","difficulty":"beginner"},{"id":"tq-sy-139","questionId":"sy-139","question":"What algorithm supports burst capacity in multi-tenant rate limiting?","type":"single","options":[{"id":"opt-0","text":"Distributed token bucket with Redis","isCorrect":true},{"id":"opt-1","text":"Fixed window counter","isCorrect":false},{"id":"opt-2","text":"Simple rate limiting","isCorrect":false},{"id":"opt-3","text":"No burst capacity support","isCorrect":false}],"explanation":"Distributed token bucket with Redis-backed state, tenant-specific configs, and local caches for performance","difficulty":"advanced"},{"id":"tq-q-361","questionId":"q-361","question":"What system is recommended for processing 10M financial transactions per hour?","type":"single","options":[{"id":"opt-0","text":"Kafka with idempotent producers and transactional APIs","isCorrect":true},{"id":"opt-1","text":"Simple message queue","isCorrect":false},{"id":"opt-2","text":"Database transactions only","isCorrect":false},{"id":"opt-3","text":"In-memory processing","isCorrect":false}],"explanation":"Implement Kafka with idempotent producers, transactional APIs, and compacted topics for deduplication. Use consumer groups with offset management and","difficulty":"advanced"},{"id":"tq-q-376","questionId":"q-376","question":"What load balancing approach handles 50M concurrent users during peak traffic?","type":"single","options":[{"id":"opt-0","text":"Multi-layer: DNS round-robin + L7 proxies + auto-scaling","isCorrect":true},{"id":"opt-1","text":"Single load balancer","isCorrect":false},{"id":"opt-2","text":"No load balancing needed","isCorrect":false},{"id":"opt-3","text":"Client-side load balancing only","isCorrect":false}],"explanation":"Implement multi-layer load balancing with DNS round-robin, geo-distributed L7 proxies, health checks, and auto-scaling with circuit breakers.","difficulty":"advanced"},{"id":"tq-sy-144","questionId":"sy-144","question":"What architecture handles 1M+ requests per second across multiple data centers?","type":"single","options":[{"id":"opt-0","text":"Sliding window counters with Redis Cluster and consistent hashing","isCorrect":true},{"id":"opt-1","text":"Single Redis instance","isCorrect":false},{"id":"opt-2","text":"Database-backed rate limiting","isCorrect":false},{"id":"opt-3","text":"Local rate limiting only","isCorrect":false}],"explanation":"Use sliding window counters with Redis Cluster, consistent hashing, and circuit breakers with jittered backoff for cache miss protection.","difficulty":"advanced"},{"id":"tq-sy-138","questionId":"sy-138","question":"What rate limiting design handles 10M requests per minute across 100+ microservices?","type":"single","options":[{"id":"opt-0","text":"Token bucket with Redis cluster and hierarchical rate limiting","isCorrect":true},{"id":"opt-1","text":"Simple rate limiting","isCorrect":false},{"id":"opt-2","text":"Database-backed rate limiting","isCorrect":false},{"id":"opt-3","text":"No rate limiting needed","isCorrect":false}],"explanation":"Use token bucket algorithm with Redis cluster, local caching, and hierarchical rate limiting (global + per-service + per-key).","difficulty":"advanced"},{"id":"tq-q-213","questionId":"q-213","question":"What provides comprehensive multi-tier caching with fallback mechanisms?","type":"single","options":[{"id":"opt-0","text":"CDN + Redis cluster + local cache with write-through and circuit breakers","isCorrect":true},{"id":"opt-1","text":"Single cache layer","isCorrect":false},{"id":"opt-2","text":"Database only","isCorrect":false},{"id":"opt-3","text":"Client-side caching only","isCorrect":false}],"explanation":"Implement CDN + Redis cluster + local cache with write-through, TTL-based invalidation, and circuit breakers for fallback.","difficulty":"advanced"},{"id":"tq-q-285","questionId":"q-285","question":"What is the key architectural difference between NGINX and HAProxy for load balancing?","type":"single","options":[{"id":"opt-0","text":"NGINX uses event-driven architecture, HAProxy uses epoll","isCorrect":true},{"id":"opt-1","text":"NGINX is for TCP only, HAProxy for HTTP only","isCorrect":false},{"id":"opt-2","text":"NGINX uses threads, HAProxy uses processes","isCorrect":false},{"id":"opt-3","text":"No significant difference","isCorrect":false}],"explanation":"NGINX uses event-driven architecture with worker processes, while HAProxy uses epoll for high concurrency. NGINX better for HTTP, HAProxy for TCP.","difficulty":"intermediate"}],"passingScore":70,"createdAt":"2025-12-21T09:17:48.005Z","lastUpdated":null,"version":1},{"id":"test-machine-learning","channelId":"machine-learning","channelName":"machine-learning","title":"machine-learning Knowledge Test","description":"Test your machine-learning knowledge.","questions":[{"id":"tq-q-201","questionId":"q-201","question":"How does an LSTM cell's forget gate regulate information flow compared to a simple RNN?","type":"single","options":[{"id":"opt-0","text":"LSTM forget gate uses sigmoid to selectively discard previous cell state, preventing vanishing gradients","isCorrect":true},{"id":"opt-1","text":"LSTM forget gate uses tanh to amplify previous cell state","isCorrect":false},{"id":"opt-2","text":"LSTM forget gate uses ReLU to filter previous cell state","isCorrect":false},{"id":"opt-3","text":"LSTM forget gate uses softmax to weight previous cell state","isCorrect":false}],"explanation":"LSTM forget gate uses sigmoid to selectively discard previous cell state, preventing vanishing gradients unlike simple RNNs.","difficulty":"beginner"},{"id":"tq-q-273","questionId":"q-273","question":"What's the difference between hyperparameters and parameters in machine learning?","type":"single","options":[{"id":"opt-0","text":"Parameters are learned during training, hyperparameters are set before training","isCorrect":true},{"id":"opt-1","text":"Hyperparameters are learned during training, parameters are set before training","isCorrect":false},{"id":"opt-2","text":"Both are learned during training","isCorrect":false},{"id":"opt-3","text":"Both are set before training","isCorrect":false}],"explanation":"Parameters are learned during training, hyperparameters are set before training. Cross-validation prevents overfitting by testing hyperparameters on multiple data splits.","difficulty":"beginner"},{"id":"tq-q-227","questionId":"q-227","question":"How would you implement dynamic quantization-aware training with mixed-precision to optimize inference?","type":"single","options":[{"id":"opt-0","text":"Use per-layer mixed-precision quantization with hardware-aware calibration and accuracy-aware layer selection","isCorrect":true},{"id":"opt-1","text":"Use uniform quantization across all layers","isCorrect":false},{"id":"opt-2","text":"Use post-training quantization only","isCorrect":false},{"id":"opt-3","text":"Use static precision without calibration","isCorrect":false}],"explanation":"Use per-layer mixed-precision quantization with hardware-aware calibration and accuracy-aware layer selection to balance latency and accuracy.","difficulty":"advanced"},{"id":"tq-q-323","questionId":"q-323","question":"How would you design an ML pipeline using Kubeflow that handles model versioning, A/B testing, and automated rollback?","type":"single","options":[{"id":"opt-0","text":"Use Kubeflow Pipelines with MLflow tracking, deploy models via KFServing, implement canary deployments with Istio, and monitor metrics for automated rollback","isCorrect":true},{"id":"opt-1","text":"Use only Kubeflow without MLflow integration","isCorrect":false},{"id":"opt-2","text":"Use manual deployment without monitoring","isCorrect":false},{"id":"opt-3","text":"Use single model deployment without versioning","isCorrect":false}],"explanation":"Use Kubeflow Pipelines with MLflow tracking, deploy models via KFServing, implement canary deployments with Istio, and monitor metrics for automated rollback.","difficulty":"advanced"},{"id":"tq-q-294","questionId":"q-294","question":"How does the attention mechanism in transformers allow the model to handle variable-length sequences efficiently?","type":"single","options":[{"id":"opt-0","text":"Attention computes weighted sums of all input tokens simultaneously, enabling parallel processing","isCorrect":true},{"id":"opt-1","text":"Attention processes tokens sequentially like RNNs","isCorrect":false},{"id":"opt-2","text":"Attention uses fixed-size windows only","isCorrect":false},{"id":"opt-3","text":"Attention requires padding to fixed lengths","isCorrect":false}],"explanation":"Attention computes weighted sums of all input tokens simultaneously, enabling parallel processing of variable-length sequences without sequential dependencies.","difficulty":"intermediate"},{"id":"tq-q-336","questionId":"q-336","question":"You're evaluating a movie recommendation system at Warner Bros. The system has 95% accuracy but poor precision for popular movies. What should you do?","type":"single","options":[{"id":"opt-0","text":"Analyze precision-recall curve, identify threshold issues, adjust decision boundary or use class weighting","isCorrect":true},{"id":"opt-1","text":"Increase accuracy threshold only","isCorrect":false},{"id":"opt-2","text":"Remove popular movies from dataset","isCorrect":false},{"id":"opt-3","text":"Use accuracy as sole metric","isCorrect":false}],"explanation":"Analyze precision-recall curve, identify threshold issues, adjust decision boundary or use class weighting to improve precision for popular movies.","difficulty":"intermediate"},{"id":"tq-q-274","questionId":"q-274","question":"How would you implement a hybrid CNN architecture combining ResNet residual connections with EfficientNet's compound scaling?","type":"single","options":[{"id":"opt-0","text":"Use ResNet blocks with channel attention, apply EfficientNet's compound scaling formula φ = α^β · γ^φ, and optimize with mixed precision","isCorrect":true},{"id":"opt-1","text":"Use only ResNet blocks without scaling","isCorrect":false},{"id":"opt-2","text":"Use only EfficientNet without residual connections","isCorrect":false},{"id":"opt-3","text":"Use simple CNN without hybrid approach","isCorrect":false}],"explanation":"Use ResNet blocks with channel attention, apply EfficientNet's compound scaling formula φ = α^β · γ^φ, and optimize with mixed precision.","difficulty":"intermediate"},{"id":"tq-q-386","questionId":"q-386","question":"You're building a fraud detection system for a large e-commerce platform. Your initial model using logistic regression has high false positives. What should you do?","type":"single","options":[{"id":"opt-0","text":"Use Random Forest or Gradient Boosting with class weighting, implement threshold tuning, and add feature engineering for transaction patterns","isCorrect":true},{"id":"opt-1","text":"Continue with logistic regression only","isCorrect":false},{"id":"opt-2","text":"Remove all features except basic ones","isCorrect":false},{"id":"opt-3","text":"Ignore false positive rate","isCorrect":false}],"explanation":"Use Random Forest or Gradient Boosting with class weighting, implement threshold tuning, and add feature engineering for transaction patterns to reduce false positives.","difficulty":"intermediate"},{"id":"tq-q-309","questionId":"q-309","question":"How would you design an MLOps pipeline using MLflow and Kubeflow for a production ML system?","type":"single","options":[{"id":"opt-0","text":"Use MLflow for experiment tracking/model registry, Kubeflow for orchestration, with CI/CD integration and monitoring","isCorrect":true},{"id":"opt-1","text":"Use only MLflow without Kubeflow","isCorrect":false},{"id":"opt-2","text":"Use only Kubeflow without MLflow","isCorrect":false},{"id":"opt-3","text":"Use manual processes without automation","isCorrect":false}],"explanation":"Use MLflow for experiment tracking/model registry, Kubeflow for orchestration, with CI/CD integration and monitoring.","difficulty":"advanced"},{"id":"tq-q-347","questionId":"q-347","question":"You're deploying a machine learning model using MLflow. How would you track experiments and ensure reproducibility?","type":"single","options":[{"id":"opt-0","text":"Use MLflow Tracking to log parameters, metrics, artifacts, and model versions. Register models in MLflow Model Registry for production deployment","isCorrect":true},{"id":"opt-1","text":"Use only local file storage","isCorrect":false},{"id":"opt-2","text":"Skip logging for faster deployment","isCorrect":false},{"id":"opt-3","text":"Use manual tracking only","isCorrect":false}],"explanation":"Use MLflow Tracking to log parameters, metrics, artifacts, and model versions. Register models in MLflow Model Registry for production deployment.","difficulty":"beginner"},{"id":"tq-q-358","questionId":"q-358","question":"You're building a customer churn prediction model. Given a dataset with customer features (age, usage patterns, etc.), which algorithms would be most appropriate?","type":"single","options":[{"id":"opt-0","text":"Use logistic regression for binary churn prediction (yes/no), linear regression for continuous values like predicted churn time or revenue loss","isCorrect":true},{"id":"opt-1","text":"Use only neural networks for all predictions","isCorrect":false},{"id":"opt-2","text":"Use clustering algorithms only","isCorrect":false},{"id":"opt-3","text":"Use unsupervised learning only","isCorrect":false}],"explanation":"Use logistic regression for binary churn prediction (yes/no), linear regression for continuous values like predicted churn time or revenue loss.","difficulty":"beginner"},{"id":"tq-q-254","questionId":"q-254","question":"When implementing a bidirectional GRU vs LSTM for sequence labeling, how do gradient clipping thresholds differ?","type":"single","options":[{"id":"opt-0","text":"Bidirectional GRU needs lower clipping thresholds (1.0-5.0) than LSTM (5.0-10.0) due to fewer parameters","isCorrect":true},{"id":"opt-1","text":"GRU needs higher thresholds than LSTM","isCorrect":false},{"id":"opt-2","text":"Both use same thresholds","isCorrect":false},{"id":"opt-3","text":"GRU doesn't need gradient clipping","isCorrect":false}],"explanation":"Bidirectional GRU needs lower clipping thresholds (1.0-5.0) than LSTM (5.0-10.0) due to fewer parameters, with optimal batch sizes 32-64 for GRU vs 16-32 for LSTM.","difficulty":"intermediate"},{"id":"tq-q-177","questionId":"q-177","question":"What is the primary difference between model serving and model deployment in machine learning?","type":"single","options":[{"id":"opt-0","text":"Deployment is the overall process; serving is the runtime API that provides predictions","isCorrect":true},{"id":"opt-1","text":"Serving is the overall process; deployment is the runtime API","isCorrect":false},{"id":"opt-2","text":"Both are the same thing","isCorrect":false},{"id":"opt-3","text":"Deployment is only about training models","isCorrect":false}],"explanation":"Deployment is the overall process; serving is the runtime API that provides predictions.","difficulty":"beginner"},{"id":"tq-q-195","questionId":"q-195","question":"How would you implement a canary deployment strategy for a TensorFlow model using MLflow and Kubernetes?","type":"single","options":[{"id":"opt-0","text":"Use MLflow model registry with blue-green deployment, Kubernetes traffic splitting, and automated monitoring with Prometheus alerts for rollback triggers","isCorrect":true},{"id":"opt-1","text":"Deploy all traffic at once without monitoring","isCorrect":false},{"id":"opt-2","text":"Use manual rollback only","isCorrect":false},{"id":"opt-3","text":"Skip monitoring in canary deployment","isCorrect":false}],"explanation":"Use MLflow model registry with blue-green deployment, Kubernetes traffic splitting, and automated monitoring with Prometheus alerts for rollback triggers.","difficulty":"intermediate"},{"id":"tq-q-372","questionId":"q-372","question":"You're training a CNN for Snapchat lens effects and notice your validation loss increases after epoch 10 while training loss decreases. What's happening and how do you fix it?","type":"single","options":[{"id":"opt-0","text":"Overfitting. Apply dropout (0.2-0.5), L2 regularization (λ=0.001), and early stopping based on validation loss","isCorrect":true},{"id":"opt-1","text":"Underfitting. Increase model complexity only","isCorrect":false},{"id":"opt-2","text":"Normal behavior. Continue training","isCorrect":false},{"id":"opt-3","text":"Data augmentation issue only","isCorrect":false}],"explanation":"Overfitting. Apply dropout (0.2-0.5), L2 regularization (λ=0.001), and early stopping based on validation loss.","difficulty":"beginner"}],"passingScore":70,"createdAt":"2025-12-21T09:15:44.176Z","lastUpdated":null,"version":1}]