{"questions":[{"id":"azure-ai-engineer-implement-vision-1768206544373-0","question":"Your team is building an AI-powered quality-control system for a consumer electronics assembly line. You plan to use Azure Custom Vision to classify images as Defective or OK. The dataset is highly imbalanced with far more OK images than Defective images. What is the most effective practice to improve defect detection while maintaining performance on OK samples during iterative training?","answer":"[{\"id\":\"a\",\"text\":\"Increase the number of OK images to balance the dataset\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Upweight the Defective class in the training loss to compensate for imbalance\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Collect more Defective samples, annotate them, and retrain with additional iterations\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Lower the confidence threshold for the Defective class across all predictions\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C: Collect more defective samples and retrain with additional iterations to improve recall and generalization.\n\n## Why Other Options Are Wrong\n- A: Merely increasing OK samples does not address the minority class and may reduce the model's ability to detect defects.\n- B: Class weighting may not be exposed or effective in Azure Custom Vision and is not guaranteed to improve real-world performance.\n- D: Lowering the threshold increases false positives, hurting precision on OK samples.\n\n## Key Concepts\n- Handling class imbalance in CV datasets\n- Iterative training in Azure Custom Vision\n- Evaluation metrics (precision, recall, F1) and practical trade-offs\n\n## Real-World Application\n- Improves defect detection on a production line by enriching scarce defect data and re-training to boost sensitivity while preserving performance on normal products.","diagram":null,"difficulty":"intermediate","tags":["Azure","CustomVision","EdgeAI","SageMaker","EKS","Terraform","certification-mcq","domain-weight-20"],"channel":"azure-ai-engineer","subChannel":"implement-vision","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:29:04.377Z","createdAt":"2026-01-12 08:29:04"},{"id":"azure-ai-engineer-implement-vision-1768206544373-1","question":"A manufacturing customer wants to extract vendor name, invoice date, and total amount from supplier invoices, but each vendor uses a different invoice layout. Which Azure AI service and approach best achieves accurate field extraction across layouts?","answer":"[{\"id\":\"a\",\"text\":\"Use the prebuilt Computer Vision OCR to extract raw text and apply custom rules\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Train a Custom Vision model to identify the fields and map them to a standard schema\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use Form Recognizer with a Custom model trained on labeled invoices to map fields to a standard schema\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Use a single object-detection model to locate fields on invoice images\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption C: Use Form Recognizer with a Custom model trained on labeled invoices to map fields to a standard schema.\n\n## Why Other Options Are Wrong\n- A: Prebuilt OCR returns unstructured text, requiring heavy post-processing and lacks reliable field extraction across varied layouts.\n- B: Custom Vision is not designed for structured data extraction from documents; it focuses on visual classification/detection, not form-field mapping.\n- D: Object detection locates regions but does not inherently map to a structured form schema across layouts.\n\n## Key Concepts\n- Form Recognizer vs OCR: structured data extraction\n- Custom model training on multiple invoice layouts\n- Field mapping to a standardized schema for downstream processing\n\n## Real-World Application\n- Automates accounts payable data extraction across diverse vendor formats, improving accuracy and processing speed.","diagram":null,"difficulty":"intermediate","tags":["Azure","FormRecognizer","FormNLP","SageMaker","Terraform","Kubernetes","certification-mcq","domain-weight-20"],"channel":"azure-ai-engineer","subChannel":"implement-vision","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:29:04.766Z","createdAt":"2026-01-12 08:29:05"},{"id":"azure-ai-engineer-implement-vision-1768206544373-2","question":"To enable real-time CV inference on a camera network with limited bandwidth, you decide to run the model on edge devices. Which deployment pathway using Azure tools is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Train a Custom Vision object detector and export the model to ONNX, then deploy to edge devices via Azure IoT Edge for runtime inference\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use Azure Video Analyzer to perform cloud-based analysis on incoming video streams\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use the prebuilt Computer Vision API directly on the edge gateway for each frame\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Train a PyTorch model locally and deploy it to the edge device without Azure integration\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A: Train a Custom Vision object detector and export the model to ONNX, then deploy to edge devices via Azure IoT Edge for runtime inference.\n\n## Why Other Options Are Wrong\n- B: Video Analyzer is optimized for cloud processing and introduces latency for real-time edge use cases.\n- C: The edge gateway would require a compatible runtime; the prebuilt API is not designed for edge runtimes without custom hosting.\n- D: Deploying without Azure integration loses centralized management, updates, and edge orchestration benefits.\n\n## Key Concepts\n- Edge AI deployment with Azure IoT Edge\n- ONNX export for cross-platform runtime\n- Real-time inference with limited bandwidth\n\n## Real-World Application\n- Enables real-time safety and quality monitoring on factory floors with local processing and minimal cloud dependency.","diagram":null,"difficulty":"intermediate","tags":["Azure","CustomVision","IoTEdge","ONNX","SageMaker","EKS","certification-mcq","domain-weight-20"],"channel":"azure-ai-engineer","subChannel":"implement-vision","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:29:05.159Z","createdAt":"2026-01-12 08:29:05"},{"id":"azure-ai-engineer-plan-manage-1768166246486-0","question":"A multinational enterprise runs an Azure OpenAI Service-powered inference layer behind an API gateway for multiple internal customers. They need predictable latency during spiky demand and tight cost control. Which architectural approach best achieves both goals?","answer":"[{\"id\":\"a\",\"text\":\"Deploy a separate OpenAI deployment per tenant and keep them always-on\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Maintain a shared pool of OpenAI deployments behind an API gateway, enforce per-tenant quotas, and enable auto-scaling of deployments to match load\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Prewarm a large number of deployments for all possible peak loads to guarantee latency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Route requests to multiple third-party inference services and pick the fastest one\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because it balances scalability and cost by using a common pool of deployments behind an API gateway, while enforcing per-tenant quotas and enabling autoscale to adapt to load.\n\n## Why Other Options Are Wrong\n- A increases cost and operational complexity and still may not scale efficiently during bursts.\n- C is wasteful and inflexible; it incurs high idle capacity and fails to adapt to unpredictable demand.\n- D introduces security, compliance, and reliability risks and undermines centralized governance.\n\n## Key Concepts\n- Multi-tenant inference architecture\n- OpenAI deployment autoscale\n- API gateway quotas and rate limiting\n- Cost governance for Azure AI\n\n## Real-World Application\n- Implement a shared deployment pool behind API Management with per-tenant quotas; configure autoscale settings to match traffic patterns; monitor latency and cost dashboards to ensure SLA adherence.","diagram":null,"difficulty":"intermediate","tags":["Azure OpenAI Service","Azure ML","Azure Cost Management","Azure API Management","Kubernetes","Terraform","AWS SageMaker","certification-mcq","domain-weight-25"],"channel":"azure-ai-engineer","subChannel":"plan-manage","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T21:17:26.487Z","createdAt":"2026-01-11 21:17:26"},{"id":"azure-ai-engineer-plan-manage-1768166246486-1","question":"Your production model on Azure ML experiences data drift. You want to detect drift automatically and alert team leads when a threshold is exceeded. Which approach is recommended?","answer":"[{\"id\":\"a\",\"text\":\"Build a custom drift detection script and run it on a schedule; email stakeholders when drift is detected\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Azure ML Model Monitoring with data drift detection and alert rules via Azure Monitor\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Explainability metrics to detect drift and send Slack messages\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Do nothing; drift is expected and acceptable in production\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Azure ML Model Monitoring provides built-in data drift detection and can publish alerts via Azure Monitor, enabling proactive governance.\n\n## Why Other Options Are Wrong\n- A is possible but requires custom maintenance and slower reaction times; not as scalable as built-in monitoring.\n- C focuses on explainability, not drift detection; it won't reliably flag distribution changes in input data.\n- D ignores model quality and compliance, risking degraded performance and stakeholder trust.\n\n## Key Concepts\n- Azure ML Model Monitoring\n- Data drift detection signals\n- Azure Monitor alerts\n- Production AI governance\n\n## Real-World Application\n- Enable model monitoring for production endpoints, configure drift thresholds, and wire alerts to on-call channels to respond promptly.","diagram":null,"difficulty":"intermediate","tags":["Azure ML","Azure Monitor","Model Monitoring","Data Drift","Kubernetes","Terraform","AWS SageMaker","certification-mcq","domain-weight-25"],"channel":"azure-ai-engineer","subChannel":"plan-manage","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T21:17:27.054Z","createdAt":"2026-01-11 21:17:27"},{"id":"azure-ai-engineer-plan-manage-1768166246486-2","question":"To manage AI workloads across Azure OpenAI and Azure ML, you want to allocate costs to departments and enforce budgets with minimal friction. Which approach best achieves this in a scalable way?","answer":"[{\"id\":\"a\",\"text\":\"Use Azure Cost Management budgets with tag-based cost allocation and department-scoped dashboards; enforce budgets with alerts and automation to pause non-critical experiments\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Give all teams access to a single large budget and rely on self-regulation\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Manually track costs in spreadsheets and share monthly reports\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Consolidate all AI workloads into a single resource group to simplify billing\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A correctly uses cost management and tagging to attribute costs to departments, with dashboards and alerts to control spend while preserving experimentation.\n\n## Why Other Options Are Wrong\n- B distributes risk and makes governance governance ineffective; budgets are hard to enforce.\n- C is labor-intensive and error-prone; lacks real-time visibility.\n- D oversimplifies billing and hinders granular cost attribution.\n\n## Key Concepts\n- Azure Cost Management and Budgets\n- Resource tagging and cost allocation\n- Department-scoped dashboards and alerts\n- Automation for policy enforcement\n\n## Real-World Application\n- Implement tags for department ownership; configure budgets per department; set up automated actions when budgets are breached to pause or throttle experiments.","diagram":null,"difficulty":"intermediate","tags":["Azure Cost Management","Azure OpenAI Service","Azure ML","Tag-based Cost Allocation","Kubernetes","Terraform","AWS SageMaker","certification-mcq","domain-weight-25"],"channel":"azure-ai-engineer","subChannel":"plan-manage","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T21:17:27.588Z","createdAt":"2026-01-11 21:17:27"}],"subChannels":["implement-vision","plan-manage"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}