{"questions":[{"id":"q-845","question":"In a MongoDB-backed service, read latency tails spike during peak hours. Provide a concrete, practical debugging plan to determine whether the bottleneck is network, driver, query plan, or index design. Include exact steps, metrics to collect, and concrete changes (indexes, readConcern, pooling) you would apply, plus how you would verify impact?","answer":"Collect end-to-end latency, queue depth, and replica lag; enable slow query logs and run explain on top slow queries; verify index coverage with compound indexes; apply index hints or add a composite ","explanation":"## Why This Is Asked\nThis question probes practical debugging of latency in a MongoDB-backed service with real-world constraints.\n\n## Key Concepts\n- Tail latency diagnosis: slow queries, network, driver pool\n- Explain plans and index design: compound indexes, prefix rules\n- Replica lag and read concerns\n- Driver tuning and observability\n\n## Code Example\n```js\ndb.collection(`orders`).find({ userId: id }).explain(`executionStats`);\n```\n\n## Follow-up Questions\n- How would you validate the impact of an index change in production?\n- What metrics would you alert on for sustained tail latency?","diagram":null,"difficulty":"intermediate","tags":["cnpa"],"channel":"cnpa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Lyft","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:43.195Z","createdAt":"2026-01-12T13:28:43.195Z"},{"id":"q-873","question":"A CNPA service receives events over HTTP, writes to PostgreSQL, and publishes to Kafka. During peak hours, read latency spikes. Describe a concrete debugging plan to determine whether the bottleneck is the HTTP handler, the DB query, or the Kafka producer, including exact steps, metrics to collect, and concrete changes (indexes, pooling, prepared statements, idempotent producer) and how you would verify impact?","answer":"Instrument with OpenTelemetry to trace HTTP handler, DB queries, and Kafka publish; collect p95/p99 latency, error rate, and queue backpressure. Reproduce under load (k6). If HTTP slow, tune keep-aliv","explanation":"## Why This Is Asked\nTests practical debugging across a real CNPA pipeline and encourages measurable fixes.\n\n## Key Concepts\n- End-to-end tracing with OpenTelemetry\n- Performance attribution across HTTP, DB, and messaging\n- Idempotent producers and pool tuning\n- Load testing and metrics-driven verification\n\n## Code Example\n```javascript\n// OpenTelemetry tracing skeleton for CNPA flow\nconst { trace } = require('@opentelemetry/api');\nconst tracer = trace.getTracer('cnpa-trace');\nasync function handleEvent(req, res) {\n  await tracer.startActiveSpan('handle_event', async (span) => {\n    await processHttp();\n    await writeDb();\n    await publishKafka();\n    span.end();\n  });\n}\n```\n\n## Follow-up Questions\n- How would you measure impact of a pool size increase?\n- What changes would you apply to avoid future tail latency spikes?","diagram":"flowchart TD\n  A[HTTP Request] --> B[HTTP Handler]\n  B --> C[PostgreSQL]\n  B --> D[Kafka Producer]\n  C --> E[Indexes/Pooling]\n  D --> F[Configs]\n  G[Metrics] --> H[Tail Latency]","difficulty":"beginner","tags":["cnpa"],"channel":"cnpa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Instacart","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:55:00.870Z","createdAt":"2026-01-12T13:55:00.870Z"}],"subChannels":["general"],"companies":["Anthropic","Databricks","Instacart","Lyft","MongoDB","NVIDIA"],"stats":{"total":2,"beginner":1,"intermediate":1,"advanced":0,"newThisWeek":2}}