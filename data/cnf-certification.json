{"questions":[{"id":"q-1019","question":"You're operating a CNF-based API gateway cluster that terminates TLS for thousands of tenants across 3 regions. A mandate requires migrating all TLS to post-quantum algorithms with per-tenant keys sourced from an HSM, while delivering zero-downtime upgrades, per-tenant key isolation, and a rollback plan. Outline an end-to-end rollout including (a) inventory and compatibility checks, (b) PQC algorithm and certificate strategy, (c) HSM PKCS#11 integration and key rotation, (d) canary/traffic-mirror rollout and drift detection, (e) observability and rollback criteria?","answer":"Audit TLS usage per tenant; adopt a hybrid post-quantum TLS approach (Kyber/Dilithium) for session keys and per-tenant certificates; load per-tenant keys from an HSM via PKCS#11 with rotation primitiv","explanation":"## Why This Is Asked\nThis question probes practical expertise in upgrading cryptography without downtime, with tenancy isolation and HSM-backed keys. It tests rollout discipline, drift handling, and observability under real-world regulatory pressure.\n\n## Key Concepts\n- Post-quantum cryptography deployment in live CNFs\n- Per-tenant key material management with HSM (PKCS#11)\n- Zero-downtime, region-wise canary rollouts and drift detection\n- Observability: handshake metrics, cipher adoption, rollback criteria\n\n## Code Example\n```javascript\n// Pseudo-code for config wiring\nconst tlsConfig = {\n  pqc: {\n    enabled: true,\n    suites: ['Kyber512', 'Dilithium3']\n  },\n  hsm: {\n    pkcs11Module: '/usr/lib/softhsm/libsofthsm2.so',\n    slot: 1,\n    pin: 'REDACTED'\n  }\n}\n```\n\n## Follow-up Questions\n- How would you verify compatibility with legacy TLS clients during the migration?\n- How would you measure and bound the impact on tenants during the rollout?","diagram":"flowchart TD\n  A[Inventory TLS usage] --> B[Choose PQC suites]\n  B --> C[HSM PKCS11 integration]\n  C --> D[Canary rollout with traffic mirroring]\n  D --> E[Observability metrics]\n  E --> F[Rollback criteria]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T19:32:58.382Z","createdAt":"2026-01-12T19:32:58.382Z"},{"id":"q-1040","question":"You're deploying a CNF-based UDP gateway across four data centers. A CVE requires hardware-backed attestation before image execution. Outline a concrete end-to-end rollout plan that (a) signs CNF images with Cosign and SBOMs, (b) enforces attestation via TPM 2.0-based attestation bundles and ImagePolicyWebhook, (c) rolls out region-by-region with traffic mirroring and per-tenant quotas, (d) implements drift detection and automated rollback on attestation failure, and (e) provides observability for attestation metrics and rollback triggers?","answer":"Sign CNF images with Cosign and SBOMs, publish to Rekor. Enforce using TPM 2.0 attestation bundles and an ImagePolicyWebhook policy so only attested images execute. Roll out region-by-region with traf","explanation":"## Why This Is Asked\nTests hardware-backed attestation, signing, and policy enforcement in CNF rollouts, plus region-by-region rollout, drift detection, and observability.\n\n## Key Concepts\n- Cosign and SBOMs with Rekor\n- TPM 2.0 attestation\n- Sigstore attestation bundles\n- ImagePolicyWebhook enforcement\n- Traffic mirroring and per-tenant quotas\n- Drift detection and automated rollback\n- Observability: attestation latency, success rate, per-tenant metrics\n\n## Code Example\n```yaml\napiVersion: policy.k8s.io/v1beta1\nkind: ImageReview\nspec:\n  image: <attested-image>\n  attestation: true\n```\n\n## Follow-up Questions\n- How would you test rollback behavior under attestation failure? \n- What metrics would you surface to detect persistent drift?\n","diagram":"flowchart TD\n  A[CNF Image] --> B[Cosign SBOM Sign]\n  B --> C[Publish to Rekor]\n  C --> D[TPM 2.0 Attestation Bundle]\n  D --> E[ImagePolicyWebhook Gate]\n  E --> F[Region 1 Canary with Traffic Mirroring]\n  F --> G[Drift Reconciliation]\n  G --> H[Observability & Rollback Triggers]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T20:28:03.844Z","createdAt":"2026-01-12T20:28:03.844Z"},{"id":"q-1071","question":"You're deploying a CNF-based API gateway across 2 Kubernetes clusters. A recent upgrade causes a cross-tenant data bleed under load due to a shared in-memory cache. Outline a beginner-friendly, end-to-end plan to fix and roll out safely: (a) reproduce in staging with two tenants and isolated traffic, (b) implement tenant-scoped cache keys and per-tenant isolation checks, (c) add unit/integration tests for isolation, (d) perform blue/green canary rollout with tenant-based traffic splits, (e) observability: per-tenant SLA metrics and automatic rollback if bleed is detected. Include a minimal code snippet for tenant-scoped cache key?","answer":"Reproduce with two tenants in separate namespaces, enable per-tenant cache keys (tenant_id + resource_id), add a small unit test asserting no cross-tenant data is returned, roll out a blue/green canar","explanation":"## Why This Is Asked\nThis question probes practical skills in tenant isolation, cache safety, and controlled rollouts, plus test design and observability.\n\n## Key Concepts\n- Multi-tenant isolation\n- Tenant-scoped caching\n- Unit/integration tests for isolation\n- Blue/green canary rollouts with traffic splitting\n- Observability and automatic rollback\n\n## Code Example\n```javascript\nfunction cacheKey(tenantId, resourceId) {\n  return `${tenantId}:${resourceId}`;\n}\n```\n\n## Follow-up Questions\n- How would you monitor cross-tenant bleed in production?\n- How would you adapt the canary ratio if bleed indicators appear?","diagram":"flowchart TD\n  A[Start] --> B[Reproduce in staging]\n  B --> C[Implement tenant cache keys]\n  C --> D[Add tests]\n  D --> E[Blue/Green rollout]\n  E --> F[Observe -> Rollback if needed]\n","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Stripe","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T21:31:42.231Z","createdAt":"2026-01-12T21:31:42.231Z"},{"id":"q-1081","question":"You're deploying a CNF-based API gateway that uses workload identities for tenants. Describe an end-to-end plan to enforce identity attestation and per-tenant isolation using SPIRE for SPIFFE IDs, OPA Gatekeeper for policy decisions, and a local Kind testbed. Include (a) issuing and rotating SVIDs, (b) encoding tenant permissions in policies, (c) testing isolation with two tenants, and (d) observability hooks for attestation and policy evaluations?","answer":"SPIRE issues per-tenant SVIDs with 24h rotation; gateway validates SVIDs; policy via OPA Gatekeeper requires SPIFFE ID prefix spiffe://example.org/tenant-<tenant> and tenant-scoped access; test in Kin","explanation":"## Why This Is Asked\nTests knowledge of workload identity and policy enforcement in CNF deployments.\n\n## Key Concepts\n- SPIRE/SPIFFE identities for CNFs\n- OPA Gatekeeper policy enforcement\n- Per-tenant network isolation\n- Observability hooks (attestation metrics, policy latency)\n\n## Code Example\n```rego\npackage cnf.auth\n\ndefault allow = false\n\nallow {\n  input.spiffe_id.startsWith(\"spiffe://example.org/tenant-\")\n  input.tenant == data.tenants[input.spiffe_id].name\n}\n```\n\n## Follow-up Questions\n- How would you rotate SVIDs with zero downtime?\n- How would you validate policy drift and trigger rollback?","diagram":"flowchart TD\n  A[Start] --> B[SPIRE setup]\n  B --> C[OPA policy]\n  C --> D[Kind tests]\n  D --> E[Observability]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:17:18.359Z","createdAt":"2026-01-12T22:17:18.359Z"},{"id":"q-1107","question":"You're deploying a CNF-based API gateway serving two tenants with strict data-retention and per-tenant log-redaction requirements. Outline an end-to-end plan using SPIRE for workload identities and OPA Gatekeeper for policy decisions to enforce data handling rules while enabling zero-downtime upgrades in a local Kind testbed. Include (a) SVID issuance/rotation tied to tenant IDs, (b) tenant-scoped policies for retention windows and redaction, (c) runtime redaction checks on logs/traces, (d) cross-tenant isolation testing under load, and (e) observability hooks for attestation, policy decisions, and redaction misses?","answer":"Propose a two-tenant end-to-end CNF gateway rollout enforcing per-tenant data-retention and log-redaction policies via SPIRE for workload identities and OPA Gatekeeper for policy decisions. Include SV","explanation":"## Why This Is Asked\n\nThis question tests practical integration of workload identity with policy enforcement in a CNF gateway, emphasizing data governance, per-tenant isolation, and non-disruptive upgrades. It requires concrete steps for credential rotation, policy encoding, runtime checks, and observability.\n\n## Key Concepts\n\n- SPIRE SVIDs and workload attestation for multitenant isolation\n- OPA Gatekeeper policy modeling per tenant (retention windows, redaction rules)\n- Runtime log redaction and per-tenant observability\n- Kind-based local testbed for end-to-end verification\n- Zero-downtime rollout with traffic shaping and drift checks\n\n## Code Example\n\n```javascript\nfunction redactLog(entry, policy) {\n  const redacted = { ...entry };\n  (policy.redactFields || []).forEach(field => {\n    if (redacted.hasOwnProperty(field)) redacted[field] = \"***REDACTED***\";\n  });\n  return redacted;\n}\n```\n\n## Follow-up Questions\n\n- How would you rotate SVIDs across tenants with revocation semantics in SPIRE?\n- How would you validate redaction coverage across logs in CI/CD and production?","diagram":null,"difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T23:16:16.754Z","createdAt":"2026-01-12T23:16:16.754Z"},{"id":"q-1187","question":"A beginner CNF certification scenario: you implement a gated CI/CD pipeline for a CNF gateway image. Outline an end-to-end workflow to ensure image provenance before deployment: (a) sign CNF images with Cosign using a KMS-backed key, (b) generate and publish SBOMs, (c) enforce signatures via ImagePolicyWebhook, and (d) surface observability in the monitoring stack for signing success/failure and rollback signals. Provide concrete steps and minimal config snippets?","answer":"GitHub Actions CI: build CNF image, sign with Cosign using a KMS-backed key, generate and publish SBOMs, update ImagePolicyWebhook to require signed images, gate deployment on attestation success, and","explanation":"## Why This Is Asked\nTests practical understanding of image provenance gates in CNF pipelines, focusing on Cosign, SBOM, ImagePolicyWebhook, and basic observability.\n\n## Key Concepts\n- Cosign signing with a KMS-backed key\n- SBOM generation and publishing\n- ImagePolicyWebhook enforcement\n- Observability signals and rollback triggers\n- CI/CD gating (e.g., GitHub Actions)\n\n## Code Example\n```javascript\n// CI pseudo steps (pseudocode)\nconst signCmd = \"cosign sign --key kms://my/key ghcr.io/org/cnf-image:${process.env.GITHUB_SHA}\";\n```\n\n## Follow-up Questions\n- How would you test the gate without a real deployment?\n- How would you handle Cosign key rotation with zero downtime?","diagram":"flowchart TD\n  CIBuild[CI Build] --> Sign[Cosign Sign]\n  Sign --> SBOM[SBOM Gen & Publish]\n  SBOM --> Policy[ImagePolicyWebhook]\n  Policy --> Deploy[Deploy to Registry]\n  Deploy --> Observability[Observability Signals]\n","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T04:39:07.086Z","createdAt":"2026-01-13T04:39:07.086Z"},{"id":"q-1221","question":"You're operating a CNF-based API gateway deployed across three regions behind a service mesh. Propose a practical upgrade workflow that enforces runtime integrity along with image attestations: (a) sign images with Cosign using a KMS-backed key and publish SBOMs, (b) require TPM/measured-boot attestation plus runtime integrity checks for CNFs, (c) roll out region-by-region with per-tenant canaries and live connection migration, (d) implement drift detection and automatic rollback on attestation/runtime mismatch, (e) surface observability for sign-off, attestation, and rollback triggers. Provide minimal config references?","answer":"Cosign-sign CNF images with a KMS-backed key and publish SBOMs; gate deploys via ImagePolicyWebhook. Enforce TPM/measured-boot attestation plus runtime integrity checks for CNFs. Roll out region-by-re","explanation":"## Why This Is Asked\nTests a concrete upgrade workflow combining image attestation, hardware-backed integrity, and multi-region rollout with per-tenant considerations.\n\n## Key Concepts\n- Image attestation with Cosign and SBOMs\n- TPM/measured boot and runtime integrity checks\n- ImagePolicyWebhook enforcement\n- Canary-based region rollout with live migration\n- Drift detection and automatic rollback\n- Observability for signatures, attestations, rollbacks\n\n## Code Example\n```javascript\n// Minimal policy concept (illustrative)\nconst policy = { requireAttestation: true, requireSBOM: true, tenantIsolation: true }\n```\n\n## Follow-up Questions\n- How would you validate rollback triggers under peak load?\n- What metrics validate attestation health in dashboards?","diagram":"flowchart TD\n  A[Sign image with Cosign] --> B[Publish SBOM]\n  B --> C[ImagePolicyWebhook]\n  C --> D[TPM/measured boot attestation]\n  D --> E[Runtime integrity checks]\n  E --> F[Region-by-region rollout]\n  F --> G[Drift detection]\n  G --> H[Auto rollback]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T05:33:18.061Z","createdAt":"2026-01-13T05:33:18.061Z"},{"id":"q-1347","question":"Advanced CNF certification scenario: deploy a CNF gateway across three air‑gapped data centers. Design an end‑to‑end plan to ensure image provenance and runtime integrity for updates, covering (a) offline Cosign signing with a TPM‑backed key, (b) SBOM generation and private catalog, (c) per‑tenant policy enforcement via OPA/Gatekeeper, (d) edge‑site offline attestation broker, (e) drift detection with automated rollback, and (f) observability hooks. Include concrete config examples?","answer":"Use an offline attestation flow: sign CNF images with Cosign using a TPM-backed key; publish SBOMs to a private catalog; enforce attestation via ImagePolicyWebhook with per-tenant OPA policies; deploy","explanation":"## Why This Is Asked\n\nThis question probes offline attestation, edge CNF deployment, and policy-driven updates in air‑gapped environments, ensuring provenance, integrity, and rollback safety.\n\n## Key Concepts\n\n- Offline attestation and TPM keys\n- SBOM generation and private catalogs\n- ImagePolicyWebhook + OPA/Gatekeeper policies\n- Edge/offline attestation brokers\n- Drift detection and automated rollback\n- Observability/telemetry for attestation and rollbacks\n\n## Code Example\n\n```javascript\n// Pseudo: Cosign signing with TPM key and SBOM publication\ncosign sign --key tpm-key.pem gcr.io/org/cnf-gateway:latest\ncosign generate sbom -o sbom.json gcr.io/org/cnf-gateway:latest\n```\n\n## Follow-up Questions\n\n- How would you handle clock skew between air‑gapped sites and the signing CA?\n- What metrics would you surface to detect attestation drift at scale?","diagram":"flowchart TD\n  A[CNF image] --> B[Cosign signing (TPM)]\n  B --> C[SBOM published]\n  C --> D[ImagePolicyWebhook]\n  D --> E[GitOps rollout]\n  E --> F[Attestation broker (edge)]\n  F --> G[Drift detection]\n  G --> H[Auto rollback]\n  H --> I[Observability]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Citadel","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:05:53.114Z","createdAt":"2026-01-13T13:05:53.115Z"},{"id":"q-1511","question":"Beginner CNF certification: You manage a CNF API gateway in a single Kubernetes namespace with a private registry and no external access. Outline an end-to-end plan to enforce SLSA provenance for each image before deployment, including (1) build and sign with Cosign using a KMS-backed key, (2) generate and attach SPDX SBOMs, (3) verify SLSA provenance via ImagePolicyWebhook, (4) canary upgrades with rollback on provenance failure, (5) observability for signing events, SBOM validity, and rollback triggers?","answer":"Sign CNF images with Cosign using a KMS-backed key, generate SPDX SBOMs and attach them to the image, enforce SLSA provenance with ImagePolicyWebhook, deploy via canary with rollback on provenance fai","explanation":"## Why This Is Asked\nTests practical understanding of end-to-end CNF provenance using SLSA, Cosign, SBOMs, and in-cluster enforcement, plus observable signals.\n\n## Key Concepts\n- SLSA provenance and Cosign signing with KMS keys\n- SPDX SBOMs and their association with container images\n- ImagePolicyWebhook enforcement in Kubernetes\n- Canary rollout and rollback on provenance failure\n- Observability: signing events, SBOM health, rollback signals\n\n## Code Example\n```yaml\n# Example: minimal ImagePolicyWebhook enforcing SLSA provenance (pseudo)\napiVersion: imagepolicy.k8s.io/v1alpha1\nkind: ImagePolicyRule\nmaliciousPattern: false\nattestation: true\n```\n\n```yaml\n# Sign image with Cosign (conceptual)\ncosign sign --key kms://<vault/key> registry.example.com/cnf-api gateway:1.0.0\n```\n\n```yaml\n# Canary upgrade cue (conceptual)\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nspec:\n  strategy:\n    canary:\n      steps:\n      - setWeight: 20\n      - pause: { }\n```\n\n## Follow-up Questions\n- How would you test SLSA provenance in a dry-run vs production promotion path?\n- What metrics would you surface to detect provenance drift quickly?","diagram":"flowchart TD\n  A[Code Commit] --> B[CI Build & Sign]\n  B --> C[SBOM Generation]\n  C --> D[Publish to Registry+SBOM]\n  D --> E[ImagePolicyWebhook Enforce]\n  E --> F[Canary Rollout]\n  F --> G{Provenance Valid?}\n  G -- Yes --> H[Full Rollout]\n  G -- No --> I[Rollback & Alert]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Hashicorp","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T19:47:55.680Z","createdAt":"2026-01-13T19:47:55.681Z"},{"id":"q-1526","question":"In a CNF gateway spanning multiple tenants, implement runtime **per-tenant feature flags** controlled by a central policy server. Describe a concrete plan using SPIRE for tenant identities, OPA for policy evaluation, and a sidecar that hot-reloads policies from a central repo. Include how you detect flag revocation, perform zero-downtime updates, and observability hooks (SBOM provenance, traces, metrics)?","answer":"Implement SPIRE-based tenant identities with per-tenant feature flags controlled by OPA policy evaluation, deployed via a sidecar that hot-reloads policies from a central repository. When flags are revoked or policy evaluation fails, trigger automatic rollback with zero-downtime updates, while maintaining comprehensive observability through SBOM provenance, distributed tracing, and metrics collection.","explanation":"## Why This Is Asked\nTests ability to design runtime policy-driven features with zero-downtime upgrades, tenant identity via SPIRE, and robust observability.\n\n## Key Concepts\n- Runtime policy loading with hot reload\n- Tenant identity via SPIRE SVIDs\n- Policy evaluation with OPA\n- Rollback on revocation or evaluation failure\n- Observability: SBOM health, tracing, metrics\n\n## Code Example\n```yaml\n# Example policy snippet for per-tenant flag\npackage cf.flags\n\ndefault allow = false\n\nallow {\n  input.tenant_id == \"tenant-A\"\n  input.flags[\"new-feature\"] == true\n}\n```\n\n## Follow-up Questions\n- How would you handle policy conflicts between multiple repositories?\n- What strategies would you use for policy versioning and rollback?\n- How do you ensure policy evaluation performance at scale?","diagram":null,"difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:49:57.937Z","createdAt":"2026-01-13T20:43:42.258Z"},{"id":"q-1544","question":"You're managing a CNF-based API gateway deployed in two regions, serving three tenants with a single global CI/CD pipeline. Propose an end-to-end upgrade and rollback strategy that delivers zero downtime while guaranteeing strict tenant isolation during updates. Include deployment approach (canary vs blue-green), tenant-aware routing, per-tenant metrics and logging, rollback triggers, and how you would validate the plan in staging that mirrors production. Cite concrete tooling choices (Argo Rollouts, Istio/Envoy, OPA, Prometheus) and touchpoints?","answer":"Implement a canary rollout strategy using Argo Rollouts across both regions, gradually increasing tenant exposure in 5–10% increments. Route traffic through Istio with per-tenant headers for strict isolation, enforced by OPA Gatekeeper policies. Monitor per-tenant metrics via Prometheus and structured logging, with automated rollback triggers based on error rates, latency thresholds, or policy violations.","explanation":"## Why This Is Asked\nInterviewers assess real-world release engineering expertise for CNF environments: multi-region coordination, multi-tenant isolation, and zero-downtime upgrades.\n\n## Key Concepts\n- Canary vs blue-green deployment strategies\n- Tenant isolation through routing and policy enforcement\n- Per-tenant observability (latency, errors, rollback signals)\n- Automated rollback criteria and triggers\n- Production-mirroring staging validation\n\n## Code Example\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: gateway-canary\nspec:\n  replicas: 4\n  strategy:\n    canary:\n```","diagram":"flowchart TD\n  A[Canary rollout] --> B[Regional exposure]\n  B --> C{Tenant isolation}\n  C --> D[Per-tenant metrics]\n  D --> E[Automated rollback]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:31:32.100Z","createdAt":"2026-01-13T21:32:16.410Z"},{"id":"q-1571","question":"You’re deploying a CNF API gateway across 6 regions and need strict per-tenant isolation with dynamic rate limits and auditable policy changes. Propose an end-to-end plan that uses SPIRE for per-tenant identities, OPA for policy decisions, Envoy with hot xDS updates, and a shared policy catalog. Include how you push canary upgrades, rollback on drift, and observability for quota hits and policy eval latency?","answer":"Plan an end-to-end approach to enforce per-tenant isolation and dynamic rate limits at an Envoy-based CNF gateway across six regions. Use SPIRE for per-tenant SVIDs, OPA for policy decisions, a shared policy catalog for centralized rule management, and Envoy with hot xDS updates for dynamic configuration. Implement canary upgrades using progressive traffic shifting, rollback on policy drift detection, and comprehensive observability for quota hits and policy evaluation latency.","explanation":"## Why This Is Asked\nEvaluates real-world ability to design cross-region CNF policy, identity, and drift controls.\n\n## Key Concepts\n- SPIRE SVIDs for per-tenant identities\n- OPA/REGO policies for per-tenant rules and rate limits\n- Envoy xDS for dynamic config updates\n- Cosign SBOM signing and policy pack attestations\n- Drift detection, canary rollouts, and rollback criteria\n- Observability: quota hits, policy eval latency, rollback signals\n\n## Code Example\n```javascript\nasync function fetchTenantPolicy(tenant){/* fetch and cache policy; evaluate with OPA */}\n```\n\n## Follow-up Questions\n- How would you handle policy versioning across regions?\n- What metrics would you use to trigger automatic rollbacks?\n- How do you ensure policy consistency during network partitions?","diagram":"flowchart TD\n  A[Request] --> B[SPIRE Auth]\n  B --> C[Envoy xDS]\n  C --> D[OPA Eval]\n  D --> E[Rate Limiter]\n  E --> F[Observability]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Stripe","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:12:37.153Z","createdAt":"2026-01-13T22:34:39.307Z"},{"id":"q-1599","question":"Outline a beginner-friendly, end-to-end workflow to enforce image provenance and runtime integrity per-tenant before deployment, using Cosign signing, SPDX SBOMs, and admission controls (ImagePolicyWebhook + Gatekeeper/OPA). Provide concrete steps and minimal config examples?","answer":"Sign each tenant's CNF image with Cosign using a tenant-scoped key, generate an SPDX SBOM, and attach it as an image annotation. Enforce with ImagePolicyWebhook and a Gatekeeper/OPA constraint that requires both valid signatures and SBOM presence before deployment.","explanation":"## Why This Is Asked\nTests practical per-tenant provenance in CNF gateways: signing, SBOMs, and policy enforcement.\n\n## Key Concepts\n- Tenant-scoped Cosign signing\n- SPDX SBOM generation and annotation\n- Admission controls: ImagePolicyWebhook + Gatekeeper/OPA\n- Canary rollout and observability\n\n## Code Example\n```yaml\n# Gatekeeper constraint (simplified)\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sCosignConstraint\nmetadata:\n  name: cnf-provenance\nspec:\n  required_signatures: 1\n  required_sboms: 1\n  image_kind: \"cnf/gateway\"\n```\n\n## Follow-up Questions\n- How would you test a tenant's","diagram":"flowchart TD\n  A[Tenant CNF upload] --> B[Cosign sign with tenant key]\n  B --> C[SBOM generation]\n  C --> D[Annotate image with SBOM]\n  D --> E[Admission via ImagePolicyWebhook]\n  E --> F[Gatekeeper/OPA policy]\n  F --> G[Deployment or rollback]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:33:32.235Z","createdAt":"2026-01-14T02:28:29.725Z"},{"id":"q-1674","question":"Advanced CNF scenario: deploy a CNF API gateway across three geographies with a private registry and multi-tenancy. Propose an end-to-end plan to enforce per-tenant image provenance and runtime integrity, including (i) per-tenant Cosign signing keys stored in KMS/HSM, (ii) per-tenant SBOMs, (iii) admission controls using ImagePolicyWebhook/OPA, (iv) tenant-aware drift detection and rollback, and (v) observability for signing, attestation, and rollback signals. Provide concrete steps and minimal config examples?","answer":"Per-tenant provenance uses tenant-scoped Cosign keys in KMS/HSM, SBOMs published to a tenant feed, and ImagePolicyWebhook + OPA to enforce signatures at admission. Drift detection compares in-cluster ","explanation":"## Why This Is Asked\nThis question probes multi-tenant CNF provenance at scale, including per-tenant keys, drift detection, rollback, and observability.\n\n## Key Concepts\n- Tenant-scoped key management\n- Per-tenant SBOMs and provenance enforcement\n- ImagePolicyWebhook + OPA constraints\n- Drift detection and tenant-aware rollback\n- Observability: metrics, traces, audit logs\n\n## Code Example\n```javascript\n// Pseudo-code: verify image provenance per tenant\nasync function verifyProvenance(imageRef, tenant) {\n  const sigOk = await cosign.verify(imageRef, { key: `kms://${tenant}-key` });\n  const sbom = await fetchSBOM(imageRef);\n  if (sbom.tenant !== tenant) throw new Error('Tenant SBOM mismatch');\n  return sigOk;\n}\n```\n\n## Follow-up Questions\n- How would you rotate tenant keys without downtime?\n- How would you test drift detection across regions?","diagram":"flowchart TD\n  A[Tenant] --> B[Signer & SBOM Publisher]\n  B --> C[Admission Controller]\n  C --> D[Cluster]\n  D --> E[Telemetry & Rollback Engine]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","IBM","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:46:49.701Z","createdAt":"2026-01-14T06:46:49.701Z"},{"id":"q-1735","question":"Beginner CNF certification: In a multi-tenant Kubernetes cluster hosting CNF gateways in separate namespaces, design an end-to-end image provenance gate: (1) sign images with Cosign using a KMS-backed key and attach SPDX SBOMs, (2) enforce with an ImagePolicyWebhook that requires both signature and SBOM presence, (3) surface a per-tenant visibility badge on deployments, (4) provide minimal config snippets and commands to validate end-to-end in one namespace before rolling out to others?","answer":"CI signs image with Cosign using a KMS-backed key and generates an SPDX SBOM; SBOM and signature are pushed to a private registry. ImagePolicyWebhook enforces signature+SBOM at admission. A per-namesp","explanation":"## Why This Is Asked\nTests practical understanding of image provenance, Cosign SBOM integration, and admission control in CNF deployments. It asks for an end-to-end flow with concrete steps and minimal config to validate in a single namespace before broader rollout.\n\n## Key Concepts\n- Cosign signing with a KMS-backed key\n- SPDX SBOM generation and attachment\n- ImagePolicyWebhook admission checks\n- Per-tenant namespace isolation and observability\n\n## Code Example\n```yaml\n# Minimal ImagePolicyWebhook-ish configuration (conceptual)\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: image-provenance\nwebhooks:\n- name: image-provenance.example.com\n  clientConfig:\n    service:\n      name: image-policy\n      namespace: image-policy\n      path: \"/validate\"\n  rules:\n  - apiGroups: [\"apps\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\"]\n    resources: [\"deployments\"]\n  failurePolicy: Fail\n  namespaceSelector:\n    matchLabels:\n      cnf-provenance: \"enabled\"\n```\n\n## Follow-up Questions\n- How would you test with a known-bad image? What signals would you surface in observability?\n- What changes if a tenant needs a temporary override for a signed image during rollout?","diagram":"flowchart TD\n  A[CI signs image with Cosign] --> B[SBOM generated]\n  B --> C[Push to private registry]\n  C --> D[Admission via ImagePolicyWebhook]\n  D --> E[Deployment with trust badge]\n  E --> F[Observability alerts]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:57:12.709Z","createdAt":"2026-01-14T08:57:12.709Z"},{"id":"q-1793","question":"In a multi-tenant cluster hosting CNF gateway images, design a beginner end-to-end flow to enforce per-tenant image provenance using Cosign signing with tenant keys, SPDX SBOMs, and a Gatekeeper constraint that reads a per-tenant policy from a ConfigMap. Include minimal YAML for the ConstraintTemplate and Constraint, plus compliant vs noncompliant Deployment manifests, and the exact kubectl steps to validate end-to-end in a single namespace first?","answer":"Sign images with Cosign using a tenant-scoped key, attach an SPDX SBOM, and publish per-tenant policy in a ConfigMap. Implement a Gatekeeper ConstraintTemplate that checks for signature and SBOM exist","explanation":"## Why This Is Asked\n\nTests ability to design a per-tenant provenance flow, integrate image signing and SBOMs, and apply admission controls with policy-as-code. It also checks practical knowledge of Gatekeeper/OPA integration, namespace-scoped policies, and minimal test workflows.\n\n## Key Concepts\n\n- Cosign signing with tenant-specific keys\n- SPDX SBOM attachment and verification\n- Gatekeeper ConstraintTemplate and Constraint\n- Per-tenant policy in a ConfigMap\n- Minimal manifests and kubectl validation in a single namespace\n\n## Code Example\n\n```yaml\n# ConstraintTemplate (yaml)\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8simageprovenance\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sImageProvenance\n  targets:\n  - target: admission.k8s.gatekeeper.sh\n    rego: |\n      package k8simageprovenance\n      violation[{\"msg\": msg}] {\n        input.review.kind.kind == \"Deployment\"\n        some c in input.review.object.spec.template.spec.containers\n        not startswith(c.image, \"ghcr.io/\")\n        msg := \"image provenance missing or not tenant-approved\"\n      }\n```\n\n```yaml\n# Constraint (yaml)\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sImageProvenance\nmetadata:\n  name: per-tenant-provenance\nspec:\n  enforcementAction: deny\n  parameters:\n    allowedTenant: \"tenant-a\"\n```\n\n```yaml\n# Compliant Deployment (yaml)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tenant-a-gateway\n  namespace: tenant-a\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - name: gateway\n        image: ghcr.io/tenant-a/gateway:v1.0.0\n```\n\n```yaml\n# Noncompliant Deployment (yaml)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tenant-a-gateway-bad\n  namespace: tenant-a\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - name: gateway\n        image: unsigned/gateway:latest\n```\n\n```bash\n# Kubectl steps (one namespace first)\nkubectl create ns tenant-a\n# 1) Register constraint template and constraint\nkubectl apply -f k8simageprovenance_template.yaml\nkubectl apply -f k8simageprovenance_constraint.yaml\n# 2) Sign and SBOM-attach a valid image (tenant-a key)\ncosign sign --key cosign-tenant-a.key ghcr.io/tenant-a/gateway:v1.0.0\n# 3) Deploy compliant manifest\nkubectl apply -f compliant-deploy.yaml -n tenant-a\n# 4) Deploy noncompliant manifest (unsigned)\nkubectl apply -f noncompliant-deploy.yaml -n tenant-a\n# 5) Check Gatekeeper denials and logs\nkubectl get events -n tenant-a\nkubectl describe deployment tenant-a-gateway-bad -n tenant-a\n```\n\n## Follow-up Questions\n- How would you rotate tenant keys without downtime?\n- How would you extend to multi-tenant namespaces concurrently?","diagram":"flowchart TD\n  A[Tenant Namespace] --> B[Compliant Image Signed]\n  B --> C[SBOM Attached]\n  C --> D[Gatekeeper Constraint Enforced]\n  D --> E[Deployment Accepted]\n  A --> F[Noncompliant Image] --> G[Denied by Gatekeeper]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:56:55.662Z","createdAt":"2026-01-14T10:56:55.662Z"},{"id":"q-1812","question":"In a beginner CNF certification scenario, you operate a multi-tenant CNF gateway platform on Kubernetes with a private image registry. Describe a concrete end-to-end workflow to enforce provenance and runtime integrity for every pull: (1) embed build provenance into image labels (commit SHA, CI job, build ID), (2) sign with Cosign using a KMS-backed key and attach SPDX SBOMs, (3) enforce per-tenant policy via Gatekeeper/OPA that rejects images missing provenance or SBOM, and (4) provide a minimal test plan and config snippets to validate in a single namespace before rolling out to others?","answer":"Embed provenance as image labels (commit SHA, CI job, build ID). Sign with Cosign using a KMS-backed key and attach an SPDX SBOM. Enforce via Gatekeeper/OPA: a constraint that rejects images without p","explanation":"## Why This Is Asked\nThis question tests practical CNF provenance enforcement from build to runtime with per-tenant controls and a low-risk rollout.\n\n## Key Concepts\n- Build provenance in image labels (commit SHA, CI job, build ID)\n- Cosign signing with a KMS-backed key\n- SPDX SBOM attachment and verification\n- Gatekeeper/OPA policy enforcing provenance presence\n- Namespace-scoped testing and rollback strategy\n\n## Code Example\n```yaml\n# Gatekeeper ConstraintTemplate skeleton\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sprovenance\nspec:\n  crd:\n    spec:\n      names:\n        kind: ProvenanceConstraint\n  targets:\n  - target: admission.k8s.gatekeeper.sh\n    rego: |\n      package provenance\n      # placeholder policy\n```\n\n```bash\n# Minimal test commands\nkubectl create namespace test-ns\n# deploy CNF, then verify policy & logs\nkubectl apply -n test-ns -f cnf-deploy.yaml\nkubectl get events -n test-ns | grep provenance\n```\n\n## Follow-up Questions\n- How would you adapt the workflow for a canary rollout?\n- How would you monitor policy violations at scale?\n","diagram":"flowchart TD\n  A[Build image] --> B[Sign with Cosign]\n  B --> C[Attach SBOM]\n  C --> D[Gatekeeper/OPA policy]\n  D --> E[Test in single namespace]\n  E --> F[Roll out]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Coinbase","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T11:47:05.982Z","createdAt":"2026-01-14T11:47:05.982Z"},{"id":"q-1914","question":"In a multi-tenant CNF gateway managed by a central control plane, design an end-to-end upgrade workflow that uses per-tenant feature flags and a canary rollout with Istio, while enforcing runtime policy with OPA Gatekeeper and SPIRE-based identity. Include: (a) how CNF versions and flags are modeled in CRDs, (b) traffic splitting and health checks for safe canaries, (c) per-tenant policy evaluation, and (d) drift detection with automatic rollback and observability?","answer":"Design a per-tenant CNFUpgrade CRD describing tenantID, image, version, and featureFlags; implement a canary rollout via Istio with 10% traffic and progressive steps; encode policy decisions in OPA th","explanation":"## Why This Is Asked\nTests practical upgrade workflows for multi-tenant CNFs with policy checks, identity, and drift-driven rollback.\n\n## Key Concepts\n- per-tenant CRD design with versions and featureFlags\n- Istio canary traffic shifting and health checks\n- OPA Gatekeeper policy evaluation per tenant\n- SPIRE/SPIFFE identity for CNF components\n- drift detection and observability for rollback\n\n## Code Example\n```yaml\napiVersion: cnf.example/v1\nkind: CNFUpgrade\nmetadata:\n  name: tenant-a-upg-1\nspec:\n  tenantID: \"tenant-a\"\n  image: \"registry.example/cnf-gateway@sha256:abc123\"\n  version: \"v1.2.3\"\n  featureFlags:\n    newTLS: true\n```\n\n## Follow-up Questions\n- How would you test rollback triggers and thresholds?\n- How to scale canary to larger tenant fractions with safety gates?","diagram":null,"difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","NVIDIA","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T16:58:56.523Z","createdAt":"2026-01-14T16:58:56.523Z"},{"id":"q-2030","question":"Beginner CNF certification: How would you design an end-to-end workflow in a multi-tenant Kubernetes cluster to enforce SBOM freshness and key-rotation awareness for CNF images, so that when a Cosign key rotates SBOMs are re-generated and re-attested, and a Kyverno policy rejects images signed with old keys or missing SBOMs, with a minimal namespace-scoped test?","answer":"Implement a comprehensive SBOM freshness and key-rotation workflow by signing CNF images with Cosign using KMS-backed keys, generating SPDX SBOMs with Syft and attaching them as attestations, then enforcing compliance through Kyverno policies that require both valid signatures and current SBOMs. When Cosign key rotation occurs, automate re-signing of all images and regeneration of SBOM attestations, while updating Kyverno policies to reject images signed with previous keys or missing current SBOMs. Validate the entire workflow with namespace-scoped tests before production deployment.","explanation":"## Why This Is Asked\nThis question evaluates your ability to design end-to-end provenance controls for CNF environments, specifically addressing how key rotation impacts SBOM generation and policy enforcement in multi-tenant Kubernetes clusters.\n\n## Key Concepts\n- Cosign image signing with KMS-backed keys\n- SPDX SBOM generation and attestation workflows\n- Kyverno policy enforcement for signature and SBOM validation\n- Key rotation impact on image provenance chains\n- Namespace-scoped testing strategies and rollback procedures\n\n## Code Example\n```bash\n# Sign image with KMS-backed key\ncosign sign --key kms://mykms/path/to/key \\\n  --attachment sbom \\\n  registry.example.com/cnf:latest\n\n# Generate and attach SBOM\nsyft registry.example.com/cnf:latest \\\n  -o spdx-json > sbom.spdx\n\ncosign attest --key kms://mykms/path/to/key \\\n  --type spdx --predicate sbom.spdx \\\n  registry.example.com/cnf:latest\n```\n\n## Implementation Strategy\nDeploy this solution progressively: start with image signing, add SBOM generation, implement Kyverno policies, then automate the key rotation workflow. Test in isolated namespaces before cluster-wide deployment.","diagram":null,"difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Cloudflare","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:23:24.155Z","createdAt":"2026-01-14T21:37:32.682Z"},{"id":"q-2189","question":"Advanced CNF Certification: Design an end-to-end runtime policy and rollout flow to ensure that only CNFs with verifiable provenance and hardware compatibility SBOM attestations can allocate SR-IOV NICs across regions; describe data sources, policy versioning, canary rollout, and rollback, plus a minimal policy snippet?","answer":"Implement an OPA-Gatekeeper policy that gates SR-IOV enablement on CNFs only when the SBOM reports hardware: sriov, attestation is valid, and image is Cosign-signed. Use a central, versioned policy st","explanation":"## Why This Is Asked\nTests ability to design runtime provenance controls that scale across regions and vendors, focusing on drift-resistant policy evolution.\n\n## Key Concepts\n- Runtime policy versioning\n- SBOM provenance and hardware attestations\n- Canary rollouts and multi-tenant isolation\n- Drift detection and automated rollback\n- OPA/Gatekeeper integration with Cosign/SBOM flows\n\n## Code Example\n```rego\npackage cnf.provenance\ndefault allow = false\nallow {\n  input.sbom.hardware == \"sriov\"\n  input.attestation.valid\n  input.signature.valid\n}\n```\n\n## Follow-up Questions\n- How would you test policy drift in a live multi-region setup?\n- What metrics indicate a failed policy rollout and rollback trade-offs?","diagram":"flowchart TD\n  A[CNF Image] --> B[SBOM & Attestation]\n  B --> C[Policy Engine]\n  C --> D{enable_sriov?}\n  D --> E[Runtime Enforce]\n  D --> F[Reject]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:56:56.092Z","createdAt":"2026-01-15T06:56:56.092Z"},{"id":"q-2262","question":"How would you implement an end-to-end runtime-provenance strategy for upgrades in a three-region, air-gapped CNF platform hosting stateful gateways across Kubernetes clusters, without pulling new images from the registry? Include image provenance checks, TPM-backed attestation via Sigstore, in-cluster drift detection with eBPF, and a safe, low-downtime rollback plan with minimal manifests?","answer":"Adopt a four-layer flow: (1) require Cosign-signed CNF images with SBOMs and a rollback tag; (2) enforce TPM-backed attestation via Sigstore (Fulcio/ Rekor) inside each cluster; (3) run in-cluster dri","explanation":"## Why This Is Asked\nTests ability to design for multi-region, air-gapped CNFs with strict provenance and runtime security, focusing on upgrade safety without image pulls.\n\n## Key Concepts\n- Runtime attestation with TPM-backed keys (Sigstore)\n- Image provenance with SBOMs and Cosign\n- In-cluster drift detection via eBPF\n- Policy-driven rollback (OPA/Gatekeeper)\n\n## Code Example\n```\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sImageProvenance\nmetadata:\n  name: require-sbom-signature\nspec:\n  match:\n    kinds:\n    - apiVersion: apps/v1\n      kind: Deployment\n  parameters:\n    requireSBOM: true\n    requireSignature: true\n```\n\n## Follow-up Questions\n- How would you test drift detection thresholds?\n- How would you simulate network partitions across regions and verify rollback?","diagram":"flowchart TD\n  A[Image Pulled] --> B[Sign & SBOM]\n  B --> C[Attestation Gate]\n  C --> D[Canary Upgrade]\n  D --> E{Drift Detected?}\n  E -- Yes --> F[Rollback]\n  E -- No --> G[Regional Rollout]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:46:42.204Z","createdAt":"2026-01-15T09:46:42.205Z"},{"id":"q-2362","question":"Beginner CNF certification: In a multi-tenant Kubernetes cluster with a shared private registry, design an end-to-end image provenance gate that adds a freshness check: require Cosign-signed images with SPDX SBOMs, and enforce via Open Policy Agent that SBOM timestamp is within 7 days. Provide minimal constraint template, example annotation, and a one-namespace test plan?","answer":"Configure Cosign signing with a KMS-backed key, generate an SPDX SBOM and annotate the image with its timestamp, then enforce via Gatekeeper/OPA constraint requiring both signature and SBOM freshness ","explanation":"## Why This Is Asked\nTests ability to design a practical, auditable provenance gate that adds a time-based freshness check, a realistic constraint template, and a focused test path.\n\n## Key Concepts\n- Cosign signing with KMS-backed keys\n- SPDX SBOM generation and image annotations\n- SBOM freshness policy (7 days)\n- Gatekeeper/OPA constraint templates and Rego rules\n- Namespace-scoped validation and test plan\n\n## Code Example\n```yaml\n# ConstraintTemplate and Rego enforcing signature presence and SBOM freshness\n# (snippets sketched for brevity)\n```\n\n## Follow-up Questions\n- How would you adjust the freshness window for regulatory changes?\n- How do you handle SBOM revocation or key rotation?\n","diagram":"flowchart TD\nA[Build CNF image] --> B[Cosign sign]\nB --> C[Attach SBOM timestamp annotation]\nC --> D[OPA Gatekeeper constraint check]\nD --> E[Deploy to namespace]\n","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Snowflake","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:51:38.630Z","createdAt":"2026-01-15T14:51:38.631Z"},{"id":"q-2486","question":"Advanced CNF certification: In a four region CNF gateway fleet with a private image registry, design a scalable end-to-end workflow for per tenant image provenance and runtime attestation. Include tenant-specific signing keys, SBOMs, admission controls, and a rollback plan for regional outages. Provide concrete steps and minimal config snippets you would actually use in practice?","answer":"Design a scalable, four-region CNF gateway provenance flow: sign images with tenant KMS keys via Cosign, attach per-tenant SBOMs, publish Rekor entries, and enforce with Gatekeeper/OPA. Include runtim","explanation":"## Why This Is Asked\nTests ability to architect cross-region provenance, tenant isolation, and runtime attestation at scale, including key management and revocation.\n\n## Key Concepts\n- Tenant-scoped key management (KMS)\n- Per-tenant SBOMs and registries\n- Signed image provenance and Rekor revocation\n- Admission controls with Gatekeeper/OPA and runtime attestation\n- Multi-region rollback and observability\n\n## Code Example\n```yaml\n# Gatekeeper constraint example (minimal)\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sSBOMPresent\nmetadata:\n  name: tenant-a-sbom-present\nspec:\n  tenant: \"tenant-a\"\n  registry: \"registry.example.com/tenant-a\"\n```\n\n## Follow-up Questions\n- How would you test revocation propagation across regions?\n- What metrics indicate drift or attestation failure?\n","diagram":null,"difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:48:10.381Z","createdAt":"2026-01-15T19:48:10.381Z"},{"id":"q-2560","question":"Design an end-to-end CNF image provenance and runtime attestation workflow for a globally deployed API gateway across x86_64 and ARM edge nodes with intermittent connectivity. Include per-arch signing and SBOMs, cross-arch attestation claims, an OPA policy enforcing SBOM presence and trusted architecture, and a testing plan with canary rollouts and rollback criteria?","answer":"Implement per-architecture Cosign signing with architecture-specific KMS keys, generate SBOMs using Syft for each build, attach SBOMs to the respective image manifests, and enforce both signature verification and SBOM presence through OPA policies scoped to architecture. At runtime, utilize in-toto attestations with architecture-specific claims, cache verification data locally to handle intermittent connectivity scenarios, and execute canary rollouts with automated rollback triggered by attestation failures.","explanation":"## Why This Is Asked\nThis question tests the ability to design a comprehensive cross-architecture supply chain security and runtime trust workflow that addresses edge deployment challenges, including offline scenarios and real-time policy enforcement.\n\n## Key Concepts\n- Per-architecture image signing and SBOM provenance tracking\n- Runtime attestation with architecture-aware claim verification\n- Policy enforcement using OPA Gatekeeper with architecture-specific constraints\n- Edge connectivity management and canary-driven rollback mechanisms\n\n## Code Example\n```javascript\nfunction isAllowed(image, arch) {\n  // Verify Cosign signature for specific architecture\n  const signatureValid = verifyCosignSignature(image, arch);\n  const sbomPresent = checkSBOMPresence(image, arch);\n  const attestationValid = verifyInTotoAttestation(image, arch);\n  \n  return signatureValid && sbomPresent && attestationValid;\n}\n```","diagram":"flowchart TD\n  A[Per-arch signing] --> B[SBOM attach]\n  B --> C[OPA policy]\n  C --> D[Runtime attestation]\n  D --> E[Central verifier]\n  E --> F[Canary validation and rollback]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","IBM","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:24:17.533Z","createdAt":"2026-01-15T22:48:20.016Z"},{"id":"q-2638","question":"In a CNF gateway deployed across multi-cloud Kubernetes clusters, outline an end-to-end plan to guarantee runtime integrity and tenant isolation during updates, by combining hardware-backed attestation (TPM/SEV), SBOM provenance, a private attestation service, SPIRE identities, and policy enforcement with OPA Gatekeeper. Include upgrade testing (canary and rollback) and observability hooks?","answer":"Propose a plan that anchors builds to SBOMs, provisions a TPM/SEV-backed runtime attestation at startup, issues per-tenant tokens from a private attestation service, and uses SPIRE identities with OPA","explanation":"Why This Is Asked\nAssesses practical ability to design end-to-end CNF runtime integrity and tenant isolation using hardware-backed attestation, SBOM provenance, and policy enforcement across multi-cloud clusters.\n\nKey Concepts\n- Hardware-backed attestation (TPM/SEV)\n- SBOM provenance and signing\n- Private attestation service\n- SPIRE identities\n- OPA Gatekeeper policies\n- Canary upgrades and rollback\n- Observability of attestation events, drift, and SBOM provenance\n\nCode Example\n```javascript\n// Example: lightweight attestation check (pseudo)\nfunction isAttested(token, tenant) {\n  return token.verified && token.tenant === tenant;\n}\n```\n\nFollow-up Questions\n- How would you handle private attestation service downtime?\n- How do you test key rotation with minimal blast radius?","diagram":"flowchart TD\n  A[Image Build + SBOM] --> B[Sign & Attest]\n  B --> C[Runtime TPM/SEV Attestation]\n  C --> D[Private Attestation Service]\n  D --> E[SPIRE Identities & OPA Gatekeeper]\n  E --> F[Canary Upgrades with Rollback]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T04:19:26.521Z","createdAt":"2026-01-16T04:19:26.521Z"},{"id":"q-2745","question":"In a multi-tenant CNF gateway namespace, design a beginner-end-to-end image provenance gate that: (1) embeds per-tenant labels cnf/tenant and commit in the image, (2) signs images with Cosign using a KMS-backed key and attaches an SPDX SBOM, (3) enforces with a Kyverno policy that validates both the signature and the presence of the SBOM and tenant label, (4) includes a minimal test plan and config snippets to verify in one namespace before rollout?","answer":"Implement it by signing with Cosign (KMS key), generating SBOM with a tool (syft), attaching SBOM via cosign attach sbom, labeling each image with cnf/tenant=<tenant>, commit=<sha>, then deploy a Kyve","explanation":"## Why This Is Asked\nTests practical understanding of end-to-end image provenance in CNF multi-tenant contexts, combining signing, SBOM, and policy.\n\n## Key Concepts\n- Cosign signing with KMS-backed key\n- SBOM generation/attachment\n- Tenant-scoped image labeling\n- Kyverno policy for signature/SBOM/label enforcement\n\n## Code Example\n```yaml\n# Kyverno policy (simplified)\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-provenance\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: verify-signature-and-sbom\n    match:\n      resources:\n        kinds: [Deployment]\n    validate:\n      message: \"Image must be signed and SBOM attached with tenant label\"\n      pattern:\n        spec:\n          template:\n            spec:\n              containers:\n              - image: ?\n```\n```bash\n# Cosign signing (example)\ncosign sign --key kms://my-kms/key registry/tenant/image:tag\nsyft registry/tenant/image:tag -o cyclonedx-json > sbom.json\ncosign attach sbom registry/tenant/image:tag < sbom.json\n```\n\n## Follow-up Questions\n- How would you rotate signing keys with minimal downtime?\n- How to test cross-tenant leakage in this setup?","diagram":"flowchart TD\n  A[Tenant Namespace] --> B[Image built and labeled with cnf/tenant, commit]\n  B --> C[Sign with Cosign (KMS)]\n  C --> D[Attach SBOM]\n  D --> E[Kyverno policy enforces signature, SBOM, tenant label]\n  E --> F[Test namespace validation]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T09:53:57.764Z","createdAt":"2026-01-16T09:53:57.764Z"},{"id":"q-2814","question":"Describe a scalable, tenant-aware CNF provenance and runtime integrity flow: tenants supply per-tenant Cosign root keys and SBOM policies; images signed with tenant key and SBOM attached; admission controls enforce signature+SBOM before deployment; a runtime sidecar attests the image via TPM-backed quote and digest, blocking traffic on failure; include minimal config and test plan?","answer":"A strong answer will outline per-tenant key management with Cosign and a KMS, SBOM generation and embedding (SPDX) in image metadata, admission controls (OPA/ Gatekeeper) enforcing tenant signature+SB","explanation":"## Why This Is Asked\nThis question probes the ability to design end-to-end secure CNF deployments across tenants, including per-tenant keys, SBOM handling, admission policy, and runtime attestation.\n\n## Key Concepts\n- Tenant-scoped signing keys\n- SBOM generation and enforcement\n- Admission controls with Gatekeeper/OPA\n- Runtime attestation and sidecar enforcement\n- Observability and rollback\n\n## Code Example\n```yaml\n# Minimal Gatekeeper constraint template (illustrative)\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: CNFProvenance\nmetadata:\n  name: tenant-a_cnf_provenance\nspec:\n  match:\n    kinds:\n      - apiGroup: apps\n        kinds: [Deployment]\n  parameters:\n    requireSignature: true\n    requireSBOM: true\n    tenantMatcher: '^tenant-a-.*$'\n```\n\n## Follow-up Questions\n- How would you scale per-tenant attestation keys to 1000 tenants?\n- What failure modes exist if TPM attestation is unavailable?","diagram":"flowchart TD\n  A[Tenant Root Key] --> B[Cosign Sign Image]\n  B --> C[SBOM Attached]\n  C --> D[Admission Policy]\n  D --> E[Deployment]\n  E --> F[Runtime Attestation]\n  F --> G[Traffic Allowed]\n  F --> H[Traffic Blocked]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Twitter","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T13:20:47.850Z","createdAt":"2026-01-16T13:20:47.850Z"},{"id":"q-3156","question":"In a multi-tenant CNF platform running on Kubernetes across edge sites, design an end-to-end runtime attestation workflow that prevents unauthorized CNF updates from taking effect without a full image rebuild. The workflow should (1) collect hardware-backed startup attestations (TPM2.0/IMA) and publish to a central verifier, (2) publish a per-patch SBOM delta and attach a trust score, (3) enforce tenant-scoped runtime policy via OPA/Kyverno that rejects changes without valid attestation and SBOM delta, and (4) include a minimal in-namespace test plan to validate end-to-end before rollout. Provide concrete steps and minimal config snippets?","answer":"Design runtime attestation flow for a multi-tenant CNF platform: at startup, CNF emits TPM2.0/IMA attestations to a central verifier; generate and sign an SBOM delta for the patch; enforce tenant-scop","explanation":"## Why This Is Asked\n\nTests a higher‑fidelity security stance: runtime integrity, not just image provenance, across distributed edge sites.\n\n## Key Concepts\n\n- Runtime attestation using TPM2.0/IMA\n- SBOM delta management per patch\n- Per-tenant policy enforcement (OPA/Kyverno)\n- Central attestation verifier and revocation handling\n- Edge multi-site rollout and in-namespace testing\n\n## Code Example\n\n```javascript\nfunction isAttestationValid(token, delta, tenant) {\n  return token.signatureValid && delta.verified && tenant === token.tenant;\n}\n```\n\n## Follow-up Questions\n\n- How would you rotate attestation keys and revoke compromised tenants?\n- What observability would prove end-to-end attestation health in production?","diagram":null,"difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","NVIDIA","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:51:38.222Z","createdAt":"2026-01-17T04:51:38.223Z"},{"id":"q-3205","question":"In a multi-tenant CNF API gateway cluster on Kubernetes, a CVE hits a shared library in the gateway control plane. Describe a concrete end-to-end patch and rollout plan that preserves per-tenant SLAs while meeting CNF governance: (1) regenerate and attach SBOMs for the patched image, (2) re-sign with Cosign and rotate KMS-backed keys if required, (3) implement per-tenant canary deployments using Argo Rollouts and Istio routing with per-tenant traffic shaping, (4) validate tenant isolation and rollback criteria with automated tests, (5) include minimal config snippets and concrete commands to validate end to end?","answer":"Patch a CVE-affected CNF image and roll out via per-tenant canaries. Steps: (1) regenerate SBOMs for the patched image, (2) sign with Cosign and rotate KMS-backed keys if policy requires, (3) deploy p","explanation":"## Why This Is Asked\nTests CVE response in a CNF multi-tenant setting, covering SBOM attestation, key management, per-tenant canary rollout, and observability.\n\n## Key Concepts\n- SBOM generation and attestation\n- Cosign signing and KMS key rotation\n- Per-tenant canary rollout with Argo Rollouts and Istio\n- Rollback criteria and observability\n\n## Code Example\n```bash\n# SBOM generation (example)\nsyft gateway-image:latest -o cyclonedx-json > sbom.json\n# Signing (example)\ncosign sign --key cosign-key.pem gateway-image:latest\n```\n\n## Follow-up Questions\n- How would you test rollback under partial failure across tenants?\n- What metrics would surface to detect drift during the rollout?","diagram":"flowchart TD\n  A[Start] --> B[Patch image per tenant]\n  B --> C[Gen SBOMs]\n  C --> D[Sign & rotate keys]\n  D --> E[Per-tenant canary rollout]\n  E --> F[Isolation tests]\n  F --> G{Success?}\n  G -->|Yes| H[Promote]\n  G -->|No| I[Rollback & alert]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Plaid","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T06:54:00.595Z","createdAt":"2026-01-17T06:54:00.595Z"},{"id":"q-3230","question":"In an air-gapped edge CNF deployment, outline a practical end-to-end provenance workflow that signs an image with Cosign using an offline KMS key, attaches an SPDX SBOM, and transfers a portable provenance manifest to edge sites for offline verification before pull. Include steps for signing, SBOM generation, manifest format, offline verification, and a minimal in-namespace check?","answer":"Outline offline provenance: generate SBOM with Syft for the CNF image, sign with Cosign using offline KMS key, attach SBOM, create a portable manifest with image_digest, sbom_digest, nonce, build_id, ","explanation":"## Why This Is Asked\nTests understanding of CNF provenance in offline environments, a realistic edge scenario, and interoperability between signing, SBOM, and verification without live Internet.\n\n## Key Concepts\n- Air-gapped deployment, portable provenance artifacts\n- Cosign signing with offline KMS keys\n- SPDX SBOM attachment and verification\n- Offline verifier at edge sites and minimal in-namespace checks\n\n## Code Example\n```bash\n# Sign image offline (cosign with offline KMS key)\ncosign sign --key kms://offlinedkms/cnf-key registry.example.com/cnf/gateway:1.0.0\n\n# Generate SBOM and attach\nsyft registry.example.com/cnf/gateway:1.0.0 -o cyclonedx-json > sbom.json\ncosign attach sbom --sbom sbom.json registry.example.com/cnf/gateway:1.0.0\n```\n\n```json\n{\n  \"image_digest\": \"sha256:abcdef...\",\n  \"sbom_digest\": \"sha256:123456...\",\n  \"nonce\": \"n-20260117-01\",\n  \"build_id\": \"ci-42\",\n  \"signature\": \"base64sig...\"\n}\n```\n\n## Follow-up Questions\n- How would you test end-to-end in a multi-site environment?\n- What are pitfalls of offline verification and how would you mitigate key rotation and revocation?","diagram":"flowchart TD\n  Central[Central Registry] --> EdgeSite1[Edge Site 1]\n  Central --> EdgeSite2[Edge Site 2]\n  EdgeSite1 --> Verifier[Offline Verifier]\n  Verifier --> EdgeSite1\n  EdgeSite2 --> Verifier\n  Verifier --> EdgeSite2","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T07:40:50.484Z","createdAt":"2026-01-17T07:40:50.484Z"},{"id":"q-3294","question":"In a multi-tenant CNF-based firewall deployed across four regional clusters, design an end-to-end provenance workflow that (1) signs CNF images with Cosign using a region-scoped KMS key, (2) attaches a tenant-bound SPDX SBOM and a site-binding annotation, (3) enforces via a Kyverno policy that both the signature and SBOM exist and that the tenant annotation matches, and (4) supports automated cross-region key rotation and revocation. Include a one-namespace test plan and minimal config snippets?","answer":"Sign CNF images with Cosign using region KMS keys; attach an SPDX SBOM and tenant/site attestation; Kyverno policy requires signature, SBOM, and tenant/site match before deploy; support cross-region k","explanation":"## Why This Is Asked\nTests end-to-end provenance across multi-region deployments, tenant-scoped controls, and rotation events.\n\n## Key Concepts\n- Cosign with region-scoped KMS keys\n- SPDX SBOM binding to CNFs\n- Kyverno validation policies for signature, SBOM presence, and tenant/site bindings\n- Attestation storage and rotation/revocation workflows\n\n## Code Example\n```javascript\ncosign sign --key kms://region/keys/cnf-key --sbom sbom.json registry.example.com/tenant-a/cnf-gateway:1.2.3\n```\n\n## Follow-up Questions\n- How would you propagate key revocation across regions without deployment downtime?\n- How would you monitor attestation freshness and alert on SBOM drift?","diagram":null,"difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","DoorDash","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T10:33:41.174Z","createdAt":"2026-01-17T10:33:41.174Z"},{"id":"q-3379","question":"Design an **external attestation API** for a Kubernetes-based multi-tenant CNF mesh (Slack/Google/OpenAI). Given an image digest and tenant, return a signed provenance bundle containing: imageDigest, sbomHash, signerKeyID, tenant, verdict, and timestamp. Describe data model, signing flow with **Sigstore** using a per-tenant KMS key, Rekor publication, and a minimal in-namespace test exercising the API end-to-end via a ServiceAccount?","answer":"Implement a microservice that accepts imageDigest and tenant, builds a payload with imageDigest, sbomHash, tenant, timestamp, and verdict, then signs with Sigstore using a per-tenant KMS key and retur","explanation":"## Why This Is Asked\n\nTests end-to-end provenance flow across cloud-native tools, including per-tenant isolation, signing with Sigstore, and Rekor integration. It also exercises API design, data modeling, and in-cluster testing patterns relevant to CNF supply chain security.\n\n## Key Concepts\n\n- Sigstore attestation flow and Rekor integration\n- Per-tenant key management (KMS) and image provenance\n- SBOM hashing and binding to image digests\n- In-cluster E2E test via ServiceAccount\n\n## Code Example\n\n```go\n// Go pseudo-structure for attestation payload\ntype Attestation struct {\n  ImageDigest string\n  SBOMHash    string\n  Tenant      string\n  Verdict     string\n  Timestamp   time.Time\n}\n```\n\n```javascript\n// Pseudo API call\nPOST /attest { imageDigest, tenant } -> { attestationID, signature }\n```\n\n## Follow-up Questions\n\n- How would you rotate tenant keys without breaking in-flight attestations?\n- How would you audit and revoke attestations if a tenant is compromised?","diagram":"flowchart TD\n  A(API receives request) --> B[Build attestation payload]\n  B --> C[Sign with tenant KMS via Sigstore]\n  C --> D[Publish to Rekor]\n  D --> E[Return attestationID to client]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","OpenAI","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T13:52:29.750Z","createdAt":"2026-01-17T13:52:29.750Z"},{"id":"q-3399","question":"In a globally distributed CNF platform spanning three regions, design an end-to-end governance gate for CNF updates that ensures provenance and safe rollback. Requirements: (1) per-tenant image SBOMs and Cosign signatures; (2) host attestation (TPM2.0/IMA) at update time to verify base hardware; (3) config-diff provenance by signing and attaching SBOM delta for Kubernetes manifests; (4) cross-region policy enforcement with Kyverno/OPA and a central verifier; (5) a minimal in-namespace test plan and config snippets. Provide concrete steps and minimal config?","answer":"Gate CNF updates with a cross-region provenance gate: (1) require Cosign-signed images plus SPDX SBOMs per tenant; (2) require hardware attestation (TPM2.0/IMA) verified by a central verifier before r","explanation":"## Why This Is Asked\n\nAssesses ability to build cross-region, production-grade CNF governance that combines image provenance, hardware attestation, and manifest-level provenance with policy enforcement and rollback controls. The question requires integrating Cosign, SBOMs, TPM/IMA attestations, and regionally replicated OPA/Kyverno policies, plus a concrete minimal test plan.\n\n## Key Concepts\n\n- End-to-end CNF provenance across regions\n- Tenant-scoped Cosign signatures and SPDX SBOMs\n- Hardware attestation (TPM2.0/IMA) verification\n- Delta SBOMs for Kubernetes manifests\n- Cross-region policy enforcement (Kyverno/OPA) with central verifier\n- Minimal in-namespace test for update and rollback\n\n## Code Example\n\n```javascript\n// Pseudo verifier sketch for central attestation check\nfunction verifyUpdate(imageSig, sbom, attestation) {\n  return imageSig.valid && sbom.valid && attestation.ok;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle key rotation and revocation in Cosign across regions?\n- How would you simulate network partitions during a rollback test and ensure safety?","diagram":null,"difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T14:38:11.463Z","createdAt":"2026-01-17T14:38:11.464Z"},{"id":"q-3452","question":"Beginner CNF certification: In a multi-tenant Kubernetes cluster, implement end-to-end config drift protection for CNF gateway deployments. Design a flow to (1) sign gateway configs with Cosign using a KMS-backed key and publish SBOMs, (2) mount a signed config as a per-tenant ConfigMap via a controller, (3) enforce at admission time that runtime config matches the signed artifact, and (4) surface per-tenant drift alerts with minimal in-namespace tests and sample manifests. What steps and minimal snippets would you provide?","answer":"Approach: implement config drift protection for CNF gateways in a multi-tenant Kubernetes cluster. Sign tenant configs with Cosign using a KMS-backed key and publish SBOMs. Use a controller to mount t","explanation":"## Why This Is Asked\n\nThis tests practical understanding of end-to-end CNF config provenance, multi-tenant drift protection, admission control, and observability.\n\n## Key Concepts\n\n- Cosign signing with KMS\n- SBOM generation\n- Per-tenant ConfigMaps and controller-driven mounting\n- Validating admission webhook for runtime config integrity\n- Drift detection and per-tenant alerts (Prometheus/Alertmanager)\n\n## Code Example\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: tenant-a-config\n  namespace: tenant-a\ndata:\n  gateway.yaml: |\n    replicas: 1\n    image: harbor.local/cnf/gateway:signed\n```\n\n## Follow-up Questions\n\n- How would you test webhook behavior across canary and prod?\n- How would you automate rotation of KMS keys without downtime?","diagram":"flowchart TD\n  A[CNF gateway] --> B[Signed config SBOM]\n  B --> C[ConfigStore]\n  C --> D[Admission webhook]\n  D --> E[Startup with config]\n  E --> F[Drift alerts]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Instacart","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T16:48:52.179Z","createdAt":"2026-01-17T16:48:52.179Z"},{"id":"q-3457","question":"In a shared Kubernetes CNF certification setup with multi-tenant Gatekeeper policies, design an end-to-end flow to validate and enforce per-tenant feature flags before deployment: 1) define a tenant-scoped FeaturePolicy CRD, 2) implement a ConstraintTemplate (Rego) that reads Deployment.annotations['cnf/feature'] and checks against the tenant policy, 3) enforce with Gatekeeper so disallowed flags fail admission, 4) wire a minimal CI gate to publish tenant policies and test manifests, 5) add in-namespace tests that verify allowed vs disallowed cases. What would you implement and why?","answer":"I would implement a tenant-scoped FeaturePolicy CRD and a Gatekeeper ConstraintTemplate that validates Deployment.annotations['cnf/feature'] against the tenant's allowedFlags. The CI gate publishes pe","explanation":"## Why This Is Asked\nTests practical understanding of policy-as-code, admission controls, and CNF feature gating in a real multi-tenant cluster.\n\n## Key Concepts\n- Tenant-scoped CRD for featurePolicy\n- Gatekeeper ConstraintTemplate with Rego logic\n- Per-tenant policy propagation in CI\n- In-namespace tests for allow/deny scenarios\n\n## Code Example\n```yaml\n# CRD: featurepolicies.example.com\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: featurepolicies.example.com\nspec:\n  group: example.com\n  versions:\n  - name: v1\n    served: true\n    storage: true\n    schema:\n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              tenant:\n                type: string\n              allowedFlags:\n                type: array\n                items:\n                  type: string\n```\n```rego\npackage gatekeeper.featurepolicy\n\nviolation[{\"msg\": msg}] {\n  input.review.object.kind == \"Deployment\"\n  annotations := input.review.object.metadata.annotations\n  feature := annotations[\"cnf/feature\"]\n  policy := data.tenants[input.review.object.metadata.namespace]\n  not featureR in policy.allowedFlags\n  msg := sprintf(\"disallowed feature flag: %v for tenant: %v\", [feature, input.review.object.metadata.namespace])\n}\n```\n\n## Follow-up Questions\n- How would you handle evolving policies without downtime?\n- How would you test performance impact of policy checks at scale?","diagram":"flowchart TD\n  A[Tenant Policy Created] --> B[Policy Sync to Gatekeeper]\n  B --> C[Deployment Annotated with cnf/feature]\n  C --> D{Admission Check Pass?}\n  D --> E[Allow Deployment]\n  D --> F[Deny Deployment]\n  F --> G[Test Namespace Verifies Denial]","difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T17:24:08.277Z","createdAt":"2026-01-17T17:24:08.279Z"},{"id":"q-3536","question":"Beginner CNF certification: In a multi-tenant CNF gateway platform on Kubernetes, design a minimal end-to-end post-deployment image revocation flow. Include (1) a signed revocation artifact published to the central registry (pointing to revoked image digests), (2) an ImagePolicyWebhook rule that denies pods whose image digest appears in the revocation list, (3) per-tenant rollback flags surfaced per-namespace via a ConfigMap, and (4) a one-namespace validation test with minimal manifests before rollout?","answer":"Publish a signed revocation JSON {revoked: ['sha256:...']} to the central registry, signed with the same KMS key. The ImagePolicyWebhook fetches and verifies signature, denying pods with revoked diges","explanation":"## Why This Is Asked\nTests ability to design post-deployment revocation with provenance and per-tenant controls.\n\n## Key Concepts\n- Signed revocation artifacts\n- ImagePolicyWebhook checks against revocation set\n- Namespace-scoped rollback controls via ConfigMap\n- Minimal in-namespace test before rollout\n\n## Code Example\n```javascript\n// Pseudo webhook logic\nif (revokedDigests.includes(imageDigest)) {\n  denyAdmission('revoked-image');\n}\n```\n\n## Follow-up Questions\n- How would you rotate keys and revoke in-flight deployments during high-traffic?\n- How to audit decisions and surface revoke events to tenants?","diagram":null,"difficulty":"beginner","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Google","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T20:36:47.824Z","createdAt":"2026-01-17T20:36:47.824Z"},{"id":"q-3689","question":"In a CNF gateway deployed across multiple clouds, design a runtime attestation workflow using Linux IMA to produce a signed attestation report for each running CNF container, verify it against a central policy server, and enforce tenant-scoped access based on attestation results. Include how to collect measurements, sign with an HSM, verify at admission, and a minimal one-namespace validation before rollout?","answer":"Design a runtime attestation workflow using Linux IMA across clouds: collect per-container measurements, sign IMA attestations with an HSM via PKCS#11, publish to a central attestation service, and ga","explanation":"## Why This Is Asked\nThis tests runtime attestation across multi-cloud CNFs, ensuring trust from build through deployment and enforcing tenant isolation at admission.\n\n## Key Concepts\n- Linux IMA and runtime integrity\n- PKCS#11/HSM signing\n- Central attestation service and baselines\n- Kubernetes ValidatingWebhookConfiguration\n- Tenant policy\n\n## Code Example\n```yaml\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nwebhooks:\n- name: attestation.example.com\n  clientConfig:\n    service:\n      name: attestation-service\n      namespace: default\n      path: /validate\n```\n\n## Follow-up Questions\n- How would you handle revocation and key rotation?\n- How would you validate attestation reports offline in air-gapped envs?","diagram":"flowchart TD\n  A[Start] --> B[Collect IMA measurements]\n  B --> C[Sign with HSM]\n  C --> D[Post to attestation service]\n  D --> E{Attestation OK?}\n  E -->|Yes| F[Allow pod admission]\n  E -->|No| G[Reject pod]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Microsoft","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:39:03.719Z","createdAt":"2026-01-18T05:39:03.720Z"},{"id":"q-3852","question":"Scenario: in a multi-tenant CNF platform on Kubernetes, design an end-to-end upgrade gate that enforces tenant-specific policies at admission time. Requirements: CNF images and SPDX SBOMs must be Cosign-signed; upgrades allowed only when provenance and SBOM delta satisfy a tenant policy stored in a KMS-backed store; a TPM2.0/IMA attestation proves a trusted baseline before upgrade; include a minimal in-namespace manifest to validate in one namespace and discuss trade-offs and fallbacks?","answer":"Implement a validating admission webhook that enforces tenant-specific upgrade policies at admission. Ensure CNF images are Cosign-signed with SBOMs; compute and store SBOM deltas per tenant; require ","explanation":"## Why This Is Asked\nTests ability to design end-to-end CNF upgrade governance with provenance, attestation, and per-tenant policy.\n\n## Key Concepts\n- CNF provenance, Cosign, SBOM\n- Per-tenant policy, KMS-backed store\n- Admission control (Validating Webhook, Kyverno/OPA)\n- TPM2.0/IMA attestation, runtime gate\n\n## Code Example\n```yaml\n# Kyverno policy skeleton enforcing tenant upgrade provenance\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: cnf-upgrade-provenance\nspec:\n  rules:\n  - name: require-provenance\n    match:\n      resources:\n        kinds:\n        - Deployment\n    validate:\n      message: \"Upgrade must have Cosign-signed image and SBOM\"\n      pattern:\n        spec:\n          template:\n            spec:\n              containers:\n              - name: '*'\n                image: '*'\n```\n\n## Follow-up Questions\n- How would you test fail-closed behavior under network partition?\n- How would you audit policy changes in the KMS-backed store without drifting?","diagram":"flowchart TD\n  A[Tenant requests upgrade] --> B[ Admission Webhook ]\n  B --> C{Provenance OK?}\n  C -- Yes --> D[Attestation TPM/IMA check]\n  C -- No --> E[Reject upgrade]\n  D --> F{Policy match?}\n  F -- Yes --> G[Upgrade allowed]\n  F -- No --> E","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T12:57:38.198Z","createdAt":"2026-01-18T12:57:38.198Z"},{"id":"q-3980","question":"In a multi-tenant CNF gateway platform on Kubernetes across two clouds, design an end-to-end image provenance gate for per-tenant upgrades. Requirements: (1) Cosign-sign images with a tenant-scoped KMS key and attach an SPDX SBOM, (2) a central policy (Kyverno/OPA) enforcing presence of both signature and SBOM before admission, (3) canary rollout with per-tenant rollback on SBOM or signature drift, (4) provide minimal in-namespace manifests and commands to validate end-to-end in one tenant namespace before broader rollout?","answer":"Outline a per-tenant upgrade workflow on Kubernetes: Cosign-sign the CNF image with a tenant KMS key and attach an SPDX SBOM; enforce with a central policy (Kyverno/OPA) that requires both signature a","explanation":"## Why This Is Asked\nTests real-world CNF provenance controls across tenants, regions, and tools, plus rollback and in-namespace validation.\n\n## Key Concepts\n- CNF provenance and SBOM attachment\n- Tenant-scoped Cosign signing with KMS\n- Central policy enforcement (Kyverno/OPA)\n- Canary rollouts and rollback triggers\n- Minimal in-namespace validation or test harness\n\n## Code Example\n```yaml\n# Kyverno policy skeleton enforcing signature and SBOM presence\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-sbom-signature\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: require-sbom-and-signature\n    match:\n      resources:\n        kinds: [\"Deployment\"]\n    validate:\n      message: \"Image must be signed and SBOM attached\"\n      pattern:\n        spec:\n          template:\n            spec:\n              containers: /[^\\n]+/  # placeholder\n```\n\n```bash\n# Example Cosign signing command (tenant-scoped key)\ncosign sign --key cosign-tenantA-key.pem ghcr.io/tenantA/cnf-gateway:1.2.3\n```\n\n## Follow-up Questions\n- How would you instrument auditing for failed sign/SBOM checks and trigger automatic rollbacks?\n- What tests would you add to ensure no drift between SBOM and image during upgrades?","diagram":"flowchart TD\n  A[Tenant upgrade request] --> B[Sign image w/ tenant KMS + SBOM]\n  B --> C[Policy check (signature + SBOM)]\n  C --> D[Canary rollout per tenant]\n  D --> E{SBOM/signature valid?}\n  E -- Yes --> F[Full rollout]\n  E -- No --> G[Rollback]\n\n","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Slack","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T18:40:42.036Z","createdAt":"2026-01-18T18:40:42.037Z"},{"id":"q-4065","question":"Scenario: You run a multi-tenant CNF platform on Kubernetes delivering real-time video processing at edge. Design an end-to-end update validation workflow that (1) signs new CNF images with Cosign and attaches SBOMs, (2) performs runtime attestation (TPM/IMA) and extracts a lightweight anomaly score from telemetry, (3) enforces via OPA/Kyverno that upgrades are blocked if attestation or SBOM is invalid or anomaly score is high, and (4) includes a minimal in-namespace test to verify rollout and rollback before full deployment?","answer":"Implement a gate that permits upgrades only if: (a) the CNF image is Cosign-signed with a KMS-backed key and an SBOM exists; (b) TPM/IMA runtime attestation is validated by a central verifier; (c) a l","explanation":"## Why This Is Asked\n\nTests end-to-end security and operability of CNF updates in multi-tenant, edge-focused Kubernetes environments, combining supply chain provenance, runtime attestation, anomaly detection, and policy-driven rollout controls.\n\n## Key Concepts\n\n- Image provenance with Cosign and SBOMs\n- Runtime attestation (TPM/IMA)\n- Telemetry-driven anomaly scoring\n- Policy enforcement with Kyverno/OPA\n- Namespace-scoped canary tests and rollback strategies\n\n## Code Example\n\n```yaml\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: cnf-update-gate\nspec:\n  rules:\n  - name: require-provenance-and-attestation\n    match:\n      resources:\n        kinds: [Deployment]\n    validate:\n      message: \"Upgrade blocked: provenance, attestation, or anomaly score invalid\"\n      pattern:\n        metadata:\n          annotations:\n            provenance.ok: 'true'\n```\n\n## Follow-up Questions\n\n- How would you implement the central verifier for TPM/IMA attestations?\n- What metrics and logs would surface for safety monitoring and audits?","diagram":null,"difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Netflix","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T22:32:24.276Z","createdAt":"2026-01-18T22:32:24.277Z"},{"id":"q-847","question":"You're deploying a CNF gateway (e.g., NGINX CNF) on a 50-node Kubernetes cluster handling streaming traffic. A node eviction hits during peak load. Outline a concrete plan to maintain streaming availability, focusing on (1) graceful drain with preStop, (2) health checks/readiness/liveness, and (3) traffic affinity and pod topology, and (4) observability and rollout strategy?","answer":"Use a Deployment of 4 replicas with PodDisruptionBudget minAvailable=3 and RollingUpdate maxUnavailable=25%. Implement a preStop hook to run nginx -s quit and wait 30s for active requests. Readiness o","explanation":"## Why This Is Asked\n\nTests practical CNF operations under eviction, not just theory.\n\n## Key Concepts\n\n- PodDisruptionBudget\n- Graceful draining\n- Readiness/Liveness probes\n- Traffic affinity\n\n## Code Example\n\n```javascript\n// Drain hook example\n```\n\n## Follow-up Questions\n\n- How would you adapt this for stateful CNFs?\n- How would you observe and rollback failed rollouts?","diagram":"flowchart TD\n  A[Node Eviction] --> B[Drain Initiated]\n  B --> C[Pod Stop/Drain]\n  C --> D[Traffic Shifts]\n  D --> E[New Pod Ready]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Plaid","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:29:51.594Z","createdAt":"2026-01-12T13:29:51.594Z"},{"id":"q-918","question":"You're rolling out a CNF-based NAT gateway across a 3-region multi-cluster Kubernetes setup. A policy change must be applied without disrupting live traffic. Outline a concrete, end-to-end rollout plan emphasizing (a) shadow canaries with traffic mirroring, (b) region-by-region rollout with per-region SLI targets, (c) policy-state reconciliation and drift detection, (d) rollback conditions and observability instrumentation?","answer":"Plan a canary rollout of CNF NAT across 3 regions. Validate in a shadow region with traffic mirroring; rollout region-by-region with explicit latency, error-rate, and drop targets; run a continuous po","explanation":"## Why This Is Asked\nTests practical rollout discipline for CNFs, multi-region consistency, and robust rollback.\n\n## Key Concepts\n- Canary rollouts in CNFs across regions\n- Policy drift detection and reconciliation\n- Observability with eBPF, traces, and metrics\n- Safe rollback criteria and traffic mirroring\n- Per-region SLI targets and controlled rollout\n\n## Code Example\n```javascript\n// Pseudocode: reconcilePolicy(desired, runtime, driftThreshold) \nasync function reconcilePolicy(desired, runtime){\n  const drift = diff(desired, runtime);\n  if(drift > driftThreshold) throw new Error('Policy drift');\n  // apply reconciliation\n}\n```\n\n## Follow-up Questions\n- How would you define drift metrics and thresholds for CNFs?\n- How would you test rollback reliability under sudden latency spikes?","diagram":"flowchart TD\n  A[Policy Change Initiated] --> B{Canary Shadow?}\n  B -- Yes --> C[Shadow Region Mirroring]\n  B -- No --> D[Region-by-Region Rollout]\n  C --> E[Monitor Shadows]\n  E --> F{Drift Detected?}\n  F -- Yes --> G[Rollback and Alert]\n  F -- No --> H[Proceed Rollout]\n  D --> H\n  H --> I[Centralize Telemetry]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Coinbase"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T15:30:48.188Z","createdAt":"2026-01-12T15:30:48.188Z"},{"id":"q-935","question":"You manage CNF-based gateways across 4 regions. A suspected supply-chain compromise requires enforcing in-cluster image attestations before rollout without downtime. Outline an end-to-end plan to (a) sign CNF images with Cosign and SBOMs, (b) enforce signatures via ImagePolicyWebhook, (c) roll out region-by-region with traffic mirroring, (d) implement drift detection and automatic rollback on attestation failure. Include observability?","answer":"Sign CNF images with Cosign and SBOMs, publish to Rekor; enforce with ImagePolicyWebhook requiring valid signature and SBOM; perform region-by-region canaries with traffic mirroring; implement drift c","explanation":"Why This Is Asked\n\nTests ability to design secure, zero-downtime CNF rollouts with supply chain attestations.\n\nKey Concepts\n\n- Image signing (Cosign), SBOMs, Rekor\n- Kubernetes policy enforcement (ImagePolicyWebhook)\n- Canary rollout, traffic mirroring, drift detection\n- Rollback criteria and observability\n\nCode Example\n\n```javascript\n// Pseudocode: drift detection between desired and deployed SBOMs\nfunction isDrifted(deployedSBOM, desiredSBOM) {\n  return deployedSBOM.hash !== desiredSBOM.hash;\n}\n```\n\nFollow-up Questions\n\n- How would you revoke a compromised image in Rekor without blocking new deployments?\n- How do you keep SBOMs up-to-date across regions during rapid changes?","diagram":"flowchart TD\n  A[Sign Image] --> B[Publish to Rekor]\n  B --> C[ImagePolicyWebhook]\n  C --> D[Canary Rollout]\n  D --> E[Drift Check]\n  E --> F[Rollback if needed]","difficulty":"intermediate","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Tesla","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:25:14.304Z","createdAt":"2026-01-12T16:25:14.304Z"},{"id":"q-985","question":"Design a zero-downtime, CNF-based API gateway rollout where per-tenant routing rules update live without dropping connections. Outline end-to-end steps: (a) safe rule distribution, (b) canary-ingress slicing with weighted traffic, (c) drift detection between desired and active routes, (d) observability and rollback?","answer":"Zero-downtime CNF gateway update for per-tenant routes: use a pull-based config bus for safe rule distribution, run canary shards with weighted traffic, and progressively shift tenants. Implement drif","explanation":"## Why This Is Asked\nTests mastery of live CNF config delivery under scale, using dynamic route management, traffic shaping, and robust rollback. It probes understanding of drift detection, observability integration, and safe rollout in multi-tenant environments.\n\n## Key Concepts\n- Zero-downtime rolling updates with canary deployments\n- Dynamic configuration distribution and consistency\n- Drift detection and automated rollback with observability\n\n## Code Example\n```javascript\n// Pseudo-implementation snippet to illustrate traffic weight update\nasync function rollWithCanary(nextWeight) {\n  await distributeConfig({ tenants: 'all', weight: nextWeight });\n  await monitorErrors(60_000);\n  if (riskTooHigh()) rollback();\n}\n```\n\n## Follow-up Questions\n- How would you detect hidden slippage in latency during canary?\n- How would you handle tenants with non-uniform traffic patterns during ramp?","diagram":"flowchart TD\n  A[Config Bus] --> B[Rule Distribution]\n  B --> C[Canary Shard]\n  C --> D[Metrics/Observability]\n  B --> E[Active Routes]\n  D --> F[Rollback on Regression]","difficulty":"advanced","tags":["cnf-certification"],"channel":"cnf-certification","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Meta","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:31:16.146Z","createdAt":"2026-01-12T18:31:16.146Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber"],"stats":{"total":44,"beginner":15,"intermediate":16,"advanced":13,"newThisWeek":44}}