{"questions":[{"id":"aws-devops-pro-config-management-1768216764137-0","question":"You manage infrastructure with Terraform using a remote state stored in S3. An operator manually changes an EC2 instance type, causing drift from the declared configuration. What is the most reliable way to detect this drift and revert to the desired state in a production pipeline?","answer":"[{\"id\":\"a\",\"text\":\"Run terraform plan (which refreshes the state) to detect drift, then run terraform apply to revert to the desired state\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use AWS Config drift detection to identify drift and then apply the manual changes to the instance\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Run terraform refresh to update state and then manually patch the EC2 instance to match the config\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Destroy the instance and recreate it from scratch with terraform apply\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Terraform plan (with state refresh) compares the real infrastructure against the desired state in code and the current state file, allowing you to identify drift. Running terraform apply then enacts the changes to revert to the declared configuration. \n\n## Why Other Options Are Wrong\n- Option B: AWS Config drift detection helps identify drift but does not automatically revert infrastructure to match Terraform configurations managed by IaC. It often requires additional remediation steps outside Terraform.\n- Option C: terraform refresh alone updates the state but does not enforce or apply changes to resources; manual patches break IaC discipline and drift remains.\n- Option D: Destroying and recreating can work but is disruptive and not idempotent; it’s not the recommended way to reconcile drift in a controlled IaC workflow.\n\n## Key Concepts\n- Terraform state and drift detection\n- Idempotent infrastructure with IaC and plan/apply workflow\n- Remote state management in S3\n\n## Real-World Application\n- In production, teams detect drift via planned state refresh checks and automatically re-apply configurations to maintain compliance with IaC definitions.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","drift-detection","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"config-management","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:19:24.139Z","createdAt":"2026-01-12 11:19:24"},{"id":"aws-devops-pro-config-management-1768216764137-1","question":"You are designing a Terraform-based deployment that provisions EC2 instances and uses a database password stored in AWS Secrets Manager. To avoid storing secrets in code or state, which approach is best for secret management in this scenario?","answer":"[{\"id\":\"a\",\"text\":\"Store the secret in AWS Secrets Manager and reference it in Terraform via a data source when rendering the instance's user-data\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Embed the secret directly in a Terraform variable and commit it to the repository\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store the secret in an S3 bucket in plaintext and fetch it at provisioning time\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Pass the secret through environment variables on the CI runner only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because secrets are best managed by a dedicated secret store (Secrets Manager) with controlled access and rotation. The Terraform data source can fetch the secret securely at plan/apply time without storing it in code or state. \n\n## Why Other Options Are Wrong\n- Option B: Embedding secrets in code or variables defeats secret management and exposes sensitive data in version control.\n- Option C: Storing plaintext secrets in S3 is insecure and risks leakage.\n- Option D: Passing secrets only via CI runner environment variables risks exposure in logs and does not centralize secret management across environments.\n\n## Key Concepts\n- Secrets management with AWS Secrets Manager\n- Data sources in Terraform to fetch secrets securely\n- Avoiding secret leakage in IaC state\n\n## Real-World Application\n- Enables secure, auditable secret handling across deployments and simplifies rotation workflows.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Secrets Manager","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"config-management","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:19:24.487Z","createdAt":"2026-01-12 11:19:24"},{"id":"aws-devops-pro-config-management-1768216764137-2","question":"In a multi-account AWS environment, you want to ensure a consistent tagging policy across all resources created by Terraform across accounts and environments. Which approach best achieves this with minimal drift and reusable code?","answer":"[{\"id\":\"a\",\"text\":\"Create a centralized Terraform module that applies a standard set of tags to all resources and enforce usage of the module across environments\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on AWS Config to flag resources without required tags and manually remediate\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use CloudFormation StackSets to enforce tags on resources\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Tag resources manually after deployment to ensure coverage\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because centralizing tagging logic in a reusable Terraform module guarantees consistent tags across all resources and environments, reducing drift and ensuring policy-compliant deployments. \n\n## Why Other Options Are Wrong\n- Option B: AWS Config helps detect non-compliant tags but remediation across many accounts is more error-prone and slower than a single source of truth in Terraform modules.\n- Option C: CloudFormation StackSets are not used to enforce Terraform tagging policies and would complicate a Terraform-centric workflow.\n- Option D: Manual tagging is error-prone and inconsistent across accounts.\n\n## Key Concepts\n- Terraform modules as policy of infrastructure\n- Tagging best practices in IaC\n- Multi-account governance\n\n## Real-World Application\n- Ensures consistent cost allocation and compliance across dozens of accounts with minimal manual intervention.","diagram":null,"difficulty":"intermediate","tags":["Terraform","AWS","Tagging","Policy as Code","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"config-management","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:19:24.835Z","createdAt":"2026-01-12 11:19:24"},{"id":"q-676","question":"You have a Node.js app deployed on EC2 instances behind an Application Load Balancer in a private VPC. You want a beginner-friendly, repeatable CI/CD pipeline that triggers on git pushes, runs tests, and safely deploys with rollback. Describe a practical setup using AWS CodePipeline, CodeBuild, and CodeDeploy (blue/green) to auto-build, test, and deploy with artifact flow in S3, and IAM roles with least privilege, including how to isolate staging vs production using separate target groups?","answer":"Describe a practical setup using AWS CodePipeline, CodeBuild, and CodeDeploy (blue/green) to auto-build, test, and deploy a Node.js app on EC2 behind an ALB, with artifacts in S3 and IAM roles with le","explanation":"## Why This Is Asked\n\nAssesses practical understanding of building an end-to-end CI/CD pipeline on AWS with concrete services, artifact handling, and rollback.\n\n## Key Concepts\n\n- CodePipeline source, build, deploy stages\n- Blue/green deployment with CodeDeploy\n- IAM least privilege roles and policy scoping\n- S3 artifacts and environment isolation\n\n## Code Example\n\n```bash\n# Example CLI invocation to create a pipeline (simplified)\naws codepipeline create-pipeline --cli-input-json file://pipeline.json\n```\n\n## Follow-up Questions\n\n- How would you validate the rollback path and automate it?\n- What are common pitfalls with blue/green workloads on EC2?","diagram":"flowchart TD\n  SourceGitHub[GitHub] --> Pipeline[CodePipeline]\n  Pipeline --> Build[CodeBuild]\n  Build --> Deploy[CodeDeploy (Blue/Green)]\n  Deploy --> ProdALB[ALB Target Group (Prod)]\n  ProdALB --> Health[Health Checks]\n  Health -->|OK| End[Done]\n  Health -->|Fail| Rollback[Rollback to Previous]","difficulty":"beginner","tags":["aws-devops-pro"],"channel":"aws-devops-pro","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Discord","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T14:47:30.424Z","createdAt":"2026-01-11T14:47:30.424Z"},{"id":"q-890","question":"Design an AWS-based CI/CD pipeline for a data platform (S3 data lake, Lambda ETL, ECS) that sources from Git, runs unit tests and data quality checks (Great Expectations) on staging data, then plans/applies Terraform in staging and promotes to production with canary deployment and traffic shift. Explain IAM least-privilege, S3 artifact flow, and staging vs prod isolation?","answer":"Propose a staged pipeline: source from Git to CodePipeline; CodeBuild runs unit tests and data quality checks against staging data in S3; Terraform plan/apply runs in a staging account; promote to pro","explanation":"## Why This Is Asked\n\nTests a real-world, multi-account CI/CD setup for a data platform, emphasizing data quality gates, safe promotion, and robust rollback.\n\n## Key Concepts\n\n- AWS CodePipeline/CodeBuild for CI\n- Great Expectations data quality checks\n- Terraform in staging vs prod with isolated state\n- Canary or blue/green deployment with traffic shift\n- Cross-account IAM and least privilege\n- S3-based artifact flow and versioning\n\n## Code Example\n\n```hcl\n# Terraform backend separation example\nterraform {\n  backend \"s3\" {\n    bucket = \"tf-artifacts-staging\"\n    key    = \"env/staging/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you implement rollback if data quality gates fail mid-deploy?\n- What monitoring and alerting would you add for canary promotions?","diagram":"flowchart TD\n  A[Git] --> B[CodePipeline]\n  B --> C{Staging}\n  C --> D[Unit Tests & Data Quality]\n  D --> E[Terraform Plan - Staging]\n  E --> F[Terraform Apply - Staging]\n  F --> G[Promote to Prod Canary]\n  G --> H[Traffic Shift]\n  H --> I[Prod Alarms & Rollback]\n  I --> J[Failure Handling]","difficulty":"intermediate","tags":["aws-devops-pro"],"channel":"aws-devops-pro","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Citadel","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:30:19.001Z","createdAt":"2026-01-12T14:30:19.001Z"},{"id":"q-924","question":"Design a beginner-friendly AWS CI/CD pipeline for a serverless REST API deployed to AWS Lambda behind API Gateway. Source from GitHub; CodeBuild runs unit tests with pytest and a basic security scan with bandit; artifacts stored in S3; deployment uses SAM/CFN to Lambda with separate stages dev/stage/prod and a canary traffic shift via Lambda aliases. Explain IAM least-privilege and secure env vars (Secrets Manager or SSM)?","answer":"Implement a CodePipeline with CodeBuild that clones from GitHub, installs dependencies, runs pytest and bandit, builds a Lambda deployment package, stores artifacts in S3, and deploys with SAM/CFN to ","explanation":"## Why This Is Asked\nTests end-to-end pipeline for serverless workloads, covering CI/CD, security checks, and access control at beginner level.\n\n## Key Concepts\n- CodePipeline + CodeBuild for serverless workflows\n- Lambda versioning and traffic shifting (canary)\n- IAM least privilege per environment\n- Secrets management (Secrets Manager or SSM Parameter Store with KMS)\n\n## Code Example\n```yaml\n# Simplified SAM/CFN deployment snippet\nResources:\n  ApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.lambda_handler\n      Runtime: python3.9\n      Environment:\n        Variables:\n          DB_PASSWORD: {{resolve:ssm-secure:/prod/db/password:1}}\n```\n\n## Follow-up Questions\n- How would you roll back a failed canary step?\n- How do you rotate credentials without downtime?\n","diagram":"flowchart TD\nA[GitHub Repo] --> B[CodeBuild]\nB --> C[S3 Artifact]\nC --> D[CodePipeline]\nD --> E[Lambda Versioned Alias]\nE --> F[Canary Traffic Shift]","difficulty":"beginner","tags":["aws-devops-pro"],"channel":"aws-devops-pro","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Square","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:35:01.144Z","createdAt":"2026-01-12T15:35:01.144Z"},{"id":"aws-devops-pro-sdlc-automation-1768181394902-0","question":"You have a microservices app deployed to Amazon ECS Fargate behind an Application Load Balancer. Your CI/CD pipeline uses CodePipeline with CodeBuild and a separate CodeDeploy stage to deploy service revisions. To minimize downtime during a deployment, which deployment strategy should you adopt?","answer":"[{\"id\":\"a\",\"text\":\"Use ECS rolling updates with CodePipeline deploy stage\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use CodeDeploy blue/green deployments for ECS\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Perform an in-place update and swap target groups manually\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Update the task definition and redeploy without traffic shifting\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct: CodeDeploy blue/green deployments for ECS enable traffic shifting between the original and new task sets, allowing instant rollback and minimal downtime. \n\n## Why Other Options Are Wrong\n- Option A: ECS rolling updates may still cause brief downtime if not tuned for min healthy percent and desired count; it doesn’t guarantee seamless traffic shift like blue/green.\n- Option C: Manual traffic switching is error-prone and adds operational overhead, defeating automation goals.\n- Option D: Updating the task definition in place without traffic shifting can cause service interruptions during new task deployment.\n\n## Key Concepts\n- ECS blue/green deployments\n- Traffic shifting and minimal-downtime releases\n- CodePipeline integration with CodeDeploy for ECS\n\n## Real-World Application\n- Configure CodeDeploy deployment group for your ECS service.\n- Set up a load balancer listener rule to shift traffic from old to new task sets gradually.\n- Implement rollback triggers to revert if metrics exceed thresholds.\n","diagram":null,"difficulty":"intermediate","tags":["AWS CodePipeline","AWS CodeDeploy","Amazon ECS","Fargate","certification-mcq","domain-weight-22"],"channel":"aws-devops-pro","subChannel":"sdlc-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:54.904Z","createdAt":"2026-01-12 01:29:55"},{"id":"aws-devops-pro-sdlc-automation-1768181394902-1","question":"You are building a multi-account CI/CD pipeline that deploys resources via Terraform. You want to ensure secrets are not exposed in code or logs and are rotated securely. Which approach provides the best balance of security and automation?","answer":"[{\"id\":\"a\",\"text\":\"Store secrets in AWS Secrets Manager and fetch them at runtime in the pipeline with an IAM role\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Commit secrets to the repository as encrypted files with the key checked in alongside code\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Pass secrets as plain environment variables in the build project\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Store secrets in an S3 bucket with public read access and fetch them via URL\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct: AWS Secrets Manager (or Secrets Manager-backed retrieval) with an IAM role scoped to the pipeline enables automatic rotation and secure, runtime access without embedding secrets in code or logs. \n\n## Why Other Options Are Wrong\n- Option B: Storing secrets in the repository—even if encrypted—risks exposure if encryption is compromised or keys are mishandled.\n- Option C: Plaintext environment variables risk leakage in logs and process listings; they also don’t support automatic rotation.\n- Option D: Public S3 access exposes secrets to anyone and violates least-privilege security practices.\n\n## Key Concepts\n- Secrets management in CI/CD\n- Rotation and least-privilege access with IAM roles\n- Runtime retrieval of secrets during builds\n\n## Real-World Application\n- Create Secrets Manager entries for each secret and map them to CodeBuild/CodePipeline tasks via IAM roles.\n- Enable automatic rotation and audit access via CloudTrail.\n- Remove any secret references from buildspec and logs.\n","diagram":null,"difficulty":"intermediate","tags":["AWS Secrets Manager","AWS CodeBuild","IAM","CI/CD","certification-mcq","domain-weight-22"],"channel":"aws-devops-pro","subChannel":"sdlc-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:55.390Z","createdAt":"2026-01-12 01:29:55"},{"id":"aws-devops-pro-sdlc-automation-1768181394902-2","question":"In a Terraform-based IaC workflow used across multiple environments, you want to enforce policy compliance before applying changes and catch drift automatically. Which approach best achieves this in a scalable, collaborative setup?","answer":"[{\"id\":\"a\",\"text\":\"Use Terraform Cloud with Sentinel policies to gate apply plans\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Run terraform apply directly in CI without plan or policy checks\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Migrate to CloudFormation to avoid Terraform policy concerns\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely on manual approvals in the pipeline without automated policy checks\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct: Terraform Cloud (or Terraform Enterprise) with Sentinel enables policy as code, enforcing compliance before plans are applied and enabling drift detection across teams. \n\n## Why Other Options Are Wrong\n- Option B: Skipping policy checks undermines governance and increases risk of non-compliant deployments.\n- Option C: CloudFormation is a different IaC tool; migrating does not address Terraform-specific policy needs and may introduce workflow disruption.\n- Option D: Manual approvals alone lack automated policy enforcement and drift detection, reducing scalability.\n\n## Key Concepts\n- Policy as code with Sentinel\n- Gatekeeping plan/apply in Terraform workflows\n- Drift detection and multi-account governance\n\n## Real-World Application\n- Integrate Terraform Cloud/Enterprise with your VCS; define policies (e.g., tagging, encryption, no public access).\n- Require policy-compliant plans before apply; implement drift checks as part of the pipeline.\n- Audit policy hits and provide actionable remediation guidance to teams.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Terraform Cloud","Sentinel","IaC","CI/CD","certification-mcq","domain-weight-22"],"channel":"aws-devops-pro","subChannel":"sdlc-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:55.857Z","createdAt":"2026-01-12 01:29:55"},{"id":"aws-devops-pro-security-compliance-1768228273614-0","question":"An AWS Organization has an OU with an SCP that restricts most IAM actions by default. A CI/CD pipeline in a member account needs to create EC2 instances, S3 buckets, and IAM roles for deployments. Which approach best achieves least privilege while allowing the pipeline to perform only the required actions?","answer":"[{\"id\":\"a\",\"text\":\"Attach a dedicated pipeline IAM role with precisely scoped permissions and apply a permission boundary to cap allowed actions.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Temporarily remove the SCP restrictions so the pipeline can operate.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Grant the pipeline role full admin privileges and monitor using audits.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Move the pipeline to a separate, less-restrictive OU.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A. Attach a dedicated pipeline IAM role with precisely scoped permissions and apply a permission boundary to cap allowed actions.\n\n## Why Other Options Are Wrong\n- B: Removing SCP restrictions defeats the purpose of centralized governance and undermines least privilege.\n- C: Full admin privileges contradict the principle of least privilege and increase risk.\n- D: Moving the pipeline to another OU does not resolve the governance constraints and reduces centralized control.\n\n## Key Concepts\n- IAM permission boundaries\n- Service Control Policies (SCPs)\n- Least privilege principle in multi-account environments\n\n## Real-World Application\n- Use this pattern for CI/CD pipelines that deploy across accounts while keeping governance intact and minimizing blast radius.","diagram":null,"difficulty":"intermediate","tags":["AWS","IAM","SCP","Organizations","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:31:13.615Z","createdAt":"2026-01-12 14:31:14"},{"id":"aws-devops-pro-security-compliance-1768228273614-1","question":"To enforce encryption at rest across multi-account S3 buckets and EBS volumes and ensure CMK rotation, which approach provides ongoing enforcement and visibility?","answer":"[{\"id\":\"a\",\"text\":\"Enable AWS Config with managed rules for kms-key-rotation-enabled and s3-bucket-encrypted-with-cmk and configure remediation.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on periodic manual audits of encryption settings.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use bucket policies to require SSE-KMS but do not enforce rotation.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use SCPs to prevent use of SSE-S3.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A. Enable AWS Config with managed rules kms-key-rotation-enabled and s3-bucket-encrypted-with-cmk and configure remediation.\n\n## Why Other Options Are Wrong\n- B: Manual audits are not proactive or scalable for multi-account environments.\n- C: Requiring SSE-KMS in policies enforces encryption but does not guarantee rotation of CMKs across accounts.\n- D: SCPs cannot reliably enforce encryption mode and rotation at scale.\n\n## Key Concepts\n- AWS Config managed rules (kms-key-rotation-enabled, s3-bucket-encrypted-with-cmk)\n- Centralized compliance and remediation\n- CMK rotation governance\n\n## Real-World Application\n- Ideal for org-wide encryption governance with automated detection and remediation.","diagram":null,"difficulty":"intermediate","tags":["AWS","KMS","S3","Config","Compliance","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:31:14.397Z","createdAt":"2026-01-12 14:31:14"},{"id":"aws-devops-pro-security-compliance-1768228273614-2","question":"A DevOps pipeline stores credentials in AWS Secrets Manager and must rotate credentials automatically for a Postgres RDS instance every 30 days. Which option ensures automatic rotation with minimal downtime?","answer":"[{\"id\":\"a\",\"text\":\"Enable Secrets Manager automatic rotation for the secret using the provided rotation function for RDS.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rotate credentials manually in Secrets Manager every 30 days.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store credentials in SSM Parameter Store and rotate on a schedule.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Embed credentials in the application code and rotate manually.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A. Enable Secrets Manager automatic rotation for the secret using the provided rotation function for RDS.\n\n## Why Other Options Are Wrong\n- B: Manual rotation introduces delay and human error risks.\n- C: SSM Parameter Store rotation is not natively connected to RDS rotation workflows.\n- D: Embedding credentials in code is insecure and brittle.\n\n## Key Concepts\n- Secrets Manager rotation templates for RDS\n- Automated credential rotation\n- Minimal downtime during rotation\n\n## Real-World Application\n- Maintains database access credentials securely with predictable rotation cycles, reducing exposure.","diagram":null,"difficulty":"intermediate","tags":["AWS","SecretsManager","RDS","CI/CD","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:31:14.914Z","createdAt":"2026-01-12 14:31:14"},{"id":"aws-devops-pro-security-compliance-1768228273614-3","question":"In an EKS cluster, you need a pod to access a specific S3 bucket with least privilege. Which configuration achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Create an IAM OIDC provider for the cluster, bind an IAM role with a policy scoped to the bucket to a Kubernetes ServiceAccount used by the pod.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Attach the bucket policy to all pods in the cluster.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store credentials in Kubernetes secrets and mount as environment variables.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Grant the node instance role broad S3 access.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A. Create an IAM OIDC provider for the cluster, bind an IAM role with a policy scoped to the bucket to a Kubernetes ServiceAccount used by the pod.\n\n## Why Other Options Are Wrong\n- B: Bucket policies applied to all pods are overly permissive and violate least privilege.\n- C: Storing credentials in Kubernetes secrets and env vars is insecure and hard to rotate.\n- D: Granting the node instance role broad S3 access gives excessive privileges to all pods on the node.\n\n## Key Concepts\n- IRSA (IAM Roles for Service Accounts)\n- OIDC federation for EKS\n- Least privilege for pod access\n\n## Real-World Application\n- Enables fine-grained AWS permissions for specific workloads without leaking credentials.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","EKS","IRSA","IAM","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:31:15.076Z","createdAt":"2026-01-12 14:31:15"},{"id":"aws-devops-pro-security-compliance-1768228273614-4","question":"You want to detect and prevent unencrypted data in S3 across an organization. Which approach provides continuous visibility and automatic remediation?","answer":"[{\"id\":\"a\",\"text\":\"Enable AWS Config with managed rules s3-bucket-server-side-encryption-enabled and kms-key-rotation-enabled, with automated remediation.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on CloudTrail daily audits of bucket configurations.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enforce encryption using IAM policies on users.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable S3 access logs and inspect them to identify non-encrypted buckets.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- A. Enable AWS Config with managed rules s3-bucket-server-side-encryption-enabled and kms-key-rotation-enabled, with automated remediation.\n\n## Why Other Options Are Wrong\n- B: CloudTrail audits alone do not provide continuous enforcement or remediation.\n- C: IAM policies cannot reliably enforce encryption at rest across buckets; policies don’t automatically remediate non-compliant resources.\n- D: Access logs reveal activity but do not prevent or remediate non-encrypted data.\n\n## Key Concepts\n- AWS Config managed rules for S3 encryption\n- Automated remediation in Config\n- Continuous enforcement and visibility\n\n## Real-World Application\n- Ensures org-wide data protection by automatically identifying and remediating non-encrypted S3 buckets.","diagram":null,"difficulty":"intermediate","tags":["AWS","Config","S3","Compliance","certification-mcq","domain-weight-17"],"channel":"aws-devops-pro","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:31:15.240Z","createdAt":"2026-01-12 14:31:15"}],"subChannels":["config-management","general","sdlc-automation","security-compliance"],"companies":["Anthropic","Citadel","Cloudflare","Databricks","Discord","Google","Microsoft","Square","Uber"],"stats":{"total":14,"beginner":2,"intermediate":12,"advanced":0,"newThisWeek":14}}