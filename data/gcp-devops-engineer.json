{"questions":[{"id":"q-1013","question":"You're managing a multi-tenant SaaS on GCP across five projects connected via Shared VPC. You must enforce per-tenant network isolation, IAM conditions, and budget governance while keeping CI/CD simple. Propose an end-to-end setup using Shared VPC, IAM Conditions, VPC Service Controls, Billing Budgets, and Cloud Asset Inventory, and outline testing and rollback steps?","answer":"Design a per-tenant isolation strategy: use Shared VPC, per-tenant IAM roles with conditional bindings, VPC Service Controls, and per-tenant budgets; implement CI/CD using Cloud Build to apply IaC (Te","explanation":"## Why This Is Asked\n\nThis question probes practical multi-tenant isolation, policy-as-code, and operational testing in GCP.\n\n## Key Concepts\n\n- Shared VPC and host projects\n- IAM Conditions for per-tenant access\n- VPC Service Controls for data exfil prevention\n- Billing Budgets and cost monitoring per tenant\n- Cloud Asset Inventory for drift detection\n- CI/CD with Terraform and Cloud Build\n- Policy-as-code (OPA) and guardrails\n\n## Code Example\n\n```javascript\n// sample budget per tenant\nresource \"google_billing_budget\" \"tenant_budget\" {\n  billing_account = var.billing_account_id\n  display_name    = \"tenant-${var.tenant_id}-budget\"\n\n  amount {\n    specified_amount {\n      currency_code = \"USD\"\n      units         = 1000\n    }\n  }\n\n  threshold_rules {\n    threshold_percent = 0.8\n    spend_basis       = \"CURRENT_SPEND\"\n  }\n\n  // optional fields omitted for brevity\n}\n```\n\n```javascript\n// per-tenant IAM condition (example)\nresource \"google_project_iam_member\" \"tenant_view\" {\n  project = var.tenant_project_id\n  role    = \"roles/viewer\"\n  member  = \"user:${var.user_email}\"\n  condition {\n    title       = \"tenant_is_owner\"\n    expression  = \"resource.name.startsWith('projects/${var.tenant_project_id}')\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you test drift between intended IAM bindings and actual bindings?  \n- How would you handle onboarding/offboarding tenants without disruptive outages?","diagram":"flowchart TD\n  A[Tenant Creation] --> B[Configure Shared VPC & IAM] \n  B --> C[Apply Budget & Guardrails] \n  C --> D[CI/CD Deployment] \n  D --> E[Monitoring & Auditing]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T19:27:58.378Z","createdAt":"2026-01-12T19:27:58.378Z"},{"id":"q-1041","question":"Design a scalable, compliant log routing pipeline on GCP that collects logs from Kubernetes clusters, Cloud Run, and Cloud Functions, redacts PII, and stores in BigQuery with environment separation. Include data flow sinks, IAM and CMEK governance, failure modes and retries, and an end-to-end testing plan?","answer":"Export logs from GKE, Cloud Run, and Cloud Functions via Cloud Logging Log Router to GCS per environment; run a Cloud Dataflow pipeline that uses the DLP API to redact PII and writes to a partitioned ","explanation":"Why This Is Asked: Assesses ability to design a compliant, scalable log pipeline across multiple services with data redaction and governance. Key trade-offs include latency vs. cost, code vs managed services, and testing rigor.","diagram":"flowchart TD\n  A[Logs: GKE/Cloud Run/Functions] --> B[Router Sink to GCS]\n  B --> C[Dataflow + DLP Redaction]\n  C --> D[BigQuery: env-specific]\n  D --> E[Access & Compliance]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T20:29:17.568Z","createdAt":"2026-01-12T20:29:17.568Z"},{"id":"q-1155","question":"You're deploying a globally distributed service on GKE across three regions, with Cloud Run and Cloud Functions used for specific workloads. Design a deployment pipeline that enforces policy-as-code, encryption at rest via CMEK, drift detection, automated rollback, and cross-region failover. Describe tooling, data planes, tests, and how you handle outages and compliance?","answer":"Use a GitOps approach with Cloud Deploy across all regions, anchoring policies in OPA (policy-as-code) and enforcing CMEK with IAM Conditions. Implement canary releases via traffic-splitting between G","explanation":"## Why This Is Asked\nAssesses real-world skills in GitOps, policy-as-code, cross-region DR, and automated rollback.\n\n## Key Concepts\n- GitOps and Cloud Deploy\n- Policy-as-code with OPA\n- CMEK and IAM Conditions\n- Canary traffic routing across GKE/Cloud Run\n- Drift detection and regional failover\n\n## Code Example\n```javascript\n// Pseudo-code: trigger a rollback if a metric breaches a threshold\nasync function maybeRollback(metrics) {\n  if (metrics.latency > 500 || metrics.errorRate > 0.02) {\n    await cloudDeploy.rollback();\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test drift detection across regions?\n- How do you simulate regional outages and verify failover?","diagram":"flowchart TD\nA[GitOps Repo] --> B[Cloud Deploy Pipeline]\nB --> C[Regions: us, eu, ap]\nC --> D[GKE/Cloud Run/Functions]\nD --> E[Drift Checks]\nE --> F{Status}\nF --> G[Rollback]\nF --> H[Continue]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:28:10.252Z","createdAt":"2026-01-13T03:28:10.252Z"},{"id":"q-1245","question":"You operate a global chat app with components on **GKE**, **Cloud Run**, and **Cloud Functions**. Latency spikes in one region go unnoticed in aggregated metrics. Design an end-to-end observability approach: (1) how to unify traces across runtimes, (2) how to instrument with **OpenTelemetry** and **OTLP** to a central collector, (3) how to build region-scoped dashboards and **SLO-based alerts**, and (4) how to validate during release with **canary** and **chaos testing**. Include tool choices, sample metrics, and a minimal config sketch?","answer":"Implement a unified OpenTelemetry pipeline across GKE, Cloud Run, and Cloud Functions, exporting traces via OTLP to a centralized collector and tagging spans with region, service, and version. Build r","explanation":"## Why This Is Asked\n\nTests the ability to design end-to-end observability across diverse runtimes, ensuring consistent tracing, metrics, and alerting. It also probes practical integration details with OpenTelemetry, OTLP, and regional dashboards, plus validation via canary and chaos testing.\n\n## Key Concepts\n\n- OpenTelemetry and OTLP exporters\n- End-to-end tracing across GKE, Cloud Run, Cloud Functions\n- Region-scoped dashboards and SLO-based alerts\n- Canary releases and chaos engineering validation\n\n## Code Example\n\n```javascript\n// Minimal OpenTelemetry setup sketch (Node.js)\nconst { NodeTracerProvider } = require('@opentelemetry/node');\nconst { SimpleSpanProcessor } = require('@opentelemetry/tracing');\n// ... configure OTLP exporter targeting central collector\n```\n\n## Follow-up Questions\n\n- How would you handle sampling decisions during traffic spikes?\n- How would you enforce consistent trace propagation across services?\n- What metrics would you expose to Cloud Monitoring for fast attribution of regional latency spikes?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:40:56.056Z","createdAt":"2026-01-13T06:40:56.056Z"},{"id":"q-1281","question":"You're maintaining a Cloud Run Python service that reads an API key from Secret Manager. Implement a 30-day secret rotation using Cloud Scheduler to publish a rotation event to Pub/Sub, and enable the Cloud Run instance to fetch updated secret without a restart. Detail the IAM permissions, wiring, and a test plan to verify end-to-end rotation?","answer":"Use a Cloud Run service account with roles/secretmanager.secretAccessor on the secret, and a rotation mechanism (Secret Manager secret with a rotation schedule). Schedule a Cloud Scheduler job to publ","explanation":"## Why This Is Asked\n\nTests practical secret management and runtime retrieval in GCP.\n\n## Key Concepts\n\n- Secret Manager rotation, Cloud Scheduler, Pub/Sub, Cloud Run IAM bindings, request-time secret fetch.\n\n## Code Example\n\n```javascript\n// Runtime fetch of Secret Manager secret in Cloud Run (Node.js)\nconst {SecretManagerServiceClient} = require('@google-cloud/secret-manager');\nconst client = new SecretManagerServiceClient();\nasync function getApiKey() {\n  const name = 'projects/PROJECT/secrets/API_KEY/versions/latest';\n  const [version] = await client.accessSecretVersion({name});\n  const apiKey = version.payload.data.toString('utf8');\n  return apiKey;\n}\n```\n\n## Follow-up Questions\n\n- How would you test failure of rotation propagation?\n- How would you handle secret versioning and rollback?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Plaid","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:28:58.600Z","createdAt":"2026-01-13T08:28:58.601Z"},{"id":"q-1514","question":"Design a cost-aware DR plan for a multi-region GKE + Cloud Run service handling 2M events/min. implement active-active with regional load balancers, Istio-based traffic shifting, CMEK, and a VPC Service Controls perimeter. automate failover tests via Cloud Build + Chaos Mesh; define SLOs and error budgets, observability, and automatic rollback triggers on latency/error breaches?","answer":"Active-active DR across two regions using regional load balancers and Istio routing; CMEK for all data stores; VPC Service Controls to bound data. Automate failover tests with Cloud Build + Chaos Mesh","explanation":"## Why This Is Asked\nEvaluates hands-on ability to design robust, cost-conscious DR for a hybrid GKE/Cloud Run stack across regions, including security (CMEK, VPC SC), traffic control (Istio), and reliable failure testing integrated into CI/CD.\n\n## Key Concepts\n- Active-active regional DR and traffic shifting\n- Istio/Anthos Service Mesh for cross-region routing\n- CMEK and VPC Service Controls for data protection\n- Chaos testing integration with Cloud Build and Chaos Mesh\n- SLOs, error budgets, observability, and automated rollback\n\n## Code Example\n```yaml\n# Cloud Build-style pseudo-config for triggering a failover test\nsteps:\n- name: gcr.io/cloud-builders/kubectl\n  args: [\"rollout\",\"restart\",\"deployment/my-service\"]\n- name: gcr.io/chaos-mesh/chaos-mesh\n  args: [\"apply\",\"-f\",\"chaosmesh/failover.yaml\"]\n```\n\n## Follow-up Questions\n- How do you quantify acceptable failover latency and error budgets across regions?\n- What are the key failure modes during regional failover and how would you mitigate data loss risks?\n- How would you validate security controls (CMEK, VPC SC) during automated tests?","diagram":"flowchart TD\n  A[Users/Events] --> B[US-East GKE]\n  A --> C[US-West Cloud Run]\n  B --> D[Ingestion/Processing]\n  C --> D\n  D --> E[Storages & Analytics]\n  E --> F[Cross-Region Backups & CMEK]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Hugging Face","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T19:50:16.997Z","createdAt":"2026-01-13T19:50:16.997Z"},{"id":"q-1664","question":"You’re tasked with enabling per-branch ephemeral environments in Google Cloud Platform for a microservice. Every feature branch should provision an isolated Cloud Run service, a dedicated Cloud SQL instance, and Secrets Manager entries, with least-privilege IAM, a per-branch namespace, and automatic teardown after 48 hours. Outline the exact steps using only GCP-native tools (no external CI), including budgets alerts, health checks, and teardown workflow?","answer":"Use per-branch isolated Cloud Run services and Cloud SQL instances provisioned by Cloud Build triggers on branch creation. Store credentials in Secret Manager; assign a dedicated service account with ","explanation":"## Why This Is Asked\nAssesses ability to design ephemeral, auditable environments using only GCP-native tools and least-privilege IAM. Encourages thinking about per-branch isolation, lifecycle management, and cost controls.\n\n## Key Concepts\n- Ephemeral environments per feature branch\n- Least privilege IAM and service accounts\n- Cloud Run and Cloud SQL provisioning\n- Secret Manager for credentials\n- Cloud Scheduler for teardown\n- Billing budgets and health checks\n\n## Code Example\n```javascript\n// Example deployment snippet (pseudo)\ngcloud run deploy ${BRANCH}-service --image gcr.io/$PROJECT/${REPO}:${BRANCH} --region us-central1 --platform managed\n```\n\n## Follow-up Questions\n- How would you adapt this if regional availability or quotas changed?\n- How would you test the 48-hour teardown to avoid data loss or orphaned resources?","diagram":"flowchart TD\n  A[Branch] --> B[Cloud Run service]\n  B --> C[Cloud SQL instance]\n  C --> D[Secret Manager entries]\n  D --> E[Teardown job]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:46:02.407Z","createdAt":"2026-01-14T05:46:02.407Z"},{"id":"q-1685","question":"You’re tasked with cost-aware deployment for a Cloud Run service used by a mobile frontend. Create a policy that (1) halts new deployments when the monthly spend exceeds a threshold, (2) scales traffic to 20% during overages, and (3) posts a Slack alert via a Cloud Function if the bill crosses the threshold. Describe exact steps using only GCP-native tools (Billing Budgets, Cloud Monitoring, Cloud Functions) and outline a minimal end-to-end workflow?","answer":"Configure Billing Budget with a monthly threshold; publish alerts to Pub/Sub; implement a Cloud Function that posts to Slack; integrate a gating step in CI (Cloud Build) that subscribes to the budget ","explanation":"## Why This Is Asked\nTests practical use of budgets, alerts, and automation to control deployments and alert on spend. It validates ability to design a self-contained, cloud-native workflow.\n\n## Key Concepts\n- Billing Budgets and alerts\n- Pub/Sub as event channel\n- Cloud Functions for webhook posting\n- Cloud Monitoring for alerting thresholds\n- Traffic splitting in Cloud Run or CI gating\n\n## Code Example\n```javascript\n// sample Cloud Function to post Slack webhook\nconst https = require('https');\nexports.postToSlack = (event, context) => {\n  const payload = JSON.stringify({ text: `Budget alert: ${event.data ? Buffer.from(event.data, 'base64').toString() : 'budget event' }`});\n  const req = https.request({ hostname: 'hooks.slack.com', path: '/services/...', method: 'POST', headers: {'Content-Type':'application/json'} }, res => { res.on('data', ()=>{}); });\n  req.write(payload);\n  req.end();\n};\n```\n\n## Follow-up Questions\n- How would you test this workflow end-to-end without incurring real charges?\n- How would you handle race conditions between spend spikes and deployment gates?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T06:56:34.254Z","createdAt":"2026-01-14T06:56:34.254Z"},{"id":"q-1763","question":"You operate a large-scale IoT ingestion pipeline on GCP: millions of device events per minute flow from Pub/Sub into Dataflow (Apache Beam) and write to BigQuery. Design an architecture that guarantees near real-time processing with exactly-once semantics, handles late data, and supports schema evolution; include windowing, idempotent writes, backpressure, and a rollback/testing plan for Dataflow job updates. What would you implement and why?","answer":"Use a streaming Dataflow pipeline: Pub/Sub -> Dataflow (Beam) -> BigQuery. Guarantee exactly-once by deduplicating on a per-event_id using a per-key stateful DoFn and writing to a staging table, follo","explanation":"## Why This Is Asked\nTests a practical, end-to-end streaming pipeline with real-time constraints, data integrity, and operational resilience. It probes deduplication strategies, windowing decisions, schema evolution handling, and rollback plans.\n\n## Key Concepts\n- Streaming Dataflow and Apache Beam primitives\n- Exactly-once semantics via dedupe and staging tables\n- Windowing and late data handling\n- BigQuery upserts via MERGE and schema evolution\n- Pub/Sub ordering and dead-lettering\n\n## Code Example\n```python\nimport apache_beam as beam\n\nclass DedupDoFn(beam.DoFn):\n  def process(self, element, *args, **kwargs):\n    # simplistic per-event_id dedupe placeholder\n    yield element\n\nSCHEMA = {\n  'fields': [ {'name': 'device_id', 'type': 'STRING'}, {'name': 'value', 'type': 'FLOAT'}, {'name': 'event_id', 'type': 'STRING'} ]\n}\n\nwith beam.Pipeline(...) as p:\n  (p\n   | 'ReadPubSub' >> beam.io.ReadFromPubSub(...)\n   | 'Parse' >> beam.Map(lambda b: json.loads(b))\n   | 'Dedup' >> beam.ParDo(DedupDoFn())\n   | 'WriteStaging' >> beam.io.WriteToBigQuery('project:dataset.staging', schema=SCHEMA, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n  )\n```\n\n## Follow-up Questions\n- How would you monitor for schema drift and automate a safe deployment when the schema changes?\n- What rollback plan would you implement if the MERGE into the main table fails mid-flight?","diagram":"flowchart TD\n  A[Pub/Sub] --> B[Dataflow (Beam)]\n  B --> C[staging.BigQuery]\n  C --> D[main.BigQuery (MERGE)]\n  B --> E[Dead Letter (GCS)]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T09:48:18.586Z","createdAt":"2026-01-14T09:48:18.586Z"},{"id":"q-1819","question":"You manage a Cloud SQL PostgreSQL instance in GCP and need a reliable disaster-recovery workflow with automated daily backups to Cloud Storage. Explain how to implement this using Cloud Scheduler and a Cloud Function that calls the Cloud SQL Admin API to export to gs://my-backups/sql-dump-YYYYMMDD.sql. Include required IAM roles, bucket lifecycle policies, and how you would validate a restore?","answer":"Enable automated backups on the Cloud SQL instance and create a Cloud Storage bucket for exports. Create a Cloud Scheduler job that triggers a Cloud Function, which calls the Cloud SQL Admin API to ex","explanation":"## Why This Is Asked\nSituations demand reliable DR with minimal ops. This tests automation, GCP-native tooling, and safe access controls.\n\n## Key Concepts\n- Cloud SQL Admin API exports\n- Cloud Scheduler + Cloud Functions permissions\n- Cloud Storage bucket lifecycle and IAM least privilege\n- Restore validation and retention strategies\n\n## Code Example\n```javascript\n// Placeholder for Cloud Function exporting Cloud SQL via API (Node.js)\nconst {google} = require('googleapis');\n// build and call sqladmin.instances.export(...)\n```\n\n## Follow-up Questions\n- How would you test export idempotency and failure retries?\n- How would you enforce encryption keys and access controls for backups?","diagram":"flowchart TD\n  A[Cloud Scheduler Job] --> B[Cloud Function (export)]\n  B --> C[Cloud SQL Admin API]\n  C --> D[gs://my-backups/sql-dump-YYYYMMDD.sql]\n  D --> E[Lifecycle & Retention]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T11:52:41.229Z","createdAt":"2026-01-14T11:52:41.229Z"},{"id":"q-1890","question":"In a multi-tenant SaaS on GCP requiring isolated per-tenant networks with a shared services hub, propose a scalable hub-and-spoke topology using Shared VPC and Private Service Connect. Include least-privilege IAM, per-tenant firewall rules, and Private Google Access. How would you implement policy-as-code, drift detection, automated rollback, and observability across tenants?","answer":"Hub-and-spoke: a Shared VPC host for shared services, per-tenant service projects with isolated VPCs, and Private Service Connect to access authentication and telemetry. Enforce least-privilege IAM, p","explanation":"## Why This Is Asked\nThis question probes practical network design for multi-tenant environments on GCP, balancing isolation with shared services, and how to enforce policy-as-code and drift prevention in production.\n\n## Key Concepts\n- Hub-and-spoke with Shared VPC for central services\n- Private Service Connect and Private Google Access\n- Least-privilege IAM and per-tenant firewall controls\n- Policy-as-code (Terraform/Config Connector)\n- Drift detection (Cloud Asset Inventory, Config Connector)\n- Automated rollback (Cloud Deploy, GitOps)\n- Observability (Cloud Monitoring/Logging)\n\n## Code Example\n```javascript\n// Pseudo-terraform drift-check snippet (illustrative)\nconst desired = loadPlan('hub-per-tenant.yaml');\nconst actual = getCurrentState('tenant-a');\nif (diff(desired, actual)) {\n  triggerRollback();\n}\n```\n\n## Follow-up Questions\n- How would you onboard/offboard tenants at scale without downtime?\n- How would you prove isolation and drift coverage in a security audit?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T15:49:59.152Z","createdAt":"2026-01-14T15:49:59.152Z"},{"id":"q-1917","question":"Scenario: A Cloud Run service connects to a Cloud SQL instance. Secrets are stored in Cloud Secret Manager and injected into the container at runtime. Propose a beginner-friendly, low-risk, weekly password rotation workflow that updates the secret, triggers a rolling update with zero downtime, and provides an immutable audit trail. Include the exact GCP services you would use and a minimal 3-step sequence to implement?","answer":"Schedule a weekly Cloud Scheduler job to trigger a Cloud Function that generates a new password, updates the Cloud SQL user, and creates a new Secret Manager secret version. Then deploy a new Cloud Ru","explanation":"## Why This Is Asked\n\nTests understanding of secret rotation, zero-downtime deployments, and basic auditing in GCP.\n\n## Key Concepts\n\n- Secret Manager secret versioning and rotation\n- Cloud SQL user credential management\n- Rolling updates in Cloud Run\n- IAM least privilege and Audit Logs\n- Cloud Scheduler and Cloud Functions\n\n## Code Example\n\n```javascript\n// Example Cloud Function to rotate secret\nconst {SecretManagerServiceClient} = require('@google-cloud/secret-manager');\nconst client = new SecretManagerServiceClient();\nasync function rotateSecret(name, value){\n  const [version] = await client.addSecretVersion({ parent: name, payload: { data: Buffer.from(value) } });\n  return version;\n}\n```\n\n## Follow-up Questions\n\n- How would you test this rotation flow locally? \n- How would you implement a rollback if the new secret fails to be used by Cloud Run?","diagram":"flowchart TD\n  Scheduler[Cloud Scheduler] --> Function[Cloud Function]\n  Function --> SecretManager[Secret Manager: rotate secret]\n  SecretManager --> Run[Cloud Run revision]\n  Run --> Audit[Cloud Audit Logs]\n  Run --> Monitor[Cloud Monitoring]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T17:01:50.588Z","createdAt":"2026-01-14T17:01:50.588Z"},{"id":"q-2006","question":"You're delivering a multi-tenant SaaS on GKE and Cloud Run with strict data residency and cost controls. Design an end-to-end pattern using only GCP-native tools to achieve per-tenant isolation, regional data stores, Canary/blue-green deployment, CMEK, VPC Service Controls, and automated rollback on degraded telemetry. Outline architecture, steps, and essential config snippets?","answer":"Use per-tenant Kubernetes namespaces and IAM bindings; provision regional Cloud Spanner instances per tenant for data residency; create per-tenant BigQuery datasets; enforce network isolation with Pri","explanation":"## Why This Is Asked\nProbes real-world multi-tenant, data residency, and cost-governance challenges on GCP; tests architectural discipline and use of native tools.\n\n## Key Concepts\n- Multi-tenant isolation via per-tenant namespaces and identifiers\n- Regional data residency with Cloud Spanner and per-tenant BigQuery\n- Canary/blue-green rollout with Cloud Deploy and Traffic Director\n- CMEK, VPC Service Controls, Cloud Armor for security\n- Telemetry-driven rollback with Cloud Monitoring\n- Budget alerts and automated teardown on offboarding\n\n## Code Example\n```javascript\n// Delivery config hints (pseudo)\n{\n  // Cloud Deploy pipelines and traffic gates would be defined here in YAML-like structure\n}\n```\n\n## Follow-up Questions\n- How would you test data residency enforcement across regions?\n- How would you handle tenant onboarding/offboarding delays and retries?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T20:42:58.109Z","createdAt":"2026-01-14T20:42:58.109Z"},{"id":"q-2054","question":"Design a beginner-friendly, GCP-native CI/CD for a Cloud Run service with a private artifact repository. Describe how you would: (a) configure Cloud Build to pull a private repo and push a container image to Artifact Registry, (b) inject a database password from Secret Manager into the Cloud Run container at runtime, and (c) rotate that secret monthly using Cloud Scheduler and a Cloud Function that updates Secret Manager. Include the specific services and minimal steps?","answer":"Configure a Cloud Build pipeline to pull from the private repository, build and push a container image to Artifact Registry, deploy to Cloud Run, and integrate Secret Manager for secure database password injection at runtime.","explanation":"## Why This Is Asked\nThis question evaluates practical knowledge of designing a beginner-friendly, GCP-native CI/CD pipeline that incorporates private repositories, containerized deployments, and secure secrets management with automated rotation.\n\n## Key Concepts\n- Cloud Build for CI/CD automation\n- Artifact Registry for private container storage\n- Secret Manager for secure credential management\n- Cloud Run for serverless container deployment\n- Cloud Scheduler for automated secret rotation\n- Cloud Functions for rotation logic execution\n- IAM least privilege principles\n- End-to-end secrets workflow\n\n## Code Example\n```yaml\n# Cloud Build pipeline: build and deploy\nsteps:\n- name: gcr.io/cloud-builders/docker\n  args: ['build', '-t', 'REGION-docker.pkg.dev/PROJECT/REPO/IMAGE:TAG', '.']\n- name: gcr.io/cloud-builders/gcloud\n  args: ['run', 'deploy', 'service', '--image', 'REGION-docker.pkg.dev/PROJECT/REPO/IMAGE:TAG', '--region', 'REGION', '--platform', 'managed']\n```","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T04:40:36.011Z","createdAt":"2026-01-14T22:42:35.098Z"},{"id":"q-2234","question":"Scenario: deploy a Cloud Run service private to a specific VPC using Private Service Connect. Detail the Google-native steps: create a Serverless VPC Access connector, set up a PSC endpoint, configure private DNS, restrict ingress to internal, grant a dedicated service account run.invoker, and validate access from a VM inside the VPC while public access is blocked. What is your minimal rollout plan and validation approach?","answer":"Create a VPC and a Serverless VPC Access connector; deploy Cloud Run with ingress=internal and attach the VPC connector; create a Private Service Connect endpoint in the VPC; configure a private DNS A","explanation":"## Why This Is Asked\nSecurity-focused deployments often require private access to serverless services. This tests understanding of VPCs, Private Service Connect, DNS, and IAM in a real workflow.\n\n## Key Concepts\n- Private Service Connect\n- Serverless VPC Access\n- Cloud Run ingress internal\n- Private DNS zones\n- IAM with least privilege\n\n## Code Example\n```javascript\n// Deploy private Cloud Run\ngcloud run deploy private-service \\\n  --image gcr.io/PROJECT/priv-service:tag \\\n  --region us-central1 \\\n  --ingress internal \\\n  --vpc-connector projects/PROJECT/locations/us-central1/connectors/serverless-vpc-connector\n```\n```javascript\n// PSC endpoint and DNS setup (illustrative)\ngcloud compute addresses create private-psc-endpoint --global\ngcloud dns managed-zones create private-zone --dns-name \"private.example.internal.\"\n```\n\n## Follow-up Questions\n- How would you rotate the PSC endpoint without downtime?\n- How would you audit access with IAM conditions and VPC firewall rules?","diagram":"flowchart TD\n  A[Cloud Run Private] --> B[PSC Endpoint]\n  B --> C[VPC]\n  C --> D[Private DNS]\n  D --> E[Service Clients]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Citadel","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T08:50:51.300Z","createdAt":"2026-01-15T08:50:51.300Z"},{"id":"q-2252","question":"How would you implement a secure, GCP-native deployment pipeline for a Cloud Run service that uses vulnerability scanning and Binary Authorization to ensure only signed, non-vulnerable images are deployed, including how you would integrate Cloud Build attestation and a guard policy?","answer":"Configure vulnerability scanning for images in Artifact Registry via Container Analysis, create a Binary Authorization attestor, and configure Cloud Build to sign images before pushing. Enforce a poli","explanation":"## Why This Is Asked\nGCP-native security, image provenance, and policy enforcement are foundational for safe deployments.\n\n## Key Concepts\n- Binary Authorization\n- Attestors\n- Container Analysis vulnerability scanning\n- Cloud Build signing and attestations\n- Artifact Registry policy integration\n\n## Code Example\n```javascript\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you test the end-to-end attestation flow in CI?\n- What happens if a CVE is found after deployment, and how would you roll back?","diagram":"flowchart TD\n  A[Source] --> B[Cloud Build]\n  B --> C[Artifact Registry]\n  C --> D[Vulnerability Scan (Container Analysis)]\n  D --> E[Attestation by Attestor]\n  E --> F[Binary Authorization Policy: allowlisted]\n  F --> G[Cloud Run]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T09:37:38.373Z","createdAt":"2026-01-15T09:37:38.373Z"},{"id":"q-2332","question":"Scenario: you must implement a real-time pricing and fraud-detection service on GCP that ingests from Pub/Sub, processes with Dataflow, and stores results in BigQuery across multiple regions. Design a production-ready pipeline with canary releases, strict IAM, CMEK, and automated recovery. Include deployment strategy, observability, and teardown plan?","answer":"Propose a streaming pipeline: Pub/Sub topic feeds a Dataflow streaming job that writes to two BigQuery datasets (RAW and ENRICHED) across three regions; Cloud Run API with canary deployments via Cloud","explanation":"## Why This Is Asked\nReal-world, multi-region streaming with canaries and strict security. Tests ability to design end-to-end pipelines, gating, and cost controls.\n\n## Key Concepts\n- Real-time ingestion via Pub/Sub and Dataflow streaming\n- Multi-region BigQuery datasets and CMEK governance\n- Canary deployments with Cloud Deploy and Shard isolation\n- Least-privilege IAM and VPC-SC considerations\n- Automated rollback, budget alerts, and ephemeral env teardown\n\n## Code Example\n```python\n# Dataflow skeleton (pseudo)\nfrom apache_beam.options.pipeline_options import PipelineOptions\nwith beam.Pipeline(options=PipelineOptions()) as p:\n  (p\n   | 'Read' >> beam.io.ReadFromPubSub(topic=topic)\n   | 'Parse' >> beam.Map(parse_fn)\n   | 'WriteRaw' >> beam.io.WriteToBigQuery(table=f'{project}:{raw_ds}.{raw_table}')\n   | 'Enrich' >> beam.ParDo(enrich_fn)\n   | 'WriteEnriched' >> beam.io.WriteToBigQuery(table=f'{project}:{enriched_ds}.{enriched_table}'))\n```\n\n## Follow-up Questions\n- How would you validate cross-region failover and data residency during incident drills?\n- What metrics and thresholds trigger rollback and how would you automate it?","diagram":"flowchart TD\n  PubSub[Pub/Sub Topic] --> Dataflow[Dataflow Streaming Job]\n  Dataflow --> BQRaw[BigQuery RAW dataset]\n  Dataflow --> BQEnrich[BigQuery ENRICHED dataset]\n  API[Cloud Run API] --> LB[Global Load Balancer]\n  LB --> Users[Users]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T13:08:12.540Z","createdAt":"2026-01-15T13:08:12.540Z"},{"id":"q-2347","question":"You're running a stateful service on GKE with a Cloud SQL primary in US-CENTRAL1 and a read replica in EUROPE-WEST1. Design an end-to-end deployment and DR strategy that (1) supports blue/green or canary rollouts with automatic rollback based on latency and error-rate gates, (2) enables cross-region failover for compute and DB, (3) enforces CMEK for storage and DB, (4) implements policy-as-code and drift detection, (5) includes observability, outage handling, and compliance. Specify tooling, data planes, tests, and failure handling?","answer":"Use Cloud Deploy with blue/green or canary releases, starting at 10% traffic and ramping if latency and error-rate gates pass. DR uses cross-region GKE failover and a Cloud SQL replica; Global Load Ba","explanation":"## Why This Is Asked\nAssesses how a candidate combines deployment strategies, DR planning, and enforcement of security/compliance in a real GCP setup.\n\n## Key Concepts\n- Blue/Green and canary deployments with automatic rollback gates\n- Cross-region DR for compute and database\n- CMEK encryption for storage and Cloud SQL\n- Policy-as-code and drift detection (Config Connector, OPA)\n- Observability, outage handling, and compliance\n\n## Code Example\n```javascript\n// Pseudo-code for SLO gate\nasync function canaryGate(metrics) {\n  const latencyOk = metrics.p95 < 200;\n  const errorOk = metrics.errorRate < 0.01;\n  return latencyOk && errorOk;\n}\n```\n\n## Follow-up Questions\n- How would you validate drift detection in CI/CD and ensure fast remediations?\n- What tests would you run to validate cross-region failover without customer-visible downtime?","diagram":"flowchart TD\n  A[Source Repo] --> B[CI/CD: Cloud Build]\n  B --> C[Deployment to GKE]\n  C --> D{Canary Gate}\n  D -->|Pass| E[Traffic Shift to New Revision]\n  D -->|Fail| F[Rollback to Previous Revision]\n  G[DR Prep] --> H[Cross-region DB Replica]\n  H --> I[Global LB Failover]\n  E --> J[Observability & Compliance]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T14:36:44.022Z","createdAt":"2026-01-15T14:36:44.022Z"},{"id":"q-2383","question":"You're deploying a new Cloud Run service named text-classifier with a v2 revision. You want a 15% canary for 30 minutes and automatic rollback if latency exceeds 1.5s or error rate exceeds 0.5%. Using only GCP-native tools, specify exact steps to build/push v2 to Artifact Registry, split traffic, configure monitoring alerts, and trigger rollback via traffic changes, including minimal IAM requirements?","answer":"Build the v2 image with Cloud Build to Artifact Registry, deploy as revision v2, split 15% of traffic to v2 for 30 minutes, and monitor p95 latency (>1.5s) or error rate (>0.5%). If alert triggers, au","explanation":"## Why This Is Asked\nTests ability to design a controlled canary deployment using native GCP tools, with observable metrics and an automated rollback path suitable for beginner familiarity.\n\n## Key Concepts\n- Cloud Run revisions and traffic splitting\n- Artifact Registry and Cloud Build integration\n- Cloud Monitoring alerting and automatic rollback triggers\n- IAM roles for service accounts and deployments\n\n## Code Example\n```bash\n# Build v2 image\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/REPO/text-classifier:v2\n\n# Deploy v2 revision (partial traffic)\ngcloud run services update-traffic text-classifier --to-revisions text-classifier-v1=85,text-classifier-v2=15\n```\n\n## Follow-up Questions\n- How would you adjust the setup for a 60-minute canary with tighter latency targets?\n- What monitoring dashboards would you create to visualize canary health during the test?","diagram":"flowchart TD\n  A[Source Code] --> B[Build & Push to Artifact Registry]\n  B --> C[Deploy v1] \n  C --> D[Canary: v2 15%]\n  D --> E[Monitor p95 latency & error rate]\n  E -->|OK| F[Continue 30m]\n  E -->|Fail| G[Rollback to v1]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Hugging Face","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T15:47:09.141Z","createdAt":"2026-01-15T15:47:09.141Z"},{"id":"q-2398","question":"You're deploying a beginner-friendly Cloud Run service named text-processor. Using only GCP-native tools, design a minimal CI/CD: build and push the container to Artifact Registry, deploy v1 to Cloud Run, implement a simple traffic split (10% dev, 90% prod) for canary testing, require a manual gate before production via an additional Cloud Build trigger, and outline a rollback plan and minimal IAM?","answer":"Build and push to Artifact Registry, deploy v1 with a dev suffix, deploy v2 with a prod suffix, split traffic 10% to dev and 90% to prod, add a manual gate in Cloud Build before prod promotion, and ro","explanation":"## Why This Is Asked\nExplores practical, beginner-friendly use of Cloud Run traffic splitting, simple canary without external tooling, and a manual gate to simulate release approvals.\n\n## Key Concepts\n- Cloud Run traffic splitting with revision suffixes\n- Artifact Registry storage and image tagging\n- Cloud Build triggers and manual approval gates\n- Least-privilege IAM for automated deployments\n\n## Code Example\n```bash\ngcloud builds submit --tag us-central1-docker.pkg.dev/myproj/repo/text-processor:v1 .\ngcloud run deploy text-processor --image us-central1-docker.pkg.dev/myproj/repo/text-processor:v1 --region us-central1 --revision-suffix dev\n```\n\n## Follow-up Questions\n- How would you extend this to multi-region deployment?\n- How would you test the manual gate workflow before prod?","diagram":"flowchart TD\n  A[Code] --> B[Build → Artifact Registry]\n  B --> C[Deploy Dev (suffix: dev)]\n  B --> D[Deploy Prod (suffix: prod)]\n  C --> E[Traffic 10% Dev]\n  D --> F[Traffic 90% Prod]\n  E --> G[Gate→Prod]\n  F --> G\n","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T16:49:11.818Z","createdAt":"2026-01-15T16:49:11.818Z"},{"id":"q-2480","question":"You're running a high-traffic payment API **payline** on Cloud Run (v2) with multi-region active-active behind a Global HTTP(S) Load Balancer. Design a production deployment plan to roll out v3 with automatic rollback based on latency and error-rate metrics. Use only Google Cloud native tools. Specify: canary strategy (**5% for 15 minutes**), traffic-split commands, monitoring alerts, CMEK/Secrets Manager handling, IAM least privilege, and a rollback workflow across regions?","answer":"Build and push v3 to Artifact Registry, deploy to both regions, then update-traffic payline to v3 at 5% for 15 minutes and 95% v2. Create Cloud Monitoring alert for p95 latency >200ms or error rate >0","explanation":"## Why This Is Asked\nTests multi-region deploys, automated rollback, and security controls in a realistic PayTech scenario.\n\n## Key Concepts\n- Cloud Run revisions, traffic-splitting, global LB\n- Cloud Monitoring alerting and SLOs, auto-rollback\n- Secrets Manager, CMEK, IAM least privilege\n- Regional Cloud SQL with read replicas for DR\n\n## Code Example\n```javascript\n// Example commands (illustrative)\n// 1) build/push\n// gcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/payline:v3 .\n// 2) traffic split\n// gcloud run services update-traffic payline --to-revisions payline-v3=5,payline-v2=95 --region us-central1\n```\n\n## Follow-up Questions\n- How would you test the rollback workflow in staging?\n- How to handle secret rotation during active deployments?","diagram":"flowchart TD\n  Start[Start] --> Deploy[Deploy v3 to regions]\n  Deploy --> Canary[5% canary for 15m]\n  Canary --> Alert{Alerts trigger?}\n  Alert -- Yes --> Rollback[Rollback to v2]\n  Alert -- No --> Promote[Promote to 100%]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T19:42:00.576Z","createdAt":"2026-01-15T19:42:00.577Z"},{"id":"q-2642","question":"You're designing a streaming ingestion pipeline on GCP: Pub/Sub topic events.raw, Dataflow job events-ingest-v2 (streaming) writing to BigQuery.events_all. Using only Google-native tools, specify a concrete plan to meet: (1) exactly-once processing semantics; (2) 25% traffic canary for v2 with safe rollback; (3) malformed events go to a Dead-Letter topic; (4) automatic rollback to v1 if latency > 1.8s or error rate > 0.8% persists for 10 minutes; include monitoring, alerting, and a traffic-switching workflow that minimizes data loss?","answer":"Proposed plan: run v1 and v2 in parallel via two Pub/Sub subscriptions (hash-based routing to target 25% for v2). Dataflow streaming with a BigQuery sink providing exactly-once semantics; route malfor","explanation":"## Why This Is Asked\n\nRealistic scenario tests ability to design end-to-end streaming pipelines with canary, error handling, and rollback on GCP-native tools.\n\n## Key Concepts\n\n- Streaming Dataflow, Pub/Sub routing, BigQuery exactly-once\n- Dead-lettering, alerting, automatic rollback\n- Traffic-switching via publisher routing or subscriptions\n\n## Code Example\n\n```javascript\n// High-level snippet illustrating routing policy\nconst routing = (tenantId) => (hash(tenantId) % 4 === 0) ? 'v2' : 'v1';\n```\n\n## Follow-up Questions\n\n- How would you validate the rollback works under real latency spikes without impacting production?\n- Which data quality checks ensure no duplicates after rollback?","diagram":"flowchart TD\n  A[events.raw] --> B[Dataflow: events-ingest-v2]\n  B --> C[BigQuery: events_all]\n  A --> D[Dataflow: events-ingest-v1]\n  D --> C\n  E[Dead-letter topic] --> A","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T04:24:52.943Z","createdAt":"2026-01-16T04:24:52.943Z"},{"id":"q-2677","question":"You're maintaining a small Cloud Run (fully managed) service named image-processor with a Git-driven CI; you want to enable per-branch deployments to isolated Cloud Run services (e.g., image-processor-dev, image-processor-staging, image-processor-prod) using only GCP-native tools. Outline concrete steps to build and push the container to Artifact Registry, deploy each environment with dedicated service accounts and IAM bindings, configure traffic routing so dev/staging canaries don't affect prod, implement a gating flow to promote from dev to staging to prod via Cloud Build triggers, and specify a rollback workflow if latency > 2s or error rate > 1% persists for 10 minutes. Include minimal Secrets Manager usage and monitoring setup?","answer":"Define three Cloud Run services: image-processor-dev, image-processor-staging, image-processor-prod. Build/push to Artifact Registry: gcloud builds submit --tag us-docker.pkg.dev/PROJECT/IMAGE/image:l","explanation":"## Why This Is Asked\nTests ability to design per-environment, per-branch deployments using GCP-native tools, with isolated resources, simple promotion gates, and a clear rollback workflow. It also evaluates IAM discipline and basic monitoring integration.\n\n## Key Concepts\n- Cloud Run service per environment to isolate code and traffic\n- Artifact Registry for image storage\n- Cloud Build triggers for gate-based promotions\n- Traffic splitting via update-traffic for controlled rollouts\n- Service accounts with least privilege IAM\n- Secret management with Secret Manager\n- Cloud Monitoring for latency/error alerts and rollback signals\n\n## Code Example\n```bash\n# Build and push (dev example)\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/IMAGE/image:dev-latest\n\n# Deploy dev service with a dedicated SA\ngcloud run deploy image-processor-dev --image us-docker.pkg.dev/PROJECT/IMAGE/image:dev-latest \\\n  --region us-central1 --service-account dev-sa@PROJECT.iam.gserviceaccount.com --platform managed --allow-unauthenticated\n\n# Traffic routing: 10% to dev, 90% to prod\ngcloud run services update-traffic image-processor-prod --to-latest\n```\n\n## Follow-up Questions\n- How would you automate cleanup of old branch deployments?\n- How would you enforce a policy that prevents prod traffic from drifting without a gate?","diagram":"flowchart TD\n  A[Git Branch] --> B[Build + Push to Artifact Registry]\n  B --> C[Deploy env: dev/staging/prod]\n  C --> D[Traffic split: canary + prod]\n  D --> E{Monitoring Alert}\n  E -->|latency/err| F[Rollback to prod]\n  E -->|ok| G[Promote to next env via Cloud Build trigger]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T06:50:31.148Z","createdAt":"2026-01-16T06:50:31.148Z"},{"id":"q-2761","question":"You're releasing a new version of a real-time image-processing service on GKE. The service is deployed in us-central1 with a hot standby in us-west1. Design a cross-region canary rollout (v2) using only Google-native tools: 20% traffic for 30 minutes, automatic rollback if end-to-end latency exceeds 0.9s or error rate exceeds 0.3% for 12 minutes. Provide exact steps to build/push to Artifact Registry, deploy with traffic-splitting, configure Cloud Monitoring alerts, and rollback workflow across regions. Include CMEK/Secrets Manager usage and IAM least privilege?","answer":"Build the v2 image and push to Artifact Registry, deploy to us-west1 as a 20% canary behind a GKE Istio VirtualService, and split traffic with weighted routing. Create Cloud Monitoring alerts for end-","explanation":"## Why This Is Asked\nThis checks multi-region progressive delivery, Google-native tooling, and a robust rollback mechanism under real-world latency/error constraints.\n\n## Key Concepts\n- Cross-region deployment strategy and traffic splitting\n- GKE/Istio traffic routing (canary) with weighted votes\n- Cloud Monitoring SLOs/alerts for latency and error rate\n- Secret management and CMEK integration\n- IAM least privilege and Service Accounts\n- Automated rollback workflow across regions\n\n## Code Example\n```yaml\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: image-processor\nspec:\n  hosts:\n  - image-processor.example.com\n  http:\n  - route:\n    - destination:\n        host: image-processor\n        subset: v2\n      weight: 20\n    - destination:\n        host: image-processor\n        subset: v1\n      weight: 80\n```\n\n## Follow-up Questions\n- How would you simulate failures to validate rollback in a staging env?\n- What metrics would you surface beyond latency/error rate to decide on promotion or rollback?","diagram":"flowchart TD\n  A[Build v2 image] --> B[Push to Artifact Registry]\n  B --> C[Deploy v2 with 20% canary in us-west1]\n  C --> D[Cloud Monitoring alerts: latency, error rate]\n  D --> E{OK to promote?}\n  E -->|Yes| F[Promote to prod across regions]\n  E -->|No| G[Rollback to v1 across regions]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Databricks","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T10:50:12.721Z","createdAt":"2026-01-16T10:50:12.721Z"},{"id":"q-2786","question":"You manage a Cloud Run API named directory-service (v1) used across internal apps. To enforce a cost-control policy with only Google-native tools, design a workflow: (a) set a Billing Budget of $100/month with 50% and 90% alerts; (b) mirror these thresholds in a Cloud Monitoring alert policy with email notifications; (c) implement a simple remediation to scale min instances to 0 or pause non-prod revisions when alerted; (d) outline verification steps for alerts and remediation?","answer":"Implement a cost-control workflow using only Google-native tools: 1) create a Billing Budget for the project at $100/month with 50% and 90% alerts emailed to Ops; 2) mirror alerts in a Cloud Monitorin","explanation":"## Why This Is Asked\nTests ability to design simple, repeatable cost-control mechanisms using native tools, a core DevOps skill for beginners.\n\n## Key Concepts\n- Billing Budgets and Alerting\n- Cloud Monitoring alert policies\n- Cloud Run scaling and revision management\n- Incident response and verification\n\n## Code Example\n```bash\n# Example commands (placeholders):\n# gcloud beta billing budgets create --billing-account=ACCT --display-name=proj-budget --amount=100\n# gcloud monitoring policies create --display-name=cost-alert --conditions=...\n```\n\n## Follow-up Questions\n- How would you test this in a non-prod project?\n- How would you automate remediation beyond manual runbooks?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Meta","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T11:42:55.256Z","createdAt":"2026-01-16T11:42:55.257Z"},{"id":"q-2849","question":"You're deploying a beginner-friendly Cloud Run service named image-processor with a v2 revision. Using only Google-native tools, design a minimal canary: 10% traffic to v2 for 15 minutes, automatic rollback to v1 if latency > 1.5s or error rate > 0.5%. Include exact gcloud steps (traffic split, rollback), monitoring alerts, and minimal IAM roles?","answer":"Plan a 10% v2 canary for 15 minutes; if latency exceeds 1.5s or error rate exceeds 0.5%, rollback to v1 by routing 100% back to the previous revision. Use gcloud run services update-traffic to split t","explanation":"## Why This Is Asked\nTests practical skill in safe feature rollouts, traffic control, and observability using only Google-native tools. It also checks IAM minimalism and rollback discipline.\n\n## Key Concepts\n- Cloud Run revision traffic splitting\n- Canary rollout timing and rollback triggers\n- Cloud Monitoring alerting on latency and error rate\n- IAM least privilege for deployment\n\n## Code Example\n```bash\n# Example traffic split (replace with actual revision names)\ngcloud run services update-traffic image-processor \\\n  --to-revisions image-processor-v2=10,image-processor=90 \\\n  --platform managed --region us-central1\n```\n\n## Follow-up Questions\n- How would you adapt this for multi-region deployments?\n- How would you automate promotion to prod after a successful canary?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Google","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T14:44:08.802Z","createdAt":"2026-01-16T14:44:08.802Z"},{"id":"q-2899","question":"You're deploying a critical microservice on GKE. Use Google-native tools to rollout v2 with a 20% canary for 20 minutes to production, with automatic rollback if latency or error rate cross thresholds. Provide exact steps: build/push v2 to Artifact Registry, update manifests, configure Cloud Deploy canary, set monitoring alerts, and define rollback triggers. Include minimal IAM roles?","answer":"Use Cloud Deploy to orchestrate a canary rollout of v2 to GKE prod with 20% traffic for 20 minutes, using Artifact Registry for the image and a verification step from Cloud Monitoring (p95 latency und","explanation":"## Why This Is Asked\nTests practical, end-to-end deployment with Google-native tools, focusing on progressive delivery, monitoring, and least-privilege IAM.\n\n## Key Concepts\n- Cloud Deploy canary releases on GKE\n- Artifact Registry as image store\n- Cloud Monitoring SLIs/alerts for verification\n- Automated rollback triggers and safe IAM bindings\n\n## Code Example\n```javascript\n// Cloud Deploy manifest sketch (pseudo)\n{\n  release: 'v2-canary',\n  target: 'prod',\n  canary: { percent: 20, durationMin: 20 }\n}\n```\n\n## Follow-up Questions\n- How would you validate canary efficacy under spike traffic?\n- How would you simulate a rollback in non-prod to test the pipeline?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","IBM","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T16:51:07.613Z","createdAt":"2026-01-16T16:51:07.613Z"},{"id":"q-3020","question":"You're deploying a Cloud Run (fully managed) service 'parser-service' that ingests Pub/Sub messages and writes to BigQuery. Implement a cross-project blue/green rollout with a DR project and Private Service Connect. Using only Google-native tools, specify exact steps to build/push v4 to Artifact Registry, deploy prod-v4 and dr-v4, configure traffic splits (start: prod 15%, DR 5% for 20 minutes; then 80/20), set monitoring alerts for Pub/Sub backlog and BigQuery latency, assign minimal IAM roles, and implement automatic rollback to v3 if error rate or backlog exceed thresholds across both regions?","answer":"Deploy prod-v4 and dr-v4 as separate Cloud Run services behind Private Service Connect; push the container image to Artifact Registry; use gcloud run deploy with --image and --traffic-split flags to route 15% traffic to prod and 5% to DR for 20 minutes, then adjust to 80/20; configure Cloud Monitoring alerts for Pub/Sub backlog and BigQuery latency; assign minimal IAM roles following the principle of least privilege; implement automatic rollback to v3 if error rate or backlog exceed thresholds across both regions.","explanation":"## Why This Is Asked\nTests ability to architect cross-project blue/green disaster recovery using GCP-native tools while addressing cross-project IAM, Private Service Connect, and real-time rollback challenges.\n\n## Key Concepts\n- Cross-project resource isolation and traffic routing\n- Private Service Connect and VPC service controls\n- Canary/blue-green traffic management and rollback\n- Observability with Pub/Sub backlog and BigQuery latency\n- Least-privilege IAM\n\n## Code Example\n```javascript\n// Example commands (pseudo)\n// Build and push\ngcloud builds submit --tag europe-docker.pkg.dev/PROJECT/```","diagram":"flowchart TD\n  A[Prod] --> B[DR]\n  B --> C[Traffic split: 15/5]\n  C --> D[Promote to 80/20]\n  D --> E[Rollback path to v3]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Citadel","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T06:02:45.118Z","createdAt":"2026-01-16T21:39:11.344Z"},{"id":"q-3048","question":"You’re deploying a new v3 of a GKE-based order-processor using Cloud Deploy with a canary rollout: 25% of traffic to v3 for 40 minutes; auto rollback if P95 latency > 1.2s or error rate > 0.4% for 5 minutes. Using only Google-native tools, outline exact steps to build/push v3 to Artifact Registry, create a Cloud Deploy delivery config with the canary strategy, wire traffic split, set Cloud Monitoring SLOs/alerts, and implement automatic rollback to v2. Include minimal IAM roles and prerequisites like service accounts and required permissions?","answer":"Build the v3 container image using Cloud Build and push to Artifact Registry; create a Cloud Deploy delivery configuration with a canary strategy (25% traffic for 40 minutes) and automatic rollback triggers for P95 latency > 1.2s or error rate > 0.4% sustained for 5 minutes; configure Cloud Monitoring SLOs and alerting policies; implement IAM with least-privilege service accounts for Cloud Build, Cloud Deploy, and GKE integration.","explanation":"## Why This Is Asked\nTests knowledge of Google-native progressive delivery in a real-world Kubernetes scenario using Cloud Deploy. Requires understanding of canary rollout, traffic shaping, monitoring, and least-privilege IAM.\n\n## Key Concepts\n- Cloud Deploy canary strategy\n- Artifact Registry & GKE integration\n- Cloud Monitoring SLOs and alerting\n- IAM least privilege for pipelines\n\n## Code Example\n```yaml\napiVersion: delivery.cloud.google.com/v1\nkind: DeliveryConfig\nmetadata:\n  name: order-processor-canary\nspec:\n  deliveryPipelines:\n  - name: order-processor\n    canary:\n      trafficPercent:","diagram":"flowchart TD\n  A[Source: Git] --> B[Artifact Registry]\n  B --> C[Cloud Deploy DeliveryConfig]\n  C --> D[Canary Deployment (v3)]\n  D --> E[Cloud Monitoring Alerts]\n  E --> F[Auto Rollback to v2]\n","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","PayPal","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T05:27:34.782Z","createdAt":"2026-01-16T22:41:47.868Z"},{"id":"q-3126","question":"Deploy a Cloud Run service audit-ingest (v1) to two regions (us-central1 and us-east1) behind a single global HTTP(S) Load Balancer. Default 100% traffic to central; auto-failover to east within 60s if central health-check shows 3 consecutive failures. Use only Google-native tools; provide exact gcloud steps for building/pushing to Artifact Registry, per-region deployments, LB setup, health checks, traffic policy, and minimal IAM?","answer":"Build and push the container to Artifact Registry, deploy v1 to us-central1 and us-east1 behind a global HTTP(S) Load Balancer. Default 100% to central; configure health checks at /health and a failov","explanation":"## Why This Is Asked\nTests multi-region deployment, global load balancing, health-check driven failover, and strictly Google-native tooling in a beginner-friendly scenario.\n\n## Key Concepts\n- Global HTTP(S) Load Balancer with serverless NEGs\n- Region-specific Cloud Run services\n- Health checks and automatic failover policies\n- Artifact Registry and Cloud Build\n- IAM least privilege\n\n## Code Example\n```bash\n# Build and push\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/audit-ingest:v1 .\n# Deploy in both regions\ngcloud run deploy audit-ingest-central --image us-central1-docker.pkg.dev/PROJECT/REPO/audit-ingest:v1 --region us-central1 --platform managed\ngcloud run deploy audit-ingest-east --image us-central1-docker.pkg.dev/PROJECT/REPO/audit-ingest:v1 --region us-east1 --platform managed\n# Global LB setup (high-level)\n#  - Create serverless NEGs for each region\n#  - Create backend services referencing the NEGs\n#  - Create URL map, target proxy, and forwarding rules (global)\n#  - Attach health checks and define failover behavior\n```\n\n## Follow-up Questions\n- How would you handle staged rollouts if central region capacity is saturated?\n- How would you monitor cross-region latency and automatically trigger a manual flip if needed?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Coinbase","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T04:08:42.474Z","createdAt":"2026-01-17T04:08:42.474Z"},{"id":"q-3209","question":"You're releasing a new Cloud Run service revision (v2) that processes real-time events. You want a 20% canary for 40 minutes with automatic rollback if latency p95 > 0.75s or error rate > 0.4% persists for 6 minutes. Using only GCP-native tools, specify exact steps to build/push v2 to Artifact Registry, deploy with traffic-split, set Cloud Monitoring alerts for the two metrics, and rollback by restoring 100% to v1. Include minimal IAM roles and Secrets Manager/CMEK usage?","answer":"Build v2 image and push to Artifact Registry, then deploy with Cloud Run v2 revision. Route 20% traffic to v2 and 80% to v1 for 40 minutes. Configure Cloud Monitoring: p95 latency alert (threshold 0.7","explanation":"## Why This Is Asked\nTests ability to design a strict, metrics-driven progressive delivery using only GCP-native tooling, ensuring security posture (IAM, Secrets Manager, CMEK) and a clear rollback path.\n\n## Key Concepts\n- Progressive delivery with traffic splits\n- Cloud Monitoring alerts on latency and error rate\n- Safe rollback triggers and minimal IAM bindings\n- Secrets Manager and CMEK integration for production safety\n\n## Code Example\n```bash\n# Build and push v2\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/service:v2 .\n\n# Deploy v2 revision (v2 suffix)\ngcloud run deploy service --image us-central1-docker.pkg.dev/PROJECT/REPO/service:v2 --platform managed --region us-central1 --revision-suffix v2\n\n# Traffic split (20% to v2, 80% to v1)\ngcloud run services update-traffic service --to-revisions service-v2-00001=0.20,service-00001=0.80\n```\n\n## Follow-up Questions\n- How would you test the rollback path under simulated latency spikes?\n- What logging and tracing spikes would you expect during canary and rollback?","diagram":"flowchart TD\n  A[Start] --> B[Build v2]\n  B --> C[Push to Artifact Registry]\n  C --> D[Deploy v2 Revision]\n  D --> E[Traffic Split 20/80]\n  E --> F[Cloud Monitoring Alerts]\n  F --> G{Alerts Firing?}\n  G -->|Yes| H[Rollback to v1]\n  G -->|No| I[Promote or Extend Canary]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","OpenAI","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T06:59:29.894Z","createdAt":"2026-01-17T06:59:29.894Z"},{"id":"q-3231","question":"Design a multi-region blue/green rollout for a Cloud Run service (image-processor) in us-central1 and europe-west1. Release v2 with 25% canary traffic per region for 30 minutes; auto-rollback if p95 latency > 0.6s or error rate > 0.3% for 5 minutes. Use only Google-native tools. Provide exact steps to build/push v2 to Artifact Registry, deploy in both regions, configure traffic and monitoring alerts, and rollback to v1. Include minimal IAM and Secrets Manager usage?","answer":"Push v2 to Artifact Registry, deploy v2 in us-central1 and europe-west1 as separate Cloud Run services, fronted by a global HTTP(S) Load Balancer. Route 25% traffic to v2 in each region; 75% to v1. Cr","explanation":"Why This Is Asked\n- Tests cross-region deployment, traffic shaping, and automated rollback using Google-native tools.\n\nKey Concepts\n- Blue/green rollout across regions; Global HTTP(S) Load Balancer; Cloud Run revisions; Cloud Monitoring alerts; IAM least privilege; Secrets Manager; CMEK.\n\nCode Example\n```javascript\n// Simple rollback decision (illustrative)\nfunction needsRollback(p95, err) {\n  return p95 > 0.6 || err > 0.003;\n}\n```\n\nFollow-up Questions\n- How would you test rollback paths with simulated latency spikes?\n- How would you adjust weights if regional latency drifts without violating SLOs?","diagram":"flowchart TD\n  A[Push v2 to Artifact Registry] --> B[Deploy v2 to Cloud Run us-central1]\n  B --> C[Deploy v2 to Cloud Run europe-west1]\n  C --> D[Configure Global HTTP(S) Load Balancer]\n  D --> E[Traffic split: 25% to v2 per region]\n  E --> F[Configure per-region monitoring alerts]\n  F --> G[Rollback to v1 in both regions]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T07:43:14.175Z","createdAt":"2026-01-17T07:43:14.175Z"},{"id":"q-3362","question":"You're deploying a new v3 of a high-volume API on two GKE clusters in US-EAST1 and US-CENTRAL1 behind a global HTTP(S) Load Balancer. Using Google-native tools only, design a blue/green progressive rollout with region-specific canary: 5% traffic to v3 in US-EAST1 for 15 minutes, alert-triggered rollback if p95 latency > 400ms or error rate > 0.5% for 5 minutes, then promote to full traffic if both regions pass. Include exact steps for building/pushing the image to Artifact Registry, Kubernetes manifests, Cloud Deploy config, monitoring, and IAM?","answer":"Use Cloud Deploy to orchestrate region-scoped blue/green for v3 on two GKE clusters. Steps: build and push image to Artifact Registry; create Kubernetes manifests for the new deployment; define a Deli","explanation":"## Why This Is Asked\nTests ability to design progressive delivery across regions with native GCP tools and precise rollback triggers.\n\n## Key Concepts\n- Cloud Deploy multi-region rollout\n- GKE blue/green deployment\n- Canary traffic shaping per region\n- Cloud Monitoring SLIs and alerting\n- IAM least privilege and artifact access\n\n## Code Example\n```javascript\n// Implementation guidance example placeholder\n```\n\n## Follow-up Questions\n- How would you test rollback safety across regions?\n- Which IAM roles are minimally required for Cloud Deploy to operate across two clusters?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T13:37:53.449Z","createdAt":"2026-01-17T13:37:53.450Z"},{"id":"q-3502","question":"You're running a multi-region Cloud Run service named video-processor behind a Global HTTP(S) Load Balancer. A new requirement mandates exactly-once processing for streaming events from Pub/Sub across regions, with progressive rollout to v4 and automated rollback on latency or dedupe failures. Using only Google-native tools, design the rollout plan including traffic-shift, Pub/Sub EOD, idempotent processing, dedupe store, alerts, and a rollback workflow with minimal IAM?","answer":"Enable Pub/Sub exactly-once delivery for the video-processor topic. Build v4 to Cloud Run, route 5% canary for 15m, then 20% for 30m; automatic rollback if p95 latency > 1.2s or dedupe failure rate >0","explanation":"## Why This Is Asked\n\nTests practical progression controls: exact delivery semantics, cross-region rollout, and safe rollback using native tools.\n\n## Key Concepts\n\n- Pub/Sub Exactly-Once Delivery\n- Idempotent event processing\n- Progressive delivery via traffic shifts\n- Cross-region rollback strategies\n- Least-privilege IAM\n\n## Code Example\n\n```javascript\nconst seen = new Set();\nfunction handle(event){\n  if (seen.has(event.id)) return; // idempotent\n  seen.add(event.id);\n  // process...\n}\n```\n\n## Follow-up Questions\n\n- How would you store the dedupe state at scale?\n- How would you test the rollback automation end-to-end?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T19:21:37.649Z","createdAt":"2026-01-17T19:21:37.651Z"},{"id":"q-3678","question":"You're deploying a beginner-friendly Cloud Run service named weather-api (v1) that must connect to a private Cloud SQL PostgreSQL instance via a Serverless VPC Access connector. Using only Google-native tools, specify exact steps to: 1) create a private Cloud SQL instance, 2) set up a Serverless VPC Access connector, 3) store a DB password in Secret Manager, 4) grant a service account minimal IAM roles (roles/cloudsql.client, roles/secretmanager.secretAccessor), 5) deploy the Cloud Run image from Artifact Registry with the VPC connector and the secret exposed as an environment variable, and 6) test connectivity from Cloud Run to Cloud SQL with a simple curl. Include concrete gcloud commands?","answer":"Outline steps: enable APIs; create a private Cloud SQL PostgreSQL instance; create a Serverless VPC Access connector; store the DB password in Secret Manager; grant a service account minimal roles (ro","explanation":"## Why This Is Asked\nDemonstrates wiring of basic GCP components (Cloud Run, Secret Manager, Cloud SQL private IP, VPC connector) with native tools, plus minimal IAM bindings and a lightweight connectivity test.\n\n## Key Concepts\n- Private IP Cloud SQL and serverless access\n- Serverless VPC Access configuration\n- Secret Manager integration with Cloud Run\n- IAM least privilege across services\n\n## Code Example\n```bash\n# Example entries (not exhaustive)\ngcloud services enable sqladmin secretmanager run.googleapis.com vpcaccess.googleapis.com\ngcloud sql instances create weather-sql --tier=db-f1-micro --region us-central1 --database-version POSTGRES_13 --private-network projects/PROJECT/global/networks/weather-vpc\ngcloud secrets create WEATHER_DB_PASSWORD -d \"changeme\"\ngcloud secrets versions add WEATHER_DB_PASSWORD --data-file=<(echo 'db-pass')\n# Bind permissions to Cloud Run service account\ngcloud projects add-iam-policy-binding PROJECT --member=serviceAccount:weather-run@PROJECT.iam.gserviceaccount.com --role=roles/cloudsql.client\ngcloud projects add-iam-policy-binding PROJECT --member=serviceAccount:weather-run@PROJECT.iam.gserviceaccount.com --role=roles/secretmanager.secretAccessor\n# Deploy with VPC connector and secret env\ngcloud run deploy weather-api --image us-central1-docker.pkg.dev/PROJECT/REPO/weather-api:latest --region us-central1 --platform managed --vpc-connector weather-connector --set-secrets WEATHER_DB_PASSWORD=WEATHER_DB_PASSWORD --update-env-vars DB_HOST=weather-sql.us-central1.private.google-cloud.something\n```\n\n## Follow-up Questions\n- How to rotate the secret without downtime?\n- How to monitor private connectivity and DNS resolution from Cloud Run?","diagram":"flowchart TD\n  A[Cloud Run] --> B[Secret Manager]\n  A --> C[Cloud SQL Private IP]\n  A --> D[Artifact Registry]\n  E[VPC Connector] --> C\n  A --> E","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Oracle","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T05:32:07.320Z","createdAt":"2026-01-18T05:32:07.323Z"},{"id":"q-3707","question":"You're releasing v2 of a high-throughput order-processor on Cloud Run. Implement a 25% canary for 60 minutes with automatic rollback if p95 latency >0.8s or error rate >0.4% persists for 5 minutes using only Google-native tools. Include exact steps to push v2 to Artifact Registry, deploy with traffic-split, set Cloud Monitoring alerts, and rollback by routing 100% to v1. Include minimal IAM roles and Secrets Manager usage?","answer":"Push v2 to Artifact Registry, deploy with 25% traffic for 60 minutes, and monitor p95 latency and error rate via Cloud Monitoring alerts. If alerts persist for 5 minutes, rollback to v1 by routing 100","explanation":"## Why This Is Asked\n\nAssesses practical, real‑world progressive delivery using Google-native tools, including Cloud Run traffic splitting, Cloud Monitoring alerting, and a clean rollback path. Emphasizes minimal IAM and Secrets Manager usage in a constrained, production‑oriented scenario.\n\n## Key Concepts\n\n- Canary/blue-green traffic shifting on Cloud Run\n- Cloud Monitoring alerting for latency and errors\n- Artifact Registry integration\n- Secrets Manager integration with least privilege IAM\n\n## Code Example\n\n```bash\n# Example commands (illustrative)\n# 1) Build and push v2 to Artifact Registry\n# 2) Deploy v2 with 25% traffic\ngcloud run deploy order-processor-v2 --image gcr.io/PROJECT/order-processor:v2 --revision-suffix v2\ngcloud run services update-traffic order-processor --to-revisions order-processor-v1=0.75,order-processor-v2=0.25\n# 3) Create alerts for p95 latency and error rate; rollback on alert\n```\n\n## Follow-up Questions\n\n- How would you handle metric flakiness or long tail latency?\n- How would you extend to multi-region deployments?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Two Sigma","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T06:46:30.891Z","createdAt":"2026-01-18T06:46:30.891Z"},{"id":"q-3745","question":"Deploy a real-time fraud API on Cloud Run in two regions (us-central1 and europe-west1) behind a Global HTTP(S) Load Balancer. Release v3 with a 5% multi-region canary for 15 minutes; rollback to v2 automatically if per-region p95 latency exceeds 0.8s or error rate exceeds 0.6% for 6 minutes. Using only Google-native tools, outline exact steps to build/push v3 to Artifact Registry, run a Cloud Deploy rollout across regions, configure per-region monitoring alerts, and implement a minimal IAM/CMEK/Secrets Manager usage?","answer":"Push v3 to Artifact Registry; deploy across us-central1 and europe-west1 behind a Global LB; run a 5% multi-region canary for 15 minutes via Cloud Deploy; alert on per-region p95 latency >0.8s or erro","explanation":"## Why This Is Asked\nTests multi-region rollout with Google-native tools, cross-region monitoring, and rollback semantics under realistic latency/error constraints.\n\n## Key Concepts\n- Multi-region Cloud Run deployment behind a Global HTTP(S) LB\n- Cloud Deploy canary rollouts across regions\n- Per-region monitoring and automated rollback triggers\n- IAM least privilege, CMEK, Secrets Manager integration\n\n## Code Example\n```yaml\n# illustrative Cloud Deploy rollout (conceptual)\nrollout:\n  targets:\n    - region: us-central1\n      revision: fraud-detect-v3\n      traffic: 5\n    - region: europe-west1\n      revision: fraud-detect-v3\n      traffic: 5\n  duration: 15m\n  rollbackIf:\n    - metric: p95_latency\n      threshold: 0.8s\n      duration: 6m\n    - metric: error_rate\n      threshold: 0.6%\n      duration: 6m\n```\n\n## Follow-up Questions\n- How would you validate no user-visible degradation during canary?\n- What re-run strategy would you implement if one region fails the canary while the other passes?","diagram":"flowchart TD\n  A[Push v3 to Artifact Registry] --> B[Deploy to regions us-central1 & europe-west1]\n  B --> C[Canary rollout via Cloud Deploy]\n  C --> D{Alerts trigger?}\n  D -->|Yes| E[Rollback to v2 across regions]\n  D -->|No| F[Promote to full traffic]\n","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Coinbase","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T07:42:21.397Z","createdAt":"2026-01-18T07:42:21.397Z"},{"id":"q-3927","question":"You're deploying a beginner-friendly Cloud Run service named image-resizer. Using only Google-native tools, design a minimal CI/CD pipeline: build/push to Artifact Registry, deploy v1, implement a manual gate before production for v2, and configure Cloud Monitoring alerts for latency and error rate that automatically rollback by re-pointing all traffic to v1. Include exact IAM considerations and a rollback workflow?","answer":"Implement a Cloud Build pipeline that builds the image, pushes to Artifact Registry, and deploys v1 to Cloud Run. Use a manual gate for v2 before production. Create Cloud Monitoring alerts for latency","explanation":"## Why This Is Asked\nTests basic Google-native CI/CD, gating, and rollback with observability.\n\n## Key Concepts\n- Cloud Build triggers\n- Artifact Registry\n- Cloud Run revisions and traffic control\n- Cloud Monitoring alerting\n- IAM least privilege\n\n## Code Example\n```yaml\n# cloudbuild.yaml (high level)\nsteps:\n- name: gcr.io/cloud-builders/docker\n  args: ['build','-t','REG-REGION-docker.pkg.dev/PROJECT/REPO/image-resizer:v1','.']\n- name: gcr.io/cloud-builders/gcloud\n  entrypoint: bash\n  args: ['-c','gcloud run deploy image-resizer --image REG-REGION-docker.pkg.dev/PROJECT/REPO/image-resizer:v1 --region us-central1 --platform managed --allow-unauthenticated']\n```\n\n## Follow-up Questions\n- How would you validate the manual gate and post-merge rollouts?\n- How would you adapt for multiple regions and autoscaling?","diagram":"flowchart TD\n  A[Build] --> B[Push to Artifact Registry]\n  B --> C[Deploy v1 to Cloud Run]\n  C --> D[Manual gate for v2]\n  D --> E[Deploy v2]\n  E --> F[Monitoring alerts]\n  F --> G[Rollback to v1]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","PayPal","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T15:42:43.913Z","createdAt":"2026-01-18T15:42:43.913Z"},{"id":"q-4009","question":"Roll out a gated v4 revision of a real-time alert service on Cloud Run (fully managed) behind a Global HTTP(S) Load Balancer and Pub/Sub. Using Google-native tools, provide an exact deployment plan: traffic-split (10% canary), automatic rollback if p95 latency >0.9s or error rate >0.5% for 12m, feature flag in Secret Manager, multi-region DR, and minimal IAM bindings?","answer":"Publish v4 to Cloud Run, split traffic 10% canary, 90% prod, gate new path with Secret Manager feature flag; monitor p95 latency and error rate; if latency>0.9s or errors>0.5% for 12m, rollback by rou","explanation":"## Why This Is Asked\n\nTests real-world deployment discipline: canary rollout, automatic rollback, secret-driven feature gating, multi-region resilience, and strict IAM boundaries using only Google-native tooling.\n\n## Key Concepts\n\n- Cloud Run traffic splitting and revision management\n- Secret Manager for feature flags and access controls\n- Cloud Monitoring alerting on p95 latency and error rate with duration thresholds\n- Global HTTP(S) Load Balancer for cross-region failover\n- IAM least privilege and CMEK-backed storage considerations\n\n## Code Example\n\n```bash\n# Example initial canary deployment (adjust project/region)\ngcloud run deploy alert-service-v4 \\\n  --image gcr.io/PROJECT/alert-service:v4 \\\n  --region us-central1 \\\n  --traffic v4=10\n\n# Gate feature via Secret Manager and monitor metrics; rollback if needed\n```\n\n## Follow-up Questions\n\n- How would you simulate the rollback scenario in CI/CD? \n- What additional observability would you add (trace, logs, SLI/SLOs)?","diagram":"flowchart TD\n  A[Dev/Release] --> B[Deploy v4 with 10% canary]\n  B --> C{Metrics OK?}\n  C -->|Yes| D[Shift 90% to prod]\n  C -->|No| E[Rollback to v3 and disable flag]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T19:28:43.540Z","createdAt":"2026-01-18T19:28:43.540Z"},{"id":"q-4081","question":"You're orchestrating a progressive rollout for two Cloud Run services, A and B, that are part of a shared feature flag. Use Cloud Deploy to run a canary of v2 across both services with a 25% traffic allocation for 30 minutes, then 80% for 15 minutes, and full rollout if latency p95 stays under 0.8s and error rate under 0.4%. If either metric breaches for two consecutive 5-minute windows, automatically rollback to v1 by routing 100% of traffic back to v1 for both services. Outline exact steps: 1) build/push images to Artifact Registry, 2) Cloud Deploy manifest for multi-service release, 3) traffic-split and rollout timings, 4) Cloud Monitoring alerting thresholds and auto-rollback gate, 5) region handling/us-central1, 6) minimal IAM roles and Secrets/CMEK usage?","answer":"Use Cloud Deploy to orchestrate a coordinated canary across services A and B. Build and push images to Artifact Registry; define a single Release with staged traffic allocation: 25% for 30 minutes, 80% for 15 minutes, then 100% rollout. Implement Cloud Monitoring gates that automatically rollback to v1 if latency p95 exceeds 0.8s or error rate exceeds 0.4% for two consecutive 5-minute windows. Deploy to us-central1 with minimal IAM roles using Workload Identity, and integrate with Secrets Manager and CMEK for security.","explanation":"## Why This Is Asked\nTests progressive delivery across multiple services with Google-native tooling. Emphasizes end-to-end flow: build, deploy, monitor, rollback, and least-privilege IAM.\n\n## Key Concepts\n- Cloud Deploy multi-service releases\n- Artifact Registry image management\n- Traffic-split canary strategies\n- Cloud Monitoring alerting and rollback gates\n- IAM least privilege and Workload Identity\n- CMEK and Secrets Manager integration\n\n## Code Example\n```yaml\n# Example snippet (clouddeploy.yaml) for a two-service canary release\nreleases:\n- name: canary-v2\n  targets:\n  - serviceA\n  - serviceB\n  phases:\n  - name: canary-25\n    percent: 25\n    duration: 30m\n  - name: canary-80\n    percent: 80\n    duration: 15m\n  - name: full-rollout\n    percent: 100\n```","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Cloudflare"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:51:08.998Z","createdAt":"2026-01-18T22:51:42.530Z"},{"id":"q-4121","question":"You're releasing v3 of a multi-region Cloud Run API behind a Global HTTP(S) Load Balancer. Implement a canary with stages: 2% for 15m, then 10% for 30m, then 40% for 60m, across all regions. Automatic rollback if p95 latency > 0.75s or error rate > 0.5% for 5 minutes. Use only Google-native tools. Provide exact steps: build/push to Artifact Registry, deploy with traffic-split (per-region), set Cloud Monitoring alert policies, and rollback by shifting all traffic back to v2. Include minimal IAM roles and Secrets/CMEK usage?","answer":"Deploy v3 via a phased, region-aware canary: 2% for 15 minutes, then 10% for 30 minutes, then 40% for 60 minutes across all regions; monitor p95 latency and error rate with Cloud Monitoring, automatically rolling back by routing all traffic back to v2 if thresholds are exceeded for 5 minutes.","explanation":"## Why This Is Asked\nTests ability to design safe, automated cross-region rollouts using only Google-native tools, with precise traffic-phase control and rollback triggers.\n\n## Key Concepts\n- Cloud Run multi-region rollout\n- Global HTTP(S) Load Balancer with traffic splitting\n- Cloud Deploy traffic shifts, Cloud Monitoring SLOs, CMEK\n\n## Code Example\n```bash\n# Example commands (illustrative)\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/REPO/v3\ngcloud run deploy api --image us-docker.pkg.dev/PROJECT/REPO/v3 --region us-central1 --platform managed --allow-unauthenticated\n```\n\n## Follow-up","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Oracle","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:08:07.082Z","createdAt":"2026-01-19T02:54:59.125Z"},{"id":"q-4160","question":"You're operating a Cloud Run API that consumes Pub/Sub messages and writes to BigQuery. A v2 producer schema adds an optional field and changes timestamp semantics. Using only Google-native tools, design a safe rollout that decouples producers from consumers: create a v2 Pub/Sub topic with a schema, publish 20% of messages to v2 for 30 minutes, route both subscriptions to the same Cloud Run service via a compatibility layer, monitor backlog and error rate with Cloud Monitoring, and rollback by deactivating v2 publishing and migrating all traffic back to v1. Also define minimal IAM roles?","answer":"Implement a dual-topic rollout: publish 80% of messages to Pub/Sub v1 and 20% to Pub/Sub v2 (with a registered schema). Add a compatibility router in Cloud Run that reads both formats and writes to th","explanation":"## Why This Is Asked\nTests ability to perform safe schema evolution and traffic diversification with native Google tools.\n\n## Key Concepts\n- Pub/Sub Schema Registry and multi-topic rollout\n- Backward/forward compatibility in producers\n- Cloud Run as a compatibility layer\n- Monitoring: backlog, latency, error rate\n- Rollback: halt v2 publishing and redirect to v1\n\n## Code Example\n```javascript\n// Pseudo-router outline: read both topics, normalize to common record, write to BigQuery\n```\n\n## Follow-up Questions\n- How would you enforce strict schema validation and prevent drift?\n- How would you simulate failure scenarios to test rollback?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T05:49:21.523Z","createdAt":"2026-01-19T05:49:21.523Z"},{"id":"q-4209","question":"You're exposing a Cloud Run API behind an HTTP(S) Load Balancer. Implement a minimal Google-native Cloud Armor defense: block a known bad IP range while allowing production traffic, apply it to the backend service, and verify blocking via test requests. Include minimal IAM roles and attach steps, plus how to validate blocking?","answer":"Create a Cloud Armor security policy named blocklist, add a DENY rule for 203.0.113.0/24 with priority 1000, apply policy to the global backend service used by the Cloud Run HTTP(S) Load Balancer, the","explanation":"## Why This Is Asked\nTests basic Cloud Armor usage with Cloud Run behind a Load Balancer, focusing on defense in depth and automation.\n\n## Key Concepts\n- Cloud Armor, HTTP(S) Load Balancer, Cloud Run behind LB\n- IP allow/deny lists, security policies, backend services\n- IAM least privilege for automation, attach to backend\n- Basic validation of deny rules\n\n## Code Example\n```bash\n# create policy\ngcloud compute security-policies create blocklist --description=\"Block bad IPs\"\n\n# add deny rule\ngcloud compute security-policies rules create 1000 --security-policy blocklist --src-ip-range 203.0.113.0/24 --action DENY --direction INGRESS\n\n# attach policy to backend service\ngcloud compute backend-services update your-backend-service --security-policy blocklist --global\n```\n\n## Follow-up Questions\n- How would you extend this to include allowlists for maintenance windows without disrupting traffic?\n- How would you verify the policy in a CI environment without using real blocked IPs?","diagram":"flowchart TD\n  A[User requests] --> B[HTTP(S) LB]\n  B --> C[Backend: Cloud Run]\n  B --> D[Cloud Armor policy]\n  D --> E[Access decision]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Microsoft","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T08:52:13.757Z","createdAt":"2026-01-19T08:52:13.757Z"},{"id":"q-4335","question":"You're releasing v4 of a Cloud Run API behind a Global HTTP(S) Load Balancer with regional backends in us-east1, us-central1, and us-west1. Using only Google-native tools, design a progressive, region-aware rollout with automatic rollback. Provide exact steps to build/push v4 to Artifact Registry, configure a Cloud Deploy pipeline with regional traffic controls, set Cloud Monitoring alerts for latency and error rate, and rollback by shifting traffic back to v3?","answer":"I would orchestrate a Cloud Deploy pipeline that stages traffic regionally: 5% in us-east1 for ~20m, then 20% globally for ~30m, with an automatic rollback to v3 if latency p95 exceeds 0.85s or error ","explanation":"Why This Is Asked: Tests ability to design progressive delivery with multi-region, no manual hacks. Key Concepts: Cloud Deploy pipelines, region-scoped traffic controls, Cloud Run traffic splits, Cloud Monitoring alerting, automatic rollback, minimal IAM. Code Example:```javascript\nconst deployConfig = {\n  pipeline: 'region-canary',\n  stages: [\n    { region: 'us-east1', canary: 0.05, durationMin: 20 },\n    { region: 'global', canary: 0.20, durationMin: 30, guard: 'latency<0.85' }\n  ],\n  rollback: 'setTraffic(v3)';\n};\n```","diagram":"flowchart TD\n  A[Code push] --> B[Artifact Registry]\n  B --> C CloudDeploy[Cloud Deploy pipeline]\n  C --> D[Regional traffic control]\n  D --> E[Monitoring alerts]\n  E --> F[Auto rollback to v3]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Microsoft","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T14:46:13.789Z","createdAt":"2026-01-19T14:46:13.790Z"},{"id":"q-4374","question":"You're deploying a Cloud Run service named inventory-sync with bursty traffic and cost controls. Using only Google-native tools, specify exact steps to configure autoscaling (min/max instances, concurrency), deploy a v2 revision, and set a Cloud Monitoring alert plan with a minimal dashboard for p95 latency and estimated spend. End with ?","answer":"Configure: min-instances 1, max-instances 20, concurrency 80; deploy v2 with gcloud run deploy inventory-sync --image gcr.io/PROJECT/inventory-sync:v2 --min-instances 1 --max-instances 20 --concurrenc","explanation":"## Why This Is Asked\n\nTests practical use of Cloud Run autoscaling knobs, v2 revision rollout, and native monitoring for cost control.\n\n## Key Concepts\n\n- Cloud Run autoscaling: min/max instances and concurrency\n- Rolling out a v2 revision with minimal downtime\n- Cloud Monitoring dashboards and alerting for latency and cost\n- Using gcloud commands to implement changes\n\n## Code Example\n\n```bash\n# Deploy v2 with autoscale\ngcloud run deploy inventory-sync \\\n  --image gcr.io/PROJECT/inventory-sync:v2 \\\n  --min-instances 1 \\\n  --max-instances 20 \\\n  --concurrency 80 \\\n  --region us-central1\n\n# Dashboard\ngcloud monitoring dashboards create --config-from-file=inventory-dashboard.json\n```\n\n## Follow-up Questions\n\n- How would you adjust for a sudden 5x traffic spike without overspending?\n- What trade-offs exist between min-instances and cold-start latency?\n","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Hashicorp","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T16:42:25.481Z","createdAt":"2026-01-19T16:42:25.481Z"},{"id":"q-4508","question":"You're releasing v6 of a latency-sensitive microservice on GKE behind a Global HTTP(S) Load Balancer with regional backends in us-central1, us-east1, and us-west1. Using only Google-native tools, design a canary rollout with regional traffic shifts: 2% in the first region for 15m, then 10% across all regions for 30m, then 25% across all regions for 60m, with automatic rollback if p95 latency > 0.8s or error rate > 0.6% for 5m. Include build/push to Artifact Registry, Cloud Deploy pipeline config, per-region traffic controls, monitoring alerts, and rollback method to prior version. Also specify minimal IAM roles and Secrets usage?","answer":"Proposed approach: Build v6 with Cloud Build and push to Artifact Registry. Define a Cloud Deploy delivery pipeline with a canary rollout strategy: 2% traffic in us-central1 for 15 minutes, then 10% across all regions for 30 minutes, then 25% across all regions for 60 minutes. Configure Cloud Monitoring alert policies for p95 latency > 0.8s and error rate > 0.6% sustained for 5 minutes, triggering automatic rollback to the prior stable version. Implement per-region traffic controls through the Global HTTP(S) Load Balancer's regional backend configurations, and apply minimal IAM roles following least privilege principles with Secrets Manager for sensitive data.","explanation":"## Why This Is Asked\nTests ability to design progressive delivery with region-aware rollout using Google-native tools end-to-end.\n\n## Key Concepts\n- Cloud Build + Artifact Registry\n- Cloud Deploy canary strategies\n- Global Load Balancer regional traffic controls\n- Cloud Monitoring alert policies and automatic rollback\n- IAM least privilege and Secrets management\n\n## Code Example\n```yaml\n# example Cloud Deploy rollout snippet (pseudo)\napiVersion: deploy.cloud.google.com/v1\nkind: Rollout\nmetadata:\n  name: canary-rollout\nspec:\n  canary:\n    regionTraffic:\n      us-central1: 2\n      us-east1: 0\n```","diagram":"flowchart TD\n  A[Build v6] --> B[Artifact Registry]\n  B --> C[Cloud Deploy pipeline]\n  C --> D[Region traffic shifts]\n  D --> E[Cloud Monitoring alerts]\n  E --> F[Automatic rollback]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-20T07:39:50.125Z","createdAt":"2026-01-19T21:48:43.687Z"},{"id":"q-4600","question":"You're deploying a Cloud Run service named weather-api. Develop a minimal, secure deployment workflow: (1) create a dedicated service account with the least privileges needed for deployment and secret access; (2) store a config value in Secret Manager and inject it into the container at runtime; (3) configure Cloud Run to run with that service account and the secret; (4) describe a secret-rotation process that requires zero downtime, with exact gcloud commands?","answer":"Create a dedicated service account weather-api-sa with limited roles (roles/run.developer, roles/iam.serviceAccountUser) and grant it secret access (roles/secretmanager.secretAccessor) on WEATHER_CONF","explanation":"Why This Is Asked\nAssess least-privilege IAM, Secret Manager integration, and deployment automation for Cloud Run.\n\nKey Concepts\n- Service accounts and IAM bindings\n- Secret Manager secret lifecycle and injection into Cloud Run\n- Cloud Run deployment flags to attach secrets\n- Zero-downtime secret rotation\n\nCode Example\n```javascript\ngcloud secrets create WEATHER_CONFIG --replication-policy automatic\ngcloud secrets versions add WEATHER_CONFIG --data-file=- <<EOF\nvalue\nEOF\ngcloud iam service-accounts create weather-api-sa --display-name \"Weather API SA\"\ngcloud projects add-iam-policy-binding my-project --member=\"serviceAccount:weather-api-sa@my-project.iam.gserviceaccount.com\" --role=\"roles/run.developer\"\ngcloud projects add-iam-policy-binding my-project --member=\"serviceAccount:weather-api-sa@my-project.iam.gserviceaccount.com\" --role=\"roles/iam.serviceAccountUser\"\ngcloud run deploy weather-api --image gcr.io/my-project/weather-api:latest --service-account weather-api-sa@my-project.iam.gserviceaccount.com --update-secrets WEATHER_CONFIG=WEATHER_CONFIG:latest\n```\n\nFollow-up Questions\n- How would you test secret rotation in a staging environment without downtime?\n- What monitoring would you add to verify the secret is read correctly at startup vs runtime?\n","diagram":"flowchart TD\n  A[Code push] --> B[Cloud Build triggers image build]\n  B --> C[Push to Artifact Registry]\n  C --> D[Deploy Cloud Run with service account]\n  D --> E[Secret injection via Secret Manager]\n  E --> F[Runtime verification and rollback if secret read fails]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T04:13:17.995Z","createdAt":"2026-01-20T04:13:17.995Z"},{"id":"q-4641","question":"You're deploying a Cloud Run service named text-processor. To enforce secure deployments using Google-native tools only, design an automated vulnerability gate: push images to Artifact Registry only after Container Analysis scans; block deploys with high-severity CVEs; add a post-deploy alert if CVEs are detected later. Include exact commands and minimal IAM roles?","answer":"Enable Container Analysis and Binary Authorization. Create a Cloud Build trigger to build/push image to Artifact Registry; enforce a policy that requires an attestation from the Cloud Build signer bef","explanation":"## Why This Is Asked\nTests knowledge of Google-native security tooling and practical gate setup for deployments.\n\n## Key Concepts\n- Container Analysis vulnerability scanning\n- Binary Authorization attestation policy\n- Cloud Build integration and minimal IAM roles\n- Logging-based alerting for post-deploy CVEs\n\n## Code Example\n```javascript\n// No code required for this task; see steps in prose\n```\n\n## Follow-up Questions\n- What if a newer CVE is discovered after deployment? How would you automate rollback or override gates?\n- How would you test this in a staging project before production?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Amazon","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:57:42.453Z","createdAt":"2026-01-20T05:57:42.453Z"},{"id":"q-4705","question":"You're operating a multi-region Cloud Run API backend that uses a database password stored in Secret Manager. Implement an automated, zero-downtime secret rotation every 24 hours that updates Cloud Run service env vars without downtime, revokes old secrets, and keeps in-flight connections secure. Outline exact steps to create a rotating secret, configure a Cloud Scheduler job that triggers a Cloud Function to perform patch updates, roll back if rotation fails, and verify audit logs and IAM permissions. Use only Google-native tools?","answer":"Create a rotating Secret Manager secret for the DB password, plus a Cloud Scheduler job every 24h that triggers a Cloud Function. The function creates a new secret version, updates the Cloud Run servi","explanation":"## Why This Is Asked\nTests automated secret rotation across managed services with zero-downtime deployments.\n\n## Key Concepts\n- Secret Manager rotation triggers\n- Cloud Run revisions and traffic shifting\n- Safe rollback and monitoring\n- IAM permissions for services and scheduler\n\n## Code Example\n```javascript\n// Pseudo: not executed here; illustrates flow\n```\n\n## Follow-up Questions\n- How would you handle long-lived DB connections during rotation?\n- What are the caveats with secret version exposure in logs?","diagram":"flowchart TD\n  A[Secret rotate trigger] --> B[Secret Manager new version]\n  B --> C[Update Cloud Run rev]\n  C --> D[Shift traffic to new rev]\n  D --> E[Health check pass]\n  E --> F[Expire old secret]\n  F --> G[Done]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Instacart","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T09:00:53.336Z","createdAt":"2026-01-20T09:00:53.336Z"},{"id":"q-4834","question":"Design a multi-region blue-green deployment for a Cloud Run API behind a Global HTTP(S) Load Balancer. Use Cloud Deploy to promote green (v2) from blue (v1) with region-level gated rollouts and automatic rollback if per-region health checks fail. Include exact build/push to Artifact Registry, deployment manifests per region, health-check thresholds, monitoring alerts, and rollback steps?","answer":"Use Cloud Deploy to enable a blue/green rollout of a Cloud Run API across regions. Build the image, push to Artifact Registry, and define a per-region rollout in a Cloud Deploy manifest. Phase the pro","explanation":"## Why This Is Asked\nTests multi-region release strategy, advanced GCP tooling, and rollback discipline with real metrics focus.\n\n## Key Concepts\n- Cloud Deploy regional rollouts; blue/green strategy across regions\n- Per-region health checks; Cloud Monitoring alerts\n- Artifact Registry builds; IAM least privilege\n\n## Code Example\n```yaml\n# sample Cloud Deploy rollout manifest (simplified)\napiVersion: deploy.cloud.google.com/v1\nkind: Rollout\nmetadata:\n  name: api-blue-green\nspec:\n  implementers:\n  - location: us-central1\n    phase: 25%\n    # ...\n```\n\n## Follow-up Questions\n- How would you automate per-region traffic shifting if a region lags behind?\n- How to ensure data residency during rollout?","diagram":"flowchart TD\n  A[Cloud Build] --> B[Artifact Registry]\n  B --> C[Cloud Deploy]\n  C --> D[Region US]\n  C --> E[Region EU]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T15:40:27.690Z","createdAt":"2026-01-20T15:40:27.692Z"},{"id":"q-4905","question":"You're deploying a new Cloud Run service 'data-ingest' that processes Pub/Sub messages and writes to Cloud Storage. To meet a strict security policy, restrict egress from Cloud Run to only Pub/Sub and Storage by using a Serverless VPC Access connector and VPC firewall rules. Provide exact steps: create a connector in us-central1, attach it to the service, implement egress allowlist and deny all others, and verify with a network reachability test. Include minimal IAM permissions?","answer":"Create a VPC connector in us-central1: gcloud compute networks vpc-access connectors create data-ingest-conn --region us-central1 --range 10.8.0.0/28. Attach to Cloud Run: gcloud run services update d","explanation":"Why This Is Asked\nTests ability to constrain Cloud Run egress using Serverless VPC Access and firewall rules, aligning security with least privilege.\n\nKey Concepts\n- Serverless VPC Access connector setup\n- Fine-grained VPC firewall egress rules\n- Minimal IAM permissions for the service account\n- End-to-end validation of allowed/denied egress\n\nCode Example\n```bash\n# Create connector\ngcloud compute networks vpc-access connectors create data-ingest-conn --region us-central1 --range 10.8.0.0/28\n\n# Attach to Cloud Run\ngcloud run services update data-ingest --region us-central1 --vpc-connector data-ingest-conn\n\n# Firewall rules (conceptual)\ngcloud compute firewall-rules create allow-pubsub-egress --direction EGRESS --priority 1000 --network default --destination-ranges <PubSub-IP-Ranges> --rules tcp:443\n# (and similar for Cloud Storage); then deny all other egress with higher priority\n```\n\nFollow-up Questions\n- How would you adapt this for a multi-region deployment?\n- What are the trade-offs of per-service connectors vs a shared connector in terms of security and maintenance?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T18:03:22.813Z","createdAt":"2026-01-20T18:03:22.813Z"},{"id":"q-4988","question":"You're running a globally deployed API on GKE in two regions behind a Global HTTP(S) Load Balancer. Roll out v4 using blue/green with automatic rollback if p95 tail latency > 1.2s or error rate > 0.6% for 10 minutes across both regions. Using Google-native tools only, specify exact steps: build/push v4 to Artifact Registry, deploy blue/green with per-region traffic targets, configure monitoring alerts, and rollback by shifting all traffic back to v3. Include minimal IAM roles and Secrets/CMEK usage?","answer":"Build and push the v4 container image to Artifact Registry. Create a Cloud Deploy blue/green release targeting us-central1 and europe-west1, initially routing 0% traffic to v4. Configure Cloud Monitoring SLOs for p95 latency < 1.2s and error rate < 0.6% with 10-minute evaluation windows across both regions. Once health checks pass, promote traffic gradually to 100% per region. If thresholds are breached, trigger automatic rollback by shifting all traffic back to v3 using Cloud Deploy's rollback capability.","explanation":"Why This Is Asked\nTests production-grade rollout discipline across regional endpoints with native Google tooling, emphasizing safe traffic shifting, observability, and rollback without vendor-specific features.\n\nKey Concepts\n- Blue/Green deployment across regions\n- Cloud Deploy traffic management\n- Global HTTP(S) Load Balancer regional routing\n- Cloud Monitoring SLOs and alerting\n- IAM least privilege and Secrets/CMEK handling\n\nCode Example\n```yaml\n# Example Cloud Deploy release skeleton (conceptual)\napiVersion: deploy.cloud.google.com/v1\nkind: Release\nmetadata:\n  name: api-blue-green-v4\nspec:\n```","diagram":"flowchart TD\n  A[Source: v3] --> B[Blue/Green Release v4]\n  B --> C{Health Check OK?}\n  C -- Yes --> D[Promote Traffic to v4]\n  C -- No --> E[Rollback to v3]\n  D --> F[Global LB directs to v4]\n  E --> F","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:50:34.586Z","createdAt":"2026-01-20T22:39:56.198Z"},{"id":"q-5083","question":"**Scenario**: You're deploying a new Cloud Run API named newsletter-sender that consumes Pub/Sub and writes to Firestore. Using only Google-native tools, design a beginner-friendly rollout plan that keeps costs predictable: (1) build and push v2 to Artifact Registry, (2) deploy v1 and v2, (3) run a 5% canary for 15 minutes, (4) Cloud Monitoring alerts for p95 latency > 1.2s or error rate > 0.3%, (5) rollback to v1 automatically on alert. Include exact gcloud commands and minimal IAM roles?","answer":"Build v2 image to Artifact Registry, deploy v1 and v2, configure 5% canary for 15 minutes, monitor p95 latency >1.2s or error rate >0.3% with Cloud Monitoring, and rollback by routing 100% traffic bac","explanation":"## Why This Is Asked\nTests ability to plan a safe, cost-conscious deployment using only Google-native tools with observable rollback criteria.\n\n## Key Concepts\n- Cloud Run traffic splitting\n- Artifact Registry integration\n- Cloud Monitoring alerting and auto-rollback triggers\n- IAM least privilege for deployment\n\n## Code Example\n```bash\n# Build v2 image to Artifact Registry\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/newsletter-sender:v2 .\n\n# Deploy v1 and v2\ngcloud run deploy newsletter-sender --image us-central1-docker.pkg.dev/PROJECT/REPO/newsletter-sender:v1 --region us-central1 --platform managed --concurrency 80 --memory 512Mi\ngcloud run deploy newsletter-sender --image us-central1-docker.pkg.dev/PROJECT/REPO/newsletter-sender:v2 --region us-central1 --platform managed --concurrency 80 --memory 512Mi\n\n# Canary traffic split (5% to v2 for 15m)\ngcloud run services update-traffic newsletter-sender --to-revisions newsletter-sender-v1=0.95,newsletter-sender-v2=0.05\n```\n\n## Follow-up Questions\n- How would you adjust for longer canary windows or higher traffic bursts?\n- What changes would you make if alerts fire intermittently but fall back quickly without a full rollback?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:44:04.730Z","createdAt":"2026-01-21T05:44:04.731Z"},{"id":"q-5114","question":"You're deploying v3 of a Cloud Run API behind a Global HTTP(S) Load Balancer. The upgrade adds a Pub/Sub-driven async workflow and region-specific data handling. Using Google-native tools only, design a staged rollout with per-region traffic splits and an automatic rollback. Provide exact steps to build/push v3 to Artifact Registry, configure a Cloud Deploy rollout with region-scoped traffic, set Cloud Monitoring alerts for latency and error rate, and rollback by shifting all traffic back to v2. Include minimal IAM roles and Secret Manager integration?","answer":"Push v3 image to Artifact Registry, then create a Cloud Deploy rollout with per-region traffic splits: us-east1 2%, us-central1 10%, others 0%. Set Cloud Monitoring alerts to trigger rollback if p95 l","explanation":"## Why This Is Asked\nTests ability to architect safe, region-aware, automated deployments using native GCP tooling, ensuring quick rollback and secure configuration.\n\n## Key Concepts\n- Cloud Run revisions and traffic splitting\n- Cloud Deploy for multi-region rollouts\n- Artifact Registry\n- Cloud Monitoring alert policies and SLOs\n- IAM least privilege model\n- Secret Manager integration for credentials\n- Pub/Sub workflow considerations\n\n## Code Example\n```bash\n# Build and push\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/api:v3\n\n# Create canary rollout (example)\ngcloud deploy releases create v3-rollout --delivery-pipeline api-pipeline --region us-central1\n```\n\n```bash\n# Example rollout YAML (pseudo)\n# trafficSplit:\n#   us-east1: 2\n#   us-central1: 10\n#   global: 0\n```\n\n## Follow-up Questions\n- How would you validate rollback, including end-to-end tests and logs?\n- What failure modes would you guard against (dependency drift, CMEK rotation, etc.)?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Bloomberg","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T07:00:32.087Z","createdAt":"2026-01-21T07:00:32.087Z"},{"id":"q-5212","question":"You're managing a global, multi-tenant app on GKE and Cloud Run behind a single Global HTTP(S) Load Balancer. A new tenant requires strict data isolation and dynamic per-tenant access policies. Using only Google-native tools, design an isolation-by-tenant deployment, including project structure, IAM Conditions, VPC Service Controls, tenant-specific storage (GCS/BigQuery), monitoring, and an automated rollback plan if a misconfiguration escalates data exposure?","answer":"Design per-tenant isolation using separate GCP projects and a Shared VPC, with IAM Conditions on roles and VPC Service Controls to prevent data exfiltration. Store tenant data in CMEK-protected bucket","explanation":"## Why This Is Asked\nThis tests multi-tenant isolation, policy-based security, and automated rollback in a single-cloud setup.\n\n## Key Concepts\n- Per-tenant project structure and Shared VPC\n- IAM Conditions and VPC Service Controls\n- CMEK for storage and BigQuery datasets\n- Cloud Monitoring + Audit Logs for guardrails\n- Reversible deployment and rollback workflows\n\n## Code Example\n```yaml\nbindings:\n- role: roles/storage.objectAdmin\n  members:\n  - serviceAccount:tenant-123-sa@example.iam.gserviceaccount.com\n  condition:\n    title: TenantIsolation\n    description: isolates tenant-123 data\n    expression: 'resource.name.startsWith(\"projects/tenant-123/\")'\n```\n\n## Follow-up Questions\n- How would you validate policy changes before they go live?\n- What monitoring metrics signal policy drift or exfiltration attempts?","diagram":"flowchart TD\n  A[Global Load Balancer] --> B[Per-tenant Projects]\n  B --> C[GKE/Cloud Run Isolation]\n  C --> D[Monitoring/Alerts]\n  D --> E[Automated Rollback]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Apple","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T10:59:24.869Z","createdAt":"2026-01-21T10:59:24.869Z"},{"id":"q-5400","question":"You're running a global API backend on GKE with Cloud Spanner as the transactional store, behind a Global HTTP(S) Load Balancer. Propose a disaster-recovery and progressive rollout plan (Google-native only) to ensure zero-downtime deploys and automated rollback: include multi-region Spanner config, cross-region backups, traffic-splitting, health checks, DNS failover, IAM least privilege, and rollback workflow?","answer":"Use Cloud Spanner multi-region with synchronous replication and a warm standby region. Deploy new releases behind a Global HTTP(S) Load Balancer with per-region routing and URL-map-based traffic shift","explanation":"## Why This Is Asked\nTests DR planning, cross-region traffic management, and Google-native rollout/rollback in real-world global apps.\n\n## Key Concepts\n- Cloud Spanner multi-region config and backups\n- Global HTTP(S) Load Balancer with URL-map-based splitting\n- DNS-based failover and Cloud Monitoring SLOs\n- IAM least privilege and Secrets Manager CMEK\n- Health checks and automated rollback triggers\n\n## Code Example\n```yaml\n# example: minimal traffic-split config (conceptual)\nfrontends:\n  - name: global-lb\n    routing:\n      rules:\n        - host: example.example.com\n          path: /*\n          backend: region-a\n```\n\n## Follow-up Questions\n- How would you test DR drills without impacting production?\n- What data consistency considerations arise during regional failover and how would you validate them?","diagram":"flowchart TD\n  A[Global HTTP(S) LB] --> B[Region A]\n  A --> C[Region B]\n  B --> D[Service vN – Region A]\n  C --> D","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Discord","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T20:57:15.673Z","createdAt":"2026-01-21T20:57:15.674Z"},{"id":"q-5476","question":"You're deploying inventory-service on Cloud Run behind a Global HTTP(S) Load Balancer with regional backends. A secret rotation is required: rotate DB_PASSWORD stored in Secret Manager by creating a new version and wiring the Cloud Run service to read the new value without downtime. Using only Google-native tools, specify exact steps to: 1) create a new Secret version; 2) update the Cloud Run service to use the new secret version via --secret-env-vars; 3) implement a 5% canary for 20 minutes and automatic rollback if latency > 1.2s or error rate > 0.5%; 4) configure Cloud Monitoring alerting policies; 5) rollback by shifting traffic back to the previous revision and reverting the secret to the old version. Include minimal IAM roles and CMEK considerations?","answer":"Create a new secret version in Secret Manager, then update the inventory-service to reference the new version via --secret-env-vars DB_PASSWORD=projects/PROJECT/secrets/DB_PASSWORD/versions/latest. Implement a 5% canary deployment for 20 minutes by splitting traffic between revisions, monitoring latency and error rate thresholds. If thresholds are exceeded (latency > 1.2s or error rate > 0.5%), automatically rollback by shifting traffic back to the previous revision and reverting to the previous secret version.","explanation":"## Why This Is Asked\nTests ability to coordinate secret rotation with zero-downtime deployments using Google-native tooling and to automate rollback via observability.\n\n## Key Concepts\n- Secret Manager secret versions\n- Cloud Run secret-env-vars and version pinning\n- Canary workflows with traffic splitting or Cloud Deploy\n- Cloud Monitoring alerting for latency and error rates\n- IAM least privilege and CMEK access considerations\n\n## Code Example\n```bash\n# create new secret version\ngcloud secrets versions add DB_PASSWORD --secret=DB_PASSWORD --data-file=./secret.txt\n\n# update service to use new\n```","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Lyft","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T05:39:45.105Z","createdAt":"2026-01-21T23:48:31.364Z"},{"id":"q-5498","question":"You're running a Cloud Run service named data-processor behind a Global HTTP(S) Load Balancer. Implement a cohort-based canary driven by HTTP header X-User-Cohort: A|B. Route Cohort A to v3 at 20% and Cohort B to v2, then after 60 minutes evaluate SLOs and progress to 100% to v3 if p95 latency <= 0.9s and error rate <= 0.2% in both cohorts. Use only Google-native tools. Provide exact steps to build/push v3 to Artifact Registry, create serverless NEGs, configure a URL map with header-based routing, and implement rollback by routing all traffic to v2. Include IAM roles and Secrets usage?","answer":"Deploy v3 to Artifact Registry and create serverless Network Endpoint Groups (NEGs) for both v2 and v3 Cloud Run services. Attach these NEGs to two backend services behind the Global HTTP(S) Load Balancer. Configure the URL map with header-based routing rules: X-User-Cohort=A routes 20% to v3 and 80% to v2, while X-User-Cohort=B routes 100% to v2. After 60 minutes, evaluate SLOs using Cloud Monitoring metrics for both cohorts. If p95 latency ≤ 0.9s and error rate ≤ 0.2% in both cohorts, update traffic weights to 100% v3. For rollback, modify the URL map to route all traffic to the v2 backend service. Required IAM roles: Artifact Registry Writer, Cloud Run Admin, Compute Network Admin, and Cloud Monitoring Viewer. Store sensitive configuration in Secret Manager and reference via Cloud Run environment variables.","explanation":"## Why This Is Asked\nTests ability to design advanced traffic routing using header-based rules and serverless NEGs, enabling cohort-driven canaries without modifying application code paths. Emphasizes per-cohort monitoring, safe rollback procedures, and Google-native tooling integration.\n\n## Key Concepts\n- Header-based routing with URL maps and traffic weights\n- Serverless NEGs and Cloud Run service management\n- Per-cohort traffic distribution and rollback strategies\n- Cloud Monitoring metrics and SLO evaluation\n- IAM role management and Secret Manager integration\n\n## Code Example\n```yaml\n# Example URL map configuration for header-based routing\nname: cohort-based-url-map\ndefaultService: https://www.googleapis.com/compute/v1/projects/project-id/global/backendServices/v2-backend\n\nhostRules:\n- hosts: ['*']\n  pathMatcher: cohort-matcher\n\npathMatchers:\n- name: cohort-matcher\n  defaultService: https://www.googleapis.com/compute/v1/projects/project-id/global/backendServices/v2-backend\n  routeRules:\n  - matchRules:\n    - headers:\n        X-User-Cohort: A\n    priority: 1\n    routeAction:\n      weightedBackendServices:\n      - backendService: https://www.googleapis.com/compute/v1/projects/project-id/global/backendServices/v3-backend\n        weight: 20\n      - backendService: https://www.googleapis.com/compute/v1/projects/project-id/global/backendServices/v2-backend\n        weight: 80\n  - matchRules:\n    - headers:\n        X-User-Cohort: B\n    priority: 2\n    routeAction:\n      weightedBackendServices:\n      - backendService: https://www.googleapis.com/compute/v1/projects/project-id/global/backendServices/v2-backend\n        weight: 100\n```","diagram":"flowchart TD\n  A[Header-based canary] --> B[serverless NEGs for v2/v3]\n  B --> C[URL map header rule]\n  C --> D[Traffic weights: A=20% to v3, others to v2]\n  D --> E[Monitoring per cohort]\n  E --> F[Rollback by removing A rule]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","OpenAI","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T05:27:04.599Z","createdAt":"2026-01-22T02:40:07.230Z"},{"id":"q-5589","question":"You're releasing v3 of a multi-region Cloud Run API behind a Global HTTP(S) Load Balancer. Design a Google-native progressive delivery using Binary Authorization attestations, Cloud Deploy, and per-region traffic shifts (5%/15m, 20%/30m, 100% thereafter) with automatic rollback if SLOs breach. Include build/push to Artifact Registry, per-region traffic split, Cloud Monitoring alerts, and rollback strategy to v2; outline necessary IAM roles and Secrets handling?","answer":"Enable Binary Authorization with an attestor and sign v3 images in Artifact Registry via Cloud Build; deploy with Cloud Deploy progressive delivery across regions: 5% for 15m, 20% for 30m, then 100% i","explanation":"## Why This Is Asked\nTests advanced, end-to-end rollout capabilities: security, multi-region deployment, and proactive rollback.\n\n## Key Concepts\n- Binary Authorization and attestation\n- Cloud Deploy progressive delivery\n- Artifact Registry signing\n- Per-region traffic management\n- Cloud Monitoring SLOs and alerting\n- Secrets Manager and IAM least privilege\n\n## Code Example\n```yaml\n# Example Cloud Deploy delivery pipeline (abbreviated)\napiVersion: deploy.cloud.google.com/v1\nkind: DeliveryPipeline\nmetadata:\n  name: multi-region-api\n```\n\n## Follow-up Questions\n- How would you validate attestation policy before enabling v3 in prod?\n- What metrics would you monitor to avoid false rollbacks?","diagram":"flowchart TD\n  A[Cloud Run v3 rollout] --> B[Artifact Registry sign]\n  B --> C[Cloud Deploy pipeline]\n  C --> D[Per-region traffic split]\n  D --> E[Cloud Monitoring alerts]\n  E --> F[Auto rollback to v2]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T07:39:48.744Z","createdAt":"2026-01-22T07:39:48.745Z"},{"id":"q-5620","question":"You're deploying a high-traffic payment API named payline on Cloud Run v2 behind a Global HTTP(S) Load Balancer. Implement a JWT-claim-driven canary where the JWT tenant claim selects routing: if tenant is A route to v3 at 15% for 20 minutes; otherwise route to v2. After 20 minutes, ramp to 60% for tenant A and full traffic for all tenants if SLOs are met (p95 latency <= 0.9s and error rate <= 0.2%). Use only Google-native tools. Provide exact steps: build and push v3 to Artifact Registry, create per-tenant serverless NEGs, configure a URL map with JWT-based routing, set monitoring alerts, and implement rollback by routing all traffic back to v2; include minimal IAM roles and Secrets/CMEK handling?","answer":"Design a per-tenant canary using Cloud Load Balancing URL maps that inspect the JWT claim tenant and route A to v3 at 15% for 20 minutes while other tenants go to v2. After 20 minutes, ramp to 60% for","explanation":"## Why This Is Asked\n\nTests ability to design advanced, JWT-driven canary deployments using Google Cloud Load Balancing without code changes, ensuring tenant isolation, precise traffic control, and automated rollback.\n\n## Key Concepts\n\n- JWT claim-based routing in Cloud Load Balancing URL maps\n- Serverless NEGs for per-tenant backends\n- Artifact Registry for versioned images\n- Cloud Monitoring and SLO-based alerting for p95 latency and error rate\n- Automated rollback via traffic policy\n- IAM least privilege and Secrets/CMEK handling\n\n## Code Example\n\n```javascript\n// Example: pseudo-URL map routing logic (illustrative)\nconst routing = {\n  tenant: getJwtClaim('tenant'),\n  route: routingTable[routing.tenant] ?? 'v2'\n}\n```\n\n## Follow-up Questions\n\n- How would you test the canary reliably across tenants without affecting production?\n- What would you monitor to distinguish genuine SLA failures from transient blips during the rollout?","diagram":"flowchart TD\n  A[JWT tenant claim] --> B{tenant==A}\n  B -->|yes| C[Route to v3 15%]\n  B -->|no| D[Route to v2]\n  C --> E[20m canary]\n  E --> F[Ramp to 60% for A]\n  F --> G[Full traffic if SLOs met]\n  G --> H[No rollback]\n  H --> I[Rollback if SLA violated to v2]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","PayPal","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T08:53:33.990Z","createdAt":"2026-01-22T08:53:33.990Z"},{"id":"q-5640","question":"You're operating a multi-region Cloud Run API behind a Global HTTP(S) Load Balancer. A new v2 revision shows sporadic latency spikes and 500 errors during peak hours in us-east1, us-central1, and us-west1. Using only Google-native tools, design a concrete rollout and rollback plan: push v2 to Artifact Registry, deploy with per-region traffic-split, set SLOs/alerts for latency and error rate, enable Cloud Trace sampling, and implement rollback to v1 if metrics degrade. Include exact gcloud commands and IAM considerations?","answer":"Deploy v2 per-region as 2% traffic for 15m, monitor p95 latency and 5xx rate; if within SLOs, escalate to 20% for 30m, then 100% if good. Use Cloud Monitoring alerts and Cloud Trace sampling. Rollback","explanation":"## Why This Is Asked\nAssesses real-world multi-region rollout discipline, per-region traffic control, observability, and safe rollback in GCP-native workflows.\n\n## Key Concepts\n- Cloud Run revisions and per-region traffic splitting\n- Global HTTP(S) Load Balancer routing\n- Cloud Monitoring SLOs and alerting on latency and error rate\n- Cloud Trace for latency diagnosis\n- IAM least privilege for deployment and monitoring\n\n## Code Example\n```bash\n# Example: create per-region traffic split for v2\ngcloud run services update-traffic image-processor --to-revisions v2=2% --region us-east1\n```\n\n## Follow-up Questions\n- How would you modify this for a sudden regional outage?\n- What changes for automatic rollback with a hard latency spike lasting 5 minutes?","diagram":"flowchart TD\nA[Global HTTP(S) LB] --> B[Cloud Run v2 per-region split]\nB --> C[Canary stages: 2% 15m -> 20% 30m -> 100%]\nC --> D[Cloud Monitoring alerts (latency, 5xx)]\nD --> E[Cloud Trace sampling]\nE --> F[Rollback to v1 if SLO violated]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T09:43:41.387Z","createdAt":"2026-01-22T09:43:41.387Z"},{"id":"q-5754","question":"You're deploying a multi-region Kubernetes API on GKE behind a Global HTTP(S) Load Balancer. Implement a progressive rollout of v2 with a multi-region canary: 5% traffic in us-east1 for 20 minutes, then 20% in us-east1 and 10% in us-west1 for 20 minutes, then full rollout if p95 latency <= 0.75s and error rate <= 0.2% in all regions. Use only Google-native tools (Cloud Deploy, Artifact Registry, Cloud Monitoring, Cloud Load Balancing, Secrets Manager). Provide exact manifests, per-region traffic-split, alert policies, and rollback workflow?","answer":"Describe the canary plan and exact commands: create per-region k8s manifests for v2, use Cloud Deploy to ship a release with region-specific traffic-splits, push images to Artifact Registry, set p95 l","explanation":"## Why This Is Asked\n\nTests mastery of multi-region progressive delivery, GM tooling, and rollback discipline in production. Emphasizes exact, reproducible steps with observable metrics.\n\n## Key Concepts\n\n- GKE progressive rollout across regions\n- Cloud Deploy traffic-splits and canary strategy\n- Per-region Monitoring and alerting\n- Artifact Registry for images\n- Secrets Manager and IAM least privilege\n\n## Code Example\n\n```yaml\n# Example: Cloud Deploy rollout snippet (conceptual)\napiVersion: deploy.cloud.google.com/v1\nkind: Release\nmetadata:\n  name: v2-canary\n...\n```\n\n## Follow-up Questions\n\n- How would you handle a regional outage during the canary?\n- What are safe thresholds if some regions have lower latency baselines?","diagram":"flowchart TD\nA[Build v2] --> B[Push to Artifact Registry]\nB --> C[Cloud Deploy release]\nC --> D[Traffic split: us-east1 5%]\nC --> E[Traffic split: us-west1 0%]\nD --> F[Monitor p95 latency & error rate]\nE --> F\nF --> G{SLO OK across regions}\nG -->|Yes| H[Increase traffic per region]\nG -->|No| I[Rollback to v1]\n","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Hashicorp","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T15:08:02.267Z","createdAt":"2026-01-22T15:08:02.267Z"},{"id":"q-5817","question":"You're deploying a beginner-friendly Cloud Run service named health-check that reads a DB password from Secret Manager. Using only Google-native tools, outline steps to store the credential in Secret Manager, grant the Cloud Run service account least-privilege access, deploy v1 to Cloud Run with the secret exposed as an environment variable, and set up a Monitoring alert if the secret cannot be retrieved more than 3 times in 10 minutes?","answer":"Create and version a Secret in Secret Manager (db-password); grant the Cloud Run service account secretAccessor. Deploy v1 to Cloud Run with the secret exposed as an env var via --set-secrets DB_PASSW","explanation":"## Why This Is Asked\n\nAssesses practical experience wiring Secret Manager, Cloud Run, and Monitoring with Google-native tools. Focuses on secure access patterns and observable failures.\n\n## Key Concepts\n\n- Secret Manager integration with Cloud Run environment variables\n- IAM least-privilege for service accounts\n- Cloud Run deployment flow and secret mapping\n- Log-based metrics and alerting in Cloud Monitoring\n\n## Code Example\n\n```javascript\n// Bash-like commands (illustrative)\n// 1) create secret\ngcloud secrets create db-password --replication-policy=automatic\n// 2) add version (password supplied securely)\ngcloud secrets versions add db-password --data-file=- << 'EOF'\n$DB_PASSWORD\nEOF\n// 3) grant access to Cloud Run SA\ngcloud run services add-iam-policy-binding health-check \\\n  --member=serviceAccount:health-check-sa@PROJECT.iam.gserviceaccount.com \\\n  --role=roles/secretmanager.secretAccessor\n// 4) deploy with secret\ngcloud run deploy health-check --image gcr.io/PROJECT/health-check:latest \\\n  --region us-central1 --set-secrets DB_PASSWORD=db-password:latest\n// 5) monitoring: create log metric and alert (simplified)\ngcloud logging metrics create secret_retrieval_errors \\\n  --log-filter='resource.type=\"cloud_run_revision\" textPayload:\"Secret retrieval failed\"'\ngcloud beta monitoring policies create --conditions '...'\n```\n\n## Follow-up Questions\n\n- How would you rotate the secret with zero-downtime?\n- How would you test the alerting in a sandbox?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","LinkedIn","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T17:55:23.993Z","createdAt":"2026-01-22T17:55:23.993Z"},{"id":"q-5836","question":"You're rotating a service account key used by CI runners and a Kubernetes cluster across multiple projects. Using Google-native tools only, outline an end-to-end plan to rotate the service account key: (1) create a new key, (2) store it safely in Secret Manager, (3) update all workloads to fetch the new secret, (4) disable the old key after a grace period, (5) verify using Cloud Audit Logs and IAM policies, and (6) provide a safe rollback if disruption occurs. Include precise gcloud/secret manager commands and rollout approach?","answer":"Create a new service account key; store it safely in Secret Manager as a new version; update workloads to fetch the new secret; disable the old key after a grace period; verify access with Cloud Audit","explanation":"## Why This Is Asked\nTests secret rotation discipline, automation, and rollback in a multi-project setup with Google-native tools.\n\n## Key Concepts\n- Service accounts and keys\n- Secret Manager secret versions\n- Workload identity and secret propagation\n- IAM least privilege and auditing\n\n## Code Example\n```bash\n# Create new key\ngcloud iam service-accounts keys create /tmp/new-key.json --iam-account my-sa@proj.iam.gserviceaccount.com\n# Push as new Secret Manager version\ngcloud secrets versions add my-sa-key-secret --data-file /tmp/new-key.json\n# Rollout update (restart deployments to fetch new secret)\nkubectl rollout restart deployment/my-app\n# Disable old key\n# (after verification period)\ngcloud iam service-accounts keys delete OLD_KEY_ID --iam-account my-sa@proj.iam.gserviceaccount.com\n```\n\n## Follow-up Questions\n- How to verify no race conditions during rollout?\n- What security controls would you add to prevent leakage during rotation?","diagram":"flowchart TD\n  A[Create new key] --> B[Store as Secret Manager version]\n  B --> C[Update workloads]\n  C --> D[Restart workloads to fetch secret]\n  D --> E[Disable old key]\n  E --> F[Audit logs & rollback if needed]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Hugging Face","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T18:56:00.076Z","createdAt":"2026-01-22T18:56:00.077Z"},{"id":"q-5952","question":"You're releasing a new Cloud Run service named log-processor-v1. Using only Google-native tools, design a beginner-friendly CI/CD: build a Docker image, push to Artifact Registry, deploy v1 to Cloud Run via a Cloud Build trigger on main, and add an uptime check in Cloud Monitoring to alert if the URL returns non-200 for 5 minutes. Include minimal IAM roles for the Build and Run service accounts and exact commands?","answer":"Create a Cloud Build configuration that builds the Docker image, pushes it to Artifact Registry, and deploys v1 to Cloud Run; configure a Cloud Build trigger on the main branch; set up a Cloud Monitoring uptime check for the deployed service URL to alert when responses are non-200 for 5 minutes; assign minimal IAM roles to both Build and Run service accounts.","explanation":"## Why This Is Asked\n\nTests practical, end-to-end CI/CD implementation on GCP: containerization, registry management, deployment automation, observability, and security through least-privilege IAM for a new service.\n\n## Key Concepts\n\n- Cloud Build triggers and automation\n- Artifact Registry for container storage\n- Cloud Run deployment workflows\n- Cloud Monitoring uptime checks\n- IAM least-privilege principles\n\n## Code Example\n\n```yaml\nsteps:\n- name: 'gcr.io/cloud-builders/docker'\n  args: ['build','-t','REGION-docker.pkg.dev/PROJECT/REPO/log-processor-v1:latest','.']\n- name: 'gcr.io/cloud-builders/docker'\n  args: ['push','REGION-docker.pkg.dev/PROJECT/REPO/log-processor-v1:latest']\n- name: 'gcr.io/google.","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T05:28:50.477Z","createdAt":"2026-01-22T23:36:52.817Z"},{"id":"q-5970","question":"You're migrating a Cloud Run service named invoice-processor behind a Global HTTP(S) Load Balancer. Implement a nightly, automated promotion from v1 to v2 using only Google-native tools: build and push the v2 image to Artifact Registry, deploy v2 with a 5% canary for 30 minutes, run a lightweight test suite and latency checks, and promote to 100% if tests pass and p95 latency <= 0.6s with error rate < 0.1%; otherwise rollback to v1 by routing all traffic back. Include exact gcloud steps, per-revision traffic split, monitoring alerts, and minimal IAM permissions?","answer":"Schedule nightly promotion for invoice-processor from v1 to v2 using Cloud Scheduler and Cloud Build. Build v2, push to Artifact Registry, deploy v2 with 5% canary for 30 minutes, run automated test suite and latency checks, then promote to 100% if tests pass with p95 latency ≤ 0.6s and error rate < 0.1%; otherwise rollback to v1 by routing all traffic back.","explanation":"## Why This Is Asked\nTests the ability to orchestrate scheduled deployments, progressive delivery, and rollback using only Google-native tools. Emphasizes automation, observable SLIs, and least-privilege IAM.\n\n## Key Concepts\n- Cloud Scheduler for nightly triggers\n- Cloud Build for image build/push to Artifact Registry\n- Cloud Run traffic updates for canary and full rollout\n- Cloud Monitoring alerts for latency and error rate\n- IAM least-privilege roles\n\n## Code Example\n```bash\n# Build v2\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJ/REPO/invoice-processor:v2 .\n# Deploy v2\ngcloud run deploy invoice-processor-v2 --image us-central1-docker.pkg.dev/PROJ/REPO/invoice-processor:v2 --no-traffic\n# Set 5% traffic to v2\ngcloud run services update-traffic invoice-processor --to-revisions=v2=5,v1=95\n```","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","NVIDIA","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T03:56:56.350Z","createdAt":"2026-01-23T02:22:43.052Z"},{"id":"q-6088","question":"You're implementing a CI/CD for a Cloud Run service named data-ingest. Using only Google-native tools, describe the exact steps to build a Docker image from a repo, push to Artifact Registry, deploy v1 to Cloud Run, inject a database connection string from Secret Manager as an environment variable, and grant the necessary IAM roles. Include explicit gcloud commands and secrets rotation approach?","answer":"Describe a Cloud Build pipeline that builds an image for data-ingest, pushes to Artifact Registry, deploys v1 to Cloud Run, and injects a DB connection string from Secret Manager as an environment var","explanation":"## Why This Is Asked\nTests ability to assemble a small, secure, Google-native CI/CD flow using familiar services and IAM considerations.\n\n## Key Concepts\n- Cloud Build, Artifact Registry, Cloud Run, Secret Manager\n- IAM roles: roles/secretmanager.secretAccessor, roles/run.admin or appropriate service account permissions\n- Secret rotation approach via new versions\n\n## Code Example\n```yaml\nsteps:\n- name: 'gcr.io/cloud-builders/docker'\n  args: ['build','-t','us-docker.pkg.dev/PROJECT/my-repos/data-ingest:v1','.']\n- name: 'gcr.io/cloud-builders/docker'\n  args: ['push','us-docker.pkg.dev/PROJECT/my-repos/data-ingest:v1']\n- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n  entrypoint: 'bash'\n  args: ['-c','gcloud secrets create DB_CONN_STRING --data-file=db_conn.txt || true && gcloud secrets versions add DB_CONN_STRING --data-file=db_conn.txt && gcloud run deploy data-ingest --image us-docker.pkg.dev/PROJECT/my-repos/data-ingest:v1 --region us-central1 --secret-env DB_CONN_STRING=DB_CONN_STRING_SECRET --platform managed']\n```\n\n## Follow-up Questions\n- How would you rotate the secret and update Cloud Run without downtime?\n- What minimal IAM bindings ensure Cloud Run can access the secret and image?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T08:00:29.957Z","createdAt":"2026-01-23T08:00:29.957Z"},{"id":"q-6187","question":"You're operating a mission-critical multi-region API on GKE with clusters in us-central1 and us-east1 behind a Google Cloud Load Balancer. Release v2 via Google Cloud Deploy with progressive delivery: Stage 1: 5% traffic in us-central1 for 10m; Stage 2: 25% across both regions for 20m; Stage 3: 100% if no degradation. Provide exact steps for building/pushing to Artifact Registry, configuring the Cloud Deploy pipeline, per-stage traffic shaping, per-regions Cloud Monitoring SLOs (p95 latency ≤1.2s, error rate ≤0.3% for 5m), and auto-rollback to v1. Include minimal IAM roles needed and how rollback is triggered?","answer":"Build v2 image and push to Artifact Registry. Create a Cloud Deploy release with three stages: Stage1 5% in us-central1 for 10m; Stage2 25% across both regions for 20m; Stage3 100% if healthy. Enable ","explanation":"## Why This Is Asked\nTests real-world progressive delivery on multi-region GKE with Cloud Deploy, observability, and IAM least privilege.\n\n## Key Concepts\n- Cloud Deploy multi-stage rollouts\n- GKE traffic shaping and regional rollout\n- Artifact Registry integration\n- Cloud Monitoring SLIs/SLOs and automatic rollback\n- IAM roles and service accounts for pipelines\n\n## Code Example\n```yaml\napiVersion: clouddeploy.googleapis.com/v1\nkind: DeliveryPipeline\nmetadata:\n  name: sample-pipeline\n# minimal example\n```\n\n## Follow-up Questions\n- How would you handle failure in Stage2 affecting all regions?\n- How would you audit rollbacks and incidents?","diagram":"flowchart TD\n  A[Build v2] --> B[Push to Artifact Registry]\n  B --> C[Cloud Deploy Release]\n  C --> D[Stage1: 5% us-central1 (10m)]\n  D --> E[Stage2: 25% all regions (20m)]\n  E --> F[Stage3: 100% if healthy]\n  F --> G[Monitor & auto-rollback to v1 on breach]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T13:06:52.901Z","createdAt":"2026-01-23T13:06:52.901Z"},{"id":"q-6312","question":"You're adding a Cloud Run Job named daily-agg to process a daily CSV from a Cloud Storage input bucket and write results to an output bucket. Using only Google-native tools, describe exact steps to: (1) build/push the container to Artifact Registry, (2) create the Cloud Run Job with a 60-minute timeout and SOURCE_BUCKET env var, (3) configure Cloud Scheduler to trigger daily at 02:00 UTC, and (4) bind IAM so only the scheduler can invoke the job. Include a simple rollback plan if the run fails?","answer":"Build and push image to Artifact Registry, create the Cloud Run Job with a 60m timeout and env SOURCE_BUCKET, OUTPUT_BUCKET; set Cloud Scheduler to trigger daily at 02:00 UTC; grant run.jobsRunner to ","explanation":"## Why This Is Asked\nTests ability to configure a scheduled batch with Cloud Run Jobs using only Google-native tools. It also touches IAM, artifact storage, and rollback—common startup-day pains.\n\n## Key Concepts\n- Cloud Run Jobs, Artifact Registry, Cloud Scheduler, IAM minimal bindings, GCS integration\n\n## Code Example\n```bash\n# Build/push\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/daily-agg:latest .\n\n# Create job\ngcloud run jobs create daily-agg --image us-central1-docker.pkg.dev/PROJECT/REPO/daily-agg:latest --region us-central1 --timeout 60m --env-vars SOURCE_BUCKET=gs://input,OUTPUT_BUCKET=gs://output\n\n# Scheduler trigger\ngcloud scheduler jobs create pubsub daily-agg-schedule --schedule '0 2 * * *' --time-zone 'UTC' --topic projects/PROJECT/topics/run-job --message-body '{\"job\":\"daily-agg\"}'\n\n# IAM binding\ngcloud run jobs add-iam-policy-binding daily-agg --region us-central1 --member=serviceAccount:cloud-scheduler-sa@PROJECT.iam.gserviceaccount.com --role=roles/run.jobsRunner\n```\n\n## Follow-up Questions\n- How would you ensure idempotency if the job runs twice?\n- How would you monitor failures and alert on retries?","diagram":"flowchart TD\n  A[Build image] --> B[Push to Artifact Registry]\n  B --> C[Create Cloud Run Job]\n  C --> D[Configure Cloud Scheduler]\n  D --> E[Grant permissions]\n  E --> F[Run daily]\n  F --> G[Rollback path]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T18:59:44.920Z","createdAt":"2026-01-23T18:59:44.920Z"},{"id":"q-6376","question":"You're deploying a Cloud Run service for external users and want to tie deployment to observability. Using only Google-native tools, describe exact steps to build/push the container to Artifact Registry, deploy v2 to Cloud Run, create a log-based metric counting 5xx errors, configure an alert that triggers a rollback to v1 after 10 minutes of elevated error rate, and enforce minimal IAM. Include a minimal cloudbuild.yaml?","answer":"Build and push the container image using Cloud Build to Artifact Registry, deploy version 2 to Cloud Run, create a log-based metric to count 5xx errors, configure an alert that triggers an automatic rollback to version 1 after 10 minutes of elevated error rate, and enforce minimal IAM permissions.","explanation":"## Why This Is Asked\nTests the ability to integrate CI/CD pipelines with observability and implement safe rollback mechanisms using only Google-native tools.\n\n## Key Concepts\n- Cloud Build, Artifact Registry, and Cloud Run integration\n- Cloud Logging log-based metrics and Monitoring alerting\n- Safe rollback implementation through traffic shifting to version 1\n- Least-privilege IAM principles\n\n## Code Example\n```yaml\n# cloudbuild.yaml\nsteps:\n- name: gcr.io/cloud-builders/docker\n  args: ['build', '-t', 'REG/IMAGE:$SHORT_SHA', '.']\n- name: gcr.io/cloud-builders/docker\n  args: ['push', 'REG/IMAGE:$SHORT_SHA']\n- name: gcr.io/cloud-builders/gcloud\n  args: ['run', 'services', 'update', 'SERVICE', '--image', 'REG/IMAGE:$SHORT_SHA', '--region', 'REGION']\n```","diagram":"flowchart TD\n  A[Build image] --> B[Push to Artifact Registry]\n  B --> C[Deploy v2 to Cloud Run]\n  C --> D[Create log-based metric (5xx)]\n  D --> E[Monitor alert]\n  E --> F[Rollback to v1 if triggered]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T05:34:55.512Z","createdAt":"2026-01-23T21:39:39.244Z"},{"id":"q-6526","question":"Your API is deployed on Cloud Run across two regions behind a Global HTTP(S) LB. Design a policy-driven promotion to prod using only Google Cloud-native tools: Binary Authorization attestations, Container Analysis vulnerability gating, CMEK on Artifact Registry, and least-privilege IAM. Include a rollback path by re-promoting the last attested image. Provide exact steps and commands?","answer":"Gate prod promotions with Binary Authorization attestations and Container Analysis scans. Use a Cloud Build trigger that promotes only if attestation passes and vulnerability score is under threshold;","explanation":"## Why This Is Asked\nStress security gates and policy-as-code in production deployments.\n\n## Key Concepts\n- Binary Authorization attestation and policy\n- Artifact Registry CMEK and IAM least privilege\n- Container Analysis vulnerability gating\n- Cloud Build gated promotion\n- Rollback with last attested image\n\n## Code Example\n```bash\n# Enable APIs\ngcloud services enable binaryauthorization.googleapis.com containeranalysis.googleapis.com \n# Create attestor and policy, then restrict prod\n# (illustrative commands only)\n```\n\n## Follow-up Questions\n- How would you monitor attestation failures and rollback latency?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Cloudflare","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T07:05:36.778Z","createdAt":"2026-01-24T07:05:36.778Z"},{"id":"q-6556","question":"You're deploying a Cloud Run service named status-api in us-central1 with two environments (dev and prod) using separate Cloud Run services. Design a minimal, Google-native setup focused on observability and cost control: tune autoscaling (min 0, max 300) and resource requests, emit a custom metric 'requests_per_second' from the app to Cloud Monitoring, build/deploy from Artifact Registry, create a Cloud Monitoring dashboard for latency, error rate, and RPS, set an alert for 5xx rate > 1% for 10 minutes, configure Cloud Billing budgets with alerts at $50 and $80, and ensure the deployment service account has least privilege (logs/metrics only). Include exact steps and code snippets for the metric, build/deploy, alert policies?","answer":"Split dev/prod as separate Cloud Run services; min instances 0, max 300; instrument code to push a custom metric 'requests_per_second' to Cloud Monitoring, deploy via Cloud Build to Artifact Registry,","explanation":"## Why This Is Asked\nThis assesses practical setup of observability and cost controls using native GCP tools without reliance on third-party services.\n\n## Key Concepts\n- Cloud Run autoscaling tuning and resource requests\n- Cloud Monitoring custom metrics and dashboards\n- Artifact Registry and Cloud Build deployment\n- Billing budgets and alerting\n- Least-privilege IAM for deployment\n\n## Code Example\n```javascript\n// Node.js snippet to emit a custom metric to Cloud Monitoring\nconst {MetricServiceClient} = require('@google-cloud/monitoring');\nconst client = new MetricServiceClient();\nasync function publishRPSS(sps) {\n  const dataPoint = {\n    value: {doubleValue: sps}\n  };\n  const timeSeries = {\n    metric: {type: 'custom.googleapis.com/requests_per_second'},\n    resource: {type: 'global', labels: {project_id: process.env.GCP_PROJECT}},\n    points: [{interval: {endTime: {seconds: Date.now()/1000}}, value: dataPoint}]\n  };\n  await client.createTimeSeries({name: client.projectPath(process.env.GCP_PROJECT), timeSeries: [timeSeries]});\n}\n```\n\n## Follow-up Questions\n- How would you test the alert policy and validate no false positives?\n- How would you scale this across many environments while maintaining least privilege?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T07:59:08.760Z","createdAt":"2026-01-24T07:59:08.760Z"},{"id":"q-6617","question":"Scenario: A real-time pricing API runs on Cloud Run Gen2 in two regions behind a Global HTTP(S) Load Balancer. A new feature flag gated by X-Feature-Flag enables a more aggressive pricing model. Design a phased, per-tenant canary rollout that starts with 2% of GOLD customers in each region for 15 minutes, expands to 10% for 30 minutes, then 50% for 1 hour, finally 100% if SLOs hold. Implement automatic rollback if p95 latency > 0.8s or error rate > 0.3% in any region. Use only Google-native tools; specify traffic-splitting, per-region rules, monitoring alerts, and feature-flag storage/rotation?","answer":"Deploy v2 in both regions; traffic canary: 2% for 15m, 10% for 30m, 50% for 1h, then 100% if p95 latency < 0.8s and error rate <0.3% in both regions. Route by header X-Feature-Flag and X-Customer-Tier","explanation":"## Why This Is Asked\nTests ability to design multi-region, tenant-aware deployments using Google-native tools and automated rollback,\n\n## Key Concepts\n- Cloud Run traffic splitting, per-region rollout, header-based routing, Cloud Monitoring SLOs, Secrets management, IAM least privilege\n- Global HTTP(S) Load Balancer integration with Cloud Run, URL maps, and warning thresholds\n- Automated rollback safety and verification across regions\n\n## Code Example\n```javascript\n// Example: gcloud traffic split commands (pseudo)\ngcloud run services update-traffic pricing-api \\\n  --region us-central1 --to-revisions v2=2,v1=98\n```\n\n## Follow-up Questions\n- How would you test the rollback in a DR drill?\n- How do you handle stale caches during rollout?","diagram":"flowchart TD\nA[Start] --> B[Deploy v2 in regions]\nB --> C{2% Canary in 15m}\nC --> D{10% in 30m}\nD --> E{50% in 60m}\nE --> F[100% if SLOs OK]\nF --> G{SLOs violated?}\nG --> H[Rollback to v1]\nH --> I[Done]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T10:35:30.026Z","createdAt":"2026-01-24T10:35:30.026Z"},{"id":"q-6735","question":"You're deploying a Cloud Run API named students-api with v1. You want to ensure observability by creating log-based latency and error metrics and alerting on p95 latency > 0.8s or error rate > 0.2% within 10 minutes, plus a health uptime check. Using only Google-native tools, outline exact steps to implement metrics, alerts, and an automated notification path (no code changes)?","answer":"Create a log-based latency metric and an error metric from Cloud Run logs for students-api v1, then set a Cloud Monitoring alert: p95 latency >0.8s and error rate >0.2% in 10 minutes, plus a health up","explanation":"## Why This Is Asked\nObservability basics: set up metrics and alerts without changing code, ensuring reliable deployments.\n\n## Key Concepts\n- Log-based metrics from Cloud Run logs\n- Cloud Monitoring alerting policies\n- Uptime checks for health\n- Least-privilege IAM for automation\n\n## Code Example\n```bash\n# Latency metric from logs\ngcloud logging metrics create latency_p95 \\\n  --description=\"p95 latency\" \\\n  --log-filter='resource.type=\"cloud_run_revision\" AND resource.labels.service_name=\"students-api\"'\n\n# Error metric from logs\ngcloud logging metrics create errors_rate \\\n  --description=\"error count\" \\\n  --log-filter='resource.type=\"cloud_run_revision\" AND resource.labels.service_name=\"students-api\" AND (httpRequest.status>=400)'\n\n# Placeholder for alert policy (define via policy.json in practice)\ngcloud beta monitoring policies create --policy-from-file=policy.json\n```\n\n## Follow-up Questions\n- How would you test the alerts without affecting traffic?\n- How would you adapt thresholds for traffic growth?\n","diagram":"flowchart TD\n  A[Define log-based latency metric] --> B[Define log-based error metric]\n  B --> C[Create Monitoring alert policy for latency]\n  C --> D[Create Monitoring alert policy for errors]\n  D --> E[Configure uptime check]\n  E --> F[Attach to notification channels]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Google","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T15:29:32.085Z","createdAt":"2026-01-24T15:29:32.085Z"},{"id":"q-6902","question":"You're deploying a Cloud Run service named log-processor across two regions with a Global HTTP(S) Load Balancer. Primary in us-central1 (v1) and backup in europe-west1 (v2). Using only Google-native tools, specify exact steps to build/push both revisions to Artifact Registry, deploy revisions, configure a cross-region failover with a backup backend, set health checks (latency and error thresholds), and implement automatic failover; include minimal IAM roles and monitoring alerts?","answer":"Deploy v1 in us-central1 and v2 in europe-west1; attach both to a Global HTTP(S) Load Balancer with primary/backup backend configuration. Implement health checks targeting the /health endpoint (latency ≤ 350ms, 5xx error rate < 0.2%). Configure automatic failover with Cloud Monitoring alerts for backend health and response time thresholds. Use least-privilege IAM roles: Cloud Run Developer, Artifact Registry Writer, and Load Balancer Administrator for deployment, and Monitoring Viewer for alerting.","explanation":"## Why This Is Asked\nTests multi-region deployment skills, cross-region failover, and Google-native traffic management. Beginner level but requires correct resource relationships and sequencing.\n\n## Key Concepts\n- Global HTTP(S) Load Balancing with failover routing\n- Cloud Run multi-region deployment strategies\n- Artifact Registry + Cloud Build CI/CD integration\n- Health checks with latency and error thresholds\n- IAM least privilege for deployment and monitoring\n\n## Code Example\n```bash\n# Build and push v1 to Artifact Registry\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/log-registry/log-processor:v1 .\n\n# Build and push v2 to Artifact Registry\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/log-registry/log-processor:v2 .\n\n# Deploy Cloud Run services\ngcloud run deploy log-processor-v1 --image us-docker.pkg.dev/PROJECT/log-registry/log-processor:v1 --region us-central1\ngcloud run deploy log-processor-v2 --image us-docker.pkg.dev/PROJECT/log-registry/log-processor:v2 --region europe-west1\n```","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Slack","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:58:02.307Z","createdAt":"2026-01-24T22:28:15.886Z"},{"id":"q-6964","question":"You're releasing v3 of a multi-region Cloud Run API behind a Global HTTP(S) Load Balancer with regional backends us-east1/us-central1/us-west1. Implement a per-tenant progressive rollout: tenants opt-in via a feature flag stored in Secret Manager; v3 serves only opted tenants while others stay on v2. Provide exact steps to build/push v3 to Artifact Registry, deploy with per-tenant routing logic, configure per-tenant health checks, Cloud Monitoring alerts for latency and errors by tenant, and automatic rollback shifting all traffic back to v2 if SLA is violated. Include minimal IAM roles and CMEK usage?","answer":"Deploy v3 to Artifact Registry and implement it behind a Global HTTP(S) Load Balancer with regional backends in us-east1, us-central1, and us-west1. Build per-tenant routing logic where each tenant's opt-in status is stored as a feature flag in Secret Manager. The application checks the tenant's flag on each request: opted tenants receive v3 while others continue on v2. Configure per-tenant health checks to monitor service health individually, implement Cloud Monitoring alerts with tenant-specific dimensions for latency and error rates, and establish automatic rollback mechanisms that shift all traffic back to v2 when SLA thresholds are violated. Apply minimal IAM roles following least privilege principles and enable CMEK for secret encryption.","explanation":"## Why This Is Asked\nTests practical rollout control in a multi-region, serverless setup with tenancy isolation and strict SLOs.\n\n## Key Concepts\n- Per-tenant feature flags in Secret Manager\n- Global Load Balancing with multi-region backends\n- Progressive rollout by tenant, not global traffic\n- Per-tenant monitoring and automatic rollback\n- Least-privilege IAM and CMEK for secret protection\n\n## Code Example\n```javascript\n// Pseudo-code: checkTenantFlag(req) -> serve v3 or v2\n```\n\n## Follow-up Questions\n- How would you test the tenancy flag without affecting real tenants?\n- How would you handle flag caching and consistency across regions?\n- What's your rollback strategy if the flag service becomes unavailable?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:26:23.469Z","createdAt":"2026-01-25T02:43:04.115Z"},{"id":"q-7035","question":"You're deploying a Cloud Run service named fast-image-resizer. To reduce cold starts in low-traffic hours, configure min-instances=2 and set up a Cloud Scheduler job to ping the URL every 5 minutes during business hours. Using only Google-native tools, provide exact gcloud steps to set min-instances, create the scheduler, authenticate to Cloud Run, and assign minimal IAM roles for the scheduler's service account?","answer":"Set min-instances to 2 on the Cloud Run service; create a Cloud Scheduler HTTP job that pings the Cloud Run URL every 5 minutes from 9:00 to 17:00, Monday–Friday, using an OIDC token from a dedicated ","explanation":"## Why This Is Asked\n\nTests practical config of pre-warm strategies using native tools and least-privilege IAM.\n\n## Key Concepts\n\n- Cloud Run min-instances\n- Cloud Scheduler with OIDC authentication\n- IAM roles/run.invoker least privilege\n\n## Code Example\n\n```bash\n# Example placeholder commands illustrating the described steps\n```\n\n## Follow-up Questions\n\n- How would you adjust if traffic spikes unpredictably?\n- What are the cost implications of min-instances?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Plaid","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T06:56:33.228Z","createdAt":"2026-01-25T06:56:33.229Z"},{"id":"q-7097","question":"You're releasing v3 of a Cloud Run (fully managed) service named file-indexer that triggers a Cloud Tasks worker per file. Using only Google-native tools, implement a canary: 10% traffic to v3 for 25 minutes with automatic rollback to v2 if p95 ingestion latency to Cloud Tasks > 1.2s for 5 minutes or queue backlog > 100 tasks for 3 consecutive 5-minute windows. Include exact steps to build/push v3 to Artifact Registry, configure a Cloud Deploy rollout with per-revision traffic-split, set Cloud Monitoring alert policies, and rollback by shifting all traffic back to v2. Include minimal IAM roles?","answer":"10% traffic to v3 for 25 minutes canary; auto-rollback to v2 if p95 ingestion latency to Cloud Tasks > 1.2s for 5 minutes or queue backlog > 100 tasks for 15 minutes. Build/push v3 to Artifact Registr","explanation":"## Why This Is Asked\n\nTests real-world progressive delivery with Cloud Deploy, Cloud Run, and Cloud Tasks, including cross-component latency/queue metrics and safe rollback.\n\n## Key Concepts\n\n- Canary deployments with per-revision traffic-split\n- Cloud Run and Artifact Registry integration\n- Cloud Tasks latency and queue depth alerts\n- IAM least-privilege for deploy/monitor\n\n## Code Example\n\n```bash\n# Build and push v3\ngcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/file-indexer:v3\n# Deploy with canary traffic\ngcloud beta run services update-file-indexer --image us-central1-docker.pkg.dev/PROJECT/REPO/file-indexer:v3 --region us-central1 --traffic v3=10\n```\n\n## Follow-up Questions\n\n- How would you adjust thresholds for burst traffic?\n- How would you extend to multi-region deployment with Cloud Load Balancing?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Anthropic","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T08:59:45.340Z","createdAt":"2026-01-25T08:59:45.340Z"},{"id":"q-7187","question":"You're deploying a Cloud Run (fully managed) service named weather-api that reads from a Cloud SQL Postgres database. Using only Google-native tools, implement a minimal blue/green canary: deploy v1, then route 10% of traffic to v2 for 12 minutes; if p95 latency > 0.9s or error rate > 1% for a 5-minute window, automatically rollback to v1 and route 100% to v1. Include exact steps to build/push images to Artifact Registry, per-revision traffic-split, Cloud Monitoring alert policies, and minimal IAM roles?","answer":"Build v2 image and push to Artifact Registry, deploy v1 then switch 10% traffic to v2 for 12 minutes via gcloud run services update-traffic weather-api --to-revisions weather-api-v1=90,weather-api-v2=","explanation":"## Why This Is Asked\nTests practical canary deployment, traffic control, and rollback using Google-native tools. Emphasizes Cloud Run traffic split, Monitoring alerts, and IAM least privilege in a real workflow.\n\n## Key Concepts\n- Cloud Run per-revision traffic splitting\n- Artifact Registry image workflow\n- Cloud Monitoring alert policies for latency and errors\n- IAM roles with least privilege for build/deploy\n\n## Code Example\n```javascript\nfunction updateTraffic(service, v1, v2, ratio) {\n  // pseudo: flip traffic between revisions based on ratio\n  console.log(`Set ${service} traffic: ${v1}=${100-ratio}%, ${v2}=${ratio}%`)\n}\n```\n\n## Follow-up Questions\n- How would you test rollback safety in a non-prod environment?\n- What changes if latency budgets or error thresholds vary by region?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Google","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T13:18:28.954Z","createdAt":"2026-01-25T13:18:28.954Z"},{"id":"q-7368","question":"You're adding a new Cloud Run job named data-refresh, triggered by Cloud Scheduler daily at 02:00. Using only Google-native tools, outline end-to-end steps to build/push image to Artifact Registry, deploy data-refresh as v2 with a dedicated service account (least-privilege), configure a Cloud Scheduler trigger, and set up a Cloud Monitoring alert that triggers rollback to v1 if the job fails for 15 minutes. Include rollback and deactivation details?","answer":"Build the container and push to Artifact Registry. Deploy Cloud Run service data-refresh v2 with a dedicated service account possessing minimal permissions (roles/run.admin, roles/iam.serviceAccountUs","explanation":"## Why This Is Asked\nTests practical use of Google-native CI/CD, scheduling, and monitoring in a low-risk deployment.\n\n## Key Concepts\n- Cloud Build + Artifact Registry\n- Cloud Run revisions and traffic splitting\n- Cloud Scheduler triggering HTTP endpoints\n- Cloud Monitoring alerts and automated rollback\n- Least-privilege IAM for service accounts\n\n## Code Example\n```javascript\n// No code required in interview; refer to cloud ops steps\n```\n\n## Follow-up Questions\n- How would you test the rollback path in a staging project?\n- How would you ensure idempotent Scheduler triggers?","diagram":"flowchart TD\nA[Source] --> B[Cloud Build/Artifact Registry]\nB --> C[Cloud Run v2]\nC --> D[Cloud Scheduler]\nD --> E[Cloud Run v1 (rollback)]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Instacart","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T20:36:15.669Z","createdAt":"2026-01-25T20:36:15.670Z"},{"id":"q-7511","question":"You're deploying a nightly Cloud Run Job named daily-processor. Using only Google-native tools, design a minimal CI/CD: build container image, push to Artifact Registry, deploy the Cloud Run Job, and set Cloud Scheduler to trigger nightly at 02:00. Add a log-based metric for job failures and a Cloud Monitoring alert if failures occur in a 24h window. Include minimal IAM permissions and a quick test plan. How would you implement this end-to-end?","answer":"Build image, push to Artifact Registry, deploy Cloud Run Job daily-processor, schedule nightly 02:00 via Cloud Scheduler, and add a log-based metric for failures with a 24h alert. IAM: roles/run.admin","explanation":"## Why This Is Asked\nTests practical, beginner-friendly use of Google-native services to automate a nightly job and monitor it end-to-end.\n\n## Key Concepts\n- Cloud Run Jobs for batch tasks\n- Artifact Registry as image store\n- Cloud Scheduler for time-based triggers\n- Cloud Logging log-based metrics for failures\n- Cloud Monitoring alerting for SLO/alerting\n- Least-privilege IAM roles for deployment\n\n## Code Example\n```javascript\n# Build and push image\ngcloud auth configure-docker us-central1-docker.pkg.dev\ndocker build -t daily-processor:latest .\ndocker tag daily-processor:latest us-central1-docker.pkg.dev/PROJECT/REPO/daily-processor:latest\ndocker push us-central1-docker.pkg.dev/PROJECT/REPO/daily-processor:latest\n\n# Deploy Cloud Run Job\ngcloud run jobs create daily-processor --image us-central1-docker.pkg.dev/PROJECT/REPO/daily-processor:latest --region us-central1\n\n# Schedule nightly trigger (requires RUN API access)\ngcloud scheduler jobs create daily-processor-schedule \\\n  --schedule \"0 2 * * *\" \\\n  --time-zone \"UTC\" \\\n  --http-method POST \\\n  --uri \"https://run.googleapis.com/v1/projects/PROJECT/locations/us-central1/jobs/daily-processor:run\" \\\n  --oauth-service-account-email service-account@PROJECT.iam.gserviceaccount.com\n\n# Manual test\ngcloud run jobs execute daily-processor --region us-central1\n```\n\n## Follow-up Questions\n- How would you extend to handle transient failures and retry limits?\n- How would you verify the alerting policy fires correctly without impacting production?","diagram":"flowchart TD\n  A[Source Image] --> B[Artifact Registry]\n  B --> C[Cloud Run Job: daily-processor]\n  C --> D[Cloud Scheduler: nightly trigger]\n  D --> E[Cloud Run Job Execution]\n  E --> F[Cloud Logging & Monitoring]\n  F --> G[IAM Roles & Permissions]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T05:38:30.802Z","createdAt":"2026-01-26T05:38:30.804Z"},{"id":"q-7640","question":"You're maintaining a Cloud Run API for image thumbnailing behind a global HTTP(S) Load Balancer with Cloud CDN. Implement a recurring canary: Sunday 02:00 UTC, route 5% of traffic to v2 for 20 minutes; automatically rollback to v1 if p95 latency > 450ms or error rate > 1% for any 5-minute window. Use only Google-native tools. Include exact steps to build/push v2 to Artifact Registry, per-revision traffic split, Cloud Monitoring alert policies, and rollback by shifting all traffic back; specify minimal IAM roles?","answer":"Deploy a v2 canary weekly: build/push to Artifact Registry, deploy as a v2 revision, route 5% traffic for 20 minutes; set Cloud Monitoring alerts for p95 latency and error rate; on alert, a Cloud Func","explanation":"## Why This Is Asked\nTests ability to combine scheduling, traffic control, and basic observability with GCP-native tools. It exercises end-to-end deployment flow, alert-driven rollback, and least-privilege IAM.\n\n## Key Concepts\n- Cloud Run revisions and traffic splits\n- Cloud Scheduler and Cloud Functions integration\n- Cloud Monitoring alert policies and SLI\n- Artifact Registry usage and IAM scoping\n\n## Code Example\n```javascript\n// No code required in prompt; orchestrate with gcloud commands and IAM bindings.\n```\n\n## Follow-up Questions\n- How would you adjust thresholds if traffic spikes? \n- What are the risks of automated rollbacks in production?","diagram":"flowchart TD\n  A[Build v2] --> B[Push to Artifact Registry]\n  B --> C[Deploy v2 revision]\n  C --> D[5% traffic canary]\n  D --> E[20 min window]\n  E --> F{Alert triggers?}\n  F -->|Yes| G[Rollback to v1 traffic]\n  F -->|No| H[Continue canary]\n","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Bloomberg","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T10:48:55.896Z","createdAt":"2026-01-26T10:48:55.896Z"},{"id":"q-7746","question":"You're deploying a PCI-compliant Cloud Run (fully managed) API 'payment-processor' behind a Global HTTP(S) Load Balancer. Design a progressive delivery with a region-aware canary: deploy v2 to Artifact Registry, route 15% of traffic to v2 in us-central1 for 20 minutes, then gradually expand to us-east1 and eu-west1 if no latency spikes. Implement automatic rollback if p95 latency > 800ms or error rate > 0.5% in any region for a 5-minute window. Use only Google-native tools; include exact commands and IAM permissions?","answer":"Plan a region-aware blue/green canary for payment-processor v2 using Cloud Deploy. Build/push v2 to Artifact Registry (us-central1), roll 15% traffic to v2 in us-central1 for 20 minutes, then expand t","explanation":"## Why This Is Asked\n\nTests real-world constraints: PCI compliance, multi-region delivery, and strict rollback controls. Candidates must map build, artifact promotion, and traffic steering to Google-native tools while enforcing least privilege.\n\n## Key Concepts\n\n- Progressive delivery with per-region rollouts\n- Cloud Deploy for region-scoped traffic control\n- Artifact Registry image promotion\n- Cloud Monitoring alerts per region and automatic rollback\n- IAM least-privilege for deployment\n\n## Code Example\n\n```yaml\n# sample Cloud Deploy manifest (snippet)\napiVersion: deployment.kpt.dev/v1\nkind: Config\nmetadata:\n  name: payment-processor-release\nspec:\n  targets:\n    - name: us-central1\n      region: us-central1\n      canaryPercent: 15\n      canaryDuration: 20m\n```\n\n## Follow-up Questions\n\n- How would you handle data residency constraints if a region becomes unavailable?\n- What metrics would you surface beyond latency and error rate to ensure user experience remains acceptable?","diagram":"flowchart TD\n  A[Build v2] --> B[Push to Artifact Registry]\n  B --> C[Cloud Deploy rollout]\n  C --> D[Region us-central1: 15% for 20m]\n  D --> E[Region expansion to us-east1/eu-west1 if healthy]\n  E --> F[Telemetry per region]\n  F --> G[Rollback on breach]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T15:56:29.087Z","createdAt":"2026-01-26T15:56:29.087Z"},{"id":"q-7794","question":"You're operating a multi-tenant GraphQL API on Cloud Run behind a Global HTTP(S) Load Balancer. Implement a per-tenant canary rollout: route 25% of tenants matching header X-Tenant-ID starting with 'A' to v2 for 40 minutes; automatically rollback that tenant group to v1 if p95 latency > 600ms or error rate > 1% in any 5-minute window. Use only Google-native tools. Include exact steps to build/push v2 to Artifact Registry, per-tenant header-based routing, Cloud Monitoring alert policies per tenant, and tenant-level rollback by traffic reallocation. Specify minimal IAM roles?","answer":"Push v2 image to Artifact Registry and deploy as a new v2 revision. Use a Global HTTP(S) LB with a header-based URL map to isolate tenants by X-Tenant-ID; apply 25% traffic to v2 for tenants with IDs ","explanation":"Why This Is Asked\n\nTests ability to design per-tenant progressive delivery using Google-native tools, not generic concepts.\n\nKey Concepts\n\n- Per-tenant routing with header-based matching in a Global HTTP(S) Load Balancer\n- Canary windows and automatic rollback driven by Cloud Monitoring alerts per tenant\n- Google-native deployment flow: Artifact Registry, Cloud Run revisions, traffic splits, and IAM minimal roles\n- Observability: per-tenant SLOs and alerting\n\nCode Example\n\n```javascript\n// Pseudo-logic for per-tenant canary routing inside a header-based LB config\nfunction routeTenant(tenantId, canaryWindowActive) {\n  const isA = tenantId.startsWith('A');\n  return (isA && canaryWindowActive) ? 'v2' : 'v1';\n}\n```\n\nFollow-up Questions\n\n- How would you handle tenants who join/leave the canary mid-window?\n- How would you model SLOs per tenant in Cloud Monitoring dashboards?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T17:59:39.416Z","createdAt":"2026-01-26T17:59:39.416Z"},{"id":"q-877","question":"Design a cross-region disaster recovery plan for a streaming data pipeline on GCP (Pub/Sub, Dataflow, BigQuery) that must survive a regional outage with RTO < 15 minutes and RPO < 5 minutes. The primary region is us-central1; second region is us-east1. Include data paths, failover triggers, data integrity guarantees, and operational testing steps?","answer":"Active-active DR: run identical streaming pipelines in us-central1 and us-east1. Publish to regional Pub/Sub with cross-region replication; Dataflow in each region writes to separate, schema-stable Bi","explanation":"## Why This Is Asked\nTests ability to design DR for streaming pipelines across regions, focusing on data integrity, operational testing, and real-world failover trade-offs.\n\n## Key Concepts\n- Active-active cross-region DR patterns\n- Pub/Sub regional replication strategies\n- Dataflow multi-region pipelines and idempotent sinks\n- BigQuery datasets per region with consistent schemas\n- Cloud SQL regional replicas for metadata\n- Global load balancer + DNS failover for traffic steering\n\n## Code Example\n```python\nclass DedupDoFn(beam.DoFn):\n  def process(self, element, window=beam.DoFn.WindowParam,\n              state=beam.DoFn.StateParam):\n    uid = element.get('id')\n    if not state.read():\n      state.write(True)\n      yield element\n```\n\n## Follow-up Questions\n- How would you validate RTO/RPO with drills without impacting production?\n- How would you handle schema drift and ensure backward compatibility across regions?","diagram":"flowchart TD\n  A[Ingest] --> B[Regional Pub/Sub] \n  B --> C[Dataflow (us-central1)] \n  B --> D[Dataflow (us-east1)] \n  C --> E[BigQuery (us-central1)] \n  D --> F[BigQuery (us-east1)] \n  G[Outage Detected] --> H[Failover to Healthy Region] \n  H --> I[DNS + LB Route]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:57:17.903Z","createdAt":"2026-01-12T13:57:17.903Z"},{"id":"q-921","question":"In a multi-tenant GKE deployment across two GCP projects, you must enforce strict per-tenant network isolation and controlled egress to external services. Design a scalable architecture using Shared VPC, Private Service Connect, and per-tenant firewall policies to ensure tenants only reach whitelisted external endpoints, while preventing cross-tenant access. Include identity management, auditing, drift control, and operational notes for adding new tenants?","answer":"Propose a Shared VPC with per-tenant subnets, PSA endpoints for approved SaaS services, deny-by-default firewall rules, per-tenant IAM bindings, and VPC Service Controls for data exfil. Use Cloud Logg","explanation":"## Why This Is Asked\nTests practical VPC, PSA, and IAM patterns for multi-tenant isolation; covers governance and onboarding.\n\n## Key Concepts\n- Shared VPC\n- Private Service Connect\n- VPC Service Controls\n- Per-tenant firewalls\n- Drift detection and automations\n\n## Code Example\n```hcl\n# Terraform example: create per-tenant subnets and firewall rules\nresource \"\"google_compute_network\"\" \"tenant_shared_vpc\" {\n  name                    = \"shared-vpc-demo\"\n  auto_create_subnetworks = false\n}\n```\n\n## Follow-up Questions\n- How would you onboard a new tenant with zero-downtime networking changes?\n- How would you test the isolation and whitelisting in a staging environment?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:32:32.583Z","createdAt":"2026-01-12T15:32:32.583Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":86,"beginner":36,"intermediate":28,"advanced":22,"newThisWeek":37}}