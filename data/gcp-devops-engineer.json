{"questions":[{"id":"gcp-devops-engineer-build-delivery-1768159039158-0","question":"In a microservices CI/CD pipeline on GCP, you want new code changes to be automatically built, containerized, scanned, and deployed to Cloud Run with a canary rollout to 10% traffic, then to 50% if no issues. Which combination and approach best achieves this using GCP-native tools?","answer":"[{\"id\":\"a\",\"text\":\"Use Cloud Build to build and push images to Artifact Registry, then manually adjust Cloud Run traffic to 10% and 50% in steps.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Cloud Build to trigger deployment via Cloud Deploy with a canary release configuration for the Cloud Run service, enabling traffic shifting.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Jenkins on Compute Engine to build and push images, then update Cloud Run traffic manually.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Run by itself to build and deploy code changes.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B is the best choice because Cloud Deploy supports progressive delivery and canary deployments for Cloud Run, enabling automated traffic shifting across defined stages. Cloud Build handles the CI portion (build, test, and scan) while Cloud Deploy handles the CD flow.\n\n## Why Other Options Are Wrong\n\n- A describes manual traffic shifts instead of a governed canary flow; lacks auditable deployment policy.\n- C uses a non-GCP-native tool (Jenkins) which adds management overhead and does not leverage Cloud Deploy's canary capabilities.\n- D Cloud Run cannot orchestrate a multi-stage, progressive delivery pipeline by itself.\n\n## Key Concepts\n\n- Progressive delivery with Cloud Deploy\n- Canary releases and traffic splitting\n- CI/CD integration with Cloud Build\n\n## Real-World Application\n\n- Create a Cloud Build trigger to build and push images to Artifact Registry\n- Define a Cloud Deploy delivery pipeline for the Cloud Run service with canary stages (e.g., 10% -> 50%) and automated promotions/rollbacks\n- Monitor health and metrics to trigger automatic promotions or rollbacks","diagram":null,"difficulty":"intermediate","tags":["GCP","CloudBuild","CloudDeploy","CloudRun","CI/CD","Kubernetes","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"build-delivery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:17:19.159Z","createdAt":"2026-01-11 19:17:19"},{"id":"gcp-devops-engineer-build-delivery-1768159039158-1","question":"You want to securely manage credentials used by Cloud Build steps. Which approach ensures least exposure and best auditability?","answer":"[{\"id\":\"a\",\"text\":\"Store credentials in a private Cloud Storage bucket with restricted access and fetch them at build time.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Secret Manager to store credentials and grant Cloud Build access to retrieve them at runtime, using built-in secret handling.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Embed credentials in the cloudbuild.yaml as plain text secrets.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use environment variables in Cloud Run to pass secrets to build steps.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B is correct because Secret Manager provides versioned, auditable secret storage with fine-grained IAM controls. Cloud Build can reference secrets securely within build steps, avoiding exposure in code or logs.\n\n## Why Other Options Are Wrong\n\n- A stores secrets in Cloud Storage with restricted access but lacks built-in secret rotation and fine-grained auditing.\n- C embeds secrets in cloudbuild.yaml, which risks exposure in version control and build logs.\n- D environment variables in Cloud Run pertain to runtime deployments, not secure build-time secret handling, and can be exposed in process listings and logs.\n\n## Key Concepts\n\n- Secret Manager integration with Cloud Build\n- IAM-based access control and secret versioning\n- Build-time secret exposure avoidance\n\n## Real-World Application\n\n- Create a secret in Secret Manager, grant the Cloud Build service account read access, and reference it in cloudbuild.yaml; rotate secrets regularly and audit access logs.","diagram":null,"difficulty":"intermediate","tags":["GCP","SecretManager","CloudBuild","IAM","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"build-delivery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:17:19.847Z","createdAt":"2026-01-11 19:17:20"},{"id":"gcp-devops-engineer-build-delivery-1768159039158-2","question":"To speed up builds by reusing downloaded dependencies across Cloud Build runs, which feature should you enable and configure?","answer":"[{\"id\":\"a\",\"text\":\"Enable build steps to run in a custom worker pool with caching.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Cloud Build caching by configuring the cloudbuild.yaml with cache paths to dependency directories.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Artifact Registry to cache artifacts.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Functions to cache build results.\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B is correct because Cloud Build supports caching of specified directories (cache paths) to persist dependencies across builds, dramatically reducing download times for languages like Node.js, Java, etc.\n\n## Why Other Options Are Wrong\n\n- A describes using a custom worker pool, which does not inherently enable dependency caching across builds.\n- C Artifact Registry caches artifacts produced by builds, not the dependencies downloaded during builds.\n- D Cloud Functions are not a caching mechanism for Cloud Build builds.\n\n## Key Concepts\n\n- Cloud Build cache feature\n- Cache paths for dependencies\n- Build performance optimization\n\n## Real-World Application\n\n- Add cache: paths in cloudbuild.yaml (e.g., node_modules, ~/.m2, ~/.gradle caches) to persist dependencies; ensure caches are invalidated when dependencies change.","diagram":null,"difficulty":"intermediate","tags":["GCP","CloudBuild","Cache","CI/CD","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"build-delivery","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:17:20.302Z","createdAt":"2026-01-11 19:17:20"},{"id":"gcp-devops-engineer-service-monitoring-1768224622960-0","question":"You are deploying a microservices application on GKE and want to monitor per-service latency with automated SLO-based alerts. Which approach best enables precise per-service SLIs and alerting in Cloud Monitoring?","answer":"[{\"id\":\"a\",\"text\":\"Create a single global SLO across all services and rely on aggregate latency\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Define a Cloud Monitoring Service for each microservice, instrument metrics for latency, configure per-service SLOs, and set separate alerting policies\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use only log-based metrics and compute SLIs offline in dashboards\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely solely on a single uptime check to measure availability\",\"isCorrect\":false}]","explanation":"## Correct Answer\nDefine a Cloud Monitoring Service for each microservice, instrument latency metrics, configure per-service SLOs, and attach separate alerting policies. This enables precise SLIs per service and targeted alerts.\n\n## Why Other Options Are Wrong\n- A: A global SLO hides per-service performance differences and can miss service-specific regressions.\n- C: Log-based metrics alone do not provide structured SLI/SLO calculation or per-service alerting capabilities.\n- D: A single uptime check only covers availability, not latency or per-service SLOs.\n\n## Key Concepts\n- Cloud Monitoring Service, SLI, SLO\n- Per-service metrics in multi-service environments\n- Alerting policies and dashboards per service\n- GKE instrumentation and service-level visibility\n\n## Real-World Application\nTeams implement per-service SLOs for critical microservices, create dashboards showing latency distributions per service, and configure alerts that fire only for the affected service, reducing noise and speeding incident response.","diagram":null,"difficulty":"intermediate","tags":["GKE","Cloud Monitoring","OpenTelemetry","Prometheus","Kubernetes","SLI","SLO","GCP","certification-mcq","domain-weight-20"],"channel":"gcp-devops-engineer","subChannel":"service-monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:30:22.961Z","createdAt":"2026-01-12 13:30:23"},{"id":"gcp-devops-engineer-service-monitoring-1768224622960-1","question":"To detect cold starts in a serverless workload (Cloud Run / Cloud Functions) and ensure timely responses, which monitoring approach best captures latency distribution and cold-start duration?","answer":"[{\"id\":\"a\",\"text\":\"Use Cloud Monitoring metrics for serverless services including request_latency and enable Cloud Trace to detect cold starts\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on application logs alone to infer latency without metrics or traces\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use only uptime checks to measure latency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a third-party monitoring tool that is not integrated with Cloud Trace\",\"isCorrect\":false}]","explanation":"## Correct Answer\nLeverage Cloud Monitoring metrics for serverless latency (e.g., request_latency) and enable Cloud Trace to capture traces, which together reveal cold-start durations and overall latency distribution.\n\n## Why Other Options Are Wrong\n- B: Logs alone do not provide structured latency distributions or cold-start visibility.\n- C: Uptime checks measure availability, not latency or cold-start metrics.\n- D: External tools may not integrate with Cloud Trace, reducing visibility for Cloud-native serverless workloads.\n\n## Key Concepts\n- Cloud Monitoring metrics for serverless\n- Cloud Trace integration\n- Cold-start analysis\n- Latency distribution\n\n## Real-World Application\nOperations teams monitor latency spikes during traffic ramps and use traces to identify cold-start delays, enabling faster tuning of memory/shutdown settings or concurrency configurations.","diagram":null,"difficulty":"intermediate","tags":["Cloud Run","Cloud Functions","Cloud Monitoring","Cloud Trace","Kubernetes","OpenTelemetry","GCP","certification-mcq","domain-weight-20"],"channel":"gcp-devops-engineer","subChannel":"service-monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:30:23.491Z","createdAt":"2026-01-12 13:30:23"},{"id":"gcp-devops-engineer-service-monitoring-1768224622960-2","question":"Your GKE deployment spans multiple namespaces and services; you want to avoid alert fatigue by deduplicating alerts and routing incidents to the right on-call rotation. What approach should you take?","answer":"[{\"id\":\"a\",\"text\":\"Create a single global alerting policy for all metrics to simplify notifications\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create per-service alerting policies with consistent labels and a multi-channel notification setup, enabling incident routing and dedup across related conditions\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use only email alerts and avoid on-call schedules to minimize overhead\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely exclusively on logs-based alerts without metrics-based conditions\",\"isCorrect\":false}]","explanation":"## Correct Answer\nPer-service alerting policies with consistent labels and a centralized notification channel enable targeted routing and dedup across related conditions, reducing alert fatigue while preserving visibility.\n\n## Why Other Options Are Wrong\n- A: A single global policy increases noise and makes it hard to distinguish which service is affected.\n- C: Email-only alerts and no on-call rotation lead to slow response and missed issues.\n- D: Logs-based alerts without metrics can miss quantitative thresholds and cross-service correlations.\n\n## Key Concepts\n- Alert policy scoping and labeling\n- Incident routing and deduplication\n- Multi-channel notifications\n- Service-level visibility in a multi-namespace cluster\n\n## Real-World Application\nOn incident, the on-call engineer receives a concise, service-specific incident with context, enabling faster triage and resolution without sifting through unrelated alerts.","diagram":null,"difficulty":"intermediate","tags":["GKE","Cloud Monitoring","Kubernetes","Prometheus","Incident Management","OpenTelemetry","GCP","certification-mcq","domain-weight-20"],"channel":"gcp-devops-engineer","subChannel":"service-monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:30:24.030Z","createdAt":"2026-01-12 13:30:24"},{"id":"gcp-devops-engineer-service-monitoring-1768224622960-3","question":"To reliably monitor external dependencies (e.g., third-party APIs) from multiple regions, which monitoring approach provides visibility into both availability and latency across geographies?","answer":"[{\"id\":\"a\",\"text\":\"Rely on internal metrics only and assume external dependencies mirror internal behavior\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Cloud Monitoring uptime checks to poll external endpoints from multiple regions and attach them to a composite SLO for external dependencies\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use only logs from your service to infer external dependency failure\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a single synthetic check from a single region to represent global availability\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUtilize Cloud Monitoring uptime checks to poll external dependency endpoints from multiple regions and bind them to a composite SLO, giving visibility into regional availability and latency.\n\n## Why Other Options Are Wrong\n- A: Internal metrics cannot reflect external dependency health across regions.\n- C: Logs do not provide proactive, region-aware availability measurements for external calls.\n- D: A single-region check misses regional variations in availability and latency.\n\n## Key Concepts\n- Uptime checks for external endpoints\n- Multi-region monitoring\n- Service dependencies and SLOs\n- Proactive availability visibility\n\n## Real-World Application\nDuring outages, teams can verify if an external API is unreachable regionally or if latency deteriorates in specific geographies, enabling targeted remediation or failover planning.","diagram":null,"difficulty":"intermediate","tags":["GKE","Cloud Monitoring","Cloud Uptime Checks","External Dependencies","SLO","Multi-Region","GCP","certification-mcq","domain-weight-20"],"channel":"gcp-devops-engineer","subChannel":"service-monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:30:24.214Z","createdAt":"2026-01-12 13:30:24"},{"id":"gcp-devops-engineer-service-monitoring-1768224622960-4","question":"To minimize instrumentation effort across many services while gaining unified visibility, which setup is most appropriate for Cloud Monitoring using OpenTelemetry?","answer":"[{\"id\":\"a\",\"text\":\"Instrument each service with bespoke metrics manually and export them individually to Cloud Monitoring\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy an OpenTelemetry Collector in a centralized manner and configure automatic instrumentation/export to Cloud Monitoring for metrics and traces\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely solely on application logs and derive metrics post hoc\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a third-party agent that does not integrate with Cloud Monitoring\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUsing a centralized OpenTelemetry Collector with automatic instrumentation and exporting to Cloud Monitoring provides broad visibility with minimal per-service code changes.\n\n## Why Other Options Are Wrong\n- A: Manual per-service instrumentation is labor-intensive and error-prone, especially at scale.\n- C: Logs alone do not provide structured metrics or real-time dashboards.\n- D: Non-integrated third-party tools reduce visibility and complicate incident response.\n\n## Key Concepts\n- OpenTelemetry Collector architecture\n- Automatic instrumentation and exporters\n- Cloud Monitoring integration\n- Unified telemetry across services\n\n## Real-World Application\nA mid-to-large organization rolls out a centralized OTEL collector to standardize metrics and traces, reducing engineering toil while enabling consistent dashboards and alerting in Cloud Monitoring.","diagram":null,"difficulty":"intermediate","tags":["OpenTelemetry","Cloud Monitoring","GKE","Cloud Run","Kubernetes","Prometheus","GCP","certification-mcq","domain-weight-20"],"channel":"gcp-devops-engineer","subChannel":"service-monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:30:24.394Z","createdAt":"2026-01-12 13:30:24"},{"id":"gcp-devops-engineer-site-reliability-1768199630277-0","question":"Which approach best ensures alerting is meaningful and reduces noise when latency spikes occur in a microservices app deployed on GKE?","answer":"[{\"id\":\"a\",\"text\":\"Alert on the 99th percentile latency of a single service across all regions\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Define SLOs and alert on the burn rate of the error budget using an aggregated SLI across affected services\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Monitor CPU usage of pods and alert when it exceeds a fixed threshold\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Only alert when the entire system is unavailable\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because it ties alerts to user-facing reliability by using SLIs/SLOs and monitoring the error-budget burn rate across services, enabling timely, focused remediation.\n\n## Why Other Options Are Wrong\n- A: Per-service percentile latency can miss cross-service impact and may produce noisy alerts if not scoped properly.\n- C: CPU usage is a resource metric, not a direct reliability signal for end-user experience.\n- D: Waiting for a full outage ignores partial degradations that impact users.\n\n## Key Concepts\n- SLIs, SLOs, and error budgets\n- Burn rate-based alerting\n- Service-wide observability\n\n## Real-World Application\n- Use Cloud Monitoring to define SLIs for latency and error rate across services, configure alerting policies on burn rate, and trigger runbooks to rollback or scale resources when thresholds are breached.","diagram":null,"difficulty":"intermediate","tags":["GKE","Kubernetes","SRE","Cloud Monitoring","SLI","Terraform","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"site-reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:50.279Z","createdAt":"2026-01-12 06:33:50"},{"id":"gcp-devops-engineer-site-reliability-1768199630277-1","question":"You are releasing a critical microservice on GKE and want to roll out a new version to a small fraction of traffic for canary testing with automatic rollback if metrics degrade. Which approach should you choose?","answer":"[{\"id\":\"a\",\"text\":\"RollingUpdate with default maxSurge and maxUnavailable\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Canary deployment using a service mesh (for example Istio or Traffic Director) with traffic splitting and metrics-driven rollback\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Blue/Green deployment with manual switch after health checks\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Deploy to production with no canary or monitoring\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because a service mesh enables fine-grained traffic splitting for canary rollouts and allows automatic rollback based on defined metrics (latency, error rate).\n\n## Why Other Options Are Wrong\n- A: RollingUpdate does not natively support granular canary traffic percentages or automated rollback based on metrics.\n- C: Blue/Green can be safe but is less flexible for gradual exposure and automated rollback compared to a canary with a mesh.\n- D: Deploying to production without gates increases risk and does not meet canary safety criteria.\n\n## Key Concepts\n- Canary deployments\n- Traffic splitting via Istio/Traffic Director\n- Metrics-driven rollback\n\n## Real-World Application\n- Deploy new revision to 5â€“10% of traffic, monitor latency/error rate, and incrementally increase traffic or revert automatically if metrics exceed thresholds.","diagram":null,"difficulty":"intermediate","tags":["GKE","Istio","Traffic Director","SRE","Kubernetes","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"site-reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:51.060Z","createdAt":"2026-01-12 06:33:51"},{"id":"gcp-devops-engineer-site-reliability-1768199630277-2","question":"To achieve low RPO and automatic failover for a globally accessed application, which approach is recommended in GCP?","answer":"[{\"id\":\"a\",\"text\":\"Use a single-region database with nightly backups\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Cloud Spanner in multi-region configuration with synchronous replication and a global load balancer\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Cloud SQL with cross-region read replicas and manual failover\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Firestore in regional mode with failover to another region configured manually\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Cloud Spanner in multi-region mode provides globally distributed, strongly consistent data with automatic failover, delivering near-zero RPO and rapid recovery.\n\n## Why Other Options Are Wrong\n- A: Single-region DBs cannot meet global RPO requirements and rely on backups rather than live failover.\n- C: Cross-region read replicas in Cloud SQL are typically asynchronous and require manual failover, increasing RPO.\n- D: Firestore regional mode does not provide the same strong global consistency and automatic regional failover guarantees as Spanner for workloads requiring global distribution.\n\n## Key Concepts\n- Global distribution and multi-region replication\n- Automatic failover and low RPO\n- Global load balancing\n\n## Real-World Application\n- For a globally active app, deploy the primary database in Spanner multi-region with Cloud Load Balancing to route traffic across continents, ensuring uninterrupted access during regional outages.","diagram":null,"difficulty":"intermediate","tags":["GCP","Cloud Spanner","Global Load Balancer","SRE","Terraform","GKE","certification-mcq","domain-weight-23"],"channel":"gcp-devops-engineer","subChannel":"site-reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:51.611Z","createdAt":"2026-01-12 06:33:51"}],"subChannels":["build-delivery","service-monitoring","site-reliability"],"companies":[],"stats":{"total":11,"beginner":0,"intermediate":11,"advanced":0,"newThisWeek":11}}