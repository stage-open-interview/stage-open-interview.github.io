{"questions":[{"id":"q-1013","question":"You're managing a multi-tenant SaaS on GCP across five projects connected via Shared VPC. You must enforce per-tenant network isolation, IAM conditions, and budget governance while keeping CI/CD simple. Propose an end-to-end setup using Shared VPC, IAM Conditions, VPC Service Controls, Billing Budgets, and Cloud Asset Inventory, and outline testing and rollback steps?","answer":"Design a per-tenant isolation strategy: use Shared VPC, per-tenant IAM roles with conditional bindings, VPC Service Controls, and per-tenant budgets; implement CI/CD using Cloud Build to apply IaC (Te","explanation":"## Why This Is Asked\n\nThis question probes practical multi-tenant isolation, policy-as-code, and operational testing in GCP.\n\n## Key Concepts\n\n- Shared VPC and host projects\n- IAM Conditions for per-tenant access\n- VPC Service Controls for data exfil prevention\n- Billing Budgets and cost monitoring per tenant\n- Cloud Asset Inventory for drift detection\n- CI/CD with Terraform and Cloud Build\n- Policy-as-code (OPA) and guardrails\n\n## Code Example\n\n```javascript\n// sample budget per tenant\nresource \"google_billing_budget\" \"tenant_budget\" {\n  billing_account = var.billing_account_id\n  display_name    = \"tenant-${var.tenant_id}-budget\"\n\n  amount {\n    specified_amount {\n      currency_code = \"USD\"\n      units         = 1000\n    }\n  }\n\n  threshold_rules {\n    threshold_percent = 0.8\n    spend_basis       = \"CURRENT_SPEND\"\n  }\n\n  // optional fields omitted for brevity\n}\n```\n\n```javascript\n// per-tenant IAM condition (example)\nresource \"google_project_iam_member\" \"tenant_view\" {\n  project = var.tenant_project_id\n  role    = \"roles/viewer\"\n  member  = \"user:${var.user_email}\"\n  condition {\n    title       = \"tenant_is_owner\"\n    expression  = \"resource.name.startsWith('projects/${var.tenant_project_id}')\"\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you test drift between intended IAM bindings and actual bindings?  \n- How would you handle onboarding/offboarding tenants without disruptive outages?","diagram":"flowchart TD\n  A[Tenant Creation] --> B[Configure Shared VPC & IAM] \n  B --> C[Apply Budget & Guardrails] \n  C --> D[CI/CD Deployment] \n  D --> E[Monitoring & Auditing]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T19:27:58.378Z","createdAt":"2026-01-12T19:27:58.378Z"},{"id":"q-1041","question":"Design a scalable, compliant log routing pipeline on GCP that collects logs from Kubernetes clusters, Cloud Run, and Cloud Functions, redacts PII, and stores in BigQuery with environment separation. Include data flow sinks, IAM and CMEK governance, failure modes and retries, and an end-to-end testing plan?","answer":"Export logs from GKE, Cloud Run, and Cloud Functions via Cloud Logging Log Router to GCS per environment; run a Cloud Dataflow pipeline that uses the DLP API to redact PII and writes to a partitioned ","explanation":"Why This Is Asked: Assesses ability to design a compliant, scalable log pipeline across multiple services with data redaction and governance. Key trade-offs include latency vs. cost, code vs managed services, and testing rigor.","diagram":"flowchart TD\n  A[Logs: GKE/Cloud Run/Functions] --> B[Router Sink to GCS]\n  B --> C[Dataflow + DLP Redaction]\n  C --> D[BigQuery: env-specific]\n  D --> E[Access & Compliance]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T20:29:17.568Z","createdAt":"2026-01-12T20:29:17.568Z"},{"id":"q-1155","question":"You're deploying a globally distributed service on GKE across three regions, with Cloud Run and Cloud Functions used for specific workloads. Design a deployment pipeline that enforces policy-as-code, encryption at rest via CMEK, drift detection, automated rollback, and cross-region failover. Describe tooling, data planes, tests, and how you handle outages and compliance?","answer":"Use a GitOps approach with Cloud Deploy across all regions, anchoring policies in OPA (policy-as-code) and enforcing CMEK with IAM Conditions. Implement canary releases via traffic-splitting between G","explanation":"## Why This Is Asked\nAssesses real-world skills in GitOps, policy-as-code, cross-region DR, and automated rollback.\n\n## Key Concepts\n- GitOps and Cloud Deploy\n- Policy-as-code with OPA\n- CMEK and IAM Conditions\n- Canary traffic routing across GKE/Cloud Run\n- Drift detection and regional failover\n\n## Code Example\n```javascript\n// Pseudo-code: trigger a rollback if a metric breaches a threshold\nasync function maybeRollback(metrics) {\n  if (metrics.latency > 500 || metrics.errorRate > 0.02) {\n    await cloudDeploy.rollback();\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test drift detection across regions?\n- How do you simulate regional outages and verify failover?","diagram":"flowchart TD\nA[GitOps Repo] --> B[Cloud Deploy Pipeline]\nB --> C[Regions: us, eu, ap]\nC --> D[GKE/Cloud Run/Functions]\nD --> E[Drift Checks]\nE --> F{Status}\nF --> G[Rollback]\nF --> H[Continue]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T03:28:10.252Z","createdAt":"2026-01-13T03:28:10.252Z"},{"id":"q-1245","question":"You operate a global chat app with components on **GKE**, **Cloud Run**, and **Cloud Functions**. Latency spikes in one region go unnoticed in aggregated metrics. Design an end-to-end observability approach: (1) how to unify traces across runtimes, (2) how to instrument with **OpenTelemetry** and **OTLP** to a central collector, (3) how to build region-scoped dashboards and **SLO-based alerts**, and (4) how to validate during release with **canary** and **chaos testing**. Include tool choices, sample metrics, and a minimal config sketch?","answer":"Implement a unified OpenTelemetry pipeline across GKE, Cloud Run, and Cloud Functions, exporting traces via OTLP to a centralized collector and tagging spans with region, service, and version. Build r","explanation":"## Why This Is Asked\n\nTests the ability to design end-to-end observability across diverse runtimes, ensuring consistent tracing, metrics, and alerting. It also probes practical integration details with OpenTelemetry, OTLP, and regional dashboards, plus validation via canary and chaos testing.\n\n## Key Concepts\n\n- OpenTelemetry and OTLP exporters\n- End-to-end tracing across GKE, Cloud Run, Cloud Functions\n- Region-scoped dashboards and SLO-based alerts\n- Canary releases and chaos engineering validation\n\n## Code Example\n\n```javascript\n// Minimal OpenTelemetry setup sketch (Node.js)\nconst { NodeTracerProvider } = require('@opentelemetry/node');\nconst { SimpleSpanProcessor } = require('@opentelemetry/tracing');\n// ... configure OTLP exporter targeting central collector\n```\n\n## Follow-up Questions\n\n- How would you handle sampling decisions during traffic spikes?\n- How would you enforce consistent trace propagation across services?\n- What metrics would you expose to Cloud Monitoring for fast attribution of regional latency spikes?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T06:40:56.056Z","createdAt":"2026-01-13T06:40:56.056Z"},{"id":"q-1281","question":"You're maintaining a Cloud Run Python service that reads an API key from Secret Manager. Implement a 30-day secret rotation using Cloud Scheduler to publish a rotation event to Pub/Sub, and enable the Cloud Run instance to fetch updated secret without a restart. Detail the IAM permissions, wiring, and a test plan to verify end-to-end rotation?","answer":"Use a Cloud Run service account with roles/secretmanager.secretAccessor on the secret, and a rotation mechanism (Secret Manager secret with a rotation schedule). Schedule a Cloud Scheduler job to publ","explanation":"## Why This Is Asked\n\nTests practical secret management and runtime retrieval in GCP.\n\n## Key Concepts\n\n- Secret Manager rotation, Cloud Scheduler, Pub/Sub, Cloud Run IAM bindings, request-time secret fetch.\n\n## Code Example\n\n```javascript\n// Runtime fetch of Secret Manager secret in Cloud Run (Node.js)\nconst {SecretManagerServiceClient} = require('@google-cloud/secret-manager');\nconst client = new SecretManagerServiceClient();\nasync function getApiKey() {\n  const name = 'projects/PROJECT/secrets/API_KEY/versions/latest';\n  const [version] = await client.accessSecretVersion({name});\n  const apiKey = version.payload.data.toString('utf8');\n  return apiKey;\n}\n```\n\n## Follow-up Questions\n\n- How would you test failure of rotation propagation?\n- How would you handle secret versioning and rollback?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Plaid","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T08:28:58.600Z","createdAt":"2026-01-13T08:28:58.601Z"},{"id":"q-1514","question":"Design a cost-aware DR plan for a multi-region GKE + Cloud Run service handling 2M events/min. implement active-active with regional load balancers, Istio-based traffic shifting, CMEK, and a VPC Service Controls perimeter. automate failover tests via Cloud Build + Chaos Mesh; define SLOs and error budgets, observability, and automatic rollback triggers on latency/error breaches?","answer":"Active-active DR across two regions using regional load balancers and Istio routing; CMEK for all data stores; VPC Service Controls to bound data. Automate failover tests with Cloud Build + Chaos Mesh","explanation":"## Why This Is Asked\nEvaluates hands-on ability to design robust, cost-conscious DR for a hybrid GKE/Cloud Run stack across regions, including security (CMEK, VPC SC), traffic control (Istio), and reliable failure testing integrated into CI/CD.\n\n## Key Concepts\n- Active-active regional DR and traffic shifting\n- Istio/Anthos Service Mesh for cross-region routing\n- CMEK and VPC Service Controls for data protection\n- Chaos testing integration with Cloud Build and Chaos Mesh\n- SLOs, error budgets, observability, and automated rollback\n\n## Code Example\n```yaml\n# Cloud Build-style pseudo-config for triggering a failover test\nsteps:\n- name: gcr.io/cloud-builders/kubectl\n  args: [\"rollout\",\"restart\",\"deployment/my-service\"]\n- name: gcr.io/chaos-mesh/chaos-mesh\n  args: [\"apply\",\"-f\",\"chaosmesh/failover.yaml\"]\n```\n\n## Follow-up Questions\n- How do you quantify acceptable failover latency and error budgets across regions?\n- What are the key failure modes during regional failover and how would you mitigate data loss risks?\n- How would you validate security controls (CMEK, VPC SC) during automated tests?","diagram":"flowchart TD\n  A[Users/Events] --> B[US-East GKE]\n  A --> C[US-West Cloud Run]\n  B --> D[Ingestion/Processing]\n  C --> D\n  D --> E[Storages & Analytics]\n  E --> F[Cross-Region Backups & CMEK]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Hugging Face","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T19:50:16.997Z","createdAt":"2026-01-13T19:50:16.997Z"},{"id":"q-1664","question":"You’re tasked with enabling per-branch ephemeral environments in Google Cloud Platform for a microservice. Every feature branch should provision an isolated Cloud Run service, a dedicated Cloud SQL instance, and Secrets Manager entries, with least-privilege IAM, a per-branch namespace, and automatic teardown after 48 hours. Outline the exact steps using only GCP-native tools (no external CI), including budgets alerts, health checks, and teardown workflow?","answer":"Use per-branch isolated Cloud Run services and Cloud SQL instances provisioned by Cloud Build triggers on branch creation. Store credentials in Secret Manager; assign a dedicated service account with ","explanation":"## Why This Is Asked\nAssesses ability to design ephemeral, auditable environments using only GCP-native tools and least-privilege IAM. Encourages thinking about per-branch isolation, lifecycle management, and cost controls.\n\n## Key Concepts\n- Ephemeral environments per feature branch\n- Least privilege IAM and service accounts\n- Cloud Run and Cloud SQL provisioning\n- Secret Manager for credentials\n- Cloud Scheduler for teardown\n- Billing budgets and health checks\n\n## Code Example\n```javascript\n// Example deployment snippet (pseudo)\ngcloud run deploy ${BRANCH}-service --image gcr.io/$PROJECT/${REPO}:${BRANCH} --region us-central1 --platform managed\n```\n\n## Follow-up Questions\n- How would you adapt this if regional availability or quotas changed?\n- How would you test the 48-hour teardown to avoid data loss or orphaned resources?","diagram":"flowchart TD\n  A[Branch] --> B[Cloud Run service]\n  B --> C[Cloud SQL instance]\n  C --> D[Secret Manager entries]\n  D --> E[Teardown job]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:46:02.407Z","createdAt":"2026-01-14T05:46:02.407Z"},{"id":"q-1685","question":"You’re tasked with cost-aware deployment for a Cloud Run service used by a mobile frontend. Create a policy that (1) halts new deployments when the monthly spend exceeds a threshold, (2) scales traffic to 20% during overages, and (3) posts a Slack alert via a Cloud Function if the bill crosses the threshold. Describe exact steps using only GCP-native tools (Billing Budgets, Cloud Monitoring, Cloud Functions) and outline a minimal end-to-end workflow?","answer":"Configure Billing Budget with a monthly threshold; publish alerts to Pub/Sub; implement a Cloud Function that posts to Slack; integrate a gating step in CI (Cloud Build) that subscribes to the budget ","explanation":"## Why This Is Asked\nTests practical use of budgets, alerts, and automation to control deployments and alert on spend. It validates ability to design a self-contained, cloud-native workflow.\n\n## Key Concepts\n- Billing Budgets and alerts\n- Pub/Sub as event channel\n- Cloud Functions for webhook posting\n- Cloud Monitoring for alerting thresholds\n- Traffic splitting in Cloud Run or CI gating\n\n## Code Example\n```javascript\n// sample Cloud Function to post Slack webhook\nconst https = require('https');\nexports.postToSlack = (event, context) => {\n  const payload = JSON.stringify({ text: `Budget alert: ${event.data ? Buffer.from(event.data, 'base64').toString() : 'budget event' }`});\n  const req = https.request({ hostname: 'hooks.slack.com', path: '/services/...', method: 'POST', headers: {'Content-Type':'application/json'} }, res => { res.on('data', ()=>{}); });\n  req.write(payload);\n  req.end();\n};\n```\n\n## Follow-up Questions\n- How would you test this workflow end-to-end without incurring real charges?\n- How would you handle race conditions between spend spikes and deployment gates?","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:56:34.254Z","createdAt":"2026-01-14T06:56:34.254Z"},{"id":"q-1763","question":"You operate a large-scale IoT ingestion pipeline on GCP: millions of device events per minute flow from Pub/Sub into Dataflow (Apache Beam) and write to BigQuery. Design an architecture that guarantees near real-time processing with exactly-once semantics, handles late data, and supports schema evolution; include windowing, idempotent writes, backpressure, and a rollback/testing plan for Dataflow job updates. What would you implement and why?","answer":"Use a streaming Dataflow pipeline: Pub/Sub -> Dataflow (Beam) -> BigQuery. Guarantee exactly-once by deduplicating on a per-event_id using a per-key stateful DoFn and writing to a staging table, follo","explanation":"## Why This Is Asked\nTests a practical, end-to-end streaming pipeline with real-time constraints, data integrity, and operational resilience. It probes deduplication strategies, windowing decisions, schema evolution handling, and rollback plans.\n\n## Key Concepts\n- Streaming Dataflow and Apache Beam primitives\n- Exactly-once semantics via dedupe and staging tables\n- Windowing and late data handling\n- BigQuery upserts via MERGE and schema evolution\n- Pub/Sub ordering and dead-lettering\n\n## Code Example\n```python\nimport apache_beam as beam\n\nclass DedupDoFn(beam.DoFn):\n  def process(self, element, *args, **kwargs):\n    # simplistic per-event_id dedupe placeholder\n    yield element\n\nSCHEMA = {\n  'fields': [ {'name': 'device_id', 'type': 'STRING'}, {'name': 'value', 'type': 'FLOAT'}, {'name': 'event_id', 'type': 'STRING'} ]\n}\n\nwith beam.Pipeline(...) as p:\n  (p\n   | 'ReadPubSub' >> beam.io.ReadFromPubSub(...)\n   | 'Parse' >> beam.Map(lambda b: json.loads(b))\n   | 'Dedup' >> beam.ParDo(DedupDoFn())\n   | 'WriteStaging' >> beam.io.WriteToBigQuery('project:dataset.staging', schema=SCHEMA, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n  )\n```\n\n## Follow-up Questions\n- How would you monitor for schema drift and automate a safe deployment when the schema changes?\n- What rollback plan would you implement if the MERGE into the main table fails mid-flight?","diagram":"flowchart TD\n  A[Pub/Sub] --> B[Dataflow (Beam)]\n  B --> C[staging.BigQuery]\n  C --> D[main.BigQuery (MERGE)]\n  B --> E[Dead Letter (GCS)]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:48:18.586Z","createdAt":"2026-01-14T09:48:18.586Z"},{"id":"q-1819","question":"You manage a Cloud SQL PostgreSQL instance in GCP and need a reliable disaster-recovery workflow with automated daily backups to Cloud Storage. Explain how to implement this using Cloud Scheduler and a Cloud Function that calls the Cloud SQL Admin API to export to gs://my-backups/sql-dump-YYYYMMDD.sql. Include required IAM roles, bucket lifecycle policies, and how you would validate a restore?","answer":"Enable automated backups on the Cloud SQL instance and create a Cloud Storage bucket for exports. Create a Cloud Scheduler job that triggers a Cloud Function, which calls the Cloud SQL Admin API to ex","explanation":"## Why This Is Asked\nSituations demand reliable DR with minimal ops. This tests automation, GCP-native tooling, and safe access controls.\n\n## Key Concepts\n- Cloud SQL Admin API exports\n- Cloud Scheduler + Cloud Functions permissions\n- Cloud Storage bucket lifecycle and IAM least privilege\n- Restore validation and retention strategies\n\n## Code Example\n```javascript\n// Placeholder for Cloud Function exporting Cloud SQL via API (Node.js)\nconst {google} = require('googleapis');\n// build and call sqladmin.instances.export(...)\n```\n\n## Follow-up Questions\n- How would you test export idempotency and failure retries?\n- How would you enforce encryption keys and access controls for backups?","diagram":"flowchart TD\n  A[Cloud Scheduler Job] --> B[Cloud Function (export)]\n  B --> C[Cloud SQL Admin API]\n  C --> D[gs://my-backups/sql-dump-YYYYMMDD.sql]\n  D --> E[Lifecycle & Retention]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T11:52:41.229Z","createdAt":"2026-01-14T11:52:41.229Z"},{"id":"q-1890","question":"In a multi-tenant SaaS on GCP requiring isolated per-tenant networks with a shared services hub, propose a scalable hub-and-spoke topology using Shared VPC and Private Service Connect. Include least-privilege IAM, per-tenant firewall rules, and Private Google Access. How would you implement policy-as-code, drift detection, automated rollback, and observability across tenants?","answer":"Hub-and-spoke: a Shared VPC host for shared services, per-tenant service projects with isolated VPCs, and Private Service Connect to access authentication and telemetry. Enforce least-privilege IAM, p","explanation":"## Why This Is Asked\nThis question probes practical network design for multi-tenant environments on GCP, balancing isolation with shared services, and how to enforce policy-as-code and drift prevention in production.\n\n## Key Concepts\n- Hub-and-spoke with Shared VPC for central services\n- Private Service Connect and Private Google Access\n- Least-privilege IAM and per-tenant firewall controls\n- Policy-as-code (Terraform/Config Connector)\n- Drift detection (Cloud Asset Inventory, Config Connector)\n- Automated rollback (Cloud Deploy, GitOps)\n- Observability (Cloud Monitoring/Logging)\n\n## Code Example\n```javascript\n// Pseudo-terraform drift-check snippet (illustrative)\nconst desired = loadPlan('hub-per-tenant.yaml');\nconst actual = getCurrentState('tenant-a');\nif (diff(desired, actual)) {\n  triggerRollback();\n}\n```\n\n## Follow-up Questions\n- How would you onboard/offboard tenants at scale without downtime?\n- How would you prove isolation and drift coverage in a security audit?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:49:59.152Z","createdAt":"2026-01-14T15:49:59.152Z"},{"id":"q-1917","question":"Scenario: A Cloud Run service connects to a Cloud SQL instance. Secrets are stored in Cloud Secret Manager and injected into the container at runtime. Propose a beginner-friendly, low-risk, weekly password rotation workflow that updates the secret, triggers a rolling update with zero downtime, and provides an immutable audit trail. Include the exact GCP services you would use and a minimal 3-step sequence to implement?","answer":"Schedule a weekly Cloud Scheduler job to trigger a Cloud Function that generates a new password, updates the Cloud SQL user, and creates a new Secret Manager secret version. Then deploy a new Cloud Ru","explanation":"## Why This Is Asked\n\nTests understanding of secret rotation, zero-downtime deployments, and basic auditing in GCP.\n\n## Key Concepts\n\n- Secret Manager secret versioning and rotation\n- Cloud SQL user credential management\n- Rolling updates in Cloud Run\n- IAM least privilege and Audit Logs\n- Cloud Scheduler and Cloud Functions\n\n## Code Example\n\n```javascript\n// Example Cloud Function to rotate secret\nconst {SecretManagerServiceClient} = require('@google-cloud/secret-manager');\nconst client = new SecretManagerServiceClient();\nasync function rotateSecret(name, value){\n  const [version] = await client.addSecretVersion({ parent: name, payload: { data: Buffer.from(value) } });\n  return version;\n}\n```\n\n## Follow-up Questions\n\n- How would you test this rotation flow locally? \n- How would you implement a rollback if the new secret fails to be used by Cloud Run?","diagram":"flowchart TD\n  Scheduler[Cloud Scheduler] --> Function[Cloud Function]\n  Function --> SecretManager[Secret Manager: rotate secret]\n  SecretManager --> Run[Cloud Run revision]\n  Run --> Audit[Cloud Audit Logs]\n  Run --> Monitor[Cloud Monitoring]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:01:50.588Z","createdAt":"2026-01-14T17:01:50.588Z"},{"id":"q-2006","question":"You're delivering a multi-tenant SaaS on GKE and Cloud Run with strict data residency and cost controls. Design an end-to-end pattern using only GCP-native tools to achieve per-tenant isolation, regional data stores, Canary/blue-green deployment, CMEK, VPC Service Controls, and automated rollback on degraded telemetry. Outline architecture, steps, and essential config snippets?","answer":"Use per-tenant Kubernetes namespaces and IAM bindings; provision regional Cloud Spanner instances per tenant for data residency; create per-tenant BigQuery datasets; enforce network isolation with Pri","explanation":"## Why This Is Asked\nProbes real-world multi-tenant, data residency, and cost-governance challenges on GCP; tests architectural discipline and use of native tools.\n\n## Key Concepts\n- Multi-tenant isolation via per-tenant namespaces and identifiers\n- Regional data residency with Cloud Spanner and per-tenant BigQuery\n- Canary/blue-green rollout with Cloud Deploy and Traffic Director\n- CMEK, VPC Service Controls, Cloud Armor for security\n- Telemetry-driven rollback with Cloud Monitoring\n- Budget alerts and automated teardown on offboarding\n\n## Code Example\n```javascript\n// Delivery config hints (pseudo)\n{\n  // Cloud Deploy pipelines and traffic gates would be defined here in YAML-like structure\n}\n```\n\n## Follow-up Questions\n- How would you test data residency enforcement across regions?\n- How would you handle tenant onboarding/offboarding delays and retries?","diagram":null,"difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T20:42:58.109Z","createdAt":"2026-01-14T20:42:58.109Z"},{"id":"q-2054","question":"Design a beginner-friendly, GCP-native CI/CD for a Cloud Run service with a private artifact repository. Describe how you would: (a) configure Cloud Build to pull a private repo and push a container image to Artifact Registry, (b) inject a database password from Secret Manager into the Cloud Run container at runtime, and (c) rotate that secret monthly using Cloud Scheduler and a Cloud Function that updates Secret Manager. Include the specific services and minimal steps?","answer":"Configure a Cloud Build pipeline to pull from the private repository, build and push a container image to Artifact Registry, deploy to Cloud Run, and integrate Secret Manager for secure database password injection at runtime.","explanation":"## Why This Is Asked\nThis question evaluates practical knowledge of designing a beginner-friendly, GCP-native CI/CD pipeline that incorporates private repositories, containerized deployments, and secure secrets management with automated rotation.\n\n## Key Concepts\n- Cloud Build for CI/CD automation\n- Artifact Registry for private container storage\n- Secret Manager for secure credential management\n- Cloud Run for serverless container deployment\n- Cloud Scheduler for automated secret rotation\n- Cloud Functions for rotation logic execution\n- IAM least privilege principles\n- End-to-end secrets workflow\n\n## Code Example\n```yaml\n# Cloud Build pipeline: build and deploy\nsteps:\n- name: gcr.io/cloud-builders/docker\n  args: ['build', '-t', 'REGION-docker.pkg.dev/PROJECT/REPO/IMAGE:TAG', '.']\n- name: gcr.io/cloud-builders/gcloud\n  args: ['run', 'deploy', 'service', '--image', 'REGION-docker.pkg.dev/PROJECT/REPO/IMAGE:TAG', '--region', 'REGION', '--platform', 'managed']\n```","diagram":null,"difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:40:36.011Z","createdAt":"2026-01-14T22:42:35.098Z"},{"id":"q-2234","question":"Scenario: deploy a Cloud Run service private to a specific VPC using Private Service Connect. Detail the Google-native steps: create a Serverless VPC Access connector, set up a PSC endpoint, configure private DNS, restrict ingress to internal, grant a dedicated service account run.invoker, and validate access from a VM inside the VPC while public access is blocked. What is your minimal rollout plan and validation approach?","answer":"Create a VPC and a Serverless VPC Access connector; deploy Cloud Run with ingress=internal and attach the VPC connector; create a Private Service Connect endpoint in the VPC; configure a private DNS A","explanation":"## Why This Is Asked\nSecurity-focused deployments often require private access to serverless services. This tests understanding of VPCs, Private Service Connect, DNS, and IAM in a real workflow.\n\n## Key Concepts\n- Private Service Connect\n- Serverless VPC Access\n- Cloud Run ingress internal\n- Private DNS zones\n- IAM with least privilege\n\n## Code Example\n```javascript\n// Deploy private Cloud Run\ngcloud run deploy private-service \\\n  --image gcr.io/PROJECT/priv-service:tag \\\n  --region us-central1 \\\n  --ingress internal \\\n  --vpc-connector projects/PROJECT/locations/us-central1/connectors/serverless-vpc-connector\n```\n```javascript\n// PSC endpoint and DNS setup (illustrative)\ngcloud compute addresses create private-psc-endpoint --global\ngcloud dns managed-zones create private-zone --dns-name \"private.example.internal.\"\n```\n\n## Follow-up Questions\n- How would you rotate the PSC endpoint without downtime?\n- How would you audit access with IAM conditions and VPC firewall rules?","diagram":"flowchart TD\n  A[Cloud Run Private] --> B[PSC Endpoint]\n  B --> C[VPC]\n  C --> D[Private DNS]\n  D --> E[Service Clients]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Citadel","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T08:50:51.300Z","createdAt":"2026-01-15T08:50:51.300Z"},{"id":"q-2252","question":"How would you implement a secure, GCP-native deployment pipeline for a Cloud Run service that uses vulnerability scanning and Binary Authorization to ensure only signed, non-vulnerable images are deployed, including how you would integrate Cloud Build attestation and a guard policy?","answer":"Configure vulnerability scanning for images in Artifact Registry via Container Analysis, create a Binary Authorization attestor, and configure Cloud Build to sign images before pushing. Enforce a poli","explanation":"## Why This Is Asked\nGCP-native security, image provenance, and policy enforcement are foundational for safe deployments.\n\n## Key Concepts\n- Binary Authorization\n- Attestors\n- Container Analysis vulnerability scanning\n- Cloud Build signing and attestations\n- Artifact Registry policy integration\n\n## Code Example\n```javascript\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you test the end-to-end attestation flow in CI?\n- What happens if a CVE is found after deployment, and how would you roll back?","diagram":"flowchart TD\n  A[Source] --> B[Cloud Build]\n  B --> C[Artifact Registry]\n  C --> D[Vulnerability Scan (Container Analysis)]\n  D --> E[Attestation by Attestor]\n  E --> F[Binary Authorization Policy: allowlisted]\n  F --> G[Cloud Run]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:37:38.373Z","createdAt":"2026-01-15T09:37:38.373Z"},{"id":"q-2332","question":"Scenario: you must implement a real-time pricing and fraud-detection service on GCP that ingests from Pub/Sub, processes with Dataflow, and stores results in BigQuery across multiple regions. Design a production-ready pipeline with canary releases, strict IAM, CMEK, and automated recovery. Include deployment strategy, observability, and teardown plan?","answer":"Propose a streaming pipeline: Pub/Sub topic feeds a Dataflow streaming job that writes to two BigQuery datasets (RAW and ENRICHED) across three regions; Cloud Run API with canary deployments via Cloud","explanation":"## Why This Is Asked\nReal-world, multi-region streaming with canaries and strict security. Tests ability to design end-to-end pipelines, gating, and cost controls.\n\n## Key Concepts\n- Real-time ingestion via Pub/Sub and Dataflow streaming\n- Multi-region BigQuery datasets and CMEK governance\n- Canary deployments with Cloud Deploy and Shard isolation\n- Least-privilege IAM and VPC-SC considerations\n- Automated rollback, budget alerts, and ephemeral env teardown\n\n## Code Example\n```python\n# Dataflow skeleton (pseudo)\nfrom apache_beam.options.pipeline_options import PipelineOptions\nwith beam.Pipeline(options=PipelineOptions()) as p:\n  (p\n   | 'Read' >> beam.io.ReadFromPubSub(topic=topic)\n   | 'Parse' >> beam.Map(parse_fn)\n   | 'WriteRaw' >> beam.io.WriteToBigQuery(table=f'{project}:{raw_ds}.{raw_table}')\n   | 'Enrich' >> beam.ParDo(enrich_fn)\n   | 'WriteEnriched' >> beam.io.WriteToBigQuery(table=f'{project}:{enriched_ds}.{enriched_table}'))\n```\n\n## Follow-up Questions\n- How would you validate cross-region failover and data residency during incident drills?\n- What metrics and thresholds trigger rollback and how would you automate it?","diagram":"flowchart TD\n  PubSub[Pub/Sub Topic] --> Dataflow[Dataflow Streaming Job]\n  Dataflow --> BQRaw[BigQuery RAW dataset]\n  Dataflow --> BQEnrich[BigQuery ENRICHED dataset]\n  API[Cloud Run API] --> LB[Global Load Balancer]\n  LB --> Users[Users]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T13:08:12.540Z","createdAt":"2026-01-15T13:08:12.540Z"},{"id":"q-2347","question":"You're running a stateful service on GKE with a Cloud SQL primary in US-CENTRAL1 and a read replica in EUROPE-WEST1. Design an end-to-end deployment and DR strategy that (1) supports blue/green or canary rollouts with automatic rollback based on latency and error-rate gates, (2) enables cross-region failover for compute and DB, (3) enforces CMEK for storage and DB, (4) implements policy-as-code and drift detection, (5) includes observability, outage handling, and compliance. Specify tooling, data planes, tests, and failure handling?","answer":"Use Cloud Deploy with blue/green or canary releases, starting at 10% traffic and ramping if latency and error-rate gates pass. DR uses cross-region GKE failover and a Cloud SQL replica; Global Load Ba","explanation":"## Why This Is Asked\nAssesses how a candidate combines deployment strategies, DR planning, and enforcement of security/compliance in a real GCP setup.\n\n## Key Concepts\n- Blue/Green and canary deployments with automatic rollback gates\n- Cross-region DR for compute and database\n- CMEK encryption for storage and Cloud SQL\n- Policy-as-code and drift detection (Config Connector, OPA)\n- Observability, outage handling, and compliance\n\n## Code Example\n```javascript\n// Pseudo-code for SLO gate\nasync function canaryGate(metrics) {\n  const latencyOk = metrics.p95 < 200;\n  const errorOk = metrics.errorRate < 0.01;\n  return latencyOk && errorOk;\n}\n```\n\n## Follow-up Questions\n- How would you validate drift detection in CI/CD and ensure fast remediations?\n- What tests would you run to validate cross-region failover without customer-visible downtime?","diagram":"flowchart TD\n  A[Source Repo] --> B[CI/CD: Cloud Build]\n  B --> C[Deployment to GKE]\n  C --> D{Canary Gate}\n  D -->|Pass| E[Traffic Shift to New Revision]\n  D -->|Fail| F[Rollback to Previous Revision]\n  G[DR Prep] --> H[Cross-region DB Replica]\n  H --> I[Global LB Failover]\n  E --> J[Observability & Compliance]","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:36:44.022Z","createdAt":"2026-01-15T14:36:44.022Z"},{"id":"q-2383","question":"You're deploying a new Cloud Run service named text-classifier with a v2 revision. You want a 15% canary for 30 minutes and automatic rollback if latency exceeds 1.5s or error rate exceeds 0.5%. Using only GCP-native tools, specify exact steps to build/push v2 to Artifact Registry, split traffic, configure monitoring alerts, and trigger rollback via traffic changes, including minimal IAM requirements?","answer":"Build the v2 image with Cloud Build to Artifact Registry, deploy as revision v2, split 15% of traffic to v2 for 30 minutes, and monitor p95 latency (>1.5s) or error rate (>0.5%). If alert triggers, au","explanation":"## Why This Is Asked\nTests ability to design a controlled canary deployment using native GCP tools, with observable metrics and an automated rollback path suitable for beginner familiarity.\n\n## Key Concepts\n- Cloud Run revisions and traffic splitting\n- Artifact Registry and Cloud Build integration\n- Cloud Monitoring alerting and automatic rollback triggers\n- IAM roles for service accounts and deployments\n\n## Code Example\n```bash\n# Build v2 image\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/REPO/text-classifier:v2\n\n# Deploy v2 revision (partial traffic)\ngcloud run services update-traffic text-classifier --to-revisions text-classifier-v1=85,text-classifier-v2=15\n```\n\n## Follow-up Questions\n- How would you adjust the setup for a 60-minute canary with tighter latency targets?\n- What monitoring dashboards would you create to visualize canary health during the test?","diagram":"flowchart TD\n  A[Source Code] --> B[Build & Push to Artifact Registry]\n  B --> C[Deploy v1] \n  C --> D[Canary: v2 15%]\n  D --> E[Monitor p95 latency & error rate]\n  E -->|OK| F[Continue 30m]\n  E -->|Fail| G[Rollback to v1]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Hugging Face","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T15:47:09.141Z","createdAt":"2026-01-15T15:47:09.141Z"},{"id":"q-2398","question":"You're deploying a beginner-friendly Cloud Run service named text-processor. Using only GCP-native tools, design a minimal CI/CD: build and push the container to Artifact Registry, deploy v1 to Cloud Run, implement a simple traffic split (10% dev, 90% prod) for canary testing, require a manual gate before production via an additional Cloud Build trigger, and outline a rollback plan and minimal IAM?","answer":"Build and push to Artifact Registry, deploy v1 with a dev suffix, deploy v2 with a prod suffix, split traffic 10% to dev and 90% to prod, add a manual gate in Cloud Build before prod promotion, and ro","explanation":"## Why This Is Asked\nExplores practical, beginner-friendly use of Cloud Run traffic splitting, simple canary without external tooling, and a manual gate to simulate release approvals.\n\n## Key Concepts\n- Cloud Run traffic splitting with revision suffixes\n- Artifact Registry storage and image tagging\n- Cloud Build triggers and manual approval gates\n- Least-privilege IAM for automated deployments\n\n## Code Example\n```bash\ngcloud builds submit --tag us-central1-docker.pkg.dev/myproj/repo/text-processor:v1 .\ngcloud run deploy text-processor --image us-central1-docker.pkg.dev/myproj/repo/text-processor:v1 --region us-central1 --revision-suffix dev\n```\n\n## Follow-up Questions\n- How would you extend this to multi-region deployment?\n- How would you test the manual gate workflow before prod?","diagram":"flowchart TD\n  A[Code] --> B[Build → Artifact Registry]\n  B --> C[Deploy Dev (suffix: dev)]\n  B --> D[Deploy Prod (suffix: prod)]\n  C --> E[Traffic 10% Dev]\n  D --> F[Traffic 90% Prod]\n  E --> G[Gate→Prod]\n  F --> G\n","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T16:49:11.818Z","createdAt":"2026-01-15T16:49:11.818Z"},{"id":"q-2480","question":"You're running a high-traffic payment API **payline** on Cloud Run (v2) with multi-region active-active behind a Global HTTP(S) Load Balancer. Design a production deployment plan to roll out v3 with automatic rollback based on latency and error-rate metrics. Use only Google Cloud native tools. Specify: canary strategy (**5% for 15 minutes**), traffic-split commands, monitoring alerts, CMEK/Secrets Manager handling, IAM least privilege, and a rollback workflow across regions?","answer":"Build and push v3 to Artifact Registry, deploy to both regions, then update-traffic payline to v3 at 5% for 15 minutes and 95% v2. Create Cloud Monitoring alert for p95 latency >200ms or error rate >0","explanation":"## Why This Is Asked\nTests multi-region deploys, automated rollback, and security controls in a realistic PayTech scenario.\n\n## Key Concepts\n- Cloud Run revisions, traffic-splitting, global LB\n- Cloud Monitoring alerting and SLOs, auto-rollback\n- Secrets Manager, CMEK, IAM least privilege\n- Regional Cloud SQL with read replicas for DR\n\n## Code Example\n```javascript\n// Example commands (illustrative)\n// 1) build/push\n// gcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/REPO/payline:v3 .\n// 2) traffic split\n// gcloud run services update-traffic payline --to-revisions payline-v3=5,payline-v2=95 --region us-central1\n```\n\n## Follow-up Questions\n- How would you test the rollback workflow in staging?\n- How to handle secret rotation during active deployments?","diagram":"flowchart TD\n  Start[Start] --> Deploy[Deploy v3 to regions]\n  Deploy --> Canary[5% canary for 15m]\n  Canary --> Alert{Alerts trigger?}\n  Alert -- Yes --> Rollback[Rollback to v2]\n  Alert -- No --> Promote[Promote to 100%]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:42:00.576Z","createdAt":"2026-01-15T19:42:00.577Z"},{"id":"q-2642","question":"You're designing a streaming ingestion pipeline on GCP: Pub/Sub topic events.raw, Dataflow job events-ingest-v2 (streaming) writing to BigQuery.events_all. Using only Google-native tools, specify a concrete plan to meet: (1) exactly-once processing semantics; (2) 25% traffic canary for v2 with safe rollback; (3) malformed events go to a Dead-Letter topic; (4) automatic rollback to v1 if latency > 1.8s or error rate > 0.8% persists for 10 minutes; include monitoring, alerting, and a traffic-switching workflow that minimizes data loss?","answer":"Proposed plan: run v1 and v2 in parallel via two Pub/Sub subscriptions (hash-based routing to target 25% for v2). Dataflow streaming with a BigQuery sink providing exactly-once semantics; route malfor","explanation":"## Why This Is Asked\n\nRealistic scenario tests ability to design end-to-end streaming pipelines with canary, error handling, and rollback on GCP-native tools.\n\n## Key Concepts\n\n- Streaming Dataflow, Pub/Sub routing, BigQuery exactly-once\n- Dead-lettering, alerting, automatic rollback\n- Traffic-switching via publisher routing or subscriptions\n\n## Code Example\n\n```javascript\n// High-level snippet illustrating routing policy\nconst routing = (tenantId) => (hash(tenantId) % 4 === 0) ? 'v2' : 'v1';\n```\n\n## Follow-up Questions\n\n- How would you validate the rollback works under real latency spikes without impacting production?\n- Which data quality checks ensure no duplicates after rollback?","diagram":"flowchart TD\n  A[events.raw] --> B[Dataflow: events-ingest-v2]\n  B --> C[BigQuery: events_all]\n  A --> D[Dataflow: events-ingest-v1]\n  D --> C\n  E[Dead-letter topic] --> A","difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T04:24:52.943Z","createdAt":"2026-01-16T04:24:52.943Z"},{"id":"q-2677","question":"You're maintaining a small Cloud Run (fully managed) service named image-processor with a Git-driven CI; you want to enable per-branch deployments to isolated Cloud Run services (e.g., image-processor-dev, image-processor-staging, image-processor-prod) using only GCP-native tools. Outline concrete steps to build and push the container to Artifact Registry, deploy each environment with dedicated service accounts and IAM bindings, configure traffic routing so dev/staging canaries don't affect prod, implement a gating flow to promote from dev to staging to prod via Cloud Build triggers, and specify a rollback workflow if latency > 2s or error rate > 1% persists for 10 minutes. Include minimal Secrets Manager usage and monitoring setup?","answer":"Define three Cloud Run services: image-processor-dev, image-processor-staging, image-processor-prod. Build/push to Artifact Registry: gcloud builds submit --tag us-docker.pkg.dev/PROJECT/IMAGE/image:l","explanation":"## Why This Is Asked\nTests ability to design per-environment, per-branch deployments using GCP-native tools, with isolated resources, simple promotion gates, and a clear rollback workflow. It also evaluates IAM discipline and basic monitoring integration.\n\n## Key Concepts\n- Cloud Run service per environment to isolate code and traffic\n- Artifact Registry for image storage\n- Cloud Build triggers for gate-based promotions\n- Traffic splitting via update-traffic for controlled rollouts\n- Service accounts with least privilege IAM\n- Secret management with Secret Manager\n- Cloud Monitoring for latency/error alerts and rollback signals\n\n## Code Example\n```bash\n# Build and push (dev example)\ngcloud builds submit --tag us-docker.pkg.dev/PROJECT/IMAGE/image:dev-latest\n\n# Deploy dev service with a dedicated SA\ngcloud run deploy image-processor-dev --image us-docker.pkg.dev/PROJECT/IMAGE/image:dev-latest \\\n  --region us-central1 --service-account dev-sa@PROJECT.iam.gserviceaccount.com --platform managed --allow-unauthenticated\n\n# Traffic routing: 10% to dev, 90% to prod\ngcloud run services update-traffic image-processor-prod --to-latest\n```\n\n## Follow-up Questions\n- How would you automate cleanup of old branch deployments?\n- How would you enforce a policy that prevents prod traffic from drifting without a gate?","diagram":"flowchart TD\n  A[Git Branch] --> B[Build + Push to Artifact Registry]\n  B --> C[Deploy env: dev/staging/prod]\n  C --> D[Traffic split: canary + prod]\n  D --> E{Monitoring Alert}\n  E -->|latency/err| F[Rollback to prod]\n  E -->|ok| G[Promote to next env via Cloud Build trigger]","difficulty":"beginner","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Snap","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T06:50:31.148Z","createdAt":"2026-01-16T06:50:31.148Z"},{"id":"q-877","question":"Design a cross-region disaster recovery plan for a streaming data pipeline on GCP (Pub/Sub, Dataflow, BigQuery) that must survive a regional outage with RTO < 15 minutes and RPO < 5 minutes. The primary region is us-central1; second region is us-east1. Include data paths, failover triggers, data integrity guarantees, and operational testing steps?","answer":"Active-active DR: run identical streaming pipelines in us-central1 and us-east1. Publish to regional Pub/Sub with cross-region replication; Dataflow in each region writes to separate, schema-stable Bi","explanation":"## Why This Is Asked\nTests ability to design DR for streaming pipelines across regions, focusing on data integrity, operational testing, and real-world failover trade-offs.\n\n## Key Concepts\n- Active-active cross-region DR patterns\n- Pub/Sub regional replication strategies\n- Dataflow multi-region pipelines and idempotent sinks\n- BigQuery datasets per region with consistent schemas\n- Cloud SQL regional replicas for metadata\n- Global load balancer + DNS failover for traffic steering\n\n## Code Example\n```python\nclass DedupDoFn(beam.DoFn):\n  def process(self, element, window=beam.DoFn.WindowParam,\n              state=beam.DoFn.StateParam):\n    uid = element.get('id')\n    if not state.read():\n      state.write(True)\n      yield element\n```\n\n## Follow-up Questions\n- How would you validate RTO/RPO with drills without impacting production?\n- How would you handle schema drift and ensure backward compatibility across regions?","diagram":"flowchart TD\n  A[Ingest] --> B[Regional Pub/Sub] \n  B --> C[Dataflow (us-central1)] \n  B --> D[Dataflow (us-east1)] \n  C --> E[BigQuery (us-central1)] \n  D --> F[BigQuery (us-east1)] \n  G[Outage Detected] --> H[Failover to Healthy Region] \n  H --> I[DNS + LB Route]","difficulty":"advanced","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:57:17.903Z","createdAt":"2026-01-12T13:57:17.903Z"},{"id":"q-921","question":"In a multi-tenant GKE deployment across two GCP projects, you must enforce strict per-tenant network isolation and controlled egress to external services. Design a scalable architecture using Shared VPC, Private Service Connect, and per-tenant firewall policies to ensure tenants only reach whitelisted external endpoints, while preventing cross-tenant access. Include identity management, auditing, drift control, and operational notes for adding new tenants?","answer":"Propose a Shared VPC with per-tenant subnets, PSA endpoints for approved SaaS services, deny-by-default firewall rules, per-tenant IAM bindings, and VPC Service Controls for data exfil. Use Cloud Logg","explanation":"## Why This Is Asked\nTests practical VPC, PSA, and IAM patterns for multi-tenant isolation; covers governance and onboarding.\n\n## Key Concepts\n- Shared VPC\n- Private Service Connect\n- VPC Service Controls\n- Per-tenant firewalls\n- Drift detection and automations\n\n## Code Example\n```hcl\n# Terraform example: create per-tenant subnets and firewall rules\nresource \"\"google_compute_network\"\" \"tenant_shared_vpc\" {\n  name                    = \"shared-vpc-demo\"\n  auto_create_subnetworks = false\n}\n```\n\n## Follow-up Questions\n- How would you onboard a new tenant with zero-downtime networking changes?\n- How would you test the isolation and whitelisting in a staging environment?","diagram":null,"difficulty":"intermediate","tags":["gcp-devops-engineer"],"channel":"gcp-devops-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T15:32:32.583Z","createdAt":"2026-01-12T15:32:32.583Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Citadel","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","OpenAI","PayPal","Plaid","Robinhood","Scale Ai","Snap","Snowflake","Square","Stripe","Tesla","Two Sigma","Zoom"],"stats":{"total":25,"beginner":11,"intermediate":8,"advanced":6,"newThisWeek":25}}