{"questions":[{"id":"q-1004","question":"Scenario: A serverless API stack (API Gateway, Lambda, DynamoDB, S3, CloudFront) runs in us-east-1 with a DR region eu-west-1. Propose an automated DR plan using AWS Global Accelerator and Route 53 health checks to failover within 15 minutes. Include data replication choices, Lambda versioning strategy, S3 replication mode, and a safe rollback/verification approach that avoids production impact during tests?","answer":"Implement with AWS Global Accelerator exposing endpoint groups in us-east-1 and eu-west-1, backed by Route 53 health checks to flip traffic to DR within 15 minutes. Use Lambda aliases with canary prom","explanation":"## Why This Is Asked\nTests practical DR planning for serverless stacks, emphasizing automation, data replication choices, and safe testing.\n\n## Key Concepts\n- AWS Global Accelerator and multi-region endpoints\n- Route 53 health checks and failover routing\n- Lambda versioning and canary deployments\n- DynamoDB Global Tables and S3 cross-region replication\n- Canary DR testing and rollback workflows\n\n## Code Example\n```javascript\n// Promote DR version by updating Route53/alias configuration (illustrative)\nimport { Route53Client, ChangeResourceRecordSetsCommand } from '@aws-sdk/client-route-53';\n\nconst client = new Route53Client({region: 'us-east-1'});\nasync function failover() {\n  // Upsert DR-records to route traffic to DR region\n  await client.send(new ChangeResourceRecordSetsCommand({/* ... */}));\n}\n```\n\n## Follow-up Questions\n- How would you validate read/write integrity after failover?\n- What metrics and alarms ensure timely detection and safe rollback?","diagram":null,"difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:49:55.875Z","createdAt":"2026-01-12T18:49:55.875Z"},{"id":"q-1291","question":"In a 12-account AWS Organization, you must implement near real-time central audit logging for VPC Flow Logs, Lambda logs, and RDS logs in a dedicated Logging account. Design the end-to-end mechanism to ship logs from all member accounts to the central account, ensuring secure cross-account access, encryption, and resilience across Regions. What is your approach?","answer":"Design a centralized Logging account for all CloudWatch Logs (VPC Flow Log, Lambda, RDS) from 12 member accounts using CloudWatch Logs subscriptions to a Kinesis Data Firehose in the central account. ","explanation":"## Why This Is Asked\nTests ability to design cross-account log centralization with real-time data flow, security controls, and disaster recovery. Demonstrates practical use of CloudWatch Logs subscriptions, cross-account roles, and Kinesis Firehose in a scalable multi-account setup.\n\n## Key Concepts\n- Cross-account IAM roles and trust policies for log producers\n- CloudWatch Logs subscriptions as a transport to a central sink\n- Kinesis Data Firehose as the delivery path to S3 (encrypted with a central KMS key)\n- Central data lake with proper retention, access controls, and lifecycle\n- Regional resilience via multi-region delivery or replication\n\n## Code Example\n```javascript\n// Pseudo-CDK-like snippet for cross-account log delivery to Firehose\nconst role = new iam.Role(this, 'CWLogsToFirehose', {\n  assumedBy: new iam.AccountPrincipal('CENTRAL_ACCOUNT_ID')\n});\nrole.addToPolicy(new iam.PolicyStatement({\n  actions: ['firehose:PutRecord', 'firehose:PutRecordBatch'],\n  resources: [firehose.attrArn]\n}));\n```\n\n## Follow-up Questions\n- How would you validate coverage and detect delivery failures across accounts?\n- What changes would you make to handle a new region or account being added?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Salesforce","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T08:35:57.950Z","createdAt":"2026-01-13T08:35:57.950Z"},{"id":"q-1481","question":"In a multi-account AWS Organization for a global SaaS app, mandate data residency: S3 buckets and DynamoDB tables used by customer data must not store or replicate data outside the designated region per account. Design an automated governance solution using SCPs, AWS Config, IAM Roles, EventBridge, and Lambda to enforce this, with testing and alerting?","answer":"Implement per-account guardrails: SCPs deny any S3/DynamoDB write or replication to non-designated regions; AWS Config custom rules audit region compliance across services; EventBridge captures drift ","explanation":"## Why This Is Asked\n\nTests knowledge of cross-account governance, data residency constraints, and automation at scale. It probes how to translate policy into enforceable controls and how to validate effectiveness.\n\n## Key Concepts\n\n- AWS Organizations SCPs\n- AWS Config custom rules and remediation\n- IAM Roles and cross-account access\n- EventBridge for event-driven governance\n- Lambda remediation and data movement\n\n## Code Example\n\n```python\nimport boto3\n\ndef is_in_designated_region(bucket_arn, target_region):\n    s3 = boto3.client('s3')\n    bucket = bucket_arn.split(':')[-1]\n    loc = s3.get_bucket_location(Bucket=bucket).get('LocationConstraint') or 'us-east-1'\n    return loc == target_region\n```\n\n## Follow-up Questions\n\n- How would you test across all accounts without affecting production data?\n- What are potential race conditions with cross-region replication and eventual consistency?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T18:54:11.477Z","createdAt":"2026-01-13T18:54:11.477Z"},{"id":"q-1536","question":"Design a DR orchestration for a global app with primary S3 (with Object Lock) and DynamoDB in us-east-1 and a DR site in us-west-2. Require 15 min RTO and 5 min RPO, data residency, automated backups via AWS Backup, cross-region replication that respects residency, and Route 53 failover. Describe a Step Functions workflow to automate failover, validation, and rollback without production impact, with testing cadence and success criteria?","answer":"Design a Step Functions–driven DR orchestration with AWS Backup vaults in us-east-1 and us-west-2 for S3 and DynamoDB; implement S3 cross-region replication with Object Lock and bucket versioning; utilize DynamoDB Global Tables or PITR; configure Route 53 failover routing with health checks; establish automated failback and rollback procedures.","explanation":"## Why This Is Asked\nThis tests practical cross-region DR orchestration with data residency constraints and non-disruptive testing capabilities.\n\n## Key Concepts\n- AWS Backup vaults per region with restoration windows\n- S3 Object Lock, cross-region replication, and versioning\n- DynamoDB backups vs Global Tables and PITR\n- Route 53 failover routing and health checks\n- Step Functions for end-to-end DR workflow automation and rollback\n\n## Code Example\n```json\n{\n  \"Comment\": \"DR workflow\",\n  \"StartAt\": \"PreFlight\",\n  \"States\": {\n    \"PreFlight\": { \"Type\": \"Task\", \"Next\": \"Backup\" },\n    \"Backup\": { \"Type\": \"Task\", \"Next\": \"Validation\" },\n    \"Validation\": { \"Type\": \"Task\", \"Next\": \"Failover\" },\n    \"Failover\": { \"Type\": \"Task\", \"Next\": \"PostFailoverCheck\" },\n    \"PostFailoverCheck\": { \"Type\": \"Task\", \"Next\": \"Success\" },\n    \"Success\": { \"Type\": \"Succeed\" }\n  }\n}\n```\n\n## Testing Cadence\n- Monthly DR drills with non-disruptive testing\n- Quarterly full failover validation\n- Weekly health check verification\n\n## Success Criteria\n- RTO ≤ 15 minutes, RPO ≤ 5 minutes\n- Zero data loss with Object Lock compliance\n- Automated rollback within 10 minutes\n- Health check response time < 30 seconds","diagram":"flowchart TD\n  A[Primary region us-east-1] -->|data residency check| B{DR eligible?}\n  B -->|Yes| C[Trigger DR in us-west-2]\n  C --> D[Route 53 DNS switch]\n  B --> E[Continue in primary if not]\n","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Hashicorp","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:33:50.831Z","createdAt":"2026-01-13T20:52:52.321Z"},{"id":"q-1542","question":"In a three-account AWS Organization (prod, staging, dev) for a global SaaS app, enforce cost governance by requiring that all new resources carry the tags Owner and Environment in prod, with automated remediation for noncompliant resources and separate budgets/alerts per account. Design an end-to-end process using SCPs, AWS Config rules, EventBridge, Lambda, and AWS Budgets to detect, remediate, and alert. Include testing steps?","answer":"Policy: Implement an SCP requiring Owner and Environment tags for all production resources. Deploy AWS Config rules to detect missing tags on EC2, S3, and RDS resources. Configure EventBridge to trigger Lambda functions that automatically apply missing tags—using Owner from a lookup table (defaulting to 'unassigned') and Environment derived from account context. Establish separate AWS Budgets per account with alerts at 80% and 100% thresholds. Noncompliant resources persisting beyond 24 hours are flagged for manual review.","explanation":"## Why This Is Asked\nTests practical governance implementation using cross-account controls, automated remediation, and comprehensive cost visibility.\n\n## Key Concepts\n- AWS Organizations SCPs for tag enforcement across production accounts\n- AWS Config custom rules for continuous tag compliance monitoring\n- EventBridge for routing noncompliance events to remediation workflows\n- Lambda functions for automated tag application and resource remediation\n- AWS Budgets with per-account alerts for proactive cost governance\n\n## Code Example\n```javascript\nconst AWS = require('aws-sdk');\nconst ec2 = new AWS.EC2();\n\nasync function tagResource(arn, tags) {\n  await ec2.createTags({\n    Resources: [arn],\n    Tags: Object.entries(tags).map(([k, v]) => ({ Key: k, Value: v }))\n  });\n}\n```","diagram":"flowchart TD\n  A[Policy (SCP)] --> B[AWS Config Rule]\n  B --> C[EventBridge]\n  C --> D[Lambda remediation]\n  D --> E[Budgets/Alerts]","difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","DoorDash","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:32:03.298Z","createdAt":"2026-01-13T21:30:58.393Z"},{"id":"q-1591","question":"In a multi-account AWS Organization hosting a global service, a misconfigured VPC peering or transit gateway leaks a route to the internet, risking data exposure and egress costs. Design an automated, end-to-end remediation and validation workflow (detection, isolation, rollback) using AWS Config and Config Rules, EventBridge, Lambda, IAM roles, and CloudWatch alarms, plus a controlled traffic test before rollback. What steps and artifacts would you implement?","answer":"The remediation workflow employs a Config custom rule to detect unintended 0.0.0.0/0 routes on VPCs or leaking transit gateway attachments. Upon detection, a Lambda function with least-privilege access removes the leaking route, detaches problematic transit gateway attachments, and updates route tables to route traffic through private endpoints. The workflow includes validation via controlled traffic testing before rollback, with CloudWatch alarms monitoring for continued leaks.","explanation":"## Why This Is Asked\nTests automated containment and rollback capabilities for network leaks at scale across multiple AWS accounts and regions.\n\n## Key Concepts\n- AWS Config rules and automated remediation\n- VPC route tables, Internet Gateways, and Transit Gateways\n- EventBridge, Lambda, and IAM least privilege\n- Canary testing and safe rollback strategies\n- Service Control Policies (SCPs) to harden cross-account controls\n\n## Code Example\n```python\n# Pseudo remediation outline\ndef remediation(event, context):\n    vpc_id = extract_vpc(event)\n    remove_leaking_route(vpc_id)\n    detach_transit_gateway_attachments(vpc_id)\n    update_route_tables(vpc_id)\n    validate_remediation(vpc_id)\n```","diagram":"flowchart TD\n  A[Detect leak] --> B[Isolate VPC and remove leaking route]\n  B --> C[Route to private subnet/NAT]\n  C --> D[Canary test]\n  D -- success --> E[Keep changes]\n  D -- fail --> F[Rollback to last good config]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Instacart","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:35:11.138Z","createdAt":"2026-01-13T22:56:15.361Z"},{"id":"q-1634","question":"How would you implement a guardrail so every new EC2 instance in a single AWS account for a mobile backend launches only in Prod-Subnet, carries Owner and Environment tags, and uses IAM role MobileBackendRole, with automated remediation and alerts via AWS Config, Lambda, EventBridge, and SNS while providing a testing plan?","answer":"Use an AWS Config Custom Rule to verify that each new EC2 instance is launched in Prod-Subnet, has tags Owner and Environment, and assumes IAM role MobileBackendRole. A Lambda remediation tags missing","explanation":"## Why This Is Asked\nTests guardrail automation basics for beginners; uses Config rules, Lambda remediation, EventBridge, SNS; ensures remediation and alerting.\n\n## Key Concepts\n- AWS Config Custom Rule\n- Lambda remediation\n- IAM roles and resource tagging\n- Subnet scoping\n- EventBridge and SNS integration\n\n## Code Example\n```javascript\n// Lambda remediation skeleton\nexports.handler = async (event) => {\n  // parse Config rule evaluation result\n  // attach missing tags or stop instance\n  return;\n}\n```\n\n## Follow-up Questions\n- How would you extend to multiple subnets or regions?\n- How would you handle resources in flight?\n- How would you reduce false positives and test coverage?","diagram":"flowchart TD\n  A[Launch Event] --> B[AWS Config Rule]\n  B --> C{Compliant?}\n  C -- Yes --> D[No Action]\n  C -- No --> E[Lambda Remediation]\n  E --> F[SNS Alert]","difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:20:04.577Z","createdAt":"2026-01-14T04:20:04.577Z"},{"id":"q-1672","question":"Across a three-account AWS Org (prod, staging, dev) hosting a Databricks-powered data lake on S3, design an automated end-to-end remediation to ensure all compute resources access S3 only via VPC Endpoints, enforce private DNS, and block public S3 access. Include SCPs, AWS Config rules, EventBridge, Lambda, and GuardDuty findings with testing steps and rollback?","answer":"Enforce S3 VPCE-only access across accounts. Use SCPs to require VPCE usage, Config rules to flag public buckets, and EventBridge/Lambda to apply SourceVpce conditions and BlockPublicAccess. Tie findi","explanation":"## Why This Is Asked\n\nTests governance and automation for cross-account data lakes. Requires practical use of SCPs, Config, EventBridge, Lambda, and GuardDuty, plus testing and rollback strategies.\n\n## Key Concepts\n\n- SCPs and least privilege\n- AWS Config rules (custom or managed)\n- VPC Endpoints and SourceVpce conditions\n- S3 Block Public Access & bucket policies\n- EventBridge-driven remediation\n- GuardDuty findings integration\n\n## Code Example\n\n```javascript\n// Example: not provided; governance policy appears in IAM and bucket policy snippets in docs\n```\n\n## Follow-up Questions\n\n- How would you test this in a multi-region Databricks deployment?\n- How do you handle exceptions for shared data buckets?","diagram":"flowchart TD\n  A[Compute Resources] --> B[S3 Access Route: VPCE]\n  B --> C[S3 Bucket Policy: SourceVpce]\n  C --> D[BlockPublicAccess Enabled]\n  E[AWS Config + SCP] --> F[Remediation via EventBridge]\n  F --> G[GuardDuty/CloudWatch Alerts]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:58:44.344Z","createdAt":"2026-01-14T05:58:44.345Z"},{"id":"q-1765","question":"Within a multi-account AWS environment across six regions hosting a critical financial service, implement automated detection and remediation of IAM role trust policy misconfigurations that could expose cross-account access. Use AWS Config, Lambda, EventBridge, IAM Access Analyzer, and SCPs in a central Governance account. Outline controls, testing, and rollback?","answer":"Detect and remediate cross-account trust misconfig via a central Config rule that flags IAM Role AssumeRole policies granting principals outside allowed accounts; feed IAM Access Analyzer findings; tr","explanation":"## Why This Is Asked\nTests ability to design cross-account IAM governance with automated remediation and testing.\n\n## Key Concepts\n- IAM trust policy analysis; Access Analyzer; Config rules\n- Event-driven remediation; Lambda automation\n- SCPs; centralized auditing; rollback planning\n\n## Code Example\n```javascript\n// Pseudo: list roles and check trust policy\nconst AWS = require('aws-sdk');\nconst iam = new AWS.IAM();\n\nasync function findCrossAccountRoles() {\n  const roles = await iam.listRoles().promise();\n  const risky = roles.Roles.filter(r => {\n     const policy = JSON.parse(r.AssumeRolePolicyDocument || '{}');\n     const statements = policy.Statement || [];\n     return statements.some(s => s.Principal && s.Principal.AWS && !s.Principal.AWS.startsWith('arn:aws:iam::' + YOUR_ACCOUNT_ID));\n  });\n  return risky;\n}\n```\n\n## Follow-up Questions\n- How would you avoid false positives for legitimate cross-account roles used by partners?\n- How would you test this in a canary or pilot account without affecting production?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Goldman Sachs","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:49:25.368Z","createdAt":"2026-01-14T09:49:25.368Z"},{"id":"q-1886","question":"In a 3-account AWS Organization (prod, staging, dev) for a global SaaS app, enforce a global IAM password policy across all accounts: min length 14, require uppercase, lowercase, number, symbol, password age 90 days, and forbid reuse of last 5. Design an end-to-end automation using SCPs, an AWS Config custom rule, EventBridge, Lambda, and AWS Budgets to detect drift, remediate, and alert. Include testing steps?","answer":"Implement a centralized policy in a master account. Use an SCP to prevent downgrades of password policy, a Config custom rule that calls GetAccountPasswordPolicy to validate all accounts, and a Lambda","explanation":"## Why This Is Asked\nTests ability to design automated governance for IAM password policies across a multi-account org with basic tooling.\n\n## Key Concepts\n- IAM password policy and enforcement across accounts\n- AWS Config custom rules for drift detection\n- Lambda remediation patterns\n- Service Control Policies (SCPs) for guardrails\n- AWS Budgets for cost awareness\n\n## Code Example\n```python\nimport boto3\ndef handler(event, context):\n    iam = boto3.client('iam')\n    iam.update_account_password_policy(\n        MinimumPasswordLength=14,\n        RequireSymbols=True,\n        RequireNumbers=True,\n        RequireUppercaseCharacters=True,\n        RequireLowercaseCharacters=True,\n        PasswordReusePrevention=5,\n        MaxPasswordAge=90\n    )\n```\n\n## Follow-up Questions\n- How would you handle exceptions for service accounts that cannot meet policy?\n- How would you test disaster recovery if policy drift cannot be remediated automatically?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:46:32.526Z","createdAt":"2026-01-14T15:46:32.526Z"},{"id":"q-1934","question":"In a 5-account, multi-region AWS setup (prod, prod-sec, staging, dev, shared) spanning 3 regions, design an automated disaster recovery plan for a critical app running on **EKS** and **RDS**. The DR must auto‑failover **RDS** to cross‑region replicas, switch **Route 53** DNS, re‑sync **EKS** state with **ArgoCD**, rotate encryption keys, and enforce **SCPs** for DR accounts. Include testing, rollback, and post‑drill validation?","answer":"Plan: Trigger a DR workflow via EventBridge and Step Functions. Promote cross-region RDS replicas to primary, switch Route 53 DNS failover to DR region, re-sync EKS state with ArgoCD to a DR cluster, ","explanation":"## Why This Is Asked\nTests multi-account, multi-region DR engineering under real-world constraints with automation, guardrails, and validation.\n\n## Key Concepts\n- Cross-region DR orchestration with EventBridge and Step Functions\n- RDS cross-region replica promotion and failover behavior\n- Route 53 DNS failover and health checks across regions\n- EKS state synchronization via ArgoCD in DR context\n- KMS key rotation and backup integrity under DR\n- IAM guardrails via SCPs and drift detection with AWS Config\n\n## Code Example\n```json\n{\n  \"Comment\": \"DR state machine skeleton\",\n  \"StartAt\": \"PromoteDRRDS\",\n  \"States\": {\n    \"PromoteDRRDS\": {\"Type\":\"Task\",\"Resource\":\"arn:aws:lambda:REGION:ACCOUNT:function:PromoteDRRDS\"},\n    \"FailoverDNS\": {\"Type\":\"Task\",\"Resource\":\"arn:aws:lambda:REGION:ACCOUNT:function:FailoverDNS\"}\n  }\n}\n```\n\n## Follow-up Questions\n- How would you verify DR readiness and measure RTO/RPO?\n- What drill failure modes would you simulate and why?","diagram":"flowchart TD\n  A[DR Trigger] --> B[DR State Machine]\n  B --> C[RDS Promote]\n  B --> D[DNS Failover]\n  B --> E[EKS ArgoCD Sync]\n  B --> F[Key Rotation]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:47:58.636Z","createdAt":"2026-01-14T17:47:58.636Z"},{"id":"q-1949","question":"In a 3-account AWS Organization (prod, staging, dev) for a global SaaS app, configure automatic idle-instance remediation. If an EC2 instance in prod has the tag AutoStop=true and CPUUtilization < 5% for 24h, stop it at 02:00 local time. Use AWS Config to detect noncompliance, EventBridge/Lambda to stop, and a Config rule to enforce tag presence. Include testing steps?","answer":"Detect prod EC2s with AutoStop=true and avg CPU <5% over 24h via a Config rule; schedule a nightly EventBridge at 02:00 local to trigger a Lambda that stops those instances. Gate with an IAM role perm","explanation":"## Why This Is Asked\nThis tests practical automation of cost control via server idle detection and cross-account governance, using Config, EventBridge, and Lambda with policy constraints.\n\n## Key Concepts\n- AWS Config rules and compliance state\n- EventBridge scheduling and Lambda remediations\n- EC2 CPU metrics and idle-detection patterns\n- IAM, SCPs, cross-account governance\n- Testing and observability\n\n## Code Example\n```python\nimport boto3\n# Pseudo: identify instances with tag AutoStop and low CPU, then stop them\n```\n\n## Follow-up Questions\n- How would you avoid stopping workloads that occasionally spike?\n- How would you test rollback if a stopped instance regains load?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:46:15.080Z","createdAt":"2026-01-14T18:46:15.080Z"},{"id":"q-2009","question":"In a single-region AWS setup hosting a small SaaS app, design a weekly automated DR test that validates restoring an RDS snapshot and at least one EBS volume, then runs a basic end-to-end check against the app. Outline practical steps using AWS Config, EventBridge, Lambda, and a separate DR bucket/account for test artifacts, including rollback steps and how you verify success?","answer":"Propose a weekly DR test pipeline in one region: schedule with EventBridge rule to trigger a Lambda that (1) creates an RDS snapshot and EBS volume snapshot; (2) copies snapshots to a DR S3 bucket or ","explanation":"## Why This Is Asked\n\nTests DR automation in a realistic, beginner-friendly context, focusing on end-to-end orchestration, cross-account artifacts, and visible validation without heavy complexity.\n\n## Key Concepts\n\n- Event-driven orchestration with EventBridge and Lambda\n- Snapshot management for RDS and EBS\n- Cross-account or isolated DR artifact storage\n- Basic health checks and rollback planning\n\n## Code Example\n\n```javascript\n// Minimal Lambda skeleton for DR test orchestration\nexports.handler = async () => {\n  // 1) createRDSnapshot, 2) snapshotEBSVolume, 3) copyArtifactsToDR, 4) restoreInDR, 5) runHealthCheck\n  return {status: 'DR test started'}\n}\n```\n\n## Follow-up Questions\n\n- How would you verify idempotence of the DR test?\n- What metrics and alerts would you configure for PASS/FAIL?\n","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hashicorp","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T20:47:09.139Z","createdAt":"2026-01-14T20:47:09.139Z"},{"id":"q-2046","question":"In a multi-region AWS deployment (prod across 4 regions) with accounts prod, security, infra, and audit, design an automated containment workflow triggered by GuardDuty findings of UnauthorizedAccess or PrivilegeEscalation. Automatically quarantine affected EC2s by swapping in a deny-all security group and routing traffic to a quarantine subnet, while persisting original SGs for rollback. Restoration requires security approval. Include cross-region EventBridge routing, Lambda orchestration, IAM permissions, rollback, and testing?","answer":"GuardDuty findings publish to EventBridge in the security account. A cross-account Lambda quarantines the EC2 by swapping to a deny-all security group and moving it to a quarantine subnet, storing the original security group configuration in SSM Parameter Store for rollback.","explanation":"## Why This Is Asked\n\nAssesses practical, scalable containment automation across accounts and regions with governance controls.\n\n## Key Concepts\n\n- GuardDuty to EventBridge integration across accounts\n- Cross-account Lambda orchestration with least privilege\n- Rapid network isolation via deny-all security group and quarantine subnet routing\n- Rollback capability using SSM Parameter Store (original security groups)\n- Approved restoration workflow (SNS or Systems Manager Automation)\n\n## Code Example\n\n```javascript\n// Skeleton containment handler\nexports.handler = async (event) => {\n  // parse GuardDuty finding\n  const finding = event.detail;\n  if (finding.type !== 'UnauthorizedAccess' && \n      finding.type !== 'PrivilegeEscalation') {\n    return;\n  }\n  \n  // extract EC2 instance details\n  const instanceId = finding.resource.instanceDetails.instanceId;\n  const region = finding.resource.region;\n  \n  // store original security groups for rollback\n  const ec2 = new AWS.EC2({ region });\n  const originalSGs = await ec2.describeInstances({\n    InstanceIds: [instanceId]\n  }).promise();\n  \n  // persist to SSM Parameter Store\n  await new AWS.SSM().putParameter({\n    Name: `/quarantine/${instanceId}/original-sgs`,\n    Value: JSON.stringify(originalSGs),\n    Type: 'String',\n    Overwrite: true\n  }).promise();\n  \n  // apply deny-all security group and quarantine subnet\n  await ec2.modifyInstanceAttribute({\n    InstanceId: instanceId,\n    Groups: ['sg-deny-all']\n  }).promise();\n  \n  // notify security team\n  await new AWS.SNS().publish({\n    TopicArn: process.env.SECURITY_TOPIC_ARN,\n    Message: JSON.stringify({\n      instanceId,\n      findingType: finding.type,\n      action: 'quarantined',\n      timestamp: new Date().toISOString()\n    })\n  }).promise();\n};\n```","diagram":"flowchart TD\n  GD[GuardDuty Finding] --> EB[EventBridge Rule]\n  EB --> L[Containment Lambda]\n  L --> SG[Update SG to DenyAll]\n  L --> Q[Quarantine Subnet Route]\n  SG --> Rb[Rollback Data in SSM]\n  Q --> Rb\n  Rb --> A[Await Restore Approval]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Meta","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:07:35.908Z","createdAt":"2026-01-14T22:31:13.452Z"},{"id":"q-2136","question":"In a 3-account AWS Organization (prod, staging, dev) for a global SaaS app, enforce a secure S3 baseline in prod: no public access, SSE-KMS with a central CMK, and versioning enabled on all buckets. Use AWS Config rules (e.g., s3-bucket-public-access-prohibited, s3-bucket-server-side-encryption-enabled, s3-bucket-versioning-enabled), EventBridge, Lambda, and SCPs to detect, remediate, and alert. Include testing steps and rollback plan?","answer":"Define a prod baseline with Config rules for public access, encryption, and versioning; trigger a Lambda remediation via EventBridge to block public access, attach CMK-based SSE, and enable versioning","explanation":"## Why This Is Asked\n\nTests practical guardrails, cross-account enforcement, and hands-on use of AWS Config, EventBridge, Lambda, and SCPs to maintain a secure baseline.\n\n## Key Concepts\n\n- AWS Config managed rules for S3 posture\n- EventBridge-Lambda remediation\n- S3 SSE-KMS using central CMK\n- Versioning and bucket policy impact\n- Service Control Policies for drift prevention\n\n## Code Example\n\n```python\n# Placeholder remediation logic sketch\ndef remediate_bucket(bucket_name):\n    enable_versioning(bucket_name)\n    apply_sse_kms(bucket_name, 'arn:aws:kms:...:cmk')\n    block_public_access(bucket_name)\n```\n\n## Follow-up Questions\n\n- How would you test cross-account drift and rollback scenarios?\n- How would you adapt for buckets owned by third-party accounts?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:18:13.152Z","createdAt":"2026-01-15T04:18:13.152Z"},{"id":"q-2196","question":"In a 4-account Organization across 3 regions hosting a real-time analytics stack (Kinesis Data Streams, S3 data lake, DynamoDB Global Tables), design an automated DR test and remediation plan that validates cross-region replication, IAM role trust policies, and automated failover with minimal downtime. Include tooling (AWS Config rules, EventBridge, Lambda, SSM Automation), rollback strategy, and testing steps?","answer":"Design a DR runbook using AWS Config to validate cross-region replication (DynamoDB Global Tables, S3), with an EventBridge trigger invoking a Lambda that runs an SSM Automation document to switch end","explanation":"## Why This Is Asked\nTests practical, scalable DR planning across accounts/regions with native AWS tooling and automated rollback.\n\n## Key Concepts\n- Automated DR testing across accounts/regions\n- AWS Config, EventBridge, Lambda, SSM Automation\n- DynamoDB Global Tables, S3 replication, endpoints\n- Rollback strategies and DR metrics\n\n## Code Example\n```javascript\n// Pseudo-implementation sketch for cutover\nconst cutover = async () => {\n  // disable primary region ingress\n  // enable secondary region endpoints\n  // validate replication lag < threshold\n};\n```\n\n## Follow-up Questions\n- How would you test the rollback triggers and ensure no data loss? \n- What metrics would you collect to meet RPO/RTO targets?","diagram":"flowchart TD\n  A[DR Trigger] --> B[Validate Replication]\n  B --> C{Healthy?}\n  C -->|Yes| D[Switch Endpoints to DR Region]\n  C -->|No| E[Abort & Notify]\n  D --> F[Run Synthetic Checks]\n  F --> G[Rollback if Needed]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T07:03:48.463Z","createdAt":"2026-01-15T07:03:48.463Z"},{"id":"q-2241","question":"In a multi-account, multi-region production setup hosting a real-time analytics microservice, design an automated DR failover/fallback that shifts traffic to a hot standby region within 5 minutes of regional outage while preserving data consistency. Specify the wiring of Route 53 failover, AWS Global Accelerator, DynamoDB global tables, S3 cross-region replication, and IAM boundaries, plus orchestration via Step Functions/Lambda, post-failover checks, testing, and rollback?","answer":"Propose a DR framework with 2 regions (primary and hot-standby) using Route 53 failover routing, AWS Global Accelerator, and two DynamoDB global tables; S3 cross-region replication for assets; per-acc","explanation":"## Why This Is Asked\n\nAssesses advanced DR design across multiple AWS services, cross-account governance, data consistency, testing rigor, and rollback plans under real-world constraints.\n\n## Key Concepts\n\n- Route 53 failover routing and health checks\n- AWS Global Accelerator for fast global routing\n- DynamoDB global tables for cross-region writes\n- S3 cross-region replication for assets\n- IAM boundary policies and per-region KMS keys\n- Step Functions / Lambda for orchestration and playbooks\n- DR testing, rollback, and cost controls\n\n## Code Example\n\n```javascript\n// Minimal Step Functions skeleton for DR orchestration (pseudo-structure)\n{\n  \"Comment\": \"DR failover workflow\",\n  \"StartAt\": \"HealthCheck\",\n  \"States\": {\n    \"HealthCheck\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:REGION:ACCOUNT:function:HealthCheck\",\n      \"Next\": \"Evaluate\"\n    },\n    \"Evaluate\": {\n      \"Type\": \"Choice\",\n      \"Choices\": [\n        { \"Variable\": \"$.outage\", \"BooleanEquals\": true, \"Next\": \"InitiateFailover\" }\n      ],\n      \"Default\": \"Done\"\n    },\n    \"InitiateFailover\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::aws-sdk:route53:changeResourceRecordSets\",\n      \"End\": true\n    },\n    \"Done\": { \"Type\": \"Succeed\" }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you validate RTO/RPO during a simulated outage without impacting customers?\n- What metrics and alarms would you attach to the DR workflow to ensure timely detection and rollback readiness?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Hashicorp","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T08:59:43.906Z","createdAt":"2026-01-15T08:59:43.907Z"},{"id":"q-2323","question":"Beginner scenario: A SaaS app stores per-tenant data in a single S3 bucket and serves tenants from a shared app tier. Design a cost- and security-friendly, auditable isolation model using per-tenant S3 Access Points and IAM roles, plus an Org SCP to prevent cross-account bucket listing. Outline required policies, Access Point config, testing, and rollback steps?","answer":"Use per-tenant S3 Access Points and per-tenant IAM roles to limit access to their own data, with a single bucket. Enforce an Org SCP that blocks ListBucket on the bucket from non-member accounts. Prov","explanation":"## Why This Is Asked\nTests knowledge of tenant isolation mechanisms in S3 using Access Points and granular IAM roles, plus organizational governance via SCPs. It also checks practical testing and rollback planning.\n\n## Key Concepts\n- S3 Access Points and per-tenant isolation\n- IAM roles with least privilege\n- Organization SCPs and cross-account boundaries\n- Testing isolation and rollback strategies\n\n## Code Example\n```javascript\n// Per-tenant role policy (conceptual)\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:GetObject\"],\n      \"Resource\": [\"arn:aws:s3:::tenant-data-bucket/tenants/tenantA/*\"]\n    }\n  ]\n}\n```\n\n```javascript\n// Access Point policy (conceptual)\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"AWS\": \"arn:aws:iam::123456789012:role/TenantAAccessRole\"},\n      \"Action\": [\"s3:GetObject\"],\n      \"Resource\": [\"arn:aws:s3:us-east-1:123456789012:accesspoint/tenantA-ap/*\"]\n    }\n  ]\n}\n```\n\n## Follow-up Questions\n- How would you scale this to 100+ tenants without exploding policy management?\n- What are trade-offs of centralizing data in one bucket vs per-tenant buckets?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T11:53:55.515Z","createdAt":"2026-01-15T11:53:55.515Z"},{"id":"q-2359","question":"Single-region web app on EC2 behind an Application Load Balancer experiences daily traffic spikes. Outline a beginner-friendly Auto Scaling setup using a Launch Template, an ASG with Target Tracking on CPU, a CloudWatch alarm, and ALB health checks. Include how you would test scaling in and out and rollback if metrics misbehave?","answer":"Create a Launch Template with the app AMI and a simple user-data startup; ASG with min 2, max 20, desired 2; Target Tracking policy on CPU 50% with 300s cooldown; ALB health checks enabled; CloudWatch","explanation":"## Why This Is Asked\n\nAssesses ability to translate beginner concepts into a concrete AWS setup, focusing on practical wiring of Launch Templates, ASGs, Target Tracking, CloudWatch alarms, and health checks, plus testing and rollback.\n\n## Key Concepts\n\n- Launch Templates vs Launch Configs\n- Auto Scaling Groups with Target Tracking\n- CloudWatch alarms and evaluation periods\n- Application Load Balancer health checks\n- Safe rollback strategies\n\n## Code Example\n\n```yaml\n# ASG/Launch Template snippet (illustrative)\nLaunchTemplate:\n  Name: MyAppLT\n  Data:\n    ImageId: ami-0abcdef123456\n    InstanceType: t3.medium\n    UserData: |\n      #!/bin/bash\n      yum update -y\n      systemctl start myapp\n```\n\n## Follow-up Questions\n\n- How would you handle longer startup times or flaky health checks?\n- What are limits and costs to consider when scaling rapidly?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Hugging Face","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:47:18.302Z","createdAt":"2026-01-15T14:47:18.303Z"},{"id":"q-2576","question":"In a two-region real-time trading data platform, design an automated security incident response workflow triggered by a GuardDuty finding that an EC2 is compromised. Outline the end-to-end flow: finding → EventBridge → Lambda to (a) attach a restrictive security group, (b) snapshot/quarantine EBS volumes, (c) pause real-time Kinesis streams, (d) copy forensic data to a dedicated S3 bucket, (e) alert on-call via SNS. Include rollback, cross-region considerations, and a test plan?","answer":"Design an automated security incident response workflow for a two-region real-time trading data platform triggered by a GuardDuty EC2 compromise finding. The end-to-end flow begins with GuardDuty generating a high-severity finding that routes through EventBridge to invoke a central Lambda orchestrator. The Lambda executes five critical containment actions: (1) immediately applies a restrictive security group blocking all traffic except necessary security operations, (2) creates EBS snapshots of all attached volumes and detaches them to a quarantine availability zone, (3) pauses real-time Kinesis data streams to prevent data exfiltration while preserving in-flight records, (4) copies forensic artifacts including memory dumps, logs, and network captures to a dedicated S3 bucket with cross-region replication, and (5) alerts on-call security teams via SNS with detailed incident context. The workflow includes comprehensive rollback procedures to restore normal operations after investigation, with cross-region considerations encompassing active-active failover, data consistency validation, and regional coordination to ensure comprehensive containment while maintaining trading platform availability.","explanation":"## Why This Is Asked\nTests hands-on incident response automation across AWS services, emphasizing idempotence, cross-region containment, and auditability under time pressure.\n\n## Key Concepts\n- GuardDuty findings, EventBridge routing, Lambda orchestration\n- IAM least privilege and cross-account roles\n- EBS snapshots, volume quarantine, and forensics data collection\n- Real-time data streams (Kinesis) pause/resume mechanics\n- S3 data retention policies and cross-region replication\n- SNS alerting and rollback procedures\n\n## Code Example\n```python\n# Lambda handler sketch (high-level)\nimport json\nimport boto3\nfrom datetime import datetime\n\ndef lambda_handler(event, context):\n    # Parse GuardDuty finding\n    finding = event['detail']\n    instance_id = finding['resource']['instanceDetails']['instanceId']\n    \n    # Initialize AWS clients\n    ec2 = boto3.client('ec2')\n    kinesis = boto3.client('kinesis')\n    s3 = boto3.client('s3')\n    sns = boto3.client('sns')\n    \n    # Execute containment actions\n    apply_restrictive_sg(instance_id)\n    quarantine_ebs_volumes(instance_id)\n    pause_kinesis_streams()\n    copy_forensics_data(instance_id)\n    alert_security_team(finding)\n    \n    return {'status': 'containment initiated'}\n```","diagram":"flowchart TD\n  A[GuardDuty Finding] --> B[EventBridge Rule]\n  B --> C[Lambda: Isolate EC2]\n  C --> D[Attach restrictive SG]\n  C --> E[Snapshot EBS volumes]\n  C --> F[Pause Kinesis streams]\n  C --> G[Copy forensics to S3]\n  C --> H[SNS alert to on-call]\n  D --> I[Rollback path]\n  E --> J[Cross-region replication]\n  F --> K[Resume after containment]\n  G --> L[Audit log + retention]\n  H --> M[Post-incident review]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:16:09.850Z","createdAt":"2026-01-15T23:37:18.175Z"},{"id":"q-2597","question":"In a three-account, multi-region AWS setup (prod, security, shared) spanning two regions, design an automated S3 governance workflow: require production buckets to enable default encryption with a CMK, block public access, and enforce versioning, with centralized cross-account access controls. Outline an end-to-end solution using AWS Config custom rules, Lambda remediation, EventBridge alerts, and Organizations SCPs; include testing steps and rollback?","answer":"I would implement a Config aggregator across accounts to detect buckets missing KMS encryption, public access blocks, or versioning. A Lambda remediation function will apply encryption with a CMK, block public access, and enable versioning automatically. EventBridge will centralize alerts, while Organizations SCPs enforce preventive controls across all accounts. The solution includes comprehensive testing and rollback procedures.","explanation":"## Why This Is Asked\nThis tests cross-account governance automation, real-world policy enforcement, and robust testing/rollback capabilities in complex AWS environments.\n\n## Key Concepts\n- AWS Config custom rules across multiple accounts\n- Lambda-based remediation for S3 bucket properties\n- EventBridge for centralized alerts\n- Organizations SCPs for policy enforcement\n- Multi-region, multi-account orchestration\n\n## Code Example\n```python\nimport boto3\nfrom botocore.exceptions import ClientError\n\ndef remediate(bucket, region):\n    s3 = boto3.client('s3', region_name=region)\n    kms = boto3.client('kms')\n    # Enable encryption with CMK```","diagram":null,"difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:04:18.776Z","createdAt":"2026-01-16T02:26:39.982Z"},{"id":"q-2645","question":"Across a 6-account AWS Organization (prod, staging, dev) spanning three regions, design an automated cross-account S3 security posture that blocks public access and enforces encryption at rest for all buckets. Include automated remediation, drift detection, and rollback using AWS Config, Lambda, EventBridge, IAM Access Analyzer, and SCPs. How would you test and verify?","answer":"I would implement a centralized governance fabric to enforce S3 security across accounts. Use Config rules to require PublicAccessBlock and SSE-KMS on all buckets, plus Access Analyzer to flag risky p","explanation":"## Why This Is Asked\n\nAssessment of practical security posture automation across multiple accounts/regions.\n\n## Key Concepts\n\n- AWS Config rules for S3 public access and encryption\n- AWS Access Analyzer for policy risk\n- EventBridge/Lambda remediation\n- Service Control Policies\n- Drift testing and rollback strategies\n\n## Code Example\n\n```javascript\n// Pseudo remediation snippet for S3 bucket\nfunction remediateBucket(bucket) {\n  // enforce PublicAccessBlock and SSE-KMS\n}\n```\n\n## Follow-up Questions\n\n- How would you scale this to additional regions or accounts?\n- How would you handle legitimate exemptions without weakening posture?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","LinkedIn","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T04:26:48.457Z","createdAt":"2026-01-16T04:26:48.457Z"},{"id":"q-2652","question":"Across six AWS accounts in three regions, design a centralized, immutable audit-log pipeline: have all accounts deliver CloudTrail, VPC Flow Logs, and Config logs to a single S3 bucket in an Audit account with Object Lock (Compliance) for 7 years; enforce encryption via a shared KMS CMK and SCPs; use EventBridge and Lambda for delivery health checks and auto-remediation; outline validation, testing, and rollback?","answer":"Implement a centralized audit-log pipeline: every account delivers CloudTrail, VPC Flow Logs, and Config logs to a single S3 bucket in an Audit account via cross-account delivery; enable S3 Object Loc","explanation":"## Why This Is Asked\nAssesss ability to design cross-account governance, immutable logs, and automated remediation in large AWS footprints. The candidate should justify cross-account delivery, object locking, encryption, and monitoring.\n\n## Key Concepts\n- Centralized log sink, cross-account delivery, S3 Object Lock; AWS KMS CMK; SCPs; CloudTrail/VPC Flow Logs/Config; EventBridge/Lambda for health checks.\n- Testing strategy: staging accounts, dry-run delivery, drift detection, rollback.\n\n## Code Example\n```json\n{\n  \"BucketPolicy\": {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"cloudtrail.amazonaws.com\"},\"Action\": \"s3:PutObject\",\"Resource\": \"arn:aws:s3:::audit-logs-bucket/*\"}\n    ]\n  }\n}\n```\n\n## Follow-up Questions\n- How would you validate cross-region delivery latency? \n- How would you handle CMK rotation and SCP exceptions during outages?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:39:12.539Z","createdAt":"2026-01-16T05:39:12.539Z"},{"id":"q-2676","question":"In a single AWS account hosting a regional web app, require that every new resource carries Owner and Environment tags; propose an end-to-end remediation flow using AWS Config Custom Rules, Lambda remediation, EventBridge, and SNS alerts. How would you test it, and what rollback steps would you include? Provide a minimal CloudFormation snippet for the Config rule and remediation Lambda, please?","answer":"Use an AWS Config Custom Rule named require-owner-env-tags backed by a remediation Lambda that adds missing Owner/Environment tags without overwriting existing values. Trigger alerts via SNS and surfa","explanation":"## Why This Is Asked\n\nTests ability to design automated governance with Config and Lambda, ensuring tag hygiene with safe remediation and observable alerts.\n\n## Key Concepts\n\n- AWS Config Custom Rules for evaluating tag presence\n- Lambda remediation that is idempotent and non-destructive\n- EventBridge for event routing and automation triggers\n- SNS for real-time alerts; CloudFormation for repeatable deployment\n\n## Code Example\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  RequireTagsConfigRule:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      Source:\n        Owner: CUSTOM_LAMBDA\n        SourceIdentifier: !GetAtt RemediateTagsLambda.Arn\n      InputParameters: '{\"RequiredTagKeys\":[\"Owner\",\"Environment\"]}'\n      ConfigRuleState: ACTIVE\n\n  RemediateTagsLambda:\n    Type: AWS::Lambda::Function\n    Properties:\n      Runtime: nodejs18.x\n      Handler: index.handler\n      Role: arn:aws:iam::123456789012:role/ConfigRemediationRole\n      Code:\n        ZipFile: |\n          exports.handler = async (event) => {\n            // remediation logic to tag missing keys\n          }\n```\n\n## Follow-up Questions\n\n- How would you handle new resource types with different tagging semantics?\n- How to ensure permissions least privilege for the remediation Lambda?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T06:48:58.546Z","createdAt":"2026-01-16T06:48:58.546Z"},{"id":"q-2718","question":"In a 3-region, multi-account SaaS deployment, enforce customer data locality so S3 data stays in the region defined by each customer and is not replicated cross-region unless explicitly approved. Design an automated policy engine using AWS Config custom rules, EventBridge, Lambda, and SCPs to prevent unauthorized replication, enforce region-bound KMS keys, and route alerts to a centralized security sink. Include testing and rollback steps with a simulated cross-region copy attempt?","answer":"Propose per-customer region tagging and a policy store; Config custom rules validate bucket replication against policy; EventBridge triggers Lambda remediation to remove unauthorized replication and a","explanation":"## Why This Is Asked\nTests ability to implement data locality governance in a real multi-region, multi-account context, with policy enforcement and automated remediation.\n\n## Key Concepts\n- AWS Config custom rules, EventBridge, Lambda, SCPs, KMS, CloudWatch/SNS\n- Data locality, cross-region replication controls, policy store\n- Testing/rollback strategies and auditability\n\n## Code Example\n```python\n# Pseudo AWS Config custom rule handler\ndef evaluate_config(config_item, policy_store):\n    bucket = config_item['resourceId']\n    region = config_item['awsRegion']\n    allowed = policy_store.is_allowed(bucket, region)\n    return {'compliance_type': 'COMPLIANT' if allowed else 'NON_COMPLIANT'}\n```\n\n## Follow-up Questions\n- How would you scale the policy store for thousands of customers?\n- How to test failure modes and ensure no data leakage during rollout?","diagram":"flowchart TD\n  A[Customer Policy] --> B[AWS Config Rule]\n  B --> C[EventBridge]\n  C --> D[Lambda Remediation]\n  D --> E[SCP Enforcement]\n  D --> F[Alerts & Audit]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Cloudflare","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T07:50:44.753Z","createdAt":"2026-01-16T07:50:44.753Z"},{"id":"q-2905","question":"Design a lightweight log aggregation pipeline for a single-region AWS deployment (EC2 behind ALB, RDS) that ships application logs and VPC flow logs to a centralized S3 bucket, with structured naming, encryption, and a 30-day retention policy. Include how CloudWatch Logs, Kinesis Data Firehose, and Lambda would be wired, how to monitor for unusual spikes, and basic testing steps?","answer":"Use CloudWatch Logs groups for app and VPC flow logs, route to a Kinesis Data Firehose delivery stream that writes to a central SSE-S3 encrypted S3 bucket. Apply a 30-day lifecycle to move data to Gla","explanation":"## Why This Is Asked\nTests knowledge of basic log ingestion, data protection, lifecycle, and alerting in a constrained environment. It validates practical wiring between CloudWatch, Firehose, and S3, plus basic testing steps.\n\n## Key Concepts\n- CloudWatch Logs\n- Kinesis Firehose\n- S3 lifecycle\n- IAM roles, SSE\n- Testing plan\n\n## Code Example\n```yaml\nResources:\n  FirehoseToS3:\n    Type: AWS::KinesisFirehose::DeliveryStream\n    Properties:\n      DeliveryStreamType: DirectPut\n      S3DestinationConfiguration:\n        BucketARN: arn:aws:s3:::central-logs\n        RoleARN: arn:aws:iam::123456789012:role/FirehoseDeliveryRole\n        BufferingHints:\n          SizeInMBs: 5\n          IntervalInSeconds: 300\n        CompressionFormat: UNCOMPRESSED\n```\n\n## Follow-up Questions\n- How would you scale for higher log throughput?\n- How would you implement log integrity checks and retries?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Meta","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T16:56:04.390Z","createdAt":"2026-01-16T16:56:04.390Z"},{"id":"q-2924","question":"Scenario: In a global SaaS with 3 AWS accounts across 2 regions, design an automated cost anomaly detection and remediation workflow that halts non-production resources when daily spend grows by more than 2x over a 7-day rolling window, while preserving prod SLAs. Specify integration of Cost Anomaly Detection, CloudWatch, Lambda, Step Functions, AWS Budgets, and guardrails and testing?","answer":"Implement a per-account cost anomaly workflow triggered by AWS Cost Anomaly Detection alerts. A Lambda listener channels events to a Step Functions state machine that tags non-prod resources, pauses i","explanation":"## Why This Is Asked\nTests ability to design automated cost governance with real-time remediation while safeguarding production workloads, and to articulate testing/rollback strategies.\n\n## Key Concepts\n- AWS Cost Anomaly Detection per account/region\n- Event-driven Lambda listeners\n- Step Functions for orchestration\n- Guardrails around prod resources\n- Tests: staging spikes, safe rollback\n\n## Code Example\n```json\n{\n  \"Comment\": \"Cost anomaly remediation state machine\",\n  \"StartAt\": \"EvaluateAnomaly\",\n  \"States\": {\n    \"EvaluateAnomaly\": {\"Type\": \"Choice\", \"Choices\": [{\"Variable\": \"$.detail.impact\", \"NumericGreaterThanEquals\": 2, \"Next\": \"Remediate\"}], \"Default\": \"NoOp\"},\n    \"Remediate\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:lambda:region:acct:function:RemediateCosts\", \"End\": true}\n  }\n}\n```\n\n```python\nimport boto3\n\ndef lambda_handler(event, context):\n    # parse anomaly alert and trigger remediation workflow\n    pass\n```\n\n## Follow-up Questions\n- How would you test remediation in a non-prod account without impacting customers?\n- How would you handle false positives and ensure a safe rollback path?","diagram":"flowchart TD\n  A[Cost Anomaly Detected] --> B[Invoke Lambda]\n  B --> C[Start Step Functions]\n  C --> D[Tag Non-Prod]\n  D --> E[Pause Non-Prod Resources]\n  E --> F[Notify & Audit]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T17:46:44.528Z","createdAt":"2026-01-16T17:46:44.528Z"},{"id":"q-2981","question":"In a multi-account AWS environment hosting a global SaaS app, you must quickly detect and isolate a misconfigured OpenSearch domain that is publicly accessible. Design an end-to-end, beginner-friendly workflow using AWS Config rules, EventBridge, Lambda, and Organizations SCPs to detect, auto-remediate (restrict access and enable encryption), alert on-call, and provide a rollback plan. Include testing steps?","answer":"Detect with a Config rule for public access or missing encryption; a central EventBridge rule triggers a Lambda to (1) apply a deny-public-access domain policy and enable encryption at rest (KMS) if n","explanation":"## Why This Is Asked\nTests practical, beginner-friendly automation for common security misconfigurations across accounts, focusing on OpenSearch governance and automated remediation.\n\n## Key Concepts\n- AWS Config rules and remediation\n- EventBridge for orchestration\n- Lambda for automated changes\n- IAM SCPs for cross-account guardrails\n- OpenSearch domain security settings (public access, encryption)\n\n## Code Example\n```javascript\nexports.handler = async (event) => {\n  // parse OpenSearch domain from event\n  // if public access detected or encryption off:\n  //   call OpenSearch updateDomainConfig to set domainConfigOptions accordingly\n  //   apply a restricted access policy\n  //   emit alert payload to a central dashboard\n};\n```\n\n## Follow-up Questions\n- How would you test the rollback path if the remediation fails to apply? \n- What logging/metrics would you collect to validate ongoing policy compliance?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Stripe","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T19:45:00.470Z","createdAt":"2026-01-16T19:45:00.470Z"},{"id":"q-3005","question":"In a six-region, multi-account AWS setup hosting a critical data platform, design an automated secrets lifecycle that rotates database credentials and API keys stored in AWS Secrets Manager, revokes stale IAM principals, and enforces cross-account access controls via IAM and resource policies. Include rotation schedules, cross-region replication, audit trails, testing, and rollback?","answer":"Implement automatic rotation for Secrets Manager entries holding DB credentials and API keys, with region-scoped Lambda rotation functions; enable cross-region replication and per-secret KMS keys; enf","explanation":"## Why This Is Asked\n\nThis tests operational design for secrets lifecycle at scale, including rotation, cross-region replication, and access governance, with rollback readiness and auditing.\n\n## Key Concepts\n\n- AWS Secrets Manager rotation\n- Lambda-based rotation templates\n- cross-region secret replication\n- KMS per-secret keys\n- IAM/resource policy scoping\n- CloudTrail and EventBridge alerting\n\n## Code Example\n\n```javascript\n// Rotation function skeleton\nexports.handler = async (event) => {\n  // handle create/cancel/rotate\n};\n```\n\n## Follow-up Questions\n\n- How would you simulate a rotation failure and trigger automatic rollback?\n- What metrics and alarms would you monitor for rotation health and secret leakage risk?","diagram":"flowchart TD\n  S[Secret] --> R[Rotation]\n  R --> C[Lambda Rotation Function]\n  C --> P[Policy Enforcement]\n  P --> R2[Cross-Region Replication]\n  R2 --> A[Audit/Logging]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T20:44:10.382Z","createdAt":"2026-01-16T20:44:10.382Z"},{"id":"q-3049","question":"Across six AWS accounts spanning four regions, design an automated failover strategy for SageMaker endpoints and associated data pipelines to achieve near-zero RTO during regional outages. Detail how Route 53 health checks, Global Accelerator, cross-region S3 replication, DynamoDB Global Tables, IAM trust models, and Step Functions/Lambda orchestration would work. Include testing, rollback, and observability?","answer":"Adopt an active‑active SageMaker deployment across two regions per model, with S3 artifacts replicated regionally, Route 53 health checks plus AWS Global Accelerator for traffic steering, DynamoDB Glo","explanation":"## Why This Is Asked\nTests ability to design cross‑region DR with low RTO for ML workloads, covering end‑to‑end automation, cross‑account security, and observability. It couples routing, data locality, and state synchronization in a production context.\n\n## Key Concepts\n- Multi‑region active‑active SageMaker deployments\n- Route 53 health checks + Global Accelerator routing\n- S3 cross‑region replication and data locality policies\n- DynamoDB Global Tables for shared state across accounts\n- Cross‑account IAM roles and trust policies\n- Step Functions/Lambda orchestration for failover and rollback\n- Observability: metrics, alarms, latency checks, data integrity tests\n\n## Code Example\n```javascript\n// Sample AWS Step Functions state machine (high level)\n{\n  \"Comment\": \"SageMaker failover workflow\",\n  \"StartAt\": \"HealthCheck\"\n  ,\"States\": {\n    \"HealthCheck\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:lambda:region:acct:function:HealthCheck\", \"Next\": \"Decide\"},\n    \"Decide\": {\"Type\": \"Choice\", \"Choices\": [{\"Variable\": \"$.__state.finalError\", \"StringEquals\": \"true\", \"Next\": \"Failover\"}], \"Default\": \"Continue\"},\n    \"Continue\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:lambda:region:acct:function:ContinueTraffic\", \"End\": true},\n    \"Failover\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:lambda:region:acct:function:RouteFailover\", \"End\": true}\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test failover without impacting production endpoints?\n- How would you validate data consistency after a failover and rollback if latency spikes occur?","diagram":"flowchart TD\n  A[User Request] --> B(Route 53 Health Check)\n  B --> C(Global Accelerator)\n  C --> D[SageMaker Endpoint Region A]\n  C --> E[SageMaker Endpoint Region B]\n  D --> F[Metrics & Health]\n  E --> F\n  F --> G{Healthy?}\n  G -- Yes --> H[Route to A or B]\n  G -- No --> I[Trigger Step Functions Failover]\n  I --> J[Data & Endpoint Sync]\n  J --> K[Rollback if needed]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Databricks","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T22:42:23.092Z","createdAt":"2026-01-16T22:42:23.092Z"},{"id":"q-3097","question":"In a 3-region SaaS deployment (prod us-east-1, prod eu-west-1, staging) implement automated containment for a newly detected public S3 bucket containing customer data. Use a Config rule to flag public buckets, EventBridge+Lambda to apply a DenyPublicAccess policy, and SCPs in prod to block exposure. Include testing steps and rollback plan?","answer":"Implement a Config rule that flags any S3 bucket with public access not blocked. On detection, a Lambda triggered by EventBridge applies a DenyPublicAccess policy to the bucket and enforces a prod SCP to prevent future public exposure.","explanation":"## Why This Is Asked\n\nTests ability to wire detection, containment, and rollback across accounts/regions using native AWS services.\n\n## Key Concepts\n\n- AWS Config custom rule for public bucket detection\n- EventBridge and Lambda for automated remediation\n- S3 public access policies and DenyPublicAccess patterns\n- Service Control Policies (SCPs) to enforce governance in prod\n- Testing and rollback planning across multi-region deployments\n\n## Code Example\n\n```python\n# Pseudo-Lambda: attach DenyPublicAccess to bucket policy\nimport json, boto3\ns3 = boto3.client('s3')\n\ndef handler(event, ctx):\n    bucket = event['detail']['requestParameters']['bucketName']\n    s3.put_public_access_block(\n        Bucket=bucket,\n        PublicAccessBlockConfiguration={\n            'BlockPublicAcls': True,\n            'IgnorePublicAcls': True,\n            'BlockPublicPolicy': True,\n            'RestrictPublicBuckets': True\n        }\n    )\n```\n\n## Testing Steps\n\n1. Create test bucket with public access in staging\n2. Verify Config rule detection within 5 minutes\n3. Confirm Lambda applies DenyPublicAccess policy\n4. Validate SCP blocks public access in prod regions\n5. Test rollback by removing Config rule and Lambda\n\n## Rollback Plan\n\n1. Disable Config rule to stop detection\n2. Remove EventBridge rule to prevent Lambda triggers\n3. Delete Lambda function\n4. Remove SCP from prod OUs\n5. Manually restore bucket policies if needed","diagram":"flowchart TD\n  A[Config Rule triggers] --> B[Lambda enforces policy]\n  B --> C[SCPs applied in prod]\n  C --> D[Alerts sent to security stack]\n  D --> E[Verification & rollback path]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","DoorDash","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:59:48.350Z","createdAt":"2026-01-17T02:18:42.048Z"},{"id":"q-3160","question":"Scenario: In a single AWS region, a small app uses an RDS MySQL primary with one read replica to handle read traffic. Design a beginner-friendly auto-scaling approach that creates a second read replica during peak hours and tears it down after. Outline the AWS components, thresholds, cost guardrails, and testing steps?","answer":"Design a beginner-friendly auto-scaling strategy for an RDS MySQL primary with one read replica in a single region. Use CloudWatch to trigger a Lambda when CPUUtilization or replicaLag thresholds are ","explanation":"## Why This Is Asked\n\nTests practical workflow for on-demand read scaling and cost control using serverless automation.\n\n## Key Concepts\n\n- CloudWatch alarms and metrics\n- Lambda-driven lifecycle automation\n- RDS read replicas lifecycle\n- IAM least privilege permissions\n- AWS Budgets and SNS alerts\n\n## Code Example\n\n```bash\n# AWS CLI example to create a read replica\naws rds create-db-instance-read-replica \\\n  --db-instance-identifier mydb-ro-2 \\\n  --source-db-instance-identifier mydb-primary \\\n  --db-instance-class db.t3.medium \\\n  --region us-east-1\n```\n\n## Follow-up Questions\n\n- How would you handle a primary failure during peak with this setup?\n- How would you test the auto-scaling safely in production?","diagram":"flowchart TD\n  A[CloudWatch Alarm] --> B[Lambda Function]\n  B --> C{Replica Count < Max}\n  C -->|Yes| D[Create Read Replica]\n  C -->|No| E[No Action]","difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Lyft","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:54:43.242Z","createdAt":"2026-01-17T04:54:43.242Z"},{"id":"q-3197","question":"In a single-region AWS setup for a small web app, design a lightweight log-collection and alerting pipeline. Use CloudWatch Logs as source, a Kinesis Data Firehose delivery stream to S3, and a Lambda function scheduled hourly to compute errors/requests. If hourly error rate > 5%, publish to SNS. Describe components, thresholds, IAM permissions, and a basic test plan?","answer":"Outline a lightweight log pipeline in one region: CloudWatch Logs as source, Firehose to S3, and a Lambda hourly job to compute errors per hour divided by total requests. If the hourly error rate exce","explanation":"## Why This Is Asked\nTests ability to design a simple, observable log pipeline using common AWS services with clear thresholds and automated alerting. Emphasizes practical data parsing and permissions best practices for a beginner-friendly scenario.\n\n## Key Concepts\n- CloudWatch Logs and metrics\n- Kinesis Data Firehose to S3\n- Lambda scheduling via EventBridge\n- IAM least privilege\n- SNS alerts\n\n## Code Example\n```javascript\nexports.handler = async (event) => {\n  // Parse S3 batch, compute errors vs total requests\n  return { status: 'ok' };\n};\n```\n\n## Follow-up Questions\n- How would you handle log lag or partial data?\n- How would you test without impacting production traffic?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Hashicorp","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T06:47:37.369Z","createdAt":"2026-01-17T06:47:37.369Z"},{"id":"q-3284","question":"In a globally distributed 4-region SaaS backend (us-east-1, eu-west-1, ap-southeast-1, ap-northeast-1) with Lambda, DynamoDB, and S3, you must guarantee an RPO of 15 minutes and an RTO of 60 minutes for customer data, with cross-account backups that survive region failure. Design a cross-region backup strategy using AWS Backup, DynamoDB backups, S3 replication, KMS with rotation, and cross-account restoration via IAM roles and SCPs. Include testing plan and cost considerations?","answer":"Design a cross-region backup strategy: use AWS Backup for EBS/AMI, enable DynamoDB on-demand backups with cross-region copies, and implement S3 cross-region replication to a centralized vault in a sep","explanation":"## Why This Is Asked\n\nTests practical multi-region backup strategy with cross-account controls and real DR validation, not theoretical talk.\n\n## Key Concepts\n\n- AWS Backup, DynamoDB backups (on-demand), S3 replication\n- Cross-account restore workflows, IAM roles, SCPs\n- KMS key management and rotation\n- DR testing, cost awareness\n\n## Code Example\n\n```javascript\n// Example: initiate a DynamoDB on-demand backup copy (pseudo)\nconst { DynamoDBClient, CreateBackupCommand } = require(\"@aws-sdk/client-dynamodb\");\nconst client = new DynamoDBClient({ region: \"us-east-1\" });\nawait client.send(new CreateBackupCommand({ TableName: \"Users\", BackupName: \"Users-backup-202601\" }));\n```\n\n## Follow-up Questions\n\n- How would you validate RPO/RTO after a drill?\n- What are the failure modes if the central vault is compromised?\n","diagram":"flowchart TD\n  A[Regions: us-east-1, eu-west-1, ap-southeast-1, ap-northeast-1] --> B[AWS Backup Plans (EBS/AMI)]\n  A --> C[DynamoDB On-Demand Backups + Cross-Region Copies]\n  A --> D[S3 Replication to Central Vault]\n  B --> E[Central Vault in Shared Account (KMS)]\n  E --> F[Cross-Account IAM Roles & SCPs for Restore]\n  F --> G[Validation: Drill, Restore Time]\n  G --> H[Cost & Compliance Review]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","IBM","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T09:46:28.364Z","createdAt":"2026-01-17T09:46:28.364Z"},{"id":"q-3406","question":"Scenario: A prod IAM key leaks across three AWS regions in a microservices app. Propose an automated, end-to-end incident response that detects, rotates credentials, revokes sessions, isolates the affected account with SCPs, and validates service health using EventBridge, Lambda, IAM, Secrets Manager, and Route 53 health checks. Include testing and rollback?","answer":"Automated cross‑account IR: detect via CloudTrail/GuardDuty a leaked prod IAM key across 3 regions; Lambda (central security account) rotates keys, disables old tokens, and revokes sessions; apply SCP","explanation":"## Why This Is Asked\nThis checks real-world incident response, cross‑account governance, and event‑driven automation across AWS services.\n\n## Key Concepts\n- Event-driven IR\n- Cross-account SCPs and IAM policies\n- Credential rotation and session control\n- Health checks and rollback\n\n## Code Example\n```javascript\nexports.handler = async (event) => {\n  // parse event, identify affected principals\n  // rotate credentials via IAM\n  // apply SCP to isolate account\n  // trigger health canaries\n};\n```\n\n## Follow-up Questions\n- How would you test the IR playbook dry-run?\n- How do you ensure idempotent retries and clean rollback?","diagram":"flowchart TD\n  A[Detect Incident] --> B[Trigger Remediation]\n  B --> C[Rotate IAM Keys]\n  C --> D[Apply SCP Isolation]\n  D --> E[Health Canary Checks]\n  E --> F{Healthy?}\n  F -->|Yes| G[Notify & Resume]\n  F -->|No| H[Rollback & Alert]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","LinkedIn","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T14:43:15.478Z","createdAt":"2026-01-17T14:43:15.478Z"},{"id":"q-3411","question":"In a single-region AWS setup, a data-processing pipeline uses an SQS standard queue triggering a Lambda function that writes results to DynamoDB. Design a beginner-friendly reliability improvement: (1) configure a Dead-Letter Queue for messages that fail processing after N receives; (2) tune Lambda retry behavior and visibility timeout; (3) add CloudWatch alarms and an SNS alert for DLQ growth and high processing latency; (4) provide a minimal runbook and testing steps?","answer":"Enable a DLQ on the SQS queue and set RedrivePolicy maxReceiveCount to 5; configure the Lambda event source mapping with MaximumRetryAttempts: 2 and a 60s visibility timeout; create CloudWatch alarms ","explanation":"## Why This Is Asked\n\nTests practical ops knowledge of reliable message processing: DLQ usage, Lambda retry behavior, visibility timeouts, and alerting. It also asks for a tangible test plan and runbook, not theory.\n\n## Key Concepts\n\n- SQS Dead-Letter Queue and redrive policy\n- Lambda Event Source Mapping: MaximumRetryAttempts, batch size\n- Visibility Timeout tuning\n- CloudWatch alarms and SNS-based alerts\n- Basic runbook and recovery testing\n\n## Code Example\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  MainQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      RedrivePolicy:\n        deadLetterTargetArn: !GetAtt DLQ.Arn\n        maxReceiveCount: 5\n  DLQ:\n    Type: AWS::SQS::Queue\n  LambdaEventSourceMapping:\n    Type: AWS::Lambda::EventSourceMapping\n    Properties:\n      EventSourceArn: !GetAtt MainQueue.Arn\n      FunctionName: !GetAtt DataProcessor.Arn\n      MaximumRetryAttempts: 2\n      BatchSize: 10\n```\n\n## Follow-up Questions\n\n- How would you test DLQ backlog and recovery workflow?\n- How would you tune for burst traffic and minimize duplicate processing?","diagram":null,"difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Meta","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T15:29:51.041Z","createdAt":"2026-01-17T15:29:51.041Z"},{"id":"q-3521","question":"In a three-region AWS multi-account data pipeline using S3 data lake, Glue ETL, and Redshift, design an automated incident response that detects data inconsistency or SLA breach, isolates the affected region, promotes a hot standby copy, and validates end-to-end data integrity before resuming writes. Outline the orchestration with EventBridge, Step Functions, Lambda, IAM roles, cross-region replication, and rollback procedures?","answer":"Detect via CloudWatch SLA metrics and data-quality anomalies. Trigger Step Functions via EventBridge to isolate the affected region, promote a hot standby (cross-region Redshift snapshot or S3 backup)","explanation":"## Why This Is Asked\nProbes real-world incident response in a multi-region data stack with automated remediation and rollback.\n\n## Key Concepts\n- Cross-region failover, data integrity checks, multi-account IAM\n- Event-driven orchestration: EventBridge, Step Functions, Lambda\n- Data-plane vs control-plane separation, traffic routing\n\n## Code Example\n```javascript\n// Pseudo-code: basic state machine flow\n```\n\n## Follow-up Questions\n- How would you simulate data corruption safely for tests?\n- Which metrics would you trust for rollback vs promotion?","diagram":null,"difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T19:34:57.698Z","createdAt":"2026-01-17T19:34:57.698Z"},{"id":"q-3597","question":"In a two-region deployment hosting a 24x7 financial service behind an ALB and an RDS primary with cross-region replication, design an automated DR workflow that fails over from us-east-1 to eu-west-1. Include data-sync approach (RDS cross-region replica vs DynamoDB Global Tables), Route 53 failover, a Lambda control plane for promoting failover, IAM rotation, ALB target switching, S3 replication, and a deterministic rollback. Outline RTO/RPO targets and a test plan?","answer":"Automate disaster recovery between us-east-1 and eu-west-1 using RDS cross-region replica promotion, Route 53 failover routing, and a Lambda control plane to promote the standby environment, rotate IAM credentials, and switch ALB target groups. Target RTO under 5 minutes and RPO under 1 minute with S3 cross-region replication for static assets. Include deterministic rollback using CloudFormation stacks and automated testing through chaos engineering.","explanation":"## Why This Is Asked\nAssessment of multi-region disaster recovery design capabilities with focus on automation, cost optimization, and testability.\n\n## Key Concepts\n- Cross-region disaster recovery architecture\n- Route 53 failover routing and health check configuration\n- RDS cross-region replication versus DynamoDB Global Tables comparison\n- Lambda control plane for environment promotion, credential rotation, and traffic routing\n- Application Load Balancer target group management and IAM credential rotation\n- S3 cross-region replication and cache invalidation strategies\n- Disaster recovery testing methodologies and rollback procedures","diagram":"flowchart TD\n  A[us-east-1 Active] --> B[Outage Detected]\n  B --> C[Promote replica in eu-west-1]\n  C --> D[Update Route53 failover]\n  D --> E[Switch ALB target group]\n  E --> F[Validate traffic and metrics]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Meta","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:30:55.677Z","createdAt":"2026-01-17T22:41:37.198Z"},{"id":"q-3676","question":"In a multi-account AWS deployment across two regions, design an automated disaster recovery (DR) plan for a data processing pipeline (S3 data lake, AWS Glue, Lambda, DynamoDB). Primary region us-east-1, standby us-west-2. Achieve RPO <= 5 minutes and RTO <= 15 minutes with automated failover using Route 53, S3 cross-region replication, DynamoDB Global Tables, and a Lambda-driven reconfiguration. Include failover sequence, data synchronization strategy, testing plan, and rollback?","answer":"Use S3 Cross-Region Replication from us-east-1 to us-west-2, DynamoDB Global Tables in both regions, and Glue jobs with region-agnostic URIs. Route 53 failover with healthy checks directs traffic to t","explanation":"## Why This Is Asked\n\nEvaluates practical DR design across accounts and regions with concrete AWS services and automation, not abstract concepts.\n\n## Key Concepts\n\n- DR planning and RPO/RTO targets\n- Route 53 failover and health checks\n- S3 Cross-Region Replication and DynamoDB Global Tables\n- Glue workflow configuration and endpoint reconfiguration\n- Testing, validation, and rollback procedures\n\n## Code Example\n\n```bash\n# DR runbook placeholder for automation sequences\n```\n\n## Follow-up Questions\n\n- How would you validate DR readiness without impacting production data?\n- How would you handle eventual consistency in DynamoDB during a failover?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","OpenAI","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T04:24:15.281Z","createdAt":"2026-01-18T04:24:15.281Z"},{"id":"q-3732","question":"In a three-region, two-account deployment hosting a real-time financial telemetry pipeline with tight latency, implement fully automated disaster recovery using Aurora Global Database, cross-region S3 replication, Route 53 failover, and Lambda-driven telemetry validation. Outline data integrity checks, failover criteria and rollback, automated DR tests, and cost considerations?","answer":"Leverage Aurora Global DB for <5s RPO, cross-region S3 replication with versioning, Route 53 failover using health checks, and Lambda checks for data latency/heartbeat. Use automated cutover with Clou","explanation":"## Why This Is Asked\nTests DR planning under strict financial SLAs and multi-region recovery, focusing on automation, data integrity, and cost control.\n\n## Key Concepts\n- Aurora Global Database cross-region replication\n- S3 cross-region replication and object versioning\n- Route 53 health checks and failover routing\n- Lambda-based telemetry validation and CloudWatch alarms\n- Rollback strategy and cost-aware DR testing\n\n## Code Example\n```bash\n# Conceptual: enable global db and ensure backups\naws rds create-global-database --db-cluster-identifier telemetry-global --engine aurora-mysql\naws s3 cp s3://telemetry-us-east-1/telemetry/ s3://telemetry-eu-west-1/telemetry/ --recursive\n```\n\n## Follow-up Questions\n- How would you validate DR readiness without impacting production data?\n- How would you handle RPO/RTO changes if latency spikes occur?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Coinbase","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T07:31:55.560Z","createdAt":"2026-01-18T07:31:55.560Z"},{"id":"q-3793","question":"In a single AWS region, a static React SPA is hosted on S3 and delivered through CloudFront; a Node API runs on EC2 behind an ALB. Design a beginner-friendly guardrail to improve security and cost control: (1) enable a rate-based AWS WAF rule to throttle abusive IPs, (2) enable CloudFront access logs to an S3 bucket with lifecycle, (3) set up a simple AWS Budgets alert for API costs, and (4) outline a practical testing plan to verify the controls?","answer":"Configure WAF with a rate-based rule that blocks IPs exceeding 100 requests per 5 minutes, and apply it to the CloudFront distribution; enable CloudFront access logs to an S3 bucket with a 30-day life","explanation":"## Why This Is Asked\nThis question tests practical, beginner-level ability to implement basic security guards and cost controls in a common web app deployment.\n\n## Key Concepts\n- AWS WAF rate-based rules\n- CloudFront access logs to S3\n- AWS Budgets alerts and SNS\n- End-to-end testing of security and cost controls\n\n## Code Example\n```javascript\n// AWS CLI example (illustrative)\naws wafv2 create-web-acl --scope CLOUDFRONT --name rate-limit --default-action Block --visibility-config ... \n```\n\n## Follow-up Questions\n- How would you adapt if the API backend is API Gateway instead of EC2?\n- What monitoring indicators would you add beyond logs and budgets to detect abuse early?\n","diagram":"flowchart TD\n  A[S3/CloudFront SPA] --> B[EC2/API/ALB]\n  A -.-> C[WAF] \n  B --> D[CloudFront Logs to S3]\n  E[Budget] --> F[SNS Alerts]","difficulty":"beginner","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Lyft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T09:40:59.143Z","createdAt":"2026-01-18T09:40:59.143Z"},{"id":"q-3853","question":"In a 3-account, 2-region production setup (prod in us-east-1, replica in us-west-2) hosting a real-time analytics platform with S3 data lake, Glue Catalog, Athena queries, and a frontend API behind an ALB, design an automated DR plan achieving RPO ~5 minutes and RTO ~15 minutes. Include cross-region S3 replication, DynamoDB metadata, Glue catalog replication, Route 53 failover with health checks, and a Lambda-driven runbook to switch endpoints, update ALB target groups, and rollback steps. Provide testing plan?","answer":"Enable S3 Cross-Region Replication from us-east-1 to us-west-2 with versioning and SSE-KMS; mirror DynamoDB via Global Tables; replicate Glue Catalog and keep Athena queries in sync; Route 53 Failover","explanation":"## Why This Is Asked\n\nTests automation, cross-region DR, and runbook discipline in a multi-account, multi-region setting; checks understanding of AWS services integration, testing, and rollback.\n\n## Key Concepts\n\n- S3 Cross-Region Replication, versioning, SSE-KMS\n- DynamoDB Global Tables or cross-region replication\n- Glue Data Catalog replication and Athena cross-region queries\n- Route 53 Failover with health checks\n- Lambda-driven runbooks to switch ALB targets and rollback\n\n## Code Example\n\n```javascript\n// Example: switch Route53 failover to replica endpoint (simplified)\nconst { Route53Client, ChangeResourceRecordSetsCommand } = require(\"@aws-sdk/client-route53\");\nconst client = new Route53Client({ region: \"us-east-1\" });\nasync function failover() {\n  // placeholder: update DNS to point to us-west-2 endpoint\n}\n```\n\n## Follow-up Questions\n\n- How would you validate DR without exposing prod data?\n- What monitoring and cost controls accompany this setup?","diagram":"flowchart TD\n  US_East[Prod us-east-1] --> DR_Runbook[Runbook triggers DR]\n  S3_Primary[(S3 Data Lake us-east-1)] --> S3_Replica[(S3 Data Lake us-west-2)]\n  Glue_Primary[(Glue Catalog us-east-1)] --> Glue_Replica[(Glue Catalog us-west-2)]\n  Route53[Route53 Failover] --> ALB_Targets[(ALB us-east-1 targets)]\n  DR_Runbook --> Route53","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Robinhood","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T12:58:26.761Z","createdAt":"2026-01-18T12:58:26.761Z"},{"id":"q-3955","question":"In a multi-region, multi-account AWS environment hosting a global web app with a primary deployment in us-east-1 and a DR site in eu-west-1, design an automated, auditable failover procedure using Route 53 failover routing, S3 cross-region replication for assets, and RDS cross-region disaster recovery. Include promotion steps, timing targets, logging, and testing plan?","answer":"Route 53 failover with health checks directing traffic to eu-west-1 when us-east-1 is unhealthy; a DR-promo Lambda in the DR account flips DNS, updates TTLs, and switches assets; enable S3 cross-regio","explanation":"## Why This Is Asked\nThis question probes real-world DR orchestration across accounts and regions, including DNS-based failover, cross-region asset replication, and database DR, with auditable workflows.\n\n## Key Concepts\n- Route 53 health checks and failover\n- Cross-region S3 replication and lifecycle\n- RDS cross-region DR and read replicas\n- IAM roles, cross-account access, auditing via CloudTrail\n- Testing, rollback, and compliance\n\n## Code Example\n```javascript\n// Pseudo Lambda: promoteDRPipeline\nexports.handler = async () => {\n  // check Route53 health, promote records to DR when primary is down\n  // switch assets, promote RDS DR replica, log events\n}\n```\n\n## Follow-up Questions\n- How would you test failover without impacting customers?\n- What metrics indicate a successful failover and how would you validate rollback?","diagram":"flowchart TD\n A[Primary us-east-1] --> B[Route53 health checks]\n B --> C{Healthy?}\n C -- Yes --> D[Traffic stays primary]\n C -- No --> E[Promote DR eu-west-1]\n E --> F[Switch S3 assets]\n F --> G[Promote DR RDS replica]\n","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Coinbase","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T16:53:40.834Z","createdAt":"2026-01-18T16:53:40.834Z"},{"id":"q-4082","question":"In a multi-region AWS deployment, a globally distributed app uses Lambda@Edge to personalize content at the edge and CloudFront to cache responses. When deploying a content update, how would you ensure deterministic cache invalidation across all regions, minimize user latency, and validate rollback strategies? Provide concrete steps and trade-offs?","answer":"Coordinate a staged rollout with CloudFront invalidations and per-cache-behavior TTLs. Use Lambda@Edge to inject a version header/cookie, serve the new version only after validation, and begin in a ca","explanation":"## Why This Is Asked\nTests ability to design edge cache invalidation and rollout strategies for multi-region deployments with Lambda@Edge.\n\n## Key Concepts\n- Lambda@Edge and CloudFront cache behaviors\n- Cache invalidation strategies and TTL control\n- Canary/deployment strategies and rollback\n\n## Code Example\n```javascript\n// Example: Lambda@Edge snippet to attach a version header\nexports.handler = async (event) => {\n  const request = event.Records[0].cf.request;\n  request.headers['x-version'] = [{ key: 'X-Version', value: 'v2' }];\n  return request;\n}\n```\n\n## Follow-up Questions\n- How would you observe cache invalidation latency across regions?\n- How would you handle a failed invalidation?","diagram":null,"difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Discord","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T22:52:27.713Z","createdAt":"2026-01-18T22:52:27.713Z"},{"id":"q-675","question":"You manage a two-region AWS deployment (us-east-1, us-west-2) behind an ALB with private subnets, NAT gateway, and RDS in us-east-1. During business hours, us-west-2 exhibits spike in 5xx errors and higher latency. Outline immediate incident triage steps, AWS CLI commands to run, how you’d identify root causes (NAT saturation, DNS routing, cross-region replication lag), and both short- and long-term mitigations with verification steps?","answer":"Start by verifying scope in CloudWatch and X-Ray, then check ALB target health, NAT gateway quotas, and RDS latency across regions. Collect logs, compare regional error rates, and run a quick failover","explanation":"## Why This Is Asked\nThis question evaluates incident triage skills in a real multi-region AWS setup, focusing on identifying root causes under pressure, deciding rapid mitigations, and confirming with telemetry. It tests familiarity with ALB, NAT, RDS, Route53, and CloudWatch/X-Ray.\n\n## Key Concepts\n- Multi-region deployment\n- Incident triage\n- ALB, NAT gateway, RDS latency\n- CloudWatch, VPC Flow Logs, X-Ray\n- DR planning\n\n## Code Example\n```javascript\n// Pseudo-logic for triage steps in a real incident\nfunction triage(incident) {\n  // fetch metrics from CloudWatch and X-Ray\n  // check ALB target health and NAT quotas\n  // identify root cause and apply mitigation\n}\n```\n\n## Follow-up Questions\n- Which metrics would you alert on for cross-region failures?\n- How would you automate the triage workflow?","diagram":"flowchart TD\n  A[Incident] --> B[Triage]\n  B --> C{Root Cause?}\n  C --> D[NAT Saturation]\n  C --> E[DNS/Routing]\n  C --> F[RDS/Replication Lag]\n  D --> G[Mitigate: scale NAT]\n  E --> H[Mitigate: Route53 routing]\n  F --> I[Mitigate: DR drill]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T14:46:56.102Z","createdAt":"2026-01-11T14:46:56.102Z"},{"id":"q-982","question":"Design an automated cross-region disaster recovery plan for a globally distributed web app currently active in us-east-1 with a DR site in us-west-2, covering RDS, DynamoDB, S3, and ALB-backed frontend. Specify data synchronization, failover steps, testing, and rollback?","answer":"Cross-region DR plan with a warm DR in us-west-2. DynamoDB Global Tables for multi-region writes; RDS cross-region read replicas with automatic failover; S3 Cross-Region Replication for objects; Route","explanation":"## Why This Is Asked\nTests practical DR thinking across AWS services, including data consistency, failover automation, and testing.\n\n## Key Concepts\n- Cross-region DR strategies and RTO/RPO\n- Data synchronization for RDS, DynamoDB, and S3\n- Automation with Step Functions/SSM for failover\n\n## Code Example\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  DRStateMachine:\n    Type: AWS::StepFunctions::StateMachine\n    Properties:\n      DefinitionString: |\n        {\n          \"Comment\": \"DR failover\",\n          \"StartAt\": \"PromoteDRRDS\",\n          \"States\": {\n            \"PromoteDRRDS\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:states:::rds:promoteReadReplica\"}\n          }\n        }\n```\n\n## Follow-up Questions\n- How would you test RPO guarantees for DynamoDB Global Tables?\n- What are potential pitfalls with Route 53 failover in multi-Region deployments?","diagram":"flowchart TD\nA[Primary Region us-east-1] --> B{Healthy?}\nB -- Yes --> C[Normal traffic]\nB -- No --> D[Failover to us-west-2]\nD --> E[Promote DR RDS; re-point ALB; update DynamoDB endpoints]\nE --> F[Run DR tests and verify]\nF --> G[Record results and rollback if needed]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:45:18.021Z","createdAt":"2026-01-12T17:45:18.021Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","Plaid","Robinhood","Salesforce","Scale Ai","Snowflake","Square","Stripe","Tesla","Two Sigma","Uber","Zoom"],"stats":{"total":46,"beginner":15,"intermediate":15,"advanced":16,"newThisWeek":45}}