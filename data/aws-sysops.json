{"questions":[{"id":"aws-sysops-cost-optimization-1768267600057-0","question":"A web service runs a batch data processing job on EC2 for 6 hours daily with varying demand. To minimize cost without sacrificing performance, which approach is best?","answer":"[{\"id\":\"a\",\"text\":\"Use only On-Demand instances and scale manually to match demand\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Purchase 1-year Standard Reserved Instances for all instances\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a mix of Spot Instances for the batch job with Auto Scaling, with On-Demand as a fallback\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Move all workloads to dedicated hosts to guarantee performance\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption C: Use a mix of Spot Instances for the batch job with Auto Scaling, with On-Demand as a fallback to balance cost and performance.\n\n## Why Other Options Are Wrong\n\n- A: On-Demand alone avoids interruptions but does not optimize for variable load and tends to be more expensive for steady but fluctuating demand.\n- B: Reserved Instances lock in capacity and cost for a long period, reducing flexibility for variable workloads.\n- D: Dedicated hosts are costly and unnecessary for most batch/workload scaling scenarios.\n\n## Key Concepts\n\n- Spot Instances\n- Auto Scaling\n- Mixed Instance Policy\n- Interruption handling\n\n## Real-World Application\n\n- Apply to batch analytics, data processing pipelines, and CI jobs with variable runtimes and demand.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","EC2","AutoScaling","Spot Instances","Cost Optimization","certification-mcq","domain-weight-12"],"channel":"aws-sysops","subChannel":"cost-optimization","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:26:40.059Z","createdAt":"2026-01-13 01:26:40"},{"id":"aws-sysops-cost-optimization-1768267600057-1","question":"An archival data set of 500 TB is stored in S3. Access patterns are unpredictable and infrequent. Which storage strategy minimizes cost while preserving fast recovery when needed?","answer":"[{\"id\":\"a\",\"text\":\"Keep data in S3 Standard\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Move data to S3 Standard-IA with a lifecycle policy to transition older data to Glacier\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable S3 Intelligent-Tiering\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Move all data to Glacier Deep Archive\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption C: Enable S3 Intelligent-Tiering.\n\n## Why Other Options Are Wrong\n\n- A: S3 Standard is costlier for infrequently accessed data.\n- B: Standard-IA requires proactive planning and can incur retrieval costs; it also involves manual transitions.\n- D: Glacier Deep Archive has long retrieval times and is not suitable when fast recovery is occasionally required.\n\n## Key Concepts\n\n- S3 storage classes\n- Intelligent-Tiering\n- Lifecycle management\n\n## Real-World Application\n\n- Suitable for large, unpredictable archival datasets where access is sporadic but occasional fast recovery is needed.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","S3","Storage Classes","Intelligent-Tiering","Cost Optimization","certification-mcq","domain-weight-12"],"channel":"aws-sysops","subChannel":"cost-optimization","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:26:40.501Z","createdAt":"2026-01-13 01:26:40"},{"id":"aws-sysops-cost-optimization-1768267600057-2","question":"Your Kubernetes cluster on AWS (EKS) experiences variable workloads. You want to minimize compute costs while preserving performance. Which approach is most effective?","answer":"[{\"id\":\"a\",\"text\":\"Disable node autoscaling and run a fixed-size cluster\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Cluster Autoscaler with mixed instance types and Spot Instances for non-critical pods, with Pod Disruption Budgets\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run all workloads on a single On-Demand node pool to reduce management overhead\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Migrate all workloads to a Fargate-only setup\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B: Enable Cluster Autoscaler with mixed instance types and Spot Instances for non-critical pods, with Pod Disruption Budgets.\n\n## Why Other Options Are Wrong\n\n- A: No autoscaling leads to over-provisioning during peak and underutilization otherwise.\n- C: Fixed-size, On-Demand-only clusters miss opportunities to scale down during quiet periods.\n- D: Fargate-only simplifies management but can significantly increase costs for sustained heavy workloads.\n\n## Key Concepts\n\n- Cluster Autoscaler\n- Mixed instance types\n- Spot Instances\n- Pod Disruption Budgets (PDB)\n\n## Real-World Application\n\n- Cost-optimal Kubernetes operation for highly variable microservices workloads.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","EKS","Kubernetes","Cluster Autoscaler","Spot Instances","Cost Optimization","certification-mcq","domain-weight-12"],"channel":"aws-sysops","subChannel":"cost-optimization","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:26:40.960Z","createdAt":"2026-01-13 01:26:41"},{"id":"aws-sysops-cost-optimization-1768267600057-3","question":"You manage hundreds of EC2 instances and want to balance performance monitoring with cost. Which monitoring strategy best balances visibility and price?","answer":"[{\"id\":\"a\",\"text\":\"Enable detailed monitoring (1-minute intervals) on all instances\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use basic CloudWatch monitoring (5-minute metrics) by default and enable detailed monitoring only for auto scaling or critical hosts\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Disable CloudWatch metrics to save on charges\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Ship all metrics to a dedicated on-prem monitoring system\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B: Use basic CloudWatch monitoring (5-minute metrics) by default and enable detailed monitoring only for auto scaling or critical hosts.\n\n## Why Other Options Are Wrong\n\n- A: 1-minute monitoring increases costs significantly and is often unnecessary for most fleets.\n- C: Disabling metrics eliminates visibility and hampers performance tuning and cost optimization.\n- D: On-prem monitoring introduces additional maintenance and is not aligned with cloud-native cost/perf optimization.\n\n## Key Concepts\n\n- CloudWatch metrics granularity\n- Auto Scaling considerations\n- Cost vs. visibility trade-offs\n\n## Real-World Application\n\n- Reduces monitoring spend while preserving critical performance signals for auto-scaling decisions.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","CloudWatch","EC2","Monitoring","Cost Optimization","certification-mcq","domain-weight-12"],"channel":"aws-sysops","subChannel":"cost-optimization","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:26:41.113Z","createdAt":"2026-01-13 01:26:41"},{"id":"aws-sysops-cost-optimization-1768267600057-4","question":"A mixed workload uses EC2, Fargate, and Lambda. You want a single purchase option to reduce costs across these compute services with flexibility. Which approach should you choose?","answer":"[{\"id\":\"a\",\"text\":\"Purchase Standard Reserved Instances for all EC2 instances\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use On-Demand for all services\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Apply Compute Savings Plans to cover EC2, Fargate, and Lambda usage\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Purchase Reserved Instances for each service separately (EC2, Fargate, Lambda)\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption C: Apply Compute Savings Plans to cover EC2, Fargate, and Lambda usage.\n\n## Why Other Options Are Wrong\n\n- A: RIs for EC2 do not cover Fargate or Lambda, limiting overall savings.\n- B: On-Demand is the most expensive option for sustained compute usage.\n- D: Lambda and Fargate do not support traditional EC2 Reserved Instances; Savings Plans provide cross-service coverage.\n\n## Key Concepts\n\n- Compute Savings Plans\n- Coverage across EC2, Fargate, and Lambda\n- Cost optimization across serverless and containerized workloads\n\n## Real-World Application\n\n- Simplifies budgeting for mixed workloads while maximizing discount opportunities.\n","diagram":null,"difficulty":"intermediate","tags":["AWS","Savings Plans","EC2","Fargate","Lambda","Cost Optimization","certification-mcq","domain-weight-12"],"channel":"aws-sysops","subChannel":"cost-optimization","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:26:41.266Z","createdAt":"2026-01-13 01:26:41"},{"id":"aws-sysops-deployment-provisioning-1768213603134-0","question":"An application runs behind an Application Load Balancer and a 6-instance Auto Scaling group in multiple AZs. You need zero-downtime deployments with automated rollout and health-based rollback. Which approach best achieves this in AWS?","answer":"[{\"id\":\"a\",\"text\":\"Perform a rolling update in the Auto Scaling group using a new Launch Template version with a controlled max in-flight and health checks\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Create a new AMI and replace all instances in a single batch to minimize deployment steps\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Deploy changes via CloudFormation StackSets across accounts and regions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Manually stop and start instances one by one to apply updates\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA rolling update in the Auto Scaling group using a new Launch Template version with a carefully tuned max in-flight, along with healthy health checks and ALB draining, enables zero-downtime deployments.\n\n## Why Other Options Are Wrong\n- Option B: Replacing all instances in a single batch can cause downtime and traffic disruption.\n- Option C: StackSets are for multi-account deployments, not the intra-ASG rollout pattern needed for zero-downtime within a single ASG behind an ALB.\n- Option D: Manual updates are error-prone and cannot guarantee zero downtime at scale.\n\n## Key Concepts\n- Auto Scaling rolling updates\n- Launch Templates and versioning\n- Application Load Balancer health checks and connection draining\n\n## Real-World Application\nUse this pattern for frequent web app deployments where you must maintain availability during updates while automatically rollback on failure.","diagram":null,"difficulty":"intermediate","tags":["AWS","EC2","Auto Scaling","Launch Template","ALB","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"deployment-provisioning","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T10:26:43.135Z","createdAt":"2026-01-12 10:26:43"},{"id":"aws-sysops-deployment-provisioning-1768213603134-1","question":"You operate a multi-account AWS environment and must apply standardized infrastructure changes with auditable history and drift detection across all accounts. Which approach best provides centralized control, auditable changes, and drift detection?","answer":"[{\"id\":\"a\",\"text\":\"Use Terraform with remote state in S3, state locking via DynamoDB, and manage changes via a centralized CI/CD pipeline\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use CloudFormation StackSets with Drift Detection enabled across all accounts\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Manually apply changes per account via the AWS Console to maintain control\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use AWS CDK to synthesize stacks and deploy individually per account without centralized drift tooling\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. CloudFormation StackSets with Drift Detection provides centralized governance across multiple accounts and built-in drift detection, enabling auditable deployments.\n\n## Why Other Options Are Wrong\n- Option A: Terraform with remote state offers auditable changes via version control, but drift detection across many accounts is not native and requires external tooling.\n- Option C: Manual changes are error-prone, non-reproducible at scale, and lack centralized drift detection.\n- Option D: CDK deployments per account lack centralized drift visibility across accounts and regions.\n\n## Key Concepts\n- CloudFormation StackSets\n- Drift Detection in CloudFormation\n- Multi-account governance\n\n## Real-World Application\nAdopt StackSets with drift detection to enforce standardized infrastructure across dozens of accounts with auditable change history.","diagram":null,"difficulty":"intermediate","tags":["AWS","CloudFormation","StackSets","DriftDetection","MultiAccount","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"deployment-provisioning","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T10:26:43.698Z","createdAt":"2026-01-12 10:26:44"},{"id":"aws-sysops-deployment-provisioning-1768213603134-2","question":"You need to patch a large fleet of EC2 instances spread across multiple regions. You want patches applied during a maintenance window with automated compliance reporting and targeted scope using tags. Which service and pattern best satisfy these requirements?","answer":"[{\"id\":\"a\",\"text\":\"Use SSH to each instance and run manual patch commands during maintenance windows\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use AWS Systems Manager Patch Manager with a Maintenance Window and Run Command, targeting instances by tags\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on Cron-based patching inside each instance and aggregate status via CloudWatch Logs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Trigger a CodePipeline job to run a patch script across all regions without using Systems Manager\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. AWS Systems Manager Patch Manager with a Maintenance Window and Run Command allows centralized patching with automatic compliance reporting and can target instances by tags across regions.\n\n## Why Other Options Are Wrong\n- Option A: Manual SSH-based patching is not scalable or auditable across many accounts/regions.\n- Option C: Cron-based patching is ad-hoc, lacks centralized scheduling, and is harder to audit at scale.\n- Option D: CodePipeline alone does not provide built-in patch baselines, maintenance windows, or centralized compliance reporting.\n\n## Key Concepts\n- AWS Systems Manager Patch Manager\n- Maintenance Window scheduling\n- Tag-based targeting\n\n## Real-World Application\nUse Patch Manager to maintain compliance posture across a large, multi-region fleet with automated reporting and centralized control.","diagram":null,"difficulty":"intermediate","tags":["AWS","SSM","PatchManager","MaintenanceWindow","EC2","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"deployment-provisioning","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T10:26:44.217Z","createdAt":"2026-01-12 10:26:44"},{"id":"q-1004","question":"Scenario: A serverless API stack (API Gateway, Lambda, DynamoDB, S3, CloudFront) runs in us-east-1 with a DR region eu-west-1. Propose an automated DR plan using AWS Global Accelerator and Route 53 health checks to failover within 15 minutes. Include data replication choices, Lambda versioning strategy, S3 replication mode, and a safe rollback/verification approach that avoids production impact during tests?","answer":"Implement with AWS Global Accelerator exposing endpoint groups in us-east-1 and eu-west-1, backed by Route 53 health checks to flip traffic to DR within 15 minutes. Use Lambda aliases with canary prom","explanation":"## Why This Is Asked\nTests practical DR planning for serverless stacks, emphasizing automation, data replication choices, and safe testing.\n\n## Key Concepts\n- AWS Global Accelerator and multi-region endpoints\n- Route 53 health checks and failover routing\n- Lambda versioning and canary deployments\n- DynamoDB Global Tables and S3 cross-region replication\n- Canary DR testing and rollback workflows\n\n## Code Example\n```javascript\n// Promote DR version by updating Route53/alias configuration (illustrative)\nimport { Route53Client, ChangeResourceRecordSetsCommand } from '@aws-sdk/client-route-53';\n\nconst client = new Route53Client({region: 'us-east-1'});\nasync function failover() {\n  // Upsert DR-records to route traffic to DR region\n  await client.send(new ChangeResourceRecordSetsCommand({/* ... */}));\n}\n```\n\n## Follow-up Questions\n- How would you validate read/write integrity after failover?\n- What metrics and alarms ensure timely detection and safe rollback?","diagram":null,"difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:49:55.875Z","createdAt":"2026-01-12T18:49:55.875Z"},{"id":"q-1291","question":"In a 12-account AWS Organization, you must implement near real-time central audit logging for VPC Flow Logs, Lambda logs, and RDS logs in a dedicated Logging account. Design the end-to-end mechanism to ship logs from all member accounts to the central account, ensuring secure cross-account access, encryption, and resilience across Regions. What is your approach?","answer":"Design a centralized Logging account for all CloudWatch Logs (VPC Flow Log, Lambda, RDS) from 12 member accounts using CloudWatch Logs subscriptions to a Kinesis Data Firehose in the central account. ","explanation":"## Why This Is Asked\nTests ability to design cross-account log centralization with real-time data flow, security controls, and disaster recovery. Demonstrates practical use of CloudWatch Logs subscriptions, cross-account roles, and Kinesis Firehose in a scalable multi-account setup.\n\n## Key Concepts\n- Cross-account IAM roles and trust policies for log producers\n- CloudWatch Logs subscriptions as a transport to a central sink\n- Kinesis Data Firehose as the delivery path to S3 (encrypted with a central KMS key)\n- Central data lake with proper retention, access controls, and lifecycle\n- Regional resilience via multi-region delivery or replication\n\n## Code Example\n```javascript\n// Pseudo-CDK-like snippet for cross-account log delivery to Firehose\nconst role = new iam.Role(this, 'CWLogsToFirehose', {\n  assumedBy: new iam.AccountPrincipal('CENTRAL_ACCOUNT_ID')\n});\nrole.addToPolicy(new iam.PolicyStatement({\n  actions: ['firehose:PutRecord', 'firehose:PutRecordBatch'],\n  resources: [firehose.attrArn]\n}));\n```\n\n## Follow-up Questions\n- How would you validate coverage and detect delivery failures across accounts?\n- What changes would you make to handle a new region or account being added?","diagram":null,"difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Salesforce","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:35:57.950Z","createdAt":"2026-01-13T08:35:57.950Z"},{"id":"q-675","question":"You manage a two-region AWS deployment (us-east-1, us-west-2) behind an ALB with private subnets, NAT gateway, and RDS in us-east-1. During business hours, us-west-2 exhibits spike in 5xx errors and higher latency. Outline immediate incident triage steps, AWS CLI commands to run, how you’d identify root causes (NAT saturation, DNS routing, cross-region replication lag), and both short- and long-term mitigations with verification steps?","answer":"Start by verifying scope in CloudWatch and X-Ray, then check ALB target health, NAT gateway quotas, and RDS latency across regions. Collect logs, compare regional error rates, and run a quick failover","explanation":"## Why This Is Asked\nThis question evaluates incident triage skills in a real multi-region AWS setup, focusing on identifying root causes under pressure, deciding rapid mitigations, and confirming with telemetry. It tests familiarity with ALB, NAT, RDS, Route53, and CloudWatch/X-Ray.\n\n## Key Concepts\n- Multi-region deployment\n- Incident triage\n- ALB, NAT gateway, RDS latency\n- CloudWatch, VPC Flow Logs, X-Ray\n- DR planning\n\n## Code Example\n```javascript\n// Pseudo-logic for triage steps in a real incident\nfunction triage(incident) {\n  // fetch metrics from CloudWatch and X-Ray\n  // check ALB target health and NAT quotas\n  // identify root cause and apply mitigation\n}\n```\n\n## Follow-up Questions\n- Which metrics would you alert on for cross-region failures?\n- How would you automate the triage workflow?","diagram":"flowchart TD\n  A[Incident] --> B[Triage]\n  B --> C{Root Cause?}\n  C --> D[NAT Saturation]\n  C --> E[DNS/Routing]\n  C --> F[RDS/Replication Lag]\n  D --> G[Mitigate: scale NAT]\n  E --> H[Mitigate: Route53 routing]\n  F --> I[Mitigate: DR drill]","difficulty":"intermediate","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T14:46:56.102Z","createdAt":"2026-01-11T14:46:56.102Z"},{"id":"q-982","question":"Design an automated cross-region disaster recovery plan for a globally distributed web app currently active in us-east-1 with a DR site in us-west-2, covering RDS, DynamoDB, S3, and ALB-backed frontend. Specify data synchronization, failover steps, testing, and rollback?","answer":"Cross-region DR plan with a warm DR in us-west-2. DynamoDB Global Tables for multi-region writes; RDS cross-region read replicas with automatic failover; S3 Cross-Region Replication for objects; Route","explanation":"## Why This Is Asked\nTests practical DR thinking across AWS services, including data consistency, failover automation, and testing.\n\n## Key Concepts\n- Cross-region DR strategies and RTO/RPO\n- Data synchronization for RDS, DynamoDB, and S3\n- Automation with Step Functions/SSM for failover\n\n## Code Example\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  DRStateMachine:\n    Type: AWS::StepFunctions::StateMachine\n    Properties:\n      DefinitionString: |\n        {\n          \"Comment\": \"DR failover\",\n          \"StartAt\": \"PromoteDRRDS\",\n          \"States\": {\n            \"PromoteDRRDS\": {\"Type\": \"Task\", \"Resource\": \"arn:aws:states:::rds:promoteReadReplica\"}\n          }\n        }\n```\n\n## Follow-up Questions\n- How would you test RPO guarantees for DynamoDB Global Tables?\n- What are potential pitfalls with Route 53 failover in multi-Region deployments?","diagram":"flowchart TD\nA[Primary Region us-east-1] --> B{Healthy?}\nB -- Yes --> C[Normal traffic]\nB -- No --> D[Failover to us-west-2]\nD --> E[Promote DR RDS; re-point ALB; update DynamoDB endpoints]\nE --> F[Run DR tests and verify]\nF --> G[Record results and rollback if needed]","difficulty":"advanced","tags":["aws-sysops"],"channel":"aws-sysops","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:45:18.021Z","createdAt":"2026-01-12T17:45:18.021Z"},{"id":"aws-sysops-monitoring-logging-1768181358641-0","question":"In a three-tier web application deployed on EC2 behind an Application Load Balancer, you want to automatically recover a degraded instance by running a remediation runbook that stops the unhealthy instance and boots a replacement from a launch template. Which AWS service is designed for creating and executing such remediation runbooks?","answer":"[{\"id\":\"a\",\"text\":\"AWS CloudFormation\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"AWS Systems Manager Automation\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"AWS Lambda\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"AWS Config\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**Correct**: AWS Systems Manager Automation is designed for creating and executing remediation runbooks that can perform actions like stopping the unhealthy instance and launching a replacement. \n\n## Why Other Options Are Wrong\n- Option A is incorrect because CloudFormation is a provisioning service, not a runtime remediation engine for automated incident response. \n- Option C is plausible for lightweight responses but requires custom wiring; it does not provide built-in, centralized remediation runbooks like Systems Manager Automation. \n- Option D is incorrect because AWS Config focuses on configuration compliance and automated remediation is not its primary capability without additional services.\n\n## Key Concepts\n- Remediation runbooks (Automation Documents)\n- Integration with CloudWatch/EventBridge for automated execution\n- Operational responses to runtime issues in EC2 environments\n\n## Real-World Application\nIf an instance remains degraded, an Automation Document can stop the unhealthy instance and launch a new one from a launch template, then update the ASG or routing as needed to restore healthy traffic.","diagram":null,"difficulty":"intermediate","tags":["AWS Systems Manager","Automation","Remediation","EC2","SSM","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:18.642Z","createdAt":"2026-01-12 01:29:19"},{"id":"aws-sysops-monitoring-logging-1768181358641-1","question":"You manage a multi-account AWS environment and need to centralize all application logs into a central account for compliance and quick analysis. Which approach provides secure, scalable ingestion across accounts while preserving log integrity?","answer":"[{\"id\":\"a\",\"text\":\"Use CloudWatch Logs export to S3 in each account and consolidate manually\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use cross-account CloudWatch Logs subscription filters to deliver to a central account's Kinesis Data Firehose\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Enable VPC Flow Logs to deliver to a central account's S3 bucket via cross-account role\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use CloudTrail Organization Trail to aggregate logs in a central account\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**Correct**: Use cross-account CloudWatch Logs subscription filters to deliver to a central account's Kinesis Data Firehose. This provides real-time, scalable ingestion to a central sink while preserving log integrity and enabling centralized processing/forwarding. \n\n## Why Other Options Are Wrong\n- Option A is slower and error-prone due to manual consolidation and lacks real-time streaming at scale. \n- Option C describes VPC Flow Logs, which cover network flow data but are not a general application log pipeline and require separate handling for centralization. \n- Option D describes CloudTrail logs, which are audit trails and not a comprehensive application log stream for centralized analytics. \n\n## Key Concepts\n- Cross-account log subscriptions\n- Centralized log processing with Kinesis Firehose\n- Real-time, scalable log ingestion across accounts\n\n## Real-World Application\nIn a multi-account org, configure each member account to publish logs to a central account via a cross-account subscription, with Firehose delivering to S3 and OpenSearch for centralized search and audits.","diagram":null,"difficulty":"intermediate","tags":["CloudWatch Logs","Cross-Account","Log Aggregation","Kinesis Firehose","AWS","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:19.185Z","createdAt":"2026-01-12 01:29:19"},{"id":"aws-sysops-monitoring-logging-1768181358641-2","question":"You have an EC2 Auto Scaling group behind an Application Load Balancer. A CloudWatch alarm monitors CPUUtilization and triggers when it exceeds 80% for 5 minutes. You want the environment to automatically scale out to maintain performance without writing custom code. Which AWS feature should you configure to accomplish this?","answer":"[{\"id\":\"a\",\"text\":\"Create an Auto Scaling policy tied to the CloudWatch alarm\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Create a Lambda function to monitor the alarm and launch new instances\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Create an SSM Automation document to scale out\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create a CloudWatch Logs Insights query to trigger scaling\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**Correct**: Create an Auto Scaling policy tied to the CloudWatch alarm. Auto Scaling can automatically add capacity when the alarm is breached, without custom code. \n\n## Why Other Options Are Wrong\n- Option B describes a custom solution that adds code; while feasible, it’s not the simplest built-in path. \n- Option C is not the standard path for dynamic scaling; SSM is for management tasks, not scaling. \n- Option D is incorrect because CloudWatch Logs Insights queries are for analyzing log data, not real-time metric-driven scaling. \n\n## Key Concepts\n- CloudWatch alarms triggering Auto Scaling policies\n- Automated in-region scaling based on metric thresholds\n\n## Real-World Application\nConfigure an ASG with a target tracking or step scaling policy linked to a CPUUtilization > 80% alarm to automatically scale out when demand increases.","diagram":null,"difficulty":"intermediate","tags":["Auto Scaling","CloudWatch","EC2","Performance","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T01:29:19.688Z","createdAt":"2026-01-12 01:29:19"},{"id":"aws-sysops-monitoring-logging-1768286029090-0","question":"An EC2 Auto Scaling group hosts your web application; during peak hours CPUUtilization exceeds the threshold for an extended period. Which configuration best enables automatic scale-out plus on-call notification?","answer":"[{\"id\":\"a\",\"text\":\"Create a CloudWatch Alarm on CPUUtilization and attach an Auto Scaling policy with an SNS notification\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable CloudWatch Logs Insights on the ASG to automatically scale based on a query\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Configure CloudTrail to trigger scaling events when CPUUtilization exceeds threshold\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Apply an AWS Config rule to auto-scale the ASG\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because CloudWatch alarms can monitor EC2 metrics, trigger Auto Scaling policies to scale out, and publish notifications via SNS to on-call channels.\n\n## Why Other Options Are Wrong\n- Option b: CloudWatch Logs Insights analyzes log data, not real-time metric-based scaling.\n- Option c: CloudTrail records API calls, not metric thresholds for scaling.\n- Option d: AWS Config tracks configuration changes, not automatic scaling actions.\n\n## Key Concepts\n- CloudWatch Alarms\n- Auto Scaling policies\n- SNS notifications\n\n## Real-World Application\nTeams use this pattern to automatically handle traffic surges while keeping on-call staff informed via alerts.\n","diagram":null,"difficulty":"intermediate","tags":["AWS CloudWatch","Auto Scaling","EC2","SNS","CloudWatch Alarms","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:33:49.091Z","createdAt":"2026-01-13 06:33:49"},{"id":"aws-sysops-monitoring-logging-1768286029090-1","question":"To enforce security governance for S3 bucket public access and automatically remediate misconfigurations across accounts, which approach is best?","answer":"[{\"id\":\"a\",\"text\":\"Create an AWS Config rule that detects public access and triggers an AWS Systems Manager Automation document to remediate ACLs and notify on SNS\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable CloudTrail Insights to detect misconfigurations and require manual remediation\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use CloudWatch to monitor bucket size and automatically enforce access controls\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rely on S3 Access Analyzer reports with no automated remediation\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because AWS Config can continuously evaluate S3 configurations across accounts, and when a misconfiguration is detected, AWS Systems Manager Automation can automatically remediate ACLs while notifications keep operators informed.\n\n## Why Other Options Are Wrong\n- Option b: CloudTrail Insights focuses on API patterns, not direct configuration remediation.\n- Option c: CloudWatch monitoring bucket size does not address public access configurations.\n- Option d: Access Analyzer helps detect issues but does not automate remediations by itself.\n\n## Key Concepts\n- AWS Config Rules\n- AWS Systems Manager Automation\n- S3 Public Access configuration\n\n## Real-World Application\nThis pattern provides continuous governance with automatic fixes, reducing the window of exposure from misconfigurations.\n","diagram":null,"difficulty":"intermediate","tags":["AWS Config","S3","S3 Access Analyzer","SSM Automation","SNS","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:33:49.447Z","createdAt":"2026-01-13 06:33:49"},{"id":"aws-sysops-monitoring-logging-1768286029090-2","question":"To achieve near real-time centralized logging across multiple AWS accounts for analytics, which pipeline is most effective?","answer":"[{\"id\":\"a\",\"text\":\"Set up CloudWatch Logs cross-account subscriptions to a central OpenSearch domain via a Kinesis Data Firehose delivery stream\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable CloudTrail Insights across accounts and run manual queries\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store logs in S3 and run Athena dashboards\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use AWS Config aggregator for log data\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because CloudWatch Logs can be subscribed across accounts to a central destination, and delivering them through Kinesis Data Firehose to OpenSearch enables near real-time analytics and centralized visibility.\n\n## Why Other Options Are Wrong\n- Option b: CloudTrail Insights is for anomaly detection in API usage, not real-time log analytics across accounts.\n- Option c: S3 + Athena is batch-oriented and not real-time analytics.\n- Option d: AWS Config aggregator focuses on configuration snapshots, not centralized application logs.\n\n## Key Concepts\n- Cross-account CloudWatch Logs subscriptions\n- Kinesis Data Firehose\n- OpenSearch (Elasticsearch) analytics\n\n## Real-World Application\nThis pattern supports security and operations teams by providing a unified view of logs from all accounts for rapid detection and investigation.\n","diagram":null,"difficulty":"intermediate","tags":["AWS CloudWatch","OpenSearch","Kinesis Data Firehose","CloudWatch Logs","Cross-Account","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:33:49.786Z","createdAt":"2026-01-13 06:33:49"},{"id":"aws-sysops-monitoring-logging-1768286029090-3","question":"An ECS service experiences intermittent task failures during deployment; you want to automatically remediate by restarting failed tasks and minimize downtime. Which approach is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Enable ECS deployment circuit breaker and set minimum healthy percent to automatically roll back or restart failed tasks\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Configure AWS Config remediation for ECS\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use CloudWatch Logs Insights to identify failures and manually restart tasks\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use an S3 event to trigger a remediation workflow\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because ECS deployment circuit breaker, together with a proper minimum healthy percent, allows automatic rollback or replacement of failed tasks during deployments, reducing downtime.\n\n## Why Other Options Are Wrong\n- Option b: AWS Config remediation is for configuration drift, not immediate deployment failure remediation.\n- Option c: Manual intervention defeats automatic remediation during deployments.\n- Option d: S3 events are unrelated to ECS deployment failures.\n\n## Key Concepts\n- ECS deployment circuit breaker\n- Deployment configuration (minimum healthy percent)\n\n## Real-World Application\nThis approach minimizes user-visible downtime during deployments by automatically handling unhealthy tasks.\n","diagram":null,"difficulty":"intermediate","tags":["AmazonECS","Deployment","ECS Deployment Circuit Breaker","CloudWatch","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:33:49.911Z","createdAt":"2026-01-13 06:33:50"},{"id":"aws-sysops-monitoring-logging-1768286029090-4","question":"Your EKS cluster experiences variable workloads, and you need to automatically scale node groups based on pod resource requests while collecting container metrics in CloudWatch. Which approach best accomplishes this?","answer":"[{\"id\":\"a\",\"text\":\"Enable Kubernetes Cluster Autoscaler and integrate with AWS Auto Scaling groups; enable CloudWatch Container Insights for metrics\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable AWS Config remediation for EKS\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on CloudWatch Logs for automatic node scaling decisions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use S3 lifecycle rules to scale worker nodes\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because the Kubernetes Cluster Autoscaler dynamically adjusts the number of nodes in the node group based on pending pods and resource requests, and CloudWatch Container Insights provides observable metrics to inform scaling decisions.\n\n## Why Other Options Are Wrong\n- Option b: AWS Config remediation does not scale nodes or collect container metrics.\n- Option c: CloudWatch Logs are for log data, not real-time scaling decisions.\n- Option d: S3 lifecycle rules do not affect Kubernetes node scaling.\n\n## Key Concepts\n- Kubernetes Cluster Autoscaler\n- AWS Auto Scaling groups integration\n- CloudWatch Container Insights\n\n## Real-World Application\nThis pattern ensures responsive infrastructure that aligns with actual workload, improving cost efficiency and performance.\n","diagram":null,"difficulty":"intermediate","tags":["AmazonEKS","Cluster Autoscaler","CloudWatch Container Insights","Auto Scaling","Kubernetes","certification-mcq","domain-weight-20"],"channel":"aws-sysops","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:33:50.202Z","createdAt":"2026-01-13 06:33:50"},{"id":"aws-sysops-networking-1768228200651-0","question":"When a VPC has private subnets that must access S3 without using a NAT instance or public IP, which AWS feature enables this private access?","answer":"[{\"id\":\"a\",\"text\":\"VPC Endpoint (Gateway) for S3\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"NAT Gateway\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Internet Gateway\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Interface VPC Endpoint for S3\",\"isCorrect\":false}]","explanation":"## Correct Answer\nVPC Endpoint (Gateway) for S3 provides private connectivity from the VPC to S3 without traffic traversing the internet.\n\n## Why Other Options Are Wrong\n- NAT Gateway would still route traffic to the internet via a public IP, defeating the private access requirement.\n- Internet Gateway exposes resources to the internet and requires public access.\n- Interface VPC Endpoints are not used for S3; S3 connectivity uses gateway endpoints for private access via PrivateLink.\n\n## Key Concepts\n- VPC Endpoints: gateway type enables private connections to S3 and DynamoDB; no public internet path required.\n- Route tables and policy control access from subnets to the endpoint.\n\n## Real-World Application\n- Use this pattern to allow private subnets to access S3 securely without NAT or public internet exposure.","diagram":null,"difficulty":"intermediate","tags":["AWS S3","AWS VPC","VPC Endpoints","AWS PrivateLink","Networking","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"networking","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:30:00.653Z","createdAt":"2026-01-12 14:30:01"},{"id":"aws-sysops-networking-1768228200651-1","question":"Which configuration best ensures CloudFront delivers content from an S3 bucket while preventing direct internet access to the bucket?","answer":"[{\"id\":\"a\",\"text\":\"Use an Origin Access Identity and a bucket policy that allows only CloudFront\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable public read on the bucket\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use CloudFront with signed URLs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use S3 bucket ACLs granting public read\",\"isCorrect\":false}]","explanation":"## Correct Answer\nCreate an Origin Access Identity (OAI) for CloudFront and configure a bucket policy that only allows CloudFront to access the S3 bucket. This keeps the bucket private while still serving via CloudFront.\n\n## Why Other Options Are Wrong\n- Enabling public read exposes the bucket to the internet.\n- CloudFront signed URLs are optional security but do not inherently restrict S3 bucket access to CloudFront.\n- S3 bucket ACLs granting public read bypass the intended private access model.\n\n## Key Concepts\n- CloudFront OAI; bucket policy referencing the OAI principal; block public access.\n- Principle of least privilege for S3 access when used with CloudFront.\n\n## Real-World Application\n- Use OAI-based access control to serve static content securely from S3 through CloudFront in production.","diagram":null,"difficulty":"intermediate","tags":["AWS CloudFront","AWS S3","Origin Access Identity","Networking","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"networking","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:30:01.112Z","createdAt":"2026-01-12 14:30:01"},{"id":"aws-sysops-networking-1768228200651-2","question":"To route users to the region with the lowest latency and ensure traffic goes only to healthy endpoints, which Route 53 configuration is appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Latency-based routing with health checks\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Geolocation routing with no health checks\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Weighted routing with static failover\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Failover routing without health checks\",\"isCorrect\":false}]","explanation":"## Correct Answer\nLatency-based routing with health checks ensures Route 53 sends users to the lowest-latency region and avoids unhealthy endpoints.\n\n## Why Other Options Are Wrong\n- Geolocation routing may direct users based on location rather than latency and may not reflect current performance.\n- Weighted routing with static failover does not optimize for latency.\n- Failover routing without health checks cannot detect endpoint failures reliably.\n\n## Key Concepts\n- Latency-based routing; health checks; DNS failover.\n\n## Real-World Application\n- Essential for multi-region apps needing optimal user experience and resilience.","diagram":null,"difficulty":"intermediate","tags":["AWS Route 53","DNS","Networking","AWS Global","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"networking","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:30:01.570Z","createdAt":"2026-01-12 14:30:01"},{"id":"aws-sysops-networking-1768228200651-3","question":"To provide a fixed set of globally reachable IPs and improve failover across AWS Regions for a global application, which AWS service should you use?","answer":"[{\"id\":\"a\",\"text\":\"CloudFront\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"AWS Global Accelerator\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Route 53\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Direct Connect\",\"isCorrect\":false}]","explanation":"## Correct Answer\nAWS Global Accelerator provides static anycast IP addresses that front your apps and optimize route selection across regions, improving failover and consistency.\n\n## Why Other Options Are Wrong\n- CloudFront is a CDN with edge caching, not fixed global IPs for origin failover.\n- Route 53 is DNS-based and does not provide fixed client-facing IPs.\n- Direct Connect is a private network connection to on-premises data centers, not global AWS-region routing.\n\n## Key Concepts\n- Static anycast IPs; regional health checks; fast failover.\n\n## Real-World Application\n- Use Global Accelerator to improve user experience for globally distributed users and reduce failover latency.","diagram":null,"difficulty":"intermediate","tags":["AWS Global Accelerator","AWS Route 53","Networking","AWS Cloud","certification-mcq","domain-weight-18"],"channel":"aws-sysops","subChannel":"networking","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:30:01.731Z","createdAt":"2026-01-12 14:30:01"},{"id":"aws-sysops-reliability-1768235174193-0","question":"For a mission-critical application with an RTO of approximately 60 minutes and an RPO of 15 minutes, which DR strategy provides a balance between recovery speed and cost by maintaining a scaled-down standby in a secondary region?","answer":"[{\"id\":\"a\",\"text\":\"Pilot light\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Warm standby\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Cold standby\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Hot standby\",\"isCorrect\":false}]","explanation":"**Correct Answer**\n\nWarm standby provides a scaled-down, ready-to-activate environment in a secondary region with ongoing data replication, balancing recovery speed and cost for the given RTO/RPO.\n\n**Why Other Options Are Wrong**\n\n- Pilot light: offers minimal active readiness and generally results in longer recovery time than warm standby.\n- Cold standby: requires provisioning most components after a disruption, causing longer downtime.\n- Hot standby: fully provisioned in advance and typically more costly; while fastest to recover, it is not the most cost-effective balance for the stated RTO/RPO.\n\n**Key Concepts**\n\n- Disaster Recovery patterns: pilot light, warm standby, cold standby, hot standby.\n- RTO and RPO definitions and trade-offs.\n\n**Real-World Application**\n\n- Use warm standby when you need quicker recovery than pilot light but want to avoid the higher cost of a full hot standby site; schedule regular failover drills to validate RTO targets.","diagram":null,"difficulty":"intermediate","tags":["AWS","DR","DisasterRecovery","Multi-Region","RTO","RPO","EC2","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:14.195Z","createdAt":"2026-01-12 16:26:14"},{"id":"aws-sysops-reliability-1768235174194-1","question":"A relational database requires automatic failover to a synchronous standby within the same AWS region to achieve high availability. Which AWS feature provides this?","answer":"[{\"id\":\"a\",\"text\":\"RDS Multi-AZ\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"RDS Read Replica\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"DynamoDB Global Tables\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Aurora Global Database\",\"isCorrect\":false}]","explanation":"**Correct Answer**\n\nRDS Multi-AZ provides automatic failover to a synchronous standby across different AZs within the same region, enabling high availability for relational databases.\n\n**Why Other Options Are Wrong**\n\n- RDS Read Replica: typically asynchronous and used for scaling read traffic, not automatic failover.\n- DynamoDB Global Tables: for NoSQL multi-region replication, not a relational DB failover feature.\n- Aurora Global Database: enables cross-region replication and global reads, not automatic regional failover in a single region setup.\n\n**Key Concepts**\n\n- High availability strategies for relational databases in AWS.\n- Synchronous vs asynchronous replication.\n\n**Real-World Application**\n\n- Use RDS Multi-AZ for mission-critical relational workloads where automatic failover within the region minimizes downtime during AZ failures.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","Multi-AZ","HA","Failover","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:14.776Z","createdAt":"2026-01-12 16:26:15"},{"id":"aws-sysops-reliability-1768235174194-2","question":"To validate a DR plan without impacting production systems, which approach is most recommended?","answer":"[{\"id\":\"a\",\"text\":\"Run DR tests directly in production during peak hours\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use a dedicated DR account with replicated data and periodic failover drills\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely only on backup restoration tests in a cold environment\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Perform automated canary tests in production with traffic shifting\",\"isCorrect\":false}]","explanation":"**Correct Answer**\n\nA dedicated DR account with replicated data allows safe, isolated failover drills without impacting production environments, enabling realistic testing of recovery procedures.\n\n**Why Other Options Are Wrong**\n\n- Running tests in production can disrupt services and affect users.\n- Relying only on backup restoration tests in a cold environment does not validate the full DR workflow or RTO/RPO in practice.\n- Canary tests in production risk introducing instability if the test affects live traffic.\n\n**Key Concepts**\n\n- DR testing in isolated environments.\n- Data replication across accounts for DR drills.\n\n**Real-World Application**\n\n- Establish annual or quarterly DR drills in a separate AWS account with mirrored data to verify processes and roles without production impact.","diagram":null,"difficulty":"intermediate","tags":["AWS","DR","Testing","Accounts","BusinessContinuity","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:15.326Z","createdAt":"2026-01-12 16:26:15"},{"id":"aws-sysops-reliability-1768235174194-3","question":"To guard against accidental or malicious deletion of backups stored in S3, which combination provides the strongest protection?","answer":"[{\"id\":\"a\",\"text\":\"Enable Versioning and MFA Delete\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable Versioning only\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable Object Lock in Governance mode\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable Cross-Region Replication\",\"isCorrect\":false}]","explanation":"**Correct Answer**\n\nEnabling Versioning ensures multiple object versions are kept, and MFA Delete requires an additional MFA for delete operations, providing strong protection against accidental or malicious deletions.\n\n**Why Other Options Are Wrong**\n\n- Versioning only does not require MFA for deletions.\n- Object Lock in Governance mode provides retention via policy, but MFA Delete adds an extra layer for delete operations and can be used in everyday workflows.\n- Cross-Region Replication protects against regional failures but does not protect against deletions in the source bucket.\n\n**Key Concepts**\n\n- S3 Versioning and MFA Delete concepts.\n- Data protection against deletion and data loss.\n\n**Real-World Application**\n\n- Use Versioning with MFA Delete on backup buckets to meet compliance and reduce risk of data loss due to human error or malicious actions.","diagram":null,"difficulty":"intermediate","tags":["AWS","S3","Versioning","MFADelete","DataProtection","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:15.508Z","createdAt":"2026-01-12 16:26:15"},{"id":"aws-sysops-reliability-1768235174194-4","question":"For a globally distributed, write-heavy NoSQL workload requiring near real-time cross-region updates, which AWS feature enables multi-region, multi-master replication with low RPO?","answer":"[{\"id\":\"a\",\"text\":\"RDS Multi-AZ\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"DynamoDB Global Tables\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"S3 Cross-Region Replication\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Neptune Global Databases\",\"isCorrect\":false}]","explanation":"**Correct Answer**\n\nDynamoDB Global Tables provide multi-region, multi-master replication for NoSQL workloads, enabling near real-time updates and low RPO across regions.\n\n**Why Other Options Are Wrong**\n\n- RDS Multi-AZ is for relational databases and within a single region, not suitable for global multi-region writes.\n- S3 Cross-Region Replication is for object storage replication, not a multi-master database pattern.\n- Neptune Global Databases address graph databases but are not the standard solution for wide-scale NoSQL write-heavy workloads.\n\n**Key Concepts**\n\n- DynamoDB Global Tables multi-region replication.\n- Multi-master write availability and RPO considerations.\n\n**Real-World Application**\n\n- Use DynamoDB Global Tables for globally distributed applications requiring low latency and consistent updates across regions.","diagram":null,"difficulty":"intermediate","tags":["AWS","DynamoDB","GlobalTables","NoSQL","MultiRegion","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"reliability","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:15.703Z","createdAt":"2026-01-12 16:26:15"},{"id":"aws-sysops-security-compliance-1768252855511-0","question":"A company wants to ensure that every new S3 bucket has server-side encryption enabled and to automatically remediate any bucket created without encryption. Which control provides the most reliable, scalable solution?","answer":"[{\"id\":\"a\",\"text\":\"Enable a bucket policy requiring SSE on PutObject\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Configure AWS Config with the managed rule s3-bucket-server-side-encryption-enabled and enable auto-remediation\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Enable GuardDuty findings for S3 and alert on unencrypted buckets\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use CloudTrail to log S3 data events and monitor encryption status\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is B. AWS Config with the managed rule s3-bucket-server-side-encryption-enabled provides ongoing evaluation of bucket encryption status and, with auto-remediation, can automatically enforce encryption on new buckets. This scales across many accounts.\n\n## Why Other Options Are Wrong\n- Option A could enforce encryption at the bucket or object level but does not automatically remediate and may be bypassed for non-object operations.\n- Option C GuardDuty focuses on threat detection, not enforcement of encryption on buckets.\n- Option D CloudTrail records API activity but does not itself enforce or remediate encryption settings.\n\n## Key Concepts\n- AWS Config managed rules\n- s3-bucket-server-side-encryption-enabled\n- Auto-remediation\n- Server-Side Encryption (SSE-S3/SSE-KMS)\n\n## Real-World Application\nUsed to baseline and automatically correct new buckets to ensure encryption compliance at scale across many accounts.","diagram":null,"difficulty":"intermediate","tags":["AWS Config","S3","KMS","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:20:55.512Z","createdAt":"2026-01-12 21:20:55"},{"id":"aws-sysops-security-compliance-1768252855511-1","question":"You run AWS accounts across an Organization; you want all API activity to be captured and stored centrally in a security account. Which option achieves centralized logging with minimal configuration and best practices?","answer":"[{\"id\":\"a\",\"text\":\"Create a CloudTrail per account and manually copy logs to a central bucket\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a single CloudTrail Organization trail that writes to a central S3 bucket in a designated security account\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use AWS Config for all event log storage\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable S3 access logs on buckets and aggregate\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct. A CloudTrail Organization trail delivers all API activity across accounts to a single central S3 bucket, simplifying governance and retention.\n\n## Why Other Options Are Wrong\n- Option A is error-prone and harder to maintain at scale.\n- Option C AWS Config tracks resource configuration changes, not comprehensive API activity logging.\n- Option D S3 access logs only cover bucket-level access, not API calls across services.\n\n## Key Concepts\n- CloudTrail Organization trails\n- Centralized log storage\n- Cross-account access and IAM permissions for log delivery\n\n## Real-World Application\nIdeal for SOC, compliance audits, and centralized incident response across multiple AWS accounts.","diagram":null,"difficulty":"intermediate","tags":["CloudTrail","AWS Organizations","S3","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:20:56.054Z","createdAt":"2026-01-12 21:20:56"},{"id":"aws-sysops-security-compliance-1768252855511-2","question":"In an AWS Organization, you need to enforce MFA for all IAM user actions across member accounts. Which mechanism is most effective?","answer":"[{\"id\":\"a\",\"text\":\"Attach an IAM policy to all users requiring MFA for sensitive actions\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a Service Control Policy that denies all actions unless aws:MultiFactorAuthPresent is true\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Require MFA by enabling MFA delete on S3 buckets\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use AWS Identity Center to enforce MFA\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct. An Organization SCP can centrally deny all actions unless MFA is present, providing scalable enforcement across all member accounts.\n\n## Why Other Options Are Wrong\n- Option A is not scalable across many accounts and may be bypassed for service actions not covered by the policy.\n- Option C MFA delete applies to S3 object deletion, not general IAM API actions.\n- Option D AWS Identity Center can enforce MFA for sign-in but does not centrally deny API actions across all services in all accounts like an SCP does.\n\n## Key Concepts\n- Service Control Policies (SCPs)\n- MFA enforcement in Organizations\n- Centralized security baselines\n\n## Real-World Application\nApply a baseline MFA requirement across all accounts to reduce risk from non-MFA access.","diagram":null,"difficulty":"intermediate","tags":["AWS Organizations","SCP","MFA","IAM","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:20:56.592Z","createdAt":"2026-01-12 21:20:56"},{"id":"aws-sysops-security-compliance-1768252855511-3","question":"Baseline security requires that all new EBS volumes are encrypted by default. Which approach achieves this with the least ongoing operational effort?","answer":"[{\"id\":\"a\",\"text\":\"Enable EBS encryption by default in the account\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Create an IAM policy that denies volume creation unless encryption is true\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a CloudFormation guard to enforce encryption on all volumes\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable AWS Config rule ebs-volume-encrypted with manual remediation\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. Enabling EBS encryption by default ensures all new volumes are encrypted without requiring per-resource configuration or extensive remediation logic.\n\n## Why Other Options Are Wrong\n- Option B may deter creation of unencrypted volumes but relies on policy accuracy and may be bypassed in some scenarios.\n- Option C Guardrails via CloudFormation are more complex and may not apply retroactively.\n- Option D AWS Config can detect non-encrypted volumes but remediation for existing volumes is non-trivial and not guaranteed to enforce encryption automatically.\n\n## Key Concepts\n- EBS encryption by default\n- Baseline security controls\n- Operational simplicity\n\n## Real-World Application\nSets a strong, scalable baseline across accounts with minimal ongoing admin.","diagram":null,"difficulty":"intermediate","tags":["EBS","KMS","AWS Accounts","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:20:56.776Z","createdAt":"2026-01-12 21:20:56"},{"id":"aws-sysops-security-compliance-1768252855511-4","question":"You need to rotate a database credential secret in AWS Secrets Manager for an RDS instance that uses IAM authentication. Which architecture best ensures rotation occurs automatically and securely?","answer":"[{\"id\":\"a\",\"text\":\"Use Secrets Manager automatic rotation with a pre-built Lambda function for RDS; configure rotation to occur on a schedule\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Manually rotate the password in the RDS console and update the secret\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use IAM roles to rotate credentials automatically\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use CloudFormation to rotate the secret weekly\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct. Secrets Manager supports automatic rotation for RDS using a pre-built Lambda function, which can be configured to rotate credentials on a defined schedule and update the secret transparently to clients.\n\n## Why Other Options Are Wrong\n- Option B is manual and error-prone; it defeats the purpose of automated rotation.\n- Option C IAM roles do not rotate database credentials within Secrets Manager.\n- Option D CloudFormation does not provide built-in rotation mechanisms for secrets; it only describes resources.\n\n## Key Concepts\n- Secrets Manager automatic rotation\n- Pre-built Lambda rotation function for RDS\n- Secure credential lifecycle management\n\n## Real-World Application\nAutomates credential management for database access, reducing drift and human error.","diagram":null,"difficulty":"intermediate","tags":["Secrets Manager","RDS","Lambda","Rotation","certification-mcq","domain-weight-16"],"channel":"aws-sysops","subChannel":"security-compliance","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:20:56.973Z","createdAt":"2026-01-12 21:20:57"}],"subChannels":["cost-optimization","deployment-provisioning","general","monitoring-logging","networking","reliability","security-compliance"],"companies":["Anthropic","Apple","Databricks","Google","MongoDB","Salesforce","Scale Ai","Snowflake"],"stats":{"total":34,"beginner":0,"intermediate":32,"advanced":2,"newThisWeek":34}}