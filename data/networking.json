{"questions":[{"id":"q-180","question":"What is the primary purpose of DNS in computer networking and how does it enable internet communication?","answer":"Translates human-readable domain names into IP addresses, enabling users to access websites using memorable names instead of numeric addresses.","explanation":"## Why Asked\nInterviewers ask this to test fundamental networking knowledge and understanding of how the internet resolves human-friendly names to machine-readable addresses.\n\n## Key Concepts\n- Domain Name System (DNS) hierarchy\n- DNS resolution process\n- IP address mapping\n- DNS caching and performance\n\n## Code Example\n```\n# Basic DNS lookup using nslookup\nnslookup google.com\n# Returns: 172.217.14.238\n```\n\n## Follow-up Questions\n- What are the different types of DNS records?\n- How does DNS caching improve performance?\n- What happens when a DNS query fails?","diagram":"graph TD\n    A[User types www.example.com] --> B[Local DNS Cache]\n    B --> C{Cache hit?}\n    C -->|No| D[Recursive DNS Server]\n    C -->|Yes| E[Return IP Address]\n    D --> F[Root DNS Server]\n    F --> G[TLD Server .com]\n    G --> H[Authoritative DNS Server]\n    H --> I[Return IP Address]\n    I --> B\n    B --> E","difficulty":"beginner","tags":["dns","resolution"],"channel":"networking","subChannel":"dns","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=UVR9lhUGAyU","longVideo":"https://www.youtube.com/watch?v=27r4Bzuj5NQ"},"companies":["Amazon","Cisco","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["domain names","ip addresses","translation","resolution","hierarchical","internet","communication"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:27:02.182Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-1031","question":"In a beginner-friendly scenario, a REST API behind a global CDN shows sporadic 1–2s latency for some users while synthetic tests pass. Outline a practical, end-to-end diagnostic plan to isolate DNS, TLS, caching, and client-network factors, including concrete commands and data you would collect and an initial fix you would try?","answer":"Collect cross-network timings: DNS resolution with `dig +trace`, TCP connect and TLS handshake times and TTFB with `curl -w`. Inspect CDN edge cache status via response headers. Compare results from o","explanation":"## Why This Is Asked\nAssesses practical debugging chops for real-world network issues beyond theory.\n\n## Key Concepts\n- DNS resolution timing\n- TCP handshake and TLS behavior\n- CDN edge caching and cache-control\n- Time To First Byte and observability\n\n## Code Example\n```bash\n# Gather data across layers\n dig +trace example.com\n curl -w 'DNS=%{time_dns} CONNECT=%{time_connect} TTFB=%{time_starttransfer} TOTAL=%{time_total}\\n' -o /dev/null -s https://example.com/v1/items\n openssl s_client -servername example.com -connect example.com:443 -brief\n```\n\n## Follow-up Questions\n- How would you automate data collection across many clients?\n- How would you present findings to non-technical stakeholders?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T19:43:59.875Z","createdAt":"2026-01-12T19:43:59.875Z"},{"id":"q-1078","question":"In a small office network, a workstation intermittently cannot reach a public API behind Cloudflare during peak hours while other destinations are responsive; outline a practical, hands-on plan to diagnose using DNS (A/AAAA, TTLs), path tracing, TLS handshakes (ALPN/SNI), and edge routing behavior, with concrete mitigations to test?","answer":"Verify DNS resolution for the API (A/AAAA, TTLs) and confirm the edge IP matches Cloudflare's; run traceroute to the API to locate where hops drop or slow; measure TLS handshake timings with openssl s","explanation":"## Why This Is Asked\nThis question probes practical triage of real-world networking issues, focusing on DNS correctness, path inspection, TLS behavior, and edge routing – core skills for entry-level network roles at large tech companies.\n\n## Key Concepts\n- DNS: A/AAAA records, TTL behavior, split-horizon views\n- Path tracing: traceroute/mtr to identify problematic hops\n- TLS: handshake timing, ALPN, SNI, certificate validation\n- Edge/CDN routing: Cloudflare edge selection, regional failures, failover\n- Mitigations: path fixes, DNS tweaks, MTU adjustments\n\n## Code Example\n```bash\ndig +short A api.example.com\ndig +short AAAA api.example.com\ntraceroute api.example.com\nopenssl s_client -servername api.example.com -connect api.example.com:443 -brief\n```\n\n## Follow-up Questions\n- How would you script this triage to run on schedule?\n- How would you validate fixes after a deployment affects edge routing?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:35:31.002Z","createdAt":"2026-01-12T21:35:31.002Z"},{"id":"q-1089","question":"In a multi-region Kubernetes deployment using VXLAN overlays for pod networking, you notice intermittent packet loss and high tail latency when pods in region A talk to pods in region B. The overlay adds headers that push MTU beyond 1500 on inter-region links, causing fragmentation in some paths. You can adjust MTU, MSS clamping, and overlay parameters but cannot modify application code. How would you diagnose end-to-end and implement a robust fix that preserves ECMP load balancing and minimizes fragmentation? Provide concrete steps?","answer":"Diagnose with path MTU discovery (tracepath, tracepath6), ping -M do -s, vxlan MTU, and ECMP hashing checks. Fix by tuning: set VXLAN MTU to 1450–1470, enable MSS clamping on border routers, ensure DF","explanation":"## Why This Is Asked\nThe scenario mirrors real-world multi-region networks where overlay overhead and MTU issues hurt performance. It tests systematic troubleshooting and pragmatic fixes rather than theory.\n\n## Key Concepts\n- MTU/PMTU and how overlays add header overhead\n- VXLAN/VTEP MTU tuning and MSS clamping\n- ECMP hashing stability across overlays\n- DF bit handling and fragmentation avoidance\n- End-to-end diagnostics: path traces, packet captures\n\n## Code Example\n```bash\n# Example MTU validation commands\ntracepath -n dest.host\nping -c 20 -M do -s 1472 dest.host\n```\n\n## Follow-up Questions\n- How would you validate that ECMP hashing remains stable after MTU changes?\n- What are trade-offs of shrinking MTU vs enabling fragmentation in practice?\n- How would you automate regression checks for MTU-related path changes?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:21:43.899Z","createdAt":"2026-01-12T22:21:43.899Z"},{"id":"q-1163","question":"In a two-region service, IPv6 clients report higher latency and intermittent timeouts to a TLS-enabled API when accessed from IPv6 only networks. You cannot modify app code. Outline a practical diagnostic plan focusing on IPv6 path MTU discovery, ICMPv6/firewall behavior, and how to verify with traceroute6, tcpdump, and TLS handshake timings. Propose concrete mitigations like adjusting VPN MTU and enabling IPv4 fallback?","answer":"Procedure: collect traceroute6 output, path MTU, and TLS handshake timings from IPv6 paths; compare with IPv4; inspect firewall logs for ICMPv6 blocks; verify VPN MTU; test by lowering VPN MTU to 1280","explanation":"## Why This Is Asked\n\nTests IPv6 end-to-end debugging in a practical setting.\n\n## Key Concepts\n\n- IPv6 path MTU discovery and 1280 MTU\n- ICMPv6 and firewall behavior\n- VPN MTU tuning\n- IPv6 fallback strategies\n\n## Code Example\n\n```javascript\n// Simple log parser to extract handshake timings\nfunction parseHandshakeTimings(lines){\n  const timings = [];\n  for (const line of lines){\n    const m = line.match(/TLS Handshake.*duration=(\\\\d+)/);\n    if (m) timings.push(parseInt(m[1],10));\n  }\n  return timings;\n}\n```\n\n## Follow-up Questions\n\n- What metrics would you monitor to confirm the root cause?\n- How would you validate mitigations across regions?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:30:25.405Z","createdAt":"2026-01-13T03:30:25.405Z"},{"id":"q-1232","question":"In a two-region deployment (us-east-1, eu-west-1) with a TLS-enabled API behind a global load balancer, peak hours yield p95 latency spikes to 350 ms while basic tests pass. No app changes allowed. Provide a concrete diagnostic plan to distinguish TLS handshake delays, ALPN/SNI issues, path MTU fragmentation, and load balancer behavior, with exact commands and data you’d collect?","answer":"Begin with cross-region baselines and TLS timings. Run curl -w '%time_connect %time_appconnect %time_total' -o /dev/null -sS https://api.example; capture TLS handshakes with tcpdump at edge and origin","explanation":"## Why This Is Asked\nTests practical debugging of regional latency under TLS without code changes.\n\n## Key Concepts\n- TLS handshake timings and ALPN/SNI\n- MTU/fragmentation and path MTU discovery\n- Load balancer behavior across regions\n- Baseline measurement and data collection\n\n## Code Example\n```javascript\ncurl -w \"%{time_connect} %{time_starttransfer} %{time_total}\\n\" -o /dev/null -sS https://api.example\n```\n\n## Follow-up Questions\n- How would you verify MTU consistency end-to-end?\n- What quick mitigations would you apply if MTU is the culprit?","diagram":"flowchart TD\n  Client --> DNS\n  DNS --> LB\n  LB --> Region\n  Region --> TLS\n  TLS --> App","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T06:30:13.994Z","createdAt":"2026-01-13T06:30:13.994Z"},{"id":"q-1461","question":"In a globally distributed API behind a CDN and global load balancer, Asia users report login latency significantly higher than North America, while overall API latency remains acceptable. The client app is mobile and uses TLS with SNI; no code changes are allowed. Outline a concrete diagnostic plan to determine whether ECS (EDNS Client Subnet), DNS TTL, CDN edge variance, or inter-region routing is responsible, including exact commands, data to collect, and initial mitigations to test?","answer":"Plan: collect per-region DNS data (A/AAAA, TTL, ECS), CDN cache headers, and edge RTTs. Use dig +trace, dig +subnet, and curl -I to capture DNS and HTTP metadata; curl -w to log TLS handshake timing f","explanation":"## Why This Is Asked\nTests practical CDN/DNS latency debugging, focusing on edge caching, ECS, and routing rather than app code.\n\n## Key Concepts\n- EDNS Client Subnet (ECS) and edge caching behavior\n- DNS TTL and resolver caching effects\n- CDN edge variance vs origin routing\n- Per-region RTT/disconnect timings via traceroute\n- Impact of inter-region routing on user experience\n\n## Code Example\n```javascript\n// Example: measure TLS handshake latency using fetch (conceptual)\nfetch('https://api.example-cdn/login')\n  .then(r => console.log('Status', r.status))\n  .catch(() => {});\n```\n\n## Follow-up Questions\n- How would ECS misconfiguration manifest in cache-hit rates across regions?\n- What low-friction tests would you run to validate a TTL adjustment on the CDN edge?","diagram":"flowchart TD\n  Asia[Asia clients] --> CDN[CDN edge]\n  CDN --> Origin[Origin server]\n  CDN --> NA[NA clients]\n  NA --> CDN","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","MongoDB","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T17:58:50.739Z","createdAt":"2026-01-13T17:58:50.739Z"},{"id":"q-1507","question":"In a globally distributed TLS-enabled API for real-time inference, traffic flows from Asia, EU, US behind a global load balancer and regional edge caches. During peak, Asia users see p95 latency spikes while NA remains stable. No code changes allowed. Provide a concrete diagnostic plan to distinguish between (1) TLS handshake/ALPN at edge vs origin, (2) inter-region routing and MTU fragmentation, (3) load balancer ECMP behavior, and (4) CDN edge miss penalties. Include exact commands, data to collect, and initial mitigations to test?","answer":"From Asia edge and NA edge, collect: (1) TLS handshake timing and ALPN with `openssl s_client -servername api.example.com -connect edge:443 -brief`; (2) ALPN/HTTP2 and TLS details with `curl -Iv https","explanation":"## Why This Is Asked\n\nReal-world cross-region latency often stems from TLS negotiations, MTU issues, and CDN/LB interplay rather than app code. This question probes a candidate's ability to design concrete experiments and identify root causes across layers.\n\n## Key Concepts\n\n- TLS handshakes, ALPN/SNI\n- Path MTU and fragment-free discovery\n- ECMP & LB behavior across regions\n- CDN edge vs origin traffic patterns\n\n## Code Example\n\n```bash\n#!/usr/bin/env bash\nHOST=api.example.com\nEDGE=asia.edge.local\nopenssl s_client -servername $HOST -connect $EDGE:443 -brief\ncurl -Iv https://$HOST/health 2>&1 | tee health.log\ntracepath $EDGE\ntracepath6 $EDGE\nmtr -rwzbd $EDGE $HOST\n```\n\n## Follow-up Questions\n\n- How would you validate TLS session resumption actually reduces latency?\n- What metrics would you monitor to detect regressive MTU changes?\n","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","OpenAI","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T19:44:50.616Z","createdAt":"2026-01-13T19:44:50.616Z"},{"id":"q-1671","question":"In a multi-cloud microservice mesh spanning AWS and Azure, inter-region service-to-service calls intermittently fail under load with rising p95 latencies. Tracing shows ECMP paths changing mid-request and MTU-related fragmentation on some hops. Without modifying applications, outline a concrete diagnostic plan and a stabilization strategy addressing PMTUD behavior, IPv4/IPv6 MTU alignment, ICMP blocking, and MTU discovery pitfalls across clouds, while preserving ECMP load balancing?","answer":"Instrument per-hop MTU tracing (tracepath/mtr), collect ICMP DF behavior, and compare overlay vs underlay MTUs across regions. Inspect VXLAN/ GRE tunnel MTU and NIC MTU; verify IPv4/IPv6 PMTUD availab","explanation":"## Why This Is Asked\n\nTests ability to diagnose cross-cloud MTU and ECMP issues without app changes, a common production pain point.\n\n## Key Concepts\n\n- Path MTU Discovery (PMTUD)\n- ICMP behavior and fragmentation control\n- Overlay underlay MTU alignment (VXLAN, GRE)\n- ECMP hashing stability across regions\n\n## Code Example\n\n```javascript\n// Conceptual snippet: parse traceroute outputs for MTU gaps\nfunction findMtuGaps(lines) {\n  return lines.filter(l => /Fragmentation Needed|MTU/.test(l));\n}\n```\n\n## Follow-up Questions\n\n- How would you verify ECMP fairness during MTU misalignment?\n- What changes to cloud networking would you propose to minimize fragmentation risk?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:56:32.830Z","createdAt":"2026-01-14T05:56:32.830Z"},{"id":"q-1766","question":"In a global data service using DNS-based global load balancing across us-east-1 and eu-west-1, cross-region reads spike latency during peak hours while intra-region calls remain fast. No app changes allowed. Outline a concrete diagnostic plan to distinguish stale DNS routing, BGP route flaps, and edge TLS termination delays, with exact commands and data you’d collect, interpretation rules, and recommended mitigations?","answer":"Plan: Collect DNS history (dig + trace, resolver IPs, TTLs); measure TLS handshake times (curl -Iv --resolve); run traceroute/MTR from multiple edge locations to both regional endpoints during peak; m","explanation":"## Why This Is Asked\n\nTests ability to diagnose cross-region latency factors beyond code, focusing on DNS routing, BGP dynamics, and edge termination.\n\n## Key Concepts\n\n- DNS-based global load balancing (GSLB) and TTL effects\n- BGP route flaps and ECMP implications\n- Edge TLS termination latency and TLS handshake timing\n- Traceroute/MTR for path visibility and latency attribution\n\n## Code Example\n\n```javascript\n// Example: parse DNS TTL history from logs\nfunction filterStaleTTL(entries){\n  return entries.filter(e => e.ttl && e.ttl > 60);\n}\n```\n\n## Follow-up Questions\n\n- How would you validate mitigations after peak?\n- What monitoring dashboards would you add or adjust to catch recurrence?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","NVIDIA","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T09:50:10.301Z","createdAt":"2026-01-14T09:50:10.301Z"},{"id":"q-2322","question":"In a global deployment using anycast DNS fronting a TLS-terminated API gateway, intermittent TLS handshake stalls and p95 latency spikes appear during peak hours. No app changes allowed. The client path crosses regions via regional load balancers and edge caches. Outline a concrete diagnostic plan to distinguish issues caused by anycast routing, TLS handshakes (ALPN, SNI, 0-RTT), and cross-region MTU/PMTUD behavior, plus a practical mitigation path?","answer":"Instrument handshake timings and per-hop latency across regions. Collect TLS timing with curl/openssl s_client, capture pcap, run traceroute/mtr from multiple clients, and correlate ALPN/SNI outcomes ","explanation":"## Why This Is Asked\nTests practical diagnostic skills for cross-region TLS and routing issues under pressure without changing apps.\n\n## Key Concepts\n- Anycast routing and ECMP path variability\n- TLS handshake timing, ALPN/SNI, and 0-RTT implications\n- Path MTU Discovery and PMTUD across CDN/edge and inter-region links\n- Edge load balancer behavior and cross-region routing stability\n- Data collection: per-hop latency, handshake timings, pcap, traceroute\n\n## Code Example\n```javascript\n// Example data collection helper (conceptual)\nconst run = require('child_process').execSync;\nconsole.log(run('curl -sS -D - https://edge.example/api -o /dev/null -w \"%{time_total}\\n\"').toString());\n```\n\n## Follow-up Questions\n- How would you validate a fix across both regions with minimal blast radius?\n- Which metrics dashboards or alerting rules would you introduce to catch this earlier?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","DoorDash","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T11:53:00.737Z","createdAt":"2026-01-15T11:53:00.737Z"},{"id":"q-2382","question":"In a regional microservice mesh with DNS-based routing and TLS termination at edge gateways, intermittent p95 latency spikes occur during peak hours despite healthy synthetic tests. No app changes allowed. Outline a concrete diagnostic plan to distinguish DNS routing churn, edge TLS handshake variability, and backbone path changes, with exact commands, data to collect, and a practical mitigation path?","answer":"Plan: test DNS churn with dig +trace and periodic TTL checks; force routes with curl -I --resolve host:443 and log p95 changes over peak hours; isolate TLS timings with openssl s_client -servername ho","explanation":"## Why This Is Asked\nDemonstrates practical diagnostic rigor for DNS routing, TLS handshakes, and backbone paths with no app changes.\n\n## Key Concepts\n- DNS-based routing stability\n- TLS handshake timing isolation\n- Path MTU and traceroute-based path mapping\n- Edge cache warmup and TLS session resumption\n\n## Code Example\n```javascript\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you validate a mitigation in production?\n- What telemetry would you add to prevent regressions?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","NVIDIA","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T15:46:26.733Z","createdAt":"2026-01-15T15:46:26.733Z"},{"id":"q-2394","question":"In a large-scale service mesh across three data centers using VXLAN overlays for pod networking, you observe intermittent packet loss and tail latency spikes when east-west traffic redirection occurs during rebalancing. No app changes allowed. Design a concrete, end-to-end diagnostic plan to isolate whether overlay encapsulation, MTU/PMTUD, or inter-domain routing is the root cause, and outline a robust mitigation path that preserves ECMP and minimizes tunnel churn?","answer":"Diagnose with cross-DC path MTU checks, PMTUD ICMP tracing, and EVPN edge state; verify overlay header size vs link MTU; collect BGP/EVPN neighbor flaps and ECMP hash distribution during traffic shift","explanation":"## Why This Is Asked\nTests ability to reason about data-plane overlays, MTU/PMTUD, and control plane dynamics in multi-DC environments.\n\n## Key Concepts\n- VXLAN overlays and encapsulation headers\n- MTU/PMTUD and fragmentation risk\n- EVPN/BGP control-plane state and ECMP hashing\n- East-west traffic rebalancing and tunnel churn\n\n## Code Example\n```bash\n#示例: tracepath over IPv6 to detect PMTUD issues\ntracepath6 -n <dest-node> | head -n 20\n```\n\n## Follow-up Questions\n- How would you automate the detection and rollback if a misconfiguration is found?\n- What metrics would you surface to SRE to prevent regression in future rebalances?","diagram":"flowchart TD\n  A[Overlay MTU Check] --> B[Inter-DC Link MTU]\n  B --> C[PMTUD/ICMP Data]\n  C --> D[EVPN/BGP State]\n  D --> E[ECMP Hashing]{Hash Dist}\n  E --> F[Latency Impact]\\n","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Snap","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-15T16:44:24.206Z","createdAt":"2026-01-15T16:44:24.206Z"},{"id":"q-2764","question":"In a globally distributed API deployed across two regions, inter-region latency spikes occur for a subset of traffic while intra-region latency remains low. The underlay uses an EVPN/VXLAN fabric with multiple interconnects and ECMP across them. You suspect per-flow ECMP hash collisions cause path oscillation and cache misses. Without changing app code, outline a concrete diagnostic plan to confirm the cause and propose mitigations that preserve ECMP while stabilizing inter-region paths?","answer":"Begin by correlating inter-region latency with per-flow paths: run repeated traceroutes and ip route get from both regions for a representative set of destinations; enable IPFIX/NetFlow on border devi","explanation":"## Why This Is Asked\nTests depth in real-world network issues: ECMP behavior, underlay visibility, and how to diagnose without app changes.\n\n## Key Concepts\n- ECMP hashing policies and per-flow vs per-destination steering\n- EVPN/VXLAN underlays with multiple interconnects\n- Telemetry: IPFIX/NetFlow, BGP state, route changes\n- Path stability implications for caches and regional traffic\n- Mitigation trade-offs: hashing adjustments vs routing policies\n\n## Code Example\n\n````bash\n# Telemetry collection (conceptual)\nip route get 203.0.113.1\ntcpdump -i any 'tcp and port 443'\n````\n\n## Follow-up Questions\n- How would you validate that per-destination hashing fixed the issue?\n- What are the risks of per-destination routing in a multi-region EVPN/VXLAN fabric?","diagram":"flowchart TD\n  A[Inter-region traffic] --> B[Border Router 1]\n  A --> C[Border Router 2]\n  B --> D[Next Hop Set 1]\n  C --> D\n  D --> E[Dest Region]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Snap","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T10:54:09.548Z","createdAt":"2026-01-16T10:54:09.548Z"},{"id":"q-2831","question":"In a globally distributed service using HTTP/3 over QUIC and TLS at edge, mobile clients roaming between networks experience intermittent QUIC connection resets and p95 latency spikes during peak hours. No app changes. Outline a concrete diagnostic plan to distinguish issues caused by QUIC connection migration, edge-cache revalidation, and DNS path changes, and propose practical mitigations that preserve ECMP and TLS posture?","answer":"Instrument edge QUIC logs to map connection IDs to migration events and CDN revalidation signals. Run roaming-path traces and compare DNS A/AAAA under different networks to spot path changes. Distingu","explanation":"## Why This Is Asked\nTests understanding of QUIC edge behavior, roaming networks, and realistic debugging plans.\n\n## Key Concepts\n- QUIC connection migration\n- Edge CDN revalidation\n- DNS path variation and ECMP\n\n## Code Example\n```javascript\n// Pseudo-logic to correlate migration events from edge logs\nfunction correlateMigration(logs) {\n  const byCID = new Map();\n  for (const e of logs) {\n    if (e.type === 'migration') byCID.set(e.cid, e);\n  }\n  return byCID;\n}\n```\n\n## Follow-up Questions\n- How would you test QUIC migration behavior in a lab without affecting real traffic?\n- What metrics would you alert on to detect roaming-related QUIC issues?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T14:07:26.512Z","createdAt":"2026-01-16T14:07:26.512Z"},{"id":"q-2844","question":"In a three-region WAN using VXLAN overlays with ECMP-enabled interconnects, EU to APAC traffic occasionally follows a suboptimal bounce path via NA, increasing tail latency of UDP telemetry without app changes. Provide a concrete diagnostic plan to identify whether inter-region underlay ECMP, tunnel encapsulation, or NAT translation is responsible, including exact commands and data to collect, and propose a robust mitigation that preserves ECMP while stabilizing end-to-end latency?","answer":"Perform a triad of checks: 1) collect per-hop traces and VXLAN header sizes on EU and APAC VTEPs to confirm the cross-region path; 2) inspect ECMP hashing groups and flow distribution (ip route get, s","explanation":"## Why This Is Asked\nTests the candidate’s ability to diagnose cross-region networking issues that involve both underlay and overlay behavior, without changing applications. It blends traceroute-like visibility, ECMP/hash behavior, and MTU considerations into a coherent plan.\n\n## Key Concepts\n- VXLAN over multi-region fabrics\n- ECMP hashing behavior and flow-level biases\n- MTU/PMTUD and NAT/edge translation interactions\n- EVPN/MPLS الخارج\n\n## Code Example\n```javascript\n// Pseudocode: build a diagnostic plan snapshot\nfunction diagnosticPlan() {\n  return [\n    'trace EU/APAC paths and VXLAN headers',\n    'inspect ECMP groups and flow distribution',\n    'verify MTU/PMTUD and edge NAT behavior',\n    'propose mitigations: MTU harmonization, per-destination hashing, flow pinning'\n  ];\n}\n```\n\n## Follow-up Questions\n- How would you validate the mitigation with controlled traffic loads?\n- Which metrics would you monitor post-implementation to ensure no ECMP degradation?","diagram":"flowchart TD\n  EU[E U] --> AP[APAC]\n  AP --> NA[NA]\n  NA --> EU\n  EU --> MON[Monitoring]\n  MON --> FIX[Sustain ECMP while stabilizing latency]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T14:38:04.458Z","createdAt":"2026-01-16T14:38:04.458Z"},{"id":"q-2891","question":"Global QUIC-based telemetry across US-East, EU-Central, and APAC suffers intermittent tail latency during bursts; no code changes allowed. Design a concrete diagnostic plan to separate handshake latency, path MTU/PMTUD, NAT/firewall drops of 0-RTT, and ECMP path flips, with exact commands and data to collect, and propose mitigations that preserve QUIC performance?","answer":"Outline a diagnostic plan that collects per-region traceroutes and mtr, UDP MTU probes (tracepath, ping -M do -s SIZE), edge PCAP captures, QUIC handshake metrics (RTT, 0-RTT success), and NetFlow/IPF","explanation":"## Why This Is Asked\nTests cross-region QUIC diagnosis without app changes, using network traces and edge telemetry to separate handshake, MTU, NAT, and ECMP factors.\n\n## Key Concepts\n- QUIC handshake behavior and 0-RTT\n- PMTUD/MTU for UDP traffic\n- NAT/firewall middleboxes affecting UDP\n- ECMP path stability and per-flow routing\n- Edge load balancer impacts on telemetry\n\n## Code Example\n```javascript\n// compute p95 latency from an array of samples\nfunction p95(arr){arr.sort((a,b)=>a-b);return arr[Math.floor(0.95*arr.length)];}\n```\n\n## Follow-up Questions\n- How would you differentiate MTU fragmentation from NAT drops in practice?\n- What edge changes would you consider to stabilize ECMP without TLS changes?","diagram":"flowchart TD\n  A[Observe QUIC handshake timings] --> B[Run per-region traceroutes/mtr]\n  B --> C[Perform UDP MTU probes and PMTUD]\n  C --> D[Capture edge PCAPs for QUIC traffic]\n  D --> E[Analyze ECMP path stability (NetFlow/IPFIX)]\n  E --> F[Propose mitigations preserving QUIC performance]","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T16:43:22.234Z","createdAt":"2026-01-16T16:43:22.235Z"},{"id":"q-3012","question":"In a two-region deployment behind regional CDNs with TLS termination at the edge, EU users report intermittent HTTPS connection setup delays during peaks while data transfer after connect is fine. Outline a concrete diagnostic plan to distinguish whether DNS TTL/path issues, TLS handshake stalls, CDN edge cache misses, or regional routing is to blame, including exact commands and data to collect, and propose a mitigation that preserves existing load balancing without app changes?","answer":"Begin with EU synthetic probes: dig +trace domain; curl -Iv https://domain; traceroute6 and mtr to the edge hostname; collect TLS handshake timing, DNS resolution latency, and CDN cache-hit/miss stats","explanation":"## Why This Is Asked\nThis checks practical, multi-layer diagnostic thinking for edge networks.\n\n## Key Concepts\n- CDN edge latency, DNS TTL, TLS handshake, cache hits/misses, IPv4/IPv6 paths.\n\n## Code Example\n```bash\ndig +trace domain\ncurl -Iv https://domain\ntraceroute6 domain\n```\n\n## Follow-up Questions\n- How would you automate these checks in a regular health window?\n- What logs would you correlate during a sudden burst?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Lyft","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-16T21:30:35.824Z","createdAt":"2026-01-16T21:30:35.824Z"},{"id":"q-3088","question":"In a global three-region deployment (NA, EU, APAC) using a UDP telemetry overlay and a TLS-terminated API gateway behind a CDN, rare mid-session UDP telemetry stalls occur during regional failovers. No app changes. Provide a concrete diagnostic plan to distinguish whether WAN path selection/ECMP, CDN edge TLS handshakes/ALPN, or UDP NAT traversal is the culprit, including exact commands and data to collect, and propose a robust mitigation that preserves ECMP while stabilizing latency?","answer":"Collect comprehensive per-region telemetry data to isolate the root cause between WAN path selection, CDN edge operations, and UDP NAT traversal: 1) Execute continuous traceroute/mtr from NA, EU, and APAC regions to telemetry endpoints during failover events, correlating path changes with BGP route convergence data; 2) Measure TLS handshake timing and ALPN negotiation performance using openssl s_client with detailed timing flags to identify edge TLS termination bottlenecks; 3) Capture UDP NAT traversal state transitions and firewall logs to detect session state loss during regional failover scenarios.","explanation":"## Why This Is Asked\nEvaluates real-world cross-region diagnostic capabilities for production latency issues during failover, spanning WAN routing dynamics, CDN TLS termination, and UDP NAT traversal complexities.\n\n## Key Concepts\n- WAN path stability and ECMP load balancing mechanisms\n- BGP route convergence and path selection algorithms\n- TLS handshake optimization, ALPN negotiation, and 0-RTT performance implications\n- UDP NAT traversal state management and firewall session persistence\n- Cross-region telemetry architecture patterns and mitigation strategies\n\n## Code Example\n```javascript\n// Pseudo-measurement harness illustrating data collection points\nasync function collectMetrics(region) {\n","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","IBM","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T05:03:27.824Z","createdAt":"2026-01-17T02:13:31.260Z"},{"id":"q-3382","question":"Context: Two-region deployment with DNS-fronted TLS API gateway. During peak hours UDP DNS queries show tail latency; TCP works. No app changes. Provide a concrete diagnostic plan to determine if EDNS0 payload fragmentation, DNSSEC validation, or resolver-specific UDP rate-limiting is the root cause. Include exact Linux commands and data to collect (pcap, dig traces, EDNS0 size), and propose a robust mitigation preserving UDP DNS performance?","answer":"Plan: compare UDP vs TCP DNS latency using dig @resolver +norecurse +bufsize=1232 example.com; dig @resolver +tcp +norecurse +bufsize=1232 example.com; check DNSSEC status with dig +dnssec example.com","explanation":"## Why This Is Asked\nTests practical DNS-path debugging, a real-world source of latency with minimal app changes.\n\n## Key Concepts\n- EDNS0 payload sizing\n- UDP vs TCP DNS behavior\n- DNSSEC impact\n- PMTUD and path MTU\n\n## Code Example\n```bash\n# Example diagnostic commands\n dig @resolver.example.com example.com A +norecurse +bufsize=1232\n dig @resolver.example.com example.com A +tcp +norecurse +bufsize=1232\n dig @resolver.example.com example.com DNSKEY +dnssec\n tcpdump -i any port 53 -w dns.pcap\n tracepath -n resolver.example.com\n```\n\n## Follow-up Questions\n- How would you automate data collection at edge nodes?\n- What metrics differ between UDP and TCP DNS paths?\n","diagram":"flowchart TD\n  A[UDP latency issue] --> B[Test UDP vs TCP]\n  B --> C[Capture dns.pcap]\n  C --> D[Review EDNS0/DNSSEC]\n  D --> E[Mitigate by EDNS0 cap and UDP-TCP fallback]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Coinbase","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T13:56:58.470Z","createdAt":"2026-01-17T13:56:58.470Z"},{"id":"q-3405","question":"In a global service using MPTCP over an overlay VPN across three regions, intermittent p95 latency spikes appear on UDP telemetry despite healthy synthetic tests. No app changes allowed. Provide a concrete diagnostic plan to determine if MPTCP subflow selection, per-path queueing, or VPN encapsulation is causing mid-flow path drift, including exact commands and data to collect and a robust mitigation that preserves MPTCP while stabilizing latency?","answer":"Inspect per-subflow RTTs and cwnd with ss -M and /proc/net/mptcp to correlate subflows; capture on each VPN tunnel with tcpdump -i <tun>; log path changes via 'ip route get' for representative destina","explanation":"## Why This Is Asked\n\nInter-region MPTCP over VPN can drift paths when ECMP flips mid-flow. A diagnostic plan showing per-subflow metrics and queueing behavior reveals root causes beyond TLS or MTU issues.\n\n## Key Concepts\n\n- MPTCP subflows and path selection\n- Overlay VPN encapsulation and NIC offloads\n- ECMP stability and per-interface queuing\n\n## Code Example\n\n```bash\n# show MPTCP connections and per-subflow state\nss -Mtn\ncat /proc/net/mptcp\n```\n\n## Follow-up Questions\n\n- How would you verify the mitigation doesn't degrade unrelated traffic?\n- How would you monitor ongoing path stability after changes?","diagram":"flowchart TD\n  Client(Client) --> OverlayEdge[Edge VPN]\n  OverlayEdge --> RegionA[Region A]\n  OverlayEdge --> RegionB[Region B]\n  RegionA --> Telemetry[Telemetry Collector]\n  RegionB --> TelemetryCollector","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Two Sigma","Uber","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T14:42:46.672Z","createdAt":"2026-01-17T14:42:46.672Z"},{"id":"q-3417","question":"In a two-region deployment where a cloud firewall performs TLS inspection in front of a regional API gateway, login requests intermittently spike in tail latency during peak hours while static content remains fast. Without changing app code, outline a concrete diagnostic plan to distinguish whether TLS-inspection queueing, firewall rate-limiting, or edge-cache invalidations drive the latency, including exact data to collect and realistic mitigations that preserve security?","answer":"To diagnose: 1) compare login latency with TLS inspection on vs bypass using curl -w '%{time_total}' https://api/.../login. 2) capture pcap at edge/firewall to measure TLS handshake times and queue de","explanation":"## Why This Is Asked\n\nTests the ability to diagnose production latency where security tooling (TLS inspection) interacts with edge caches and rate limits.\n\n## Key Concepts\n\n- TLS inspection overhead and queueing\n- Firewall connection limits and burst behavior\n- Edge CDN caching and TTLs\n- Observability: edge logs, pcap, and curl timing data\n\n## Code Example\n\n```javascript\n// Simple latency probe using fetch\nasync function probe(url){\n  const t0 = performance.now();\n  await fetch(url);\n  const t1 = performance.now();\n  console.log('latency', t1 - t0);\n}\nprobe('https://edge.example/login');\n```\n\n## Follow-up Questions\n\n- How would you verify bypass granularity while maintaining security?\n- What metrics would you monitor during a peak event to alert on this issue?\n","diagram":"flowchart TD\n  A[Client] --> B[Edge CDN/LB]\n  B --> C[Regional API Gateway]\n  C --> D[Cloud TLS Inspection Firewall]\n  D --> E[Origin API]\n  E --> F[Back-end Services]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T15:34:40.191Z","createdAt":"2026-01-17T15:34:40.191Z"},{"id":"q-3472","question":"In a three-region deployment (NA, EU, APAC) of a real-time service using a WireGuard-over-UDP overlay, UDP telemetry exhibits intermittent p95 latency spikes under load with no app changes. Outline a concrete diagnostic plan to determine whether overlay MTU fragmentation, WireGuard per-peer RTT, or NAT traversal is the culprit, including exact commands to run and data to collect, and propose a robust mitigation that preserves overlay security and ECMP stability?","answer":"Focus on overlay MTU, per-peer RTT, and NAT traversal. Steps: 1) MTU discovery across WG peers with ping -M do -s 1472 <peer>; 2) tcpdump -i wg0 and -i <uplink> to capture UDP flows; 3) wg show to rea","explanation":"## Why This Is Asked\n\nTests practical, production-ready debugging of overlay networks under real-time load, focusing on IX routing, MTU, and NAT behavior.\n\n## Key Concepts\n\n- WireGuard MTU and fragmentation in overlays\n- Per-peer RTT measurement and path stability\n- NAT traversal interactions with overlays\n- ECMP compatibility during MTU adjustments\n\n## Code Example\n\n```bash\n#!/bin/bash\n# MTU discovery across peers\nfor p in peer1 peer2 peer3; do\n  ping -M do -s 1472 $p\ndone\n```\n\n## Follow-up Questions\n\n- How would you automate this telemetry into a dashboard?\n- What changes if a different transport (e.g., QUIC) is used over the overlay?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-17T17:39:15.094Z","createdAt":"2026-01-17T17:39:15.094Z"},{"id":"q-3677","question":"In a globally distributed VPN with IPv6-only edge where telemetry endpoints are IPv4, NAT64/DNS64 is used. Intermittent UDP telemetry tail latency spikes occur when clients cross-region. Without app changes, outline a concrete diagnostic plan to identify whether DNS64 resolution, NAT64 translation state, or UDP fragmentation is responsible, including exact commands and data to collect, and propose mitigations that preserve connectivity?","answer":"Plan to isolate DNS64/NAT64 vs UDP fragmentation: 1) dig telemetry.example and compare AAAA vs A responses; 2) monitor NAT64 translations with conntrack -L and edge firewall logs during traffic; 3) tc","explanation":"## Why This Is Asked\nTests practical debugging in a real-world IPv6-to-IPv4 edge translation scenario, focusing on DNS64/NAT64 behavior, PMTUD, and UDP reliability.\n\n## Key Concepts\n- DNS64/NAT64 interaction\n- Path MTU Discovery and fragmentation\n- UDP telemetry reliability in edge NATs\n- Edge firewall/logging and translation state\n\n## Code Example\n```bash\ntcpdump -i any 'udp port 9999'\n```\n\n## Follow-up Questions\n- How would you validate DNS64 glue health under failover?\n- What mitigations ensure UDP telemetry remains reliable without app changes?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T04:25:25.277Z","createdAt":"2026-01-18T04:25:25.277Z"},{"id":"q-3748","question":"In a globally distributed network using Segment Routing with IPv6 (SRv6) across three regions, inter-region traffic experiences sporadic long-tail latency due to per-flow path selection not aligning with ECMP groupings. Without changing applications, propose a concrete diagnostic plan to determine whether per-flow SID steering, TE-rule misconfig, or ingress replication is causing instability, including exact commands and data to collect, and propose a robust mitigation that preserves ECMP while stabilizing latency?","answer":"## Diagnostic Plan\n\n**Step 1: Capture Per-Flow Path Data During Latency Spikes**\n```bash\n# Ingress traffic capture with flow identifiers\ntcpdump -i any -w /tmp/trace_ingress.pcap 'ip6 and (tcp or udp)' -c 100000\n\n# SRv6 header inspection for per-flow SID sequences\ntshark -r /tmp/trace_ingress.pcap -Y 'ipv6' -T fields \\\n  -e ipv6.src -e ipv6.dst -e ipv6.flow -e ipv6.hbh_sr_segments \\\n  -e frame.time_relative -e tcp.stream\n\n# Flow hash verification on different paths\nshow platform software fed switch active qos queue stats interface <ingress-if>\nshow platform software fed switch active acl detail interface <ingress-if>\n\n# SRv6 specific flow monitoring\nshow segment-routing srv6 policy name <policy-name> statistics\nshow segment-routing srv6 steering detail\n```\n\n**Step 2: SRv6 Policy State Analysis**\n```bash\n# Check SRv6 policy configuration and active paths\nshow segment-routing srv6 policy detail\nshow segment-routing srv6 policy database\nshow segment-routing srv6 steering\nshow segment-routing srv6 locator detail\nshow segment-routing srv6 localsid\n\n# ECMP group verification with SRv6 context\nshow ip cef <prefix> detail\nshow ip cef <prefix> internal\nshow mpls forwarding-table <prefix> detail\nshow bgp vpnv6 unicast <prefix>\nshow bgp vpnv6 unicast <prefix> detail\n\n# TE policy validation with SRv6 integration\nshow traffic-eng tunnels brief\nshow traffic-eng forwarding-adjacency\nshow segment-routing traffic-eng policy detail\nshow segment-routing traffic-eng database\nshow segment-routing traffic-eng autoroute\n```\n\n**Step 3: Ingress Replication Detection**\n```bash\n# Monitor SID list variations for same flow\nmonitor capture buffer SRV6_FLOW match ipv6 any any\nmonitor capture buffer SRV6_FLOW interface any both\nmonitor capture buffer SRV6_FLOW limit 1000000\nshow monitor capture buffer SRV6_FLOW parameters\nshow monitor capture buffer SRV6_FLOW buffer\n\n# Check for multiple ingress points\nshow segment-routing srv6 locator detail\nshow segment-routing srv6 localsid detail\nshow running-config | include segment-routing srv6\nshow segment-routing srv6 policy name <policy> candidate-paths\n\n# Validate SID consistency across regions\nshow segment-routing srv6 policy name <policy> segment-lists\nshow segment-routing srv6 policy name <policy> active-path\n```\n\n**Step 4: Advanced State Correlation**\n```bash\n# Correlate flow hashes with path selection\nshow platform software fed switch active forwarding route <prefix>\nshow platform software fed switch active sr6 policy\nshow platform hardware qfp active feature srv6 stats\n\n# TE policy interaction analysis\nshow traffic-eng topology brief\nshow traffic-eng link bandwidth\nshow segment-routing traffic-eng policy name <policy> bandwidth\nshow segment-routing traffic-eng policy name <policy> constraints\n\n# BGP-SRv6 policy validation\nshow bgp ipv6 unicast neighbors <peer> advertised-routes\nshow bgp ipv6 unicast neighbors <peer> received-routes\nshow bgp ipv6 sr-policy detail\n```\n\n## Root Cause Analysis\n\n**Per-Flow SID Steering Issues:**\n- Compare flow hash to selected SID sequence across time windows\n- Verify consistent mapping between flow 5-tuple and SRv6 segment list\n- Check for SID list variations within same flow during latency spikes\n- Validate SRv6 steering policy configuration and effectiveness\n\n**TE-Rule Misconfiguration:**\n- Validate TE policy bandwidth constraints and actual utilization\n- Check for overlapping policy priorities causing path flapping\n- Verify path selection algorithm consistency across regions\n- Examine TE policy interaction with IGP shortest path first\n\n**Ingress Replication Problems:**\n- Identify multiple SIDs pointing to same destination from different locators\n- Detect inconsistent localSID configurations across region boundaries\n- Verify policy steering rules don't conflict between regions\n- Check for SID allocation conflicts and overlap\n\n**ECMP-HSRv6 Interaction Analysis:**\n- Examine how ECMP hash results map to SRv6 candidate paths\n- Verify hash algorithm stability with SRv6 segment lists\n- Check for hash collisions causing suboptimal path selection\n- Validate ECMP group composition with SRv6 policy constraints\n\n## Mitigation Strategy\n\n**Preserve ECMP While Stabilizing Latency:**\n\n1. **Implement Flow-Aware SRv6 Steering**\n```bash\n# Configure consistent flow-based steering\nsegment-routing\n  srv6\n    locator LOC1\n      prefix 2001:db8:1::/48\n      behavior usd\n    policy POLICY_100\n      color 100\n      end-point ipv4 10.0.0.0\n      candidate-paths\n        preference 100\n          segment-list LIST_1\n            index 1 sid 2001:db8:1::1\n            index 2 sid 2001:db8:2::1\n            index 3 sid 2001:db8:3::1\n          segment-list LIST_2\n            index 1 sid 2001:db8:1::2\n            index 2 sid 2001:db8:2::2\n            index 3 sid 2001:db8:3::2\n          steering\n            bgp\n              ipv6\n                route-target 65000:100\n                flow-based\n                algorithm 128\n```\n\n2. **ECMP Hash Optimization for SRv6**\n```bash\n# Configure stable ECMP hashing with SRv6 awareness\nip cef load-sharing algorithm include-ports\nip cef load-sharing algorithm universal\nmpls load-balancing flow ipv4\nmpls load-balancing flow ipv6\nsegment-routing\n  srv6\n    encapsulation\n      source-address 2001:db8:ffff::1\n      hop-limit 64\n```\n\n3. **Policy Priority and Bandwidth Management**\n```bash\n# Ensure consistent TE policy selection across regions\ntraffic-eng\n  tunnel-te100\n    bandwidth 100000\n    priority 7 7\n    affinity 0x0 mask 0x0\n    autoroute announce\n    autoroute metric 10\n  tunnel-te101\n    bandwidth 100000\n    priority 7 7\n    affinity 0x1 mask 0x1\n    autoroute announce\n    autoroute metric 20\n\nsegment-routing\n  traffic-eng\n    policy TE_POLICY_100\n      color 100\n      endpoint ipv4 10.0.0.0\n      bandwidth 100000\n      constraints\n        segment-rules strict\n        adjacency-sids prefer\n```\n\n4. **Advanced Monitoring and Validation**\n```bash\n# Continuous path verification and alerting\nshow segment-routing srv6 policy name POLICY_100 statistics\nshow segment-routing srv6 policy name POLICY_100 active-path\nshow platform software fed switch active sr6 policy\nshow platform hardware qfp active feature srv6 stats\n\n# Automated health check script\n#!/bin/bash\nwhile true; do\n  echo \"=== $(date) ===\"\n  show segment-routing srv6 policy summary\n  show platform software fed switch active sr6 stats\n  sleep 30\ndone\n```\n\n5. **Failure Detection and Automatic Recovery**\n```bash\n# Configure fast failure detection\nsegment-routing\n  srv6\n    policy POLICY_100\n      candidate-paths\n        preference 100\n          segment-list LIST_1\n            backup-segment-list LIST_BACKUP_1\n              index 1 sid 2001:db8:1::10\n              index 2 sid 2001:db8:2::10\n          bfd\n            fast-detect\n            minimum-interval 50\n            multiplier 3\n```\n\n**Expected Outcome:** Stabilized latency distribution while maintaining ECMP benefits through consistent flow-to-path mapping, optimized hash algorithms, and robust SRv6 policy management across all three regions.","explanation":"## Why This Is Asked\nTests ability to diagnose advanced SRv6 path selection issues in multi-region deployments, focusing on observable telemetry, policy state, and stable routing behavior.\n\n## Key Concepts\n- SRv6 policy state and candidate path selection mechanisms\n- ECMP hashing interaction with SRv6 segment lists\n- Ingress replication and TE policy conflict resolution\n- Flow-based steering algorithms and consistency\n- Per-flow latency stability in distributed networks\n- BGP-SRv6 policy distribution and validation\n- Hardware acceleration and QFP statistics for SRv6\n- Fast failure detection with BFD integration\n\n## Technical Implementation Details\n\n**SRv6 Policy State Machine:**\n- Policy installation: locator configuration → policy definition → candidate-path selection\n- Path evaluation: bandwidth constraints → priority comparison → algorithm selection\n- Steering application: BGP route-target matching → flow-based mapping → hardware programming\n\n**ECMP-HSRv6 Integration Points:**\n- Hash algorithm: include-ports, universal, or L4-based for flow consistency\n- SID list impact: segment order affects hash calculation and path selection\n- Hardware considerations: QFP feature statistics and policy replication\n\n**Diagnostic Methodology:**\n1. Real-time traffic capture with SRv6 header inspection\n2. Policy state correlation across control and data planes\n3. Flow-to-path mapping validation during latency events\n4. Cross-region consistency verification\n\n**Operational Validation:**\n- Continuous monitoring with automated health checks\n- Performance impact measurement before/after mitigation\n- Scalability testing with increasing flow counts\n- Failover behavior validation with BFD integration\n\nThis comprehensive approach ensures accurate diagnosis of SRv6 path selection instability while preserving ECMP benefits through optimized flow-to-path mapping and robust policy management across globally distributed regions.","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Oracle","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-22T03:53:57.280Z","createdAt":"2026-01-18T07:43:58.864Z"},{"id":"q-3756","question":"In a global telemetry pipeline over UDP QUIC, edge collectors in three regions send to a central sink through cloud regions. During peak hours, tail latency spikes appear with no app changes. The path includes NIC offloads (GSO/TSO), IRQ coalescing, and hypervisor scheduling. Provide a concrete diagnostic plan to distinguish NIC offloads, interrupt coalescing, and scheduler jitter, with exact commands and data to collect, and a robust mitigation that preserves throughput and latency, without changing app code?","answer":"Diagnose NIC offloads vs IRQ coalescing vs scheduler jitter. Collect: NIC offload settings (ethtool -k), per-queue stats (ethtool -S), interrupts (/proc/interrupts, /proc/net/softnet_stat), per-CPU pe","explanation":"## Why This Is Asked\n\nTests practical troubleshooting for cross-region telemetry with hidden path issues, focusing on NIC offloads, IRQ coalescing, and scheduler behavior rather than code fixes.\n\n## Key Concepts\n\n- NIC offloads (GSO/TSO/GRO) and their impact on latency\n- IRQ coalescing and interrupt affinity\n- Hypervisor scheduling jitter and CPU locality\n\n## Code Example\n\n```javascript\n// placeholder script showing metrics collection skeleton\nconst collect = () => ({ latencyHist: [], cpuStats: [] })\n```\n\n## Follow-up Questions\n\n- How would results change if MTU is fluctuating?\n- What production-safe mitigations balance latency and throughput best?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Stripe","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T08:40:01.791Z","createdAt":"2026-01-18T08:40:01.792Z"},{"id":"q-3870","question":"Three-region deployment NA, EU, APAC uses edge TLS termination and a UDP telemetry overlay. Tail latency spikes appear EU→APAC during peak; suspect TLS session resumption misses on regional proxies, clock skew, or ticket rotation across regions. Without app changes, design a concrete diagnostic plan with commands and data to collect, and propose a mitigation that preserves ECMP while stabilizing latency?","answer":"Enable TLS session-ticket logs on EU and APAC proxies; collect handshake timing, cache-hit/miss rates, ticket lifetimes; compare latency with tickets vs full handshakes using openssl s_client and curl","explanation":"## Why This Is Asked\nTests diagnosing TLS-level cross-region latency in edge-terminated, ECMP-enabled networks, focusing on handshake costs, ticket management, and time synchronization.\n\n## Key Concepts\n- TLS session tickets and 0-RTT\n- Edge termination and cross-region flow symmetry\n- Clock synchronization (NTP/chrony)\n- ECMP and per-hop latency\n- Observability: handshake timings, ticket metrics, path tracing\n\n## Code Example\n```bash\n# Example data-gathering commands (illustrative)\nopenssl s_client -connect eu-edge.example.com:443 -servername eu-edge.example.com -tls1_3\ncurl -v https://eu-edge.example.com/health\nchronyc tracking\n```\n\n## Follow-up Questions\n- How would you rotate TLS tickets safely across regions without downtime?\n- How do TLS handshakes interact with ECMP hashing to affect tail latency, and what mitigations would you apply?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-18T13:10:20.249Z","createdAt":"2026-01-18T13:10:20.249Z"},{"id":"q-4198","question":"Two WAN uplinks (ISP-A, ISP-B) on a single edge router use ECMP for outbound traffic to a global telemetry collector. UDP telemetry to the collector occasionally drops when the path leaves via ISP-B; ISP-A path remains healthy. Without app changes, provide a concrete diagnostic plan to confirm if reverse-path filtering or asymmetric routing is to blame, detailing exact commands and data to collect, and propose a mitigation that preserves ECMP while stabilizing end-to-end delivery?","answer":"Check RP filtering and routing symmetry: inspect rp_filter values on both interfaces; verify path symmetry with 'ip route get <collector-ip>' and 'traceroute -I <collector-ip>'; capture traffic with '","explanation":"## Why This Is Asked\nTests practical understanding of basic multi-homed routing issues, especially reverse-path filtering and how policy-based routing interacts with ECMP in real deployments.\n\n## Key Concepts\n- Reverse Path Filtering (rp_filter)\n- ECMP and path symmetry\n- Policy-based routing\n- Packet capture and tracing\n\n## Code Example\n```bash\n# Basic rp_filter checks\nsysctl net.ipv4.conf.all.rp_filter\nsysctl -w net.ipv4.conf.all.rp_filter=1\n# Interface-specific rp_filter\ncat /proc/sys/net/ipv4/conf/eth0/rp_filter\n```\n\n## Follow-up Questions\n- How would you adjust rp_filter to minimize disruptions while preserving security?\n- How would you test during a live failover to verify ECMP still distributes traffic evenly?\n","diagram":"flowchart TD\n  A[Edge Router] -->|ECMP| B[ISP-A]\n  A -->|ECMP| C[ISP-B]\n  B --> D[Collector]\n  C --> D","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["DoorDash","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T08:14:03.544Z","createdAt":"2026-01-19T08:14:03.544Z"},{"id":"q-4215","question":"In a two-region EVPN/VXLAN fabric with INT telemetry, inter-region traffic experiences sudden tail-latency spikes tied to backbone rebalancing events. No app changes. Outline a concrete diagnostic plan to determine whether INT metadata misalignment, ingress replication, or per-flow hashing changes drive the spikes, including exact commands and data to collect, and propose a robust mitigation that preserves ECMP while stabilizing latency?","answer":"Two-region EVPN/VXLAN fabric with INT telemetry; spikes align with backbone rebalancing. Diagnostic plan: 1) collect per-flow ECMP stats (tc -s qdisc, ss, sFlow) for both regions; 2) inspect INT heade","explanation":"## Why This Is Asked\n\nTests practical diagnostic skill for inter-region network issues, telemetry interpretation, and concrete mitigations.\n\n## Key Concepts\n\n- ECMP hashing behavior\n- INT telemetry\n- VXLAN EVPN fabric\n- Ingress replication\n- Backbone rebalancing\n\n## Code Example\n\n```javascript\n// example: map flow to ECMP path using a hash\nfunction pathForFlow(srcIP,dstIP,srcPort,dstPort,proto,seed=0){\n  const key = [srcIP,dstIP,srcPort,dstPort,proto,seed].join('|');\n  return hash32(key) % 8; // 8-path ECMP\n}\n```\n\n## Follow-up Questions\n\n- How would you validate that a fixed ECMP seed improves tail latency without harming overall balance?\n- How would you detect and prevent INT metadata misalignment from causing misrouted flows?","diagram":"flowchart TD\n  A[Two-region EVPN/VXLAN] --> B[INT telemetry]\n  B --> C[Path misalignment?]\n  C --> D[Hashing / replication checks]\n  D --> E[Mitigation: stable ECMP hash]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Citadel","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T09:00:41.288Z","createdAt":"2026-01-19T09:00:41.288Z"},{"id":"q-4255","question":"In a globally distributed anycast frontend with ECMP across three regional edges, EU clients intermittently exit via NA during peak, causing tail latency spikes in UDP telemetry. Without app changes, design a concrete diagnostic plan to determine whether BGP path selection, inter-provider ECMP, or edge-cache routing is at fault, including exact commands and data to collect. Propose mitigations that preserve ECMP while stabilizing latency?","answer":"Collect per-edge BGP state for the anycast prefix (AS_PATH, MED, communities); log path churn during peak. From EU, run tracepath to the anycast IP and compare with NA. Capture UDP telemetry RTT histo","explanation":"## Why This Is Asked\n\nReal-world issue where anycast with ECMP interacts with multi-edge routing, requiring precise diagnostics across BGP, path tracing, and edge caching. Candidates must design concrete data collection and safe mitigations that keep ECMP intact.\n\n## Key Concepts\n\n- Anycast with ECMP across multiple regional edges\n- BGP path attributes (AS_PATH, MED, communities)\n- Path tracing, UDP telemetry latency\n- Edge caching and CDN routing\n\n## Code Example\n\n```javascript\n// Placeholder: no code expected in interview answer\n```\n\n## Follow-up Questions\n\n- How would you validate the effectiveness of the chosen TE policy across peak hours?\n- What risks exist when steering traffic away from NA to EU in this topology?","diagram":"flowchart TD\nA(Client) --> B[Anycast IP]\nB --> C{Best Path via Edge}\nC --> D[Edge EU]\nC --> E[Edge NA]\nC --> F[Edge APAC]\nD --> G[Regional gateway]\nE --> G\nF --> G\nG --> H[Origin API]\n","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Google","Hashicorp","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-19T10:45:48.697Z","createdAt":"2026-01-19T10:45:48.697Z"},{"id":"q-4585","question":"IPv6-only clients intermittently fail TLS handshakes in a regional service behind NAT64/DNS64 and a dual-stack load balancer. Outline a concrete diagnostic plan to confirm whether DNS64 synthesis, NAT64 translation table exhaustion, or TLS 0-RTT/ALPN behavior is the culprit. Include exact commands and data to collect, likely log locations, and a practical mitigation that preserves IPv6 reachability without app changes?","answer":"Diagnose IPv6-only clients experiencing intermittent TLS handshake failures behind NAT64/DNS64 with a dual-stack load balancer. Implementation: 1) Verify DNS64 synthesis by querying both A and AAAA records to confirm proper IPv6 address generation; 2) Inspect NAT64 translation state using conntrack to identify potential table exhaustion; 3) Capture edge traffic to analyze TLS handshake patterns and identify 0-RTT/ALPN issues. Commands: `dig +short A example.com` and `dig +short AAAA example.com` for DNS verification, `sudo conntrack -L | grep nat` and `sudo conntrack -S` for translation state analysis, and `sudo tcpdump -i edges0 'tcp or ip6' -w /tmp/trace.pcap` for packet capture. Monitor logs in `/var/log/syslog`, `/var/log/messages`, and load balancer access logs. Mitigation: Increase NAT64 pool size and adjust timeout values while preserving IPv6 reachability without application changes.","explanation":"## Why This Is Asked\nTests practical knowledge of IPv6 translation mechanisms, DNS64 synthesis, NAT64 state management, and TLS handshake behavior in production infrastructure.\n\n## Key Concepts\n- IPv6-only network connectivity\n- DNS64 synthesis and AAAA record generation\n- NAT64 translation table management\n- TLS 0-RTT and ALPN protocol interactions\n- Dual-stack load balancer configuration\n\n## Code Example\n```bash\n# Verify DNS64 synthesis\ndig +short A example.com\ndig +short AAAA example.com\n\n# Check NAT64 translation state\nsudo conntrack -L | grep nat\nsudo conntrack -S\n\n# Capture edge traffic\nsudo tcpdump -i edges0 'tcp or ip6' -w /tmp/trace.pcap\n```","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Discord","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-20T05:54:37.365Z","createdAt":"2026-01-20T02:40:34.814Z"},{"id":"q-4614","question":"In a three-region real-time messaging service using QUIC with TLS, users report sporadic tail latency spikes on new connections during peak hours. No app changes allowed. Provide a concrete diagnostic plan to distinguish (a) QUIC handshake stalls and 0-RTT acceptance, (b) TLS handshake negotiation on edge proxies, and (c) per-edge queueing or NAT translation, with exact commands and data to collect, and propose a robust mitigation that preserves ECMP?","answer":"Instrument QUIC handshakes with client/server qlog and edge TLS proxy logs; capture UDP 443 traffic with tcpdump at each PoP; collect per-hop queue and NAT state via conntrack and tc; compare handshak","explanation":"## Why This Is Asked\nTests practical diagnostic thinking for real-time networking across regions, focusing on QUIC, TLS proxies, and edge queueing rather than generic theory.\n\n## Key Concepts\n- QUIC handshake and 0-RTT behavior\n- TLS termination in edge proxies\n- Per-edge queueing, NAT translation, and ECMP sensitivity\n\n## Code Example\n\n```javascript\n// Example telemetry collection sketch (pseudo)\n```\n\n## Follow-up Questions\n- How would you verify ECMP stability while collecting traces?\n- What safeguards would you put in place when enabling 0-RTT broadly?\n","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Discord","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T04:32:44.584Z","createdAt":"2026-01-20T04:32:44.584Z"},{"id":"q-4628","question":"In a dual-region deployment (NA and EU) using IPsec-over-VXLAN inter-region tunnels within an EVPN fabric, UDP telemetry experiences sporadic stalls during bursts and failover. No app changes. Design a concrete diagnostic plan to confirm whether IPsec SA rekey, ESP overhead, or IGP/ECMP reshaping is the culprit, including exact commands and data to collect, and propose a robust mitigation that preserves ECMP while stabilizing latency?","answer":"Diagnose by aligning stall windows with IPsec SA rekeys and IKE events. Collect: ip xfrm state, ip xfrm policy, logs for ike, and tcpdump on the IPsec tunnel (tcpdump -i <tun> -n -vv 'udp port 4500').","explanation":"Why This Is Asked\n\nTests ability to diagnose production issues involving overlay security tunnels and ECMP, focusing on correlation, data collection, and non-app mitigations.\n\nKey Concepts\n\n- IPsec SA lifetimes and rekey behavior\n- IKE/ISAKMP logs and troubleshooting\n- Overlay tunnel traffic patterns and ECMP stability\n- How to interpret pcap and kernel state outputs\n\nCode Example\n\n```javascript\n// commands to run during diagnosis\nip xfrm state\nip xfrm policy\ntcpdump -i eth0 -n -vv 'udp port 4500'\n```\n\nFollow-up Questions\n\n- How would you validate the fix in a staging environment before rolling out?\n- What monitoring dashboards would you expose to detect rekey storms early?","diagram":"flowchart TD\n  A[Start] --> B[Identify stall window]\n  B --> C[Collect ip xfrm state/policy]\n  C --> D[Tcpdump on IPsec tunnel]\n  D --> E[Correlate with IKE logs & ECMP churn]\n  E --> F[Implement staggered rekeys & higher lifetimes]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Apple","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:46:30.678Z","createdAt":"2026-01-20T05:46:30.678Z"},{"id":"q-4670","question":"In a three-region deployment of a WebRTC-based collaboration feature with TURN relays and enterprise firewalls, users report intermittent 2–5s stalls during peak hours. No app changes allowed. Provide a concrete diagnostic plan to distinguish (a) ICE connectivity checks stuck behind NAT/firewall, (b) TURN relay queueing/overload, (c) UDP multiplexing/packet pacing affecting media, with exact commands and data to collect, and propose a mitigation preserving end-to-end encryption?","answer":"Collect webrtc-internals traces, ICE connection states, and STUN/TURN logs; capture coturn TURN statistics (Alloc, AllocError, remotes); run pcap on media ports to measure RTP/RTCP loss and jitter; te","explanation":"## Why This Is Asked\n\nTests ability to reason about WebRTC NAT traversal, multi-region relay load, and firewall interactions; challenges like ICE connectivity, TURN overload, and UDP pacing require concrete instrumentation rather than speculation.\n\n## Key Concepts\n\n- WebRTC ICE and STUN/TURN\n- NAT/firewall traversal and UDP keepalives\n- Relay load, queueing, and QoS\n- End-to-end encryption constraints\n\n## Code Example\n\n```javascript\n// Minimal example: monitor ICE state transitions\nconst pc = new RTCPeerConnection(config);\npc.oniceconnectionstatechange = () => console.log(pc.iceConnectionState);\n```\n\n## Follow-up Questions\n\n- How would you validate a production mitigation without affecting active users?\n- What metrics indicate TURN overload vs ICE stall?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Databricks","Discord","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T07:43:19.517Z","createdAt":"2026-01-20T07:43:19.517Z"},{"id":"q-469","question":"Explain what happens when you type google.com into your browser and press Enter, focusing on the networking layers involved?","answer":"When you type google.com into your browser and press Enter, the browser first checks its DNS cache for the IP address. If not found, it queries DNS servers recursively to resolve the domain name. Once the IP address is obtained, the browser creates a TCP socket and performs a three-way handshake (SYN, SYN-ACK, ACK) to establish a reliable connection. The browser then sends an HTTP GET request over TCP, which the server processes and returns a response. Finally, the browser renders the received content.","explanation":"## DNS Resolution\n- Browser checks local DNS cache first for previously resolved addresses\n- Queries recursive DNS servers starting from the root DNS hierarchy\n- Returns the IP address for google.com to the browser\n\n## TCP Connection\n- Performs three-way handshake: SYN, SYN-ACK, ACK\n- Establishes a reliable, ordered data transmission channel\n- Uses port 443 for HTTPS connections or port 80 for HTTP\n\n## HTTP Request\n- Browser sends GET request to the server\n- Includes essential headers like User-Agent, Accept, and Host\n- Server processes the request and prepares the response\n\n## Response Processing\n- Server returns HTML, CSS, JavaScript, and other resources\n- Browser parses the HTML and constructs the DOM tree\n- Makes additional requests for referenced resources (images, scripts, stylesheets)\n- Renders the complete page for the user","diagram":"flowchart TD\n  A[Browser] --> B[DNS Lookup]\n  B --> C[Get IP Address]\n  C --> D[TCP Handshake]\n  D --> E[HTTP Request]\n  E --> F[Server Response]\n  F --> G[Render Page]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Goldman Sachs","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-09T09:01:53.350Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-4713","question":"Three-region deployment with a TLS-terminated edge gateway and a service mesh. New HTTPS connections spike tail latency under load; existing sessions unaffected. No app changes. Provide a concrete diagnostic plan to distinguish edge TLS stalls (certificate chain or OCSP), region NAT/firewall rate-limits, mesh CA rotation delays, and DNS endpoint churn. Include exact commands/data to collect and a mitigation that preserves ECMP?","answer":"Plan focuses on: edge TLS handshake latencies (certificate chain, OCSP), regional NAT/firewall rate limits, mesh CA rotation delays, and DNS endpoint churn. Collect: per-region tcpdump on port 443, ed","explanation":"## Why This Is Asked\n\nTests practical debugging across edge, mesh, and DNS layers under load, emphasizing diagnostic precision and safe, ECMP-preserving mitigations.\n\n## Key Concepts\n\n- TLS handshake behavior at edge gateways\n- NAT/firewall rate-limiting and per-region policing\n- Service mesh CA rotation and mTLS handshake impact\n- DNS routing churn and endpoint stability\n\n## Code Example\n\n```javascript\n// Example snippet to collect diagnostics\nconst {execSync} = require('child_process');\nconsole.log(execSync('tcpdump -i any tcp port 443 -c 100').toString());\n```\n\n## Follow-up Questions\n\n- How would you automate cross-region diagnostics?\n- How would you validate mitigation without changing apps?","diagram":"flowchart TD\n  Client[Client] --> EdgeDNS[Edge DNS/LB]\n  EdgeDNS --> RegionalLB1[Regional LB]\n  RegionalLB1 --> Gateway[Ingress Gateway]\n  Gateway --> SpA[Service A]\n  Gateway --> SpB[Service B]","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Hashicorp","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T09:17:01.800Z","createdAt":"2026-01-20T09:17:01.800Z"},{"id":"q-4849","question":"In a three-region deployment (US-East, EU-Central, APAC-East) using a VXLAN overlay with ECMP-enabled underlays, intermittent new-connection tail latency spikes appear despite stable average load; no app changes. Provide a concrete diagnostic plan to distinguish whether (a) underlay ECMP hashing, (b) EVPN/underlay path selection, (c) VXLAN MTU fragmentation, or (d) inter-region NAT/policy translation is responsible, with exact commands and data to collect, and propose a robust mitigation that preserves ECMP?","answer":"Run parallel traces and captures across all inter-region links. Collect VXLAN traffic via tcpdump 'udp port 4789' on edge gateways, plus 'ip route get' for multiple 5-tuples to observe ECMP paths. Gat","explanation":"## Why This Is Asked\nTests practical, line-by-line diagnostics for multi-region overlays, focusing on real root-cause signals rather than abstractions.\n\n## Key Concepts\n- VXLAN overlays and UDP tunneling\n- ECMP hashing behavior across regions\n- EVPN/BGP route visibility\n- MTU, fragmentation, and NAT interactions\n\n## Code Example\n```bash\n# VXLAN traffic capture on edge gateways\ntcpdump -i any 'udp port 4789' -nn -w vxlan_capture.pcap\n# Observe inter-region path selection per 5-tuple\nip route get <dest_ip>\n```\n\n## Follow-up Questions\n- How would you adjust ECMP hashing to minimize path variance without increasing stickiness?\n- What MTU strategy would you use to prevent fragmentation without sacrificing throughput?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Adobe","Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T16:16:02.193Z","createdAt":"2026-01-20T16:16:02.193Z"},{"id":"q-4924","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across multiple transit providers, a new 24x7 telemetry UDP stream shows persistent tail latency spikes for cross-region traffic while intra-region latency remains low. The underlay is IPsec tunnels with NAT at the edge. No app changes allowed. Provide a concrete diagnostic plan to determine whether (a) inter-region underlay ECMP hashing, (b) EVPN route convergence, (c) IPsec MTU/fragmentation, or (d) NAT stateful translations are responsible, with exact commands and data to collect, and propose a robust mitigation preserving ECMP and telemetry reliability?","answer":"Run a targeted test to isolate MTU, NAT state, and ECMP hashing by measuring per-tunnel path MTU with ping -M do -s 1472 across inter-region tunnels, capture ESP/NAT counters (ip xfrm stats, conntrack","explanation":"## Why This Is Asked\nTests ability to reason about complex cross-region fabric issues without app changes, focusing on data-plane diagnostics and mitigations.\n\n## Key Concepts\n- EVPN/VXLAN underlay and ECMP behavior across multi-homed interconnects\n- IPsec tunneling, MTU fragmentation, and NAT state explosion risks\n- Real-time telemetry performance sensitivity to path changes\n\n## Code Example\n```bash\n#!/bin/bash\n# Quick checks for inter-region paths\nfor t in us-eu eu-apac apac-us; do\n  echo \"Testing tunnel: $t\"\n  ping -c 5 -M do -s 1472 <tunnel-peer-ip>\ndone\n```\n\n## Follow-up Questions\n- How would you validate a mitigation if NAT session tables continue to balloon under load?\n- What traffic engineering or QoS changes would you apply to preserve ECMP while reducing tail latency?","diagram":"flowchart TD\n  A[Three-region EVPN/VXLAN Fabric] --> B{Spikes observed}\n  B --> C[ECMP hashing]\n  B --> D[EVPN convergence]\n  B --> E[IPsec MTU/fragmentation]\n  B --> F[NAT state]\n  C --> G[Measure per-tunnel hashes]\n  D --> H[Monitor route convergence]\n  E --> I[MTU probe]/J[Fragmentation risk]\n  F --> K[NAT session capacity]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Snowflake","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T19:20:52.365Z","createdAt":"2026-01-20T19:20:52.365Z"},{"id":"q-4961","question":"In a four-region deployment (US-East, EU-Central, APAC-West, APAC-East) using a VXLAN EVPN fabric with ECMP across several transit providers, a new high-rate UDP telemetry stream causes cross-region tail latency spikes while intra-region latency stays low. No app changes. Provide a concrete diagnostic plan to determine whether (a) inter-region underlay ECMP flowhash collisions, (b) EVPN route dampening or path oscillation, (c) VTEP MTU fragmentation, or (d) NIC offload pacing/interrupt coalescing are responsible, with exact commands and data to collect, and propose robust mitigations preserving telemetry reliability and ECMP?","answer":"Execute a comprehensive diagnostic plan to collect per-path latency metrics, ECMP hash distribution analysis, EVPN route change tracking, VTEP MTU health assessment, and NIC offload performance data. Utilize the following command sequence: `tc qdisc show` for traffic discipline verification; `ethtool -S <iface>` for interface statistics; `ping -M do -s 1472 -f <peer>` for MTU validation; `tcpdump -i <iface> -w capture.pcap` for packet capture analysis; `vtysh -c 'show evpn vni'` for EVPN VNI status; `show route evpn` for EVPN routing table; `show ip route flow-hash` for ECMP hash distribution; `show ip cef exact-route` for specific path verification; `show interface counters` for traffic statistics; and `show platform hardware qfp active feature` for hardware forwarding plane analysis.","explanation":"## Why This Is Asked\nThis question evaluates the ability to systematically diagnose cross-region performance issues in complex multi-layer networks, specifically analyzing how telemetry workloads interact with underlay ECMP, EVPN control planes, MTU constraints, and hardware optimizations.\n\n## Key Concepts\n- ECMP flowhash distribution across multi-provider transit paths and potential collision scenarios\n- EVPN route convergence dynamics, dampening mechanisms, and path oscillation patterns\n- VTEP MTU configuration impacts on UDP telemetry streams and fragmentation behavior\n- NIC offload mechanisms, interrupt coalescing, and their effects on latency tail characteristics\n\n## Code Example\n```python\n# Parse latency samples from packet captures and compute tail latency per ECMP path\nimport json\nimport statistics\n\ndef analyze_tail_latency(latency_samples, percentile=99):\n    \"\"\"Calculate tail latency at specified percentile\"\"\"\n    sorted_samples = sorted(latency_samples)\n    tail_index = int((percentile / 100) * len(sorted_samples))\n    return sorted_samples[tail_index]\n\n# Example usage\nlatencies = []  # Populate from pcap parsing\ntail_latency = analyze_tail_latency(latencies)\nprint(f\"99th percentile latency: {tail_latency:.2f}ms\")\n```","diagram":"flowchart TD\n  US[US-East] --> Inter[Inter-Region Links]\n  EU[EU-Central] --> Inter\n  APAC[APAC-West] --> Inter\n  Inter --> Telemetry[Telemetry Stream]\n  Inter --> Intra[Intra-Region Traffic]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Google","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T06:08:48.314Z","createdAt":"2026-01-20T21:41:22.123Z"},{"id":"q-499","question":"How would you design a TCP load balancer that handles 1M concurrent connections with consistent hashing while preventing connection thrashing during backend failures?","answer":"Implement a ring-based consistent hash with virtual nodes for even distribution. Use connection pooling with health checks and circuit breakers. During failures, gradually drain connections using weig","explanation":"## Key Components\n\n- **Consistent Hashing**: Ring-based with 160 virtual nodes per backend\n- **Connection Management**: Keep-alive pools with configurable timeouts\n- **Failure Detection**: Active health checks with 5s interval, 3 failures threshold\n- **Traffic Distribution**: Weighted round-robin during failover\n\n## Implementation Details\n\n```go\n// Consistent hash ring implementation\ntype HashRing struct {\n  nodes map[uint32]string\n  sorted []uint32\n  replicas int\n}\n\n// Connection state tracking\ntype ConnTracker struct {\n  active map[string]int\n  maxConns int\n  drainMode bool\n}\n```\n\n## Production Considerations\n\n- **SYN Flood Protection**: Enable SYN cookies and rate limiting\n- **Connection Draining**: 30s graceful shutdown period\n- **Metrics**: Track connection distribution, latency, error rates\n- **Backpressure**: Implement TCP receive buffer tuning","diagram":"flowchart TD\n  A[Client Request] --> B[Load Balancer]\n  B --> C{Hash Ring}\n  C --> D[Backend Node 1]\n  C --> E[Backend Node 2]\n  C --> F[Backend Node 3]\n  D --> G[Health Check]\n  E --> G\n  F --> G\n  G --> H{Healthy?}\n  H -->|Yes| I[Route Traffic]\n  H -->|No| J[Remove from Ring]\n  J --> K[Gradual Drain]\n  K --> L[Rehash Connections]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2025-12-25T01:15:23.733Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-5183","question":"In a campus LAN, cross-switch reachability intermittently fails while same-subnet traffic remains OK. Provide a concrete diagnostic plan focusing on ARP resolution, CAM table aging, spanning-tree states, and port-security/storm-control configurations. Include exact commands and data to collect, and propose a mitigation that preserves L2 reachability?","answer":"Collect ARP entries (arp -a, ip neigh) and CAM table (show mac address-table), verify aging (show mac address-table aging-time), check STP state (show spanning-tree), and port-security counters (show ","explanation":"## Why This Is Asked\nTests practical L2 troubleshooting in campus networks; beginners connect theory to concrete commands. Covers ARP, CAM tables, STP, port-security, foundational and commonly misconfigured.\n\n## Key Concepts\n- ARP resolution\n- CAM/mac address aging\n- Spanning Tree Protocol and blocking/forwarding\n- Port-security and storm-control\n- Per-port statistics\n\n## Code Example\n```javascript\narp -a\nip neigh\n```\n\n## Follow-up Questions\n- How differentiate CAM aging vs topology loop?\n- What metrics indicate STP convergence issues?","diagram":"flowchart TD\n  Start[Start] --> ARP[ARP resolution]\n  ARP --> CAM[CAM table]\n  CAM --> STP[Spanning-Tree state]\n  STP --> Mit[Mitigation steps]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Goldman Sachs","Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T10:07:08.027Z","createdAt":"2026-01-21T10:07:08.027Z"},{"id":"q-5219","question":"In a two-building campus network with a single L3 inter-VLAN router and VLAN 10/20, a new SSH management server in VLAN 20 becomes intermittently unreachable from VLAN 10 during peak hours. No apps changes. Provide a concrete diagnostic plan to determine whether (a) ARP storms or MAC table flips, (b) inter-VLAN routing path flaps, (c) trunk misconfig or ACLs, or (d) switch QoS/buffering is responsible, with exact commands and data to collect, and propose a remediation that preserves L3 reachability?","answer":"Collect ARP and MAC stats, inter-VLAN path data, and interface counters. Steps: ping across VLANs, run arp -a, show mac address-table, show interfaces status, show interfaces counters errors, tracerou","explanation":"## Why This Is Asked\nTests structured triage using basic tools, not guesses.\n\n## Key Concepts\n- ARP/MAC learning and storms\n- Inter-VLAN routing paths and stability\n- Switchport/trunk configuration and ACLs\n- QoS and buffering implications\n\n## Code Example\n```javascript\n// Example: data collection stub (replace with real commands in practice)\nconsole.log('Collect ARP: arp -a');\nconsole.log('Show MAC-table: show mac address-table');\nconsole.log('Check interfaces: show interfaces status');\nconsole.log('Trace: traceroute to SSH host');\n```\n\n## Follow-up Questions\n- How would you automate this diagnostic data collection across multiple devices?\n- What remediation steps ensure continued VLAN isolation while removing the fault?","diagram":"flowchart TD\n  A[Host VLAN10] --> B[Inter-VLAN Router]\n  B --> C[Host VLAN20]\n  B --> D[Switch Ports]\n  E[ArpStormDetector] --> F[Data Collector]\n  F --> G[Remediation Plan]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Anthropic","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:11:18.534Z","createdAt":"2026-01-21T11:11:18.534Z"},{"id":"q-5232","question":"In a three-region VXLAN EVPN fabric with ECMP and IPsec inter-region tunnels, cross-region traffic between tenants experiences sporadic 200ms tail latency during peak hours, while intra-region is fine. No app changes. Provide a concrete diagnostic plan to determine whether (a) EVPN route convergence, (b) IPsec SA rekey/fragmentation, (c) NAT translation exhaustion, or (d) ECMP hashing on overlay/underlay is to blame, with exact commands and data to collect, and propose robust mitigations preserving isolation and telemetry reliability?","answer":"Plan: identify if (a) EVPN convergence delay, (b) IPsec SA rekey/fragmentation, (c) NAT port exhaustion, or (d) ECMP hashing is at fault. Include exact commands/data: show evpn route; show ip xfrm sta","explanation":"## Why This Is Asked\nTests practical triage across multi-region fabric, forcing candidates to distinguish between control-plane convergence, tunnel security lifecycles, NAT state pressure, and hashing behavior under load.\n\n## Key Concepts\n- EVPN route convergence and timing under churn\n- IPsec SA lifecycle, rekey bursts, and fragmentation\n- NAT translation handling and port exhaustion under concurrency\n- ECMP/hash behavior across overlay vs underlay paths\n\n## Code Example\n```javascript\n// Pseudo-commands flow (illustrative)\ncollectData();\nlogEVPN();\nlogIPsec();\nlogNAT();\ncalcPathHashes();\nproveMitigation();\n```\n\n## Follow-up Questions\n- How would you validate per-tenant isolation in telemetry after a mitigation?","diagram":"flowchart TD\n  Edge[Edge Router] --> IPsec[IPsec Inter-Region Tunnel]\n  IPsec --> EVPN[EVPN Route/ARPs]\n  EVPN --> TenantA[Tenant A Traffic]\n  EVPN --> TenantB[Tenant B Traffic]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Discord","Meta","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:47:51.962Z","createdAt":"2026-01-21T11:47:51.962Z"},{"id":"q-5432","question":"In a dual-stack data center, a new UDP telemetry stream over **IPv6** intermittently experiences 200–400 ms tail latency, while **IPv4** telemetry remains fine. IPv6 uses a separate GRE tunnel; IPv4 uses standard VXLAN. No app changes. Provide a concrete **diagnostic plan** to identify whether (a) **IPv6 tunnel MTU/fragmentation**, (b) **GRE keepalive/session stability**, (c) **IPv6 neighbor discovery delays**, or (d) **ECMP hashing on the IPv6 path** is to blame, with exact commands and data to collect, and propose robust mitigations that preserve telemetry reliability?","answer":"Execute IPv6-specific diagnostics: ping6 to the collector, traceroute6, and tracepath6; inspect MTU on the GRE tunnel and IPv6 interfaces; capture tcpdump on the GRE/underlay; compare with IPv4 path. Mitigations include adjusting MTU, enabling GRE keepalives, optimizing neighbor discovery timers, and verifying ECMP hashing consistency.","explanation":"## Why This Is Asked\nTests practical IPv6 debugging skills and MTU awareness for beginners.\n\n## Key Concepts\n- IPv6 MTU/PMTUD\n- GRE tunnels\n- IPv6 neighbor discovery\n- ECMP hashing\n\n## Code Example\n```javascript\n# Commands to gather data (adjust for environment)\nping6 -c 5 collector.example\ntraceroute6 -n collector.example\ntracepath6 -n collector.example\n```\n```\n#!/bin/bash\n# Collect GRE/IPv6 path data\nip -6 addr show\nip -6 route show\ntcpdump -i gre0 -n icmp || true\n```\n\n## Follow-up Questions\n- How would you validate PMTUD after MTU changes?\n- How would you verify ECMP hashing stability for telemetry flows?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Microsoft","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T06:04:11.650Z","createdAt":"2026-01-21T22:08:20.824Z"},{"id":"q-5447","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across transit providers, a new cross-tenant telemetry UDP stream is intermittently dropped during peak hours due to per-tenant microsegmentation policies at the edge that pin flows to a subset of egress links. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant ACLs/PBR skew ECMP hashing, (b) EVPN route convergence under multi-tenant policy changes, (c) NAT translation state exhaustion per tenant, or (d) inter-region load balancer flow-split, and propose robust mitigations preserving telemetry reliability and tenant isolation?","answer":"Investigate whether per-tenant ACLs/PBR are skewing ECMP hashing and pinning telemetry flows to limited egress links. Collect per-tenant ACL counters, PBR statistics, ECMP hash distribution metrics, and inter-region convergence data. Analyze patterns to identify if policy enforcement is causing flow pinning or hash imbalance across transit providers.","explanation":"## Why This Is Asked\nTests the ability to diagnose complex multi-tenant edge policy interactions with ECMP and EVPN across distributed regions—a realistic production challenge for large-scale cloud and network fabrics.\n\n## Key Concepts\n- Per-tenant ACL/PBR impact on ECMP hashing and flow distribution\n- EVPN route convergence under multi-tenant policy changes\n- NAT translation state management per tenant\n- Inter-region load balancer behavior and flow-splitting mechanisms\n\n## Code Example\n```javascript\n// Example: map tenant to ECMP bucket for even distribution\nfunction bucket(tenantId, buckets){ return Math.abs(hashCode(tenantId)) % buckets; }\n```\n\n## Follow-up Questions\n- How would you implement flow entropy preservation for UDP telemetry streams?\n- What monitoring strategies would detect ECMP hash skew in real-time?\n- How can you validate that tenant isolation remains intact during mitigations?","diagram":"flowchart TD\n  A[Start] --> B[Collect per-tenant ACL/PBR stats]\n  B --> C[Check ECMP hash distribution across tenants]\n  C --> D{Issue reproduced?}\n  D -->|Yes| E[Adjust policies or hashing]\n  D -->|No| F[Inspect EVPN/NAT policy state]\n  E --> G[Validate telemetry reliability]\n  G --> H[End]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T04:49:00.725Z","createdAt":"2026-01-21T22:49:17.096Z"},{"id":"q-5656","question":"Three-region WAN (US-East, EU-Central, APAC-East) using public internet and UDP telemetry between EU-Central and US-East; tail latency spikes during business hours with no app changes. Design a concrete diagnostic plan to determine whether (a) QoS/policer misconfiguration on edge devices, (b) link-level queue depth and ECMP flow pinning, (c) MTU fragmentation on the UDP path, or (d) path asymmetry from inter-provider routing, with exact commands and data to collect. Propose a robust mitigation preserving telemetry reliability?","answer":"Collect per-hop latency and MTU data, inspect edge QoS (show policy-map, tc qdisc), measure interface queue depths, perform UDP-specific tests (iperf3 -u -b 10M) and ping with DF bit set, and run trac","explanation":"## Why This Is Asked\nBeginners analyze real cross-region troubleshooting without app changes.\n\n## Key Concepts\n- QoS configuration and its impact on latency\n- UDP fragmentation and MTU\n- ECMP flow behavior and queueing\n\n## Code Example\n```bash\n# sample commands to run\nsudo tc -s qdisc show dev eth0\nsudo ping -c 20 -M do -s 1472 <destination>\nsudo tcpdump -i any udp and port <telemetry_port>\n```\n\n## Follow-up Questions\n- How would you verify ECMP hashes are not starving telemetry? \n- How would you rollout changes safely across regions?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","Plaid","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T10:13:12.978Z","createdAt":"2026-01-22T10:13:12.978Z"},{"id":"q-5662","question":"In a three-region VXLAN EVPN fabric with SRv6 underlay and ECMP, a high-rate cross-region telemetry UDP stream shows tail latency spikes when traffic from US-East to EU-Central. No app changes. Provide a concrete diagnostic plan to determine whether (a) SRv6 path steering, (b) EVPN route convergence delays, (c) SRv6 MTU/fragmentation, or (d) edge shaping is responsible, with exact commands and data to collect, and propose robust mitigations preserving telemetry reliability?","answer":"Plan: instrument per-SRv6 tracing, gather SRv6 policy counters, verify MTU/fragments on the SR-encapsulated underlay, inspect EVPN/BGP convergence timings, and monitor UDP drop counters at edge/collec","explanation":"## Why This Is Asked\nTests advanced network diagnostics across underlay overlays, focusing on SRv6, EVPN convergence, and edge QoS—critical in multi-region environments.\n\n## Key Concepts\n- SRv6 path steering and counters\n- EVPN route convergence timing\n- MTU/fragmentation in SR-encapsulated tunnels\n- Edge shaping and QoS policies\n\n## Code Example\n```bash\n# Example diagnostic commands\nip -s link\nping -M do -s 1472 <dest>\nshow sr policy\ntcpdump -i <edge-if> udp port 5000\n```\n\n## Follow-up Questions\n- How would you validate that a change improves telemetry latency without affecting other traffic?\n- What artifacts would you collect to reproduce failure in a lab?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Apple","Lyft","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T10:44:57.258Z","createdAt":"2026-01-22T10:44:57.258Z"},{"id":"q-5816","question":"In a four-region deployment (NA, EU, APAC, LATAM) using a SRv6-based WAN with ECMP across multiple providers, a new cross-region telemetry UDP stream exhibits tail latency spikes during peak hours while intra-region remains low. No app changes. Provide a concrete diagnostic plan to determine whether (a) SRv6 path steering/hash, (b) inter-provider TE churn, (c) MTU/fragmentation in SRv6 tunnels, or (d) NAT64 state is at fault, with exact commands and data to collect, and propose robust mitigations preserving telemetry reliability?","answer":"Instrument per-path SRv6 telemetry across all four regions. Collect per-hop latency (traceroute6), MTU visibility, SID binding and steering counts, TE path churn, NAT64 translation table hits and time","explanation":"## Why This Is Asked\nTests ability to reason about advanced WAN architectures beyond ECMP/NAT storytelling, focusing on SRv6 traffic steering, TE churn, and NAT64 state.\n\n## Key Concepts\n- SRv6, traffic engineering (TE), MTU discovery, NAT64 state tracking\n- Path steering/hash behavior under peak load\n- Telemetry reliability across multi-provider WAN\n\n## Code Example\n```javascript\n// Pseudo-collection trigger for SRv6 telemetry data\nfunction collectSRv6Telemetry(edge) {\n  return edge.get('sidBindings')\n    .concat(edge.get('teStats'))\n    .concat(edge.get('nat64TableHits'));\n}\n```\n\n## Follow-up Questions\n- How would you design tests to distinguish SRv6 steering churn from NAT64 exhaustion?\n- What metrics and alarms would indicate a needed re-tune of TE policies or MTU sizing?","diagram":"flowchart TD\n  A[SRv6 Path] --> B[Edge Router 1]\n  A --> C[Edge Router 2]\n  B --> D[Telemetry Collector]\n  C --> D","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Anthropic","DoorDash","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-22T17:54:17.367Z","createdAt":"2026-01-22T17:54:17.367Z"},{"id":"q-583","question":"How would you design a load balancer to handle 1M concurrent connections with sub-10ms latency, considering TCP connection pooling, health checks, and graceful degradation?","answer":"Implement an L4 load balancer using epoll/kqueue for efficient I/O multiplexing. Leverage connection pooling with TCP keep-alive to minimize connection overhead, and implement both active and passive health checks with exponential backoff strategies. Add circuit breakers and rate limiting for graceful degradation under high load.","explanation":"## Architecture\n- **L4 Load Balancer**: TCP-level routing for optimal performance and minimal latency\n- **Connection Pooling**: Reuse connections with persistent keep-alive mechanisms\n- **Health Checks**: Dual approach with active HTTP probes and passive monitoring\n- **Graceful Degradation**: Circuit breakers and rate limiting for fault tolerance\n\n## Implementation\n```nginx\nupstream backend {\n    least_conn;\n    server 10.0.1.1:80 max_fails=3 fail_timeout=30s;\n    keepalive 1000;\n}\n```\n\n## Monitoring\n- Track connection metrics and latency percentiles in real-time\n- Alert when error rates exceed 1% threshold\n- Implement auto-scaling based on active connection count","diagram":"flowchart TD\n  A[Client Request] --> B[L4 Load Balancer]\n  B --> C[Connection Pool]\n  C --> D[Health Check]\n  D --> E[Backend Server]\n  E --> F[Response]\n  F --> G[Client]\n  D -->|Failed| H[Circuit Breaker]\n  H --> I[Graceful Degradation]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":["load balancer","tcp connection pooling","health checks","circuit breakers","graceful degradation","i/o multiplexing","connection pooling"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:51:28.197Z","createdAt":"2025-12-27T01:14:00.333Z"},{"id":"q-6017","question":"Three-region deployment (US-East, EU-Central, APAC) uses VXLAN EVPN fabric with ECMP across transport providers. A new cross-region UDP telemetry stream shows tail latency spikes only for cross-region paths; intra-region latency is fine. No app changes. Provide a concrete diagnostic plan to determine whether (a) NIC offload misbehavior (GRO/TSO/LRO) on cross-region interfaces, (b) ECMP hashing for cross-region paths, (c) inter-region MTU/fragmentation, or (d) edge queueing/rate-limiting is to blame, with exact commands and data to collect, and propose mitigations?","answer":"Audit cross-region NIC offloads on edge interfaces and compare latency with offloads enabled vs disabled. Collect interface stats with ethtool -S, ethtool -k, and apply ethtool -K ethX gro off; tso on","explanation":"## Why This Is Asked\n\nExamines practical, production-grade debugging of packet processing hazards at the NIC and edge, not just routing. The candidate must map symptoms to low-level features and propose concrete, verifiable steps.\n\n## Key Concepts\n\n- NIC offloads and their impact on latency/reordering\n- EVPN/VXLAN behavior with ECMP across regions\n- Inter-region MTU/fragmentation and edge queueing\n\n## Code Example\n\n```bash\n# Inspect NIC offloads\nethtool -k ethX\n# Collect counters\nethtool -S ethX\n# Test with offloads disabled\nsudo ethtool -K ethX gro off\nsudo ethtool -K ethX lro off\n```\n\n## Follow-up Questions\n\n- How would you quantify reorder vs loss when offloads are disabled?\n- Which metrics would you monitor during a change window to ensure ECMP stability remains intact?","diagram":"flowchart TD\n  A[Three-region EVPN] --> B[Edge NICs]\n  B --> C[Inter-region paths]\n  C --> D[Telemetry collector]\n  D --> E[((Analytics/dashboard))]","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","Scale Ai","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T04:37:25.636Z","createdAt":"2026-01-23T04:37:25.636Z"},{"id":"q-6038","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP, telemetry UDP streams across tenants intermittently drop during peak hours when IPv6 with NAT64 is deployed at the edge. No app changes. Provide a concrete diagnostic plan to determine whether (a) NAT64 per-tenant state exhaustion, (b) IPv6 MTU/fragmentation, (c) ECMP hashing for IPv6 traffic, or (d) EVPN convergence with tenant prefixes is to blame, with exact commands and data to collect, and propose robust mitigations preserving telemetry reliability?","answer":"Plan: diagnose NAT64 per-tenant state exhaustion, IPv6 MTU/fragmentation, IPv6 ECMP hashing, and EVPN convergence. Collect: per-tenant NAT64 counters, IPv6 MTU probes, ECMP path distribution, EVPN rou","explanation":"## Why This Is Asked\n\nTests ability to diagnose multi-layer underlays (NAT64, IPv6 MTU, ECMP, EVPN) under peak load without app changes, a common advanced scenario in large-scale deployments.\n\n## Key Concepts\n\n- NAT64 translation state handling per tenant\n- IPv6 MTU/fragmentation in VXLAN overlays\n- ECMP hashing behavior for IPv6 traffic in multi-region fabrics\n- EVPN convergence and tenant-prefix propagation\n\n## Code Example\n\n```javascript\n// Pseudo diagnostic helper (illustrative)\nfunction collectNAT64Stats(tenantId){ /* query NAT64 per-tenant counters */ return {}; }\n```\n\n## Follow-up Questions\n\n- How would you distinguish NAT64 exhaustion from EVPN convergence delays?\n- What changes would you make to MTU discovery and ECMP hashing to stabilize telemetry throughput?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Coinbase","Plaid","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T05:59:52.310Z","createdAt":"2026-01-23T05:59:52.310Z"},{"id":"q-6109","question":"In a three-region VXLAN EVPN fabric (US-East, EU-Central, APAC) with ECMP across transit providers, a cross-region UDP telemetry stream intermittently drops during peak. No app changes. Provide a concrete diagnostic plan to determine whether (a) NIC RSS hashing collisions for cross-tenant flows, (b) SR-IOV offloads misbehaving under multi-tenant VFs, (c) edge flow director queueing, or (d) EVPN route churn under overload is to blame, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Root cause likely NIC RSS hashing collisions on cross-tenant UDP telemetry. Plan: (1) capture RSS settings and per-queue counters (ethtool -x; ethtool -k); (2) run tcpdump on telemetry UDP port across","explanation":"## Why This Is Asked\nTests depth in NIC offloads, EVPN behavior, and cross-region telemetry reliability under multi-tenant load.\n\n## Key Concepts\n- NIC RSS hashing and per-queue mapping\n- SR-IOV and VF offloads with multi-tenant workloads\n- EVPN route churn under overload\n- Edge queueing and tenant isolation\n\n## Code Example\n```bash\n# Inspect NIC and offloads\nethtool -x eth1\nethtool -k eth1\n# Capture cross-region telemetry on UDP port\ntcpdump -i any 'udp port 1620' -w /tmp/telemetry.pcap\n```\n\n## Follow-up Questions\n- How would you verify isolation while applying per-tenant queue mappings?\n- How would you validate that the mitigation does not degrade overall throughput?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Apple","Databricks","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T09:10:39.281Z","createdAt":"2026-01-23T09:10:39.281Z"},{"id":"q-6140","question":"In a distributed telemetry fabric using a DNS-based load balancer that round-robins UDP collectors across NA, EU, and APAC, devices intermittently reach different collectors and tail latency increases when peak traffic coincides with a collector outage. No app changes. Provide a concrete diagnostic plan to determine whether (a) DNS TTL caching causes stale mappings, (b) health checks remove backends too aggressively, (c) health-check probe cadence causes false failures, or (d) firewall rewriting DNS responses, with exact commands and data to collect, and propose mitigations that stabilize collector selection?","answer":"Collect DNS responses for telemetry.example.com (dig +short, TTL), run traceroute/ping to each collector IP, inspect load-balancer health-check logs, and reproduce with a fixed TTL to observe failover","explanation":"## Why This Is Asked\n\nDNS-based load balancing is common and tests understanding of TTLs, caching, health checks, and how they affect telemetry reliability across regions.\n\n## Key Concepts\n\n- DNS TTL and caching behavior\n- Health checks and backend pool updates\n- Latency tail and cross-region routing\n- DNS monitoring and troubleshooting\n\n## Code Example\n\n```bash\n# DNS lookup and TTL dump\ndig telemetry.example.com\n\n# Trace the resolution path\ndig +trace telemetry.example.com\n```\n\n## Follow-up Questions\n\n- How would you ensure sticky client mapping across TTL changes?\n- What additional monitoring would you add to detect stale DNS mappings in production?\n","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["NVIDIA","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T10:47:08.911Z","createdAt":"2026-01-23T10:47:08.911Z"},{"id":"q-6190","question":"In a multi-region VXLAN EVPN fabric with ECMP across providers, edge hosts implement per-tenant microsegmentation using eBPF at the kernel. A cross-tenant UDP telemetry stream intermittently drops under peak load. No app changes. Provide a concrete diagnostic plan to determine whether (a) BPF map sizing/hash collisions, (b) XDP redirection/encap path, (c) NIC RSS/GSO/LRO offloads, or (d) EVPN path selection interactions are responsible, with exact commands and data to collect, and propose mitigations?","answer":"Plan: confirm kernel path vs NIC path. Collect: bpftool map show; bpftool prog show; cat /sys/kernel/debug/tracing/trace; ethtool -k <iface> | grep -E 'gro|tso|lro'; tcpdump -i <iface> 'udp and port <","explanation":"## Why This Is Asked\n\nTests practical debugging of kernel-level networking with eBPF/XDP, per-tenant isolation, and cross-region telemetry, integrating underlay and overlay considerations.\n\n## Key Concepts\n\n- eBPF maps and XDP\n- NIC offloads (GRO/TSO/LRO)\n- EVPN/ECMP interactions\n- Telemetry reliability and tenant isolation\n\n## Code Example\n\n```javascript\n// pseudo eBPF outline\nchar* bpf_prog() {\n  // attach to TC/XDP, consult per-tenant map\n  return NULL;\n}\n```\n\n## Follow-up Questions\n\n- How would you mitigate map collisions if bursty tenants share the same hash bucket?\n- How would you validate end-to-end telemetry stability during peak without affecting other tenants?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Hugging Face","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T13:18:31.144Z","createdAt":"2026-01-23T13:18:31.145Z"},{"id":"q-6266","question":"In a two-site network (Site A and Site B) connected by VPN, api.example.com is reachable from Site A but not from Site B. DNS for api.example.com recently changed to a new IP, but Site B still resolves to the old IP. Provide a concrete, beginner-friendly diagnostic plan to verify (a) DNS resolution behavior from both sites (dig/nslookup, +trace, TTLs), (b) whether DNS caching or zone delegation is stale, (c) network reachability to both old and new IPs with traceroute and curl, and (d) edge firewall/NAT rules affecting outbound DNS/IP. Propose practical mitigations to restore service quickly?","answer":"Compare DNS from Site A and Site B using dig +trace and direct queries to the authoritative server; record TTLs and CNAMEs. From both sites, curl -I api.example.com and traceroute to the old and new I","explanation":"## Why This Is Asked\nTests DNS propagation, basic network troubleshooting, and edge-case cache issues in a multi-site setup.\n\n## Key Concepts\n- DNS TTL propagation\n- Local resolvers and caches\n- Basic reachability tools: curl, traceroute, dig\n- Edge firewall/NAT impact on DNS/IP traffic\n\n## Code Example\n```javascript\n// Node.js snippet to run a dig command and print results\nconst { exec } = require('child_process');\nexec('dig +trace api.example.com', (err, stdout, stderr) => {\n  if (err) { console.error(err); return; }\n  console.log(stdout);\n});\n```\n\n## Follow-up Questions\n- How would you verify TTL propagation across multiple resolvers?\n- How would you safely roll DNS changes with minimal downtime?","diagram":"flowchart TD\nA[Site A] --> B[Site B]\nB --> C[VPN Edge]\nC --> D[DNS Proxy]\nD --> E[API Endpoint]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["DoorDash","Square","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T16:59:37.797Z","createdAt":"2026-01-23T16:59:37.797Z"},{"id":"q-6370","question":"In a three-region deployment (US-East, EU-Central, APAC) with a shared per-tenant edge proxy handling both API and cross-region telemetry streams, a new cross-region gRPC telemetry channel stalls intermittently during peak hours while short API calls remain responsive. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant gRPC windowing at the edge causes head-of-line blocking, (b) HTTP/2 multiplexing-induced cross-tenant queue contention, (c) cross-region DNS load-balancing skew, or (d) edge TLS session resumption overhead, and propose mitigations preserving telemetry throughput?","answer":"Plan: instrument per-tenant edge proxy metrics (queue depth, outstanding streams, per-tenant buffers) and correlate stalls with gRPC window sizes and HTTP/2 multiplexing. Collect DNS TTLs, TLS resumpt","explanation":"## Why This Is Asked\n\nThis question probes ability to diagnose cross-region streaming bottlenecks at the network edge, focusing on per-tenant isolation and streaming protocols.\n\n## Key Concepts\n\n- gRPC streaming vs HTTP/2 multiplexing\n- Per-tenant fairness and edge proxy configuration\n- DNS-based routing and TTL effects\n- TLS session resumption and cache\n\n## Code Example\n\n```javascript\n// Example: correlate log timestamps with stream windows\nfunction correlate(events) {\n  // pseudo\n  return events.map(e => ({ts: e.ts, w: e.window}));\n}\n```\n\n## Follow-up Questions\n\n- How would you verify per-tenant fairness in the edge proxy during peak hours?\n- What concrete changes would you implement to reduce tail stalls without breaking isolation?","diagram":"flowchart TD\n  Edge[Edge Proxy] --> US[US-East Region]\n  Edge --> EU[EU-Central]\n  Edge --> AP[APAC]\n  US --> Telemetry[Telemetry Channel]\n  EU --> Telemetry\n  AP --> Telemetry","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Cloudflare","MongoDB","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-23T21:02:11.832Z","createdAt":"2026-01-23T21:02:11.832Z"},{"id":"q-6758","question":"Three-region deployment (US-East, EU-Central, APAC) using VXLAN EVPN with ECMP across transit providers. A new cross-tenant telemetry UDP stream shows intermittent drops and reorders during peak hours. Edge devices enforce per-tenant egress shaping and ACLs. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant shaping/policing skews ECMP hashing, (b) EVPN route convergence under tenant policy changes, (c) UDP checksum offload interactions with NICs, or (d) path MTU/fragmentation across tunnels is to blame, with exact commands and data to collect, and propose mitigations to preserve telemetry reliability and tenant isolation?","answer":"Plan: 1) verify per-tenant egress shaping/policers and ECMP hash bias with tc -s qdisc and ethtool -S; 2) examine NIC offload GRO/TSO interactions for UDP telemetry; 3) check cross-region MTU/fragment","explanation":"## Why This Is Asked\nWe add a new angle: cross-tenant telemetry issues tied to edge QoS and NIC offloads, not just underlay routing. This tests practical triage, data collection, and mitigation skills.\n\n## Key Concepts\n- ECMP hashing, per-tenant QoS, NIC offloads GRO/TSO, MTU, EVPN churn\n\n## Code Example\n```javascript\n// Sample commands to collect data\n```\n\n## Follow-up Questions\n- How would you validate the chosen mitigation preserves tenant isolation?\n- What metrics would you monitor post-change to ensure stability?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-24T16:39:20.309Z","createdAt":"2026-01-24T16:39:20.309Z"},{"id":"q-6918","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across transit providers, a new tenant-specific telemetry collector path intermittently drops during peak hours. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant EVPN route dampening causing path churn, (b) VXLAN tunnel MTU fragmentation, (c) control-plane replication delays in EVPN/ARP, or (d) per-tenant ACL/PBR misconfig causing asymmetric egress, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Implement a systematic diagnostic approach: (1) Verify BGP/EVPN route dampening configuration and per-tenant route stability across all peers; (2) Validate VXLAN tunnel MTU settings and monitor for fragmentation events on all transit paths; (3) Collect per-tenant ACL/PBR hit counters and NAT translation states; (4) Conduct end-to-end path tracing during peak traffic periods to identify asymmetric egress patterns. Mitigate by adjusting dampening thresholds, ensuring consistent MTU provisioning, optimizing control-plane replication timers, and verifying per-tenant policy consistency.","explanation":"## Why This Is Asked\nEvaluates expertise in diagnosing complex multi-region EVPN fabric issues affecting tenant-specific services, requiring systematic analysis of control-plane and data-plane interactions.\n\n## Key Concepts\n- EVPN route dampening mechanisms and tenant-specific route stability\n- VXLAN MTU provisioning and fragmentation impact on telemetry flows\n- Control-plane replication latency in distributed multi-region fabrics\n- Per-tenant ACL/PBR configuration consistency and ECMP asymmetric routing implications\n\n## Code Example\n```javascript\n// Diagnostic data collection framework\nconst collectTelemetryDiagnostics = {\n  bgpEvpnStatus: 'show bgp evpn summary',\n  routeDampening: 'show bgp dampening',\n  vxlanMtu: 'show interface vxlan',\n  aclCounters: 'show access-list',\n  pathTraceroute: 'traceroute tenant-collector'\n};\n```\n\n## Follow-up Questions\n- How would you implement automated monitoring and alerting for telemetry path degradation?\n- What mitigations would you prioritize to maintain tenant isolation while ensuring telemetry reliability?","diagram":"flowchart TD\n  A[US-East] --> B[Transit 1]\n  B --> C[EU-Central]\n  C --> D[APAC]\n  D --> E[Telemetry Collector]","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T05:53:17.975Z","createdAt":"2026-01-24T22:52:35.762Z"},{"id":"q-7001","question":"In a three-region VXLAN EVPN fabric (US-East, EU-Central, APAC) with ECMP across transit providers, a new cross-region UDP telemetry feed shows tail-latency spikes during peak hours. No app changes. Propose a concrete diagnostic plan to determine whether (a) control-plane time synchronization drift causing path churn, (b) EVPN route-refresh storms, (c) inter-region MTU/fragmentation of UDP telemetry, or (d) NIC timestamp offloads affecting capture. Include exact commands/data to collect, and mitigations preserving telemetry reliability?","answer":"Time-sync drift and control-plane churn suspected. Plan: verify NTP/PTP across regions; capture EVPN route-change rate and BFD timers; test UDP telemetry MTU fragmentation with ping -M do -s 1400; ins","explanation":"## Why This Is Asked\nThis question exams diagnosing subtle cross-region telemetry issues tied to time synchronization, control-plane stability, MTU handling, and NIC behavior, not just data-path faults.\n\n## Key Concepts\n- Time synchronization protocols (NTP/PTP)\n- EVPN route convergence and BFD timers\n- UDP telemetry MTU/fragmentation implications\n- NIC offloads and timestamp behavior\n\n## Code Example\n```javascript\n// Example: quick log parser for interval spikes\nconst fs=require('fs');\nconst lines=fs.readFileSync(process.argv[2],'utf8').split('\\n');\nlet spikes=0;\nlines.forEach(l=>{ if(/telemetry.*tail/.test(l)) spikes++;});\nconsole.log('spikes',spikes);\n```\n\n## Follow-up Questions\n- How would you automate this diagnostic with a runbook?\n- What thresholds would trigger configuration changes (timers, MTU, pacing)?","diagram":"flowchart TD\n  Start(Start) --> TimeSyncCheck[Check time sync across regions]\n  TimeSyncCheck --> EVPNCheck{EVPN route-change rate ok?}\n  EVPNCheck --> UDPPath{UDP telemetry path healthy?}\n  UDPPath --> Mitigations[Run mitigations]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Citadel","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T04:39:52.754Z","createdAt":"2026-01-25T04:39:52.754Z"},{"id":"q-7054","question":"In a three-building campus Wi‑Fi 6 deployment used for video conferencing, intermittent roaming freezes cause brief call drops during peak hours. No app changes. Provide a concrete diagnostic plan to determine whether (a) 802.11k/v/r roaming is enabled and misconfigured, (b) AP load/channel plan causes missed handoffs, or (c) rogue APs or interference affect roaming, with exact commands and data to collect, and propose a practical mitigation that preserves seamless roaming?","answer":"To diagnose, collect per-AP client counts, RSSI, retransmits and handoff latency from the wireless controller; enable 802.11k/v/r traces; capture spectrum during peak; compare roaming events to channe","explanation":"## Why This Is Asked\nTests practical roaming diagnostics in campus Wi‑Fi with 802.11k/v/r. \n\n## Key Concepts\n- Roaming decisions, 802.11k/v/r usage\n- Interference, channel planning, power control\n- Baseline measurements and triage\n\n## Code Example\n```javascript\n// Example CLI: show ap stats (vendor dependent)\n// show ap stats; show clients on AP; capture spectrum\n```\n\n## Follow-up Questions\n- How would you verify fast BSS transition settings on the controller? \n- How would you validate no rogue AP exists during a spectrum dump?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Tesla","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T07:36:30.280Z","createdAt":"2026-01-25T07:36:30.280Z"},{"id":"q-7143","question":"In a two-site VXLAN EVPN fabric linking NYC and SF with ECMP across transit, a tenant’s cross-site VM live migrations experience intermittent jitter during peak hours. No app changes. Provide a concrete diagnostic plan to determine whether (a) EVPN route dampening or route flap on NVE peers, (b) MAC/IP learning instability, (c) VTEP multicast/replication bottlenecks, or (d) per-tenant PBR causing path churn, with exact commands and data to collect, and propose mitigations preserving tenant isolation?","answer":"Propose a stepwise plan: capture BGP neighbor state, EVPN route history, MAC/IP table churn, VTEP replication stats, PBR rules. Collect: show bgp evpn summary, show evpn xcon, show mac, show arp, tcpd","explanation":"## Why This Is Asked\n\nTests debugging multi-site EVPN issues, route dampening, MAC learning, and VTEP replication under load.\n\n## Key Concepts\n\n- EVPN route dampening and flap control\n- MAC/IP learning stability in VXLAN\n- VTEP replication and multicast paths\n- Per-tenant PBR and path churn\n\n## Code Example\n\n```javascript\n// Example data collection snippet (pseudocode)\ncollect = [\"bgp evpn summary\", \"evpn mac\", \"arp -a\", \"tcpdump -i vxlan0\"]\n```\n\n## Follow-up Questions\n\n- How would you validate a mitigation without impacting other tenants?\n- Which metrics indicate a root cause and what thresholds matter?\n","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Apple","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T10:49:43.964Z","createdAt":"2026-01-25T10:49:43.964Z"},{"id":"q-7179","question":"In a three-region WAN (US-East, EU-Central, APAC) using VXLAN EVPN fabric with IPv6 multicast for telemetry, cross-region multicast latency spikes while intra-region is fine. No app changes. Provide a concrete diagnostic plan to determine whether (a) edge multicast replication delay, (b) EVPN multicast route scaling/dampening, (c) IPv6 UDP VXLAN MTU/fragmentation, or (d) PIM/IGMP join processing at edge are to blame, with exact commands and data to collect, and propose mitigations preserving telemetry latency and reliability?","answer":"Isolate multicast path end-to-end. Verify EVPN IPv6 multicast routes, monitor per-edge replication latency, and inspect PIM join trees. Collect: tcpdump -i <edge> udp port 4789 for VXLAN, show evpn mu","explanation":"## Why This Is Asked\n\nTests ability to diagnose complex, real‑world WAN issues involving multicast over VXLAN EVPN at scale, focusing on edge replication, control plane dampening, and MTU interactions across IPv6.\n\n## Key Concepts\n\n- IPv6 multicast in EVPN/VXLAN\n- Cross-region replication and ECMP implications\n- MTU/fragementation and UDP characteristics\n- PIM/IGMP join processing at edge devices\n\n## Code Example\n\n```javascript\n// Script sketch: collect per-edge multicast stats\nconsole.log('collect multicast stats');\n```\n\n## Follow-up Questions\n\n- How would you verify that a change in MTU alleviates the issue without breaking intra-region traffic?\n- Which observability signals are most trustworthy for multicast path health in this fabric?","diagram":"flowchart TD\n  A[Telemetry multicast path] --> B[Check replication delay]\n  B --> C{Issue?}\n  C -->|Yes| D[Inspect edge replication config]\n  C -->|No| E[Check MTU/fragmentation]\n  E --> F[Review PIM/IGMP]\n  F --> G[Implement mitigations]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Anthropic","Apple"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T13:09:55.299Z","createdAt":"2026-01-25T13:09:55.299Z"},{"id":"q-7229","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across multiple transit providers, a new cross-region UDP telemetry stream shows sporadic tail latency spikes during mid-day while intra-region latency remains flat. A novel SRv6-based interconnect steers inter-region traffic with per-path SIDs. No app changes. Provide a concrete diagnostic plan to determine whether (a) SRv6 SID stack path selection causes cross-region asymmetry, (b) ECMP hashing across SRv6 tunnels, (c) MTU fragmentation on SRv6 encapsulation, or (d) SRv6 policy distribution delays are to blame, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and cross-region performance?","answer":"Measure UDP telemetry RTT/jitter per SRv6 path (iperf3 -6, ping6) and map paths with traceroute6. Inspect SRv6 state: SID maps and per-path policies via seg6 tooling or ip -6 route show. Compare MTU a","explanation":"## Why This Is Asked\nTests the ability to reason about new interconnect paradigms (SRv6-based steering) and multi-region telemetry reliability, beyond standard ECMP checks.\n\n## Key Concepts\n- SRv6 service chaining and per-path SIDs\n- ECMP hashing with SRv6 tunnels\n- MTU discovery/fragmentation in SRv6 encapsulation\n- Telemetry reliability under dynamic policy updates\n\n## Code Example\n```bash\n# Pseudo: inspect SID map and policy (tool names vary by vendor)\nseg6ctl show-sids\nseg6ctl show-policies\n```\n\n## Follow-up Questions\n- How would you design a monitoring plan to detect policy distribution delays in real time?\n- What mitigations would you apply to restore telemetry stability if misordering is observed on one region?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T14:42:12.804Z","createdAt":"2026-01-25T14:42:12.804Z"},{"id":"q-7282","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across transit providers, a new cross-region UDP telemetry stream intermittently drops during peak hours. Per-tenant rate limiters at the edge implement token buckets synchronized by NTP. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant NTP drift causes token refill timing skew, (b) ECMP hashing interacts with per-tenant rate queues, (c) UDP port reuse or firewall statefulness blocks bursts, or (d) inter-region load balancers split flows, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Plan: confirm time-sync uniformity across edge devices and tenants; compare token-refill timestamps to drop windows; collect per-tenant queue depths, pcap traces, and ECMP path hashes during bursts; r","explanation":"## Why This Is Asked\nTests ability to diagnose how time synchronization and per-tenant rate limiting interact in a multi-region fabric, ensuring telemetry reliability under peak load.\n\n## Key Concepts\n- Time synchronization (NTP/PTP) across edge devices\n- Per-tenant token bucket rate limiting\n- ECMP behavior with per-tenant queues\n- Cross-region telemetry reliability and isolation\n\n## Code Example\n```javascript\n// Example: simple token bucket sketch (conceptual)\nfunction refill(tokens, rate, capacity) {\n  // placeholder logic for illustration\n}\n```\n\n## Follow-up Questions\n- How would you verify clock drift impact without stopping traffic?\n- What changes to per-tenant limits would maintain isolation while absorbing bursts?","diagram":null,"difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Hashicorp","LinkedIn","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T16:49:51.280Z","createdAt":"2026-01-25T16:49:51.280Z"},{"id":"q-7341","question":"In a four-region deployment using a VXLAN EVPN fabric with multicast replication for telemetry streams, a cross-region UDP telemetry flow intermittently drops during peak hours for certain tenants. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant IGMP/MLD snooping state pruning is cutting trees, (b) multicast group membership consistency across regions via mtrace/PIM neighbors is failing, (c) per-tenant edge ACLs block multicast, or (d) RPF failures due to dynamic path changes, with exact commands and data to collect, and propose mitigations?","answer":"Plan to diagnose intermittent cross-region multicast drops for telemetry in a four-region EVPN fabric. Check per-tenant IGMP/MLD snooping state and pruning, verify multicast group membership across re","explanation":"## Why This Is Asked\n\nTests expertise in multicast behavior within EVPN fabrics and how per-tenant policies can affect telemetry delivery without app changes.\n\n## Key Concepts\n\n- EVPN multicast replication, PIM, IGMP/MLD snooping, RPF checks\n- Multicast pruning, per-tenant ACLs, cross-region consistency\n- Telemetry reliability under peak loads, least-disruptive diagnostics\n\n## Code Example\n\n```markdown\n# Example diagnostic commands\nshow ip mroute vrf TENANT-A\nshow ip igmp groups vrf TENANT-A\nshow pim neighbors\ntcpdump -i mgmt0 udp dst port 520\n```\n\n## Follow-up Questions\n\n- How would you validate tree stability during a failover?\n- What non-disruptive instrumentation would you add to prevent tenant impact during diagnosis?","diagram":"flowchart TD\n  A[Telemetry Tenant] --> B[Multicast Group] \n  B --> C[Region-1 Edge]\n  B --> D[Region-2 Edge]\n  B --> E[Region-3 Edge]\n  B --> F[Region-4 Edge]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Google","IBM","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T19:29:17.113Z","createdAt":"2026-01-25T19:29:17.113Z"},{"id":"q-7379","question":"In a two-region edge network (US-East and EU-Central) delivering UDP telemetry to a central collector, tail latency spikes occur during business hours while intra-region latency remains flat. No app changes. Outline a concrete diagnostic plan to determine whether (a) edge QoS/DSCP rewriting causes latency, (b) MTU fragmentation in UDP tunnels, (c) dynamic routing path changes, or (d) firewall rate-limiting; include exact commands and data to collect, and propose mitigations?","answer":"Capture cross-edge UDP 3000 traffic to compare DSCP markings and drops; use tcpdump on source and WAN edge, then tc -s qdisc for drops. Perform MTU tests (ping -M do -s 1472) and tracepath to confirm ","explanation":"## Why This Is Asked\nTests basic network diagnostic thinking for telemetry reliability across regions, focusing on real-world constraints like QoS, MTU, routing, and firewall behavior.\n\n## Key Concepts\n- DSCP QoS handling across WAN edges\n- PMTUD and MTU fragmentation in tunnels\n- Path stability vs routing churn\n- Firewall rate limits and NAT state tracking\n\n## Code Example\n```javascript\n// no code required for this question\n```\n\n## Follow-up Questions\n- How would you validate a change to DSCP policies without impacting existing traffic?\n- What monitoring dashboards would you prepare to catch regressions quickly?\n","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Tesla","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-25T20:48:21.089Z","createdAt":"2026-01-25T20:48:21.089Z"},{"id":"q-7446","question":"In a three-region deployment (US-East, EU-Central, APAC) using a VXLAN EVPN fabric with ECMP across transit providers, a new cross-region UDP telemetry stream experiences intermittent packet loss during peak hours due to a new per-tenant network policy at the edge that enforces per-tenant socket buffering limits. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant socket buffer limits cause tail-drop for high-bandwidth tenants, (b) ECMP hashing interactions with per-tenant queueing, (c) UDP port-based multi-queue distribution misalignment across NICs, or (d) NAT translation state exhaustion per tenant, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Begin with a per-tenant path audit: collect tc qdisc/classstats, per-tenant queue depths, ECMP hash seeds, and per-tenant NAT/session counts. Validate UDP path via tcpreplay/iperf3 UDP tests per tenant, correlating packet loss with buffer saturation events. Analyze ECMP hash distribution across transit paths and verify NIC multi-queue mapping for UDP port hashing. Monitor NAT state table utilization per tenant during peak telemetry streams.","explanation":"## Why This Is Asked\n\nTests ability to architect and diagnose cross-region telemetry degradation caused by edge policies and NIC-level behaviors, not application code.\n\n## Key Concepts\n- VXLAN EVPN with ECMP\n- UDP telemetry and per-tenant QoS\n- Edge buffering, NIC multi-queue, NAT state\n- Path hashing and topology changes\n\n## Code Example\n```bash\n# Quick data-collection scaffold\ntcpdump -i any 'udp and port 5000' -c 1000 -w /tmp/telemetry.pcap\nip route get <telemetry_dst>\ntc qdisc show\nethtool -S eth0\n```\n\n## Follow-up Questions\n- How would you validate fairness across tenants under bursty traffic conditions?\n- What metrics would you use to detect buffer exhaustion before packet loss occurs?\n- How would you implement automated remediation for per-tenant buffer saturation?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Databricks","Instacart","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T05:52:03.410Z","createdAt":"2026-01-25T23:48:49.279Z"},{"id":"q-7499","question":"In a four-region fabric deploying VXLAN EVPN with multi-tenant VRFs and per-tenant QoS, a new cross-region UDP telemetry stream experiences intermittent packet loss during peak times for a single tenant. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant NIC queue starvation at leaf switches, (b) per-tenant QoS scheduler misconfiguration causing tail drop, (c) ECMP hash imbalance on cross-region paths, or (d) MTU fragmentation along the path is to blame, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Collect per-tenant queue depths and drop counters on leaf ports; verify DSCP-to-queue mappings and WRED thresholds; inspect ECMP hash distribution for cross-region flows; check MTU and fragmentation a","explanation":"## Why This Is Asked\nTests real-world debugging across control and data planes under multi-region load. \n\n## Key Concepts\n- Per-tenant queueing and QoS configuration; ECMP hashing; MTU fragmentation; telemetry path discipline.\n\n## Code Example\n```javascript\n// Pseudo: fetch per-tenant queue depth via NETCONF/RESTCONF and correlate with loss window\nasync function getTenantQueue(tenantId){\n  const q = await fetch(`/api/tenants/${tenantId}/queues`).then(r=>r.json())\n  return q\n}\n```\n\n## Follow-up Questions\n- How would you reconfigure policies to avoid tail drops while preserving isolation?\n- What metrics indicate a switch-level bottleneck versus a path issue?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Anthropic","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T04:37:31.813Z","createdAt":"2026-01-26T04:37:31.813Z"},{"id":"q-7523","question":"In a two-region deployment (US-East, EU-Central) hosting a regional analytics API behind a global DNS and regional load balancers, EU clients intermittently resolve to US endpoints during peak hours. No app changes. Provide a concrete diagnostic plan to determine whether (a) DNS TTL/cache behavior, (b) geolocation-based DNS routing rules, or (c) edge LB health checks are to blame, with exact commands and data to collect, and propose mitigations that keep region-local endpoints stable?","answer":"Plan: verify region-local routing by querying DNS from EU and US resolvers, using dig +trace and dig @resolver api.example.com; compare A-record results and TTLs; run traceroute/tracepath to EU endpoi","explanation":"## Why This Is Asked\nTests practical DNS- and LB-related troubleshooting that intermediate engineers confront in global deployments. It emphasizes data collection, reproducibility, and concrete mitigations rather than theory.\n\n## Key Concepts\n- DNS TTL and resolver caching\n- Geolocation-based routing rules\n- Regional load balancer health checks and failover\n- Traceroute/tracepath, dig +trace, and MTR for path visibility\n\n## Code Example\n```javascript\n// Simple DNS lookup example using Node.js\nconst dns = require('dns');\ndns.resolve4('api.example.com', (err, addresses) => {\n  console.log(addresses, err);\n});\n```\n\n## Follow-up Questions\n- How would you design a minimal reproducible test for this issue?\n- What mitigations would you apply if you must avoid application changes?","diagram":"flowchart TD\nEU_Client[EU Client] --> DNS[DNS Resolver (EU)]\nDNS --> LB_EU[Regional LB EU]\nLB_EU --> API_EU[EU Endpoint]\nAPI_EU --> Internet[Public Internet]\n\nEU_Client -->|Latency clues| Traceroute[Traceroute to EU endpoint]\n","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Meta","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T05:51:17.339Z","createdAt":"2026-01-26T05:51:17.339Z"},{"id":"q-7651","question":"Two VLANs in a campus network (VLAN10 192.168.10.0/24 and VLAN20 192.168.20.0/24) share a L3 gateway. A server on VLAN20 is intermittently unreachable from VLAN10 during business hours. Provide a concrete diagnostic plan to determine whether (a) inter-VLAN routing misconfig on the gateway, (b) MTU fragmentation on trunks, (c) ARP/MAC instability on core switches, or (d) ACL/PBR on the gateway affecting inter-subnet traffic, with exact commands and data to collect, and propose mitigations?","answer":"Begin with end-to-end checks: ping and traceroute across subnets to confirm reachability, then validate routing with show ip route and show ip arp, inspect MAC tables, and verify trunk MTU with show i","explanation":"## Why This Is Asked\n\nTests practical troubleshooting steps for inter-subnet connectivity, focusing on routing state, MTU, MAC learning, and policy controls without app edits.\n\n## Key Concepts\n\n- Inter-VLAN routing, MTU and fragmentation, ARP/MAC learning, ACLs and PBR.\n- How to collect deterministic data across devices and interpret it.\n\n## Code Example\n\n```javascript\n// Simple latency summarizer (conceptual)\nfunction avgLatency(samples){return samples.reduce((a,b)=>a+b,0)/samples.length}\n```\n\n## Follow-up Questions\n\n- How would you differentiate MTU issues from path MTU discovery failures?\n- What changes would you implement to minimize recurrence while preserving security policies?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Microsoft","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T11:14:29.953Z","createdAt":"2026-01-26T11:14:29.953Z"},{"id":"q-7658","question":"In a four-region deployment (US-East, EU-Central, APAC, LATAM) using a VXLAN EVPN fabric with ECMP across multiple transit providers, a per-tenant UDP telemetry stream is intermittently dropped when new tenants are onboarded and under IPv6 traffic. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant eBPF filters or map collisions causing misrouting, (b) UDP checksum offloads interacting with NIC features, (c) kernel queuing pressure on the telemetry path, or (d) EVPN VXLAN route convergence delays for tenants, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Diagnose plan: 1) audit per-tenant eBPF maps and hash collisions (bpftool map dump, show prog); 2) monitor per-tenant qdisc depths (tc -s qdisc) and per-tenant queue occupancy; 3) capture UDP flows wi","explanation":"## Why This Is Asked\nAdvanced network operators must diagnose cross-tenant data-plane issues that blend programmable NICs, EVPN control planes, and kernel paths. This question probes tooling, data collection discipline, and concrete mitigations under realistic rollouts.\n\n## Key Concepts\n- eBPF data planes and maps\n- EVPN/VXLAN multi-tenant routing\n- NIC offloads and kernel queuing\n- Troubleshooting in IPv6 environments\n\n## Code Example\n```bash\n# Example commands for initial triage (not a solution)\nbpftool map show\nbpftool prog show\nip -s link\nethtool -k eth0\n```\n\n## Follow-up Questions\n- How would you differentiate a hash collision from an intentional per-tenant policy decision?\n- What changes would you make to prevent future cross-tenant drops while preserving isolation?","diagram":"flowchart TD\n  Telemetry[Telemetry Stream] --> EdgePath[Edge eBPF Path]\n  EdgePath --> Diagnostic[Diagnostics]\n  Diagnostic -->|Plan A| PlanA[Check eBPF maps & hashes]\n  Diagnostic -->|Plan B| PlanB[Inspect NIC offloads & queues]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Hugging Face","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T11:43:42.628Z","createdAt":"2026-01-26T11:43:42.628Z"},{"id":"q-7690","question":"In a campus WAN with central DHCP and two subnets 10.0.1.0/24 and 10.0.2.0/24, DHCP clients intermittently fail to obtain addresses during mid-day. No server changes. Provide a concrete diagnostic plan to determine whether (a) relay agent configuration on edge switches is incorrect, (b) DHCP scope exhaustion or exclusions, (c) VLAN/trunk misconfig causing broadcast drops, or (d) DHCP snooping/port-security blocking relay traffic, with exact commands and data to collect, and propose mitigations to restore reliable DHCP service?","answer":"1) Verify DHCP relay settings and pools: show ip dhcp binding, show ip dhcp pool, show run | include ip helper-address. 2) Check relay reachability and scopes: ping the helper IP from clients’ subnet;","explanation":"## Why This Is Asked\nTests practical DHCP debugging in campus networks, ensuring candidates map symptoms to verifiable data. \n\n## Key Concepts\n- DHCP relay and pools\n- VLANs and trunks\n- DHCP snooping and port-security\n- DHCP packet capture\n\n## Code Example\n```bash\n# capture DHCP traffic\ntcpdump -i eth0 'udp port 67 or 68' -w dhcp.cap\n```\n\n## Follow-up Questions\n- How would you confirm a specific relay path is failing?\n- What changes would you make to mitigate future drops?","diagram":null,"difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["DoorDash","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T13:31:57.130Z","createdAt":"2026-01-26T13:31:57.130Z"},{"id":"q-7892","question":"In a two-site WAN (HQ and Data Center) connected by IPsec tunnels with NAT-T, a newly observed UDP telemetry stream from HQ to Data Center shows intermittent tail latency during peak hours while TCP/SSH latency remains normal. No app changes. Provide a concrete diagnostic plan to determine whether (a) underlay path asymmetry, (b) IPsec MTU/fragmentation, (c) NAT-T translation state, or (d) edge QoS/rate-limiting is to blame, with exact commands and data to collect, and propose mitigations that stabilize UDP telemetry without impacting other traffic?","answer":"Plan: 1) traceroute HQ-DC and DC-HQ; 2) test MTU with ping -M do -s 1472 across IPsec; 3) tcpdump \"udp and host <telemetry_ip>\" on both ends to capture timing/loss; 4) inspect NAT-T state and QoS rule","explanation":"## Why This Is Asked\n\nAssess practical troubleshooting of VPNs, MTU, NAT-T, and QoS in a realistic telemetry scenario. Keeps it beginner-friendly yet concrete with commands and data collection steps.\n\n## Key Concepts\n\n- IPsec NAT-T behavior and PMTUD\n- MTU fragmentation and path MTU discovery\n- NAT-T translation state tracking\n- QoS/traffic shaping on edge devices\n\n## Code Example\n\n```bash\n# Example diagnostic commands\ntraceroute HQ-DC\nping -M do -s 1472 <telemetry_ip>\ntcpdump -i eth0 'udp and host <telemetry_ip>'\n```\n\n## Follow-up Questions\n\n- How would you verify PMTUD is not blocked?\n- What MTU adjustments would you test and why?\n- How could you modify QoS to protect telemetry without harming other traffic?","diagram":"flowchart TD\n  A[Identify Telemetry Path] --> B[Run MTU Test]\n  B --> C[Check NAT-T State]\n  C --> D[Review QoS]\n  D --> E[Implement Mitigation]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Snowflake","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T21:51:08.577Z","createdAt":"2026-01-26T21:51:08.577Z"},{"id":"q-7924","question":"In a three-region VXLAN EVPN fabric with ECMP across transit providers, a per-tenant UDP telemetry stream is multicast replicated to a set of collectors. During peak hours, some collectors intermittently miss packets for a specific tenant due to multicast replication tree imbalance. No app changes. Provide a concrete diagnostic plan to determine whether (a) per-tenant multicast group assignment or IGMP snooping misconfig, (b) EVPN multicast routes or PIM/BDR state, (c) VXLAN MTU/fragmentation for multicast, or (d) per-tenant ACLs filtering multicast, with exact commands and data to collect, and propose mitigations preserving telemetry reliability and tenant isolation?","answer":"Plan: verify per-tenant multicast group membership and IGMP snooping per leaf; inspect EVPN multicast routes and PIM/BDR state for the tenant; confirm VXLAN MTU/fragmentation along the path; audit per","explanation":"## Why This Is Asked\nThis tests practical multicast/TN networking expertise in EVPN fabrics, edge ACLs, and telemetry reliability. It emphasizes concrete data collection, vendor-agnostic checks, and actionable mitigations.\n\n## Key Concepts\n- VXLAN EVPN multicast replication\n- IGMP snooping and PIM/BDR state\n- EVPN multicast routing state and MTU/fragmentation\n- Tenant isolation and ACL scoping\n\n## Code Example\n```javascript\n// Pseudo-collector path validation\nfunction validateTenantPath(tenantId){ /* collect and verify paths */ }\n```\n\n## Follow-up Questions\n- How would you validate changes won’t impact other tenants?\n- What monitoring would you add to prevent future imbalance?","diagram":null,"difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Meta","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-26T23:40:52.782Z","createdAt":"2026-01-26T23:40:52.782Z"},{"id":"q-7949","question":"In a two-site VPN over the Internet, a new UDP telemetry stream from Site A to Site B intermittently drops during peak hours. No app changes. Provide a concrete diagnostic plan to determine whether (a) tunnel MTU fragmentation, (b) IPsec anti-replay/replay window, (c) NAT state exhaustion on egress, or (d) ECMP hashing across multiple tunnels is to blame, with exact commands and data to collect, and propose robust mitigations that preserve telemetry reliability?","answer":"Plan: on Site A and Site B gateways, collect per-tunnel stats and IPsec SA counters; capture UDP telemetry packets with tcpdump; test MTU/PMTU with ping -M do -s 1472 to trigger fragmentation; inspect","explanation":"## Why This Is Asked\nTests practical, beginner-friendly diagnostic skills for common VPN and telemetry reliability issues in enterprise networks.\n\n## Key Concepts\n- IPsec SA counters and replay window\n- MTU/PMTU and fragmentation in tunnels\n- NAT state handling and translation tables\n- ECMP hashing behavior across multiple tunnels\n\n## Code Example\n```bash\n# Basic diagnostic script sketch\ntcpdump -i any 'udp and port <telemetry-port>' -w /tmp/telemetry.pcap\nip xfrm state show\nip xfrm policy show\nping -M do -s 1472 <siteB-peer>\n```\n\n## Follow-up Questions\n- How would you verify per-tunnel loss vs. global loss and isolate the root cause?\n- What safe, staged changes would you apply in production to remediate the issue without dropping telemetry traffic?","diagram":"flowchart TD\n  A[Site A UDP Telemetry] --> B[IPsec Tunnel 1]\n  A --> C[IPsec Tunnel 2]\n  B --> D[Site B Receiver]\n  C --> D","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":null,"companies":["IBM","Oracle","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-27T02:31:36.946Z","createdAt":"2026-01-27T02:31:36.946Z"},{"id":"q-926","question":"In a multi-region deployment (US-East, EU-West) for a high-throughput service, end-to-end latency spikes to 150–300 ms during peak hours while synthetic tests pass. You observe edge drops and retransmissions. Provide a practical plan to diagnose and mitigate network-related factors, including path MTU discovery, ECN, TCP congestion control, TLS handshakes, SNI/ALPN behavior, and load-balancing strategy across regions, with data you’d collect and initial fixes?","answer":"Begin by correlating latency spikes with cross-region routes and packet loss. Verify MTU/path MTU discovery and ICMP behavior; enable ECN if endpoints support it. Compare congestion control (BBR vs Cu","explanation":"## Why This Is Asked\nTests real-world network troubleshooting in multi-region environments, focusing on path MTU, ECN, congestion control, TLS handshakes, and load balancing.\n\n## Key Concepts\n- Path MTU Discovery and ICMP behavior\n- ECN enablement and compatibility\n- TCP congestion control algorithms (BBR, Cubic)\n- TLS handshake optimization and session resumption\n- Geo-based load balancing and observability\n\n## Code Example\n```javascript\n// example: simulate enabling ECN and logging results\n```\n\n## Follow-up Questions\n- How would you measure tail latency separately from average?\n- Which metrics dashboards would help you detect similar issues earlier?","diagram":"flowchart TD\n  A[Client request] --> B[Edge load balancer]\n  B --> C[Regional load balancer]\n  C --> D[Service instance]\n  D --> E[Telemetry collection]\n  E --> F[Root cause analysis]","difficulty":"intermediate","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Snowflake","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:36:36.243Z","createdAt":"2026-01-12T15:36:36.243Z"},{"id":"q-946","question":"In a globally distributed service behind a multi-region, ECMP-enabled load balancer, you observe sporadic high-tail latency while averages look fine. Explain the network mechanisms that could cause tail latency in this setup (per-path RTT variance, path MTU, reordering, retransmissions). Propose a concrete diagnostic workflow using production telemetry (eBPF per-flow histograms, NetFlow/SFlow, MTU checks) and practical remediation steps (MTU tuning, pacing, queue management)?","answer":"Tail latency can arise when ECMP splits a connection across WAN paths with different RTTs, MTU fragmentation, and reordering that trigger retransmissions. Diagnose with per-flow RTT histograms (eBPF),","explanation":"## Why This Is Asked\n\nTests understanding of how ECMP, MTU, and path variance affect tail latency in real networks, plus practical instrumentation and remediation strategies.\n\n## Key Concepts\n\n- ECMP flow splitting across multiple paths\n- Tail latency and observability\n- Path MTU and fragmentation\n- Reordering and retransmissions\n- Telemetry: eBPF histograms, NetFlow/SFlow, MTU checks\n- Queue management: AQM and pacing\n\n## Code Example\n\n```javascript\n// Pseudo-illustration: per-flow RTT histogram collector (conceptual)\nfunction recordRtt(flowKey, rttMs) {\n  // update a per-flow histogram in a BPF map (conceptual)\n  // bucket = determineBucket(rttMs)\n  // histogram[flowKey][bucket]++\n}\n```\n\n## Follow-up Questions\n\n- How would you distinguish MTU-related drops from congestion-related drops?\n- How would you validate changes in a staging environment without impacting production?","diagram":"flowchart TD\n  Client(Client) --> LB[Load Balancer]\n  LB --> R1[Region A Service]\n  LB --> R2[Region B Service]\n  R1 --> Telemetry[(Telemetry Sink)]\n  R2 --> Telemetry","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Salesforce","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:35:56.716Z","createdAt":"2026-01-12T16:35:56.716Z"},{"id":"gh-72","question":"How would you design and implement network segmentation for a microservices architecture, including Zero Trust principles, east-west traffic monitoring, and compliance requirements?","answer":"Network segmentation isolates workloads using micro-segmentation with service mesh (Istio), VPCs, and Kubernetes NetworkPolicies. Zero Trust architecture enforces mTLS between services, with east-west traffic monitoring via eBPF agents (Cilium) and compliance automation for PCI-DSS/HIPAA through policy-as-code (OPA/Gatekeeper).","explanation":"## Core Architecture\n\n**Micro-segmentation** isolates individual services rather than broad zones, reducing blast radius. Implement using:\n- Kubernetes NetworkPolicies for pod-level isolation\n- Service mesh (Istio/Linkerd) for mTLS and traffic control\n- Cloud VPCs/subnets for infrastructure-level segmentation\n\n## Zero Trust Integration\n\n- **mTLS everywhere**: Service mesh enforces mutual authentication\n- **Identity-based policies**: Use SPIFFE/SPIRE for service identities\n- **Least privilege**: Granular RBAC per service endpoint\n- **Continuous verification**: Real-time policy enforcement\n\n## East-West Traffic Monitoring\n\n- **eBPF-based observability**: Cilium/Hubble for deep packet inspection\n- **Service mesh telemetry**: Istio's Mixer for policy enforcement\n- **Anomaly detection**: ML models identify unusual lateral movement\n- **Audit trails**: Immutable logs for forensic analysis\n\n## Cloud Implementation\n\n```yaml\n# Kubernetes NetworkPolicy example\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: payment-service\nspec:\n  podSelector:\n    matchLabels:\n      app: payment-service\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: api-gateway\n    ports:\n    - protocol: TCP\n      port: 8443\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: database\n    ports:\n    - protocol: TCP\n      port: 5432\n```\n\n## Compliance Automation\n\n- **PCI-DSS**: Cardholder data isolation with dedicated segments\n- **HIPAA**: PHI segregation with audit logging\n- **Policy-as-code**: OPA/Gatekeeper for automated compliance checks\n- **Continuous validation**: Automated penetration testing\n\n## Real-world Trade-offs\n\n- **Performance overhead**: mTLS adds ~2-5ms latency\n- **Operational complexity**: Requires specialized networking skills\n- **Cost**: Additional monitoring and enforcement tools\n- **Flexibility vs security**: Balance business agility with protection needs","diagram":"flowchart TD\n  A[Untrusted Network] --> B[Firewall]\n  B --> C[DMZ Segment]\n  B --> D[Application Segment]\n  B --> E[Database Segment]\n  C --> F[Web Servers]\n  D --> G[App Servers]\n  E --> H[Database Servers]","difficulty":"advanced","tags":["security","network"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":null,"companies":["Amazon","Cloudflare","Google","Hashicorp","Microsoft","Stripe"],"eli5":"Imagine your house has different rooms for different activities. You keep your toys in the playroom, food in the kitchen, and books in the study. If someone spills juice in the kitchen, it doesn't get on your toys! Network segmentation is like putting walls between these rooms. It keeps different parts of a computer network separate, so if a bad guy gets into one room, they can't wander into other rooms and cause more trouble. It's like having special doors that only certain people can use - the toy room door only opens for kids who want to play, the kitchen door only for people who are hungry, and so on. This way, even if one room has a problem, all the other rooms stay safe and sound!","relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2025-12-24T16:50:40.489Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-186","question":"How would you implement session affinity (sticky sessions) in HAProxy while maintaining high availability, and what are the trade-offs compared to stateless load balancing?","answer":"Implement session affinity in HAProxy using either source IP hashing with 'balance source' or cookie-based stick tables, while maintaining high availability through health checks. The trade-offs include improved user experience and session consistency versus reduced scalability and potential uneven load distribution.","explanation":"## Session Affinity in HAProxy\n\nSession affinity ensures users consistently reach the same backend server, which is essential for applications storing session data locally rather than in shared stores.\n\n## Implementation Methods\n\n### Source IP Hashing\n```haproxy\nbackend web_servers\n    balance source\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n    server web3 192.168.1.12:80 check\n```\n\n### Stick Tables (Cookie-based)\n```haproxy\nbackend web_servers\n    balance roundrobin\n    stick-table type string len 32 size 30k expire 30m\n    stick on cookie(JSESSIONID)\n    server web1 192.168.1.10:80 check cookie web1\n    server web2 192.168.1.11:80 check cookie web2\n    server web3 192.168.1.12:80 check cookie web3\n```\n\n## High Availability Considerations\n\nBoth implementations include health checks (`check` directive) to automatically remove failed servers from rotation, ensuring high availability while maintaining session affinity.\n\n## Trade-offs vs Stateless Load Balancing\n\n**Advantages:**\n- Maintains session state without external session stores\n- Better user experience for stateful applications\n- Reduced complexity in application code\n\n**Disadvantages:**\n- Uneven load distribution when user traffic is concentrated\n- Reduced scalability during server failures\n- Session loss on backend server failures\n- Complicates horizontal scaling and maintenance","diagram":"graph TD\n    A[Client Requests] --> B[HAProxy Load Balancer]\n    B --> C{Session Affinity Check}\n    C -->|Existing Session| D[Route to Same Server]\n    C -->|New Session| E[Apply Load Balancing Algorithm]\n    D --> F[Web Server 1]\n    E --> F[Web Server 1]\n    E --> G[Web Server 2]\n    E --> H[Web Server 3]\n    F --> I[Session Store/Local State]\n    G --> J[Session Store/Local State]\n    H --> K[Session Store/Local State]\n    L[Health Check] --> F\n    L --> G\n    L --> H\n    M[Stick Table] --> B\n    N[Cookie/Source IP] --> C","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"longVideo":"https://www.youtube.com/watch?v=qYnA2DFEELw"},"companies":["Amazon","Bloomberg","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-08T11:27:10.141Z","createdAt":"2025-12-26 12:51:06"},{"id":"sd-1","question":"Explain load balancing strategies and when to use Layer 4 vs Layer 7. How do round-robin, least connections, and IP hash algorithms compare?","answer":"Layer 4 uses TCP/UDP for faster performance with session persistence challenges. Layer 7 inspects HTTP headers for intelligent routing (path-based, host-based). Round-robin distributes evenly, least connections handles varying request loads, IP hash maintains session affinity. AWS ALB (L7) supports path-based routing while NLB (L4) offers ultra-low latency.","explanation":"## Interview Context\nThis question evaluates system design skills, networking knowledge, and performance optimization capabilities essential for senior roles.\n\n## Key Technical Concepts\n### Load Balancing Layers\n- **Layer 4**: TCP/UDP level, faster (~1ms), no content inspection, session persistence challenges\n- **Layer 7**: Application level, intelligent routing, SSL termination, content-based rules (~5ms overhead)\n\n### Algorithms Comparison\n```yaml\n# Weighted Round Robin\nservers:\n  - id: server1\n    weight: 3  # 60% traffic\n    connections: 0\n  - id: server2\n    weight: 2  # 40% traffic\n    connections: 0\n\n# Least Connections\nactive_connections:\n  server1: 150\n  server2: 100  # Route new requests here\n\n# IP Hash\nhash_source: client_ip\nmodulus: server_count\nresult: consistent server mapping\n```\n\n### Architecture for 100K RPS\n```\nInternet → CDN → L7 Load Balancer (ALB) → L4 Load Balancer (NLB) → Microservices集群\n                                ↓\n                          WAF & Rate Limiting\n                                ↓\n                       Health Checks & Auto Scaling\n```\n\n## Performance Considerations\n- **Throughput**: NLB handles >100M TPS, ALB handles ~10M requests\n- **Latency**: Layer 4 = 1-2ms, Layer 7 = 3-8ms\n- **Scaling**: Horizontal load balancer deployment with DNS round-robin\n\n## Implementation Examples\n```javascript\n// Weighted Round Robin Implementation\nclass LoadBalancer {\n  constructor(servers) {\n    this.servers = servers.map(s => ({...s, currentWeight: 0}));\n  }\n  \n  getServer() {\n    const totalWeight = this.servers.reduce((sum, s) => sum + s.weight, 0);\n    let best = null;\n    let max = -1;\n    \n    this.servers.forEach(server => {\n      server.currentWeight += server.weight;\n      if (server.currentWeight > max) {\n        max = server.currentWeight;\n        best = server;\n      }\n    });\n    \n    if (best) best.currentWeight -= totalWeight;\n    return best;\n  }\n}\n```\n\n## Trade-offs\n- **Layer 4**: Max performance, minimal features\n- **Layer 7**: Rich features, higher latency\n- **Round Robin**: Simple, equal distribution\n- **Least Connections**: Better for varied response times\n- **IP Hash**: Session persistence, uneven distribution risk\n\n## Follow-up Questions\n1. How would you handle database connection pooling with this architecture?\n2. What monitoring metrics would you track for load balancer health?\n3. How does this design change for WebSocket connections?","diagram":"graph LR\n    User --> LB[Load Balancer]\n    LB -->|Layer 4| S1[\"Server 1<br/>IP:Port\"]\n    LB -->|Layer 7| S2[\"Server 2<br/>/api\"]\n    style LB fill:#fff,stroke:#000,color:#000","difficulty":"advanced","tags":["infra","scale","networking"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=dBmxNsS3BGE","longVideo":"https://www.youtube.com/watch?v=aKMLgFVxZYk"},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":"Imagine you're the lunch line monitor at school! When lots of kids want lunch at once, you can't let everyone rush to one lunch lady - that would make her super tired and some kids would wait forever. So you send kids to different lunch ladies so everyone gets food fast! Layer 4 is like just counting kids and sending them to the next available lunch lady - you don't care what lunch they want, just keeping the line moving. Layer 7 is like looking at each kid's lunch order first - if someone wants a sandwich, you send them to the sandwich station, if they want pizza, to the pizza line! This way, the pizza experts handle pizza orders and sandwich experts handle sandwiches. Use Layer 4 when you just need to spread people out evenly, and Layer 7 when different servers are good at different things!","relevanceScore":null,"voiceKeywords":["layer 4","layer 7","round-robin","least connections","ip hash","session persistence","alb","nlb"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2025-12-27T05:52:25.933Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-203","question":"How does TCP's congestion control algorithm interact with HTTP/2's multiplexing when multiple streams compete for bandwidth?","answer":"TCP's congestion control operates at the transport layer and treats all HTTP/2 streams as a single connection, meaning all streams share the same congestion window and experience identical throughput limitations, which can lead to head-of-line blocking across streams.","explanation":"## Concept Overview\nTCP's congestion control algorithm manages network throughput at the transport layer, completely unaware of HTTP/2's application-layer multiplexing. This creates a fundamental architectural mismatch where TCP's connection-level control impacts all HTTP/2 streams equally.\n\n## Implementation Details\nTCP implements congestion control through algorithms like Reno, CUBIC, or BBR that maintain a congestion window (cwnd) limiting the number of unacknowledged bytes in flight. When HTTP/2 multiplexes multiple streams over this single TCP connection, all streams compete for the same bandwidth resources and are subject to identical packet loss recovery mechanisms.\n\n## Performance Implications\nThis interaction means that packet loss affecting any single HTTP/2 stream triggers TCP's congestion control response, reducing throughput for all streams simultaneously. The lack of per-stream congestion awareness can result in inefficient bandwidth utilization and increased latency for high-priority streams when sharing the connection with lower-priority traffic.","diagram":"graph TD\n    A[HTTP/2 Client] --> B[TCP Connection]\n    B --> C[Congestion Control]\n    C --> D[Network]\n    B --> E[Stream 1]\n    B --> F[Stream 2]\n    B --> G[Stream 3]\n    C --> H[Shared cwnd]\n    H --> E\n    H --> F\n    H --> G","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=0j_4EDV-nWY","longVideo":"https://www.youtube.com/watch?v=fVKPrDrEwTI"},"companies":["Amazon Aws","Cloudflare","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["tcp","congestion control","http/2","multiplexing","head-of-line blocking"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2025-12-30T01:44:31.798Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-256","question":"How does QUIC solve TCP's head-of-line blocking problem in HTTP/2 multiplexing, and what are the implementation trade-offs?","answer":"QUIC eliminates head-of-line blocking by implementing stream-independent packet delivery over UDP, where lost packets only affect their specific stream rather than blocking the entire connection.","explanation":"## Concept Overview\nHead-of-line blocking occurs when a single lost packet blocks all subsequent packets, even those belonging to different streams. This significantly impacts HTTP/2 performance over TCP connections.\n\n## Implementation Details\n- **TCP Approach**: All multiplexed streams share a single TCP connection. Packet loss blocks the entire connection, affecting all streams simultaneously.\n- **QUIC Approach**: Each QUIC stream operates independently. Lost packets only block their specific stream, allowing other streams to continue transmitting.\n- QUIC utilizes connection IDs (rather than IP+port combinations) for connection identification and supports connection migration.\n\n## Code Example\n```bash\n# TCP (HTTP/2) - blocked by single loss\nStream 1: [P","diagram":"graph TD\n    A[HTTP/2 over TCP] --> B[Single TCP Connection]\n    B --> C[Packet Loss on Stream 1]\n    C --> D[All Streams Blocked]\n    \n    E[HTTP/3 over QUIC] --> F[Multiple Independent Streams]\n    F --> G[Packet Loss on Stream 1]\n    G --> H[Only Stream 1 Affected]\n    H --> I[Other Streams Continue]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://www.haproxy.com/blog/choosing-the-right-transport-protocol-tcp-vs-udp-vs-quic/","videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","multiplexing","udp","stream independence","tcp"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:21:25.402Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-275","question":"How does QUIC solve HTTP/2's head-of-line blocking issue over TCP, and what are the implementation trade-offs?","answer":"QUIC runs over UDP with independent streams, eliminating TCP-level blocking while implementing reliability at the application layer.","explanation":"## Concept\nHTTP/2 suffers from head-of-line blocking at the TCP level - a single lost packet blocks all streams. QUIC solves this by using UDP as the transport protocol and implementing reliability, congestion control, and stream multiplexing at the application layer.\n\n## Implementation\n```go\n// QUIC stream independence\nfor _, stream := range conn.Streams() {\n    go func(s quic.Stream) {\n        // Each stream processes independently\n        data, err := io.ReadAll(s)\n        // Lost packets only affect this stream\n        handleStreamData(s.ID(), data)\n    }(stream)\n}\n\n// Connection-level recovery\nconn.HandleLostPackets(func(packetID uint64) {\n    // Selective retransmission\n    if shouldRetransmit(packetID) {\n        conn.RetransmitPacket(packetID)\n    }\n})\n```\n\n## Trade-offs\n- **Pros**: Stream independence, faster recovery, reduced latency\n- **Cons**: Higher CPU usage, UDP firewall issues, complex implementation","diagram":"flowchart TD\n    A[Client Request] --> B{Transport Layer}\n    B -->|HTTP/2| C[TCP]\n    B -->|QUIC| D[UDP]\n    C --> E[TCP Stream 1] --> F[TCP Stream 2] --> G[TCP Stream 3]\n    D --> H[QUIC Stream 1] --> I[QUIC Stream 2] --> J[QUIC Stream 3]\n    \n    K[Packet Loss] --> E\n    K --> F\n    K --> G\n    style E fill:#ffcccc\n    style F fill:#ffcccc\n    style G fill:#ffcccc\n    \n    L[Packet Loss] --> H\n    style H fill:#ffcccc\n    style I fill:#ccffcc\n    style J fill:#ccffcc\n    \n    M[TCP HOL Blocking] --> N[All Streams Blocked]\n    O[QUIC Independence] --> P[Only Affected Stream Blocked]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://tools.ietf.org/html/rfc9000","videos":{"shortVideo":null,"longVideo":"https://www.youtube.com/watch?v=GriONb4EfPY"},"companies":["Amazon","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","tcp","udp","streams","reliability"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:22:20.630Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["dns","general","load-balancing","tcp-ip"],"companies":["Adobe","Airbnb","Amazon","Amazon Aws","Anthropic","Apple","Bloomberg","Cisco","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":83,"beginner":27,"intermediate":24,"advanced":32,"newThisWeek":41}}