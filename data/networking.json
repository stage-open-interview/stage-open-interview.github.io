{"questions":[{"id":"q-180","question":"What is the primary purpose of DNS in computer networking and how does it enable internet communication?","answer":"Translates human-readable domain names into IP addresses, enabling users to access websites using memorable names instead of numeric addresses","explanation":"## Why Asked\nInterviewers ask this to test fundamental networking knowledge and understanding of how the internet resolves human-friendly names to machine-readable addresses\n\n## Key Concepts\n- Domain Name System (DNS) hierarchy\n- DNS resolution process\n- IP address mapping\n- DNS caching and performance\n\n## Code Example\n```\n# Basic DNS lookup using nslookup\nnslookup google.com\n# Returns: 172.217.14.238\n```\n\n## Follow-up Questions\n- What are the different types of DNS records?\n- How does DNS caching improve performance?\n- What happens when a DNS query fails?","diagram":"graph TD\n    A[User types www.example.com] --> B[Local DNS Cache]\n    B --> C{Cache hit?}\n    C -->|No| D[Recursive DNS Server]\n    C -->|Yes| E[Return IP Address]\n    D --> F[Root DNS Server]\n    F --> G[TLD Server .com]\n    G --> H[Authoritative DNS Server]\n    H --> I[Return IP Address]\n    I --> B\n    B --> E","difficulty":"beginner","tags":["dns","resolution"],"channel":"networking","subChannel":"dns","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=UVR9lhUGAyU","longVideo":"https://www.youtube.com/watch?v=27r4Bzuj5NQ"},"companies":["Amazon","Cisco","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["domain names","ip addresses","translation","resolution","hierarchical","internet","communication"],"voiceSuitable":true,"lastUpdated":"2025-12-27T04:57:24.460Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-469","question":"Explain what happens when you type google.com into your browser and press Enter, focusing on the networking layers involved?","answer":"Browser checks DNS cache, queries DNS servers for IP address. Creates TCP socket, performs 3-way handshake. Sends HTTP GET request over TCP. Server processes request, sends response. Browser renders H","explanation":"## DNS Resolution\n- Browser checks local cache first\n- Queries recursive DNS servers\n- Returns IP address for google.com\n\n## TCP Connection\n- 3-way handshake: SYN, SYN-ACK, ACK\n- Establishes reliable connection\n- Uses port 443 for HTTPS\n\n## HTTP Request\n- Browser sends GET request\n- Includes headers (User-Agent, Accept)\n- Server processes and responds\n\n## Response Processing\n- Server returns HTML/CSS/JS\n- Browser parses and renders\n- Makes additional requests for resources","diagram":"flowchart TD\n  A[Browser] --> B[DNS Lookup]\n  B --> C[Get IP Address]\n  C --> D[TCP Handshake]\n  D --> E[HTTP Request]\n  E --> F[Server Response]\n  F --> G[Render Page]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Goldman Sachs","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-24T02:47:24.899Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-499","question":"How would you design a TCP load balancer that handles 1M concurrent connections with consistent hashing while preventing connection thrashing during backend failures?","answer":"Implement a ring-based consistent hash with virtual nodes for even distribution. Use connection pooling with health checks and circuit breakers. During failures, gradually drain connections using weig","explanation":"## Key Components\n\n- **Consistent Hashing**: Ring-based with 160 virtual nodes per backend\n- **Connection Management**: Keep-alive pools with configurable timeouts\n- **Failure Detection**: Active health checks with 5s interval, 3 failures threshold\n- **Traffic Distribution**: Weighted round-robin during failover\n\n## Implementation Details\n\n```go\n// Consistent hash ring implementation\ntype HashRing struct {\n  nodes map[uint32]string\n  sorted []uint32\n  replicas int\n}\n\n// Connection state tracking\ntype ConnTracker struct {\n  active map[string]int\n  maxConns int\n  drainMode bool\n}\n```\n\n## Production Considerations\n\n- **SYN Flood Protection**: Enable SYN cookies and rate limiting\n- **Connection Draining**: 30s graceful shutdown period\n- **Metrics**: Track connection distribution, latency, error rates\n- **Backpressure**: Implement TCP receive buffer tuning","diagram":"flowchart TD\n  A[Client Request] --> B[Load Balancer]\n  B --> C{Hash Ring}\n  C --> D[Backend Node 1]\n  C --> E[Backend Node 2]\n  C --> F[Backend Node 3]\n  D --> G[Health Check]\n  E --> G\n  F --> G\n  G --> H{Healthy?}\n  H -->|Yes| I[Route Traffic]\n  H -->|No| J[Remove from Ring]\n  J --> K[Gradual Drain]\n  K --> L[Rehash Connections]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-25T01:15:23.733Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-583","question":"How would you design a load balancer to handle 1M concurrent connections with sub-10ms latency, considering TCP connection pooling, health checks, and graceful degradation?","answer":"Implement L4 load balancer with epoll/kqueue for I/O multiplexing. Use connection pooling with keep-alive, implement active/passive health checks with exponential backoff. Add circuit breakers and rat","explanation":"## Architecture\n- **L4 Load Balancer**: TCP-level routing for performance\n- **Connection Pooling**: Reuse connections with keep-alive\n- **Health Checks**: Active HTTP probes + passive monitoring\n- **Graceful Degradation**: Circuit breakers, rate limiting\n\n## Implementation\n```nginx\nupstream backend {\n    least_conn;\n    server 10.0.1.1:80 max_fails=3 fail_timeout=30s;\n    keepalive 1000;\n}\n```\n\n## Monitoring\n- Track connection metrics, latency percentiles\n- Alert on error rates > 1%\n- Auto-scale based on connection count","diagram":"flowchart TD\n  A[Client Request] --> B[L4 Load Balancer]\n  B --> C[Connection Pool]\n  C --> D[Health Check]\n  D --> E[Backend Server]\n  E --> F[Response]\n  F --> G[Client]\n  D -->|Failed| H[Circuit Breaker]\n  H --> I[Graceful Degradation]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":["load balancer","tcp connection pooling","health checks","circuit breakers","graceful degradation","i/o multiplexing","connection pooling"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:47:36.001Z","createdAt":"2025-12-27T01:14:00.333Z"},{"id":"gh-72","question":"How would you design and implement network segmentation for a microservices architecture, including Zero Trust principles, east-west traffic monitoring, and compliance requirements?","answer":"Network segmentation isolates workloads using micro-segmentation with service mesh (Istio), VPCs, and Kubernetes NetworkPolicies. Zero Trust architecture enforces mTLS between services, with east-west traffic monitoring via eBPF agents (Cilium) and compliance automation for PCI-DSS/HIPAA through policy-as-code (OPA/Gatekeeper).","explanation":"## Core Architecture\n\n**Micro-segmentation** isolates individual services rather than broad zones, reducing blast radius. Implement using:\n- Kubernetes NetworkPolicies for pod-level isolation\n- Service mesh (Istio/Linkerd) for mTLS and traffic control\n- Cloud VPCs/subnets for infrastructure-level segmentation\n\n## Zero Trust Integration\n\n- **mTLS everywhere**: Service mesh enforces mutual authentication\n- **Identity-based policies**: Use SPIFFE/SPIRE for service identities\n- **Least privilege**: Granular RBAC per service endpoint\n- **Continuous verification**: Real-time policy enforcement\n\n## East-West Traffic Monitoring\n\n- **eBPF-based observability**: Cilium/Hubble for deep packet inspection\n- **Service mesh telemetry**: Istio's Mixer for policy enforcement\n- **Anomaly detection**: ML models identify unusual lateral movement\n- **Audit trails**: Immutable logs for forensic analysis\n\n## Cloud Implementation\n\n```yaml\n# Kubernetes NetworkPolicy example\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: payment-service\nspec:\n  podSelector:\n    matchLabels:\n      app: payment-service\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: api-gateway\n    ports:\n    - protocol: TCP\n      port: 8443\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: database\n    ports:\n    - protocol: TCP\n      port: 5432\n```\n\n## Compliance Automation\n\n- **PCI-DSS**: Cardholder data isolation with dedicated segments\n- **HIPAA**: PHI segregation with audit logging\n- **Policy-as-code**: OPA/Gatekeeper for automated compliance checks\n- **Continuous validation**: Automated penetration testing\n\n## Real-world Trade-offs\n\n- **Performance overhead**: mTLS adds ~2-5ms latency\n- **Operational complexity**: Requires specialized networking skills\n- **Cost**: Additional monitoring and enforcement tools\n- **Flexibility vs security**: Balance business agility with protection needs","diagram":"flowchart TD\n  A[Untrusted Network] --> B[Firewall]\n  B --> C[DMZ Segment]\n  B --> D[Application Segment]\n  B --> E[Database Segment]\n  C --> F[Web Servers]\n  D --> G[App Servers]\n  E --> H[Database Servers]","difficulty":"advanced","tags":["security","network"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":null,"companies":["Amazon","Cloudflare","Google","Hashicorp","Microsoft","Stripe"],"eli5":"Imagine your house has different rooms for different activities. You keep your toys in the playroom, food in the kitchen, and books in the study. If someone spills juice in the kitchen, it doesn't get on your toys! Network segmentation is like putting walls between these rooms. It keeps different parts of a computer network separate, so if a bad guy gets into one room, they can't wander into other rooms and cause more trouble. It's like having special doors that only certain people can use - the toy room door only opens for kids who want to play, the kitchen door only for people who are hungry, and so on. This way, even if one room has a problem, all the other rooms stay safe and sound!","relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-24T16:50:40.489Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-186","question":"How would you implement session affinity (sticky sessions) in HAProxy while maintaining high availability, and what are the trade-offs compared to stateless load balancing?","answer":"Use 'balance source' or 'stick-table' with health checks. Trade-offs: better user experience vs reduced scalability and uneven load distribution.","explanation":"## Session Affinity in HAProxy\n\nSession affinity ensures users consistently reach the same backend server, crucial for applications storing session data locally.\n\n## Implementation Methods\n\n### Source IP Hashing\n```haproxy\nbackend web_servers\n    balance source\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n    server web3 192.168.1.12:80 check\n```\n\n### Stick Tables (Cookie-based)\n```haproxy\nbackend web_servers\n    balance roundrobin\n    stick-table type string len 32 size 30k expire 30m\n    stick on cookie(JSESSIONID)\n    server web1 192.168.1.10:80 check cookie web1\n    server web2 192.168.1.11:80 check cookie web2\n    server web3 192.168.1.12:80 check cookie web3\n```\n\n## High Availability Considerations\n\n- **Health Checks**: Failed servers automatically removed from rotation\n- **Backup Servers**: Configure backup servers for failover\n- **Session Replication**: Implement session sharing between servers\n\n## Trade-offs\n\n### Sticky Sessions\n- ✅ Maintains user state\n- ✅ No session synchronization needed\n- ❌ Uneven load distribution\n- ❌ Server failure loses sessions\n- ❌ Harder horizontal scaling\n\n### Stateless Load Balancing\n- ✅ Perfect load distribution\n- ✅ Easy scaling\n- ✅ Server failure doesn't affect users\n- ❌ Requires external session storage (Redis, database)\n- ❌ Additional infrastructure complexity\n\n## Common Pitfalls\n\n- **Hot Spots**: Source IP hashing can create uneven distribution\n- **Session Loss**: Server failures break user sessions\n- **Cache Inefficiency**: Users may hit different servers, reducing cache effectiveness","diagram":"graph TD\n    A[Client Requests] --> B[HAProxy Load Balancer]\n    B --> C{Session Affinity Check}\n    C -->|Existing Session| D[Route to Same Server]\n    C -->|New Session| E[Apply Load Balancing Algorithm]\n    D --> F[Web Server 1]\n    E --> F[Web Server 1]\n    E --> G[Web Server 2]\n    E --> H[Web Server 3]\n    F --> I[Session Store/Local State]\n    G --> J[Session Store/Local State]\n    H --> K[Session Store/Local State]\n    L[Health Check] --> F\n    L --> G\n    L --> H\n    M[Stick Table] --> B\n    N[Cookie/Source IP] --> C","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"longVideo":"https://www.youtube.com/watch?v=qYnA2DFEELw"},"companies":["Amazon","Bloomberg","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-25T12:50:05.238Z","createdAt":"2025-12-26 12:51:06"},{"id":"sd-1","question":"Explain load balancing strategies and when to use Layer 4 vs Layer 7. How do round-robin, least connections, and IP hash algorithms compare?","answer":"Layer 4 uses TCP/UDP for faster performance with session persistence challenges. Layer 7 inspects HTTP headers for intelligent routing (path-based, host-based). Round-robin distributes evenly, least connections handles varying request loads, IP hash maintains session affinity. AWS ALB (L7) supports path-based routing while NLB (L4) offers ultra-low latency.","explanation":"## Interview Context\nThis question evaluates system design skills, networking knowledge, and performance optimization capabilities essential for senior roles.\n\n## Key Technical Concepts\n### Load Balancing Layers\n- **Layer 4**: TCP/UDP level, faster (~1ms), no content inspection, session persistence challenges\n- **Layer 7**: Application level, intelligent routing, SSL termination, content-based rules (~5ms overhead)\n\n### Algorithms Comparison\n```yaml\n# Weighted Round Robin\nservers:\n  - id: server1\n    weight: 3  # 60% traffic\n    connections: 0\n  - id: server2\n    weight: 2  # 40% traffic\n    connections: 0\n\n# Least Connections\nactive_connections:\n  server1: 150\n  server2: 100  # Route new requests here\n\n# IP Hash\nhash_source: client_ip\nmodulus: server_count\nresult: consistent server mapping\n```\n\n### Architecture for 100K RPS\n```\nInternet → CDN → L7 Load Balancer (ALB) → L4 Load Balancer (NLB) → Microservices集群\n                                ↓\n                          WAF & Rate Limiting\n                                ↓\n                       Health Checks & Auto Scaling\n```\n\n## Performance Considerations\n- **Throughput**: NLB handles >100M TPS, ALB handles ~10M requests\n- **Latency**: Layer 4 = 1-2ms, Layer 7 = 3-8ms\n- **Scaling**: Horizontal load balancer deployment with DNS round-robin\n\n## Implementation Examples\n```javascript\n// Weighted Round Robin Implementation\nclass LoadBalancer {\n  constructor(servers) {\n    this.servers = servers.map(s => ({...s, currentWeight: 0}));\n  }\n  \n  getServer() {\n    const totalWeight = this.servers.reduce((sum, s) => sum + s.weight, 0);\n    let best = null;\n    let max = -1;\n    \n    this.servers.forEach(server => {\n      server.currentWeight += server.weight;\n      if (server.currentWeight > max) {\n        max = server.currentWeight;\n        best = server;\n      }\n    });\n    \n    if (best) best.currentWeight -= totalWeight;\n    return best;\n  }\n}\n```\n\n## Trade-offs\n- **Layer 4**: Max performance, minimal features\n- **Layer 7**: Rich features, higher latency\n- **Round Robin**: Simple, equal distribution\n- **Least Connections**: Better for varied response times\n- **IP Hash**: Session persistence, uneven distribution risk\n\n## Follow-up Questions\n1. How would you handle database connection pooling with this architecture?\n2. What monitoring metrics would you track for load balancer health?\n3. How does this design change for WebSocket connections?","diagram":"graph LR\n    User --> LB[Load Balancer]\n    LB -->|Layer 4| S1[\"Server 1<br/>IP:Port\"]\n    LB -->|Layer 7| S2[\"Server 2<br/>/api\"]\n    style LB fill:#fff,stroke:#000,color:#000","difficulty":"advanced","tags":["infra","scale","networking"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=dBmxNsS3BGE","longVideo":"https://www.youtube.com/watch?v=aKMLgFVxZYk"},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":"Imagine you're the lunch line monitor at school! When lots of kids want lunch at once, you can't let everyone rush to one lunch lady - that would make her super tired and some kids would wait forever. So you send kids to different lunch ladies so everyone gets food fast! Layer 4 is like just counting kids and sending them to the next available lunch lady - you don't care what lunch they want, just keeping the line moving. Layer 7 is like looking at each kid's lunch order first - if someone wants a sandwich, you send them to the sandwich station, if they want pizza, to the pizza line! This way, the pizza experts handle pizza orders and sandwich experts handle sandwiches. Use Layer 4 when you just need to spread people out evenly, and Layer 7 when different servers are good at different things!","relevanceScore":null,"voiceKeywords":["layer 4","layer 7","round-robin","least connections","ip hash","session persistence","alb","nlb"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:52:25.933Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-203","question":"How does TCP's congestion control algorithm interact with HTTP/2's multiplexing when multiple streams compete for bandwidth?","answer":"TCP treats all HTTP/2 streams as one connection, so congestion control affects all streams equally, causing head-of-line blocking.","explanation":"## Concept Overview\nTCP's congestion control operates at the transport layer, managing the entire connection's throughput regardless of how many application-layer streams (HTTP/2) are multiplexed over it.\n\n## Implementation Details\n- TCP uses algorithms like Reno, CUBIC, or BBR to adjust cwnd based on packet loss/RTT\n- HTTP/2 multiplexes multiple streams over a single TCP connection\n- All streams share the same congestion window and experience identical throttling\n\n## Common Pitfalls\n- Assuming per-stream bandwidth allocation\n- Ignoring that packet loss affects all streams simultaneously\n- Not considering TCP head-of-line blocking despite HTTP/2 stream multiplexing\n\n## Code Example\n```go\n// HTTP/2 client configuration\nclient := &http.Client{\n    Transport: &http2.Transport{\n        // Single TCP connection for all streams\n        AllowHTTP: false,\n    },\n}\n```","diagram":"graph TD\n    A[HTTP/2 Client] --> B[TCP Connection]\n    B --> C[Congestion Control]\n    C --> D[Network]\n    B --> E[Stream 1]\n    B --> F[Stream 2]\n    B --> G[Stream 3]\n    C --> H[Shared cwnd]\n    H --> E\n    H --> F\n    H --> G","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=0j_4EDV-nWY","longVideo":"https://www.youtube.com/watch?v=fVKPrDrEwTI"},"companies":["Amazon Aws","Cloudflare","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["tcp","congestion control","http/2","multiplexing","head-of-line blocking"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:31:41.476Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-256","question":"How does QUIC solve TCP's head-of-line blocking problem in HTTP/2 multiplexing, and what are the implementation trade-offs?","answer":"QUIC eliminates head-of-line blocking using stream-independent packet delivery over UDP, allowing lost packets to only affect their specific stream.","explanation":"## Concept Overview\nHead-of-line blocking occurs when a single lost packet blocks all subsequent packets, even those belonging to different streams. This affects HTTP/2 over TCP significantly.\n\n## Implementation Details\n- **TCP Approach**: All multiplexed streams share one TCP connection. Packet loss blocks entire connection.\n- **QUIC Approach**: Each QUIC stream operates independently. Lost packets only block their specific stream.\n- QUIC uses connection IDs (not IP+port) for connection identification and migration.\n\n## Code Example\n```bash\n# TCP (HTTP/2) - blocked by single loss\nStream 1: [P1][P2][LOSS][P4] - BLOCKS\nStream 2: [Q1][Q2][Q3][Q4] - BLOCKED despite no loss\n\n# QUIC (HTTP/3) - independent streams\nStream 1: [P1][P2][LOSS][P4] - PARTIAL BLOCK\nStream 2: [Q1][Q2][Q3][Q4] - CONTINUES normally\n```\n\n## Common Pitfalls\n- Increased CPU overhead due to user-space encryption\n- UDP blocked by some corporate firewalls\n- Connection state management complexity\n- Bandwidth estimation challenges in multiplexed streams","diagram":"graph TD\n    A[HTTP/2 over TCP] --> B[Single TCP Connection]\n    B --> C[Packet Loss on Stream 1]\n    C --> D[All Streams Blocked]\n    \n    E[HTTP/3 over QUIC] --> F[Multiple Independent Streams]\n    F --> G[Packet Loss on Stream 1]\n    G --> H[Only Stream 1 Affected]\n    H --> I[Other Streams Continue]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://www.haproxy.com/blog/choosing-the-right-transport-protocol-tcp-vs-udp-vs-quic/","videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","multiplexing","udp","stream independence","tcp"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:50:54.664Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-275","question":"How does QUIC solve HTTP/2's head-of-line blocking issue over TCP, and what are the implementation trade-offs?","answer":"QUIC runs over UDP with independent streams, eliminating TCP-level blocking while implementing reliability at the application layer.","explanation":"## Concept\nHTTP/2 suffers from head-of-line blocking at TCP level - one lost packet blocks all streams. QUIC solves this by using UDP as transport and implementing reliability, congestion control, and stream multiplexing at the application layer.\n\n## Implementation\n```go\n// QUIC stream independence\nfor _, stream := range conn.Streams() {\n    go func(s quic.Stream) {\n        // Each stream processes independently\n        data, err := io.ReadAll(s)\n        // Lost packets only affect this stream\n        handleStreamData(s.ID(), data)\n    }(stream)\n}\n\n// Connection-level recovery\nconn.HandleLostPacket(packetID)\n// Other streams continue unaffected\n```\n\n## Trade-offs\n**Pros:**\n- No head-of-line blocking between streams\n- Faster connection establishment (0-RTT)\n- Better mobility support (connection migration)\n\n**Cons:**\n- Higher CPU usage (user-space reliability)\n- More complex implementation\n- Potential NAT/UDP blocking issues\n\n## Pitfalls\n- UDP may be blocked by corporate firewalls\n- Increased packet overhead vs TCP\n- Debugging complexity with custom reliability layer","diagram":"flowchart TD\n    A[Client Request] --> B{Transport Layer}\n    B -->|HTTP/2| C[TCP]\n    B -->|QUIC| D[UDP]\n    C --> E[TCP Stream 1] --> F[TCP Stream 2] --> G[TCP Stream 3]\n    D --> H[QUIC Stream 1] --> I[QUIC Stream 2] --> J[QUIC Stream 3]\n    \n    K[Packet Loss] --> E\n    K --> F\n    K --> G\n    style E fill:#ffcccc\n    style F fill:#ffcccc\n    style G fill:#ffcccc\n    \n    L[Packet Loss] --> H\n    style H fill:#ffcccc\n    style I fill:#ccffcc\n    style J fill:#ccffcc\n    \n    M[TCP HOL Blocking] --> N[All Streams Blocked]\n    O[QUIC Independence] --> P[Only Affected Stream Blocked]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://tools.ietf.org/html/rfc9000","videos":{"shortVideo":null,"longVideo":"https://www.youtube.com/watch?v=GriONb4EfPY"},"companies":["Amazon","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","tcp","udp","streams","reliability"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:52:09.371Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["dns","general","load-balancing","tcp-ip"],"companies":["Adobe","Amazon","Amazon Aws","Bloomberg","Cisco","Cloudflare","Discord","Goldman Sachs","Google","Hashicorp","IBM","Meta","Microsoft","Netflix","Snowflake","Stripe","Twitter"],"stats":{"total":10,"beginner":2,"intermediate":4,"advanced":4,"newThisWeek":10}}