{"questions":[{"id":"q-180","question":"What is the primary purpose of DNS in computer networking and how does it enable internet communication?","answer":"Translates human-readable domain names into IP addresses, enabling users to access websites using memorable names instead of numeric addresses.","explanation":"## Why Asked\nInterviewers ask this to test fundamental networking knowledge and understanding of how the internet resolves human-friendly names to machine-readable addresses.\n\n## Key Concepts\n- Domain Name System (DNS) hierarchy\n- DNS resolution process\n- IP address mapping\n- DNS caching and performance\n\n## Code Example\n```\n# Basic DNS lookup using nslookup\nnslookup google.com\n# Returns: 172.217.14.238\n```\n\n## Follow-up Questions\n- What are the different types of DNS records?\n- How does DNS caching improve performance?\n- What happens when a DNS query fails?","diagram":"graph TD\n    A[User types www.example.com] --> B[Local DNS Cache]\n    B --> C{Cache hit?}\n    C -->|No| D[Recursive DNS Server]\n    C -->|Yes| E[Return IP Address]\n    D --> F[Root DNS Server]\n    F --> G[TLD Server .com]\n    G --> H[Authoritative DNS Server]\n    H --> I[Return IP Address]\n    I --> B\n    B --> E","difficulty":"beginner","tags":["dns","resolution"],"channel":"networking","subChannel":"dns","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=UVR9lhUGAyU","longVideo":"https://www.youtube.com/watch?v=27r4Bzuj5NQ"},"companies":["Amazon","Cisco","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["domain names","ip addresses","translation","resolution","hierarchical","internet","communication"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:27:02.182Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-469","question":"Explain what happens when you type google.com into your browser and press Enter, focusing on the networking layers involved?","answer":"When you type google.com into your browser and press Enter, the browser first checks its DNS cache for the IP address. If not found, it queries DNS servers recursively to resolve the domain name. Once the IP address is obtained, the browser creates a TCP socket and performs a three-way handshake (SYN, SYN-ACK, ACK) to establish a reliable connection. The browser then sends an HTTP GET request over TCP, which the server processes and returns a response. Finally, the browser renders the received content.","explanation":"## DNS Resolution\n- Browser checks local DNS cache first for previously resolved addresses\n- Queries recursive DNS servers starting from the root DNS hierarchy\n- Returns the IP address for google.com to the browser\n\n## TCP Connection\n- Performs three-way handshake: SYN, SYN-ACK, ACK\n- Establishes a reliable, ordered data transmission channel\n- Uses port 443 for HTTPS connections or port 80 for HTTP\n\n## HTTP Request\n- Browser sends GET request to the server\n- Includes essential headers like User-Agent, Accept, and Host\n- Server processes the request and prepares the response\n\n## Response Processing\n- Server returns HTML, CSS, JavaScript, and other resources\n- Browser parses the HTML and constructs the DOM tree\n- Makes additional requests for referenced resources (images, scripts, stylesheets)\n- Renders the complete page for the user","diagram":"flowchart TD\n  A[Browser] --> B[DNS Lookup]\n  B --> C[Get IP Address]\n  C --> D[TCP Handshake]\n  D --> E[HTTP Request]\n  E --> F[Server Response]\n  F --> G[Render Page]","difficulty":"beginner","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Goldman Sachs","IBM"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2026-01-09T09:01:53.350Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-499","question":"How would you design a TCP load balancer that handles 1M concurrent connections with consistent hashing while preventing connection thrashing during backend failures?","answer":"Implement a ring-based consistent hash with virtual nodes for even distribution. Use connection pooling with health checks and circuit breakers. During failures, gradually drain connections using weig","explanation":"## Key Components\n\n- **Consistent Hashing**: Ring-based with 160 virtual nodes per backend\n- **Connection Management**: Keep-alive pools with configurable timeouts\n- **Failure Detection**: Active health checks with 5s interval, 3 failures threshold\n- **Traffic Distribution**: Weighted round-robin during failover\n\n## Implementation Details\n\n```go\n// Consistent hash ring implementation\ntype HashRing struct {\n  nodes map[uint32]string\n  sorted []uint32\n  replicas int\n}\n\n// Connection state tracking\ntype ConnTracker struct {\n  active map[string]int\n  maxConns int\n  drainMode bool\n}\n```\n\n## Production Considerations\n\n- **SYN Flood Protection**: Enable SYN cookies and rate limiting\n- **Connection Draining**: 30s graceful shutdown period\n- **Metrics**: Track connection distribution, latency, error rates\n- **Backpressure**: Implement TCP receive buffer tuning","diagram":"flowchart TD\n  A[Client Request] --> B[Load Balancer]\n  B --> C{Hash Ring}\n  C --> D[Backend Node 1]\n  C --> E[Backend Node 2]\n  C --> F[Backend Node 3]\n  D --> G[Health Check]\n  E --> G\n  F --> G\n  G --> H{Healthy?}\n  H -->|Yes| I[Route Traffic]\n  H -->|No| J[Remove from Ring]\n  J --> K[Gradual Drain]\n  K --> L[Rehash Connections]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-25T01:15:23.733Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-583","question":"How would you design a load balancer to handle 1M concurrent connections with sub-10ms latency, considering TCP connection pooling, health checks, and graceful degradation?","answer":"Implement an L4 load balancer using epoll/kqueue for efficient I/O multiplexing. Leverage connection pooling with TCP keep-alive to minimize connection overhead, and implement both active and passive health checks with exponential backoff strategies. Add circuit breakers and rate limiting for graceful degradation under high load.","explanation":"## Architecture\n- **L4 Load Balancer**: TCP-level routing for optimal performance and minimal latency\n- **Connection Pooling**: Reuse connections with persistent keep-alive mechanisms\n- **Health Checks**: Dual approach with active HTTP probes and passive monitoring\n- **Graceful Degradation**: Circuit breakers and rate limiting for fault tolerance\n\n## Implementation\n```nginx\nupstream backend {\n    least_conn;\n    server 10.0.1.1:80 max_fails=3 fail_timeout=30s;\n    keepalive 1000;\n}\n```\n\n## Monitoring\n- Track connection metrics and latency percentiles in real-time\n- Alert when error rates exceed 1% threshold\n- Implement auto-scaling based on active connection count","diagram":"flowchart TD\n  A[Client Request] --> B[L4 Load Balancer]\n  B --> C[Connection Pool]\n  C --> D[Health Check]\n  D --> E[Backend Server]\n  E --> F[Response]\n  F --> G[Client]\n  D -->|Failed| H[Circuit Breaker]\n  H --> I[Graceful Degradation]","difficulty":"advanced","tags":["networking"],"channel":"networking","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":["load balancer","tcp connection pooling","health checks","circuit breakers","graceful degradation","i/o multiplexing","connection pooling"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:51:28.197Z","createdAt":"2025-12-27T01:14:00.333Z"},{"id":"gh-72","question":"How would you design and implement network segmentation for a microservices architecture, including Zero Trust principles, east-west traffic monitoring, and compliance requirements?","answer":"Network segmentation isolates workloads using micro-segmentation with service mesh (Istio), VPCs, and Kubernetes NetworkPolicies. Zero Trust architecture enforces mTLS between services, with east-west traffic monitoring via eBPF agents (Cilium) and compliance automation for PCI-DSS/HIPAA through policy-as-code (OPA/Gatekeeper).","explanation":"## Core Architecture\n\n**Micro-segmentation** isolates individual services rather than broad zones, reducing blast radius. Implement using:\n- Kubernetes NetworkPolicies for pod-level isolation\n- Service mesh (Istio/Linkerd) for mTLS and traffic control\n- Cloud VPCs/subnets for infrastructure-level segmentation\n\n## Zero Trust Integration\n\n- **mTLS everywhere**: Service mesh enforces mutual authentication\n- **Identity-based policies**: Use SPIFFE/SPIRE for service identities\n- **Least privilege**: Granular RBAC per service endpoint\n- **Continuous verification**: Real-time policy enforcement\n\n## East-West Traffic Monitoring\n\n- **eBPF-based observability**: Cilium/Hubble for deep packet inspection\n- **Service mesh telemetry**: Istio's Mixer for policy enforcement\n- **Anomaly detection**: ML models identify unusual lateral movement\n- **Audit trails**: Immutable logs for forensic analysis\n\n## Cloud Implementation\n\n```yaml\n# Kubernetes NetworkPolicy example\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: payment-service\nspec:\n  podSelector:\n    matchLabels:\n      app: payment-service\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: api-gateway\n    ports:\n    - protocol: TCP\n      port: 8443\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: database\n    ports:\n    - protocol: TCP\n      port: 5432\n```\n\n## Compliance Automation\n\n- **PCI-DSS**: Cardholder data isolation with dedicated segments\n- **HIPAA**: PHI segregation with audit logging\n- **Policy-as-code**: OPA/Gatekeeper for automated compliance checks\n- **Continuous validation**: Automated penetration testing\n\n## Real-world Trade-offs\n\n- **Performance overhead**: mTLS adds ~2-5ms latency\n- **Operational complexity**: Requires specialized networking skills\n- **Cost**: Additional monitoring and enforcement tools\n- **Flexibility vs security**: Balance business agility with protection needs","diagram":"flowchart TD\n  A[Untrusted Network] --> B[Firewall]\n  B --> C[DMZ Segment]\n  B --> D[Application Segment]\n  B --> E[Database Segment]\n  C --> F[Web Servers]\n  D --> G[App Servers]\n  E --> H[Database Servers]","difficulty":"advanced","tags":["security","network"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":null,"companies":["Amazon","Cloudflare","Google","Hashicorp","Microsoft","Stripe"],"eli5":"Imagine your house has different rooms for different activities. You keep your toys in the playroom, food in the kitchen, and books in the study. If someone spills juice in the kitchen, it doesn't get on your toys! Network segmentation is like putting walls between these rooms. It keeps different parts of a computer network separate, so if a bad guy gets into one room, they can't wander into other rooms and cause more trouble. It's like having special doors that only certain people can use - the toy room door only opens for kids who want to play, the kitchen door only for people who are hungry, and so on. This way, even if one room has a problem, all the other rooms stay safe and sound!","relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-24T16:50:40.489Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-186","question":"How would you implement session affinity (sticky sessions) in HAProxy while maintaining high availability, and what are the trade-offs compared to stateless load balancing?","answer":"Implement session affinity in HAProxy using either source IP hashing with 'balance source' or cookie-based stick tables, while maintaining high availability through health checks. The trade-offs include improved user experience and session consistency versus reduced scalability and potential uneven load distribution.","explanation":"## Session Affinity in HAProxy\n\nSession affinity ensures users consistently reach the same backend server, which is essential for applications storing session data locally rather than in shared stores.\n\n## Implementation Methods\n\n### Source IP Hashing\n```haproxy\nbackend web_servers\n    balance source\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n    server web3 192.168.1.12:80 check\n```\n\n### Stick Tables (Cookie-based)\n```haproxy\nbackend web_servers\n    balance roundrobin\n    stick-table type string len 32 size 30k expire 30m\n    stick on cookie(JSESSIONID)\n    server web1 192.168.1.10:80 check cookie web1\n    server web2 192.168.1.11:80 check cookie web2\n    server web3 192.168.1.12:80 check cookie web3\n```\n\n## High Availability Considerations\n\nBoth implementations include health checks (`check` directive) to automatically remove failed servers from rotation, ensuring high availability while maintaining session affinity.\n\n## Trade-offs vs Stateless Load Balancing\n\n**Advantages:**\n- Maintains session state without external session stores\n- Better user experience for stateful applications\n- Reduced complexity in application code\n\n**Disadvantages:**\n- Uneven load distribution when user traffic is concentrated\n- Reduced scalability during server failures\n- Session loss on backend server failures\n- Complicates horizontal scaling and maintenance","diagram":"graph TD\n    A[Client Requests] --> B[HAProxy Load Balancer]\n    B --> C{Session Affinity Check}\n    C -->|Existing Session| D[Route to Same Server]\n    C -->|New Session| E[Apply Load Balancing Algorithm]\n    D --> F[Web Server 1]\n    E --> F[Web Server 1]\n    E --> G[Web Server 2]\n    E --> H[Web Server 3]\n    F --> I[Session Store/Local State]\n    G --> J[Session Store/Local State]\n    H --> K[Session Store/Local State]\n    L[Health Check] --> F\n    L --> G\n    L --> H\n    M[Stick Table] --> B\n    N[Cookie/Source IP] --> C","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"longVideo":"https://www.youtube.com/watch?v=qYnA2DFEELw"},"companies":["Amazon","Bloomberg","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2026-01-08T11:27:10.141Z","createdAt":"2025-12-26 12:51:06"},{"id":"sd-1","question":"Explain load balancing strategies and when to use Layer 4 vs Layer 7. How do round-robin, least connections, and IP hash algorithms compare?","answer":"Layer 4 uses TCP/UDP for faster performance with session persistence challenges. Layer 7 inspects HTTP headers for intelligent routing (path-based, host-based). Round-robin distributes evenly, least connections handles varying request loads, IP hash maintains session affinity. AWS ALB (L7) supports path-based routing while NLB (L4) offers ultra-low latency.","explanation":"## Interview Context\nThis question evaluates system design skills, networking knowledge, and performance optimization capabilities essential for senior roles.\n\n## Key Technical Concepts\n### Load Balancing Layers\n- **Layer 4**: TCP/UDP level, faster (~1ms), no content inspection, session persistence challenges\n- **Layer 7**: Application level, intelligent routing, SSL termination, content-based rules (~5ms overhead)\n\n### Algorithms Comparison\n```yaml\n# Weighted Round Robin\nservers:\n  - id: server1\n    weight: 3  # 60% traffic\n    connections: 0\n  - id: server2\n    weight: 2  # 40% traffic\n    connections: 0\n\n# Least Connections\nactive_connections:\n  server1: 150\n  server2: 100  # Route new requests here\n\n# IP Hash\nhash_source: client_ip\nmodulus: server_count\nresult: consistent server mapping\n```\n\n### Architecture for 100K RPS\n```\nInternet → CDN → L7 Load Balancer (ALB) → L4 Load Balancer (NLB) → Microservices集群\n                                ↓\n                          WAF & Rate Limiting\n                                ↓\n                       Health Checks & Auto Scaling\n```\n\n## Performance Considerations\n- **Throughput**: NLB handles >100M TPS, ALB handles ~10M requests\n- **Latency**: Layer 4 = 1-2ms, Layer 7 = 3-8ms\n- **Scaling**: Horizontal load balancer deployment with DNS round-robin\n\n## Implementation Examples\n```javascript\n// Weighted Round Robin Implementation\nclass LoadBalancer {\n  constructor(servers) {\n    this.servers = servers.map(s => ({...s, currentWeight: 0}));\n  }\n  \n  getServer() {\n    const totalWeight = this.servers.reduce((sum, s) => sum + s.weight, 0);\n    let best = null;\n    let max = -1;\n    \n    this.servers.forEach(server => {\n      server.currentWeight += server.weight;\n      if (server.currentWeight > max) {\n        max = server.currentWeight;\n        best = server;\n      }\n    });\n    \n    if (best) best.currentWeight -= totalWeight;\n    return best;\n  }\n}\n```\n\n## Trade-offs\n- **Layer 4**: Max performance, minimal features\n- **Layer 7**: Rich features, higher latency\n- **Round Robin**: Simple, equal distribution\n- **Least Connections**: Better for varied response times\n- **IP Hash**: Session persistence, uneven distribution risk\n\n## Follow-up Questions\n1. How would you handle database connection pooling with this architecture?\n2. What monitoring metrics would you track for load balancer health?\n3. How does this design change for WebSocket connections?","diagram":"graph LR\n    User --> LB[Load Balancer]\n    LB -->|Layer 4| S1[\"Server 1<br/>IP:Port\"]\n    LB -->|Layer 7| S2[\"Server 2<br/>/api\"]\n    style LB fill:#fff,stroke:#000,color:#000","difficulty":"advanced","tags":["infra","scale","networking"],"channel":"networking","subChannel":"load-balancing","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=dBmxNsS3BGE","longVideo":"https://www.youtube.com/watch?v=aKMLgFVxZYk"},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":"Imagine you're the lunch line monitor at school! When lots of kids want lunch at once, you can't let everyone rush to one lunch lady - that would make her super tired and some kids would wait forever. So you send kids to different lunch ladies so everyone gets food fast! Layer 4 is like just counting kids and sending them to the next available lunch lady - you don't care what lunch they want, just keeping the line moving. Layer 7 is like looking at each kid's lunch order first - if someone wants a sandwich, you send them to the sandwich station, if they want pizza, to the pizza line! This way, the pizza experts handle pizza orders and sandwich experts handle sandwiches. Use Layer 4 when you just need to spread people out evenly, and Layer 7 when different servers are good at different things!","relevanceScore":null,"voiceKeywords":["layer 4","layer 7","round-robin","least connections","ip hash","session persistence","alb","nlb"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:52:25.933Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-203","question":"How does TCP's congestion control algorithm interact with HTTP/2's multiplexing when multiple streams compete for bandwidth?","answer":"TCP's congestion control operates at the transport layer and treats all HTTP/2 streams as a single connection, meaning all streams share the same congestion window and experience identical throughput limitations, which can lead to head-of-line blocking across streams.","explanation":"## Concept Overview\nTCP's congestion control algorithm manages network throughput at the transport layer, completely unaware of HTTP/2's application-layer multiplexing. This creates a fundamental architectural mismatch where TCP's connection-level control impacts all HTTP/2 streams equally.\n\n## Implementation Details\nTCP implements congestion control through algorithms like Reno, CUBIC, or BBR that maintain a congestion window (cwnd) limiting the number of unacknowledged bytes in flight. When HTTP/2 multiplexes multiple streams over this single TCP connection, all streams compete for the same bandwidth resources and are subject to identical packet loss recovery mechanisms.\n\n## Performance Implications\nThis interaction means that packet loss affecting any single HTTP/2 stream triggers TCP's congestion control response, reducing throughput for all streams simultaneously. The lack of per-stream congestion awareness can result in inefficient bandwidth utilization and increased latency for high-priority streams when sharing the connection with lower-priority traffic.","diagram":"graph TD\n    A[HTTP/2 Client] --> B[TCP Connection]\n    B --> C[Congestion Control]\n    C --> D[Network]\n    B --> E[Stream 1]\n    B --> F[Stream 2]\n    B --> G[Stream 3]\n    C --> H[Shared cwnd]\n    H --> E\n    H --> F\n    H --> G","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":null,"videos":{"shortVideo":"https://www.youtube.com/watch?v=0j_4EDV-nWY","longVideo":"https://www.youtube.com/watch?v=fVKPrDrEwTI"},"companies":["Amazon Aws","Cloudflare","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["tcp","congestion control","http/2","multiplexing","head-of-line blocking"],"voiceSuitable":true,"lastUpdated":"2025-12-30T01:44:31.798Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-256","question":"How does QUIC solve TCP's head-of-line blocking problem in HTTP/2 multiplexing, and what are the implementation trade-offs?","answer":"QUIC eliminates head-of-line blocking by implementing stream-independent packet delivery over UDP, where lost packets only affect their specific stream rather than blocking the entire connection.","explanation":"## Concept Overview\nHead-of-line blocking occurs when a single lost packet blocks all subsequent packets, even those belonging to different streams. This significantly impacts HTTP/2 performance over TCP connections.\n\n## Implementation Details\n- **TCP Approach**: All multiplexed streams share a single TCP connection. Packet loss blocks the entire connection, affecting all streams simultaneously.\n- **QUIC Approach**: Each QUIC stream operates independently. Lost packets only block their specific stream, allowing other streams to continue transmitting.\n- QUIC utilizes connection IDs (rather than IP+port combinations) for connection identification and supports connection migration.\n\n## Code Example\n```bash\n# TCP (HTTP/2) - blocked by single loss\nStream 1: [P","diagram":"graph TD\n    A[HTTP/2 over TCP] --> B[Single TCP Connection]\n    B --> C[Packet Loss on Stream 1]\n    C --> D[All Streams Blocked]\n    \n    E[HTTP/3 over QUIC] --> F[Multiple Independent Streams]\n    F --> G[Packet Loss on Stream 1]\n    G --> H[Only Stream 1 Affected]\n    H --> I[Other Streams Continue]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://www.haproxy.com/blog/choosing-the-right-transport-protocol-tcp-vs-udp-vs-quic/","videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","multiplexing","udp","stream independence","tcp"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:21:25.402Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-275","question":"How does QUIC solve HTTP/2's head-of-line blocking issue over TCP, and what are the implementation trade-offs?","answer":"QUIC runs over UDP with independent streams, eliminating TCP-level blocking while implementing reliability at the application layer.","explanation":"## Concept\nHTTP/2 suffers from head-of-line blocking at the TCP level - a single lost packet blocks all streams. QUIC solves this by using UDP as the transport protocol and implementing reliability, congestion control, and stream multiplexing at the application layer.\n\n## Implementation\n```go\n// QUIC stream independence\nfor _, stream := range conn.Streams() {\n    go func(s quic.Stream) {\n        // Each stream processes independently\n        data, err := io.ReadAll(s)\n        // Lost packets only affect this stream\n        handleStreamData(s.ID(), data)\n    }(stream)\n}\n\n// Connection-level recovery\nconn.HandleLostPackets(func(packetID uint64) {\n    // Selective retransmission\n    if shouldRetransmit(packetID) {\n        conn.RetransmitPacket(packetID)\n    }\n})\n```\n\n## Trade-offs\n- **Pros**: Stream independence, faster recovery, reduced latency\n- **Cons**: Higher CPU usage, UDP firewall issues, complex implementation","diagram":"flowchart TD\n    A[Client Request] --> B{Transport Layer}\n    B -->|HTTP/2| C[TCP]\n    B -->|QUIC| D[UDP]\n    C --> E[TCP Stream 1] --> F[TCP Stream 2] --> G[TCP Stream 3]\n    D --> H[QUIC Stream 1] --> I[QUIC Stream 2] --> J[QUIC Stream 3]\n    \n    K[Packet Loss] --> E\n    K --> F\n    K --> G\n    style E fill:#ffcccc\n    style F fill:#ffcccc\n    style G fill:#ffcccc\n    \n    L[Packet Loss] --> H\n    style H fill:#ffcccc\n    style I fill:#ccffcc\n    style J fill:#ccffcc\n    \n    M[TCP HOL Blocking] --> N[All Streams Blocked]\n    O[QUIC Independence] --> P[Only Affected Stream Blocked]","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"channel":"networking","subChannel":"tcp-ip","sourceUrl":"https://tools.ietf.org/html/rfc9000","videos":{"shortVideo":null,"longVideo":"https://www.youtube.com/watch?v=GriONb4EfPY"},"companies":["Amazon","Google","Meta","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":["quic","head-of-line blocking","http/2","tcp","udp","streams","reliability"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:22:20.630Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["dns","general","load-balancing","tcp-ip"],"companies":["Adobe","Amazon","Amazon Aws","Bloomberg","Cisco","Cloudflare","Discord","Goldman Sachs","Google","Hashicorp","IBM","Meta","Microsoft","Netflix","Snowflake","Stripe","Twitter"],"stats":{"total":10,"beginner":2,"intermediate":4,"advanced":4,"newThisWeek":0}}