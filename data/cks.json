{"questions":[{"id":"cks-minimize-vulnerabilities-1768151890328-0","question":"An e-commerce platform runs microservices in Kubernetes with an Istio service mesh. A malicious actor gains access to a pod in the payments namespace and attempts to call the billing service to exfiltrate customer data. Which control most effectively minimizes blast radius in this scenario?","answer":"[{\"id\":\"a\",\"text\":\"Enforce Istio AuthorizationPolicy to restrict which services can be called by each workload\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on Kubernetes NetworkPolicy alone to segment traffic\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Disable mTLS to enable traffic inspection at the gateway\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Place all services into a single namespace with broad RBAC\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\na. Enforce Istio AuthorizationPolicy to restrict which services can be called by each workload\n\n## Why Other Options Are Wrong\n\n- b) Relying on Kubernetes NetworkPolicy alone is insufficient for L7 service-to-service authorization in a mesh.\n- c) Disabling mTLS would weaken authentication and confidentiality and could worsen the breach.\n- d) Splitting the cluster into multiple clusters is heavy-handed and does not address the immediate risk from a compromised pod.\n\n## Key Concepts\n\n- Istio AuthorizationPolicy\n- Zero-trust security\n- Service-to-service access control\n\n## Real-World Application\n\n- Apply per-workload AuthorizationPolicy across all namespaces; combine with strict PeerAuthentication; validate traffic with Istio telemetry to detect violations.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Istio","Security","Service Mesh","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"minimize-vulnerabilities","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:18:10.329Z","createdAt":"2026-01-11 17:18:10"},{"id":"cks-minimize-vulnerabilities-1768151890328-1","question":"A Kubernetes cluster stores database credentials in Kubernetes Secrets in etcd. Encryption at rest is not enabled, and backups contain plaintext secrets. Which remediation provides the strongest defense against credential leakage?","answer":"[{\"id\":\"a\",\"text\":\"Enable encryption at rest for Kubernetes Secrets using a cloud KMS and rotate existing credentials\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Switch Secrets to ConfigMaps to improve readability\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Place credentials in environment variables inside Pod specs\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Remove Secrets and inject credentials at runtime via prompts\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\na. Enable encryption at rest for Kubernetes Secrets using a cloud KMS and rotate existing credentials\n\n## Why Other Options Are Wrong\n\n- b) ConfigMaps are not suitable for storing secrets and do not provide encryption or access controls.\n- c) Environment variables in Pod specs can be exposed via process listings and logs.\n- d) Runtime prompts are insecure and not suitable for automated deployment pipelines.\n\n## Key Concepts\n\n- Kubernetes Secrets encryption at rest\n- KMS integration\n- Credential rotation\n\n## Real-World Application\n\n- Enable encryption at rest for Secrets; consider external secret stores (e.g., AWS Secrets Manager) and rotate credentials regularly to minimize leakage risk.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","AWS","KMS","Secrets","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"minimize-vulnerabilities","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:18:10.737Z","createdAt":"2026-01-11 17:18:11"},{"id":"cks-minimize-vulnerabilities-1768151890328-2","question":"During deployment, some services communicate over TLS, while development environments use self-signed certs and code disables certificate verification. Which approach best minimizes this vulnerability in production?","answer":"[{\"id\":\"a\",\"text\":\"Adopt a service mesh with mTLS enabled and use a trusted certificate authority with rotating certs; enforce peer authentication across all services\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Always disable TLS verification in the client to simplify calls\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Pin static certificates in code and rebuild for each rotation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Remove TLS from internal calls and rely on network isolation\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\na. Adopt a service mesh with mTLS enabled and use a trusted certificate authority with rotating certs; enforce peer authentication across all services\n\n## Why Other Options Are Wrong\n\n- b) Disabling TLS verification creates MITM risks and undermines security.\n- c) Pinning static certificates is brittle and rotation-heavy; risks stale trust anchors.\n- d) Removing TLS from internal calls removes encryption and increases exposure; network isolation is insufficient alone.\n\n## Key Concepts\n\n- mTLS and certificate rotation\n- Istio/Envoy CA and PeerAuthentication\n- Service-to-service security\n\n## Real-World Application\n\n- Implement Istio or another service mesh to automatically manage short-lived certs; enforce strict peer verification and regular certificate rotations to minimize production risk.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Istio","TLS","Security","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"minimize-vulnerabilities","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T17:18:11.192Z","createdAt":"2026-01-11 17:18:11"},{"id":"cks-monitoring-logging-1768221909292-0","question":"In a Kubernetes cluster, you want to detect and respond to runtime security threats such as privilege escalation and container breakout in near real time. Which combination best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Deploy Falco with custom rules for privilege escalation and route alerts to the security incident channel\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on Kubernetes events from kubelet alone to trigger investigations\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable only Kubernetes API audit logs and store them offline for investigations\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Install a host-based IDS on the operating system without container runtime monitoring\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Falco provides runtime security monitoring for Kubernetes and can detect privilege escalation and container breakout in near real time when paired with custom rules and real-time alerting.\n\n## Why Other Options Are Wrong\n- Option B is incorrect because Kubernetes events from kubelet offer limited runtime visibility and can miss syscall-level events and subtle container intrusions.\n- Option C is incorrect because API audit logs monitor API activity only and do not reveal or correlate runtime container behavior necessary for detecting compromises.\n- Option D is incorrect because host-based IDS without container runtime integration lacks visibility into containerized workloads and cannot reliably detect container-level anomalies.\n\n## Key Concepts\n- Runtime security tooling (e.g., Falco) for Kubernetes, with custom rules for common attack patterns\n- Real-time alerting and integration with incident response workflows\n\n## Real-World Application\nDeploy Falco as a DaemonSet, write rules for privilege escalation (e.g., shell access, unexpected exec), and integrate alerts with your SIEM or incident channel. Combine with container image provenance and, where possible, Kubernetes audit logs for a layered defense.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Falco","Loki","Fluent Bit","Prometheus","Grafana","Runtime Security","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:45:09.293Z","createdAt":"2026-01-12 12:45:09"},{"id":"cks-monitoring-logging-1768221909292-1","question":"You operate a Kubernetes cluster and need to centralize logs and metrics to support security investigations. Which approach provides reliable log correlation across pods, namespaces, and containers?","answer":"[{\"id\":\"a\",\"text\":\"Ship container logs to Loki via Fluent Bit with Kubernetes metadata, and build Grafana dashboards that correlate by pod UID and container ID\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Collect only Prometheus metrics and forego logs\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use CloudWatch Logs only without structured Kubernetes metadata\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Retrieve logs using kubectl logs only and store them in a separate blob\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Loki, when paired with Fluent Bit, preserves Kubernetes metadata (namespace, pod, container, UID) enabling precise cross-component log correlation, and Grafana dashboards can unite logs with metrics and traces for efficient investigations.\n\n## Why Other Options Are Wrong\n- Option B is incorrect because metrics alone do not provide the context needed to diagnose security incidents; logs are essential for root-cause analysis.\n- Option C is incorrect because CloudWatch Logs without Kubernetes metadata limits correlation across pods/nods, reducing investigative effectiveness in multi-cluster or on-prem environments.\n- Option D is incorrect because kubectl logs is manual, non-scalable, and loses historical context when stored in a separate blob without centralized indexing.\n\n## Key Concepts\n- Centralized observability stacks (logs, metrics, traces) with Kubernetes metadata\n- Loki + Fluent Bit integration for scalable log shipping\n\n## Real-World Application\nDeploy Fluent Bit as a DaemonSet to ship container logs to Loki, enrich with Kubernetes metadata, and create Grafana dashboards that link logs to Prometheus metrics for rapid security investigations.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Loki","Fluent Bit","Grafana","Prometheus","Observability","Security","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:45:09.808Z","createdAt":"2026-01-12 12:45:10"},{"id":"cks-monitoring-logging-1768221909292-2","question":"To detect and prevent anomalous network behavior in real time within a Kubernetes cluster, which tooling approach is most effective?","answer":"[{\"id\":\"a\",\"text\":\"Use an eBPF-based CNI like Cilium to enforce and monitor policies and generate runtime security alerts\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on Kubernetes NetworkPolicy objects alone and don't monitor runtime traffic\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use an IDS on a separate host with no integration into the cluster network\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a static firewall rule set on the ingress controller only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because eBPF-based CNIs like Cilium provide visibility into live network flows, allow enforcement of fine-grained policies at the kernel level, and generate runtime security alerts for anomalous traffic patterns.\n\n## Why Other Options Are Wrong\n- Option B is incorrect because static Kubernetes NetworkPolicy objects do not monitor runtime traffic or detect anomalies in real time.\n- Option C is incorrect because an external IDS on a separate host may miss in-cluster east-west traffic and lacks tight integration for immediate containment.\n- Option D is incorrect because ingress-only firewalls miss internal cluster traffic and lateral movement within the pod network.\n\n## Key Concepts\n- In-cluster runtime network visibility with eBPF (e.g., Cilium, Hubble)\n- Real-time policy enforcement and alerting for Kubernetes workloads\n\n## Real-World Application\nDeploy Cilium with its Hubble observability, define runtime network policies, and wire alerts to your incident response tooling to detect and block suspicious cross-pod communication in real time.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Cilium","eBPF","Networking","Observability","Security","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"monitoring-logging","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T12:45:10.294Z","createdAt":"2026-01-12 12:45:10"},{"id":"cks-supply-chain-1768193408010-0","question":"A development team builds Docker images in CI for a microservice that runs on an EKS cluster. To enforce reproducible builds and trusted provenance, which approach should be implemented end-to-end?","answer":"[{\"id\":\"a\",\"text\":\"Sign the image with Cosign and publish attestations to Rekor; generate a CycloneDX SBOM; enforce in-cluster by admission controls.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely solely on static code analysis in CI for provenance.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a private registry without attestations and disable image verification.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a build with no signature and rely on KMS encryption only.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Sign the image with Cosign and publish attestations to Rekor; generate a CycloneDX SBOM; enforce in-cluster by admission controls.\n\n## Why Other Options Are Wrong\n- B: Static code analysis does not provide cryptographic provenance or tamper-evidence for artifacts.\n- C: A private registry without attestations lacks verifiable provenance and can undermine supply chain integrity.\n- D: Encryption alone protects confidentiality but does not provide artifact provenance or tamper-evidence.\n\n## Key Concepts\n- Image provenance with Sigstore Cosign and Rekor\n- SBOM generation with CycloneDX\n- Reproducible builds and attestations\n- In-cluster enforcement via admission controls (e.g., Webhook/OPA)\n\n## Real-World Application\n- Integrate Cosign signing in CI, publish attestations to Rekor, generate CycloneDX SBOMs, and implement a Kubernetes admission webhook or OPA policy to require valid signatures for deployments.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","EKS","Cosign","Rekor","SBOM","CycloneDX","OPA","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"supply-chain","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:50:08.011Z","createdAt":"2026-01-12 04:50:08"},{"id":"cks-supply-chain-1768193408010-1","question":"In a multi-language software project, a company wants a single source of truth SBOM across languages to support audits and vulnerability management. Which practice best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Generate CycloneDX SBOMs for each language and publish to a central SBOM registry with consistent metadata.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Generate a single SBOM only for the primary language and reuse for others.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on license scanning tools as a substitute for SBOM.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Maintain SBOMs in local spreadsheets for each repo.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Generate CycloneDX SBOMs for each language and publish to a central SBOM registry with consistent metadata.\n\n## Why Other Options Are Wrong\n- B: Different languages have distinct dependencies; a single SBOM per language avoids gaps and ensures completeness.\n- C: License scanning does not provide a complete SBOM with component versions and transitive dependencies.\n- D: Spreadsheets are prone to drift and are not tamper-evident or machine-readable for audits.\n\n## Key Concepts\n- CycloneDX standard for SBOMs\n- Multi-language dependency management\n- Central SBOM registry for tamper-evidence\n\n## Real-World Application\n- Implement automated SBOM generation in CI for each language and push artifacts to a centralized SBOM catalog used by security and compliance teams.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","CycloneDX","SBOM","OPA","Multi-language","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"supply-chain","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:50:08.441Z","createdAt":"2026-01-12 04:50:08"},{"id":"cks-supply-chain-1768193408010-2","question":"To prevent supply chain compromise in a Kubernetes deployment, a policy enforces that all container images must be signed by a trusted signer before they can be deployed. Which implementation best enforces this policy in practice?","answer":"[{\"id\":\"a\",\"text\":\"Deploy a ValidatingAdmissionWebhook (e.g., using Sigstore or Cosign integration) with Gatekeeper/OPA policy that rejects unsigned images.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely on runtime security scanning and block unsigned images after deployment.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use image pull-through caching with no signature checks.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Allow developers to override policy with cluster-admin privileges.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Deploy a ValidatingAdmissionWebhook (e.g., using Sigstore or Cosign integration) with Gatekeeper/OPA policy that rejects unsigned images.\n\n## Why Other Options Are Wrong\n- B: Runtime checks after deployment miss early failure and can allow unsigned images to run in production.\n- C: Caching without signature checks defeats provenance guarantees.\n- D: Overriding policy with cluster-admin privileges undermines the control and increases risk.\n\n## Key Concepts\n- Image provenance enforcement via admission controls\n- Sigstore/Cosign signing with Rekor\n- Gatekeeper/OPA policies for Kubernetes\n\n## Real-World Application\n- Implement a ValidatingWebhookConfiguration and Gatekeeper policy requiring signatures; set fail-closed for unsigned artifacts and maintain an exceptions workflow for legitimate cases.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Cosign","Sigstore","Gatekeeper","OPA","EKS","certification-mcq","domain-weight-20"],"channel":"cks","subChannel":"supply-chain","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T04:50:08.834Z","createdAt":"2026-01-12 04:50:08"}],"subChannels":["minimize-vulnerabilities","monitoring-logging","supply-chain"],"companies":[],"stats":{"total":9,"beginner":0,"intermediate":9,"advanced":0,"newThisWeek":9}}