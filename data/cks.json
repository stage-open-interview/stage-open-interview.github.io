{"questions":[{"id":"q-1121","question":"Scenario: You operate a shared Kubernetes cluster serving multiple product teams. You must prevent cross-namespace data leakage and enforce least-privilege access while remaining auditable and scalable. Describe a concrete strategy using either OPA Gatekeeper or Kyverno for admission control (with at least two constraints), implement namespace RBAC boundaries, apply Calico NetworkPolicy for namespace isolation, and outline a monitoring/audit plan with tests and runbooks. Include example policies and a minimal test commands snippet?","answer":"Implement policy-as-code with admission controls using either OPA Gatekeeper or Kyverno, enforcing at least two constraints: (1) workloads must run in approved namespaces, (2) pods must not run as pri","explanation":"## Why This Is Asked\n\nEvaluates practical multi-tenant security controls, policy-as-code, and operational testing in Kubernetes.\n\n## Key Concepts\n\n- Admission control with Gatekeeper or Kyverno\n- Namespace RBAC scoping\n- Calico NetworkPolicy isolation\n- Auditing and runbooks\n- CI validation and drift checks\n\n## Code Example\n\n```javascript\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sNSApproved\nmetadata:\n  name: ns-approved\nspec:\n  match:\n    namespaces: [\"approved-*\"]\n```\n\n```javascript\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: restrict-privileges\nspec:\n  rules:\n  - name: disallow-privileged\n    match:\n      resources:\n        kinds: [\"Pod\"]\n    validate:\n      message: \"Privileged containers are not allowed\"\n      pattern:\n        spec:\n          containers:\n          - securityContext:\n              allowPrivilegeEscalation: false\n              readOnlyRootFilesystem: true\n```\n\n```javascript\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\nspec:\n  podSelector: {}\n  policyTypes: [\"Ingress\",\"Egress\"]\n  ingress: []\n  egress: []\n```\n\n## Follow-up Questions\n\n- How would you test these policies in CI?\n- How would you handle policy drift and remediation?\n","diagram":"flowchart TD\n  A[Namespaces] --> B[RBAC]\n  B --> C[AdmissionPolicy]\n  C --> D[NetworkPolicy]\n  D --> E[Auditing]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T23:29:20.472Z","createdAt":"2026-01-12T23:29:20.472Z"},{"id":"q-1130","question":"You're running a Kubernetes cluster for a web app. A Pod mounting hostPath and running as root was detected in dev. Outline a practical plan to enforce least privilege across namespaces (Baseline/Restricted) using a policy engine (Kyverno or OPA Gatekeeper) and show how you would validate enforcement without disrupting workloads. What steps and files would you use?","answer":"Implement a baseline Pod Security Standard across namespaces by enabling Kyverno policy or OPA Gatekeeper constraint. Enforce runAsNonRoot: true, readOnlyRootFilesystem: true, disallow hostPath, and d","explanation":"## Why This Is Asked\nA practical beginner-level check for implementing and validating security controls in Kubernetes using policy engines, focusing on least privilege and safe defaults.\n\n## Key Concepts\n- Pod Security Standards Baseline/Restricted\n- Policy engines: Kyverno, OPA Gatekeeper\n- Privilege escalation controls: runAsNonRoot, readOnlyRootFilesystem, capabilities\n- Testing methods: compliant vs non-compliant pods, namespace scoping\n- Change management and rollback\n\n## Code Example\n```javascript\n// Conceptual Kyverno policy (JS object for illustration)\nconst policy = {\n  apiVersion: 'kyverno/v1',\n  kind: 'ClusterPolicy',\n  metadata: { name: 'require-baseline-security' },\n  spec: {\n    rules: [\n      {\n        name: 'require-baseline',\n        match: { resources: { kinds: ['Pod'] }},\n        validate: {\n          message: 'Pods must set runAsNonRoot, readOnlyRootFilesystem and avoid hostPath',\n          pattern: {\n            spec: {\n              containers: { any: { securityContext: { runAsNonRoot: true, readOnlyRootFilesystem: true } }},\n              hostPath: { absent: {} }\n            }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n## Follow-up Questions\n- How would you handle exceptions for legitimate hostPath usage?\n- How would you monitor for policy violations in production?","diagram":"flowchart TD\n  A[Define Baseline] --> B[Apply to Namespace]\n  B --> C[Test Compliant Pod]\n  C --> D[Test Violating Pod]\n  D --> E[Monitor & Iterate]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:22:06.201Z","createdAt":"2026-01-13T01:22:06.201Z"},{"id":"q-1167","question":"Scenario: You operate a multi-cluster Kubernetes data platform (cloud+on‑prem) where a Spark job can access customer data. Design an end-to-end approach to detect, prevent, and respond to data exfiltration attempts from pods across clusters. Include policy design, telemetry signals, enforcement, and incident runbooks; discuss trade-offs?","answer":"Adopt a data-classification driven policy wired through OPA Gatekeeper and Kyverno, enforce egress with default-deny for pods without explicit allow, and centralize audit logs across clusters. Use lab","explanation":"## Why This Is Asked\nTests ability to design end-to-end controls across multi-cluster environments, not just single-cluster examples.\n\n## Key Concepts\n- Data classification and tagging in Kubernetes\n- OPA Gatekeeper and Kyverno policy frameworks\n- Egress controls with Calico/Cilium\n- Kubernetes audit logging and tamper-evident storage\n- Spark / data platform security\n\n## Code Example\n```javascript\n// Example policy sketch (pseudo)\nfunction policy(pod, action, dest){ /* evaluate against labels, namespaces, and allowlists */ }\n```\n\n## Follow-up Questions\n- How would you test policy drift at scale?\n- What telemetry would you collect to distinguish exfiltration from legitimate data movement?","diagram":"flowchart TD\n  A[Data classification] --> B[Policy evaluation]\n  B --> C{Allow or Deny}\n  C --> D[Enforcement point]\n  A --> E[Audit & telemetry]\n  D --> E","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T03:32:11.099Z","createdAt":"2026-01-13T03:32:11.099Z"},{"id":"q-1278","question":"Scenario: A fintech data platform runs a multi-tenant data lake on Kubernetes. Each data job uses per-job ServiceAccounts to access restricted cloud storage. A rogue pod tries to exfiltrate data via the bucket. Propose a security approach that binds each pod to a dedicated cloud IAM role (workload identity), enforces namespace-scoped permissions, and provides tamper-evident audit trails. Include detection and response for abnormal egress and a safe rotation plan. What trade-offs?","answer":"Bind each pod to a dedicated cloud IAM role via workload identity federation, with namespace-scoped permissions and least privilege. Disable instance metadata access, use private endpoints, and short-","explanation":"## Why This Is Asked\n\nThis question assesses practical implementation of workload identity, RBAC scoping, and robust audit/response in a fintech-like Kubernetes deployment.\n\n## Key Concepts\n\n- Workload Identity Federation\n- Least privilege RBAC and namespace isolation\n- IMDS access control and private endpoints\n- Immutable audit logs and egress monitoring\n- Credential rotation and incident response\n\n## Code Example\n\n```yaml\n# GKE Workload Identity binding example\napiVersion: v1\nkind: Pod\nmetadata:\n  name: data-job\n  annotations:\n    iam.gke.io/gcp-service-account: data-job-sa@PROJECT.iam.gserviceaccount.com\nspec:\n  serviceAccountName: data-job-sa\n```\n\n## Follow-up Questions\n\n- How would you test these controls end-to-end?\n- How would you rotate keys without restarting jobs?\n- How would you handle missed bindings or fallback scenarios?","diagram":null,"difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T07:41:55.251Z","createdAt":"2026-01-13T07:41:55.251Z"},{"id":"q-1301","question":"You're debugging a Kubernetes deployment in a multi-tenant environment where one namespace's pods delay startup by several minutes. Provide a practical, beginner-friendly diagnostic flow focusing on pod events, init containers, image pulls, and config maps. List concrete kubectl commands you would run and how you’d determine the root cause?","answer":"Begin with: kubectl describe pod <pod> -n <ns> to surface events and init-container status. Inspect init containers with kubectl get pod <pod> -n <ns> -o jsonpath '{.status.initContainerStatuses[*].st","explanation":"## Why This Is Asked\n\nTests practical Kubernetes debugging skills, focusing on actionable steps, not theory. It checks familiarity with pod lifecycle, init containers, and how to correlate events with configuration objects during startup delays.\n\n## Key Concepts\n\n- Pod lifecycle and init containers\n- kubectl debugging commands (describe, get, logs, jsonpath)\n- Image pull behavior and identifiers\n- ConfigMaps and Secrets mounting in pods\n- Deployment rollout and readiness checks\n\n## Code Example\n\n```javascript\n// Example diagnostic sequence (pseudo-commands, replace <pod> and <ns> accordingly)\nkubectl describe pod <pod> -n <ns>\nkubectl get pod <pod> -n <ns> -o jsonpath '{.status.initContainerStatuses[*].state}'\nkubectl logs <pod> -c <init-container> -n <ns>\nkubectl describe deployment <deploy> -n <ns>\nkubectl get cm -n <ns>\nkubectl get secret -n <ns>\n```\n\n## Follow-up Questions\n\n- What would you check if the pod remains Pending after image pull completes?\n- How would you distinguish between a misconfigured readinessProbe vs a slow startup?","diagram":"flowchart TD\n  A[Start] --> B[Describe Pod] \n  B --> C[InitContainers Status] \n  C --> D[Check InitContainer Logs] \n  D --> E[Inspect Image Pull Policy/IDs] \n  E --> F[Review ConfigMaps/Secrets] \n  F --> G[Check Deployment Rollout]\n  G --> H[Root Cause Identified]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T08:47:12.930Z","createdAt":"2026-01-13T08:47:12.930Z"},{"id":"q-1323","question":"In a Kubernetes cluster deploying an ML inference service, models and weights live in a private registry. Outline a practical plan to sign models with cosign, publish attestations, and enforce runtime verification so only attested models can be deployed via GitOps (Argo CD) and an enforcement policy (OPA Gatekeeper or Kyverno). Include concrete commands and sample configuration?","answer":"Sign each model blob with cosign sign-blob, generate and publish an attestation, and require attested provenance in deployment. Integrate into Argo CD via a policy check and enforce at admission with ","explanation":"## Why This Is Asked\nTests end-to-end security for ML artifacts, combining signing attestations, GitOps, and runtime policy in Kubernetes.\n\n## Key Concepts\n- Sigstore Cosign sign-blob attest and verify-blob\n- Model provenance and SBOM\n- GitOps with Argo CD\n- Admission policies: OPA Gatekeeper or Kyverno\n\n## Code Example\n```bash\n# Sign a model blob and create an attestation\ncosign sign-blob -key cosign.key models/model-v1.bin\ncosign attest -key cosign.key --predicate predicate.json models/model-v1.bin\ncosign verify-blob -key cosign.pub models/model-v1.bin\n```\n\n```yaml\n# Kyverno policy requiring attestation before deployment\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-model-attestation\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: attested-model-artifact\n    match:\n      resources:\n        kinds: [Deployment]\n    validate:\n      message: Attestation required for model artifact\n      pattern:\n        metadata.annotations.cosign_attested: \"true\"\n```\n\n```rego\npackage kubernetes.admission\n\ndeny[{\"msg\": msg}] {\n  input.request.kind.kind == \"Deployment\"\n  not input.request.object.metadata.annotations[\"cosign_attested\"] == \"true\"\n  msg = \"Model artifact must be attested with cosign before deployment\"\n}\n```\n\n## Follow-up Questions\n- How would you handle key rotation and revocation?\n- How would you test end-to-end in CI/CD and cluster?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","PayPal","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T11:34:44.913Z","createdAt":"2026-01-13T11:34:44.913Z"},{"id":"q-1356","question":"You manage a Kubernetes cluster hosting regulated data across tenants. Design a practical end-to-end plan to enable at-rest encryption with envelope encryption using a cloud KMS, protect both API server data and etcd data, rotate keys safely, and prove compliance via CI checks. Include concrete commands and sample manifests?","answer":"Configure Kubernetes EncryptionConfig to use a cloud KMS as the envelope-encryption provider, encrypting secrets and etcd data. Rotate keys by adding a new KMS key, applying it via the config, and rol","explanation":"## Why This Is Asked\nTests practical mastery of data protection in Kubernetes, including key management, rotation strategies, and CI validation for compliance.\n\n## Key Concepts\n- Envelope encryption with Kubernetes EncryptionConfig\n- Cloud KMS integration for kms provider\n- etcd and secrets encryption\n- Key rotation and rolling updates\n- CI gates and audit logging\n\n## Code Example\n```yaml\napiVersion: v1\nkind: EncryptionConfig\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      name: \"cloud-kms\"\n      endpoint: \"unix:///var/run/kms/kms.sock\"\n      cachesize: 1000\n  - aesgcm:\n      keys:\n        - name: \"default-key\"\n          secret: \"BASE64ENCODEDKEY==\"\n```\n\n## Follow-up Questions\n- How would you validate re-encryption during rotation without downtime?\n- What logging/auditing would you implement to detect key mis-rotation or misuse?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:11:29.765Z","createdAt":"2026-01-13T13:11:29.765Z"},{"id":"q-1374","question":"Scenario: A multi-cloud platform runs Kubernetes on EKS and serverless runtimes; ensure only cosign-signed images with verifiable attestations can be deployed across all targets. Describe an end-to-end plan to enforce cross-registry provenance, automate Rekor attestations, and integrate with a GitOps workflow (Argo CD), including concrete commands and sample policy rules?","answer":"Sign images in CI with a KMS-backed cosign key, push to all registries, and attach a Rekor attestation. Enforce via a Gatekeeper/OPA policy that rejects unsigned images and a GitOps gate in Argo CD. C","explanation":"## Why This Is Asked\nTests understanding of cross-environment image provenance and automated attestation in a multi-cloud setup.\n\n## Key Concepts\n- Cross-registry signing and verification\n- Rekor attestations and intoto format\n- Policy-driven deployment gates (OPA/Gatekeeper, Argo CD gate)\n\n## Code Example\n```bash\n# Sign and verify (example for AWS KMS key)\ncosign sign --key 'kms://aws/kms/cosign' ghcr.io/org/service:tag\ncosign verify --key 'kms://aws/kms/cosign' ghcr.io/org/service:tag\ncosign attest ghcr.io/org/service:tag --predicate attest.json --type intoto\n```\n\n## Follow-up Questions\n- How would you rotate signing keys without breaking deployments?\n- How do you audit failed attestations across clusters?","diagram":"flowchart TD\n  A[Code Commit] --> B[CI Build]\n  B --> C[cosign Sign]\n  C --> D[Publish to Registries]\n  D --> E[Attach Attestations]\n  E --> F[Policy Enforcement]\n  F --> G[Deployment Across Environments]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:37:12.766Z","createdAt":"2026-01-13T14:37:12.766Z"},{"id":"q-1398","question":"In a multi-tenant Kubernetes cluster with images stored in a private OCI registry, design an end-to-end workflow to sign images with cosign, publish attestations, and enforce that only attested images are deployed. Include concrete commands, CI hints, and an admission control policy snippet?","answer":"Sign each image with cosign and publish attestations to the private OCI registry; automate in CI by running 'cosign sign' and 'cosign attest' on tag pushes. Enforce with a Kyverno deny policy (check f","explanation":"## Why This Is Asked\nReal-world supply chain integrity for multi-tenant clusters requires verifiable attestation and automated enforcement.\n\n## Key Concepts\n- Sigstore cosign attestations\n- Private OCI registries\n- CI/CD integration (GitHub Actions)\n- Admission control (Kyverno) and OPA/rego\n\n## Code Example\n```yaml\n# Kyverno policy example (high level)\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-signed-images\nspec:\n  rules:\n  - name: deny-unsigned\n    match:\n      resources:\n        kinds: [\"Deployment\"]\n    validate:\n      message: \"Image must be cosign-attested\"\n      pattern:\n        spec:\n          template:\n            spec:\n              containers:\n              - image: \"*\"\n```\n\n```rego\npackage imageauth\ndefault allow = false\n\nallow {\n  input.request.kind.kind == \"Pod\"\n  # imagine a field that indicates attestation validity\n  input.review.request.object.spec.containers[_].imageAttested == true\n}\n```\n\n## Follow-up Questions\n- How would you handle base-image rotation and attestation key rotation?\n- How do you test the policy across multiple clusters and during CI/CD failures?\n- What performance trade-offs arise with frequent attestations and how to mitigate them?","diagram":"flowchart TD\n  A[CI Build] --> B[cosign sign]\n  B --> C[cosign attest]\n  C --> D[Push to registry]\n  D --> E[GitOps deploy]\n  E --> F[Admission checks]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Discord","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:40:02.857Z","createdAt":"2026-01-13T15:40:02.857Z"},{"id":"q-1444","question":"Scenario: A poly-cloud serverless stack runs AWS Lambda, GCP Cloud Functions, and Azure Functions. CI/CD signs each function package and its dependencies with cosign and publishes SLSA attestations to a central registry. Deployments must be allowed only if attested across all clouds. Describe an end-to-end plan, including concrete commands and sample configs for signing, attesting, and cross-cloud enforcement?","answer":"Sign each function image digest and its SBOM with cosign sign-blob or cosign sign, then publish an attestation via cosign attest to Rekor. Enforce across clouds with OPA/Kyverno policies that block de","explanation":"## Why This Is Asked\nTests cross-cloud supply chain security for serverless deployments, requiring practical steps to sign artifacts, publish attestations, and enforce those attestations across multiple cloud platforms.\n\n## Key Concepts\n- Sigstore cosign and SLSA attestations\n- Multi-cloud deployment and policy enforcement (OPA, Kyverno)\n- CI/CD automation with GitHub Actions\n\n## Code Example\n```yaml\n# GitHub Actions: sign and attest serverless image\nname: Sign and Attest Serverless Images\non:\n  push:\n    branches: [ main ]\njobs:\n  sign_attest:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Setup cosign\n        uses: sigstore/cosign-installer@v1\n      - name: Build image\n        run: |\n          IMAGE=registry.example.com/function-${{ github.sha }}:latest\n          docker build -t $IMAGE .\n      - name: Sign image\n        run: cosign sign --key cosign.key $IMAGE\n      - name: Attest image\n        run: cosign attest --key cosign.key --predicate attest.json $IMAGE\n```\n\n```rego\n# Kyverno policy enforcing attestations (example)\npackage sigstore\n\ndefault allow = false\n\nallow {\n  input.attestations[_].predicate.type == \"type.googleapis.com/slsa.Provenance\"\n  input.image.docker_content_digest != \"\"\n}\n```\n\n## Follow-up Questions\n- How would you handle key rotation and revocation across clouds?\n- What metrics and dashboards would you add to monitor attestation health?","diagram":"flowchart TD\n  A[Digest] --> B[Sign Image]\n  B --> C[Publish Attestation]\n  C --> D[Policy Check]\n  D --> E[Deploy Across Clouds]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","LinkedIn","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:37:52.667Z","createdAt":"2026-01-13T17:37:52.667Z"},{"id":"q-1522","question":"Scenario: In a multi-tenant SaaS, a central migration service applies Flyway SQL scripts to dozens of PostgreSQL instances. How would you implement a concrete plan to sign each migration with cosign in CI, publish attestations to a registry, and enforce at runtime that only attested migrations are executed? Include concrete signing commands, attestation storage approach, and a sample enforcement policy (Kyverno/OPA) plus integration steps with Flyway?","answer":"Sign each migration in CI with cosign using a dedicated key, publish the attestation to a Sigstore-compatible registry, and enforce runtime verification before Flyway applies the script. Fail the job ","explanation":"## Why This Is Asked\nTests practical signing and runtime enforcement in migration workflows.\n\n## Key Concepts\n- Artifact signing with cosign\n- Attestations and trust roots\n- Runtime verification before DB changes\n- Policy tooling (Kyverno/OPA)\n\n## Code Example\n```yaml\n# Kyverno or OPA policy samples would be here in a real setup\n```\n\n## Follow-up Questions\n- How would you scale attestation storage across tenants?\n- How do you handle key rotation and revocation?","diagram":"flowchart TD\n  CI[CI/CD] --> Sign[Sign Migration]\n  Sign --> Attest[Publish Attestation]\n  Attest --> Runner[Migration Runner]\n  Runner --> DB[PostgreSQL DBs]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Slack","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T20:40:10.489Z","createdAt":"2026-01-13T20:40:10.489Z"},{"id":"q-1551","question":"In a Kubernetes-based data platform hosting a multi-tenant ML feature store exposed via a high-volume API, design a privacy-preserving, end-to-end audit trail to support forensics without exposing PII. Specify architecture, RBAC/ABAC controls, OpenTelemetry instrumentation, log pipeline (Fluentd/Loki), encryption, data redaction, retention, and how you’d run production-scale incident drills. What would you monitor first and why?","answer":"Instrument all feature-store accesses with OpenTelemetry; funnel logs/traces to per-tenant Loki sinks; redact PII before persistence; encrypt at rest with KMS; enforce ABAC via OPA and per-tenant RBAC.","explanation":"## Why This Is Asked\nThis question tests end-to-end design for privacy-preserving forensics on a multi-tenant data platform, focusing on practical tooling choices and production safety.\n\n## Key Concepts\n- OpenTelemetry instrumentation\n- Per-tenant isolation (Namespaces, ServiceAccounts)\n- Loki/NDS for immutable logs\n- Data redaction, KMS, mTLS\n- ABAC with OPA, RBAC policies\n- Incident drills and validation\n\n## Code Example\n```javascript\n// No executable code required in interview; design rationale only\n```\n\n## Follow-up Questions\n- How would you validate retention and deletion across tenants?","diagram":null,"difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","LinkedIn","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:29:58.858Z","createdAt":"2026-01-13T21:39:15.067Z"},{"id":"q-1691","question":"Scenario: A Terraform-driven multi-tenant cloud platform provisions resources across clouds. You must sign every Terraform plan in CI with cosign, publish an attestation to a central registry, and enforce at runtime that only attested plans are applied by the GitOps flow. Describe an end-to-end approach with concrete signing commands, attestation storage layout, an sample OPA policy, and integration steps with the deployment pipeline?","answer":"CI: terraform plan -out=tfplan; terraform show -json tfplan > tfplan.json; cosign sign-blob tfplan.json ghcr.io/org/terraform-plans/tenant-A:plan-${CI_COMMIT_SHORT_SHA}; cosign attest ghcr.io/org/terr","explanation":"## Why This Is Asked\nTests the ability to extend supply chain security to IaC, operationalize attestation, and integrate with GitOps across Terraform and multiple clouds. It covers plan hashing, artifact signing, attestation publication, and policy enforcement, including drift handling and key rotation.\n\n## Key Concepts\n- IaC plan provenance (Terraform plan JSON)\n- cosign sign-blob and attest\n- Rekor/Sigstore attestation registry\n- Open Policy Agent (OPA) for gate policies\n- GitOps gating (Argo CD / Tekton)\n\n## Code Example\n```javascript\nconst fs = require('fs');\nconst crypto = require('crypto');\nconst plan = fs.readFileSync('tfplan.json');\nconsole.log('SHA256', crypto.createHash('sha256').update(plan).digest('hex'));\n```\n\n## Follow-up Questions\n- How would you handle re-signing if a plan changes post-attestation?\n- How to scale attestations across dozens of tenants with separate keys and registries?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T07:01:14.464Z","createdAt":"2026-01-14T07:01:14.464Z"},{"id":"q-1734","question":"In a multi-cloud Terraform deployment across AWS, GCP, and Azure, a central registry hosts official modules. Propose a concrete plan to: - sign every module and its dependencies with cosign during CI, - publish attestations to a provenance registry, - enforce at plan/apply time that only attested modules are used via an OPA policy or equivalent gate, including concrete signing commands, storage layout for attestations, and a sample enforcement policy with integration steps?","answer":"CI signs and attests every Terraform module tarball using cosign, stores attestations in registry.example.com/terraform/attestations, and gates plans with an OPA policy requiring an attestation for al","explanation":"## Why This Is Asked\nEvaluates end-to-end IaC provenance, cross‑cloud module governance, and CI/CD gating.\n\n## Key Concepts\n- Terraform module provenance, cosign attestations, SBOMs\n- GitHub Actions or CI gates, OPA policy enforcement\n- Multi-cloud module registry integration and access control\n\n## Code Example\n```javascript\npackage terraform\n\ndefault allow = false\n\nallow {\n  input.module == m\n  data.attestations[m].signed == true\n}\n```\n\n## Follow-up Questions\n- How would you handle rotated signing keys across clouds?\n- What changes when using a module registry instead of a local path?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Apple","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:56:28.436Z","createdAt":"2026-01-14T08:56:28.436Z"},{"id":"q-1846","question":"In a Tesla-scale Databricks lakehouse on AWS, with Unity Catalog and a Kubernetes data plane, contractors routinely export aggregated datasets to external S3 buckets. Design a detection and response mechanism that distinguishes legitimate exports from exfiltration attempts. Include telemetry (Unity Catalog audit logs, IAM activity, Delta table operations), thresholds, alerting, and an incident playbook?","answer":"Implement a multi-layer detection using Unity Catalog audit logs, IAM/STS activity, and Delta Lake metadata to flag outbound exports to external buckets beyond a whitelist. Enrich with VPC flow logs a","explanation":"## Why This Is Asked\n\nTests ability to design multi-source telemetry-driven detection for data exfiltration in complex cloud-native data platforms, balancing legitimate data workflows with security controls. Evaluates incident response readiness and depth of tooling integration.\n\n## Key Concepts\n\n- Unity Catalog audit logs and Delta Lake metadata\n- IAM/STS activity and rule-based access governance\n- External data egress controls and approval workflows\n- VPC flow logs, Kubernetes data plane telemetry, and export APIs\n- Baseline-based anomaly detection and auto-containment\n\n## Code Example\n\n```python\ndef is_suspicious(event, whitelist, THRESHOLD_GB):\n    if event.type != \"EXPORT\":\n        return False\n    if event.destination_bucket not in whitelist:\n        return True\n    if event.size_gb > THRESHOLD_GB:\n        return True\n    return False\n```\n\n## Follow-up Questions\n- How would you minimize false positives while maintaining network security?\n- What metrics would you monitor to tune thresholds over time?","diagram":"flowchart TD\n  A[Export Event] --> B{IsDestinationWhitelisted?}\n  B -- Yes --> C[CheckSizeThreshold]\n  B -- No --> D[Flag as Suspicious]\n  C -- IfAboveThreshold --> D\n  C -- IfBelowThreshold --> E[Allow with Monitoring]","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T14:33:35.974Z","createdAt":"2026-01-14T14:33:35.976Z"},{"id":"q-1964","question":"In a multi-tenant notebook service on Kubernetes, each notebook runs in a transient pod and pulls dependencies from a private registry. Design a concrete plan to sign the notebook artifact (notebook.ipynb) and its dependencies with cosign, publish SLSA attestations to a central registry, and enforce at runtime that only attested notebooks and dependencies are allowed to run. Include concrete signing commands, attestations storage, and a sample Kyverno/OPA policy plus integration steps with the notebook runner?","answer":"Sign notebook.ipynb and its dependencies with cosign, e.g. cosign sign notebook.ipynb --key cosign.key and cosign sign libs/*.whl --key cosign.key; publish SLSA attestations to a central registry; enf","explanation":"## Why This Is Asked\nTests practical attestation workflows in a notebook-centric, multi-tenant Kubernetes setup, including artifact signing, attestation storage, and runtime enforcement. \n\n## Key Concepts\n- Cosign signing of notebooks and dependencies\n- SLSA attestations and registry storage\n- Runtime policy enforcement (Kyverno/OPA)\n- Notebook runner integration and rollback considerations\n\n## Code Example\n```javascript\n// Example: building a simple policy check string to feed into OPA or Kyverno\nconst policy = `\npackage notebook.authz\n\ndefault allow = false\n\nallow {\n  input.attested == true\n}\n`;\n```\n\n## Follow-up Questions\n- How would you handle key rotation and revocation for cosign keys in this flow?\n- How would you test this end-to-end in CI/CD and in disaster recovery scenarios?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Citadel","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:58:00.356Z","createdAt":"2026-01-14T18:58:00.356Z"},{"id":"q-2092","question":"In a Kubernetes-based data-analytics platform with two namespaces, dev and prod, design a practical RBAC and Pod Security setup for a new microservice 'data-processor' to ensure it can only read its own ConfigMaps and Secrets, runs as a non-root user, and cannot escalate privileges. Provide concrete manifest fragments (RBAC, ServiceAccount, RoleBinding, PodSecurityContext) and describe how to validate at admission time that all pods comply?","answer":"Create namespace-scoped RBAC with a dedicated ServiceAccount for data-processor in each namespace, a Role granting read access to ConfigMaps and Secrets, and a RoleBinding associating the ServiceAccount with the Deployment. Include PodSecurityContext to enforce non-root execution and restrict capabilities.","explanation":"## Why This Is Asked\n\nThis question evaluates practical understanding of Kubernetes security primitives including RBAC, ServiceAccount isolation, PodSecurityContext, and admission controls—essential skills for securing containerized workloads.\n\n## Key Concepts\n\n- **Namespace-scoped RBAC**: Role and RoleBinding for resource access control within specific namespaces\n- **ServiceAccount isolation**: Dedicated service accounts to separate pod identities and permissions\n- **PodSecurityContext**: Security constraints including runAsNonRoot, runAsUser, readOnlyRootFilesystem, and capability dropping\n- **Admission controls**: PodSecurity standards and OPA Gatekeeper for policy enforcement at admission time\n\n## Code Example\n\n```yaml\n# ServiceAccount (dev)\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: data-processor-sa\n  namespace: dev\n---\n# Role for read-only access to ConfigMaps and Secrets\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: data-processor-role\n  namespace: dev\nrules:\n- apiGroups: [\"\"]\n  resources: [\"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\"]\n---\n# RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: data-processor-binding\n  namespace: dev\nsubjects:\n- kind: ServiceAccount\n  name: data-processor-sa\n  namespace: dev\nroleRef:\n  kind: Role\n  name: data-processor-role\n  apiGroup: rbac.authorization.k8s.io\n```\n\n## Follow-up Questions\n\n- How would you test the RBAC permissions locally?\n- What changes are needed for the prod namespace?\n- How would you implement network policies alongside these security controls?","diagram":null,"difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Databricks","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:14:12.430Z","createdAt":"2026-01-14T23:42:07.566Z"},{"id":"q-2128","question":"In a high-sensitivity environment spanning on-prem and cloud, design a tamper-evident Kubernetes audit logging and incident-response pipeline that preserves evidence from the API server, etcd, and kubelets while enabling automated triage and containment during a breach. Specify data formats, forwarding targets, non-repudiation measures, and failure modes?","answer":"Implement a multi-layered, tamper‑evident pipeline: enable API server and etcd audit logs, forward securely to an immutable object store (S3 with bucket-level and object immutability) and a SIEM via s","explanation":"## Why This Is Asked\n\nThis question probes practical design for tamper-resistant security data collection across heterogeneous Kubernetes estates, addressing post-breach forensics, automation, and resilience.\n\n## Key Concepts\n\n- Tamper-evident logs, audit policy, etcd encryption\n- Immutable storage, HMAC signing, key rotation\n- Secure log forwarding (webhooks, TLS)\n- Runtime security (Falco) and IR playbooks\n- Non-repudiation, data retention, failure modes\n\n## Code Example\n\n```javascript\nfunction signEvent(event, key) {\n  const crypto = require('crypto');\n  const h = crypto.createHmac('sha256', key);\n  h.update(event);\n  return h.digest('hex');\n}\n```\n\n## Follow-up Questions\n\n- How would you test integrity guarantees across region failures?\n- What are failure modes if the webhook sink is compromised?","diagram":"flowchart TD\n  A(API Server Audit) --> B(Immutable Store)\n  A --> C(SIEM Webhook)\n  D(Etcd Audit) --> B\n  E(Kubelet Audit) --> C\n  F(Falco) --> G(IR Playbook)\n  H(Integrity Verifier) --> B","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:11:32.481Z","createdAt":"2026-01-15T04:11:32.482Z"},{"id":"q-2188","question":"In a monorepo-managed Kubernetes fleet with per-service Helm charts and shared base images, design an attestation model where base image attestations are linked to derived service images via SBOM, and enforcement ensures every deployed chart references an attested base. Describe signing commands, SBOM workflow, attestation storage, and a gating policy (OPA/Kyverno) with CI/CD integration?","answer":"Sign both base and service images with cosign, generate SBOMs with Syft, and publish attestations to Rekor; link derived attestation to base by embedding the base digest in the predicate. Commands: co","explanation":"## Why This Is Asked\nTests ability to design provenance enforcement across multiple artifacts and enforce it in a GitOps workflow.\n\n## Key Concepts\n- Attestation chaining and SBOM provenance\n- Rekor as a verifiable registry of attestations\n- Policy enforcement with Kyverno/OPA in deployment pipelines\n\n## Code Example\n```bash\ncosign sign --key cosign.key base.img:tag\n```\n\n```bash\nsyft base.img -o json:base.json\n```\n\n```bash\ncosign attest --artifact service.img:tag --predicate base.json\n```\n\n## Follow-up Questions\n- How would you scale attestations across 100+ services?\n- How to handle base image updates without breaking attestations?","diagram":"flowchart TD\n  A[Base image] --> B[cosign sign base]\n  B --> C[Attest base to Rekor]\n  D[Service image] --> E[cosign sign service]\n  E --> F[Attest service to Rekor]\n  C & F --> G[Enforcement gate (Kyverno/OPA)]\n  G --> H[Argo CD deploy]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:56:20.700Z","createdAt":"2026-01-15T06:56:20.700Z"},{"id":"q-2418","question":"A data ingestion pipeline uses a private artifact registry hosting Spark JARs and Python wheels. Each artifact is cosign-signed with a SBOM attestation; runtime must guarantee that only attested artifacts execute in Spark jobs managed by Airflow on Kubernetes. Describe an end-to-end plan to sign, publish attestations, and enforce runtime checks across the data plane, including concrete cosign commands, attestation storage approach, and a sample Kyverno/OPA policy plus integration steps with Airflow and the registry?","answer":"Sign artifacts with cosign and attach SBOM attestations; publish to a private registry; enforce at runtime via a Kyverno/OPA policy that blocks SparkSubmit when the artifact digest lacks a valid attes","explanation":"## Why This Is Asked\nTests hands-on signing, attestation generation, and runtime enforcement across data-plane components (Airflow, Spark, Kubernetes). It probes operational trade-offs like key rotation and attestation storage.\n\n## Key Concepts\n- cosign attestations and SBOMs\n- private artifact registries\n- runtime policy (Kyverno/OPA)\n- data-plane integration (Airflow, SparkSubmit)\n\n## Code Example\n\n```javascript\n// Example sequence:\ncosign generate-key-pair\ncosign sign --key cosign.key registry.example.org/pipeline/transforms.jar:sha256:<digest>\ncosign attest --predicate sbom.json --key cosign.key registry.example.org/pipeline/transforms.jar:sha256:<digest>\n```\n\n## Follow-up Questions\n- How would you rotate keys without breaking existing attestations?\n- How would you test the end-to-end policy in CI/CD?\n","diagram":"flowchart TD\n  A[Artifact] --> B[cosign Sign]\n  B --> C[cosign Attest]\n  C --> D[Publish Attestation to Registry]\n  D --> E[Enforcement (Kyverno/OPA)]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T17:41:09.088Z","createdAt":"2026-01-15T17:41:09.090Z"},{"id":"q-2508","question":"In a Knative-based FaaS layer on Kubernetes, functions are built as OCI images stored in a private registry and loaded by the function runtime at cold start. Design an end-to-end plan to sign and attest function images, publish attestations to Rekor, and enforce at runtime that only attested functions execute in the Knative namespace. Include concrete cosign commands, attestation storage approach, and a sample Kyverno or OPA policy plus integration steps with the registry and the function loader?","answer":"Plan: generate cosign keys, sign the image, create an SBOM, attest, and enforce at admission. Example commands: cosign generate-key-pair cosign.key cosign.pub; cosign sign --key cosign.key registry.ex","explanation":"## Why This Is Asked\nTests end-to-end attestation workflows: signing, SBOM generation, log storage, and runtime enforcement.\n\n## Key Concepts\n- OCI image signing and attestation with cosign\n- SBOM generation with syft\n- Rekor as transparency log\n- Policy-based enforcement (OPA/Kyverno)\n\n## Code Example\n```rego\npackage kubernetes.admission\ndeny[msg] {\n  input.request.kind.kind == \"Deployment\"\n  digest := input.request.object.spec.template.spec.containers[0].image\n  not data.attestations[digest]\n  msg := sprintf(\"Image %s not attested\", [digest])\n}\n```\n\n## Follow-up Questions\n- How would you scale attestation checks across hundreds of images?\n- What are failure modes if Rekor is unavailable?","diagram":"flowchart TD\nA[Build image] --> B[Push to registry]\nB --> C[Sign with cosign]\nC --> D[Create SBOM with syft]\nD --> E[Attest for SBOM]\nE --> F[ Rekor logs ]\nF --> G[Enforce at runtime via policy]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","LinkedIn","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T20:51:45.426Z","createdAt":"2026-01-15T20:51:45.426Z"},{"id":"q-2537","question":"In a policy-driven edge compute fleet, WASM modules are built per customer and pushed to a private OCI registry. You must ensure only attested modules run on edge devices. Design a concrete plan to sign modules with cosign, publish SLSA attestations, and enforce at runtime that only attested modules are loaded via an admission controller (Kyverno/OPA). Include concrete commands and sample policies?","answer":"Sign each WASM module with cosign, generate an SBOM with Syft, publish an attestation to the registry, and enforce at edge runtimes that only attested modules load via Kyverno/OPA. Commands: cosign sign --key cosign.key ghcr.io/org/module@tag && cosign attest --predicate attest.json --signature sig.cosign ghcr.io/org/module@tag","explanation":"## Why This Is Asked\nTests practical enforcement of attestation for edge modules, including SBOM integration and automation.\n\n## Key Concepts\n- Cosign signing and attestations\n- SBOMs for wasm modules\n- Runtime admission controls (Kyverno/OPA)\n- GitHub Actions automation\n\n## Code Example\n\n```bash\ncosign sign --key cosign.key ghcr.io/org/module@tag\ncosign attest --predicate attest.json --signature sig.cosign ghcr.io/org/module@tag\n```\n\n```yaml\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: require-attested-wasm\nspec:\n  rules:\n  - name: attestation-check\n    match:\n      resources:\n        kinds:\n        - Pod\n        selector:\n          matchLabels:\n            app: wasm-edge\n    validate:\n      pattern:\n        spec:\n          containers:\n          - image: \"ghcr.io/org/*\"\n            securityContext:\n              capabilities:\n                add: [\"SYS_ADMIN\"]\n  - name: verify-attestation\n    match:\n      resources:\n        kinds:\n        - Pod\n    validate:\n      anyPattern:\n      - pattern:\n          metadata:\n            annotations:\n              cosign.sigstore.dev/attestations: \"?*\"\n```","diagram":"flowchart TD\n  A[WASM Module] --> B{Signed?}\n  B -->|Yes| C[Attested in Registry]\n  B -->|No| D[Rejected]\n  C --> E[Edge Runtime]\n  E --> F[Policy Enforced]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T04:25:33.253Z","createdAt":"2026-01-15T21:44:20.454Z"},{"id":"q-2639","question":"In an AWS EKS cluster with Istio, an attacker attempts DNS tunneling to exfiltrate data from the dev namespace. Design a practical detection pipeline using: (a) eBPF-based DNS egress monitoring, (b) CoreDNS query analytics, (c) Istio telemetry + network policies, and (d) alerting aligned to MITRE techniques. Explain data flow, signals to watch, and how you would validate alerts?","answer":"Flag DNS tunneling by watching: (i) high-entropy, long random subdomains; (ii) spikes in external DNS queries from dev namespace; (iii) frequent TXT/NULL queries. Collect via eBPF, enrich with pod/nam","explanation":"## Why This Is Asked\nTests ability to design a practical detection pipeline for cloud-native DNS tunneling, combining kernel telemetry, DNS-layer analytics, and service-mesh visibility; emphasizes real-world validation and false-positive control.\n\n## Key Concepts\n- eBPF DNS egress monitoring\n- CoreDNS analytics and entropy-based signals\n- Istio telemetry integration and namespace scoping\n- Multi-signal alerting and validation\n- Synthetic traffic to verify detections\n\n## Code Example\n```javascript\nfunction entropy(s){\n  const counts = {};\n  for(const ch of s) counts[ch]=(counts[ch]||0)+1;\n  const total = s.length;\n  let e=0; for(const c of Object.values(counts)){ const p=c/total; e -= p*Math.log2(p); }\n  return e;\n}\nfunction isSuspicious(domain){\n  const parts = domain.split('.');\n  const labels = parts.slice(0,-1);\n  const ent = labels.map(l=>entropy(l)).reduce((a,b)=>a+b,0);\n  const len = domain.length;\n  return ent>3.5 || len>30;\n}\n```\n\n## Follow-up Questions\n- How would you tune thresholds to reduce false positives across tenants?\n- What data retention and RBAC would you implement for CoreDNS and eBPF telemetry?","diagram":null,"difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T04:20:05.084Z","createdAt":"2026-01-16T04:20:05.084Z"},{"id":"q-2687","question":"Scenario: A Kafka Connect cluster loads dozens of custom connectors from a shared registry. Describe a concrete plan to sign each connector JAR and its JSON configs with cosign, publish attestations to Rekor, and enforce at deployment and runtime that only attested connectors are loaded. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy and integration steps with Kafka Connect?","answer":"Generate a cosign key pair, sign each connector JAR and its JSON configs, and publish an attestation to Rekor. Store attestations in a central registry and reference them from the Connector manifest. ","explanation":"## Why This Is Asked\n\nTests practical end-to-end security for data integration pipelines, including artifact signing, attestation storage, and runtime enforcement with policy engines.\n\n## Key Concepts\n\n- Artifact signing with cosign and key management\n- Attestations stored in Rekor registry\n- Policy-driven runtime enforcement (Kyverno/OPA)\n- Integration points with Kafka Connect\n\n## Code Example\n\n```javascript\n// Minimal illustration: pseudo-check attestation reference in manifest\nasync function isAttested(manifest) {\n  const ref = manifest.attestationRef;\n  // fetch and verify against Rekor/public cosign key\n  return !!ref;\n}\n```\n\n## Follow-up Questions\n\n- How would you handle rotation of signing keys and revocation?\n- What metrics and alerts would you add to detect failed attestations at startup?","diagram":"flowchart TD\n  A[Connector Registry] --> B[Signing Service]\n  B --> C[ Rekor Registry ]\n  C --> D[Kafka Connect Deployment]\n  D --> E[Policy Engine (Kyverno/OPA)]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Instacart","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T06:58:58.892Z","createdAt":"2026-01-16T06:58:58.893Z"},{"id":"q-2747","question":"Scenario: An edge compute platform runs user-provided WASM modules on 100 edge nodes. A compromised module could exfiltrate data or break isolation. Describe a concrete plan to sign each WASM module and its metadata with cosign in CI, publish attestations to Rekor, and enforce at deployment and runtime that only attested WASMs are loaded, including exact signing commands, attestation layout, and a sample Kyverno/OPA policy plus integration steps with the edge runtime?","answer":"Describe a concrete pipeline to secure edge WASM modules: sign modules with cosign in CI, publish Rekor attestations, and run a per-node verifier that only loads attested artifacts. Include exact sign","explanation":"## Why This Is Asked\nTests practical, implementable security controls for edge WASM deployment: signing, attestations, and runtime enforcement, plus policy-as-code integration.\n\n## Key Concepts\n- WASM module attestation and integrity\n- Cosign signing in CI and Rekor attestations\n- Edge runtimes and module-verification\n- Policy enforcement with Kyverno/OPA\n- Attestation lifecycle: rotation and revocation\n\n## Code Example\n```javascript\n// Signing commands (illustrative)\ncosign generate-key-pair\ncosign sign --key cosign.key wasm-module.wasm\ncosign attest --key cosign.key --artifact wasm-module.wasm --predicate '{\"build\":\"ci\"}'\n```\n\n## Follow-up Questions\n- How would you test end-to-end attestation validation across 100 edge nodes?\n- How would you handle key rotation and revocation without affecting in-flight modules?","diagram":"flowchart TD\n  A[WASM Module Published] --> B[Cosign Sign] \n  B --> C[Rekor Attestation] \n  C --> D[Edge Verifier Checks] \n  D --> E[Module Loaded on Edge Node]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Slack","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T10:36:21.058Z","createdAt":"2026-01-16T10:36:21.059Z"},{"id":"q-2837","question":"In a multi-tenant Kubernetes cluster used by several large services, you must build a scalable, privacy-conscious audit-logging and anomaly-detection pipeline that ingests API server audit events from multiple masters, normalizes per-tenant identity, and emits near-real-time alerts for suspicious access patterns (e.g., sudden spikes in secret fetches, impersonation). Outline the design, components, and trade-offs?","answer":"Design uses API server audit policy with tiered sampling, redact PII, route events to a centralized ledger via a mutating webhook and Kafka, normalize by tenant using the user/impersonation fields, st","explanation":"## Why This Is Asked\nAssesses ability to design scalable, privacy-aware audit pipelines for multi-tenant clusters, balancing compliance with operational overhead.\n\n## Key Concepts\n- Kubernetes Audit Logs\n- Webhook backends & mutating webhooks\n- Per-tenant identity normalization\n- Privacy redaction & data retention\n- Real-time anomaly detection & alerting\n\n## Code Example\n```javascript\n// Pseudo-processor: route audit events to tenant-scoped store\nfunction routeEvent(evt){\n  const tenant = evt.user.tenant;\n  store.append(tenant, evt);\n  if (detectAnomaly(evt, tenant)) alert(tenant, evt);\n}\n```\n\n## Follow-up Questions\n- How would you test for false positives at scale?\n- Which storage/processing stack would you choose for 1k+ tenants and why?","diagram":"flowchart TD\n  API[API Server] --> Policy[Audit Policy]\n  Policy --> Webhook[Webhook Backend]\n  Webhook --> Store[Audit Store]\n  Store --> Detector[Anomaly Detector]\n  Detector --> Alert[Alerts]","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T14:12:38.997Z","createdAt":"2026-01-16T14:12:38.997Z"},{"id":"q-2843","question":"Scenario: A data platform ingests dozens of datasets into a lakehouse from multiple teams. Design a concrete plan to sign each dataset file with cosign, publish attestations to Rekor, and enforce at read-time that only attested datasets are processed by downstream Airflow pipelines and Looker dashboards. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy integration with Airflow?","answer":"Sign each dataset.parquet with cosign, publish attestations to Rekor, and enforce at read-time that only attested datasets flow to Airflow and Looker. Steps: (1) generate per-org cosign keys; (2) sign","explanation":"## Why This Is Asked\nTests data provenance, policy enforcement, and integration with real tools.\n\n## Key Concepts\n- Data provenance and attestations\n- Cosign and Rekor for file-level artifacts\n- OPA/Kyverno policies for data reads\n- Airflow integration points and looker read-time checks\n\n## Code Example\n```rego\npackage data.provenance\n\ndefault allow = false\n\nallow {\n  input.kind == \"dataset_read\"\n  attest := data.attestations[input.path]\n  attest.digest == input.digest\n  attest.exists\n}\n```\n\n## Follow-up Questions\n- How would you scale attestation storage for thousands of datasets?\n- How would you handle revoked attestations in Rekor?\n","diagram":"flowchart TD\n  A[Data Ingest] --> B[Compute Digest]\n  B --> C[Sign with cosign & attestation]\n  C --> D[Publish to Rekor]\n  D --> E[Catalog reference]\n  E --> F[OPA/Kyverno policy]\n  F --> G[Airflow DAGs / Looker reads]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Citadel","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T14:36:56.036Z","createdAt":"2026-01-16T14:36:56.036Z"},{"id":"q-2911","question":"In a private Python package index used by Apple and MongoDB, design a beginner CI workflow to generate CycloneDX SBOMs for wheels, cosign-sign artifacts, publish attestations to Rekor, and enforce that only attested wheels can be uploaded. Include concrete cosign commands, attestation storage layout, and a sample Kyverno/OPA policy?","answer":"Design a CI gate: for each wheel built, generate an SBOM (CycloneDX), sign the wheel with cosign, attach the SBOM as an attestation, and publish to Rekor. Gate uploads by running cosign verify and Rek","explanation":"## Why This Is Asked\nTests practical skills in securing third‑party artifacts in a private Python index, using SBOMs, cosign attestations, and policy gates.\n\n## Key Concepts\n- CycloneDX SBOM generation\n- Cosign signing and attestations\n- Rekor attestation store\n- CI gates and policy enforcement (Kyverno/OPA)\n\n## Code Example\n```bash\n# Build wheel\npython -m build --wheel\n\n# SBOM\ncyclonedx-bom -o dist/name-0.1-py3-none-any.bom.json\n\n# Sign\ncosign sign --key cosign.key dist/name-0.1-py3-none-any.whl\n\n# Attest SBOM\ncosign attest --key cosign.key --attestation dist/name-0.1-py3-none-any.bom.json dist/name-0.1-py3-none-any.whl\n\n# Verification gate\ncosign verify --key cosign.pub dist/name-0.1-py3-none-any.whl --rekor-url https://rekor.example.com\n```\n\n## Follow-up Questions\n- How would you handle key rotation and revocation for cosign keys?\n- How would you simulate a failed attestation in the CI pipeline and prevent uploads?","diagram":null,"difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T17:31:09.683Z","createdAt":"2026-01-16T17:31:09.685Z"},{"id":"q-3034","question":"In a Kubernetes-based edge compute platform, workers pull WebAssembly plugins from a registry to extend behavior. Describe a concrete plan to sign WASM plugins with cosign, publish attestations to Rekor, and enforce at runtime that only attested WASM plugins are loaded by the plugin loader. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy plus integration steps with the plugin loader?","answer":"Sign each WASM plugin with cosign using a private key, push the signed artifact to the registry, and publish a Rekor attestation. Commands: cosign sign --key cosign.key wasm-plugin.wasm; cosign attach sbom --sbom sbom.json wasm-plugin.wasm; cosign attest --predicate https://rekor.example/api/v1/log/entries --key cosign.key wasm-plugin.wasm","explanation":"## Why This Is Asked\n\nTests ability to apply attestation to WASM plugins in edge/k8s environments, a realistic gap beyond container images.\n\n## Key Concepts\n\n- WASM module signing with cosign\n- Rekor attestations for wasm artifacts\n- Runtime verification in a restricted loader\n- Policy enforcement with Kyverno/OPA\n- Edge CI/CD integration with registry labels\n\n## Code Example\n\n```javascript\n// Pseudo loader verification\nasync function verifyAndLoad(wasmName) {\n  const att = await fetch(`https://rekor.example/attestations/${wasmName}`);\n  if (!att?.valid) throw new Error('Attestation missing or invalid');\n  // Load WASM module\n  return await WebAssembly.instantiateStreaming(fetch(wasmName));\n}\n```","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Microsoft","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:41:54.553Z","createdAt":"2026-01-16T21:49:09.596Z"},{"id":"q-3076","question":"In a Kubernetes cluster with Kyverno installed, draft a beginner policy to ensure all pods in namespace secure cannot run as root, require runAsNonRoot true and runAsUser 1000, enforce readOnlyRootFilesystem, disallow privileged containers and added capabilities, require imagePullPolicy Always, and images from registry example.com/secure/*. Provide the Kyverno policy YAML, an example compliant Pod spec and a noncompliant one, and the validation steps?","answer":"I would implement a Kyverno policy named secure-pods in namespace secure that enforces: runAsNonRoot true, runAsUser 1000, readOnlyRootFilesystem true, no privileged, and drop ALL capabilities. Also r","explanation":"## Why This Is Asked\n\nTests understanding of policy as code, basic Kubernetes security posture, and simple automation.\n\n## Key Concepts\n\n- Kyverno policy definitions\n- Pod securityContext fields\n- Image provenance enforcement\n\n## Code Example\n\n```yaml\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: secure-pods\nspec:\n  validationFailureAction: enforce\n  rules:\n  - name: ensure-secure-context\n    match:\n      resources:\n        kinds: [Pod]\n        namespaces: [secure]\n    validate:\n      message: SecurityContext must be non-root, readOnlyRootFilesystem, no privileged, drop ALL\n      pattern:\n        spec:\n          containers:\n          - name: \"*\"\n            securityContext:\n              runAsNonRoot: true\n              runAsUser: 1000\n              allowPrivilegeEscalation: false\n              readOnlyRootFilesystem: true\n              capabilities:\n                drop:\n                - ALL\n  - name: image-policy\n    match:\n      resources:\n        kinds: [Pod]\n        namespaces: [secure]\n    validate:\n      message: Image must come from allowed registry\n      pattern:\n        spec:\n          containers:\n          - image: example.com/secure/*\n  - name: image-pull-policy\n    match:\n      resources:\n        kinds: [Pod]\n        namespaces: [secure]\n    validate:\n      message: imagePullPolicy must be Always\n      pattern:\n        spec:\n          containers:\n          - imagePullPolicy: Always\n```\n\n## Follow-up Questions\n\n- How would you test policy enforcement with a compliant Pod? a noncompliant Pod?\n- How would you extend to cover initContainers or multiple namespaces?","diagram":null,"difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T23:45:30.368Z","createdAt":"2026-01-16T23:45:30.369Z"},{"id":"q-3103","question":"You operate a multi-tenant data science platform on Kubernetes used by multiple teams across Uber and Robinhood; design a concrete, automated control plane to enforce per-tenant data access, runtime isolation, and secrets management. Include: (1) a policy framework using Open Policy Agent (OPA) or Kyverno, (2) secret rotation and access controls with Kubernetes Secrets and CSI Secrets Store, (3) namespace network egress controls and audit logging to Rekor, (4) a test plan with compliant vs noncompliant examples, and (5) an integration with CI to attest policy conformance. How would you implement this end-to-end?","answer":"Design a comprehensive, automated control plane for multi-tenant Kubernetes environments: implement policy-as-code using OPA for complex authorization decisions or Kyverno for simpler Kubernetes-native policies, integrate Secrets Store CSI Driver with external secret providers (AWS Secrets Manager, Azure Key Vault, or HashiCorp Vault) for automatic credential rotation, enforce namespace-level NetworkPolicies with egress controls to restrict tenant traffic, implement comprehensive audit logging to Rekor for policy compliance tracking, and establish CI/CD integration with policy conformance testing using tools like Conftest or Kyverno CLI to ensure all deployments meet security requirements before production.","explanation":"## Why This Is Asked\n\nTests ability to design scalable, automated security controls in multi-tenant Kubernetes environments, focusing on policy-language choice, secret management, network isolation, and attestation.\n\n## Key Concepts\n\n- Policy-as-code (OPA vs Kyverno) for tenant isolation\n- Secrets management with CSI Secrets Store and automatic rotation\n- Namespace-level NetworkPolicy and egress controls\n- Audit/attestation with Rekor/Sigstore\n- CI integration for policy conformance and artifact attestation\n\n## Code Example\n\n```yaml\n# Example Kyverno policy snippet (placeholder)\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: tenant-isolation\nspec:\n  validationFailureAction: Enforce\n  rules:\n  - name: require-namespace-labels\n    match:\n      any:\n      - resources:\n          kinds: [Pod]\n    validate:\n      message: \"Pods must have tenant labels for isolation\"\n      pattern:\n        metadata:\n          labels:\n            tenant: \"?*\"\n```\n\n## Implementation Approach\n\n1. **Policy Framework**: Choose OPA Gatekeeper for complex cross-namespace policies or Kyverno for simpler, Kubernetes-native validation\n2. **Secrets Management**: Deploy CSI Secrets Store with provider-specific drivers and configure automatic rotation policies\n3. **Network Controls**: Implement namespace-scoped NetworkPolicies with egress deny-by-default and specific allow rules\n4. **Audit Logging**: Configure policy decision logging to Rekor with signed transparency logs\n5. **CI Integration**: Add policy testing stages using Conftest/Kyverno CLI and integrate with Sigstore for artifact signing","diagram":"flowchart TD\n  A[User tenant] --> B[Namespace per tenant]\n  B --> C[Policy gatekeeper (OPA/Kyverno)]\n  B --> D[Secrets Store CSI integration]\n  C --> E[Audit to Rekor]\n  D --> F[Network egress controls]\n  E --> G[Attestation workflow in CI]","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T03:45:54.686Z","createdAt":"2026-01-17T02:21:59.015Z"},{"id":"q-3222","question":"Scenario: A Kubernetes-based plugin host loads third‑party data processors at runtime. Design a concrete plan to cosign sign each plugin binary and its manifest, publish attestations to Rekor, and enforce at load time that only attested plugins are admitted by a loader gatekeeper with OPA/Kyverno. Include concrete signing/verification commands, attestation layout, and sample policy?","answer":"Sign each plugin binary and its manifest with cosign using a dedicated key, publish attestations to Rekor, and enforce at load time via a loader gatekeeper using an OPA/Kyverno policy. Commands: cosig","explanation":"## Why This Is Asked\nThis probes practical risk mitigation for runtime extensibility, requiring hands-on knowledge of container image/artifact attestation, and runtime policy enforcement.\n\n## Key Concepts\n- Artifact attestation with cosign and Rekor\n- Runtime policy enforcement (OPA/Kyverno)\n- Attestation layout and versioned mapping to plugins\n\n## Code Example\n```javascript\ncosign sign --key cosign.key plugins/processor.so\ncosign sign --key cosign.key manifests/processor.yaml\n```\n\n## Follow-up Questions\n- How would you handle key rotation and revocation?\n- How would you test and audit the policy across diverse environments?","diagram":"flowchart TD\n  A[Plugin Release] --> B[Sign Binary]\n  A --> C[Sign Manifest]\n  B --> D[ Rekor Entry ]\n  C --> D\n  E[Loader Gatekeeper] --> F[Enforce Attestation]\n  D --> F","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Salesforce","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T07:35:43.547Z","createdAt":"2026-01-17T07:35:43.548Z"},{"id":"q-3298","question":"In a security-focused edge compute platform with 50k devices, function bundles are delivered as WebAssembly modules from a private registry. Propose a concrete plan to sign WASM bundles and their JSON manifests with cosign, publish Rekor attestations, and enforce at load time that only attested bundles are executed. Include exact signing commands, an attestation storage layout, and a sample Kyverno/OPA policy plus integration steps with the edge runtime?","answer":"Sign and attest WASM bundles and their JSON manifests; concrete commands: generate keys; cosign sign --key cosign.key wasm/bundle.wasm; cosign sign --key cosign.key manifests/bundle.json; cosign attes","explanation":"## Why This Is Asked\n\nEdge compute poses unique trust boundaries; standard registry signing isn't enough. This question probes plan for attested code at scale, offline verification, and edge-specific policy enforcement, including integration with Rekor/ Kyverno/ OPA.\n\n## Key Concepts\n\n- WebAssembly module attestation\n- Edge runtime verification\n- Rekor attestations\n- Kyverno/OPA policy integration\n\n## Code Example\n\n```javascript\n// Example pseudo-code for edge loader verification\nfunction verifyEdgeBundle(digest, attestationURL) { /* ... */ }\n```\n\n## Follow-up Questions\n\n- How would you handle revocation of attested modules at scale?\n- What are failure modes if Rekor is temporarily unavailable?","diagram":"flowchart TD\n  A[Edge Registry] --> B[WASM Bundle digest]\n  B --> C[Cosign Sign]\n  C --> D[Rekor Attestations]\n  D --> E[Edge Loader]\n  E --> F[Execute Attested Bundle]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Coinbase","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T10:37:03.147Z","createdAt":"2026-01-17T10:37:03.147Z"},{"id":"q-3423","question":"Scenario: A multi-tenant data platform deploys user-defined data processing plugins as containerized extensions loaded by a central registry. Design a concrete plan to sign each plugin image and its JSON config with cosign, publish attestations to Rekor, and enforce at runtime that only attested plugins are loaded by the plugin host. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy and integration steps with the plugin loader?","answer":"Adopt a plugin attestation flow: cosign-sign each container image and its config, publish attestations to Rekor, and enforce at runtime that only attested plugins load in the host. Commands: cosign si","explanation":"## Why This Is Asked\n\nThis probes end-to-end supply‑chain security for pluggable components, including signing scope, attestation layout, and runtime enforcement in multi-tenant environments.\n\n## Key Concepts\n\n- Cosign signing of images and artifact configs\n- Rekor transparency log attestations\n- Runtime verification inside a plugin loader\n- Kyverno/OPA policies for attestation enforcement\n- Attestation storage and rotation considerations\n\n## Code Example\n\n```javascript\nasync function verifyAttestation(imageDigest) {\n  // query Rekor for attestation of imageDigest and verify signature\n  // return true/false\n}\n```\n\n## Follow-up Questions\n\n- How would you handle key rotation and revocation for cosign keys in this setup?\n- How would you scale attestation verification in a high-churn plugin ecosystem?","diagram":"flowchart TD\n  A[Registry publishes plugin] --> B[Signer cosign image and config]\n  B --> C[Attestations stored in Rekor]\n  C --> D[Plugin loader enforces policy at load]\n  D --> E[Plugin runs in sandbox]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T15:38:09.824Z","createdAt":"2026-01-17T15:38:09.824Z"},{"id":"q-3474","question":"In a data lake, design a practical plan to sign each ingested dataset with cosign, publish Rekor attestations, and enforce at read time that only attested data is processed by Spark/Presto, including integration with a data catalog and an OPA policy. Include concrete commands and an artifact layout?","answer":"Ingest pipeline signs every dataset blob (Parquet/CSV) with cosign, publishes the attestation to Rekor, and records digest + attestation_id in the data catalog. Read-time enforcement via OPA rules tie","explanation":"## Why This Is Asked\nThis tests end-to-end data provenance, integrity, and policy enforcement in a real data platform.\n\n## Key Concepts\n- Cosign attestations\n- Rekor storage\n- Data catalog integration\n- OPA policy for read-time enforcement\n\n## Code Example\n```bash\n# sign the dataset\ncosign sign -key cosign.key datasets/ingest-202601.parquet\n# verify\ncosign verify datasets/ingest-202601.parquet\n```\n\n## Follow-up Questions\n- How to model attestation metadata in the data catalog and support revocation?\n- What latency and scale considerations arise when enforcing attestations in large Spark workloads?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T17:41:08.077Z","createdAt":"2026-01-17T17:41:08.077Z"},{"id":"q-3561","question":"Design a lightweight runtime security check in Kubernetes using Falco to alert on containers running as root or spawning a shell; provide two concrete Falco rules (compliant vs noncompliant), a minimal test Pod manifest to trigger the alert, and a verification plan to confirm alerts route to the chosen sink?","answer":"Install Falco on the cluster and write two rules: (1) detect containers where user_id == 0 or runAsUser == 0; (2) detect shell spawning (exe contains /bin/sh or /bin/bash). Provide a tiny compliant Pod manifest that avoids these conditions, then a noncompliant manifest that triggers them, and verify alerts reach your chosen sink (e.g., Falco logs, webhook, or SIEM).","explanation":"## Why This Is Asked\nRuntime security is essential for Kubernetes. This beginner-friendly task tests practical rule-writing, basic detection, and end-to-end validation.\n\n## Key Concepts\n- Falco rule syntax and output formatting\n- Kubernetes security contexts (runAsUser, user)\n- Pod testing and alert sinks (log/monitoring)\n- False positives handling\n\n## Code Example\n```yaml\n# Example Falco rule\n- rule: Detect Root User\n  desc: Container runs as root\n  condition: evt.user.id == 0\n  output: 'root user in container (container=%container.name image=%container.image.repository)'\n  priority: WARNING\n```","diagram":"flowchart TD\n  A[Define threat] --> B[Write Falco rule] \n  B --> C[Deploy Falco] \n  C --> D[Test Pod] \n  D --> E[Validate alerts]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","MongoDB","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:45:30.961Z","createdAt":"2026-01-17T21:31:11.376Z"},{"id":"q-3674","question":"Scenario: An edge platform runs WebAssembly (WASM) modules pushed from a central registry to thousands of devices. Devs want to ensure only attested modules load. Describe a concrete plan to cosign-sign each WASM module and its metadata, publish attestations to Rekor, and enforce at the loader level that only attested modules execute. Include concrete signing commands, attestation storage layout, and a sample policy (Kyverno/OPA) plus edge-loader integration steps?","answer":"Sign each WASM module and its metadata with cosign (e.g., cosign sign --key cosign.key wasm/module.wasm; cosign sign --key cosign.key wasm/module.json). Generate an attestation with cosign attest and ","explanation":"## Why This Is Asked\nEdge workloads require strong provenance for code that executes locally. This question probes real‑world practice for signing WASM modules, linking attestations to artifacts in Rekor, and enforcing runtime loading only of attested modules.\n\n## Key Concepts\n- WASM/module signing with cosign\n- Rekor attestations and artifact provenance\n- Edge loader enforcement and verification\n- Policy as code (Kyverno/OPA) for runtime guarantees\n- Attestation storage and mapping to artifacts\n\n## Code Example\n```javascript\n// signing and attestation commands\ncosign sign --key cosign.key wasm/module.wasm\ncosign attest --key cosign.key --artifact wasm/module.wasm --predicate '{\"op\":\"load\",\"name\":\"module.wasm\"}' --type cosign/attestation wasm/module.wasm\n```\n\n## Follow-up Questions\n- How would you rotate signing keys and invalidate old attestations without downtime?\n- How would you handle attestation lookups on devices with intermittent connectivity?","diagram":"flowchart TD\n  A[Edge Device] --> B[Loader]\n  B --> C{Attested?}\n  C -- Yes --> D[Load Module]\n  C -- No --> E[Abort]\n","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","DoorDash","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T04:22:38.493Z","createdAt":"2026-01-18T04:22:38.494Z"},{"id":"q-3768","question":"Advanced interview: In a production ML platform used by Tesla, Databricks, and PayPal, ensure every ML model artifact (weights, config) and its data dependencies are signed, attested, and verifiable before deployment to inference endpoints. Design a policy-driven end-to-end pipeline: 1) signing workflow with Cosign, 2) attestation storage with Rekor, 3) pre-deployment checks enforcing Rekor attestations and an SBOM, and 4) a test plan that detects tampering and blocks deployment. Include concrete Cosign commands and a sample Rekor layout?","answer":"Sign all artifacts with Cosign, publish Rekor attestations, and enforce a deployment gate that requires a Rekor attestation plus an SBOM before inference endpoints are updated. Provide concrete Cosign","explanation":"## Why This Is Asked\nTests ability to design end-to-end software supply chain security for ML deployments, including signing, attestation, and gatekeeping at deployment time across multi-cloud teams.\n\n## Key Concepts\n- ML artifact signing with Cosign\n- Rekor attestations and verification\n- SBOMs for ML assets and pipelines\n- Deployment gates via policy engines (OPA-like) and CI integration\n- Tamper testing and revocation handling\n\n## Code Example\n```bash\n# Generate signing keys (one-time)\ncosign generate-key-pair\n\n# Sign artifacts\ncosign sign -key cosign.key models/weights.pt\ncosign sign -key cosign.key data/config.json\n\n# Create attestations\ncosign attest -key cosign.key -predicate attestation.json models/weights.pt\n\n# Verify artifacts\ncosign verify weights.pt\ncosign verify data/config.json\n```\n\n## Follow-up Questions\n- How would you revoke a compromised artifact in Rekor?\n- How would you scale this across multiple regions and compute environments?","diagram":"flowchart TD\n  Artifacts[Artifacts] --> Sign[Sign artifacts with Cosign]\n  Sign --> Rekor[Store Rekor attestations]\n  Rekor --> Gate[Pre-deploy gate checks]\n  Gate --> Deploy[Deploy to inference endpoints]","difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T08:47:54.422Z","createdAt":"2026-01-18T08:47:54.422Z"},{"id":"q-3949","question":"In a multi-tenant SaaS, Terraform modules are published to a private registry. Propose a practical plan to cosign-sign each module package and its accompanying values.json, publish attestations to Rekor, and enforce at plan/apply that only attested modules are used. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy plus Terraform integration steps?","answer":"CI should tarball the module and values.json, cosign sign both with a dedicated key, and cosign attest the module for Rekor. Example: tar czf mod.tar.gz module values.json; cosign sign mod.tar.gz --ke","explanation":"## Why This Is Asked\nTests ability to implement end-to-end attestation for IaC artifacts, covering signing, attestation storage, and runtime policy checks in a multi-tenant setting.\n\n## Key Concepts\n- Cosign attestations and Rekor integration\n- Artifact scope: module package + values.json\n- Attestation storage layout in the registry\n- Policy enforcement with Kyverno/OPA\n- CI/CD integration and pre-Plan validation\n\n## Code Example\n```bash\n# signing steps\ntar czf mod.tar.gz module values.json\ncosign sign mod.tar.gz --key cosign.key\ncosign sign values.json --key cosign.key\ncosign attest mod.tar.gz --key cosign.key\n```\n\n## Follow-up Questions\n- How would you rotate keys and manage revocation?\n- How to test policies across environments with drift detection?","diagram":"flowchart TD\n  A[Terraform Module] --> B[CI: Package & Sign]\n  B --> C[Attest & Push to Rekor]\n  C --> D[Policy Engine (Kyverno/OPA) Validate]\n  D --> E[Terraform Plan/Apply]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T16:45:44.882Z","createdAt":"2026-01-18T16:45:44.882Z"},{"id":"q-3961","question":"Scenario: An extensible web server loads dynamic plugins (shared objects) from a private registry at runtime. Design a concrete plan to sign each plugin artifact and its manifest with cosign, publish attestations to Rekor, and enforce at runtime that only attested plugins are loaded. Include concrete signing commands, attestation storage layout, and a sample Kyverno/OPA policy and integration steps with the plugin loader?","answer":"Build a signed attestation workflow: sign the plugin binary with cosign, create a predicate.json describing name/version, run cosign attest to publish to Rekor, and store attestations under /attestati","explanation":"## Why This Is Asked\nDemonstrates end-to-end understanding of signing, attestation, and runtime enforcement for dynamic plugins.\n\n## Key Concepts\n- Artifact signing and attestations\n- Rekor/Cosign integration\n- Runtime policy enforcement (Kyverno/OPA)\n- Loader integration and attestation verification\n\n## Code Example\n```javascript\n// Pseudo plugin loader check\nif (!attestedDigest(digest)) throw new Error('Unattested plugin');\nloadPlugin(digest);\n```\n\n## Follow-up Questions\n- How to scale attestation lookups?\n- How to handle key rotation and revocation?","diagram":"flowchart TD\n  A[Plugin Loader] --> B[Resolve Digest]\n  B --> C[Query Rekor for Attestation]\n  C --> D{Attested?}\n  D -->|Yes| E[Load Plugin]\n  D -->|No| F[Reject Load]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T17:31:51.009Z","createdAt":"2026-01-18T17:31:51.009Z"},{"id":"q-4062","question":"Scenario: A data platform spanning Snowflake and IBM workloads runs Spark jobs in Kubernetes and must enforce that only pods with SPIRE-backed identities can call the Kubernetes API. Design a runtime access-control solution using OPA Gatekeeper with RBAC, SPIRE, and a mutating webhook to inject auditing sidecars. Provide a concrete constraint template, an example compliant Pod, a noncompliant Pod, and a validation plan?","answer":"Use SPIRE to assign pod identities and bind them to a restricted RBAC role, enforced by an OPA Gatekeeper constraint template that denies API access unless the identity matches an allowlist. Add a mut","explanation":"## Why This Is Asked\nTests understanding of identity-based runtime access control in Kubernetes, integrating SPIRE, OPA Gatekeeper, and admission/mutating webhooks for auditing. It also evaluates plan for cross-cloud (Snowflake/IBM) data workloads and secure Spark job execution.\n\n## Key Concepts\n- SPIRE workload identity and attestation\n- OPA Gatekeeper constraint templates and validation hooks\n- Kubernetes RBAC and API access control\n- Mutating webhook for audit sidecars\n- Validation strategy with compliant vs noncompliant pods\n\n## Code Example\n```yaml\n# ConstraintTemplate (example): OPA-based API access gate\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sapiaiaccess\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sAPIAccess\n  targets:\n  - target: admission.k8s.gatekeeper.sh\n    rego: |-\n      package k8sapiaiaccess\n      violate[\"API access denied: identity not whitelisted\"] {\n        input.review.kind.kind == \"Pod\"\n        identity := input.review.object.metadata.annotations[\"spire.identity\"]\n        not identity_in_allowlist(identity)\n      }\n      \n      # allowlisted identities (simplified)\n      identity_in_allowlist(id) {\n        id == \"spiffe://cluster.local/ns/default/sa/spark-sa\"\n      }\n```\n\n```yaml\n# Compliant Pod (SPIRE-identity annotated)\napiVersion: v1\nkind: Pod\nmetadata:\n  name: compliant-spark\n  annotations:\n    spire.identity: \"spiffe://cluster.local/ns/default/sa/spark-sa\"\nspec:\n  serviceAccountName: spark-sa\n  containers:\n  - name: spark\n    image: myrepo/spark:latest\n```\n\n```yaml\n# Noncompliant Pod (no SPIRE identity)\napiVersion: v1\nkind: Pod\nmetadata:\n  name: noncompliant-spark\nspec:\n  containers:\n  - name: spark\n    image: myrepo/spark:latest\n```\n\n## Validation Plan\n- Deploy constraint template and constraint; attempt compliant pod deployment; verify admission allows and audit sidecar is injected. \n- Deploy noncompliant pod; confirm admission denies with clear event reason. \n- Run a Spark job and inspect API calls logged by the auditing sidecar for traceability.","diagram":null,"difficulty":"advanced","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T22:27:30.677Z","createdAt":"2026-01-18T22:27:30.679Z"},{"id":"q-4109","question":"In a Kubernetes cluster, implement a Gatekeeper policy that enforces container image provenance: images must come from an allowlisted registry and include a digest; provide YAML for ConstraintTemplate and Constraint, a compliant Pod manifest, a noncompliant Pod manifest, and a validation plan using kubectl?","answer":"Implement a Gatekeeper ConstraintTemplate named K8sImageDigestConstraint to enforce: image must reference an allowlisted registry and include a digest (@sha256). Include the YAML for ConstraintTemplat","explanation":"## Why This Is Asked\nUnderstanding admission control and policy as code.\n\n## Key Concepts\n- Gatekeeper ConstraintTemplate, Constraint\n- Rego-based policy, allowlist, image digest\n- Pod spec image references and admission outcomes\n\n## Code Example\n```rego\npackage k8simagedigest\nviolation[{\"msg\": msg}] {\n  container := input.review.object.spec.containers[_]\n  image := container.image\n  digest := index_of(image, \"@sha256:\")\n  not digest\n  msg := \"image must include a sha256 digest\"\n}\nviolation[{\"msg\": msg}] {\n  image := input.review.object.spec.containers[_].image\n  reg := strings.Split(image, \"/\")[0]\n  allowed := input.parameters.allowed_registries\n  reg notin allowed\n  msg := \"registry not allowlisted\"\n}\n```\n\n```yaml\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8simagedigest\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sImageDigestConstraint\n  targets:\n  - target: OPA\n    rego: |\n      package k8simagedigest\n      violation[{\"msg\": msg}] {\n        container := input.review.object.spec.containers[_]\n        image := container.image\n        digest := index_of(image, \"@sha256:\")\n        not digest\n        msg := \"image must include a sha256 digest\"\n      }\n      violation[{\"msg\": msg}] {\n        container := input.review.object.spec.containers[_]\n        image := container.image\n        reg := strings.Split(image, \"/\")[0]\n        allowed := input.parameters.allowed_registries\n        reg notin allowed\n        msg := \"registry not allowlisted\"\n      }\n```\n\n```yaml\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sImageDigestConstraint\nmetadata:\n  name: require-image-digest-allowlist\nspec:\n  allowed_registries: [\"registry.company.local\", \"registry.dev.local\"]\n```\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: compliant-pod\nspec:\n  containers:\n  - name: app\n    image: registry.company.local/app@sha256:abcdef...\n```\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: noncompliant-pod\nspec:\n  containers:\n  - name: app\n    image: registry.unauthorized.local/app:latest\n```\n\n## Follow-up Questions\n- How would you test additional image attributes (size, architecture) in Gatekeeper? \n- How would you roll back a failing policy without downtime?","diagram":"flowchart TD\n  A[Pod Created] --> B[Admission Check: Gatekeeper]\n  B --> C{Compliance?}\n  C -->|Yes| D[Pod Starts]\n  C -->|No| E[Admission Denied]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T02:42:40.852Z","createdAt":"2026-01-19T02:42:40.852Z"},{"id":"q-920","question":"In a real-time chat service like Discord, deployed on Kubernetes with NVIDIA GPUs for video processing, you introduce a third-party plugin system that runs as WebAssembly modules to apply custom video filters. How would you design a secure plugin sandbox and runtime attestation to prevent leakage of streams or keys, ensure isolation from other plugins, and enable rapid rollback if a plugin behaves unexpectedly in production? Provide concrete approaches and trade-offs?","answer":"Adopt a per-plugin WebAssembly sandbox with strict memory caps (e.g., 32–64MB), syscall filtering (seccomp), and an isolated FS; require attestation using a signed manifest and a hardware-backed key f","explanation":"## Why This Is Asked\n\nThis question probes pragmatic security engineering for dynamic plugin ecosystems in real-time services with GPU workloads. It tests risk modeling, tooling choices, and trade-offs between performance and isolation.\n\n## Key Concepts\n\n- WebAssembly sandboxing\n- syscall filtering and memory limits\n- hardware-backed attestation and KMS\n- per-plugin encryption and data isolation\n- runtime observability and quick rollback\n\n## Code Example\n\n```javascript\n// Verify plugin signature before load\nconst sig = loadSignature(plugin);\nconst ok = verifySignature(sig, plugin.code, TRUSTED_PUBLIC_KEY);\nif (!ok) throw new Error(\"Invalid plugin\");\n```\n\n## Follow-up Questions\n\n- How would you test the sandbox boundaries and detect escapes?\n- What would you monitor to detect a compromised plugin, and how would you roll back safely?","diagram":"flowchart TD\n  A[Plugin Load] --> B{Attestation Passed?}\n  B -->|Yes| C[Isolate in WASM sandbox]\n  B -->|No| D[Reject]\n  C --> E[Run in separate process]\n  E --> F[Audit Logs to tamper-evident store]","difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T15:31:52.573Z","createdAt":"2026-01-12T15:31:52.573Z"},{"id":"q-959","question":"Scenario: A service executes user-provided Python plugins inside a container. Design a concrete runtime hardening plan using Linux namespaces, a minimal seccomp profile, and capability bounding, ensuring plugins cannot access host files or network directly while preserving IPC with a controlled channel. Outline exact steps and validation tests?","answer":"Drop all capabilities, run in a dedicated user namespace, mount root as read-only, and bind‑mount only the plugin assets at /plugins. Use a strict seccomp profile that whitelists essential syscalls (r","explanation":"## Why This Is Asked\n\nTests practical security hardening with knowledge of namespaces, seccomp, and capabilities—core skills for roles that handle untrusted code.\n\n## Key Concepts\n\n- Linux namespaces (user/net)\n- Capability bounding and dropping all caps\n- Seccomp profiles with syscall whitelists\n- Read-only root filesystem and selective bind mounts\n- Inter-process communication (IPC) channel integrity\n\n## Code Example\n\n```javascript\n// Example: docker run sandbox flags (conceptual)\nconst cmd = [\n  'docker', 'run', '--rm',\n  '--cap-drop', 'ALL',\n  '--security-opt', 'seccomp=seccomp-profile.json',\n  '--read-only',\n  '--network', 'none',\n  '--mount', 'type=bind,source=/path/to/plugins,target=/plugins',\n  'python-plugin-runner'\n];\n```\n\n## Follow-up Questions\n\n- How would you test for privilege escalation attempts from within the plugin?\n- What trade-offs exist between security and plugin functionality, and how would you mitigate them?","diagram":"flowchart TD\n  A[User Plugin] -->|Runs in sandbox| B[Isolated Container]\n  B --> C{Seccomp Filters}\n  C --> D[Allowed syscalls]\n  C --> E[Blocked syscalls]\n  B --> F[IPC Channel to Host]\n  F --> G[Controlled IPC Endpoint]","difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:44:33.574Z","createdAt":"2026-01-12T16:44:33.574Z"},{"id":"q-967","question":"Scenario: You manage a microservice app deployed to Kubernetes with CI/CD; you need to prevent tampered container images. **Describe a practical, beginner-friendly plan** to implement image signing and verification using **cosign**, integrate it into a GitHub Actions workflow, and enforce verification at deployment (registry or admission webhook). Include concrete commands?","answer":"Plan: sign container images with cosign in CI, store keys in a cloud KMS, rotate monthly, and require signature verification before deployment. In CI: sign on push, verify before publish. Commands to ","explanation":"## Why This Is Asked\nTest practical understanding of software supply chain security with beginner-friendly tooling.\n\n## Key Concepts\n- Image signing with cosign\n- Key management and rotation\n- CI/CD integration (GitHub Actions)\n- Deployment-time verification (registry or admission webhook)\n- Basic audit logging\n\n## Code Example\n```bash\ncosign generate-key-pair\ncosign sign docker.io/org/app:tag --key cosign.key\ncosign verify docker.io/org/app:tag --key cosign.pub\n```\n\n## Follow-up Questions\n- How would you rotate signing keys with minimal downtime?\n- How would you handle private registries and secret key storage in CI?\n","diagram":null,"difficulty":"beginner","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","NVIDIA","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:28:30.376Z","createdAt":"2026-01-12T17:28:30.376Z"},{"id":"q-994","question":"Scenario: A Kubernetes-based ML platform serves multiple teams; outbound data exfiltration is a breach risk. Propose a concrete, end-to-end control plane approach to prevent unauthorized data egress using policy-as-code, Kubernetes NetworkPolicy, and a centralized egress gateway. Include a sample Rego policy for Gatekeeper that enforces a namespace label data-export=allowed and an annotation egress-proxy=https://proxy.internal, and outline testing and GitOps integration?","answer":"An example: I implement an OPA Gatekeeper deny rule requiring pods to carry label data-export=allowed and annotation egress-proxy=https://proxy.internal; Gatekeeper blocks otherwise. A Calico NetworkP","explanation":"## Why This Is Asked\n\nThis tests practical application of policy-as-code (OPA Gatekeeper), Kubernetes security controls (NetworkPolicy), and GitOps-driven deployment, plus testing and trade-offs.\n\n## Key Concepts\n\n- OPA Gatekeeper\n- Rego policies\n- Kubernetes NetworkPolicy / Calico egress\n- GitOps (ArgoCD)\n- End-to-end testing\n\n## Code Example\n\n```rego\npackage gatekeeper.sample\n\ndeny[{\"msg\":\"Outbound egress blocked\",\"ns\":ns}]\n{ input.review.kind == \"AdmissionReview\"; obj := input.review.object; ns := obj.metadata.namespace; not obj.metadata.labels[\"data-export\"] == \"allowed\"; not obj.metadata.annotations[\"egress-proxy\"] }\n```\n\n## Follow-up Questions\n\n- How would you test this in a CI pipeline?\n- What are potential bypass vectors and mitigations?","diagram":null,"difficulty":"intermediate","tags":["cks"],"channel":"cks","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:39:01.707Z","createdAt":"2026-01-12T18:39:01.707Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","PayPal","Plaid","Robinhood","Salesforce","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":46,"beginner":10,"intermediate":26,"advanced":10,"newThisWeek":46}}