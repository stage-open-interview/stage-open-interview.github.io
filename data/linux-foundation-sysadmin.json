{"questions":[{"id":"linux-foundation-sysadmin-essential-commands-1768169900531-0","question":"Which command creates a gzipped tarball of the contents of the directory /srv/app, excluding the file config.yaml?","answer":"[{\"id\":\"a\",\"text\":\"tar czf /backup/app.tar.gz -C /srv/app --exclude=config.yaml .\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"tar czf /backup/app.tar.gz -C /srv/app/config.yaml .\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"tar czf /backup/app.tar.gz -C /srv/app --exclude=/srv/app/config.yaml .\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"tar czf /backup/app.tar.gz -C /srv/app --exclude=config.yaml\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. The command tar czf /backup/app.tar.gz -C /srv/app --exclude=config.yaml . creates a gzipped tarball of the directory /srv/app, excluding the file named config.yaml. The -C /srv/app switches to that directory, and the trailing . includes all contents. The --exclude flag patterns exclude matching paths from the archive.\n\n## Why Other Options Are Wrong\n- B attempts to archive a single file path instead of the directory contents and would not produce the full directory tree as intended.\n- C uses an absolute path in --exclude which tar may interpret relative to the -C path and could fail to exclude the intended file.\n- D uses a non-existent short option -exclude and would fail to parse.\n\n## Key Concepts\n- Tar with compression: czf\n- -C to change directory before archiving\n- --exclude to skip patterns\n- including the contents of a directory with .\n\n## Real-World Application\n- Backing up an application directory while omitting sensitive or large config files during automated backups.","diagram":null,"difficulty":"intermediate","tags":["Linux","Essential Commands","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-25"],"channel":"linux-foundation-sysadmin","subChannel":"essential-commands","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:18:20.535Z","createdAt":"2026-01-11 22:18:20"},{"id":"linux-foundation-sysadmin-essential-commands-1768169900531-1","question":"You want to list the 20 most recently modified files under /var/log, including their full paths, and constrain results to regular files only. Which command is most robust?","answer":"[{\"id\":\"a\",\"text\":\"find /var/log -type f -printf '%T@ %p\\\\n' | sort -n | tail -n 20\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"ls -ltR /var/log | head -n 20\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"find /var/log -type d -mtime -1\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"stat -c '%y %n' /var/log/* | sort -n | tail -n 20\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. The find command with -type f restricts to files, -printf '%T@ %p' prints a timestamp and path, and sorting by time then tail -n 20 returns the 20 most recently modified files with full paths.\n\n## Why Other Options Are Wrong\n- B lists entries recursively but may include directories and non-files, and head -n 20 may miss the actual most recently modified files and not show full paths consistently.\n- C searches only directories, not files.\n- D uses wildcard expansion that may fail with spaces or hidden files and does not filter by modification time as robustly.\n\n## Key Concepts\n- find with -type f and -printf\n- Sorting by timestamp to identify recent changes\n- Handling full paths for real-world log audits\n\n## Real-World Application\n- Quickly auditing the most recently updated log files for incident response or troubleshooting.","diagram":null,"difficulty":"intermediate","tags":["Linux","Essential Commands","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-25"],"channel":"linux-foundation-sysadmin","subChannel":"essential-commands","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:18:21.057Z","createdAt":"2026-01-11 22:18:21"},{"id":"linux-foundation-sysadmin-essential-commands-1768169900531-2","question":"Which command prints the top memory consuming process's PID and RSS value, ignoring the header line, in a single line?","answer":"[{\"id\":\"a\",\"text\":\"ps -eo pid,rss,cmd --sort=-rss | awk 'NR==2{print $1, $2}'\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"ps -eo pid,rss,cmd --sort=-rss | sed -n '2p'\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"ps -eo pid,rss,cmd --sort=-rss | tail -n +2 | head -n 1\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"ps aux --sort=-rss | head -n 1\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. The command prints only the PID and RSS fields for the second line of the ps output, which corresponds to the top memory-consuming process when sorted by RSS. The use of awk ensures only PID and RSS are shown.\n\n## Why Other Options Are Wrong\n- B prints the entire line which also contains the CMD, not just PID and RSS.\n- C skips the header but may return the top line differently depending on environment and still includes more fields if not filtered.\n- D shows the header line or the first line of ps output in some environments, which does not guarantee extracting PID and RSS of the top memory process.\n\n## Key Concepts\n- ps with --sort=-rss for memory ranking\n- awk to select specific columns\n- Excluding the header for clean data extraction\n\n## Real-World Application\n- Quickly triaging memory hogs on a live server during incident response.","diagram":null,"difficulty":"intermediate","tags":["Linux","Essential Commands","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-25"],"channel":"linux-foundation-sysadmin","subChannel":"essential-commands","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:18:21.523Z","createdAt":"2026-01-11 22:18:21"},{"id":"linux-foundation-sysadmin-operation-running-1768206659074-0","question":"On a server running systemd, the persistent journal is consuming disk space. You want to reduce the stored logs to a maximum 500M while preserving the most recent logs. Which command should you run?","answer":"[{\"id\":\"a\",\"text\":\"journalctl --rotate && journalctl --vacuum-size=500M\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"journalctl --vacuum-size=500M\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"systemctl restart systemd-journald\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"rm -rf /var/log/journal/*\",\"isCorrect\":false}]","explanation":"## Q1 Correct Answer\n- B\n\n## Why Other Options Are Wrong\n- A: Rotating logs without vacuuming may not reduce total space to the desired limit and can still leave old entries. Vacuum requires size limit and keeps recent data when combined with rotation; using only rotate without vacuum is insufficient.\n- C: Restarting the service does not reduce the amount of stored logs; it only restarts the daemon and may trigger a new log file but does not enforce retention.\n- D: Manual deletion of journal files can corrupt the journal or lose the ability to query it reliably; it bypasses proper retention policies and may break integrity.\n\n## Key Concepts\n- Systemd journal retention\n- journalctl vacuum options\n- Persistent vs volatile journald storage\n\n## Real-World Application\n- You implement automated log retention for hosts running systemd, ensuring disk space is reclaimed without losing access to the most recent events.","diagram":null,"difficulty":"intermediate","tags":["Linux","systemd","journald","AWS","Kubernetes","certification-mcq","domain-weight-20"],"channel":"linux-foundation-sysadmin","subChannel":"operation-running","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:30:59.075Z","createdAt":"2026-01-12 08:30:59"},{"id":"linux-foundation-sysadmin-operation-running-1768206659074-1","question":"You maintain a daemon on a systemd-based host. The daemon occasionally terminates due to transient errors. You want systemd to restart it automatically but with a backoff to avoid flapping. Which unit configuration is correct?","answer":"[{\"id\":\"a\",\"text\":\"Restart=on-failure, RestartSec=10s\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Restart=always, RestartSec=0s\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Restart=on-success, RestartSec=60s\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"TimeoutStartSec=2s, StartLimitInterval=60s\",\"isCorrect\":false}]","explanation":"## Q2 Correct Answer\n- A\n\n## Why Other Options Are Wrong\n- B: Restart=always restarts the service even on normal exits or successes, which can cause unnecessary restarts.\n- C: Restart=on-success would only restart on a clean exit, which is not suitable for transient failures.\n- D: TimeoutStartSec and StartLimitInterval are unrelated to implementing a backoff restart policy and do not guarantee backoff behavior.\n\n## Key Concepts\n- systemd Restart options\n- Backoff strategies\n- StartLimit to prevent crash loops\n\n## Real-World Application\n- Applying backoff policies prevents log floods and helps maintain service stability during transient issues.","diagram":null,"difficulty":"intermediate","tags":["Linux","systemd","monitoring","AWS","Kubernetes","certification-mcq","domain-weight-20"],"channel":"linux-foundation-sysadmin","subChannel":"operation-running","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:30:59.498Z","createdAt":"2026-01-12 08:30:59"},{"id":"linux-foundation-sysadmin-operation-running-1768206659074-2","question":"A backup script run by cron fails because required commands are not in cron's default PATH. What change will most reliably ensure the script runs under cron?","answer":"[{\"id\":\"a\",\"text\":\"Call absolute paths for all commands and set PATH explicitly at the top of the script\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Source the user's profile from cron before running the script\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Move binaries into a directory that is in cron's default PATH\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Run the script using at instead of cron\",\"isCorrect\":false}]","explanation":"## Q3 Correct Answer\n- A\n\n## Why Other Options Are Wrong\n- B: Cron typically does not source user profiles; relying on profiles is not dependable for cron jobs.\n- C: Moving binaries to fit cron's PATH is impractical and can introduce maintenance issues; absolute paths are more reliable.\n- D: Using at changes scheduling semantics and is not a drop-in replacement for cron for recurring backups.\n\n## Key Concepts\n- Cron PATH limitations\n- Absolute paths in scripts\n- Environment isolation for scheduled jobs\n\n## Real-World Application\n- Ensures scheduled backups run reliably in production environments by eliminating PATH-related failures.","diagram":null,"difficulty":"intermediate","tags":["Linux","cron","shell","AWS","Kubernetes","certification-mcq","domain-weight-20"],"channel":"linux-foundation-sysadmin","subChannel":"operation-running","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:30:59.912Z","createdAt":"2026-01-12 08:30:59"}],"subChannels":["essential-commands","operation-running"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}