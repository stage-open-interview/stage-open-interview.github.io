{"questions":[{"id":"gcp-ml-engineer-architect-ml-1768282342218-0","question":"In a GCP-based low-code ML pipeline using Vertex AI, you want to monitor data drift and model behavior across features in a feature store with minimal code changes. Which approach is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Use Vertex AI Model Monitoring with a Data Drift Monitor attached to the model endpoint\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Export data to BigQuery and run custom drift checks daily using SQL\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on Cloud Logging alerts from the training job\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Pub/Sub to stream warnings to your dashboard\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA Vertex AI Model Monitoring with a Data Drift Monitor is the correct choice because it provides automated drift detection for production data and model behavior with minimal code changes.\n\n## Why Other Options Are Wrong\n- Option B: This requires manual setup and periodic checks; it does not provide real-time monitoring or automated alerts.\n- Option C: Training-time logs do not capture production data drift or model health.\n- Option D: Pub/Sub alone does not implement drift detection or model monitoring.\n\n## Key Concepts\n- Data drift monitoring\n- Vertex AI Model Monitoring\n\n## Real-World Application\n- Attach a Data Drift Monitor to your deployed endpoint to receive drift alerts and trigger retraining pipelines when drift thresholds are exceeded.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Kubernetes","Terraform","AWS Sagemaker","certification-mcq","domain-weight-12"],"channel":"gcp-ml-engineer","subChannel":"architect-ml","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:32:22.219Z","createdAt":"2026-01-13 05:32:22"},{"id":"gcp-ml-engineer-architect-ml-1768282342218-1","question":"To privacy-protect training data in a low-code ML workflow on GCP, you want to redact PII with minimal code changes before ingestion. Which approach is most suitable?","answer":"[{\"id\":\"a\",\"text\":\"Use Vertex AI Privacy Preserving ML\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Cloud Data Loss Prevention (DLP) to redact PII before ingestion\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Disable logging of dataset attributes\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use separate sandbox for training\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. Cloud Data Loss Prevention (DLP) can redact or de-identify PII before data ingestion, aligning with privacy requirements without extensive code changes.\n\n## Why Other Options Are Wrong\n- Option A: Vertex AI Privacy Preserving ML is a broader concept and not a concrete, minimal-code redaction flow in typical pipelines.\n- Option C: Simply disabling logs does not address data exposure in training data.\n- Option D: Sandboxing alone does not redact sensitive data before training.\n\n## Key Concepts\n- Data de-identification\n- Cloud DLP integration with ML pipelines\n\n## Real-World Application\n- Apply DLP transformations upstream so training datasets never expose PII in feature stores or model artifacts.","diagram":null,"difficulty":"intermediate","tags":["Cloud DLP","Terraform","AWS Sagemaker","Kubernetes","certification-mcq","domain-weight-12"],"channel":"gcp-ml-engineer","subChannel":"architect-ml","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:32:22.812Z","createdAt":"2026-01-13 05:32:23"},{"id":"gcp-ml-engineer-architect-ml-1768282342218-2","question":"Your low-code ML solution experiences sporadic prediction requests. Which pattern minimizes cost while still meeting latency requirements?","answer":"[{\"id\":\"a\",\"text\":\"Always-on Vertex AI Endpoint with autoscaling\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Batch predictions on a schedule\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Real-time streaming inference using Dataflow\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Running predictions on a dedicated VM\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. Batch predictions are cost-efficient for sporadic workloads since they avoid maintaining an always-on serving endpoint while still delivering timely results.\n\n## Why Other Options Are Wrong\n- Option A: Always-on endpoints incur baseline costs even during idle periods.\n- Option C: Streaming adds complexity and often higher costs for low-frequency events.\n- Option D: VMs require continuous provisioning and maintenance, increasing cost.\n\n## Key Concepts\n- Batch vs online inference\n- Cost optimization for irregular workloads\n\n## Real-World Application\n- Schedule batch prediction runs during off-peak hours when possible and route results to downstream dashboards.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Terraform","AWS Sagemaker","Kubernetes","certification-mcq","domain-weight-12"],"channel":"gcp-ml-engineer","subChannel":"architect-ml","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:32:23.332Z","createdAt":"2026-01-13 05:32:23"},{"id":"gcp-ml-engineer-architect-ml-1768282342218-3","question":"For a real-time inference requirement in a low-code ML app, which deployment approach provides the best low-latency predictions with minimal maintenance?","answer":"[{\"id\":\"a\",\"text\":\"Vertex AI Endpoint with autoscaling\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Cloud Run with a warmed container pool\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cloud Functions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"BigQuery UDFs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Vertex AI Endpoint provides managed hosting with autoscaling, optimized for low-latency predictions and minimal maintenance for ML models.\n\n## Why Other Options Are Wrong\n- Option B: Warmed containers add complexity and may still not meet latency of dedicated endpoints.\n- Option C: Cloud Functions typically have higher cold-start latency for ML models.\n- Option D: BigQuery UDFs are not suitable for real-time model inference.\n\n## Key Concepts\n- Online vs batch inference\n- Managed endpoints\n\n## Real-World Application\n- Use Vertex AI Endpoints to serve latency-critical models with automatic scaling and monitoring.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Kubernetes","AWS Sagemaker","GKE","certification-mcq","domain-weight-12"],"channel":"gcp-ml-engineer","subChannel":"architect-ml","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:32:23.526Z","createdAt":"2026-01-13 05:32:23"},{"id":"gcp-ml-engineer-architect-ml-1768282342218-4","question":"Which GCP service provides model registry and lineage capabilities for governance in a multi-environment low-code ML solution?","answer":"[{\"id\":\"a\",\"text\":\"Vertex AI Model Registry\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Cloud Data Catalog\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cloud Composer\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Source Repositories\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Vertex AI Model Registry provides versioning, lineage, and governance features for ML models across environments.\n\n## Why Other Options Are Wrong\n- Option B: Cloud Data Catalog is for metadata discovery but not specific to model lifecycle and registry.\n- Option C: Cloud Composer is for workflow orchestration, not model governance.\n- Option D: Cloud Source Repositories is for code version control, not model artifacts and lineage.\n\n## Key Concepts\n- Model versioning\n- Model lineage and governance\n\n## Real-World Application\n- Use the Model Registry to promote models from staging to production with traceable lineage and metadata.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Terraform","AWS Sagemaker","Kubernetes","certification-mcq","domain-weight-12"],"channel":"gcp-ml-engineer","subChannel":"architect-ml","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:32:23.701Z","createdAt":"2026-01-13 05:32:23"},{"id":"gcp-ml-engineer-automate-orchestrate-1768158985475-0","question":"Which approach best ensures reproducible experiment runs across dev, staging, and prod environments by parameterizing pipelines, isolating artifacts, and recording lineage?","answer":"[{\"id\":\"a\",\"text\":\"Use a single hard-coded pipeline with a global artifact bucket shared by all environments\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use parameterized Vertex AI Pipelines with environment-specific configuration files, separate artifact storage per environment, and Vertex AI Metadata for experiment lineage\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Run the pipeline once and reuse results across environments without environment isolation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use manual steps per environment with no centralized configuration\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is B because parameterizing Vertex AI Pipelines with environment-specific configuration, separate artifact storage per environment, and Vertex AI Metadata enables reproducible runs and traceability across dev/stage/prod.\n\n## Why Other Options Are Wrong\n- A is incorrect because sharing a single global artifact bucket and not parameterizing pipelines leads to cross-environment contamination and non-reproducible runs.\n- C is incorrect because reusing results across environments without isolation increases drift and undermines reproducibility.\n- D is incorrect because manual, ad-hoc steps introduce variability and prevent centralized configuration.\n\n## Key Concepts\n- Parameterized Vertex AI Pipelines\n- Environment-specific configuration management\n- Artifact storage isolation per environment\n- Vertex AI Metadata for lineage\n\n## Real-World Application\nMaintain separate GCS buckets per environment, version-control all per-environment configs, and drive deployments via a centralized CI/CD workflow that injects environment parameters. Use Vertex AI Metadata to capture lineage across runs.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","Vertex AI","Cloud Composer","Dataflow","BigQuery","Airflow","certification-mcq","domain-weight-21"],"channel":"gcp-ml-engineer","subChannel":"automate-orchestrate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:16:25.476Z","createdAt":"2026-01-11 19:16:25"},{"id":"gcp-ml-engineer-automate-orchestrate-1768158985475-1","question":"Which deployment strategy provides safe rollback and minimal downtime when releasing a new model version to a Vertex AI Endpoint?","answer":"[{\"id\":\"a\",\"text\":\"Deploy new model to a separate endpoint and switch traffic via DNS\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use a canary deployment on Vertex AI Endpoints with traffic-splitting and an automated rollback if latency or accuracy drift exceeds threshold\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Immediately swap traffic to the new model on the same endpoint and delete the old version\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create a new endpoint per deployment and keep old endpoints\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is B because canary deployments with traffic splitting allow progressive rollout and automatic rollback triggers based on latency or accuracy drift, minimizing downtime and risk.\n\n## Why Other Options Are Wrong\n- A defines a DNS-based switch which can introduce routing complexity and lacks automated rollback tied to model performance.\n- C causes potential downtime and provides no gradual validation.\n- D multiplies endpoints, increasing resource usage and routing complexity without inherent rollback guarantees.\n\n## Key Concepts\n- Canary deployments\n- Traffic splitting on Vertex AI Endpoints\n- Telemetry and automatic rollback logic\n\n## Real-World Application\nConfigure an initial traffic ramp (e.g., 10-20%), monitor latency, error rate, and drift metrics, and automatically roll back if thresholds are breached; once validated, shift remaining traffic to the new model.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","Vertex AI","Cloud Composer","Dataflow","BigQuery","Airflow","certification-mcq","domain-weight-21"],"channel":"gcp-ml-engineer","subChannel":"automate-orchestrate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:16:25.963Z","createdAt":"2026-01-11 19:16:26"},{"id":"gcp-ml-engineer-automate-orchestrate-1768158985475-2","question":"You're building a data processing and feature store pipeline. You need to incrementally materialize features from BigQuery to Vertex AI Feature Store while handling late data and ensuring idempotent writes. Which design best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Full re-ingestion daily, ignoring late data\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Streaming ingestion with Pub/Sub feeding Feature Store with upsert semantics\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Incremental batch pipeline using Dataflow that fetches last_update timestamp and upserts to Feature Store, with dedup and idempotent writes\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Manual data transfer using a single batch job\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is C because an incremental batch Dataflow pipeline that uses last_update timestamp and idempotent writes to Vertex AI Feature Store ensures correct handling of late data and avoids duplicates.\n\n## Why Other Options Are Wrong\n- A full daily re-ingestion ignores late data and wastes compute.\n- B Streaming ingestion with Pub/Sub can provide near-real-time updates, but dedup semantics for Feature Store can be complex and may require additional logic.\n- D Manual data transfer lacks automation and reproducibility.\n\n## Key Concepts\n- Dataflow incremental batch processing\n- Last_update timestamp-based ingestion\n- Vertex AI Feature Store upserts and idempotent writes\n- Late-arriving data handling\n\n## Real-World Application\nImplement a Dataflow pipeline that queries BigQuery with a windowed last_update filter, performs dedup, and upserts to Feature Store; integrate with Cloud Composer to schedule and monitor retries and alerts.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","Vertex AI","Cloud Composer","Dataflow","BigQuery","Airflow","certification-mcq","domain-weight-21"],"channel":"gcp-ml-engineer","subChannel":"automate-orchestrate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:16:26.440Z","createdAt":"2026-01-11 19:16:26"},{"id":"gcp-ml-engineer-data-prep-1768249406549-0","question":"A data science team needs to share a common feature store across multiple product teams with strict access control and lineage. Which approach best supports cross-team collaboration?","answer":"[{\"id\":\"a\",\"text\":\"Create separate feature stores per team to avoid cross-team access\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use a centralized Vertex AI Feature Store with IAM-based access control, feature-level permissions, and versioning\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Export features to BigQuery datasets per team and manage permissions there\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Store features as Cloud Storage files and manage permissions with bucket ACLs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe centralized Vertex AI Feature Store with IAM-based access control and versioning provides centralized governance, reuse, and traceability across teams.\n\n## Why Other Options Are Wrong\n- a: Duplicating feature stores creates silos and complicates governance.\n- c: Moving features into BigQuery per-team undermines centralized feature management and lineage tracking.\n- d: Storing features as files lacks the metadata and governance of a dedicated feature store.\n\n## Key Concepts\n- Vertex AI Feature Store\n- IAM-based access control and data lineage\n\n## Real-World Application\n- Enables safe feature reuse across product teams while enabling traceability and governance.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Feature Store","IAM","Kubernetes","Terraform","BigQuery","Data Governance","certification-mcq","domain-weight-16"],"channel":"gcp-ml-engineer","subChannel":"data-prep","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T20:23:26.550Z","createdAt":"2026-01-12 20:23:27"},{"id":"gcp-ml-engineer-data-prep-1768249406549-1","question":"Two teams contribute models to a shared registry and require controlled promotion from staging to production with audit trails. What pattern should they adopt?","answer":"[{\"id\":\"a\",\"text\":\"Each team deploys directly to production from their own pipelines\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Vertex AI Model Registry with versions, stages (staging, prod) and an approval workflow controlled by IAM and CI/CD\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Manually copy model artifacts to shared bucket and deploy via scripts\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use BigQuery ML to manage deployment\",\"isCorrect\":false}]","explanation":"## Correct Answer\nUsing Vertex AI Model Registry with versions, stages, and an approval workflow controlled by IAM and CI/CD ensures auditable promotion from staging to prod and preserves lineage.\n\n## Why Other Options Are Wrong\n- a: Bypasses centralized governance and auditing.\n- c: Lacks formal versioning and approval trails; increases drift risk.\n- d: BigQuery ML is not a deployment/registry mechanism for models.\n\n## Key Concepts\n- Vertex AI Model Registry\n- Versioned stages and approvals\n\n## Real-World Application\n- Enables cross-team model governance and compliant deployment processes.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Model Registry","IAM","Kubernetes","Terraform","CI/CD","GKE","certification-mcq","domain-weight-16"],"channel":"gcp-ml-engineer","subChannel":"data-prep","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T20:23:27.094Z","createdAt":"2026-01-12 20:23:27"},{"id":"gcp-ml-engineer-data-prep-1768249406549-2","question":"When tracking experiments and model lineage across teams, which combination provides end-to-end provenance and reproducibility?","answer":"Vertex AI Metadata combined with Data Catalog provides end-to-end provenance and reproducibility for experiment tracking and model lineage across teams by automatically capturing runs, artifacts, and data asset relationships in a unified metadata system.","explanation":"## Correct Answer\nVertex AI Metadata provides structured tracking of runs and artifacts, and Data Catalog offers centralized data asset provenance; together they enable end-to-end lineage and reproducibility.\n\n## Why Other Options Are Wrong\n- b: Logs alone do not capture model artifacts or experimental lineage.\n- c: Manual tracing is error-prone and not scalable.\n- d: Cloud Trace focuses on distributed tracing of API calls, not ML asset lineage.\n\n## Key Concepts\n- Vertex AI Metadata (ML Metadata)\n- Data Catalog\n\n## Real-World Application\n- Ensures researchers and engineers can reproduce experiments across teams with auditable lineage.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Metadata","Data Catalog","Experiment Tracking","GKE","Terraform","certification-mcq","domain-weight-16"],"channel":"gcp-ml-engineer","subChannel":"data-prep","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:32:40.313Z","createdAt":"2026-01-12 20:23:27"},{"id":"gcp-ml-engineer-data-prep-1768249406549-3","question":"You need to standardize experiment naming, metrics collection, and artifact storage across teams. Which pattern ensures consistent governance?","answer":"[{\"id\":\"a\",\"text\":\"Use a manual spreadsheet to track experiments\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Vertex AI Experiments with Metadata templates and standardized dashboards\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Increment numbers in model names only\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Spanner as the sole store for experiments\",\"isCorrect\":false}]","explanation":"## Correct Answer\nVertex AI Experiments paired with Metadata templates and dashboards provides structured naming, centralized metrics collection, and consistent artifact storage across teams.\n\n## Why Other Options Are Wrong\n- a: Prone to human error and not scalable for cross-team governance.\n- c: Naming is insufficient without structured metrics and artifact management.\n- d: Cloud Spanner is not a specialized ML experiment store and lacks ML-grade governance features.\n\n## Key Concepts\n- Vertex AI Experiments\n- Metadata-driven dashboards\n\n## Real-World Application\n- Enables consistent cross-team experiment governance and reporting.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Experiments","Metadata","Kubernetes","Terraform","GKE","certification-mcq","domain-weight-16"],"channel":"gcp-ml-engineer","subChannel":"data-prep","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T20:23:27.615Z","createdAt":"2026-01-12 20:23:27"},{"id":"gcp-ml-engineer-data-prep-1768249406549-4","question":"To meet governance policy on sensitive data, you must redact or tokenize before training while enabling cross-team collaboration. Which approach enables this while preserving utility?","answer":"[{\"id\":\"a\",\"text\":\"Apply per-dataset IAM restrictions and train on raw data\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Cloud DLP to redact sensitive fields before training and enforce access controls\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Share raw data across teams with encryption keys\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Train on synthetic data only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nCloud DLP can redact or tokenize sensitive fields prior to training, combined with access controls, providing compliant cross-team collaboration while preserving useful signals.\n\n## Why Other Options Are Wrong\n- a: Training on raw data may violate governance policies.\n- c: Sharing raw data with keys still risks exposure and governance gaps.\n- d: Synthetic data alone may not meet all regulatory or analytic needs.\n\n## Key Concepts\n- Cloud DLP\n- Data masking and access controls\n\n## Real-World Application\n- Enables compliant ML workflows across teams by protecting PII and sensitive fields during preprocessing.","diagram":null,"difficulty":"intermediate","tags":["Cloud DLP","Data Protection","IAM","Kubernetes","Terraform","GCP","certification-mcq","domain-weight-16"],"channel":"gcp-ml-engineer","subChannel":"data-prep","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T20:23:27.748Z","createdAt":"2026-01-12 20:23:27"},{"id":"q-1008","question":"You're building a real-time customer-review sentiment classifier on GCP. Design a beginner-friendly end-to-end pipeline using Vertex AI for training and hosting, Vertex AI Feature Store for online features, Dataflow for ETL, and Pub/Sub for ingestion. Describe data flow, feature materialization cadence, a canary rollout strategy, and basic drift monitoring with rollback triggers. Include cost considerations?","answer":"Use Vertex AI for training and online serving, Feature Store for online features, and Dataflow for ETL. Ingest reviews via Pub/Sub, materialize offline features in BigQuery, push to Feature Store, and","explanation":"## Why This Is Asked\nTests the ability to design an end-to-end GCP ML pipeline with practical constraints, focusing on data freshness, feature management, canary deployment, and cost awareness.\n\n## Key Concepts\n- End-to-end pipeline design on GCP\n- Online vs offline features with Vertex AI Feature Store\n- Real-time ingestion with Pub/Sub and Dataflow ETL\n- Canary rollout and drift-triggered rollback\n- Cost optimization strategies\n\n## Code Example\n```python\n# placeholder snippet illustrating a simple canary flag and feature-store write\n```\n\n## Follow-up Questions\n- How would you implement drift thresholds and alerting?\n- How would you validate the feature pipeline during retraining?","diagram":null,"difficulty":"beginner","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Snowflake","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:52:22.133Z","createdAt":"2026-01-12T18:52:22.133Z"},{"id":"q-1199","question":"Design a multi-tenant, privacy-preserving online inference and feature materialization pipeline on GCP for a cross-region ride-hailing platform. Each tenant has its own feature schema and data residency needs. Outline how you would manage per-tenant Feature Store namespaces, Canary deployments across tenants, live vs. batch feature materialization, drift/bias monitoring, provenance, and automated rollback with Vertex AI Endpoints, Dataflow, and Pub/Sub. Include concrete rollback criteria and cost considerations?","answer":"Use per-tenant feature store namespaces and a tenant-scoped Vertex AI Endpoint. Ingest events with Pub/Sub, materialize online features in Dataflow into a tenant-specific online store, and route reque","explanation":"## Why This Is Asked\n\nExplores multi-tenant data isolation, per-tenant schemas, data residency, and governance in production ML pipelines, plus practical rollback and cost controls.\n\n## Key Concepts\n\n- Multi-tenant Feature Store namespaces and tenant-scoped endpoints\n- Data residency controls (EU/US), VPC Service Controls, RBAC\n- Canary rollouts per tenant with traffic-splitting\n- Drift and bias monitoring across tenants; data provenance\n- Online/Offline feature materialization via Dataflow; Pub/Sub as ingestion backbone\n\n## Code Example\n\n```yaml\ntenants:\n  - id: tenant-A\n    feature_store: projects/xxx/locations/us-central1/featurestores/tenantA\n    endpoint: https://endpointA.example.com/predict\n  - id: tenant-B\n    feature_store: projects/xxx/locations/eu-west1/featurestores/tenantB\n    endpoint: https://endpointB.example.com/predict\n```\n\n## Follow-up Questions\n\n- How would you detect data poisoning or schema drift in real time across tenants?\n- What rollback criteria would you enforce for drift, latency, or cost violations, and how would you automate it across regions?","diagram":"flowchart TD\nA[Event with TenantID] --> B[Feature Store (per-tenant namespace)]\nB --> C[Materialize Online Features]\nC --> D[Vertex AI Endpoint (tenant-scoped)]\nD --> E[Canary Controller]\nE --> F[Monitoring & Drift Detection]","difficulty":"advanced","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:48:07.297Z","createdAt":"2026-01-13T04:48:07.297Z"},{"id":"q-1225","question":"Design a beginner-friendly end-to-end GCP pipeline for a price-optimization model. Use Vertex AI for training and hosting, Vertex AI Feature Store for online/offline features, Dataflow for ETL into BigQuery, and Pub/Sub for ingestion. Describe data flow, feature derivation cadence, training trigger cadence, online/offline feature consistency, and a simple rollback strategy if offline metrics degrade. Include a basic cost plan?","answer":"Dataflow ingests price and demand signals into BigQuery; derive features like price elasticity and seasonality; feed online features to Vertex AI Feature Store. Train nightly with Vertex AI, deploy to","explanation":"## Why This Is Asked\nTests ability to design a practical, beginner-friendly GCP ML pipeline across multiple services, focusing on data flow, feature management, and simple rollback. \n\n## Key Concepts\n- Vertex AI training and hosting\n- Vertex AI Feature Store (online/offline features)\n- Dataflow for ETL into BigQuery\n- Pub/Sub ingestion for streaming signals\n- Training triggers, drift checks, and rollback strategy\n\n## Code Example\n```javascript\n// Lightweight drift check example (pseudo)\nfunction driftScore(current, baseline) {\n  const diff = Math.abs(current - baseline);\n  return diff / Math.max(1, baseline);\n}\n```\n\n## Follow-up Questions\n- How would you validate consistency between online and offline features?\n- Which metrics signal a rollback, and how would you automate it?","diagram":"flowchart TD\n  PubSub[Pub/Sub] --> Dataflow[Dataflow ETL]\n  Dataflow --> BigQuery[BigQuery]\n  BigQuery --> FeatureStore[Vertex AI Feature Store]\n  FeatureStore --> OnlineServing[Online Serving]\n  Dataflow --> Training[Vertex AI Training]\n  Training --> Serving[Vertex AI Endpoint]","difficulty":"beginner","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:37:15.077Z","createdAt":"2026-01-13T05:37:15.077Z"},{"id":"q-882","question":"You run a real-time fraud-detection model on GCP at ~25k QPS with sub-20 ms P95 latency. Design a production pipeline using Vertex AI, Feature Store, Pub/Sub, and Dataflow that ingests events, materializes features, serves online predictions, and supports canary rollouts. Include data/model drift monitoring, automated rollback, and cost considerations?","answer":"To meet those goals, route events via Pub/Sub to Dataflow for feature prep, push online features to Vertex AI Feature Store, deploy models in Vertex AI with 10–20% traffic to a canary, and monitor dri","explanation":"## Why This Is Asked\nTests ability to design end-to-end ML platform on GCP at scale, covering real-time ingestion, feature stores, model registry, canary deployments, monitoring, and cost control.\n\n## Key Concepts\n- Realtime ingestion via Pub/Sub\n- Feature Store online/offline usage\n- Vertex AI deployment and model monitoring\n- Canary traffic splitting and rollback\n- Drift detection and alerting\n- Cost-aware scaling\n\n## Code Example\n\n```python\n# Pseudo-code: canary traffic split and monitoring start\n```\n\n## Follow-up Questions\n- How would you set drift thresholds and alerts?\n- How would you evolve feature schemas without breaking serving?","diagram":null,"difficulty":"advanced","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:00:47.597Z","createdAt":"2026-01-12T14:00:47.597Z"},{"id":"q-905","question":"You operate a multi-tenant content recommender service on GCP used by advertisers. Each tenant has its own feature schema and data retention. Design a production ML pipeline (training and online serving) using Vertex AI, Feature Store, Pub/Sub, and Dataflow that supports **per-tenant namespaces**, **policy-based access**, **drift monitoring**, **automated rollback**, and **cost isolation**. Include data leakage prevention, schema evolution, and canary rollouts across regions?","answer":"Use tenant-scoped Feature Stores and separate training runs per tenant via Vertex AI Pipelines. Route streaming data through Pub/Sub and Dataflow into per-tenant online/offline stores, with IAM per-te","explanation":"## Why This Is Asked\nThis question probes how candidates architect multi-tenant ML workflows with governance, isolation, and reliability. It emphasizes production concerns beyond single-tenant pipelines.\n\n## Key Concepts\n- Multi-tenant feature store namespaces\n- IAM and per-tenant isolation\n- Drift detection and monitoring per tenant\n- Canary rollouts and automated rollbacks\n- Cost isolation via quotas and budgets\n- Schema evolution and data leakage prevention\n- Cross-region delivery and auditability\n\n## Code Example\n```javascript\nfunction featureStorePath(tenantId, project, location = 'us-central1') {\n  return `projects/${project}/locations/${location}/featurestores/${tenantId}_fs`;\n}\n```\n\n## Follow-up Questions\n- How would you validate cross-tenant feature leakage guarantees? \n- How would you implement tenant-specific canary traffic and rollbacks at scale?","diagram":"flowchart TD\nA[Tenant] --> B[Feature Store Namespace]\nB --> C[Training Pipeline]\nC --> D[Online Serving]\nD --> E[Canary Manager]\nE --> F[Region Failover]","difficulty":"advanced","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Scale Ai","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:43:57.232Z","createdAt":"2026-01-12T14:43:57.232Z"},{"id":"q-922","question":"Design a real-time content moderation inference path on GCP that adds a Redis-based in‑memory cache in front of a Vertex AI online endpoint to reduce latency and cost. Outline what you cache (embeddings vs predictions), key schema (e.g., user_id, model_version, language), TTL and eviction policy, and how you invalidate cache on model deploy or feature updates. Include data privacy considerations and a plan for monitoring latency, cache hit rate, and drift. Provide a small Python sketch of the cache lookup?","answer":"Add a Redis cache in front of the Vertex AI online endpoint. Cache embeddings or prediction results keyed by user_id, model_version, language. Use a short TTL (5–15 min) with invalidation on new deplo","explanation":"## Why This Is Asked\n\nTests practical cache design between online model serving, latency, and cost, plus how to keep data private and fresh.\n\n## Key Concepts\n\n- In‑memory caching in front of online endpoints\n- Cache keys tied to user_id, language, and model_version\n- Invalidation triggers on model deploys or feature updates\n- Data privacy: hashing identifiers before caching\n- Observability: latency, cache hit rate, drift checks\n\n## Code Example\n\n```python\nimport redis\nimport hashlib\n\ncache = redis.Redis(host='redis-host', port=6379)\n\ndef cache_key(user_id, model_version, language):\n    return f\"{hashlib.sha256(user_id.encode()).hexdigest()}:{model_version}:{language}\"\n\ndef get_inference(user_id, model_version, language, compute_embedding, ttl=900):\n    key = cache_key(user_id, model_version, language)\n    val = cache.get(key)\n    if val is not None:\n        return val\n    value = compute_embedding(user_id)\n    cache.setex(key, ttl, value)\n    return value\n```\n\n## Follow-up Questions\n\n- How would you validate cache correctness when model_version changes?\n- How would you scale Redis for bursty traffic while preventing stale data?","diagram":"flowchart TD\n  Client[Client] --> Cache[Redis Cache]\n  Cache --> Endpoint[Vertex AI Endpoint]\n  Endpoint --> Cache\n  Cache --> FeatureStore[Feature Store]","difficulty":"beginner","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Discord","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:33:12.035Z","createdAt":"2026-01-12T15:33:12.035Z"},{"id":"q-955","question":"Design a multi-tenant ML service on GCP that serves diverse customers with strict data isolation and retention policies. Propose a deployment and feature governance pattern using Vertex AI, Feature Store, Private Service Connect, Data Catalog, and Pub/Sub to isolate customer data, manage per-tenant feature lifecycles, perform drift monitoring, and enable tenant-specific canary rollouts with automated rollback and cost controls. Include concrete components, data flow, and rollback criteria?","answer":"Use a per-tenant project and separate datasets; expose a single endpoint with traffic-split by tenant via Vertex AI Endpoints with canary deployments per tenant. Store features per-tenant in Feature S","explanation":"## Why This Is Asked\n\nTests ability to design a scalable, compliant ML service with strict data isolation across tenants, a common real-world constraint.\n\n## Key Concepts\n\n- Multi-tenant data isolation and policy enforcement\n- Vertex AI Endpoints and canary deployments per tenant\n- Feature Store per-tenant featureviews and telemetry via Pub/Sub\n- Model Monitoring, drift-driven rollback, and cost controls\n\n## Code Example\n\n```python\n# Pseudo-code: create canary deployment per tenant (illustrative)\nfrom google.cloud import aiplatform\nendpoint = aiplatform.Endpoint(\".../endpoints/...\")\nendpoint.deploy_model(\n  display_name=\"tenant-a-canary\",\n  model_id=\"projects/.../models/...\",\n  dedicated_resources=None,\n  traffic_split={\"0\": 0.2, \"1\": 0.8},\n)\n```\n\n## Follow-up Questions\n\n- How would you design alerting thresholds for drift vs latency?\n- How would you test tenant-specific policy changes before rollout?\n","diagram":"flowchart TD\n  TenantIsolation[Tenant Isolation] --> Endpoint[Vertex AI Endpoint per Tenant]\n  Endpoint --> Canary[Canary Deploy per Tenant]\n  Canary --> Telemetry[Telemetry via Pub/Sub]\n  Telemetry --> Dataflow[Feature Ingestion & Materialization]\n  Endpoint --> Drift[Model Monitoring]\n  Drift --> Rollback[Auto Rollback on Drift/Latency]\n  Policy[Policy & Retention via Data Catalog/IAM] --> DataStore[Storage & Cost Controls]","difficulty":"intermediate","tags":["gcp-ml-engineer"],"channel":"gcp-ml-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:41:58.596Z","createdAt":"2026-01-12T16:41:58.596Z"},{"id":"gcp-ml-engineer-monitoring-1768260114416-0","question":"A Vertex AI endpoint is serving real-time inferences for a mission-critical model. You want to detect data drift and alert your team when drift exceeds a threshold. Which approach best achieves this with minimal operational overhead?","answer":"[{\"id\":\"a\",\"text\":\"Build a custom data drift detector by exporting incoming request data to Cloud Storage, compute statistics daily with Dataflow, and trigger Cloud Functions on anomalies.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Vertex AI Model Monitoring's Data Drift monitoring with deterministic thresholds and configure alerting policies in Cloud Monitoring.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Periodically run a manual review of incoming data in the UI and adjust thresholds manually.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Logging to search for anomalies in inference requests and create a dashboard.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is B because Vertex AI Model Monitoring provides built-in data drift detection across features, collects data statistics automatically, and can publish drift alerts via Cloud Monitoring. It minimizes operational overhead compared to a custom drift detector or manual reviews.\n\n## Why Other Options Are Wrong\n- A: describes a custom data drift detector requiring data export and daily batch processing; higher maintenance and latency.\n- C: manual review is not scalable and may miss rapid drift.\n- D: logging alone does not offer automatic drift metrics or alerting.\n\n## Key Concepts\n- Vertex AI Model Monitoring\n- Data drift detection\n- Cloud Monitoring alerts\n\n## Real-World Application\n- In production, you can rely on Vertex AI to continuously monitor feature distributions and alert on drift beyond thresholds, enabling faster remediation.","diagram":null,"difficulty":"intermediate","tags":["GCP","VertexAI","CloudMonitoring","Kubernetes","Terraform","EKS","certification-mcq","domain-weight-14"],"channel":"gcp-ml-engineer","subChannel":"monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:21:54.418Z","createdAt":"2026-01-12 23:21:54"},{"id":"gcp-ml-engineer-monitoring-1768260114416-1","question":"You deployed a Vertex AI endpoint in a GKE cluster and want to monitor latency percentiles and error rates in real time. Which combination of Google Cloud Monitoring features best supports this?","answer":"[{\"id\":\"a\",\"text\":\"Create a custom metric in Cloud Monitoring from endpoint logs and set an alert when p95 latency exceeds threshold.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Rely solely on Cloud Logging and build dashboards manually in Google Data Studio.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use Cloud Trace and Cloud Profiler to measure latency, ignoring logs.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use only built-in Vertex AI dashboards and avoid Cloud Monitoring.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because it enables real-time visibility into latency and error rates by exporting or deriving metrics used by Cloud Monitoring, enabling alerting and dashboards. Relying solely on logs or traces misses end-to-end visibility for ML endpoints, and ignoring Cloud Monitoring dashboards reduces proactive observability.\n\n## Why Other Options Are Wrong\n- B: Data Studio dashboards built from logs are not real-time and require manual maintenance.\n- C: Tracing and profiling help with code paths but do not provide end-to-end ML endpoint latency and error-rate metrics by themselves.\n- D: Vertex AI dashboards exist but do not replace the need for Cloud Monitoring for SLOs/alerts.\n\n## Key Concepts\n- Cloud Monitoring custom metrics\n- Vertex AI endpoint observability\n- SLIs and alerting\n\n## Real-World Application\n- Use this to maintain SLOs for a multi-region endpoint with real-time alerting.","diagram":null,"difficulty":"intermediate","tags":["GCP","VertexAI","CloudMonitoring","Kubernetes","Terraform","EKS","certification-mcq","domain-weight-14"],"channel":"gcp-ml-engineer","subChannel":"monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:21:54.830Z","createdAt":"2026-01-12 23:21:55"},{"id":"gcp-ml-engineer-monitoring-1768260114416-2","question":"In a model monitoring scenario, data quality metrics show a spike in missing values after a data source change. Which practice ensures you quickly identify and remediate the issue while meeting compliance requirements?","answer":"[{\"id\":\"a\",\"text\":\"Pause alerting and wait for manual review to avoid noisy alerts.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Vertex AI Data Quality Monitoring to automatically detect missing values and configure data quality thresholds; open an incident in Cloud Monitoring; set remediation steps.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Ignore the drift if model accuracy remains high.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Rebuild the model from scratch.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Vertex AI Data Quality Monitoring can automatically detect anomalies such as missing values, enforce data quality thresholds, and integrate with Cloud Monitoring for incident workflows, enabling rapid remediation while maintaining compliance audits.\n\n## Why Other Options Are Wrong\n- A: Pausing alerts delays detection of issues and does not ensure compliance.\n- C: Ignoring drift risks degraded performance or compliance issues.\n- D: Rebuilding the model is unnecessary and often wasteful.\n\n## Key Concepts\n- Data quality monitoring\n- Data drift vs data quality\n- Incident management integration\n\n## Real-World Application\n- During a source migration, automatic data quality monitoring flags issues early and accelerates remediation while keeping audits intact.","diagram":null,"difficulty":"intermediate","tags":["GCP","VertexAI","CloudMonitoring","Kubernetes","Terraform","EKS","certification-mcq","domain-weight-14"],"channel":"gcp-ml-engineer","subChannel":"monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:21:55.232Z","createdAt":"2026-01-12 23:21:55"},{"id":"gcp-ml-engineer-monitoring-1768260114416-3","question":"You want to ensure your ML inference service meets its SLOs in a multi-region deployment. Which monitoring strategy best supports SLO validation and cross-region alerting?","answer":"[{\"id\":\"a\",\"text\":\"Use Cloud Monitoring Service Level Objectives (SLOs) with SLI from Vertex AI endpoints and alert policies per region.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use a single global endpoint and global dashboards only.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Monitor only CPU utilization of the serving nodes.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable monitoring to reduce overhead.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because per-region SLIs and SLOs with alert policies enable accurate validation of performance across regions and timely notifications when thresholds are breached. A single global endpoint may hide regional issues.\n\n## Why Other Options Are Wrong\n- B: Global dashboards alone miss regional deviations.\n- C: CPU metrics alone do not measure user-facing latency or error rates.\n- D: Disabling monitoring defeats the purpose of ensuring SLOs.\n\n## Key Concepts\n- Service Level Objectives (SLOs)\n- Service Level Indicators (SLIs)\n- Multi-region observability\n\n## Real-World Application\n- Guarantees customer experience by surfacing regional performance issues quickly.","diagram":null,"difficulty":"intermediate","tags":["GCP","VertexAI","CloudMonitoring","Kubernetes","Terraform","EKS","certification-mcq","domain-weight-14"],"channel":"gcp-ml-engineer","subChannel":"monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:21:55.370Z","createdAt":"2026-01-12 23:21:55"},{"id":"gcp-ml-engineer-monitoring-1768260114416-4","question":"A compliance requirement mandates data-access auditing for features used in model scoring. Which monitoring/observability feature best supports this without impacting latency?","answer":"[{\"id\":\"a\",\"text\":\"Enable Cloud Audit Logs for Vertex AI and integrate with Cloud Monitoring dashboards for access metrics.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Collect all raw requests in memory on endpoint for auditing.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Disable all logs to minimize latency.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use external SQL database to log every inference.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is correct because Cloud Audit Logs capture access events and Vertex AI interactions, which can be aggregated in Cloud Monitoring dashboards for visibility and compliance auditing without adding runtime latency. The other options either add latency, reduce observability, or introduce unnecessary complexity.\n\n## Why Other Options Are Wrong\n- B: Keeping raw requests in memory harms latency and is not scalable.\n- C: Disabling logs eliminates auditing capabilities.\n- D: An external database can add latency and maintenance overhead without built-in integration.\n\n## Key Concepts\n- Cloud Audit Logs\n- Vertex AI access auditing\n- Observability integration\n\n## Real-World Application\n- Ensures traceable access for regulatory audits while preserving inference latency.","diagram":null,"difficulty":"intermediate","tags":["GCP","VertexAI","CloudAuditLogs","CloudMonitoring","Kubernetes","Terraform","EKS","certification-mcq","domain-weight-14"],"channel":"gcp-ml-engineer","subChannel":"monitoring","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:21:55.511Z","createdAt":"2026-01-12 23:21:55"},{"id":"gcp-ml-engineer-scaling-automation-1768224572525-0","question":"You’ve prototyped a ML model locally and want to scale it to production with traffic-based canary rollout to Vertex AI. Which deployment pattern best supports gradual traffic shift and autoscaling?","answer":"[{\"id\":\"a\",\"text\":\"Deploy as a single endpoint with fixed replicas\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy two model revisions behind a single Vertex AI Endpoint and split traffic 10/90\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Deploy the new model to a completely separate Endpoint and switch DNS\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use batch predictions only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B because Vertex AI Endpoints support traffic splitting and autoscaling, which enables canary deployments for gradual rollout while monitoring live metrics.\n\n## Why Other Options Are Wrong\n- A deploys a single endpoint with fixed replicas, which lacks dynamic autoscaling and traffic-based canary control.\n- C relies on DNS switch between endpoints, which is slow and brittle for real-time traffic routing.\n- D uses batch predictions, which are not suitable for live online inference at scale.\n\n## Key Concepts\n- Vertex AI Endpoints\n- Traffic splitting / canary deployments\n- Autoscaling\n\n## Real-World Application\n- In production, start with 10% traffic to the new model, monitor latency and accuracy, then progressively increase traffic and remove the old revision once metrics are satisfactory.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","AWS S3","AWS EC2","GKE","Vertex AI","Kubeflow","certification-mcq","domain-weight-18"],"channel":"gcp-ml-engineer","subChannel":"scaling-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:29:32.526Z","createdAt":"2026-01-12 13:29:32"},{"id":"gcp-ml-engineer-scaling-automation-1768224572525-1","question":"Your prototype needs sub-second scoring with regional low latency; you have traffic variability across regions. Which approach is most appropriate to ensure low latency and scalable inference?","answer":"[{\"id\":\"a\",\"text\":\"A single Vertex AI Endpoint in a single region and route through a CDN\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Multiple Vertex AI Endpoints deployed in several regions with a global load balancer directing traffic\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Cloud Functions to proxy requests to a single endpoint\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use batch predictions only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B because deploying endpoints in multiple regions and using a global load balancer directs requests to the nearest region, reducing latency while preserving scalability.\n\n## Why Other Options Are Wrong\n- A centralizes in one region, increasing latency for distant users.\n- C adds an extra hop and is not optimized for real-time, high-throughput inference.\n- D batch predictions are not suitable for sub-second, per-request scoring.\n\n## Key Concepts\n- Multi-region deployment\n- Global load balancing\n- Latency-sensitive inference\n\n## Real-World Application\n- Use this pattern when serving a worldwide user base to maintain consistent SLA across regions.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","AWS S3","AWS EC2","GKE","Vertex AI","Kubeflow","certification-mcq","domain-weight-18"],"channel":"gcp-ml-engineer","subChannel":"scaling-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:29:33.064Z","createdAt":"2026-01-12 13:29:33"},{"id":"gcp-ml-engineer-scaling-automation-1768224572525-2","question":"You want reproducibility and governance of ML experiments going to production; what pipeline approach ensures lineage, reproducibility, and auditability?","answer":"[{\"id\":\"a\",\"text\":\"Jupyter notebooks stored locally\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Vertex AI Pipelines with metadata store and artifact lineage\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Manual script logs in a storage bucket\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Spreading experiments across multiple Git branches only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B because Vertex AI Pipelines provides end-to-end workflow orchestration with metadata and lineage, enabling reproducibility and auditability.\n\n## Why Other Options Are Wrong\n- A lacks systematic reproducibility and governance.\n- C stores logs without explicit lineage and auditability.\n- D disperses experiments without centralized metadata or lineage tracking.\n\n## Key Concepts\n- Vertex AI Pipelines / Kubeflow Pipelines\n- Metadata store and artifact lineage\n\n## Real-World Application\n- Use pipelines to version data preprocessing, training, and deployment steps with attached lineage for audits.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","AWS S3","AWS EC2","GKE","Vertex AI","Kubeflow","certification-mcq","domain-weight-18"],"channel":"gcp-ml-engineer","subChannel":"scaling-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:29:33.590Z","createdAt":"2026-01-12 13:29:33"},{"id":"gcp-ml-engineer-scaling-automation-1768224572525-3","question":"To optimize costs for ephemeral prototypes with sporadic traffic, which deployment pattern best balances cost and availability?","answer":"[{\"id\":\"a\",\"text\":\"Keep all models loaded on a fixed number of replicas\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Vertex AI Endpoints with autoscaling (minReplicas and maxReplicas) and canary traffic\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Keep warm instances always on in a single region\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Convert to batch inference only\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B because autoscaling with defined min and max replicas balances cost during idle periods while ensuring responsiveness during traffic spikes.\n\n## Why Other Options Are Wrong\n- A maintains constant resources, increasing cost.\n- C keeps resources on regardless of demand, wasting capacity during quiet periods.\n- D reduces real-time serving capabilities, which harms user experience for active deployments.\n\n## Key Concepts\n- Autoscaling endpoints\n- Min/max replicas\n- Canary traffic\n\n## Real-World Application\n- For models with irregular traffic, leverage autoscaling to scale down during idle times and ramp up during events.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","AWS S3","AWS EC2","GKE","Vertex AI","Kubeflow","certification-mcq","domain-weight-18"],"channel":"gcp-ml-engineer","subChannel":"scaling-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:29:33.772Z","createdAt":"2026-01-12 13:29:33"},{"id":"gcp-ml-engineer-scaling-automation-1768224572525-4","question":"You need to monitor data drift and trigger retraining automatically after deployment; which approach provides automated drift detection and end-to-end retraining pipeline?","answer":"[{\"id\":\"a\",\"text\":\"Manual quarterly reviews\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Vertex AI Model Monitoring with drift detection and a retraining pipeline triggered by alerts\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on evaluation dataset accuracy monitoring only\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Hard-code drift thresholds in application code\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct answer is B because Model Monitoring detects drift in production data and can trigger retraining pipelines, enabling automated governance for production models.\n\n## Why Other Options Are Wrong\n- A delays detection and retraining opportunities.\n- C relies only on historical evaluation metrics and may miss real-time drift.\n- D thresholds embedded in code can become stale and miss evolving data patterns.\n\n## Key Concepts\n- Vertex AI Model Monitoring\n- Drift detection\n- Retraining pipelines\n\n## Real-World Application\n- Configure drift alerts to automatically start a retraining workflow with updated data and validated pipelines.","diagram":null,"difficulty":"intermediate","tags":["Kubernetes","Terraform","AWS S3","AWS EC2","GKE","Vertex AI","Kubeflow","certification-mcq","domain-weight-18"],"channel":"gcp-ml-engineer","subChannel":"scaling-automation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:29:33.954Z","createdAt":"2026-01-12 13:29:34"},{"id":"gcp-ml-engineer-serving-scaling-1768199588961-0","question":"An online inference endpoint for a sentiment-analysis model receives sudden surges during a marketing campaign. The team wants to maintain median latency under 120 ms at up to 2k QPS while avoiding over-provisioning. You have a Vertex AI Endpoint. Which configuration best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Disable autoscaling and fix the endpoint to 10 replicas\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Configure automatic scaling with min_replica = 2, max_replica = 50, and target_cpu_utilization = 60%\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Deploy a separate replica in a distant region to reduce latency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use batch predictions during bursts to handle high traffic\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe best approach is to configure automatic scaling with sensible min and max replicas and a target CPU utilization. This lets Vertex AI scale in response to actual load, keeping latency under control while avoiding over-provisioning.\n\n## Why Other Options Are Wrong\n- Option A: Manual scaling cannot adapt to spikes and risks under- or over-provisioning.\n- Option C: Regional distribution may affect latency but does not address per-request scaling during spikes and increases complexity.\n- Option D: Batch predictions are not suitable for real-time latency guarantees.\n\n## Key Concepts\n- Vertex AI endpoint automatic scaling\n- min_replica and max_replica configuration\n- target_cpu_utilization as a scaling signal\n\n## Real-World Application\n- Apply to a live inference endpoint for real-time user requests during campaigns; monitor latency and adjust min/max replicas as needed.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Kubernetes","AWS","Terraform","GKE","certification-mcq","domain-weight-19"],"channel":"gcp-ml-engineer","subChannel":"serving-scaling","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:08.963Z","createdAt":"2026-01-12 06:33:09"},{"id":"gcp-ml-engineer-serving-scaling-1768199588961-1","question":"During a model update, a data-science team wants to canary-test a new version while continuing to serve existing traffic with minimal risk. Which approach should they use in Vertex AI?","answer":"[{\"id\":\"a\",\"text\":\"Create a new endpoint and deploy only the new model version; route traffic there later\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Deploy both versions to the same endpoint and use traffic_split to gradually shift traffic to the new version\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Stop traffic to the old version and roll out the new version immediately\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Deploy the new version to a separate endpoint and disable the older endpoint\",\"isCorrect\":false}]","explanation":"## Correct Answer\nDeploy both versions to the same endpoint and use traffic_split to gradually shift traffic to the new version. This enables canary testing with real traffic while maintaining the current version as a safety fallback.\n\n## Why Other Options Are Wrong\n- Option A: A new endpoint would split management and make gradual traffic control harder.\n- Option C: Stopping all traffic to old version risks service disruption.\n- Option D: A separate endpoint increases coordination overhead and is less safe for canary tests.\n\n## Key Concepts\n- Vertex AI endpoint traffic_split across deployed_models\n- Canary testing with phased traffic\n- Endpoint-level deployment management\n\n## Real-World Application\n- Roll out a model update with 10–20% canary traffic, monitor KPIs, then increase if metrics are satisfactory.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Kubernetes","AWS","Terraform","GKE","certification-mcq","domain-weight-19"],"channel":"gcp-ml-engineer","subChannel":"serving-scaling","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:09.508Z","createdAt":"2026-01-12 06:33:09"},{"id":"gcp-ml-engineer-serving-scaling-1768199588961-2","question":"A model deployed on Vertex AI Endpoint exhibits high cold-start latency for the first request after deployment. Which practice is recommended to minimize cold-start latency in production?","answer":"[{\"id\":\"a\",\"text\":\"Set min_replica to a non-zero value to keep instances warm\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase max_replica to a very large number to ensure enough instances\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Pre-warm by sending test requests during deployment without relying on autoscaling\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Switch to batch predictions to avoid online latency\",\"isCorrect\":false}]","explanation":"## Correct Answer\nSetting min_replica to a non-zero value keeps at least some instances warm, reducing cold-start latency for the first requests after deployment.\n\n## Why Other Options Are Wrong\n- Option B: Over-provisioning by raising max_replica increases costs and may not reduce cold-start latency meaningfully.\n- Option C: Pre-warming can help but Vertex AI does not guarantee consistent warm-start without non-zero min_replica; it’s less reliable than always-warm replicas.\n- Option D: Batch predictions do not serve real-time latency-sensitive requests.\n\n## Key Concepts\n- Warm-start vs cold-start latency\n- min_replica as a stabilizing factor\n- Online predictions vs batch predictions\n\n## Real-World Application\n- After deploying critical inference endpoints, configure min_replica to maintain service level KPIs during traffic peaks.","diagram":null,"difficulty":"intermediate","tags":["Vertex AI","Kubernetes","AWS","Terraform","GKE","certification-mcq","domain-weight-19"],"channel":"gcp-ml-engineer","subChannel":"serving-scaling","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T06:33:10.029Z","createdAt":"2026-01-12 06:33:10"}],"subChannels":["architect-ml","automate-orchestrate","data-prep","general","monitoring","scaling-automation","serving-scaling"],"companies":["Airbnb","Amazon","Cloudflare","Discord","Goldman Sachs","Lyft","Meta","Oracle","PayPal","Scale Ai","Snap","Snowflake","Tesla","Twitter","Two Sigma"],"stats":{"total":33,"beginner":3,"intermediate":27,"advanced":3,"newThisWeek":33}}