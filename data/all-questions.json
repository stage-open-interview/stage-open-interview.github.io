[{"id":"q-1158","question":"How would you implement a health check mechanism for a load balancer that uses exponential backoff for failed servers, and how does this approach prevent cascading failures during partial outages?","channel":"algorithms","subChannel":"algorithms","difficulty":"intermediate","tags":["load-balancing","health-checks","exponential-backoff","fault-tolerance","cascading-failures"],"companies":[]},{"id":"q-653","question":"How would you implement a consistent hashing load balancer that handles server additions and removals with minimal key remapping? What data structures would you use and how would you handle virtual nodes?","channel":"algorithms","subChannel":"algorithms","difficulty":"intermediate","tags":["consistent-hashing","load-balancing","distributed-systems","hash-ring","virtual-nodes"],"companies":[]},{"id":"q-659","question":"How would you implement a consistent hashing load balancer and what advantages does it provide over traditional hash-based load balancing when servers are added or removed?","channel":"algorithms","subChannel":"algorithms","difficulty":"intermediate","tags":["load-balancing","consistent-hashing","distributed-systems","scalability"],"companies":[]},{"id":"q-767","question":"Design a load balancer that implements adaptive load balancing using real-time server metrics. How would you collect and weight server performance data, and what algorithm would you use to dynamically adjust traffic distribution?","channel":"algorithms","subChannel":"algorithms","difficulty":"intermediate","tags":["adaptive-load-balancing","performance-monitoring","dynamic-weighting","real-time-metrics"],"companies":[]},{"id":"al-1","question":"When would you choose a Linked List over an Array and what are the key trade-offs for each data structure?","channel":"algorithms","subChannel":"data-structures","difficulty":"beginner","tags":["struct","comparison","basics"],"companies":["Adobe","Amazon","Apple","Google","Meta","Microsoft"]},{"id":"al-165","question":"Implement a Trie data structure for efficient prefix search with insert, search, and startsWith operations. What are its advantages over hash maps for autocomplete systems, and what are the trade-offs?","channel":"algorithms","subChannel":"data-structures","difficulty":"intermediate","tags":["struct","basics"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-187","question":"How would you implement a thread-safe LRU cache using a HashMap and DoublyLinkedList, considering eviction policy and O(1) operations?","channel":"algorithms","subChannel":"data-structures","difficulty":"intermediate","tags":["arrays","linkedlist","hashtable","heap"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Uber"]},{"id":"q-277","question":"How would you efficiently process a 50GB log file to extract the top 10 most frequent IP addresses from millions of entries while handling memory constraints and optimizing for performance?","channel":"algorithms","subChannel":"data-structures","difficulty":"advanced","tags":["find","xargs","cut","sort"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Snowflake"]},{"id":"q-377","question":"Implement a min-heap using an array that supports insert, extractMin, and peek operations in O(log n) time. Include time/space complexity analysis and edge cases?","channel":"algorithms","subChannel":"data-structures","difficulty":"beginner","tags":["arrays","linkedlist","hashtable","heap"],"companies":null},{"id":"q-407","question":"Given a stream of log events with timestamps, design an algorithm to find the top K most frequent error messages in the last N minutes using O(K) space, where each event contains timestamp, error type, and message?","channel":"algorithms","subChannel":"data-structures","difficulty":"intermediate","tags":["arrays","linkedlist","hashtable","heap"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-418","question":"Design a data structure that supports range sum queries and point updates on a dynamic array with O(log n) operations. How would you implement this using a segment tree, and what are the trade-offs compared to a Binary Indexed Tree?","channel":"algorithms","subChannel":"data-structures","difficulty":"advanced","tags":["bst","avl","trie","segment-tree"],"companies":null},{"id":"q-425","question":"Given an array of integers and a target sum, find two numbers that add up to the target. How would you implement this efficiently and what's the time complexity?","channel":"algorithms","subChannel":"data-structures","difficulty":"beginner","tags":["arrays","linkedlist","hashtable","heap"],"companies":["Adobe","Amazon","Two Sigma"]},{"id":"q-442","question":"Given a stream of user actions with timestamps, design a system to find the top K most frequent actions in the last N minutes using O(1) time per query?","channel":"algorithms","subChannel":"data-structures","difficulty":"intermediate","tags":["arrays","linkedlist","hashtable","heap"],"companies":["LinkedIn","OpenAI"]},{"id":"q-565","question":"Given a stream of timestamped events, find the maximum number of concurrent events at any time?","channel":"algorithms","subChannel":"data-structures","difficulty":"advanced","tags":["arrays","linkedlist","hashtable","heap"],"companies":["Salesforce","Slack","Square"]},{"id":"al-152","question":"You have a staircase with n steps. You can climb 1, 2, or 3 steps at a time. How many distinct ways can you reach the top? Implement a solution with O(n) time and O(1) space?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"intermediate","tags":["dp","optimization"],"companies":null},{"id":"al-166","question":"Given a string, find the minimum cost to transform it into a palindrome where insertions cost 2 and deletions cost 1. What is the optimal dynamic programming approach?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"intermediate","tags":["dp","optimization"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"al-167","question":"Given a target sum n, count the number of ways to reach it using dice rolls where each roll can be 1-6. Return the result modulo 10^9+7. Optimize for O(n) time and O(1) space?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"intermediate","tags":["dp","optimization"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"al-170","question":"Given an array of integers where each element represents the maximum number of steps you can jump forward from that position, find the minimum number of jumps required to reach the last index. If it's not possible to reach the end, return -1. How would you implement this efficiently?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"advanced","tags":["dp","optimization"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"al-3","question":"What is Dynamic Programming and how does it differ from plain recursion? When would you choose one over the other?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"advanced","tags":["dp","optimization","theory"],"companies":["Amazon","Google","Meta"]},{"id":"q-328","question":"Given a grid of size m x n where each cell contains a non-negative integer representing the cost to enter that cell, find the minimum cost path from the top-left corner (0,0) to the bottom-right corner (m-1,n-1) moving only right or down. Return both the minimum cost and the path itself?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"intermediate","tags":["dp","memoization","tabulation"],"companies":["Amazon","Apple","Google","Meta","Microsoft","NVIDIA"]},{"id":"q-440","question":"Given a string s and dictionary wordDict, return all possible sentences where s can be segmented into space-separated words from wordDict. Handle overlapping subproblems efficiently?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"advanced","tags":["dp","memoization","tabulation"],"companies":["Adobe","Google","NVIDIA"]},{"id":"q-540","question":"Given a string s and a dictionary wordDict, return all possible sentences formed by inserting spaces in s such that each word exists in wordDict. Use DP with memoization to avoid exponential recomputation?","channel":"algorithms","subChannel":"dynamic-programming","difficulty":"advanced","tags":["dp","memoization","tabulation"],"companies":["Goldman Sachs","LinkedIn","Slack"]},{"id":"q-214","question":"Given a directed weighted graph with up to 10^6 edges and frequent edge weight updates, design a data structure that supports dynamic shortest path queries with sub-millisecond response time?","channel":"algorithms","subChannel":"graphs","difficulty":"advanced","tags":["bfs","dfs","dijkstra","topological"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Uber"]},{"id":"q-286","question":"Explain the difference between BFS and DFS and when would you use each?","channel":"algorithms","subChannel":"graphs","difficulty":"intermediate","tags":["bfs","dfs","dijkstra","topological"],"companies":["Amazon","Google","Meta"]},{"id":"q-350","question":"Given a directed graph representing city intersections and one-way streets, implement a function to find if there's a valid route from point A to point B using BFS. Return the shortest path distance or -1 if no route exists?","channel":"algorithms","subChannel":"graphs","difficulty":"beginner","tags":["bfs","dfs","dijkstra","topological"],"companies":["Amazon","Apple","Cruise","Google","Meta","Microsoft","Netflix","Vercel"]},{"id":"q-394","question":"Given a directed acyclic graph representing task dependencies where each task takes 1 unit of time and you have unlimited workers, what is the minimum time to complete all tasks?","channel":"algorithms","subChannel":"graphs","difficulty":"advanced","tags":["bfs","dfs","dijkstra","topological"],"companies":null},{"id":"q-662","question":"Given a directed graph with N nodes and M weighted edges (positive weights) and a source s, describe an implementation to (1) identify nodes reachable from s via BFS, (2) compute shortest distances dist[] to all nodes with Dijkstra, and (3) count the number of distinct shortest s→v paths for every v (mod 1e9+7). How would you build a DAG of edges on shortest paths and perform a topological DP over dist-ordered nodes to obtain path counts?","channel":"algorithms","subChannel":"graphs","difficulty":"advanced","tags":["bfs","dfs","dijkstra","topological"],"companies":["Anthropic","NVIDIA","Robinhood"]},{"id":"q-596","question":"Explain the differences between round-robin, least connections, and IP hash load balancing algorithms. When would you choose each one?","channel":"algorithms","subChannel":"load-balancing-algorithms","difficulty":"intermediate","tags":["load-balancing","algorithms","networking","scalability","system-design"],"companies":["Google","Amazon","Meta","Netflix","Microsoft","Twitter","Uber","Airbnb"]},{"id":"q-627","question":"Explain the difference between round-robin and weighted round-robin load balancing algorithms. When would you choose one over the other?","channel":"algorithms","subChannel":"load-balancing-algorithms","difficulty":"intermediate","tags":["load-balancing","algorithms","distributed-systems","networking"],"companies":["Amazon","Google","Microsoft","Netflix","Facebook","Twitter"]},{"id":"al-163","question":"You have an array where each element appears twice except one element that appears once. Sort the array in O(n) time without using extra space for sorting. How would you approach this?","channel":"algorithms","subChannel":"sorting","difficulty":"intermediate","tags":["sort","complexity"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"al-2","question":"Compare QuickSort, MergeSort, and Timsort. When would you choose each algorithm and what are their key trade-offs in production systems?","channel":"algorithms","subChannel":"sorting","difficulty":"intermediate","tags":["sort","recursion","complexity"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-300","question":"Explain the difference between quicksort and mergesort, including their time and space complexities?","channel":"algorithms","subChannel":"sorting","difficulty":"beginner","tags":["quicksort","mergesort","complexity"],"companies":["Amazon","Google","Meta"]},{"id":"q-362","question":"Given an array of integers, implement quicksort with proper partitioning, explain its O(n log n) average vs O(n²) worst-case complexity, and compare with mergesort in terms of stability, space usage, and practical performance?","channel":"algorithms","subChannel":"sorting","difficulty":"beginner","tags":["quicksort","mergesort","complexity"],"companies":null},{"id":"q-433","question":"Implement quicksort and explain when you'd choose it over mergesort. What's the worst-case scenario and how do you avoid it?","channel":"algorithms","subChannel":"sorting","difficulty":"beginner","tags":["quicksort","mergesort","complexity"],"companies":["Hashicorp","Oracle","Snowflake"]},{"id":"q-167","question":"Write a function to find the maximum depth of a binary tree using both recursive DFS and iterative BFS approaches. Discuss time/space complexity and handle edge cases?","channel":"algorithms","subChannel":"trees","difficulty":"beginner","tags":["tree","binary"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-314","question":"Given a binary search tree with n nodes, find the kth smallest element where 1 ≤ k ≤ n. Discuss both recursive and iterative approaches with their time and space complexities?","channel":"algorithms","subChannel":"trees","difficulty":"beginner","tags":["bst","avl","trie","segment-tree"],"companies":null},{"id":"q-340","question":"Given a BST that may have duplicate values, implement a function to find the kth smallest element considering duplicates. What's the time complexity and how would you handle edge cases?","channel":"algorithms","subChannel":"trees","difficulty":"intermediate","tags":["bst","avl","trie","segment-tree"],"companies":["Hrt","New Relic","Sap"]},{"id":"q-451","question":"Given a BST, write a function to find the kth smallest element using O(h) space and O(n) time, where h is height and n is nodes?","channel":"algorithms","subChannel":"trees","difficulty":"beginner","tags":["bst","avl","trie","segment-tree"],"companies":["Anthropic","Cloudflare"]},{"id":"q-660","question":"You’re building a chat app that autocompletes words as users type. Implement a Trie with insert(word), search(word), and startsWith(prefix). Provide a compact JavaScript class with these methods, assuming lowercase a-z. After inserting 'apple','app','application', does search('app') return true and does startsWith('appl') return true?","channel":"algorithms","subChannel":"trees","difficulty":"beginner","tags":["bst","avl","trie","segment-tree"],"companies":["Cloudflare","IBM","Slack"]},{"id":"q-258","question":"How would you design a reactive Android ViewModel using StateFlow with sealed classes to handle network API responses, ensuring proper error handling and loading states?","channel":"android","subChannel":"architecture","difficulty":"intermediate","tags":["coroutines","flow","sealed-classes"],"companies":["Airbnb","Google","Meta","Microsoft","Uber"]},{"id":"q-1022","question":"You're building an Android field-inspection app where users collect forms and photos offline. When connectivity returns, design a robust sync engine that uploads only new or updated items, resolves conflicts via last_modified, and handles intermittent networks. Use WorkManager with network constraints and a foreground service for long syncs; include backoff and tests?","channel":"android","subChannel":"general","difficulty":"intermediate","tags":["android"],"companies":["Airbnb","Goldman Sachs","Scale Ai"]},{"id":"q-1127","question":"Design a beginner Android feature: a simple offline notes app. Notes stored in Room with fields id, text, tag, last_modified. Provide a tag-based search, and a background export to cloud via WorkManager that runs only on WiFi and while charging. Ensure deduplication by last_modified, handle restarts, and outline a minimal test plan?","channel":"android","subChannel":"general","difficulty":"beginner","tags":["android"],"companies":["Anthropic","Robinhood"]},{"id":"q-1143","question":"You’re building a chat-like Android app. Messages are stored in Room with fields: id (UUID), text (String), timestamp (Long), status (pending, sending, sent, failed). When sending, insert a pending message and enqueue a WorkManager task to upload unsent messages when online, using exponential backoff. On success, save serverId and set status to sent; on failure, keep failed with a retriable option. Outline the data flow, DAO/Worker skeleton, and offline→online test plan?","channel":"android","subChannel":"general","difficulty":"beginner","tags":["android"],"companies":["Snowflake","Twitter"]},{"id":"q-1267","question":"You're building an Android offline-first app that records field observations (id, timestamp, value) in Room. Changes are queued when offline and synced to a REST backend when online. Implement a robust sync with versioning, conflict resolution (server-wins, client-wins, or merge), and tombstones. Describe data flow, DAO/Repository, a WorkManager worker, and a testing strategy for edge cases like concurrent edits and delayed pushes?","channel":"android","subChannel":"general","difficulty":"intermediate","tags":["android"],"companies":["Cloudflare","Hugging Face","Tesla"]},{"id":"q-452","question":"How would you implement a RecyclerView with multiple view types while maintaining smooth scrolling performance on large datasets?","channel":"android","subChannel":"general","difficulty":"intermediate","tags":["android"],"companies":["Adobe","Citadel","Google"]},{"id":"q-482","question":"How would you handle Activity lifecycle when screen rotates and you need to preserve user input data?","channel":"android","subChannel":"general","difficulty":"beginner","tags":["android"],"companies":["Amazon","Google","Oracle"]},{"id":"q-512","question":"How would you implement a simple RecyclerView in Android to display a list of user profiles with name and email?","channel":"android","subChannel":"general","difficulty":"beginner","tags":["android"],"companies":["MongoDB","Tesla","Two Sigma"]},{"id":"q-541","question":"How would you implement a RecyclerView with ViewHolder pattern to display a list of user profiles efficiently?","channel":"android","subChannel":"general","difficulty":"beginner","tags":["android"],"companies":["Databricks","Goldman Sachs","Tesla"]},{"id":"q-976","question":"You are building an Android app that tracks a delivery ride; location updates every 5 seconds; battery life; Doze; Provide plan using FusedLocationProvider, ForegroundService, and WorkManager; include backoff; testing; intermittent connectivity?","channel":"android","subChannel":"general","difficulty":"intermediate","tags":["android"],"companies":["Goldman Sachs","Oracle","Uber"]},{"id":"q-205","question":"How would you implement Compose Navigation with nested graphs, shared ViewModels, configuration change handling, and deep linking in a production Android app?","channel":"android","subChannel":"jetpack-compose","difficulty":"intermediate","tags":["composables","state","navigation"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-182","question":"What is the first lifecycle method called when an Android Activity is created, and what critical initialization tasks must be performed within it?","channel":"android","subChannel":"lifecycle","difficulty":"beginner","tags":["lifecycle","components"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-236","question":"How would you implement a comprehensive contract testing strategy using MSW (Mock Service Worker) with OpenAPI to ensure frontend API mocks stay synchronized with backend specifications, including CI/CD integration and drift detection?","channel":"api-testing","subChannel":"contract-testing","difficulty":"intermediate","tags":["wiremock","mockserver","msw"],"companies":["Amazon","Microsoft","Netflix","Salesforce","Square","Stripe"]},{"id":"q-1030","question":"Design a test strategy for an API gateway that enforces per-tenant sliding-window rate limits with dynamic quotas updated via admin API. Outline how you'd simulate high-concurrency traffic, verify quota propagation across nodes, validate headers and 429 responses, and test failure modes (Redis outage or misconfig). Include concrete test cases and tooling suggestions?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Citadel","Google","Meta"]},{"id":"q-1050","question":"Design an automated test plan for a REST + streaming API: /inventory/{sku}/status returns current stock via a streaming endpoint /inventory/stream (Server-Sent Events). The plan should cover stream resilience, event deduplication, per-warehouse aggregation under bursts, and failure modes when downstream storage becomes partially unavailable. Provide concrete test cases, tooling suggestions, and expected outcomes, with emphasis on realism for high-scale retail backends?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Amazon","Apple","DoorDash"]},{"id":"q-1061","question":"Design a practical test plan for a GraphQL API that aggregates data from products, pricing, and reviews. Include how you validate query depth limits, detect N+1 issues, test caching and cache invalidation under high concurrency, and ensure partial responses when some downstream services fail. Provide concrete test cases and tooling?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Instacart","NVIDIA","PayPal"]},{"id":"q-1166","question":"You manage a public REST API with versioning: /v1/... and /v2/... Design a practical, automated test plan to validate backward compatibility as v2 introduces a new field (tags) and changes a field type (price from int to decimal). Include concrete test cases, OpenAPI contract checks, cross-version schema validation, and how to verify deprecation behavior via a warnings header and 429s for old clients. Outline tooling and steps?","channel":"api-testing","subChannel":"general","difficulty":"beginner","tags":["api-testing"],"companies":["Google","Lyft","NVIDIA"]},{"id":"q-1251","question":"You're testing an inventory REST API for a global retail platform. `/inventory/{sku}` returns current stock and scheduled restock ETA from a separate availability service that uses eventual consistency and a message bus (Kafka). Design a practical test plan to verify consistency windows, eventual accuracy under bursts, and cross-region cache coherency, including late-arriving events, out-of-order messages, and failure modes of Kafka and Redis caching. Include concrete test cases, tooling, and expected outcomes?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Discord","Square"]},{"id":"q-1284","question":"You maintain a simple REST API with POST /checkout that creates a payment intent for a cart. As a beginner, outline an end-to-end test plan to verify input validation, idempotent retries, and error handling under transient failures. Include concrete test cases, tooling suggestions, and expected responses?","channel":"api-testing","subChannel":"general","difficulty":"beginner","tags":["api-testing"],"companies":["DoorDash","MongoDB"]},{"id":"q-453","question":"You're testing a REST API that returns paginated results. The endpoint has a rate limit of 100 requests per minute and sometimes returns 500 errors under load. How would you design a comprehensive test strategy?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Airbnb","Google","Lyft"]},{"id":"q-483","question":"You're testing a REST API that returns paginated results. How would you design a comprehensive test strategy to verify pagination works correctly across different page sizes and edge cases?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Discord","Netflix","Salesforce"]},{"id":"q-513","question":"How would you test a REST API endpoint that returns user data, including both success and error scenarios?","channel":"api-testing","subChannel":"general","difficulty":"beginner","tags":["api-testing"],"companies":["Bloomberg","OpenAI"]},{"id":"q-542","question":"You're testing a payment API that processes transactions. How would you design test cases to verify idempotency, and what specific HTTP status codes would you expect for duplicate requests?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Cloudflare","NVIDIA","Stripe"]},{"id":"q-566","question":"How would you design a comprehensive API testing strategy for a machine learning model deployment pipeline that handles real-time inference requests?","channel":"api-testing","subChannel":"general","difficulty":"advanced","tags":["api-testing"],"companies":["Goldman Sachs","Hugging Face","Snap"]},{"id":"q-909","question":"Design a practical test plan for an asynchronous data ingestion API: POST / ing est accepts CSV payload and returns 202 with a job_id. It enqueues to a queue, then a worker writes to storage and updates a /status/{job_id} endpoint. Some tenants require PII redaction controlled by a tenant flag; a 'force' param bypasses CSV schema validation. Outline concrete test cases to verify correctness, privacy, idempotency, race conditions, and failure modes when queue or storage fail. Include sample CSV payloads and expected outcomes?","channel":"api-testing","subChannel":"general","difficulty":"intermediate","tags":["api-testing"],"companies":["Robinhood","Snowflake","Two Sigma"]},{"id":"q-209","question":"How would you design a REST API testing framework that handles rate limiting, circuit breaking, and distributed tracing for microservices with 10,000+ concurrent requests?","channel":"api-testing","subChannel":"rest-testing","difficulty":"advanced","tags":["postman","rest-assured","supertest"],"companies":["Amazon","Goldman Sachs","Microsoft","Netflix","Stripe"]},{"id":"gh-12","question":"What are the three main service models of cloud computing and how do they differ?","channel":"aws","subChannel":"compute","difficulty":"beginner","tags":["cloud","aws","azure","gcp"],"companies":["Amazon","Google","Meta"]},{"id":"gh-13","question":"What is AWS (Amazon Web Services)?","channel":"aws","subChannel":"compute","difficulty":"beginner","tags":["cloud","aws","azure","gcp"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Netflix"]},{"id":"gh-15","question":"Compare AWS IaaS, PaaS, and SaaS service models with specific examples and use cases?","channel":"aws","subChannel":"compute","difficulty":"intermediate","tags":["cloud","aws","azure","gcp"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-34","question":"How would you design an Auto Scaling configuration for a high-traffic e-commerce application that handles 10,000 RPS with 99.99% availability, including scaling policies, health checks, and cost optimization?","channel":"aws","subChannel":"compute","difficulty":"advanced","tags":["scale","ha"],"companies":null},{"id":"gh-57","question":"What is Cloud Cost Optimization and what are the key strategies to reduce cloud spending in production environments?","channel":"aws","subChannel":"compute","difficulty":"beginner","tags":["finops","cost"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-58","question":"What are AWS Reserved Instances and how do they compare to On-Demand pricing?","channel":"aws","subChannel":"compute","difficulty":"intermediate","tags":["finops","cost"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Uber"]},{"id":"gh-83","question":"How do you evaluate cloud services for business needs using TCO analysis, SLA metrics, and migration strategies?","channel":"aws","subChannel":"compute","difficulty":"advanced","tags":["migration","cloud"],"companies":["Amazon","Google","IBM","Microsoft","Oracle","Salesforce"]},{"id":"gh-85","question":"How do cloud migration tools automate application and data transfer between on-premise and cloud environments, and what are the key technical challenges in ensuring data consistency and minimal downtime?","channel":"aws","subChannel":"compute","difficulty":"intermediate","tags":["migration","cloud"],"companies":["Amazon","Citadel","Goldman Sachs","Google","Microsoft"]},{"id":"gh-87","question":"How would you implement a multi-cloud cost allocation system using tagging strategies and automation APIs?","channel":"aws","subChannel":"compute","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Stripe","Uber"]},{"id":"q-174","question":"You have an EC2 instance that suddenly becomes unresponsive. What step-by-step troubleshooting methodology would you follow, which specific AWS tools and commands would you use at each stage, and how would you handle different instance states and recovery scenarios?","channel":"aws","subChannel":"compute","difficulty":"intermediate","tags":["ec2","compute"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-321","question":"You have a containerized web application that needs to handle variable traffic loads. When would you choose ECS Fargate over EKS and what are the key trade-offs?","channel":"aws","subChannel":"compute","difficulty":"beginner","tags":["ec2","ecs","eks","fargate"],"companies":["Cloudflare","Figma","MongoDB"]},{"id":"q-216","question":"How would you design an eventual consistency strategy for a multi-region DynamoDB application using Global Tables to handle write conflicts, ensure data convergence, and minimize latency?","channel":"aws","subChannel":"database","difficulty":"intermediate","tags":["mongodb","dynamodb","cassandra","redis"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-357","question":"You're designing a security monitoring system that needs to store 10M+ events per day with millisecond read latency. How would you choose between DynamoDB, Aurora, and ElastiCache, and what's your data partitioning strategy?","channel":"aws","subChannel":"database","difficulty":"intermediate","tags":["rds","aurora","dynamodb","elasticache"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix","Palo Alto Networks"]},{"id":"q-401","question":"You're designing a real-time analytics dashboard for Scale AI that needs to handle 10,000 events/second. Your team is debating between using DynamoDB with DAX vs. Aurora with ElastiCache. What are the key trade-offs you'd consider, and which would you choose for this use case?","channel":"aws","subChannel":"database","difficulty":"intermediate","tags":["rds","aurora","dynamodb","elasticache"],"companies":["Cohere","Oscar Health","Scale Ai"]},{"id":"q-413","question":"You're designing a real-time analytics dashboard for an IoT application that receives 10,000 events per second. The dashboard needs to show current metrics and historical trends. How would you design the database architecture using AWS services, and what caching strategy would you implement?","channel":"aws","subChannel":"database","difficulty":"intermediate","tags":["rds","aurora","dynamodb","elasticache"],"companies":["Amazon","Apple","Databricks","Google","Micron","Microsoft","Netflix","Snowflake"]},{"id":"q-1256","question":"You're operating a global real-time analytics pipeline on AWS: data streams from mobile apps ingest via Kinesis Data Streams, processed by Lambda, stored in DynamoDB and S3 Parquet. A new release causes timeouts and duplicate processing under peak load. Propose a concrete plan to fix cold starts and throttling, ensure exactly-once semantics, and safely deploy with minimal data loss. Include services, config values, and rollout steps?","channel":"aws","subChannel":"general","difficulty":"advanced","tags":["aws"],"companies":["Amazon","Robinhood","Two Sigma"]},{"id":"q-454","question":"You need to host a static website with high availability and low latency globally. How would you configure AWS S3 and CloudFront to achieve this?","channel":"aws","subChannel":"general","difficulty":"beginner","tags":["aws"],"companies":["Cloudflare","Google","Netflix"]},{"id":"q-484","question":"You're designing a real-time ML inference pipeline on AWS that must process 10,000 requests/second with sub-100ms latency. How would you architect this using serverless components, and what trade-offs would you consider?","channel":"aws","subChannel":"general","difficulty":"advanced","tags":["aws"],"companies":["Databricks","Hugging Face","Snowflake"]},{"id":"q-514","question":"You're building a serverless application that needs to process user uploads. How would you design an architecture using S3, Lambda, and API Gateway to handle file uploads securely and efficiently?","channel":"aws","subChannel":"general","difficulty":"beginner","tags":["aws"],"companies":["OpenAI","Stripe"]},{"id":"q-543","question":"You're deploying a microservices application on AWS ECS. One service is experiencing intermittent 503 errors during peak traffic. How would you diagnose and resolve this issue?","channel":"aws","subChannel":"general","difficulty":"intermediate","tags":["aws"],"companies":["Apple","Bloomberg","Meta"]},{"id":"q-567","question":"How would you design a multi-region serverless architecture for a real-time chat application using AWS services, ensuring low latency and high availability?","channel":"aws","subChannel":"general","difficulty":"advanced","tags":["aws"],"companies":["Slack","Tesla"]},{"id":"q-220","question":"How would you design a multi-AZ VPC architecture with Route53 latency-based routing to CloudFront, ALB, and private EC2 instances while ensuring failover within 30 seconds?","channel":"aws","subChannel":"networking","difficulty":"intermediate","tags":["vpc","route53","cloudfront","alb"],"companies":["Amazon","Databricks","Goldman Sachs","Microsoft","Netflix"]},{"id":"q-384","question":"You're designing a multi-region SaaS application with users in North America and Europe. How would you configure Route53, CloudFront, ALB, and VPC to ensure low latency and high availability? What are the key trade-offs?","channel":"aws","subChannel":"networking","difficulty":"intermediate","tags":["vpc","route53","cloudfront","alb"],"companies":["Airtable","Cisco","Epic Games"]},{"id":"gh-66","question":"How does serverless computing abstract infrastructure management and what are its key execution characteristics?","channel":"aws","subChannel":"serverless","difficulty":"beginner","tags":["serverless","lambda"],"companies":["Airbnb","Amazon","Google","Microsoft","Uber"]},{"id":"q-246","question":"How would you design a serverless order processing workflow using AWS Step Functions with Lambda functions, implementing specific retry patterns, error handling, and state management?","channel":"aws","subChannel":"serverless","difficulty":"intermediate","tags":["lambda","api-gateway","step-functions"],"companies":["Amazon","Google","Microsoft","Netflix","Salesforce","Stripe"]},{"id":"q-292","question":"How would you design a data lifecycle strategy for a media company storing petabytes of video content requiring immediate access, archiving, and cost optimization across AWS storage services?","channel":"aws","subChannel":"storage","difficulty":"advanced","tags":["s3","ebs","efs","glacier"],"companies":["Meta","Netflix","Youtube"]},{"id":"q-307","question":"What are the key differences between S3, EBS, and EFS in terms of performance, scalability, and use cases?","channel":"aws","subChannel":"storage","difficulty":"intermediate","tags":["s3","ebs","efs","glacier"],"companies":["Amazon","Google","Meta"]},{"id":"q-370","question":"You're designing a file storage system for Canva's design assets. Users upload large PSD files (up to 10GB) that need versioning and quick access. How would you architect this using AWS storage services, considering cost, performance, and durability?","channel":"aws","subChannel":"storage","difficulty":"intermediate","tags":["s3","ebs","efs","glacier"],"companies":["Affirm","Booking.com","Canva"]},{"id":"q-1001","question":"You're building a beginner-friendly AWS-only pipeline to ingest customer chat transcripts (text files up to 50 KB) uploaded to S3. Design how to automatically redact PII using Amazon Comprehend PII detection, store the redacted transcript back to S3, and index metadata in DynamoDB. Include data flow, IAM permissions, error handling, and privacy considerations?","channel":"aws-ai-practitioner","subChannel":"general","difficulty":"beginner","tags":["aws-ai-practitioner"],"companies":["Snowflake","Zoom"]},{"id":"q-1058","question":"Design a cross region, multi account AI inference platform for real time pricing and risk scoring in a fintech setting. Ingest streaming data, enforce per tenant data residency, and meet sub 100 ms latency. Describe data flow, services, IAM boundaries, model registry, feature store, drift monitoring, error handling, and cost controls?","channel":"aws-ai-practitioner","subChannel":"general","difficulty":"advanced","tags":["aws-ai-practitioner"],"companies":["Coinbase","NVIDIA","Stripe"]},{"id":"q-1259","question":"Design an end-to-end AWS-native real-time fraud detection pipeline for a global e-commerce platform. Ingest event streams (Kinesis Data Streams), redact PII, create real-time features stored in SageMaker Feature Store (online) and offline store, with governance, lineage, access control, and cost constraints. Include data flow, IAM, retry logic, backpressure, testing, and incident response?","channel":"aws-ai-practitioner","subChannel":"general","difficulty":"advanced","tags":["aws-ai-practitioner"],"companies":["Airbnb","Cloudflare","Salesforce"]},{"id":"q-1292","question":"Design a real-time fraud-detection pipeline on AWS for a FinTech use-case. Ingest streaming transactions via Kinesis Data Streams, preprocess with Lambda, and invoke a SageMaker endpoint for real-time scores. Persist results to DynamoDB with audit logs in S3. Address latency (<200 ms), data privacy (KMS, VPC endpoints), IAM, drift monitoring, error handling, and cost control. Provide concrete components and trade-offs?","channel":"aws-ai-practitioner","subChannel":"general","difficulty":"intermediate","tags":["aws-ai-practitioner"],"companies":["Citadel","Coinbase"]},{"id":"q-951","question":"You're building a low‑ops internal voice assistant for support scripts. Audio files up to 60 seconds are uploaded to S3. Design an AWS‑only pipeline that transcribes, analyzes sentiment, and stores a brief summary plus an index in DynamoDB, with minimal cost and ops. Include data flow, services, error handling, and privacy considerations?","channel":"aws-ai-practitioner","subChannel":"general","difficulty":"beginner","tags":["aws-ai-practitioner"],"companies":["MongoDB","Snap"]},{"id":"q-886","question":"Scenario: you manage a financial data lake with multiple transactional sources feeding S3 via DMS. Stakeholders require upserts, full history for compliance, fast dashboards using a latest-state table, and seamless schema evolution. Compare Iceberg, Hudi, and Delta Lake for this scenario and outline a concrete pipeline (CDC, ETL, compaction, governance)?","channel":"aws-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["aws-data-engineer"],"companies":["Goldman Sachs","Tesla"]},{"id":"q-948","question":"In a multi-tenant data lake on S3 across two AWS accounts, each tenant's data must be isolated, with auditable access, cost accounting, and fast analytics for dashboards. Design a solution using AWS Lake Formation for governance, S3 prefixes per tenant, and Athena/Glue for analytics. Explain cross-account sharing, tag-based access, and data lineage, plus failure modes?","channel":"aws-data-engineer","subChannel":"general","difficulty":"advanced","tags":["aws-data-engineer"],"companies":["Apple","Discord","Netflix"]},{"id":"q-1074","question":"Scenario: A global time-series platform ingests 1M events/hour in us-west-2; dashboards in eu-central-1 and ap-southeast-2 need sub-200ms reads on the latest window. Data must be immutable for 90 days for compliance. Compare DynamoDB Global Tables with DAX vs Aurora PostgreSQL Global Database with cross-region backups. Provide topology, replication, PITR/backup plans, and RPO/RTO targets?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Apple","Microsoft"]},{"id":"q-1131","question":"**Hybrid Analytics Path for Multiregion Aurora**\n\nYou're running an Aurora PostgreSQL OLTP cluster with tenant isolation via RLS in us-east-1. A regulatory BI team in eu-west-1 requires near real-time analytics with masked PII. Design a hybrid analytics path using Aurora Global Database for OLTP replicas and a CDC-based analytic store (Redshift or DynamoDB+Lambda) in eu-west-1. Describe data flow, masking strategy, encryption, failover, and how to meet RPO 5s and RTO 60s, including cost considerations?","channel":"aws-database-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-database-specialty"],"companies":["Coinbase","Goldman Sachs","Two Sigma"]},{"id":"q-1279","question":"In a multi-tenant SaaS on AWS, run a single Aurora PostgreSQL cluster with per-tenant schemas and RLS to isolate data. An analytics team in eu-west-1 requires cross-tenant BI with masked PII in near real-time dashboards. Design a cost-aware architecture that delivers masking, auditing, and SLA, comparing per-tenant schemas in a single cluster vs separate clusters per tenant. Include data flow, backup, and failover?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Amazon","Hugging Face","Robinhood"]},{"id":"q-1303","question":"In a multi-tenant SaaS using Aurora PostgreSQL with Global Database spanning us-west-2 and us-east-1, tenants must have isolated data access and BI dashboards must mask PII in real time. Propose an end-to-end design using per-tenant RLS, dynamic masking for BI, and a separate analytics store fed by CDC (DMS/Debezium). Include cross-region DR with RPO <5s and RTO <60s, data flow, encryption, backups, and a concrete sizing plan (replicas, window, network)?","channel":"aws-database-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-database-specialty"],"companies":["Databricks","Lyft","Tesla"]},{"id":"q-851","question":"Two-region OLTP SaaS with a single writer in us-east-1 and read replicas in eu-west-1. Compare Aurora Global Database (PostgreSQL) vs DynamoDB Global Tables for this workload: latency targets, consistency model, failover behavior, and cost. Which approach would you pick and why, and what concrete configuration (replica count, failover window, write routing) would you implement to meet RTO < 60s and RPO < 5s?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Robinhood","Snowflake"]},{"id":"q-871","question":"Migration plan: An OLTP app runs on Aurora PostgreSQL provisioned; traffic is bursty; you want to evaluate Aurora Serverless v2. Provide a concrete plan to migrate, including: (1) start/stop criteria and scaling configuration; (2) handling of long-running transactions and prepared statements; (3) how to keep reads consistent during scaling; (4) testing approach for failover/RTO targets; (5) cost considerations and potential pitfalls with Serverless v2?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Hugging Face","IBM","Uber"]},{"id":"q-895","question":"Your multi-region SaaS needs an audit-friendly cross-tenant analytics store with writes transactional in us-east-1 and analytics queries in eu-west-1 under GDPR. Compare Aurora PostgreSQL Global Database vs DynamoDB Global Tables for this workload, focusing on transactional integrity, analytics capability, PITR/retention, cross-region latency, and cost. Recommend a concrete configuration (writer region, replica counts, PITR window, tenant isolation, ETL approach) to meet RPO 15 minutes and RTO 1 hour?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Google","Slack","Square"]},{"id":"q-956","question":"For a real-time fraud graph application needing sub-100ms neighbor lookups across two AWS regions, compare Amazon Neptune Global Database with DynamoDB (using graph patterns and DAX) for this workload. Writer region us-east-1; readers in eu-west-1; assess graph traversal latency, consistency guarantees, failover behavior, and total cost. Provide a concrete setup (cluster engine and size, replica counts, PITR window, backup schedule, and network/config) to meet an RPO of 5s and an RTO of 60s?","channel":"aws-database-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-database-specialty"],"companies":["Meta","NVIDIA","Snap"]},{"id":"q-964","question":"You run an Amazon RDS PostgreSQL in **us-east-1** with automated backups. A regional outage blocks access from that region. How would you achieve **RPO ≤ 60s** and **RTO ≤ 15 minutes** by restoring to **eu-west-1**? Compare cross-region read replicas, backup copy, and Aurora Global Database, and outline concrete steps, knobs, and caveats?","channel":"aws-database-specialty","subChannel":"general","difficulty":"beginner","tags":["aws-database-specialty"],"companies":["LinkedIn","Slack","Tesla"]},{"id":"q-1183","question":"Design a cross-account AWS CI/CD flow for a real-time analytics platform with data plane in Account A, model training in Account B, and API endpoints in Account C. Implement Terraform-driven IaC, policy-driven approvals, drift detection, canary promotion with synthetic monitoring, and automated rollback. How do you enforce least privilege, secret rotation, and auditable artifact pipelines across accounts?","channel":"aws-devops-pro","subChannel":"general","difficulty":"advanced","tags":["aws-devops-pro"],"companies":["Coinbase","Microsoft","MongoDB"]},{"id":"q-676","question":"You have a Node.js app deployed on EC2 instances behind an Application Load Balancer in a private VPC. You want a beginner-friendly, repeatable CI/CD pipeline that triggers on git pushes, runs tests, and safely deploys with rollback. Describe a practical setup using AWS CodePipeline, CodeBuild, and CodeDeploy (blue/green) to auto-build, test, and deploy with artifact flow in S3, and IAM roles with least privilege, including how to isolate staging vs production using separate target groups?","channel":"aws-devops-pro","subChannel":"general","difficulty":"beginner","tags":["aws-devops-pro"],"companies":["Cloudflare","Discord","Google"]},{"id":"q-890","question":"Design an AWS-based CI/CD pipeline for a data platform (S3 data lake, Lambda ETL, ECS) that sources from Git, runs unit tests and data quality checks (Great Expectations) on staging data, then plans/applies Terraform in staging and promotes to production with canary deployment and traffic shift. Explain IAM least-privilege, S3 artifact flow, and staging vs prod isolation?","channel":"aws-devops-pro","subChannel":"general","difficulty":"intermediate","tags":["aws-devops-pro"],"companies":["Anthropic","Citadel","Databricks"]},{"id":"q-924","question":"Design a beginner-friendly AWS CI/CD pipeline for a serverless REST API deployed to AWS Lambda behind API Gateway. Source from GitHub; CodeBuild runs unit tests with pytest and a basic security scan with bandit; artifacts stored in S3; deployment uses SAM/CFN to Lambda with separate stages dev/stage/prod and a canary traffic shift via Lambda aliases. Explain IAM least-privilege and secure env vars (Secrets Manager or SSM)?","channel":"aws-devops-pro","subChannel":"general","difficulty":"beginner","tags":["aws-devops-pro"],"companies":["Microsoft","Square","Uber"]},{"id":"q-998","question":"In a 3-account AWS setup (Dev, SecProd, Prod), you need a Git-driven CI/CD that builds a container image in Dev, promotes IaC and app config via Terraform, and signals canary tests in Prod before full rollout. Explain cross-account CodePipeline stages, IAM roles with least privilege, Secrets Manager rotation, and canary deployment with rollback triggers. Include artifact flow and auditing considerations?","channel":"aws-devops-pro","subChannel":"general","difficulty":"intermediate","tags":["aws-devops-pro"],"companies":["Apple","Databricks"]},{"id":"q-1025","question":"In a multi-account AWS DVA data platform, streaming IoT telemetry into Kinesis Data Firehose feeding an S3 data lake with Glue catalog. Data schemas evolve and backfills are needed without full reprocessing. Design an end-to-end approach for schema evolution, idempotent writes, and backfill using Glue Schema Registry, Iceberg on S3, and partition pruning. Include data validation, DLQ, and observability?","channel":"aws-dva","subChannel":"general","difficulty":"advanced","tags":["aws-dva"],"companies":["Goldman Sachs","Instacart","Snap"]},{"id":"q-1268","question":"Design an AWS data lake pattern for multi-tenant analytics where each tenant's data sits under /tenants/{tenantId} in S3 and is exposed to Athena and QuickSight. How would you implement strict tenant isolation, least-privilege access, and automated policy-driven discovery and auditing using Lake Formation, IAM, CMKs, and SCPs? Include governance, testing, and performance considerations?","channel":"aws-dva","subChannel":"general","difficulty":"advanced","tags":["aws-dva"],"companies":["Discord","Oracle","Salesforce"]},{"id":"q-674","question":"You're building an AWS DVA data-analytics pipeline ingesting telemetry from 2000 devices/sec via Kinesis Data Streams. A Spark/Glue path processes windows and writes Parquet to S3; aggregation state in DynamoDB. Data loss or duplicates occur during retries and outages; costs spike at peak. Design a resilient, cost-efficient approach: shard sizing, processing path, idempotent writes, error handling with DLQ, and observability. What would you implement and why?","channel":"aws-dva","subChannel":"general","difficulty":"intermediate","tags":["aws-dva"],"companies":["Microsoft","OpenAI"]},{"id":"q-916","question":"In an AWS-based DVA pipeline ingesting telemetry from 2000 devices/sec via Kinesis Data Streams, with a Spark/Glue path writing Parquet to S3 and cataloged in Glue, design an end-to-end strategy for robust schema evolution, data validation, and partitioning that minimizes reprocessing and supports backfills. Include schema registry, idempotence, DLQ, and observability?","channel":"aws-dva","subChannel":"general","difficulty":"intermediate","tags":["aws-dva"],"companies":["MongoDB","Snowflake","Tesla"]},{"id":"q-1228","question":"Design a drift-aware continuous training and multi-region deployment workflow for a fraud-detection model, using SageMaker Model Monitor, Pipelines, and Model Registry. Explain how you detect data and feature drift (PSI/KS against baselines), retrain triggers, versioning, canary validation, rollback, and how cross-region consistency is maintained?","channel":"aws-ml-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-ml-specialty"],"companies":["Amazon","Bloomberg","Square"]},{"id":"q-1297","question":"You're deploying a multilingual sentiment-analysis model for a global customer-support chatbot. To minimize downtime when updating language adapters, design a SageMaker-based deployment with per-language variants, Model Registry, and canary rollouts that preserve latency SLAs and isolate traffic. Describe autoscaling, traffic routing, validation, and rollback criteria with concrete values?","channel":"aws-ml-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-ml-specialty"],"companies":["Amazon","Google"]},{"id":"q-876","question":"You're deploying a SageMaker real-time endpoint for a model expected to see bursty, unpredictable traffic. Propose a concrete autoscaling setup using AWS Application Auto Scaling that keeps latency under a target while never scaling to zero. Specify min and max instances, the metric and target value (latency or invocations), the policy type, and cooldowns; discuss validation steps?","channel":"aws-ml-specialty","subChannel":"general","difficulty":"beginner","tags":["aws-ml-specialty"],"companies":["Bloomberg","Lyft"]},{"id":"q-896","question":"You run a SageMaker real-time endpoint serving a risk-scoring model for payments. After a drift alert, outline a canary deployment plan using endpoint variants and the Model Registry to shift 20% of traffic to a new version while preserving latency and safety. Describe how you automate metric validation (latency, error rate, and drift), rollback triggers, and guardrails, and how you promote a stable canary to baseline?","channel":"aws-ml-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-ml-specialty"],"companies":["Bloomberg","PayPal","Robinhood"]},{"id":"q-969","question":"In a production AWS ML pipeline, you must serve multiple fraud-detection models across two regions using a SageMaker Multi-Model Endpoint (MME). Propose a concrete deployment and autoscaling strategy that keeps p95 latency under 200 ms during peak, prevents cold starts, and optimizes memory by loading only active models. Describe per-model versioning with SageMaker Model Registry, traffic routing, canary validation, rollback triggers, cost implications, and cross-region consistency?","channel":"aws-ml-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-ml-specialty"],"companies":["Bloomberg","Netflix","Tesla"]},{"id":"q-902","question":"A multinational bank operates 6 VPCs across 3 AWS accounts in two regions. They want to centralize north-south internet egress for security inspection, keep east-west traffic private, minimize inter-region data transfer costs, and streamline onboarding of new accounts. Propose a hub-and-spoke design using AWS Transit Gateway, Network Firewall, and VPC Endpoints. Describe routing, policy model, and observability considerations?","channel":"aws-networking-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-networking-specialty"],"companies":["Goldman Sachs","Google","Tesla"]},{"id":"q-923","question":"In a multi-account AWS environment with four accounts (prod, dev, staging, shared-services) and two regions, internal services (e.g., app.internal, db.internal) must resolve to private IPs across accounts, with public DNS unchanged for customers. Propose a scalable private DNS design using a private hosted zone and Route 53 Resolver (inbound/outbound as needed). Explain setup steps, minimal cross-account boundaries, and basic validation methods?","channel":"aws-networking-specialty","subChannel":"general","difficulty":"beginner","tags":["aws-networking-specialty"],"companies":["DoorDash","Hashicorp","Meta"]},{"id":"q-939","question":"An enterprise runs 4 AWS accounts across 2 regions with 10 VPCs. They require centralized north-south internet egress through a firewall inspection stack, private east-west traffic, cross-region replication, and scalable SaaS access via PrivateLink. Design an end-to-end network using Transit Gateway, VPC Endpoints, Private DNS, and optional Direct Connect/Interconnect. Describe routing, policy model, failover, and observability considerations?","channel":"aws-networking-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-networking-specialty"],"companies":["DoorDash","Microsoft","Square"]},{"id":"q-1047","question":"Design a multi-tenant analytics data lake on AWS for 3,000 tenants with strict data isolation. Propose an architecture using a shared S3 data lake with per-tenant prefixes, Lake Formation permissions, and ABAC via tenant tags. Outline governance (IAM, KMS, RAM), onboarding/offboarding automation, cost accounting, and cross-region DR. Include testing strategies to validate isolation and detect privilege escalation?","channel":"aws-saa","subChannel":"general","difficulty":"advanced","tags":["aws-saa"],"companies":["Cloudflare","Robinhood","Snowflake"]},{"id":"q-1203","question":"A web app runs in a private subnet in a VPC with no Internet access. It must fetch a config.json from a single S3 bucket owned by the same account. Design the minimal IAM role for the EC2 instance, a bucket policy, and a VPC endpoint setup to allow access via the VPC endpoint while denying access to other buckets. What steps and policies would you implement?","channel":"aws-saa","subChannel":"general","difficulty":"beginner","tags":["aws-saa"],"companies":["Cloudflare","DoorDash","Snowflake"]},{"id":"q-672","question":"Design a scalable, cost-aware data ingestion and processing pipeline on AWS for 1 TB/day of log data arriving from multiple on-prem and cloud sources. The pipeline must deliver raw data immutably for 90 days, provide near-real-time enrichment within 5 seconds, and support cross-region failover. Specify services, data flows, constraints, and trade-offs?","channel":"aws-saa","subChannel":"general","difficulty":"advanced","tags":["aws-saa"],"companies":["Hashicorp","IBM"]},{"id":"q-930","question":"An existing web service runs on EC2 in a single VPC with an ALB. Traffic surges cause latency spikes and occasional outages during AZ failures. Propose a beginner-friendly, cost-conscious HA setup using an Application Load Balancer, Auto Scaling across at least two AZs, and a relational database option. Include networking, health checks, a scaling policy, and a basic DB deployment choice with trade-offs. What would you implement first and why?","channel":"aws-saa","subChannel":"general","difficulty":"beginner","tags":["aws-saa"],"companies":["Amazon","MongoDB"]},{"id":"q-944","question":"Design a multi-tenant SaaS on AWS that ingests telemetry from thousands of tenants daily, enforces strict data isolation, and provides cross-region DR. Outline data partitioning, access control, encryption strategy, immutable logging, and DR failover. Include services, trade-offs, and how you test isolation?","channel":"aws-saa","subChannel":"general","difficulty":"advanced","tags":["aws-saa"],"companies":["Anthropic","Meta","Snap"]},{"id":"q-989","question":"Design a centralized security telemetry pipeline for 1,000 AWS accounts to detect anomalies in near real-time. Ingest VPC Flow Logs, CloudTrail, and GuardDuty findings into a central security account using AWS Organizations, implement least-privilege cross-account roles, normalize data into a common schema in S3, partition by source account and region, apply Lake Formation permissions, and set up alerting with EventBridge and security findings. Include scaling, cost, DR, and testing?","channel":"aws-saa","subChannel":"general","difficulty":"intermediate","tags":["aws-saa"],"companies":["Google","Plaid"]},{"id":"q-1005","question":"You operate SAP S/4HANA on AWS with analytics in Snowflake and must implement a data masking/tokenization pipeline so analytics do not expose PII. Design end-to-end data flow, masking rules by field, latency (<5 minutes), and governance using KMS/IAM. Include auditing, rollback, and failover considerations?","channel":"aws-sap","subChannel":"general","difficulty":"intermediate","tags":["aws-sap"],"companies":["Oracle","Snap","Snowflake"]},{"id":"q-1011","question":"How would you implement an automated cross-region DR for SAP HANA on AWS? Use SAP HANA System Replication with Region A as primary and Region B as hot standby, orchestrated by AWS Step Functions; back up to EBS/S3 with Data Lifecycle Manager and cross-region KMS keys; ensure automated DR tests, rollback playbooks, and meet RPO <5 minutes, RTO <15 minutes?","channel":"aws-sap","subChannel":"general","difficulty":"advanced","tags":["aws-sap"],"companies":["PayPal","Uber"]},{"id":"q-1059","question":"Design an advanced SAP S/4HANA on AWS architecture using SAP HANA MDC on EC2 across 3 AZs, with analytics separated into a data lake. Propose a rolling OS/kernel/SAP patching and upgrade strategy that preserves near-zero downtime, enables automated cross-region DR testing, and guarantees RPO <2 minutes and RTO <5 minutes; specify automation, services, failure modes, and rollback?","channel":"aws-sap","subChannel":"general","difficulty":"advanced","tags":["aws-sap"],"companies":["Airbnb","Hashicorp","Stripe"]},{"id":"q-1179","question":"Design an automated, auditable patching workflow for SAP S/4HANA on EC2 across multiple AWS accounts and regions. Use AWS Systems Manager Patch Manager to patch OS and SAP kernel updates with rolling upgrades, pre/post checks, and automated rollback if SLA drift occurs. Include governance, approvals, testing, and validation of success before go-live?","channel":"aws-sap","subChannel":"general","difficulty":"advanced","tags":["aws-sap"],"companies":["Apple","Citadel","Plaid"]},{"id":"q-1186","question":"Design a multi-account SAP S/4HANA on AWS with SAP HANA MDC across 3 AZs and a cross-region DR setup. Route SAP system and security logs to a centralized, cross-account S3 data lake with Object Lock (WORM) and cross-region replication. Use AWS Glue/Data Catalog and Lake Formation for lineage and access control; enforce least privilege with SCPs. Automate DR tests and integrity checks?","channel":"aws-sap","subChannel":"general","difficulty":"advanced","tags":["aws-sap"],"companies":["Instacart","Lyft","Plaid"]},{"id":"q-673","question":"You manage a small SAP NetWeaver footprint on AWS using EC2 for the app tier and a separate DB tier on HANA. Describe a practical single-region HA and backup plan to meet an RPO of 15 minutes and an RTO of 60 minutes. Include chosen services, EC2 sizing approach, storage strategy (EBS/S3), backup schedule, and a cost-conscious trade-off you’d consider?","channel":"aws-sap","subChannel":"general","difficulty":"beginner","tags":["aws-sap"],"companies":["Microsoft","Robinhood"]},{"id":"q-900","question":"Scenario: You manage a single-region SAP NetWeaver deployment on AWS with a separate SAP HANA DB on EC2. You need a beginner-friendly, cost-conscious maintenance workflow that automates OS patching and SAP kernel upgrades using only AWS native services, with minimal downtime. Outline the steps, services, and a sample two-hour weekly maintenance window, including how you validate success and perform rollback?","channel":"aws-sap","subChannel":"general","difficulty":"beginner","tags":["aws-sap"],"companies":["Cloudflare","Hashicorp","Zoom"]},{"id":"q-1302","question":"A data pipeline in Account A must read daily compressed data from a bucket in Account B, with no Internet access and least privilege. Propose a practical cross-account access pattern using a role in Account B that can be assumed by a service role in Account A, a bucket policy, and a CMK policy. Include how you would validate that only authorized principals can access and that encryption keys are used and rotated?","channel":"aws-security-specialty","subChannel":"general","difficulty":"beginner","tags":["aws-security-specialty"],"companies":["Hashicorp","NVIDIA","Uber"]},{"id":"q-853","question":"In a multi-account AWS setup, centralize a logs bucket in Account A that stores CloudTrail and VPC Flow Logs from Accounts B and C. All objects must be encrypted at rest with a CMK in Account A that rotates automatically. Design the KMS key policy, bucket policy, and cross-account IAM roles to allow Account B/C services to encrypt, while preventing decryption except via a centralized IAM role in Account A. Include how you would validate encryption, rotation status, and auditability?","channel":"aws-security-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-security-specialty"],"companies":["Citadel","IBM"]},{"id":"q-867","question":"Design cross-account data sharing using Lake Formation and S3 that lets Account B write to a shared data lake in Account A and Account C read it via a service role, with a CMK in A that rotates automatically and multi-region, tamper-evident audit logs. Provide IAM/Lake Formation/KMS policies, cross-account trust, and a validation plan?","channel":"aws-security-specialty","subChannel":"general","difficulty":"advanced","tags":["aws-security-specialty"],"companies":["Bloomberg","MongoDB","Snap"]},{"id":"q-938","question":"In a two-account data lake, enforce immutable data retention with S3 Object Lock across regions. Buckets in Account A replicate to Account B via CRR. Design the retention policy (COMPLIANCE vs GOVERNANCE), enable automatic CMK rotation, and set cross-account IAM trust for replication. Explain how you'd validate retention, replication integrity, and rotation status?","channel":"aws-security-specialty","subChannel":"general","difficulty":"intermediate","tags":["aws-security-specialty"],"companies":["DoorDash","MongoDB","Scale Ai"]},{"id":"q-1004","question":"Scenario: A serverless API stack (API Gateway, Lambda, DynamoDB, S3, CloudFront) runs in us-east-1 with a DR region eu-west-1. Propose an automated DR plan using AWS Global Accelerator and Route 53 health checks to failover within 15 minutes. Include data replication choices, Lambda versioning strategy, S3 replication mode, and a safe rollback/verification approach that avoids production impact during tests?","channel":"aws-sysops","subChannel":"general","difficulty":"intermediate","tags":["aws-sysops"],"companies":["Databricks","Google"]},{"id":"q-1291","question":"In a 12-account AWS Organization, you must implement near real-time central audit logging for VPC Flow Logs, Lambda logs, and RDS logs in a dedicated Logging account. Design the end-to-end mechanism to ship logs from all member accounts to the central account, ensuring secure cross-account access, encryption, and resilience across Regions. What is your approach?","channel":"aws-sysops","subChannel":"general","difficulty":"advanced","tags":["aws-sysops"],"companies":["MongoDB","Salesforce","Scale Ai"]},{"id":"q-675","question":"You manage a two-region AWS deployment (us-east-1, us-west-2) behind an ALB with private subnets, NAT gateway, and RDS in us-east-1. During business hours, us-west-2 exhibits spike in 5xx errors and higher latency. Outline immediate incident triage steps, AWS CLI commands to run, how you’d identify root causes (NAT saturation, DNS routing, cross-region replication lag), and both short- and long-term mitigations with verification steps?","channel":"aws-sysops","subChannel":"general","difficulty":"intermediate","tags":["aws-sysops"],"companies":["Apple","Snowflake"]},{"id":"q-982","question":"Design an automated cross-region disaster recovery plan for a globally distributed web app currently active in us-east-1 with a DR site in us-west-2, covering RDS, DynamoDB, S3, and ALB-backed frontend. Specify data synchronization, failover steps, testing, and rollback?","channel":"aws-sysops","subChannel":"general","difficulty":"advanced","tags":["aws-sysops"],"companies":["Anthropic","Google"]},{"id":"q-1036","question":"Scenario: A new external vendor needs read-only access to a single Azure AD-secured web portal (SaaS app) via B2B. Create a guest user, assign them to a dedicated App Role of the portal, enforce MFA and device-compliant access with a Conditional Access policy restricted to the office IP range, and outline post-grant validation and rollback?","channel":"azure-administrator","subChannel":"general","difficulty":"beginner","tags":["azure-administrator"],"companies":["Citadel","NVIDIA","PayPal"]},{"id":"q-1109","question":"How would you enable Self-Service Password Reset (SSPR) for a 20-user Azure AD group, enforce MFA during resets, and ensure auditable reset events with a simple rollback plan? Include licensing notes, enrollment flow, verification steps, and failure handling?","channel":"azure-administrator","subChannel":"general","difficulty":"beginner","tags":["azure-administrator"],"companies":["MongoDB","Stripe"]},{"id":"q-1191","question":"Scenario: A data platform CI/CD pipeline deploys to Data Lake Gen2, Synapse, and a storage account across three subscriptions using a non-interactive service principal. Design a secure, rotating, auditable auth model: App Registration with certificate-based OAuth, Key Vault-stored certs rotated every 30 days, per-resource RBAC with least privilege, automatic revocation on build failure, and validation steps. Include how you would test access during runs and how to roll back changes if needed?","channel":"azure-administrator","subChannel":"general","difficulty":"advanced","tags":["azure-administrator"],"companies":["Databricks","Google","PayPal"]},{"id":"q-1304","question":"Scenario: a startup with 5–15 users is moving to Azure AD for the first time. You need to enable basic identity services: (a) create users and groups, (b) provide SSO for a SaaS app using SAML, (c) enforce MFA, (d) automatically assign Office 365 licenses via group membership, and (e) enable self-service password reset for all users. Outline an end-to-end setup plan and a minimal validation checklist prior to go-live?","channel":"azure-administrator","subChannel":"general","difficulty":"beginner","tags":["azure-administrator"],"companies":["Discord","IBM","Lyft"]},{"id":"q-855","question":"Your organization needs a temporary access workflow: grant a contractor read/write access to a single Blob Storage container for 30 days using Azure AD groups and RBAC, and automatically revoke access at day 30. How would you implement this end-to-end?","channel":"azure-administrator","subChannel":"general","difficulty":"beginner","tags":["azure-administrator"],"companies":["DoorDash","IBM","Stripe"]},{"id":"q-897","question":"Scenario: A contractor needs access to a single Azure AD‑secured app (CI/CD portal) for 14 days. Outline an end‑to‑end approach using a dedicated Azure AD security group, app RBAC, and an Access Review to auto‑revoke access at day 14. Include how you would validate access during the window and after expiry, with minimal automation and no custom scripts?","channel":"azure-administrator","subChannel":"general","difficulty":"beginner","tags":["azure-administrator"],"companies":["Airbnb","Twitter","Two Sigma"]},{"id":"q-929","question":"Scenario: A multinational bank needs external data scientists to access multiple Azure resources (Data Lake Gen2, Synapse, and a storage account) for a 6-week analytics project. Propose an end-to-end access model using Azure AD Entitlement Management, Access Reviews, B2B collaboration, and Privileged Identity Management (PIM) for Just-In-Time role activations, with cross-subscription considerations, least privilege, and auditability. Include how you enforce MFA, token lifetimes, revocation at end, and validation steps?","channel":"azure-administrator","subChannel":"general","difficulty":"advanced","tags":["azure-administrator"],"companies":["Goldman Sachs","Netflix","PayPal"]},{"id":"q-942","question":"Scenario: A vendor must run nightly ingestion pipelines against Data Lake Gen2, a storage account, and Synapse in a shared Azure AD tenant for 10 days using a single service principal. Propose an end-to-end access model using an App Registration with scoped RBAC, Just-In-Time activation (PIM) for the service principal, Entitlement Management or Access Reviews, and automatic revocation at expiry. Include how you would validate access during the window and after expiry with minimal automation and no custom scripts?","channel":"azure-administrator","subChannel":"general","difficulty":"advanced","tags":["azure-administrator"],"companies":["Instacart","NVIDIA"]},{"id":"q-1053","question":"You’re deploying a multi-tenant Azure OpenAI-powered customer-support assistant for a global marketplace. Describe an end-to-end plan for runtime isolation and governance: prevent prompt injection, redact PII before OpenAI calls, enforce per-tenant quotas, maintain data lineage in Purview, ensure regional residency, and implement drift alerts via Azure Monitor plus a lightweight detector in Azure ML?","channel":"azure-ai-engineer","subChannel":"general","difficulty":"advanced","tags":["azure-ai-engineer"],"companies":["Cloudflare","DoorDash","Snowflake"]},{"id":"q-1134","question":"You're building a beginner-level Azure OpenAI-powered chat assistant for a rideshare service that serves clients in two regions. Outline a concrete data path and a minimal routing implementation that ensures user messages and model outputs stay in-region. Include a TypeScript function that selects the regional OpenAI endpoint based on client region, a latency fallback policy, and basic in-region logging to Azure Monitor. Provide testing approaches?","channel":"azure-ai-engineer","subChannel":"general","difficulty":"beginner","tags":["azure-ai-engineer"],"companies":["Citadel","Google","Uber"]},{"id":"q-866","question":"You're deploying a multi-tenant chat assistant on Azure OpenAI Service for a rideshare company. PII must never be sent to OpenAI and responses must redact sensitive data before delivery. Outline a practical, beginner-friendly data path using Azure API Management, Azure Functions, Text Analytics for PII detection, and a regional OpenAI deployment. Include a simple data flow?","channel":"azure-ai-engineer","subChannel":"general","difficulty":"beginner","tags":["azure-ai-engineer"],"companies":["MongoDB","Tesla","Uber"]},{"id":"q-963","question":"You're building a beginner-friendly customer support bot on Azure OpenAI Service. How would you design a lightweight API boundary policy (Azure API Management) to rate-limit per user, cap monthly spend, and gracefully fall back to a rule-based reply if OpenAI is unavailable? Describe the data flow from API call through OpenAI or fallback, and include a minimal policy snippet?","channel":"azure-ai-engineer","subChannel":"general","difficulty":"beginner","tags":["azure-ai-engineer"],"companies":["Apple","Bloomberg","Square"]},{"id":"q-1029","question":"In a global IoT telemetry pipeline ingesting 100k events/s per region into ADLS Gen2 and Databricks Delta Lake, implement schema drift tolerant ingestion, end-to-end data lineage via Purview, RBAC, and cross-region DR replication. How would you architect the data contracts, partitioning, watermarking, retention, and governance to meet data residency and fault-tolerance requirements?","channel":"azure-data-engineer","subChannel":"general","difficulty":"advanced","tags":["azure-data-engineer"],"companies":["Cloudflare","Twitter","Uber"]},{"id":"q-1043","question":"Design an end-to-end Azure data-ecosystem pipeline that ingests incremental changes from a MongoDB Atlas collection into Delta Lake on ADLS Gen2, preserving SCD Type 2 history for a customers dimension, and handling schema drift. Include data lineage to Azure Purview, late-arriving updates, and on-demand reprocessing without data loss. Which components and config would you choose, and why?","channel":"azure-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["azure-data-engineer"],"companies":["MongoDB","NVIDIA","Robinhood"]},{"id":"q-940","question":"Daily CSV exports arrive in an ADLS Gen2 container at /incoming/sales/. Files may evolve over time as columns drift. Build a beginner pipeline using Data Factory to stage raw data, infer/handle schema changes, and load a simple star schema in Azure Synapse Analytics. Include a watermark-based incremental load and basic scheduling. Which services and steps would you implement?","channel":"azure-data-engineer","subChannel":"general","difficulty":"beginner","tags":["azure-data-engineer"],"companies":["Adobe","Amazon","Zoom"]},{"id":"q-980","question":"Design a global streaming-to-batch data pipeline for a PayPal/Adobe/Netflix-scale analytics platform: ingest real-time clickstream from Event Hubs into ADLS Gen2, maintain a Delta Lake with drift-tolerant schema, mask PII at ingestion, expose masked aggregates via serverless SQL pool, and enforce end-to-end lineage with Purview while supporting cross-region DR and data residency. Which Azure components and patterns would you use, and how would you handle schema evolution and failure modes?","channel":"azure-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["azure-data-engineer"],"companies":["Adobe","Netflix","PayPal"]},{"id":"q-1006","question":"Design a real-time telemetry ingestion pipeline for a fleet of autonomous vehicles on Azure. Events arrive at high volume per region; you must store compact per-vehicle summaries in Cosmos DB and archive raw events to Data Lake Gen2. How would you achieve exactly-once processing for aggregates, sub-200 ms latency, and zero data loss on transient failures? Propose architecture using Event Hubs, Functions, Databricks, and cross-region replication; justify idempotency and retry strategies?","channel":"azure-developer","subChannel":"general","difficulty":"advanced","tags":["azure-developer"],"companies":["Lyft","Slack","Tesla"]},{"id":"q-1136","question":"Design an end-to-end telemetry ingestion pipeline for 1M devices/min delivering messages {vehicleId, ts, lat, lon, speed}. Ingest via HTTPS into Event Hubs with vehicleId as partition key, process with a Function app (Event Hubs trigger) using batchSize=100; deduplicate per vehicle with Durable Entity and upsert to Cosmos DB multi-region. Explain data model, idempotency, Change Feed, backpressure, and monitoring?","channel":"azure-developer","subChannel":"general","difficulty":"advanced","tags":["azure-developer"],"companies":["Airbnb","Amazon","Tesla"]},{"id":"q-1248","question":"Design an end-to-end Azure ingestion pipeline for multi-tenant IoT events: thousands of devices per region send JSON to a gateway, per-tenant aggregates stored in Cosmos DB, raw data archived to Data Lake Gen2. Explain chosen services (Event Hub, Function/Durable Function, Cosmos DB with TTL, Data Lake), how you enforce per-tenant isolation and auditability, and how you achieve exactly-once processing and retry semantics?","channel":"azure-developer","subChannel":"general","difficulty":"intermediate","tags":["azure-developer"],"companies":["Amazon","Citadel","Google"]},{"id":"q-1277","question":"Design a real-time multi-tenant feature-store pipeline on Azure for a high-velocity AI platform. Ingest telemetry events via Event Hubs (tenantId, featureName, value, ts). Build end-to-end streaming with exactly-once semantics, isolation by tenant, and low-latency online reads. Specify concrete components (Event Hubs, Spark Structured Streaming, Cosmos DB with tenantId partition, Redis online store), auditability, TTL, and testing strategy?","channel":"azure-developer","subChannel":"general","difficulty":"advanced","tags":["azure-developer"],"companies":["Google","Hugging Face","OpenAI"]},{"id":"q-891","question":"Design a beginner-friendly serverless image-upload API on Azure: clients POST JPEGs to an HTTP-triggered Function, which saves the file to Blob Storage, enqueues a processing job, and stores a metadata record in Cosmos DB. How would you ensure idempotency, handle retries with back-off, and keep costs predictable on a Consumption plan?","channel":"azure-developer","subChannel":"general","difficulty":"beginner","tags":["azure-developer"],"companies":["Robinhood","Salesforce","Tesla"]},{"id":"q-973","question":"Case: You’re building a beginner-friendly Azure API that accepts events from mobile apps. Each event includes userId, eventType, and timestamp. The API should write a compact summary to Cosmos DB and stream raw events to Event Hubs for analytics. On a Consumption plan, outline the minimal architecture, bindings, and error handling to ensure low latency, safe retries, and no data loss during transient outages?","channel":"azure-developer","subChannel":"general","difficulty":"beginner","tags":["azure-developer"],"companies":["PayPal","Scale Ai"]},{"id":"q-1063","question":"With a 60-service monorepo deployed to Azure subscriptions across three regions, design an end-to-end release strategy that builds per-service artifacts, promotes to dev/stage/prod environments, gates each promotion with environment approvals tied to region-owner groups, and enforces that PRs link to an Azure Boards item. Include a minimal YAML template and gating approach?","channel":"azure-devops-engineer","subChannel":"general","difficulty":"advanced","tags":["azure-devops-engineer"],"companies":["Airbnb","Cloudflare"]},{"id":"q-1135","question":"Design an Azure DevOps multi-tenant canary deployment pipeline for a SaaS service that promotes per-tenant changes to prod only after a staged rollout window, uses tenant-scoped feature flags, enforces per-tenant approvals before prod, and rolls back automatically if telemetry thresholds are exceeded; outline the pipeline structure, environment gates, and auditing approach?","channel":"azure-devops-engineer","subChannel":"general","difficulty":"intermediate","tags":["azure-devops-engineer"],"companies":["LinkedIn","Stripe"]},{"id":"q-1255","question":"Scenario: You’re configuring a new Azure DevOps project with Repos and Boards for a small service. How would you implement beginner-friendly PR governance to ensure PRs into main are linked to a Boards work item, the PR title includes the work item ID, a PR validation build runs and passes, and an automatic staging deployment with a manual prod gate? Outline exact steps and considerations?","channel":"azure-devops-engineer","subChannel":"general","difficulty":"beginner","tags":["azure-devops-engineer"],"companies":["Microsoft","Robinhood"]},{"id":"q-1007","question":"A web app hosted in Azure App Service must securely call a private API hosted in an Azure Function behind a VNet. How would you implement private connectivity so traffic never leaves the Azure backbone? Include which resources you’d use, how to create a Private Endpoint for the API, DNS configuration, and how to restrict public access?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["DoorDash","Lyft","Salesforce"]},{"id":"q-1083","question":"An enterprise web app must enforce data residency per region, minimize egress costs, and meet real-time latency targets. Design an Azure-native, region-aware architecture that enforces residency, uses regional storage and a global entry point, and supports auditing and DR. Outline services, data replication, access control, and failover strategy?","channel":"azure-fundamentals","subChannel":"general","difficulty":"advanced","tags":["azure-fundamentals"],"companies":["Coinbase","Oracle","Scale Ai"]},{"id":"q-1110","question":"Scenario: A web API running in Azure App Service must persist user uploads to an Azure Storage account. Public access to the storage is disabled. How would you implement a Private Endpoint so the App Service talks to Storage over a private network, including enabling VNet integration, creating the Private Endpoint in the storage subnet, DNS configuration for privatelink, and any trade-offs?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["Citadel","Coinbase","Goldman Sachs"]},{"id":"q-1212","question":"Scenario: a new web app stores and serves user-uploaded images globally. To keep costs predictable and delivery fast, which Azure services would you pair to store, serve, and secure access to images, and what trade-offs would you consider for storage tiering, CDN option, and access control?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["Adobe","Hugging Face"]},{"id":"q-1242","question":"A startup runs a web app that stores user-uploaded images in Azure Blob Storage and serves them globally via CDN. Describe a practical storage design to minimize costs and latency: container layout, default and lifecycle tiers, lifecycle rules to auto-tier/delete, access control (RBAC vs SAS), and how you’d wire in CDN caching. Include concrete steps and example commands?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["Cloudflare","IBM","Two Sigma"]},{"id":"q-1276","question":"Design an end-to-end Azure architecture for a globally distributed analytics platform servicing EU customers with strict data residency. Your plan should cover: data at rest with customer-managed keys, cross-region disaster recovery, private networking (Private Link/Endpoints), least-privilege access, encryption key rotation, and continuous policy compliance checks. Explain key services and trade-offs?","channel":"azure-fundamentals","subChannel":"general","difficulty":"advanced","tags":["azure-fundamentals"],"companies":["Hugging Face","Oracle"]},{"id":"q-859","question":"You have a REST API hosted on Azure App Service that processes user uploads and stores them in a separate Azure Blob Storage account. To avoid embedding secrets, how would you securely grant the API read/write access to the blob container using a managed identity? Outline the exact steps and roles you would apply, and mention any network considerations?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["Amazon","MongoDB","Two Sigma"]},{"id":"q-865","question":"An IoT platform deployed in Azure collects about 5 million device events per minute from global regions. You must build an ingestion and processing pipeline that guarantees at-least-once delivery with idempotent writes to Cosmos DB, tolerates regional outages, and minimizes cost. Describe the end-to-end architecture, data flow, dedup strategy, and monitoring?","channel":"azure-fundamentals","subChannel":"general","difficulty":"intermediate","tags":["azure-fundamentals"],"companies":["Discord","Scale Ai"]},{"id":"q-932","question":"Scenario: a multi-tenant SaaS app runs on Azure App Service and stores per-tenant files in separate containers in Azure Blob Storage. To avoid hard-coded keys, describe a secure pattern using managed identities and RBAC to grant the app the correct container access while ensuring tenant isolation and minimal permission surface. Outline steps, roles, and any network considerations (e.g., Private Endpoint)?","channel":"azure-fundamentals","subChannel":"general","difficulty":"beginner","tags":["azure-fundamentals"],"companies":["DoorDash","Oracle"]},{"id":"q-984","question":"In a globally distributed API using Azure Functions and Cosmos DB, implement per-tenant data isolation with minimal cross-region data transfer. How would you design the architecture, enforce least-privilege access via managed identities and RBAC, and ensure data residency with Private Endpoints and cross-region replication policies?","channel":"azure-fundamentals","subChannel":"general","difficulty":"advanced","tags":["azure-fundamentals"],"companies":["Bloomberg","MongoDB","Square"]},{"id":"q-898","question":"In a multi-cluster AKS deployment with rapid scale-out, design a workload-based segmentation pattern that avoids per-VM NSGs. Use Kubernetes NetworkPolicy/Calico, central allowlists, and Azure Policy for drift remediation. Include how to enforce per-service identity, automate policy checks, and detect violations with Defender for Cloud?","channel":"azure-security-engineer","subChannel":"general","difficulty":"advanced","tags":["azure-security-engineer"],"companies":["Bloomberg","Google","NVIDIA"]},{"id":"q-925","question":"In a multi-subscription Azure deployment with ephemeral, autoscaled workloads across AKS and VMs, how would you achieve scalable, workload-oriented segmentation without updating NSG rules on every VM? Propose a concrete design using Azure Firewall Manager, managed identities, Private Link, and policy-driven groupings, plus a plan to test at scale?","channel":"azure-security-engineer","subChannel":"general","difficulty":"advanced","tags":["azure-security-engineer"],"companies":["Discord","Microsoft"]},{"id":"q-968","question":"In a global Azure deployment with microservices spread across AKS clusters and VM Scale Sets, design a workload-based segmentation that avoids touching NSG rules on every VM. Outline a concrete end-to-end approach using Azure Firewall Manager, policy-based groups, Private Endpoints, workload tags, and Managed Identities. Include deployment steps, scale testing, and violation monitoring?","channel":"azure-security-engineer","subChannel":"general","difficulty":"intermediate","tags":["azure-security-engineer"],"companies":["MongoDB","Snap","Uber"]},{"id":"q-1046","question":"You're building a regulated, multi-tenant analytics platform on Azure that ingests IoT and application logs from customers across three continents. Customers demand regional data residency while analytics must be global for cross-tenant benchmarks. Propose a practical, cost-conscious architecture that enforces per-tenant data isolation (at rest and in transit), regional ingestion, geo-redundant storage, cross-region analytics, and auditable access control using Azure native services. Include data plane vs control plane separation, and show how you'd satisfy RPO/RTO targets and regulatory requirements?","channel":"azure-solutions-architect","subChannel":"general","difficulty":"intermediate","tags":["azure-solutions-architect"],"companies":["Databricks","Google"]},{"id":"q-1181","question":"You operate a fintech SaaS platform serving tenants across US, EU, and APAC. Each tenant's data must reside regionally at rest, yet global analytics require anonymized cross-tenant insights. Describe an Azure-native architecture that (1) enforces per-tenant data isolation in storage and processing, (2) supports real-time ingestion of fraud/transaction events, (3) enables cross-region analytics without tenant leakage, (4) meets DR targets with RPO <15 minutes and RTO <5 minutes, and (5) provides end-to-end auditing and governance. Include components, data flows, trade-offs, and a concrete failover test plan?","channel":"azure-solutions-architect","subChannel":"general","difficulty":"advanced","tags":["azure-solutions-architect"],"companies":["Plaid","Snap"]},{"id":"q-1305","question":"You manage a global healthcare analytics platform on Azure. Regulations require that **PHI** stays in-country while **non-PHI** can aggregate regionally. Propose an end-to-end data pipeline using **Azure Data Lake Storage Gen2**, **Data Factory**/Synapse, and **Purview** to enforce residency, enable regional analytics, and provide auditable data lineage and masking. Include encryption, governance, and failover strategies across regions?","channel":"azure-solutions-architect","subChannel":"general","difficulty":"advanced","tags":["azure-solutions-architect"],"companies":["Google","Instacart","OpenAI"]},{"id":"q-887","question":"You’re building a multi-tenant analytics platform on Azure for a consumer-brand SaaS product. Each tenant must have isolated data processing, with per-tenant data lake isolation, on-demand Spark/notebook compute that auto-suspends, and cost governance at the tenant level. Propose an architecture using Azure Data Lake Storage Gen2, Unity Catalog or RBAC, Synapse or Databricks, private endpoints, and auditing. How do you ensure data isolation, prevent cross-tenant leakage, and meet compliance while keeping ops simple?","channel":"azure-solutions-architect","subChannel":"general","difficulty":"intermediate","tags":["azure-solutions-architect"],"companies":["Instacart","Microsoft","Snap"]},{"id":"q-606","question":"How would you implement a rate limiter for a REST API to prevent abuse while ensuring legitimate users aren't blocked? Describe the algorithm and data structures you would use.","channel":"backend","subChannel":"api-design","difficulty":"intermediate","tags":["rate-limiting","api-design","redis","distributed-systems","backend"],"companies":["Google","Amazon","Twitter","Stripe","GitHub"]},{"id":"q-614","question":"How would you implement API rate limiting for a high-traffic service that needs to handle millions of requests per minute? Discuss the trade-offs between different algorithms and your approach for distributed systems.","channel":"backend","subChannel":"api-gateway","difficulty":"intermediate","tags":["rate-limiting","api-design","distributed-systems","redis","token-bucket","scalability"],"companies":["Google","Meta","Twitter","Stripe","Amazon","Netflix"]},{"id":"q-624","question":"How would you implement API rate limiting in a distributed system to prevent abuse while ensuring fair usage across multiple servers?","channel":"backend","subChannel":"api-infrastructure","difficulty":"intermediate","tags":["rate-limiting","redis","distributed-systems","api-design","scalability"],"companies":["Stripe","Twitter","GitHub","Google","Amazon"]},{"id":"q-611","question":"How would you implement API rate limiting to prevent abuse while ensuring fair usage for legitimate clients?","channel":"backend","subChannel":"api-middleware","difficulty":"intermediate","tags":["rate-limiting","api-design","middleware","redis","security"],"companies":["Twitter","GitHub","Stripe","Google","Amazon"]},{"id":"gh-46","question":"How would you design comprehensive API documentation that ensures smooth developer integration and reduces support overhead?","channel":"backend","subChannel":"apis","difficulty":"beginner","tags":["api","service-mesh"],"companies":["GitHub","LinkedIn","Microsoft","Postman","Stripe"]},{"id":"q-267","question":"Compare REST, GraphQL, and gRPC performance characteristics and identify optimal use cases for each protocol in modern microservices architecture?","channel":"backend","subChannel":"apis","difficulty":"beginner","tags":["rest","graphql","grpc","openapi"],"companies":["Amazon","Google","Microsoft","Netflix","Square","Stripe"]},{"id":"q-396","question":"You're building a microservice that needs to expose both REST and GraphQL endpoints for the same data model. How would you design the architecture to avoid code duplication while maintaining optimal performance for each query type?","channel":"backend","subChannel":"apis","difficulty":"intermediate","tags":["rest","graphql","grpc","openapi"],"companies":["Amazon","Booking.com","Citadel"]},{"id":"q-515","question":"You're building a REST API for a payment service. How would you design the endpoint for processing a payment, and what HTTP status codes would you return for different scenarios?","channel":"backend","subChannel":"apis","difficulty":"beginner","tags":["rest","graphql","grpc","openapi"],"companies":["PayPal","Twitter"]},{"id":"q-539","question":"What is dependency injection in Spring and how does it improve application design?","channel":"backend","subChannel":"apis","difficulty":"intermediate","tags":["spring","dependency-injection","ioc","design-patterns","java"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-1196","question":"In a production backend with multiple IdPs (OIDC providers and a SAML bridge), design a token validation strategy to prevent replay and bind tokens to a device/session. Outline how you would implement: (a) JWKS caching and per-provider key rotation, (b) replay protection using jti stored in a distributed cache with TTL, (c) token binding via mTLS or client certificate binding, and (d) cross-provider revocation propagation and token lifecycle (short-lived access tokens with refresh tokens)?","channel":"backend","subChannel":"authentication","difficulty":"intermediate","tags":["jwt","oauth2","oidc","saml"],"companies":["Goldman Sachs","Hashicorp","Twitter"]},{"id":"q-1240","question":"Within an enterprise multi-IdP setup (OIDC and SAML), you run an API gateway that issues short-lived JWTs for a service mesh. Propose a concrete bridge design that: (a) supports converting SAML assertions and OIDC tokens into token-bound JWTs with audience and scope constraints, (b) binds tokens to a device fingerprint and a one-time nonce, (c) supports PKCE-backed mobile/native flows and refresh token rotation, (d) provides revocation and token introspection across regions, and (e) prevents token replay in a globally distributed environment. Explain data flows, token formats, and security checks?","channel":"backend","subChannel":"authentication","difficulty":"advanced","tags":["jwt","oauth2","oidc","saml"],"companies":["Anthropic","MongoDB"]},{"id":"q-342","question":"You're implementing OAuth2 for a SaaS product. A user reports their access token works but refresh token fails. What are the top 3 causes and how would you debug each?","channel":"backend","subChannel":"authentication","difficulty":"intermediate","tags":["jwt","oauth2","oidc","saml"],"companies":["Cohere","Hulu","Spotify"]},{"id":"q-455","question":"Design a secure authentication system for a microservices architecture that supports JWT, OAuth2, and SAML. How would you handle token rotation, session management, and prevent token replay attacks across multiple services?","channel":"backend","subChannel":"authentication","difficulty":"advanced","tags":["jwt","oauth2","oidc","saml"],"companies":["OpenAI","Twitter"]},{"id":"q-544","question":"You're implementing SSO for an enterprise application using SAML 2.0. The IdP sends signed assertions but you're seeing intermittent 'Invalid Signature' errors. What are the most common causes and how would you debug them?","channel":"backend","subChannel":"authentication","difficulty":"intermediate","tags":["jwt","oauth2","oidc","saml"],"companies":["Adobe","Hashicorp"]},{"id":"q-1116","question":"You're building a highly cached backend for a social app. **Redis** stores user profiles and feeds; **Memcached** caches post details. On a user profile edit, describe a precise, scalable strategy for **cache invalidation** that prevents stampedes, maintains consistency, and minimizes stale reads. Include data structures, TTLs, invalidation triggers, and atomic operations across **Redis** and **Memcached**, with concrete commands or pseudo-code?","channel":"backend","subChannel":"caching","difficulty":"advanced","tags":["redis","memcached","cache-invalidation"],"companies":["Apple","Google","Snap"]},{"id":"q-427","question":"You're building a user profile service that caches frequently accessed profiles. How would you implement cache invalidation when a user updates their profile, and what trade-offs would you consider between Redis and Memcached?","channel":"backend","subChannel":"caching","difficulty":"beginner","tags":["redis","memcached","cache-invalidation"],"companies":["Airbnb","Amazon","Google","Microsoft","Netflix","Snowflake","Stripe","Zoom"]},{"id":"q-443","question":"You're building a user profile API that caches user data in Redis. How would you implement cache invalidation when a user updates their profile, and what's the difference between using TTL vs explicit invalidation?","channel":"backend","subChannel":"caching","difficulty":"beginner","tags":["redis","memcached","cache-invalidation"],"companies":["Meta","MongoDB","NVIDIA"]},{"id":"q-330","question":"You're building a collaborative whiteboard app like Miro. When a user drags a shape, you need to update the UI immediately and persist the change. How would you implement this using CQRS?","channel":"backend","subChannel":"microservices","difficulty":"beginner","tags":["saga","cqrs","event-sourcing"],"companies":["Miro","Slack","Snowflake"]},{"id":"q-364","question":"You're building an order management system using CQRS with microservices architecture. How would you ensure data consistency between the write and read models when a command to create an order is processed, considering network partitions and potential service failures?","channel":"backend","subChannel":"microservices","difficulty":"beginner","tags":["saga","cqrs","event-sourcing"],"companies":null},{"id":"q-379","question":"You're building a distributed order processing system using the Saga pattern. How would you handle compensation when a payment service fails after inventory has been reserved?","channel":"backend","subChannel":"microservices","difficulty":"beginner","tags":["saga","cqrs","event-sourcing"],"companies":["Elastic","Epic Systems","Oscar Health"]},{"id":"q-666","question":"How would you implement a **saga**-driven checkout across services using **CQRS** and **event-sourcing**? Provide a concrete flow for an order touching Inventory, Payment, and Shipping: what commands and events you define, orchestration vs choreography, idempotency, compensating actions, and how read models are projected and kept consistent. Include reliability patterns like outbox and retries to ensure at-least-once delivery?","channel":"backend","subChannel":"microservices","difficulty":"intermediate","tags":["saga","cqrs","event-sourcing"],"companies":["DoorDash","OpenAI","Oracle"]},{"id":"q-667","question":"In a microservices backend for a retail platform, design a saga-driven workflow using CQRS and event sourcing across Order, Inventory, Payment, and Shipping. When an order is created, reserve inventory and authorize payment; on success, create shipping and complete the order. If inventory or payment fails, apply compensations (InventoryRelease, RefundPayment). Detail the event/command sequence, data in the event store, idempotency strategy, and orchestration vs choreography trade-offs?","channel":"backend","subChannel":"microservices","difficulty":"advanced","tags":["saga","cqrs","event-sourcing"],"companies":["Meta","Snowflake"]},{"id":"q-1095","question":"Design a globally distributed event store for a chat app where user_id determines the shard via consistent hashing. Each shard has 3 replicas in distinct regions; ingestion writes go to a leader replica and durably commit to all replicas using a 2-of-3 quorum. Reads are served from any replica with read-your-writes guarantees. Explain shard rebalancing without downtime, hot shard mitigation, cross-region replication lag, and failure recovery strategies?","channel":"backend","subChannel":"server-architecture","difficulty":"advanced","tags":["scaling","sharding","replication"],"companies":["Discord","MongoDB","Tesla"]},{"id":"q-249","question":"How would you implement a connection pool manager for aiohttp that handles graceful degradation under high load and connection timeouts?","channel":"backend","subChannel":"server-architecture","difficulty":"advanced","tags":["asyncio","aiohttp","concurrency"],"companies":["Airbnb","Amazon","Google","Meta","Microsoft","Netflix","Stripe","Uber"]},{"id":"q-485","question":"You're designing a distributed database for a fintech platform handling 10M transactions/day. How would you implement sharding and replication to ensure strong consistency while maintaining 99.99% availability?","channel":"backend","subChannel":"server-architecture","difficulty":"advanced","tags":["scaling","sharding","replication"],"companies":["Amazon","Coinbase","Plaid"]},{"id":"q-568","question":"How would you design a database schema for a user authentication system that needs to handle 1 million users with proper indexing and sharding considerations?","channel":"backend","subChannel":"server-architecture","difficulty":"beginner","tags":["scaling","sharding","replication"],"companies":["Citadel","LinkedIn","Tesla"]},{"id":"q-185","question":"Describe a specific situation where you had to resolve a technical disagreement with a difficult team member. What conflict resolution techniques did you use, and what was the measurable outcome?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"intermediate","tags":["communication","collaboration"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-312","question":"Tell me about a time you had to negotiate a solution between two team members with conflicting approaches?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"beginner","tags":["negotiation","mediation","feedback"],"companies":["Amazon","Google","Meta"]},{"id":"q-326","question":"Tell me about a time you had a conflict with a team member. How did you handle it and what was the outcome?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"beginner","tags":["negotiation","mediation","feedback"],"companies":["Crowdstrike","Salesforce","Tesla"]},{"id":"q-439","question":"Tell me about a time you had to mediate a conflict between two senior engineers who disagreed on a critical technical approach for a high-stakes project with a tight deadline?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"advanced","tags":["negotiation","mediation","feedback"],"companies":["Amazon","Apple","Google","Instacart","Meta","Microsoft","Netflix"]},{"id":"q-446","question":"Tell me about a time you had a disagreement with a teammate about how to approach a project. How did you handle it?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"beginner","tags":["negotiation","mediation","feedback"],"companies":["IBM","OpenAI"]},{"id":"q-486","question":"Tell me about a time you had to mediate a conflict between two senior engineers with opposing technical approaches. How did you handle it?","channel":"behavioral","subChannel":"conflict-resolution","difficulty":"advanced","tags":["negotiation","mediation","feedback"],"companies":["Microsoft","OpenAI","Square"]},{"id":"q-1039","question":"Describe a real incident in a fintech app where a release caused a customer-visible outage during market hours. Outline the explicit ownership and the immediate bias-for-action decision (hotfix vs rollback) with severity criteria, and how to ensure customer-obsessed restitution (transparent status updates, potential compensation, postmortem, and preventive steps)?","channel":"behavioral","subChannel":"leadership-principles","difficulty":"beginner","tags":["ownership","bias-for-action","customer-obsession"],"companies":["Google","Robinhood"]},{"id":"q-1243","question":"You're inheriting a mission-critical data pipeline that powers dashboards for a global customer; a nightly ETL job is failing in one region. Describe exactly how you would take ownership, act with urgency, and prioritize fixes while keeping customers informed. What trade-offs would you make and how would you measure success?","channel":"behavioral","subChannel":"leadership-principles","difficulty":"advanced","tags":["ownership","bias-for-action","customer-obsession"],"companies":["Airbnb","NVIDIA","Snowflake"]},{"id":"q-431","question":"Tell me about a time when you noticed a small issue that others overlooked. How did you take ownership and what was the impact?","channel":"behavioral","subChannel":"leadership-principles","difficulty":"beginner","tags":["ownership","bias-for-action","customer-obsession"],"companies":["Hugging Face","IBM","Tesla"]},{"id":"q-516","question":"Tell me about a time you had to make a critical decision with incomplete data. How did you balance speed vs accuracy?","channel":"behavioral","subChannel":"leadership-principles","difficulty":"intermediate","tags":["ownership","bias-for-action","customer-obsession"],"companies":["Cloudflare","Coinbase","PayPal"]},{"id":"q-1273","question":"Describe a time you faced a technical disagreement in a cross-functional project and successfully influenced a decision without direct authority. What was the conflict, what steps did you take to communicate your view, what data or patterns supported you, and what was the outcome?","channel":"behavioral","subChannel":"soft-skills","difficulty":"beginner","tags":["communication","collaboration","influence"],"companies":["NVIDIA","Tesla"]},{"id":"q-1282","question":"Describe a time when influence changed a project's approach after data showed the initial plan underperformed. What data did you present, what communication channels did you use, how did you secure collaboration, and what was the outcome and learning?","channel":"behavioral","subChannel":"soft-skills","difficulty":"beginner","tags":["communication","collaboration","influence"],"companies":["Google","Tesla","Twitter"]},{"id":"q-297","question":"Tell me about a time you had to influence a senior stakeholder who disagreed with your technical approach. How did you handle it?","channel":"behavioral","subChannel":"soft-skills","difficulty":"advanced","tags":["communication","collaboration","influence"],"companies":["Amazon","Google","Meta"]},{"id":"q-913","question":"Tell me about a time you persuaded a cross-functional team to adopt a non-obvious technical approach. What was the situation, how did you influence without direct authority, what data or experiments did you rely on, what trade-offs did you communicate, and what was the result?","channel":"behavioral","subChannel":"soft-skills","difficulty":"intermediate","tags":["communication","collaboration","influence"],"companies":["Bloomberg","Google","Salesforce"]},{"id":"q-212","question":"How would you structure a STAR method response when describing a time you resolved a technical conflict between frontend and backend teams over API design, and what specific communication strategies did you employ?","channel":"behavioral","subChannel":"star-method","difficulty":"beginner","tags":["situation","task","action","result"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Postman"]},{"id":"q-375","question":"Tell me about a time when you had to make a critical technical decision with incomplete data that impacted production systems. What was the situation, what data did you have, what decision did you make, and what was the result?","channel":"behavioral","subChannel":"star-method","difficulty":"advanced","tags":["situation","task","action","result"],"companies":["Amazon","Apple","Coinbase","Google","Meta","Microsoft","Netflix"]},{"id":"q-389","question":"Tell me about a time when you had to convince your team to adopt a new technology or approach that they were initially resistant to. What was the situation, what did you do, and what was the outcome?","channel":"behavioral","subChannel":"star-method","difficulty":"intermediate","tags":["situation","task","action","result"],"companies":["Expedia","IBM","Shopify"]},{"id":"q-569","question":"Tell me about a time you had to make a difficult technical decision with incomplete information under extreme pressure?","channel":"behavioral","subChannel":"star-method","difficulty":"advanced","tags":["situation","task","action","result"],"companies":["Citadel","Netflix","Tesla"]},{"id":"q-1073","question":"Implement transpose64(uint64_t x) by treating x as an 8x8 bit matrix in row-major order (bits 0-7 are row 0, 8-15 row 1, etc.). Return the transposed matrix (bit (r,c) moves to (c,r)). Use only bitwise ops and shifts; no loops or conditionals. Provide signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Cloudflare","Coinbase","Hashicorp"]},{"id":"q-1216","question":"Implement reverse128 for a 128-bit value stored as two 64-bit halves hi and lo. Provide a function:\n\nvoid reverse128(uint64_t hi, uint64_t lo, uint64_t *out_hi, uint64_t *out_lo);\n\nThe reversal should map bit i to bit 127 - i, using only bitwise operations and shifts (no loops or conditionals). Include a brief justification and 1-2 quick test examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Google","Snowflake","Stripe"]},{"id":"q-680","question":"Given a 32-bit unsigned int n, implement a function hasAdjacentOnes(n) that returns true if n contains any two consecutive 1 bits (for example 0b1100100 has adjacent ones). Use only bitwise operations, no loops or lookups. Explain the core trick in a sentence?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Cloudflare","Oracle","Two Sigma"]},{"id":"q-689","question":"Given a 32-bit unsigned integer n, implement a function isSingleEvenBitSet(n) that returns true if exactly one bit is set and that bit lies at an even index (0, 2, 4, ...). Use only bitwise operations, no loops or built-in helpers. Provide the expression and a brief justification, plus a couple of quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["LinkedIn","MongoDB","Snowflake"]},{"id":"q-698","question":"Implement a 32-bit unsigned integer function popcount32(n) that returns the number of set bits in n using only bitwise operations and shifts, with no loops or built-ins. Use the SWAR (SIMD Within A Register) technique: apply a sequence of masks and shifts (0x55555555, 0x33333333, 0x0F0F0F0F) and a final multiply to consolidate counts. Provide the function and a brief justification, plus a couple of quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Google","Two Sigma"]},{"id":"q-705","question":"Implement reverseBits32(n) that reverses all 32 bits in a 32-bit unsigned integer using only a fixed sequence of bitwise operations (no loops or conditionals). Use a SWAR-style approach with masks 0x55555555, 0x33333333, 0x0F0F0F0F and 0x00FF00FF, finishing with a 16-bit half-swap. Provide the function signature and a brief justification, plus a couple of quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Coinbase","Snap"]},{"id":"q-711","question":"In a network packet parser, a 32-bit field uses trailing-zero count to encode the length of a value. Given a 32-bit unsigned n, implement countTrailingZeros32(n) that returns the number of trailing zero bits (0-32). If n==0, return 32. Use only bitwise operations, shifts, and basic arithmetic, no loops or built-ins. Provide signature, brief justification, and 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Amazon","Google","Uber"]},{"id":"q-724","question":"In memory allocation, implement nextPowerOfTwo32(uint32_t n) that returns the smallest 32-bit unsigned power-of-two >= n, given n > 0, using only bitwise operations with no loops or conditionals. If the result would overflow 32 bits, return 0. What is the correct implementation signature and approach?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Apple","IBM","Uber"]},{"id":"q-730","question":"Given a 32-bit unsigned integer n, implement swapAdjacentBits32(n) that returns a new 32-bit value with every adjacent bit pair swapped (bits 0-1, 2-3, ..., 30-31). Use only bitwise operations, no loops or conditionals. Provide the function signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Amazon","Plaid","Twitter"]},{"id":"q-738","question":"Implement a 64-bit bit reversal function reverse64(uint64_t n) that returns the bitwise reversal of n (bit 0 becomes bit 63, bit 63 becomes bit 0). Use only bitwise operations and shifts, no loops or conditionals. Provide the function signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Lyft","MongoDB","PayPal"]},{"id":"q-747","question":"Implement isBinaryPalindrome32(uint32_t n) that returns 1 if the 32-bit binary representation of n is a palindrome (bit0 equals bit31, bit1 equals bit30, etc.), and 0 otherwise. Use only bitwise operations and shifts; no loops or conditional branches. Provide the function signature and a brief justification, plus 1-2 quick examples.\n\nExamples:\n- 0x80000001 is a palindrome\n- 0xA5A5A5A5 is not a palindrome?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Coinbase","Google","Netflix"]},{"id":"q-751","question":"Implement popcount64(uint64_t x) that returns the number of set bits in x using only bitwise operations and shifts, with no loops and no built-in popcount. Use a fixed SWAR approach with masks 0x5555555555555555ULL, 0x3333333333333333ULL, 0x0F0F0F0F0F0F0F0FULL and a final multiply/shift step. Provide the function signature and a brief justification, plus 1-2 quick examples of inputs and outputs?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Lyft","MongoDB","Snap"]},{"id":"q-757","question":"Given a 32-bit unsigned integer n, implement maskBelowLSB32(n) that returns a 32-bit mask with all bits at positions <= the least significant set bit of n turned on; if n is 0 return 0. Use bitwise operations and shifts (and optional arithmetic). Provide the signature, justification, and 1-2 examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Meta","Microsoft","Zoom"]},{"id":"q-776","question":"Implement a 64-bit bitboard function knightAttacks64(n) that returns a 64-bit mask of all squares attacked by knights, given a 64-bit bitboard n where 1s indicate knight positions. Use only bitwise operations and shifts, no loops or conditionals. Provide the signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Bloomberg","Netflix","Plaid"]},{"id":"q-783","question":"Given a 32-bit unsigned n, implement hasPattern101(n) that returns true if there exists any i such that bits i, i+1, i+2 form 101 (n_i=1, n_{i+1}=0, n_{i+2}=1). Use only bitwise operations and shifts, no loops or conditionals. Provide the function signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Apple","Plaid","Slack"]},{"id":"q-791","question":"Implement parity32(n) that returns 1 if the number of set bits in a 32-bit unsigned n is odd, otherwise 0. Do not use loops or built-ins; only bitwise ops and shifts. Provide function signature parity32(uint32_t n) and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Databricks","DoorDash"]},{"id":"q-798","question":"Implement nextHigherWithSamePopcount64(uint64_t n) that returns the smallest integer greater than n with the same number of 1-bits. Use only bitwise operations and shifts; no loops or conditionals. If no such number exists, return 0. Provide the function signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Google","Two Sigma"]},{"id":"q-807","question":"Implement rotateLeft128 by k on a 128-bit value stored as two 64-bit words (hi, lo). The function rotates within the 128-bit boundary by k bits (0 <= k < 128) using only bitwise operations and shifts, no loops or conditionals. Provide the signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"advanced","tags":["bit-manipulation"],"companies":["Google","Meta","Twitter"]},{"id":"q-814","question":"Implement interleave16(uint16_t a, uint16_t b) that returns a 32-bit value with bits interleaved as a0 b0 a1 b1 ... a15 b15, where a0 is LSB of a and b0 is LSB of b. Use only bitwise operations and shifts (no loops or conditionals). Provide the function signature and a brief justification, plus 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"intermediate","tags":["bit-manipulation"],"companies":["Adobe","Snowflake","Zoom"]},{"id":"q-823","question":"Implement rotateLeft32(uint32_t n, unsigned int k) that returns the 32-bit value formed by rotating n left by k bits. Constraints: no loops or conditionals; handle k >= 32 by using k % 32. Provide the function signature and a brief justification, and give 1-2 quick examples?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Citadel","LinkedIn","Stripe"]},{"id":"q-830","question":"Implement xor32(uint32_t a, uint32_t b) that returns a ^ b without using the ^ operator. Use only &, |, ~ and shifts. Provide the function signature and a brief justification, plus 1-2 quick examples to verify correctness?","channel":"bit-manipulation","subChannel":"general","difficulty":"beginner","tags":["bit-manipulation"],"companies":["Instacart","Netflix"]},{"id":"q-1091","question":"Scenario: An OTA firmware update causes GPS altitude drift in a subset of IoT devices across regions. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API for CAPAs with device logs, 4) region/device-type metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollback plan for OTA updates?","channel":"capa","subChannel":"general","difficulty":"intermediate","tags":["capa"],"companies":["Plaid","Snowflake","Tesla"]},{"id":"q-1111","question":"Scenario: Production ML feature store drift after a data refresh degrades latency and CTR across regions due to stale features and late streaming data. Propose a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPAs, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove containment and recurrence, 5) an RCA template and a canary rollout plan to prevent recurrence during future refreshes?","channel":"capa","subChannel":"general","difficulty":"advanced","tags":["capa"],"companies":["LinkedIn","Tesla"]},{"id":"q-1132","question":"Scenario: batch ingestion misses PII masking in two tenants across regions, raising privacy risk. Design a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant/region-aware metrics to prove containment and recurrence (MTTD, MTTR, false positives), 5) an RCA template and a canary rollout plan to validate policy enforcement before global deployment?","channel":"capa","subChannel":"general","difficulty":"advanced","tags":["capa"],"companies":["Coinbase","MongoDB","Salesforce"]},{"id":"q-1156","question":"Scenario: A distributed streaming analytics pipeline processes click events for an online marketplace. A recently deployed shard rebalancing causes out-of-order events in two regions, leading to incorrect revenue attribution and fraud alerts. Design a CAPA program that covers: 1) a CAPA data model that captures evidence (events, traces, timestamps, orderings) and artifacts (config, manifest, canary results), 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces and event metadata, 4) region- and shard-aware metrics to prove containment (recurrence rate, MTTR, misattribution rate), 5) an RCA template and a canary-rollback plan for shard rebalancing?","channel":"capa","subChannel":"general","difficulty":"advanced","tags":["capa"],"companies":["Amazon","Apple"]},{"id":"q-1200","question":"Scenario: A global real-time telemetry platform for autonomous vehicles experiences intermittent PII exposure due to a log-redaction misconfiguration after a software update in two regions. Design a CAPA program to detect, document, and prevent recurrence. Include: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant- and region-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary-based rollback/patch plan, 6) a policy gate preventing deployment until redact coverage is above threshold?","channel":"capa","subChannel":"general","difficulty":"advanced","tags":["capa"],"companies":["MongoDB","Tesla"]},{"id":"q-841","question":"Design a CAPA workflow for a high-volume platform (Airbnb/LinkedIn scale). The system must log incidents, perform RCA, implement corrective and preventive actions, and verify outcomes before closing. Provide: 1) a CAPA data model, 2) a lifecycle state machine, 3) an API surface to create/update CAPAs, 4) metrics to prove effectiveness (recurrence rate, time-to-close)?","channel":"capa","subChannel":"general","difficulty":"advanced","tags":["capa"],"companies":["Airbnb","LinkedIn"]},{"id":"q-937","question":"Scenario: A post-rollout incident caused latency spikes and higher error rates for a subset of regions when a new feature flag was enabled. Design a beginner-friendly CAPA to address this. Your task: 1) propose a CAPA data model, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with evidence, 4) specify practical metrics to prove effectiveness, 5) provide a simple RCA template and a canary-based preventive action you would test before full rollout?","channel":"capa","subChannel":"general","difficulty":"beginner","tags":["capa"],"companies":["DoorDash","Twitter"]},{"id":"q-965","question":"Scenario: A multilingual moderation model update causes spikes in unsafe content in two locales. Design a beginner CAPA plan focusing on locale-scoped evidence, drift checks, and a safe rollback with feature flags. Include: 1) a CAPA data model, 2) a lifecycle machine, 3) a minimal REST API to capture CAPAs with evidence, 4) locale-specific success metrics, 5) an RCA template and a locale-specific canary plan for preview before global rollout?","channel":"capa","subChannel":"general","difficulty":"beginner","tags":["capa"],"companies":["Apple","Hugging Face"]},{"id":"q-986","question":"Scenario: After a schema evolution in the event ingestion pipeline, latency spikes and incorrect bids appear in two regions. Design a CAPA program with: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove effectiveness (recurrence rate, mean time to containment, false-positive rate), 5) an RCA template and a canary rollout plan to validate before global deployment?","channel":"capa","subChannel":"general","difficulty":"intermediate","tags":["capa"],"companies":["Citadel","Oracle","Uber"]},{"id":"q-1020","question":"You’re evaluating a beginner feature: a daily market digest in a Robinhood-like app. Do a practical cost‑benefit analysis: state assumptions, estimate data/API costs, storage and engineering time, quantify benefits (retention lift, ARPU), and compute break-even time. Provide a rough calculation and rationale?","channel":"cba","subChannel":"general","difficulty":"beginner","tags":["cba"],"companies":["MongoDB","NVIDIA","Robinhood"]},{"id":"q-1052","question":"Scenario: Real-time ingestion service receives JSON events from edge devices. Guarantee per-user throughput while allowing bursts in a distributed cluster. Design and implement a practical throttling mechanism, specify data structures, atomicity (e.g., Redis Lua script), failure modes, testing strategy, and observability?","channel":"cba","subChannel":"general","difficulty":"intermediate","tags":["cba"],"companies":["NVIDIA","OpenAI","Tesla"]},{"id":"q-1057","question":"In a real-time feed system using a contextual bandit with attention weighting (CBA), design a policy that balances short-term CTR and long-term engagement. Explain your reward decomposition, exploration strategy, and handling of non-stationarity. How would you validate offline with CPE and ramp online safely? Provide a concise update rule?","channel":"cba","subChannel":"general","difficulty":"advanced","tags":["cba"],"companies":["Hugging Face","Microsoft","Uber"]},{"id":"q-1084","question":"Given a large social network planning to adopt a real-time feature flag evaluation service that runs on a hybrid stream/batch pipeline. Current pipeline: 1.2M events/sec, median latency 50 ms, 5% tail. New service promises 20–30% latency reduction and 25% cost increase, plus migration risk. Perform a cost-benefit analysis: quantify costs, benefits, risks, horizon (12 months), and decision rule with sensitivity ranges?","channel":"cba","subChannel":"general","difficulty":"advanced","tags":["cba"],"companies":["LinkedIn","Meta","Snowflake"]},{"id":"q-1114","question":"You’re migrating a real-time feature flag engine (multi-tenant SaaS) to reduce tail latency and cost. Propose a three-phase migration: centralized eval, regional edge gateway, then hybrid routing with per-tenant caches. Specify success metrics, rollback criteria, and a 12-month plan?","channel":"cba","subChannel":"general","difficulty":"intermediate","tags":["cba"],"companies":["DoorDash","Hashicorp","Two Sigma"]},{"id":"q-1151","question":"In a real-time analytics system for engagement on a large social app, design a privacy-preserving cohort analytics pipeline that ingests ~3M events/sec with sub-100 ms latency per region. Requirements: data residency, differential privacy for cohort counts, delta- or exact-once streaming state, drift detection, and cost-conscious multi-region deployment. Outline architecture, data contracts, and trade-offs?","channel":"cba","subChannel":"general","difficulty":"intermediate","tags":["cba"],"companies":["Coinbase","Meta","Snap"]},{"id":"q-1209","question":"You’re building an offline-first version of a daily digest app for low-connectivity users. Outline a minimal data model, eviction policy, and a practical plan to quantify cost savings from reduced network usage versus increased storage and complexity; provide a concrete example with rough numbers?","channel":"cba","subChannel":"general","difficulty":"beginner","tags":["cba"],"companies":["Adobe","DoorDash","Goldman Sachs"]},{"id":"q-1238","question":"You're evaluating a beginner feature: a daily 'Portfolio Health Snap' panel that assigns a risk score to each user based on volatility of top holdings. Do a practical cost-benefit analysis: state assumptions, data/API costs, storage, and engineering time; quantify benefits (retention lift, ARPU) and compute break-even time. Provide rough calculations and rationale?","channel":"cba","subChannel":"general","difficulty":"beginner","tags":["cba"],"companies":["Adobe","Square","Two Sigma"]},{"id":"q-1274","question":"You're assessing migrating a high-volume telemetry pipeline from a centralized data warehouse to a lakehouse with streaming ingestion and on-demand materialized views. Current throughput 5M events/sec, latency 5–7 min; target latency 2–3 min, 25% cost increase. Build a 12-month cost-benefit model: incremental storage/compute, streaming infra, data egress, drift/rollback costs; specify decision rules and sensitivity ranges?","channel":"cba","subChannel":"general","difficulty":"intermediate","tags":["cba"],"companies":["Bloomberg","Citadel","Slack"]},{"id":"q-843","question":"Given a CSV file with columns user_id, action, timestamp, write a Python function using only the standard library that returns the most recent action per user by deduplicating on user_id and keeping the latest timestamp; describe time complexity and edge cases?","channel":"cba","subChannel":"general","difficulty":"beginner","tags":["cba"],"companies":["OpenAI","PayPal","Twitter"]},{"id":"q-872","question":"You are evaluating two deployment options for a new AI inference service under budget and latency constraints. Outline a practical, end-to-end cost-benefit analysis framework to decide which to deploy in production. Include: data you would collect (traffic, latency, SLA penalties, accuracy), metrics (NPV, ROI, payback), horizons, discount rate, handling uncertainty (scenarios), and a concrete calculation workflow you would run?","channel":"cba","subChannel":"general","difficulty":"advanced","tags":["cba"],"companies":["Meta","Scale Ai"]},{"id":"q-1010","question":"You're building a GPU-accelerated graph analytics pipeline that streams 1e9 edges. Design a cache coherence protocol (CCA) to keep per-vertex state consistent across 8 GPUs via a central directory. Choose directory vs snooping, invalidation vs update, and granularity. Describe data layout, coherence transitions, and a minimal update protocol with atomic operations; include trade-offs and performance tips?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["Amazon","LinkedIn","NVIDIA"]},{"id":"q-1102","question":"You’re building a real-time 'cca' analytics service ingesting 10k events/sec from multiple services; it must provide low latency, deduplicate, and support backfill. Describe the architecture, data model, and exactly-once strategy, including how you’d implement dedup, transactional writes, and testing under node failures. What trade-offs do you consider?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["Lyft","Netflix"]},{"id":"q-1106","question":"Design an end-to-end CDC pipeline that ingests change events from Salesforce and MongoDB and publishes to downstream consumers with at-least-once delivery. Explain your transport choice, deduplication, ordering across partitions, schema evolution, and strategies for backfills, replay, and rollbacks. Include monitoring, testing, and failover plans?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["MongoDB","Salesforce"]},{"id":"q-1190","question":"You're building a real-time collaborative whiteboard for a chat/video platform at Discord/Airbnb/Netflix scale. Each of 5–10k rooms can have up to 200 concurrent editors and must stay highly available with <100 ms latency. Explain your stack decisions: transport (WebSocket vs gRPC streaming), per-room state partitioning, operation encoding, and conflict resolution (CRDT vs OT). How would you handle exactly-once delivery and failure recovery?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["Airbnb","Discord","Netflix"]},{"id":"q-1211","question":"In a multi-region service, each region maintains a local L1 cache and a shared L2 cache. How would you implement a robust cache coherence protocol to prevent stale reads while keeping latency low during write-heavy workloads? Include data paths, an invalidation strategy (push vs TTL), race-condition handling, and testing approaches?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["Bloomberg","Microsoft"]},{"id":"q-1260","question":"You're building a real-time cca analytics service that ingests 20k-50k events/sec from multiple microservices and external partners. It must deliver per-user engagement scores with sub-second latency, handle out-of-order and late data, deduplicate events, and support backfill. Describe the end-to-end architecture, data model, and exactly-once strategy, including how you'd implement dedup, transactional writes, watermarking, and backfill testing under network partitions and clock skew?","channel":"cca","subChannel":"general","difficulty":"advanced","tags":["cca"],"companies":["Google","Uber","Zoom"]},{"id":"q-1296","question":"Design a privacy-conscious extension of a real-time cca analytics pipeline that computes per-user engagement scores across multiple geo-regions for three partner firms (Lyft, NVIDIA, Instacart). The extension must minimize PII exposure, support synthetic data feeds for testing without leaking real PII, provide auditable data events for compliance, and preserve correctness under backpressure, partition rebalancing, and clock skew. Describe architecture, data model changes, masking strategies, and how you’d validate with synthetic data?","channel":"cca","subChannel":"general","difficulty":"advanced","tags":["cca"],"companies":["Instacart","Lyft","NVIDIA"]},{"id":"q-840","question":"In a secure messaging service, ciphertexts are decrypted by a server with a decryption oracle exposed to clients, creating a potential CCA risk. Design a practical IND-CCA secure scheme for message confidentiality using existing primitives (e.g., OAEP, AES-GCM, MACs). Explain how you prevent chosen-ciphertext attacks, outline a concrete protocol, and discuss trade-offs?","channel":"cca","subChannel":"general","difficulty":"intermediate","tags":["cca"],"companies":["Microsoft","Oracle","Stripe"]},{"id":"q-879","question":"Describe a cross-region user preferences syncing protocol using MongoDB that tolerates regional partitions. Specify the data model (per-field version stamps), conflict resolution policy, and read/write configurations. Provide a concrete merge approach and an example conflict scenario?","channel":"cca","subChannel":"general","difficulty":"advanced","tags":["cca"],"companies":["Coinbase","MongoDB","Uber"]},{"id":"q-970","question":"You're shipping an E2E chat feature for an internal Meta–Microsoft product. An attacker may access a decryption oracle. Outline a concrete IND-CCA2 secure scheme for message exchange using public-key crypto, detailing padding (OAEP), a KEM/DEM split or AEAD wrapper, ephemeral keys, and how you bind metadata (timestamps, sender IDs) to prevent malleability. What are the failure modes and mitigations?","channel":"cca","subChannel":"general","difficulty":"advanced","tags":["cca"],"companies":["Meta","Microsoft"]},{"id":"q-1026","question":"Design a CGOA wrapper for a C library that provides two symbols: int* generate_seq(int n) which allocates an int array of length n via malloc filled with 0..n-1, and void free_seq(int* p) to free it. Provide the C header, the Go binding using CGO, and a small Go program that concurrently requests arrays of sizes 4 and 8, validates contents, and frees them. Include exact build steps?","channel":"cgoa","subChannel":"general","difficulty":"beginner","tags":["cgoa"],"companies":["Bloomberg","Coinbase","Oracle"]},{"id":"q-1099","question":"Given a C library with an asynchronous API: \n\n- void run_async(const char* input, void (*cb)(int status, const char* data, void* user), void* user);\n\nwhere the callback runs on a worker thread and data is malloc-allocated or NULL on error. Design a CGO-based Go wrapper that exposes RunAsync(input string, cb func(status int, data string, err error)). The wrapper must: manage the Go callback safely across C boundaries, free C data, map non-zero status to errors, and handle thread attachment; provide header + binding + minimal test harness to demonstrate safety?","channel":"cgoa","subChannel":"general","difficulty":"intermediate","tags":["cgoa"],"companies":["Google","LinkedIn","PayPal"]},{"id":"q-1207","question":"Design a CGO bridge for a C EventLib that exposes a function: void register_event_source(int stream_id, void (*cb)(int, const char*)); void start_event_loop(); Build a Go binding that lets two independent streams subscribe and receive events via a single exported Go callback, using a C shim to bridge into Go. Describe memory management and thread-safety; provide header, Go binding, and a small Go program demonstrating two streams; include build steps?","channel":"cgoa","subChannel":"general","difficulty":"advanced","tags":["cgoa"],"companies":["Hashicorp","Twitter","Two Sigma"]},{"id":"q-1235","question":"Implement a CGOA binding for an opaque C Counter handle. API: typedef struct Counter Counter; Counter* CounterNew(int); void CounterInc(Counter*, int); int CounterValue(Counter*); void CounterFree(Counter*); In Go wrap as type Counter with NewCounter, Inc, Value, Close. Show two goroutines each creating its own Counter, incrementing independently, and printing values to verify isolation and no data races. Include header, binding, and a minimal program with build steps?","channel":"cgoa","subChannel":"general","difficulty":"beginner","tags":["cgoa"],"companies":["Adobe","Instacart","Tesla"]},{"id":"q-1294","question":"Implement a CGOA bridge that lets C trigger a Go callback asynchronously when an external sensor fires events. Provide a C header and stub, a CGO binding in Go that registers a Go callback and routes events through an exported Go function, and a safe cleanup mechanism to release resources when producers stop?","channel":"cgoa","subChannel":"general","difficulty":"advanced","tags":["cgoa"],"companies":["Anthropic","Lyft","NVIDIA"]},{"id":"q-842","question":"You have a Go service using cgo to wrap a C API. A C function 'char* fetch_data(int id)' returns a malloc-allocated string or NULL on error. Design a safe Go wrapper that converts the result to a Go string, ensures the C allocation is freed, handles NULL with a meaningful error, and notes CGO thread-safety considerations. What implementation would you write?","channel":"cgoa","subChannel":"general","difficulty":"intermediate","tags":["cgoa"],"companies":["Meta","PayPal","Snowflake"]},{"id":"q-870","question":"Design a Go wrapper for a C API with malloc’d results that must be freed, exploring a new angle: ensure thread-safe, single-point ownership transfer for each call and robust error handling when the C call returns a non-zero code or NULL. API: typedef struct { int code; const char* msg; } ScanResult; ScanResult* perform_scan(const char* query); void free_scan_result(ScanResult*); Implement function: func Scan(query string) (string, error)?","channel":"cgoa","subChannel":"general","difficulty":"intermediate","tags":["cgoa"],"companies":["Instacart","Netflix"]},{"id":"q-914","question":"Using cgo, how would you wrap a C function that allocates a string (char*) and returns it, ensuring memory is freed by Go code without leaks, and provide a minimal working example?","channel":"cgoa","subChannel":"general","difficulty":"beginner","tags":["cgoa"],"companies":["Instacart","Snap","Twitter"]},{"id":"q-950","question":"Implement a minimal CGOA wrapper that exposes a C function int add(int a, int b) to Go. Provide the C header, the Go binding using CGO, and a small Go program that concurrently calls Add from two goroutines to demonstrate thread safety. Include build steps?","channel":"cgoa","subChannel":"general","difficulty":"beginner","tags":["cgoa"],"companies":["Google","Snap","Twitter"]},{"id":"q-978","question":"Design a CGO bridge for a C streaming API that delivers chunks via a callback: void stream_data(int id, void (*chunk_cb)(const char* data, size_t len, void*), void* ctx). Implement a Go wrapper StreamFromC(id int) (io.Reader, error) that buffers chunks into an io.Pipe and exposes a safe reader, supporting concurrent streams and proper backpressure. Include a C header, a Go CGO binding, and a simple consumer showing two goroutines reading from the reader?","channel":"cgoa","subChannel":"general","difficulty":"intermediate","tags":["cgoa"],"companies":["Goldman Sachs","Microsoft","NVIDIA"]},{"id":"q-987","question":"Implement a CGO binding for a C function char* greet(const char* name) that returns a newly allocated string. Provide the C header and implementation, a Go binding using CGO that wraps greet in a safe Go function returning (string, error), and a small Go program that concurrently calls the binding from multiple goroutines and frees the allocated memory. How would you handle NULL returns and memory deallocation robustly?","channel":"cgoa","subChannel":"general","difficulty":"beginner","tags":["cgoa"],"companies":["Google","MongoDB","Snap"]},{"id":"cissp-communication-network-1768227886993-3","question":"An organization wants to ensure the integrity and authenticity of DNS responses to prevent cache poisoning, while not necessarily encrypting DNS query payloads. Which mechanism provides this guarantee?","channel":"cissp","subChannel":"communication-network","difficulty":"intermediate","tags":["AWS","DNS","Terraform","certification-mcq","domain-weight-13"],"companies":null},{"id":"q-1097","question":"An enterprise with microservices deployed across AWS, Azure, and GCP stores API keys and credentials in Kubernetes secrets and environment variables. After an audit finds stale keys and overly broad service accounts, design a defense‑in‑depth credential management strategy: architecture changes, tooling choices (Vault, AWS Secrets Manager, KMS, Kubernetes CSI or equivalent), rotation cadence, access controls, and how you would validate effectiveness?","channel":"cissp","subChannel":"general","difficulty":"intermediate","tags":["cissp"],"companies":["Apple","Discord","Meta"]},{"id":"q-1113","question":"In a multi-tenant ML feature store on AWS, a compromised notebook can access all tenants due to broad IAM policy. Propose a concrete mitigation plan to enforce tenant isolation and data protection: separate namespaces, least-privilege roles with explicit ARNs, ABAC tags (TenantID/DataClass), SCPs to block cross-tenant actions, VPC isolation with PrivateLink, per-tenant KMS keys, and centralized logging with CloudTrail, Config, and GuardDuty. Include testing steps?","channel":"cissp","subChannel":"general","difficulty":"intermediate","tags":["cissp"],"companies":["Scale Ai","Twitter"]},{"id":"q-958","question":"Scenario: A fintech startup uses cloud IAM for multi-cloud apps. Admins use weak passwords and MFA is not enforced; API keys are shared in chat and stored insecurely. You’re asked to pick one first CISSP-aligned control to reduce risk while enabling operations. Which baseline control should be implemented first and why?","channel":"cissp","subChannel":"general","difficulty":"beginner","tags":["cissp"],"companies":["Coinbase","Google","Meta"]},{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","channel":"cka","subChannel":"general","difficulty":"intermediate","tags":["cka"],"companies":["Cloudflare","Scale Ai","Snap"]},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","channel":"cka","subChannel":"general","difficulty":"intermediate","tags":["cka"],"companies":["Cloudflare","Salesforce","Snap"]},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","channel":"cka","subChannel":"general","difficulty":"intermediate","tags":["cka"],"companies":["Cloudflare","IBM","Netflix"]},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","channel":"cka","subChannel":"general","difficulty":"intermediate","tags":["cka"],"companies":["Airbnb","Databricks","Google"]},{"id":"q-1066","question":"Inside namespace analytics, schedule a daily batch to process a CSV: use a CronJob (02:00 UTC) to start a Job that runs a Python script from a ConfigMap, reads input from a ConfigMap, uses a Secret for DB credentials to insert results into Postgres service, writes output to a PVC, runs as non-root with a readOnlyRootFilesystem, with resource limits, a backoffLimit of 3, and a 15-minute activeDeadlineSeconds; ensure proper probes?","channel":"ckad","subChannel":"general","difficulty":"advanced","tags":["ckad"],"companies":["Goldman Sachs","Microsoft","Snowflake"]},{"id":"q-858","question":"In a Kubernetes CKAD scenario, you have a Deployment named 'web-app' in namespace 'prod' with 3 replicas; pods frequently OOMKilled under load. Describe a practical debugging plan and provide a minimal manifest patch showing resource requests/limits, a readiness probe, and a liveness probe. Include scaling considerations and how you'd validate the fix under load?","channel":"ckad","subChannel":"general","difficulty":"intermediate","tags":["ckad"],"companies":["Hugging Face","LinkedIn","Snowflake"]},{"id":"q-1180","question":"Design a CKNE-aware per-tenant admission control for a multi-tenant real-time analytics gateway. Downstream CKNE health signals (queue depth, latency, error rate) are exposed via metadata. Propose a per-tenant health score, a dynamic token-bucket policy, and a cross-tenant shedding strategy that preserves fairness and SLA compliance. Include payload schemas, a minute-by-minute control loop, and a minimal sample payload?","channel":"ckne","subChannel":"general","difficulty":"advanced","tags":["ckne"],"companies":["Goldman Sachs","Meta","Snap"]},{"id":"q-1198","question":"Design a CKNE-aware per-tenant traffic shaping policy for a real-time collaboration platform (gateway -> engine -> persistence) servicing thousands of tenants with different SLAs. Edge CKNE health signals drive a minute-by-minute token-bucket shedding policy that prioritizes high-SLA tenants while gracefully degrading others; specify payload schemas and provide a minimal test plan?","channel":"ckne","subChannel":"general","difficulty":"advanced","tags":["ckne"],"companies":["Discord","Snap"]},{"id":"q-1214","question":"Design a CKNE-aware data lineage policy for a three-stage ETL pipeline (ingest → transform → load) servicing thousands of tenants. Each hop attaches CKNE health in trace metadata. Propose a per-tenant degradation policy that preserves auditability for high‑SLA tenants while shedding heavy lineage data during degradation. Include payload schema, a minute-by-minute decision loop, and a minimal payload example?","channel":"ckne","subChannel":"general","difficulty":"beginner","tags":["ckne"],"companies":["Anthropic","Google","Scale Ai"]},{"id":"q-1280","question":"Scenario: A serverless workflow (API gateway -> orchestrator -> worker) serves thousands of tenants. Design a CKNE-aware tracing approach where every hop propagates a CKNE health signal in trace metadata and implement a per-tenant adaptive sampling policy that starts at 3% and scales to 25% during degradation. Include payload schemas, per-tenant health aggregation at the orchestrator, strategies to preserve trace fidelity during micro-bursts, and a minute-by-minute loop mapping health to sampling for the next window; provide a minimal payload example and a test plan?","channel":"ckne","subChannel":"general","difficulty":"intermediate","tags":["ckne"],"companies":["Discord","Microsoft","Netflix"]},{"id":"q-1289","question":"Design a CKNE-aware canary rollout strategy for a multi-tenant image-resize API (ingest -> process -> deliver). Each tenant's requests carry CKNE health in headers. Propose a per-tenant rollout policy that starts at 5% canary, scales to 40% during healthy conditions, and reverts on degradation, with a minute-by-minute control loop. Include payload schemas, edge aggregation, and a minimal payload example?","channel":"ckne","subChannel":"general","difficulty":"beginner","tags":["ckne"],"companies":["Amazon","Meta","NVIDIA"]},{"id":"q-846","question":"Design a real-time CKNE failure detector for a distributed microservice mesh. Specify the data pipeline, latency budget, how you compute p95 latency and error rate, and how you implement replay and backpressure for fault tolerance. Include testing strategies and production validation to demonstrate correctness and resilience?","channel":"ckne","subChannel":"general","difficulty":"advanced","tags":["ckne"],"companies":["Coinbase","Meta","NVIDIA"]},{"id":"q-861","question":"Design an adaptive CKNE-aware tracing and sampling strategy for a real-time order-processing pipeline in a multi-tenant mesh. Explain how CKNE health signals influence sampling decisions, how you preserve trace fidelity under bursts, and how you quantify the overhead and impact on latency. Include concrete data structures and an example workflow?","channel":"ckne","subChannel":"general","difficulty":"intermediate","tags":["ckne"],"companies":["PayPal","Snap","Tesla"]},{"id":"q-954","question":"Scenario: A three-service order flow (API gateway -> inventory -> payment) runs in one region. Design a CKNE-aware tracing approach where each service propagates a CKNE health signal in trace metadata and employs an adaptive sampling policy: base 10% with a health-adjusted factor that can raise sampling to 50% during degradation. Specify data structures for per-service health, the trace metadata payload, and a minute-by-minute workflow to compute health and adjust sampling for the next window. Provide a minimal code snippet showing the payload and health update logic?","channel":"ckne","subChannel":"general","difficulty":"beginner","tags":["ckne"],"companies":["Goldman Sachs","IBM"]},{"id":"q-991","question":"Design a CKNE-aware tracing strategy for a real-time ad bidding pipeline (gateway -> bidding service -> settlement) servicing multi-tenant advertisers. Each leg propagates a CKNE health signal; implement an adaptive sampling policy that scales from 5% baseline to 60% during degradation, with per-tenant health aggregation at the edge. Specify payload schemas, how to preserve trace fidelity under micro-burst traffic, and a minute-by-minute workflow for health-to-sampling decisions; provide a minimal payload example and a test plan?","channel":"ckne","subChannel":"general","difficulty":"advanced","tags":["ckne"],"companies":["NVIDIA","Netflix","Stripe"]},{"id":"q-1121","question":"Scenario: You operate a shared Kubernetes cluster serving multiple product teams. You must prevent cross-namespace data leakage and enforce least-privilege access while remaining auditable and scalable. Describe a concrete strategy using either OPA Gatekeeper or Kyverno for admission control (with at least two constraints), implement namespace RBAC boundaries, apply Calico NetworkPolicy for namespace isolation, and outline a monitoring/audit plan with tests and runbooks. Include example policies and a minimal test commands snippet?","channel":"cks","subChannel":"general","difficulty":"intermediate","tags":["cks"],"companies":["Google","IBM","Snap"]},{"id":"q-1130","question":"You're running a Kubernetes cluster for a web app. A Pod mounting hostPath and running as root was detected in dev. Outline a practical plan to enforce least privilege across namespaces (Baseline/Restricted) using a policy engine (Kyverno or OPA Gatekeeper) and show how you would validate enforcement without disrupting workloads. What steps and files would you use?","channel":"cks","subChannel":"general","difficulty":"beginner","tags":["cks"],"companies":["Amazon","Google"]},{"id":"q-1167","question":"Scenario: You operate a multi-cluster Kubernetes data platform (cloud+on‑prem) where a Spark job can access customer data. Design an end-to-end approach to detect, prevent, and respond to data exfiltration attempts from pods across clusters. Include policy design, telemetry signals, enforcement, and incident runbooks; discuss trade-offs?","channel":"cks","subChannel":"general","difficulty":"advanced","tags":["cks"],"companies":["Bloomberg","Instacart"]},{"id":"q-1278","question":"Scenario: A fintech data platform runs a multi-tenant data lake on Kubernetes. Each data job uses per-job ServiceAccounts to access restricted cloud storage. A rogue pod tries to exfiltrate data via the bucket. Propose a security approach that binds each pod to a dedicated cloud IAM role (workload identity), enforces namespace-scoped permissions, and provides tamper-evident audit trails. Include detection and response for abnormal egress and a safe rotation plan. What trade-offs?","channel":"cks","subChannel":"general","difficulty":"advanced","tags":["cks"],"companies":["DoorDash","Robinhood"]},{"id":"q-1301","question":"You're debugging a Kubernetes deployment in a multi-tenant environment where one namespace's pods delay startup by several minutes. Provide a practical, beginner-friendly diagnostic flow focusing on pod events, init containers, image pulls, and config maps. List concrete kubectl commands you would run and how you’d determine the root cause?","channel":"cks","subChannel":"general","difficulty":"beginner","tags":["cks"],"companies":["Anthropic","Netflix","Twitter"]},{"id":"q-920","question":"In a real-time chat service like Discord, deployed on Kubernetes with NVIDIA GPUs for video processing, you introduce a third-party plugin system that runs as WebAssembly modules to apply custom video filters. How would you design a secure plugin sandbox and runtime attestation to prevent leakage of streams or keys, ensure isolation from other plugins, and enable rapid rollback if a plugin behaves unexpectedly in production? Provide concrete approaches and trade-offs?","channel":"cks","subChannel":"general","difficulty":"intermediate","tags":["cks"],"companies":["Discord","NVIDIA","Zoom"]},{"id":"q-959","question":"Scenario: A service executes user-provided Python plugins inside a container. Design a concrete runtime hardening plan using Linux namespaces, a minimal seccomp profile, and capability bounding, ensuring plugins cannot access host files or network directly while preserving IPC with a controlled channel. Outline exact steps and validation tests?","channel":"cks","subChannel":"general","difficulty":"beginner","tags":["cks"],"companies":["PayPal","Tesla"]},{"id":"q-967","question":"Scenario: You manage a microservice app deployed to Kubernetes with CI/CD; you need to prevent tampered container images. **Describe a practical, beginner-friendly plan** to implement image signing and verification using **cosign**, integrate it into a GitHub Actions workflow, and enforce verification at deployment (registry or admission webhook). Include concrete commands?","channel":"cks","subChannel":"general","difficulty":"beginner","tags":["cks"],"companies":["Apple","NVIDIA","Stripe"]},{"id":"q-994","question":"Scenario: A Kubernetes-based ML platform serves multiple teams; outbound data exfiltration is a breach risk. Propose a concrete, end-to-end control plane approach to prevent unauthorized data egress using policy-as-code, Kubernetes NetworkPolicy, and a centralized egress gateway. Include a sample Rego policy for Gatekeeper that enforces a namespace label data-export=allowed and an annotation egress-proxy=https://proxy.internal, and outline testing and GitOps integration?","channel":"cks","subChannel":"general","difficulty":"intermediate","tags":["cks"],"companies":["OpenAI","Zoom"]},{"id":"q-1019","question":"You're operating a CNF-based API gateway cluster that terminates TLS for thousands of tenants across 3 regions. A mandate requires migrating all TLS to post-quantum algorithms with per-tenant keys sourced from an HSM, while delivering zero-downtime upgrades, per-tenant key isolation, and a rollback plan. Outline an end-to-end rollout including (a) inventory and compatibility checks, (b) PQC algorithm and certificate strategy, (c) HSM PKCS#11 integration and key rotation, (d) canary/traffic-mirror rollout and drift detection, (e) observability and rollback criteria?","channel":"cnf-certification","subChannel":"general","difficulty":"advanced","tags":["cnf-certification"],"companies":["Goldman Sachs","LinkedIn","PayPal"]},{"id":"q-1040","question":"You're deploying a CNF-based UDP gateway across four data centers. A CVE requires hardware-backed attestation before image execution. Outline a concrete end-to-end rollout plan that (a) signs CNF images with Cosign and SBOMs, (b) enforces attestation via TPM 2.0-based attestation bundles and ImagePolicyWebhook, (c) rolls out region-by-region with traffic mirroring and per-tenant quotas, (d) implements drift detection and automated rollback on attestation failure, and (e) provides observability for attestation metrics and rollback triggers?","channel":"cnf-certification","subChannel":"general","difficulty":"intermediate","tags":["cnf-certification"],"companies":["Adobe","OpenAI"]},{"id":"q-1071","question":"You're deploying a CNF-based API gateway across 2 Kubernetes clusters. A recent upgrade causes a cross-tenant data bleed under load due to a shared in-memory cache. Outline a beginner-friendly, end-to-end plan to fix and roll out safely: (a) reproduce in staging with two tenants and isolated traffic, (b) implement tenant-scoped cache keys and per-tenant isolation checks, (c) add unit/integration tests for isolation, (d) perform blue/green canary rollout with tenant-based traffic splits, (e) observability: per-tenant SLA metrics and automatic rollback if bleed is detected. Include a minimal code snippet for tenant-scoped cache key?","channel":"cnf-certification","subChannel":"general","difficulty":"beginner","tags":["cnf-certification"],"companies":["Discord","Stripe","Two Sigma"]},{"id":"q-1081","question":"You're deploying a CNF-based API gateway that uses workload identities for tenants. Describe an end-to-end plan to enforce identity attestation and per-tenant isolation using SPIRE for SPIFFE IDs, OPA Gatekeeper for policy decisions, and a local Kind testbed. Include (a) issuing and rotating SVIDs, (b) encoding tenant permissions in policies, (c) testing isolation with two tenants, and (d) observability hooks for attestation and policy evaluations?","channel":"cnf-certification","subChannel":"general","difficulty":"beginner","tags":["cnf-certification"],"companies":["Lyft","Meta"]},{"id":"q-1107","question":"You're deploying a CNF-based API gateway serving two tenants with strict data-retention and per-tenant log-redaction requirements. Outline an end-to-end plan using SPIRE for workload identities and OPA Gatekeeper for policy decisions to enforce data handling rules while enabling zero-downtime upgrades in a local Kind testbed. Include (a) SVID issuance/rotation tied to tenant IDs, (b) tenant-scoped policies for retention windows and redaction, (c) runtime redaction checks on logs/traces, (d) cross-tenant isolation testing under load, and (e) observability hooks for attestation, policy decisions, and redaction misses?","channel":"cnf-certification","subChannel":"general","difficulty":"intermediate","tags":["cnf-certification"],"companies":["Google","Meta","Twitter"]},{"id":"q-1187","question":"A beginner CNF certification scenario: you implement a gated CI/CD pipeline for a CNF gateway image. Outline an end-to-end workflow to ensure image provenance before deployment: (a) sign CNF images with Cosign using a KMS-backed key, (b) generate and publish SBOMs, (c) enforce signatures via ImagePolicyWebhook, and (d) surface observability in the monitoring stack for signing success/failure and rollback signals. Provide concrete steps and minimal config snippets?","channel":"cnf-certification","subChannel":"general","difficulty":"beginner","tags":["cnf-certification"],"companies":["Instacart","LinkedIn","Tesla"]},{"id":"q-1221","question":"You're operating a CNF-based API gateway deployed across three regions behind a service mesh. Propose a practical upgrade workflow that enforces runtime integrity along with image attestations: (a) sign images with Cosign using a KMS-backed key and publish SBOMs, (b) require TPM/measured-boot attestation plus runtime integrity checks for CNFs, (c) roll out region-by-region with per-tenant canaries and live connection migration, (d) implement drift detection and automatic rollback on attestation/runtime mismatch, (e) surface observability for sign-off, attestation, and rollback triggers. Provide minimal config references?","channel":"cnf-certification","subChannel":"general","difficulty":"advanced","tags":["cnf-certification"],"companies":["Netflix","Plaid"]},{"id":"q-847","question":"You're deploying a CNF gateway (e.g., NGINX CNF) on a 50-node Kubernetes cluster handling streaming traffic. A node eviction hits during peak load. Outline a concrete plan to maintain streaming availability, focusing on (1) graceful drain with preStop, (2) health checks/readiness/liveness, and (3) traffic affinity and pod topology, and (4) observability and rollout strategy?","channel":"cnf-certification","subChannel":"general","difficulty":"intermediate","tags":["cnf-certification"],"companies":["Netflix","Plaid","Tesla"]},{"id":"q-918","question":"You're rolling out a CNF-based NAT gateway across a 3-region multi-cluster Kubernetes setup. A policy change must be applied without disrupting live traffic. Outline a concrete, end-to-end rollout plan emphasizing (a) shadow canaries with traffic mirroring, (b) region-by-region rollout with per-region SLI targets, (c) policy-state reconciliation and drift detection, (d) rollback conditions and observability instrumentation?","channel":"cnf-certification","subChannel":"general","difficulty":"intermediate","tags":["cnf-certification"],"companies":["Citadel","Coinbase"]},{"id":"q-935","question":"You manage CNF-based gateways across 4 regions. A suspected supply-chain compromise requires enforcing in-cluster image attestations before rollout without downtime. Outline an end-to-end plan to (a) sign CNF images with Cosign and SBOMs, (b) enforce signatures via ImagePolicyWebhook, (c) roll out region-by-region with traffic mirroring, (d) implement drift detection and automatic rollback on attestation failure. Include observability?","channel":"cnf-certification","subChannel":"general","difficulty":"intermediate","tags":["cnf-certification"],"companies":["IBM","Tesla","Two Sigma"]},{"id":"q-985","question":"Design a zero-downtime, CNF-based API gateway rollout where per-tenant routing rules update live without dropping connections. Outline end-to-end steps: (a) safe rule distribution, (b) canary-ingress slicing with weighted traffic, (c) drift detection between desired and active routes, (d) observability and rollback?","channel":"cnf-certification","subChannel":"general","difficulty":"advanced","tags":["cnf-certification"],"companies":["Goldman Sachs","Meta","Tesla"]},{"id":"q-1051","question":"CNPA stack: HTTP API writes to PostgreSQL and emits Kafka events. A hot, large users table needs a non-blocking schema change (e.g., adding a new NOT NULL column with default). Propose a production-grade online migration plan that minimizes downtime, keeps Kafka in sync, handles backfill, and describes rollback and validation steps?","channel":"cnpa","subChannel":"general","difficulty":"advanced","tags":["cnpa"],"companies":["Amazon","Instacart","Plaid"]},{"id":"q-1150","question":"In a CNPA stack: HTTP API ingests events, writes to PostgreSQL, and publishes to Kafka; during spikes, retries duplicate processed events. Propose a concrete, end-to-end plan to guarantee idempotent processing and prevent duplicates under retry storms. Include idempotency key strategy, dedup enforcement point, Kafka/DB coordination, and validation?","channel":"cnpa","subChannel":"general","difficulty":"advanced","tags":["cnpa"],"companies":["Netflix","Snap","Twitter"]},{"id":"q-1157","question":"CNPA pipeline uses an HTTP API -> PostgreSQL -> Kafka with Avro schemas in a Schema Registry. A new optional field is added to the events, and some consumers crash when they see older versions. Provide a concrete, zero-downtime plan for schema evolution, including compatibility mode, rollout strategy, topic/consumer changes, backfill approach, rollback, and validation?","channel":"cnpa","subChannel":"general","difficulty":"advanced","tags":["cnpa"],"companies":["Anthropic","Hugging Face","Salesforce"]},{"id":"q-1188","question":"CNPA stack: an HTTP API writes to PostgreSQL and publishes to Kafka. During peak load, duplicate events may be produced due to retries and at-least-once semantics. Describe a concrete end-to-end plan to enforce idempotent processing across HTTP, DB, and Kafka, including dedupe strategy, upsert/constraints, transactional writes, offset tracking, and how you’d validate correctness under load?","channel":"cnpa","subChannel":"general","difficulty":"intermediate","tags":["cnpa"],"companies":["Meta","PayPal","Tesla"]},{"id":"q-1283","question":"CNPA stack with HTTP API, PostgreSQL, Kafka, and Redis: a Redis-based rate limiter fronting the API causes legitimate bursts to be 429-throttled during a promo, despite normal traffic. Provide a concrete debugging plan to isolate whether latency or errors come from Redis Lua script, Redis network, the HTTP handler, or downstream services, with exact metrics and concrete fixes and how you’d validate impact?","channel":"cnpa","subChannel":"general","difficulty":"beginner","tags":["cnpa"],"companies":["DoorDash","PayPal"]},{"id":"q-845","question":"In a MongoDB-backed service, read latency tails spike during peak hours. Provide a concrete, practical debugging plan to determine whether the bottleneck is network, driver, query plan, or index design. Include exact steps, metrics to collect, and concrete changes (indexes, readConcern, pooling) you would apply, plus how you would verify impact?","channel":"cnpa","subChannel":"general","difficulty":"intermediate","tags":["cnpa"],"companies":["Anthropic","Lyft","MongoDB"]},{"id":"q-873","question":"A CNPA service receives events over HTTP, writes to PostgreSQL, and publishes to Kafka. During peak hours, read latency spikes. Describe a concrete debugging plan to determine whether the bottleneck is the HTTP handler, the DB query, or the Kafka producer, including exact steps, metrics to collect, and concrete changes (indexes, pooling, prepared statements, idempotent producer) and how you would verify impact?","channel":"cnpa","subChannel":"general","difficulty":"beginner","tags":["cnpa"],"companies":["Databricks","Instacart","NVIDIA"]},{"id":"q-903","question":"In a CNPA stack, an HTTP API writes to Postgres, publishes to Kafka, and a Redis-backed dashboard consumes the stream. During peak load, HTTP latency tails spike. Provide a concrete debugging plan to isolate whether the bottleneck is HTTP, DB, Kafka, producer, consumer, or Redis, with exact metrics, sampling, and concrete changes (pooling, prepared statements, acks, batch sizes, caching strategies) and how you would verify impact?","channel":"cnpa","subChannel":"general","difficulty":"intermediate","tags":["cnpa"],"companies":["Bloomberg","Meta","Tesla"]},{"id":"q-928","question":"In a CNPA stack consisting of an HTTP API, PostgreSQL, Kafka, and Redis, latency tails spike under peak load. Provide a concrete, beginner-friendly plan to enable end-to-end tracing with OpenTelemetry to pinpoint the bottleneck. Include trace propagation, spans for HTTP handler, DB query, Kafka publish/consume, Redis access, and verification steps with a sample end-to-end trace?","channel":"cnpa","subChannel":"general","difficulty":"beginner","tags":["cnpa"],"companies":["Discord","Hashicorp","Netflix"]},{"id":"q-957","question":"CNPA stack with HTTP API, PostgreSQL, Kafka, and Redis dashboards requires a schema evolution: add a new optional field region_id to event records without downtime or breaking producers/consumers. Describe a practical, step-by-step migration plan: DB changes, schema registry versioning, producer/consumer updates, data backfill, testing, and rollback strategies, ensuring end-to-end consistency?","channel":"cnpa","subChannel":"general","difficulty":"intermediate","tags":["cnpa"],"companies":["PayPal","Scale Ai"]},{"id":"q-1193","question":"You have an array A of n positive integers and a threshold T. For a given window length L, define ok(L) as: there exists a subarray of length L with sum <= T. Design an O(n) check for ok(L) using a sliding window, then outline how to find the maximum L with binary search over [1..n], and analyze total time and space. Include edge-case handling and practical optimizations?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Airbnb","Snowflake","Tesla"]},{"id":"q-1254","question":"You're given a DAG G=(V,E) with N nodes and M edges. Edges can be inserted online in batches of size B. Design a dynamic transitive-closure using bitsets to answer reachability queries in O(1). Provide initialization, amortized per-batch update time, and memory. Include two practical optimizations and compare to recomputing the closure after each batch?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Goldman Sachs","Square","Two Sigma"]},{"id":"q-678","question":"In a directed acyclic graph with N nodes and M edges, all edge costs are nonnegative. Compute the minimum-cost path from S to T. Costs can decrease online; design a strategy to maintain shortest paths with updates, aiming for sublinear re-computation on average. Provide initial complexity and amortized update complexity, plus memory usage and practical optimizations?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Lyft","Meta","Oracle"]},{"id":"q-690","question":"Design a data structure to support two online operations on an integer array A of length N: 1) rangeAdd(l, r, delta) adds delta to A[i] for l <= i <= r, 2) queryMaxSubarray() returns the maximum subarray sum of the current A. Provide a structure that supports both operations in O(log N) time, describe what to store per node, how to merge children, and how to apply a lazy add. Include correctness and complexity considerations?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Goldman Sachs","Microsoft"]},{"id":"q-700","question":"You're building a real-time analytics dashboard that shows the top-k most frequent event types from a high-volume log stream (e.g., clicks, errors). Each event has a string type. Design a data structure and algorithm to maintain the current top-k frequencies with online increments, aiming for roughly O(log k) update time and O(n) memory. Explain how you handle ties and memory growth, and compare with a naive approach that re-sorts after every insert?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Bloomberg","Google"]},{"id":"q-704","question":"Scenario: a directed graph with nonnegative weights and a fixed source S. Each batch updates up to B edges (increases or decreases). Propose a practical dynamic data structure to maintain exact distances from S to all nodes and answer distance queries S→T in polylog time, with sublinear amortized update time. Compare to rerunning Dijkstra after every batch; include expected bounds, memory usage, and practical heuristics?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Salesforce","Snap"]},{"id":"q-709","question":"Given a directed graph with nonnegative weights, a fixed source S, and a stream of online edge weight updates (both increases and decreases), design a dynamic SSSP data structure that maintains exact distances dist(S, v) for all v after each update. Aim for sublinear amortized update time per edge change; specify initial preprocessing, worst-case vs amortized bounds, memory usage, and practical optimizations. Provide a plan for applying this in a traffic-graph scenario with frequent but localized updates?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["OpenAI","PayPal"]},{"id":"q-721","question":"Given a fixed directed graph with nonnegative weights and a single source S, handle a batch of edge-weight decreases (no insertions/deletions). Design a dynamic algorithm to update the exact S→v distances after each batch with sublinear amortized per-edge cost. Specify data structures, provide an amortized bound, and discuss memory and practical optimizations for real-time traffic networks?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Lyft","NVIDIA","Two Sigma"]},{"id":"q-732","question":"Scenario: A data stream yields integers. At each time step, a new value enters a sliding window of fixed size W, and the oldest value leaves. Design a solution to maintain the top-2 most frequent values in the current window with fast updates. Compare a naive O(W) recompute to an augmented structure using a frequency map and a max-heap with lazy deletions. Provide update and query complexities and memory usage?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Meta","Twitter","Two Sigma"]},{"id":"q-740","question":"Scenario: An edge CDN collects response times in milliseconds for every request. Design a beginner-friendly online algorithm to maintain the median latency as new times arrive, using only inserts. Explain the data structure, update steps, and time/space bounds, assuming up to 1e6 entries?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Cloudflare","Coinbase","Oracle"]},{"id":"q-742","question":"In a DAG with N nodes and M edges, nonnegative edge weights. You maintain shortest-path distances from source S to a fixed set of target nodes {T1,...,Tk}. Edge weights can only decrease over time due to updates. After a batch of updates, you should update only the target distances that can improve, avoiding full re-relaxation. Propose a practical algorithm that lazily propagates decreases using the DAG’s topological order, such that total work across updates is sublinear on average. Provide update and query steps, concrete time bounds, and memory usage, plus optimizations?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Microsoft","Robinhood"]},{"id":"q-755","question":"You're maintaining real-time travel times in a citywide road network modeled as a weighted directed graph with nonnegative costs. Costs can only decrease as new data arrives. Design an incremental algorithm to keep the shortest-path distances from a fixed hub S to all nodes up-to-date after each edge-cost decrease, aiming for sublinear amortized update work. Provide initial SSSP complexity, amortized per-decrease update, memory usage, and practical optimization strategies?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Discord","Google","Zoom"]},{"id":"q-766","question":"## Prompt\n\nIn a dynamic directed graph G=(V,E) with nonnegative weights, edge latencies only decrease in batches. Design a practical, production-ready algorithm to maintain a (1+ε)-approximate SSSP tree from a source S under these updates, enabling distance queries dist(S,v) in O(log|V|) time. Target sublinear amortized update in |E| for batch updates, and linear space. Explain data structures, update bounds, and how you bound cascade effects?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Discord","Meta","OpenAI"]},{"id":"q-770","question":"Given a directed graph G=(V,E) with |V|=N and |E|=M, nonnegative weights, support online operations: 1) decreaseWeight(u,v,delta) with delta>0, 2) queryShortestPath(S,T) returning current shortest path length. Updates and queries are interleaved. Propose a data-structure and algorithm that achieves sublinear amortized reprocessing per update, justify amortized bounds, and discuss space and practical optimizations for massive graphs (N up to 1e6, M up to 1e7)?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Citadel","Lyft"]},{"id":"q-779","question":"You're building a real-time analytics component for a fintech platform. You must maintain the number of distinct values in the most recent W events in a streaming fashion. Implement two operations: append(v) to push a new event value, and distinctCount() to return the number of unique values among the last W events. Assume values are integers up to 1e9 and W can be large. Provide a simple approach with its time/memory costs, then describe an amortized-constant-time solution using a hashmap plus a circular buffer, and discuss edge cases (e.g., large W, many duplicates). How would you implement and analyze it?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Databricks","LinkedIn","Robinhood"]},{"id":"q-787","question":"You maintain N players with integer scores in the range 0..10000. You must support two online operations: 1) update(i, s) — set player i's score to s; 2) countLE(X) — return how many players have score <= X. Propose a data structure and algorithm to support both in O(log V) time per operation, where V=10001, and analyze space usage. Include initialization and a brief correctness sketch?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["Apple","Cloudflare","Snowflake"]},{"id":"q-796","question":"Given an array A of length N with integers in range [0, R). You implement a function to count distinct values by inserting each A[i] into a hash set, then return its size. 1) What is the time and space complexity in terms of N and D (distinct values)? 2) If R is small, propose a memory-efficient alternative and analyze its tradeoffs?","channel":"complexity-analysis","subChannel":"general","difficulty":"beginner","tags":["complexity-analysis"],"companies":["DoorDash","Netflix","PayPal"]},{"id":"q-803","question":"In a directed graph G=(V,E) with N nodes, M edges and nonnegative weights, a fixed source S, and an SSSP tree T. Edges can change weight online (increase or decrease), but no edges are added or removed. Propose a concrete, implementable strategy to maintain the SSSP efficiently, including data structures, update rules, and expected time bounds. Provide preprocessing, amortized per-update, and memory usage, plus practical optimizations and a concrete scenario where it shines (e.g., streaming latency updates)?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Instacart","LinkedIn"]},{"id":"q-808","question":"Dynamic path counting in a DAG: maintain the number of S→T paths of length at most L under online edge insertions and deletions. Propose a data structure and amortized update time bound in terms of N, M, L and #updates; discuss memory usage and how to handle large L and modulo arithmetic in practice?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Citadel","Snowflake","Zoom"]},{"id":"q-817","question":"Design a dynamic, multi-source shortest-path maintenance scheme for a directed graph with nonnegative weights. A fixed set of K hub nodes H must always have exact shortest-path distances to all nodes. Edges can be inserted or weights decreased online, in batches of size at most B. Provide initial preprocessing and a full-update algorithm, with (i) initial time, (ii) amortized update time per batch, and (iii) memory usage. Include two practical optimizations and compare to recomputing from scratch after each batch?","channel":"complexity-analysis","subChannel":"general","difficulty":"advanced","tags":["complexity-analysis"],"companies":["Bloomberg","PayPal","Uber"]},{"id":"q-827","question":"Design a dynamic distance labeling scheme for an undirected weighted graph that supports edge insertions and deletions online. Use a fixed hub set H to enable dist(u,v) queries via dist(u,v)=min_h dist(u,h)+dist(h,v) only if H covers all shortest paths. Explain maintenance of hub distances under updates, and bound update/query times and memory usage. Provide two optimizations and a comparison to recomputing from scratch?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Google","Meta","Microsoft"]},{"id":"q-831","question":"In an undirected weighted graph G=(V,E) with nonnegative weights, design a (1+ε)-approximate distance oracle based on a fixed landmark set L (|L|=k). Edges are only inserted online in batches of size B; no deletions. After each batch, specify: (i) preprocessing time and space to build distances from every landmark, (ii) amortized update time per batch to update the oracle, (iii) query time for dist(u,v), (iv) total memory, (v) two practical optimizations, (vi) a comparison to rebuilding all-pairs distances after each batch. Provide concrete asymptotics in terms of n=|V|, m=|E|, k, ε, B?","channel":"complexity-analysis","subChannel":"general","difficulty":"intermediate","tags":["complexity-analysis"],"companies":["Instacart","Microsoft","NVIDIA"]},{"id":"q-1028","question":"Your team runs a multi-tenant SaaS analytics platform on Kubernetes in AWS. Each tenant lives in an isolated namespace with 100+ microservices. Explain how you enforce least privilege RBAC, ephemeral credentials with automatic rotation, secrets management, mTLS/workload identity (SPIFFE/SPIRE), policy-driven runtime enforcement, and a playbook for detecting and responding to cross-tenant data exfiltration?","channel":"comptia-security-plus","subChannel":"general","difficulty":"intermediate","tags":["comptia-security-plus"],"companies":["Airbnb","Google","Meta"]},{"id":"q-1034","question":"In a multi-region SaaS platform running 3,000 microservices on Kubernetes in AWS with a shared data lake, design a secure data-access flow that enforces least privilege, uses workload identity (SPIFFE/SPIRE), ephemeral credentials with rotation, and policy-driven runtime checks. Include tenant isolation, secret management, and a playbook for cross-tenant data exfiltration?","channel":"comptia-security-plus","subChannel":"general","difficulty":"intermediate","tags":["comptia-security-plus"],"companies":["Netflix","PayPal","Zoom"]},{"id":"q-1079","question":"In a multi-tenant rideshare analytics platform with per-tenant clusters and a shared data lake, design a zero-trust data-access pattern that enforces least privilege, uses SPIFFE/SPIRE for workload identity, ephemeral credentials with rotation, and policy-driven runtime checks. Include tenant isolation, secret management, cross-tenant data-exfiltration playbooks, and a DR/IR plan?","channel":"comptia-security-plus","subChannel":"general","difficulty":"advanced","tags":["comptia-security-plus"],"companies":["Lyft","Snap"]},{"id":"q-883","question":"Describe a practical, scalable secure software supply-chain workflow for an automotive platform with OTA-enabled ECUs, leveraging SBOMs, code signing, and runtime attestation. Include concrete steps for CI/CD isolation, secret management, artifact signing, and incident response?","channel":"comptia-security-plus","subChannel":"general","difficulty":"advanced","tags":["comptia-security-plus"],"companies":["Hashicorp","Salesforce","Tesla"]},{"id":"q-974","question":"Given a global fintech platform delivering real-time risk analytics via a fleet of edge appliances and cloud microservices, outline a practical, end-to-end security workflow for secure software and firmware updates that ensures provenance, integrity, and trust. Include: SBOMs, code signing, runtime attestation for both containers and devices; CI/CD isolation and secrets management; artifact signing and key rotation; secure OTA rollout with canarying and rollback; and incident response playbooks?","channel":"comptia-security-plus","subChannel":"general","difficulty":"advanced","tags":["comptia-security-plus"],"companies":["Goldman Sachs","Meta","Tesla"]},{"id":"q-988","question":"Scenario: A fintech app runs microservices in Kubernetes on AWS and Cloud Run on GCP. You must implement least privilege and dynamic secrets for a data-access service. Outline a practical, beginner-friendly workflow to give the service temporary credentials to a Postgres DB, with a choice between Vault or cloud-native secret managers. Include CI/CD integration, rotation, RBAC, and auditability?","channel":"comptia-security-plus","subChannel":"general","difficulty":"beginner","tags":["comptia-security-plus"],"companies":["Bloomberg","Citadel","Cloudflare"]},{"id":"q-1018","question":"You’re building a mobile camera app that auto-captures frames from a live video feed. Describe a practical, beginner-friendly pipeline to decide whether a frame is usable by applying two simple checks: (1) sharpness via variance of Laplacian, (2) exposure via histogram-based brightness. Explain how thresholds would be chosen, how you'd adapt them across lighting, and provide a minimal code snippet illustrating the core checks?","channel":"computer-vision","subChannel":"general","difficulty":"beginner","tags":["computer-vision"],"companies":["Goldman Sachs","LinkedIn","NVIDIA"]},{"id":"q-1093","question":"Design a privacy-preserving, real-time hand-gesture recognition system for video calls on consumer laptops (720p camera) that distinguishes a small set of gestures (hand-raise, thumbs-up, peace) without exposing facial details. Must run on-device at 30–60 FPS, handle lighting/occlusion, and support federated fine-tuning with differential privacy. Outline architecture, data strategy, and evaluation plan?","channel":"computer-vision","subChannel":"general","difficulty":"intermediate","tags":["computer-vision"],"companies":["Hashicorp","Tesla","Zoom"]},{"id":"q-1108","question":"Design a real-time, on-device hand pose/gesture system for air-drawing in a video-conferencing app. From a monocular 1080p60 stream, infer 2D/3D hand pose with <40ms latency on a CPU, robust to occlusion and varied skin tones, and support at least 5 gestures (draw, erase, next, previous, pointer). Outline data needs, model architecture, latency optimizations, temporal consistency, and evaluation plan?","channel":"computer-vision","subChannel":"general","difficulty":"advanced","tags":["computer-vision"],"companies":["Adobe","Plaid","Zoom"]},{"id":"q-1270","question":"Design a real-time monocular 3D detector for an assembly line that estimates 6-DoF pose of tools from a single RGB camera, achieving sub-50ms per frame on embedded hardware. Use a lightweight backbone with self-supervised pretraining plus a small labeled set; recover pose via differentiable PnP from 2D-3D correspondences with a temporal filter and reprojection losses. Monitor drift with streaming per-frame errors?","channel":"computer-vision","subChannel":"general","difficulty":"intermediate","tags":["computer-vision"],"companies":["Goldman Sachs","Hashicorp","MongoDB"]},{"id":"q-456","question":"How would you design a real-time object detection system for a social media platform that processes 10M images/day with 99.9% accuracy and <100ms latency?","channel":"computer-vision","subChannel":"general","difficulty":"advanced","tags":["computer-vision"],"companies":["Microsoft","Salesforce","Twitter"]},{"id":"q-487","question":"Design a real-time object detection system for DoorDash delivery vehicles that must identify packages, license plates, and traffic signs in varying weather conditions. How would you handle model optimization for edge deployment and ensure 99% accuracy?","channel":"computer-vision","subChannel":"general","difficulty":"advanced","tags":["computer-vision"],"companies":["DoorDash","Google"]},{"id":"q-517","question":"Design a real-time object detection system for cryptocurrency trading terminals that must detect and classify multiple monitor types, trading interfaces, and unauthorized screen recording devices with <100ms latency. How would you optimize YOLOv8 for this specific use case?","channel":"computer-vision","subChannel":"general","difficulty":"advanced","tags":["computer-vision"],"companies":["Amazon","Coinbase","Meta"]},{"id":"q-545","question":"How would you detect if an image contains a face using basic computer vision techniques?","channel":"computer-vision","subChannel":"general","difficulty":"beginner","tags":["computer-vision"],"companies":["Airbnb","NVIDIA","Netflix"]},{"id":"q-570","question":"How would you design a real-time object detection system for Airbnb's property listing photos that can identify amenities and safety violations while processing 10,000 images per hour?","channel":"computer-vision","subChannel":"general","difficulty":"advanced","tags":["computer-vision"],"companies":["Airbnb","Instacart"]},{"id":"q-274","question":"How would you implement a hybrid CNN architecture combining ResNet residual connections with EfficientNet compound scaling for production image classification?","channel":"computer-vision","subChannel":"image-classification","difficulty":"intermediate","tags":["cnn","resnet","efficientnet"],"companies":["Amazon","Google","Meta","Microsoft"]},{"id":"q-253","question":"How does YOLO implement real-time object detection using grid-based prediction and what are the key components of its architecture?","channel":"computer-vision","subChannel":"object-detection","difficulty":"beginner","tags":["yolo","rcnn","detr"],"companies":["Amazon","Google","Meta","Microsoft","NVIDIA","Tesla"]},{"id":"q-200","question":"How does U-Net's skip connection architecture enable precise medical image segmentation?","channel":"computer-vision","subChannel":"segmentation","difficulty":"beginner","tags":["unet","mask-rcnn","sam"],"companies":["Amazon","Google","Meta"]},{"id":"q-228","question":"How would you optimize a real-time medical image segmentation pipeline using SAM with 100ms latency constraint on edge devices?","channel":"computer-vision","subChannel":"segmentation","difficulty":"advanced","tags":["unet","mask-rcnn","sam"],"companies":["Apple","Google","Meta","Microsoft","NVIDIA"]},{"id":"q-1080","question":"In a log-processing pipeline, multiple producers enqueue log entries into a bounded, rate-limited work queue. Implement a beginner-friendly token-bucket rate limiter that allows enqueuing only when a token is available; a background timer refills tokens at a fixed rate up to a max. Producers block when tokens==0; workers process items from the queue. Provide a concrete Go/Python/Java solution and discuss testing?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Bloomberg","Lyft","NVIDIA"]},{"id":"q-1204","question":"In a real-time notification system with thousands of tenants, each tenant's events must be delivered to their own handler in order, while cross-tenant processing happens in parallel. Design a bounded, multi-queue architecture with per-tenant in-order guarantees, backpressure, and graceful shutdown. Compare two backpressure strategies (per-tenant token buckets vs. global credits) and discuss testing and failure scenarios. Provide runnable sketch in Go or Rust?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Scale Ai","Tesla"]},{"id":"q-682","question":"In a service handling image uploads, each file triggers a resize and thumbnail generation pipeline. Design a bounded producer-consumer queue in Python using asyncio. Use a Queue with maxsize, a fixed number of worker coroutines, and backpressure so producers await when full. Include clean shutdown and error handling. Provide a runnable minimal example showing enqueue, worker loop, and cancellation?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Discord","Lyft","Snap"]},{"id":"q-687","question":"Write a small Python snippet: create a shared counter initialized to 0, spawn 4 threads that increment it 1000 times each, using a Lock to protect the increment. After joining, print the final value. Explain what happens if the lock is removed and how atomicity is ensured. What value do you expect and why?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Google","Tesla","Two Sigma"]},{"id":"q-696","question":"Context: in a real-time analytics pipeline for a video-conference system, dozens of producers emit events into a shared queue and multiple workers consume them. Implement a bounded, multi-producer, multi-consumer queue with capacity 1024. It must not drop messages while not full, block producers when full, support concurrent consumers, and support a clean shutdown. Describe API, invariants, and a simple synchronization strategy?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Hugging Face","Zoom"]},{"id":"q-708","question":"Design a bounded, concurrent, multi-priority work scheduler for a rendering service: 3 priority levels (0 highest). Producers enqueue tasks into per-priority queues with backpressure; workers drain from the highest non-empty queue (0→1→2). Include aging to prevent starvation and a graceful shutdown sentinel. Provide a runnable minimal Java example?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["Adobe","Salesforce","Snap"]},{"id":"q-713","question":"You’re building a web service that enqueues tasks from many request handlers into a shared, fixed-capacity queue consumed by a single worker. Implement a thread-safe bounded queue with a fixed circular buffer, a mutex, not_full and not_empty condition variables, and a shutdown signal. Show enqueue and dequeue semantics and how shutdown behaves?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Adobe","Cloudflare","Tesla"]},{"id":"q-720","question":"Design a bounded worker pool for a high-throughput API gateway that queues work with backpressure. Use a lock-free ring buffer, N workers, and blocking enqueue when full. Include per-task cancellation, timeouts, and metrics. Compare Go, Rust, and Java trade-offs and explain how you’d debug data races and starvation under burst traffic?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Hugging Face","Square"]},{"id":"q-726","question":"Design a concurrent event broker for a live chat service that guarantees per-user in-order delivery while allowing parallel processing across users, using a bounded buffer; describe backpressure handling when the buffer fills, and compare locking versus lock-free approaches in your language of choice?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Meta","Microsoft","Zoom"]},{"id":"q-735","question":"Design a concurrency-safe per-channel message queue for a Discord-like chat service: multiple producers push messages, a single consumer persists them to storage; implement bounded capacity, preserve per-channel order, and handle backpressure. Which synchronization primitives would you use and how would you test edge cases?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Discord","Snowflake"]},{"id":"q-748","question":"You're building a real-time analytics pipeline with many shards. Propose a concurrent, bounded path that preserves per-shard in-order processing while enabling cross-shard parallelism. Design a data structure and protocol (enqueuing, routing, backpressure, and shutdown). Provide a runnable sketch in Go or Rust showing enqueue, per-shard consumer loop, and graceful shutdown?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["NVIDIA","Snap","Twitter"]},{"id":"q-756","question":"Implement a concurrent task-graph executor with dependencies. Tasks form a DAG; a task runs only after all its prerequisites complete. Use a bounded in-flight task pool, per-worker work stealing, and deadlock/backpressure handling. Provide a runnable Go or Rust sketch showing submission, ready-state transitions, worker loop, and graceful shutdown?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Lyft","NVIDIA"]},{"id":"q-759","question":"In a multi-threaded microservice, there is a shared in-memory counter for total processed events. Provide a concrete, beginner-friendly approach to implement a thread-safe increment using language primitives (Java, Go, or Python) and discuss the trade-offs between lock-based vs lock-free solutions when scaling across cores?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Bloomberg","Coinbase","MongoDB"]},{"id":"q-773","question":"In a Go HTTP server, you maintain a per-user quota counter in memory. Multiple requests for different users should advance concurrently, but updates to the same user must be serialized. Design a striped lock (a fixed set of mutexes) to guard a map[string]int, map userID to a bucket via hashing, and explain how you minimize contention, handle hash collisions, and ensure correctness when entries may be evicted?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["MongoDB","NVIDIA","Plaid"]},{"id":"q-780","question":"Implement a lock-free, bounded multi-producer, multi-consumer pipeline with per-symbol partitions and fixed-capacity queues. Producers must acquire credits to enqueue; downstream workers release credits on completion. Explain memory visibility, false sharing avoidance, and a clean shutdown. How do you guarantee in-order per partition and exactly-once processing on failure?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["Bloomberg","Microsoft","PayPal"]},{"id":"q-788","question":"In a streaming data pipeline, multiple producers generate frames and a bounded buffer sits between the producer stage and a consumer stage. Implement a backpressure-enabled producer-consumer pair in JavaScript (Node.js) using an async bounded queue that supports multiple producers and multiple consumers. It must guarantee no data loss, bounded memory, and graceful shutdown. How would you test under varying production/consumption rates?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Citadel","Tesla"]},{"id":"q-795","question":"Design a dynamic, concurrency-safe worker pool in Go for a real-time analytics pipeline. Each task type has its own queue; enforce backpressure with bounded channels and implement a central scaler that adjusts worker counts based on observed tail latency and throughput. Provide a runnable skeleton showing enqueue, worker loops, and graceful shutdown?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["Databricks","Meta","Microsoft"]},{"id":"q-804","question":"You're building a video-frame ingestion service where frames from thousands of users arrive on a shared input channel. Design a bounded, concurrent dispatcher that routes frames to per-user in-order queues, enabling parallel processing across users. Provide backpressure handling when the global buffer fills, a strategy for reordering out-of-order frames, and a graceful shutdown. Sketch the core data structures and synchronization in Rust or C++ and explain trade-offs?","channel":"concurrency","subChannel":"general","difficulty":"intermediate","tags":["concurrency"],"companies":["Hugging Face","Netflix","Snap"]},{"id":"q-811","question":"In a real-time analytics service, multiple producers enqueue data into a fixed-size circular buffer consumed by multiple workers. Design a beginner-friendly concurrency solution in Java, Go, or Python that guarantees producers block when the buffer is full and consumers block when empty, while maintaining correctness under concurrent access; compare lock-based vs channel-based approaches for this bounded buffer?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Databricks","Oracle","Two Sigma"]},{"id":"q-818","question":"In a build pipeline, N compile tasks run in parallel and must all finish before the linker runs. Design a barrier that blocks each task at barrier.wait() until all N tasks have arrived, then releases them to proceed. Implement two beginner-friendly approaches in Go (or Java/Python): (A) locks/condition variables; (B) channels/futures. Ensure the barrier is reusable for repeated builds, avoids deadlocks, and explain correctness and trade-offs?","channel":"concurrency","subChannel":"general","difficulty":"beginner","tags":["concurrency"],"companies":["Discord","Two Sigma"]},{"id":"q-825","question":"In a real-time chat moderation pipeline for a platform like Discord/LinkedIn, design a dynamic Go worker pool that scales from minWorkers to maxWorkers based on a bounded task queue. The queue should backpressure producers, guarantee per-user fairness, support graceful shutdown, and tolerate occasional misbehaving workers (timeouts). Provide runnable code showing enqueue, worker loop, and scaler?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["Discord","LinkedIn"]},{"id":"q-835","question":"Design a multi-tenant dispatcher for a streaming event bus. Producers from each tenant push events into per-tenant input channels; a central dispatcher interleaves tenants fairly, enforces per-tenant rate limits using a token-bucket, and enforces a maximum in-flight events per tenant. Implement in Go using channels; ensure backpressure propagates to producers when quotas or in-flight limits are reached, and support graceful shutdown. Include a runnable minimal example with: per-tenant limiter, dispatcher loop, producer(s), and cancellation?","channel":"concurrency","subChannel":"general","difficulty":"advanced","tags":["concurrency"],"companies":["Airbnb","NVIDIA","Slack"]},{"id":"q-1027","question":"You're running a mixed Consul Connect mesh with Kubernetes services in DC1 and VM-based services in DC2. A new API service in DC1 calls a legacy VM backend behind a firewall via a mesh gateway, but TLS handshakes intermittently fail after a CA rotation. Propose a zero-downtime plan to diagnose, implement automatic CA rotation, and validate end-to-end, including config changes, monitoring, and rollback steps?","channel":"consul-associate","subChannel":"general","difficulty":"advanced","tags":["consul-associate"],"companies":["Cloudflare","LinkedIn","Microsoft"]},{"id":"q-1178","question":"Across a tri-cloud Consul Connect mesh, a new microservice 'payments-api' in namespace 'payments' must reach a legacy data service 'orderdb' in namespace 'legacy' via a mesh gateway. Propose an end-to-end pattern that enforces strict identity via namespace-scoped Intention defaults, per-service tokens, and gateway ACLs, including resource definitions, deployment steps, and rollback plan?","channel":"consul-associate","subChannel":"general","difficulty":"intermediate","tags":["consul-associate"],"companies":["Anthropic","DoorDash","Tesla"]},{"id":"q-1293","question":"In a hybrid setup with Consul across two Kubernetes clusters (AWS) and VM-based services on-prem, how would you design cross-cluster service authentication and discovery using Consul Connect with mesh gateways, Namespaces, and ACLs to enforce zero-trust policy and automatic token rotation while preserving DNS-based discovery?","channel":"consul-associate","subChannel":"general","difficulty":"advanced","tags":["consul-associate"],"companies":["Microsoft","Snowflake"]},{"id":"q-880","question":"In a Consul Connect-enabled dev cluster, two services run in namespace dev: 'reviews' and 'ratings'. You want to enforce that only reviews can call ratings via the mesh, with all other cross-service calls denied by default. Describe the minimal service-defaults and service-intentions changes needed, and how you would verify using a small client container in dev?","channel":"consul-associate","subChannel":"general","difficulty":"beginner","tags":["consul-associate"],"companies":["Amazon","Google","Square"]},{"id":"q-919","question":"You're operating a multi-datacenter Consul Connect mesh. A new API service in DC1 must reach a legacy monolith in DC2 that cannot run a sidecar. Design a cross-datacenter connectivity pattern using a mesh gateway, per-service Intentions with explicit allow rules, and TLS credential rotation. Include resource definitions, deployment steps, and rollback plan?","channel":"consul-associate","subChannel":"general","difficulty":"advanced","tags":["consul-associate"],"companies":["Anthropic","Hugging Face","PayPal"]},{"id":"q-999","question":"Design a cross-datacenter Consul Connect pattern in a three-datacenter setup where api-service.dc1 must reach legacy-db.dc3 (no sidecar). Use a MeshGateway to bridge DC1↔DC3, per-service Intentions with explicit allow rules, and TLS credential rotation. Include concrete resource definitions, deployment steps, and a rollback plan?","channel":"consul-associate","subChannel":"general","difficulty":"intermediate","tags":["consul-associate"],"companies":["NVIDIA","Salesforce","Two Sigma"]},{"id":"q-1077","question":"Design a data ingestion and processing pipeline for a global ride-hailing platform that ingests 5 TB/day of operational events from multiple regional Kafka topics and batch feeds. Requirements: idempotent upserts into a table (Iceberg/Delta), handle late-arriving events, schema evolution, and partition pruning by country/date. Compare Flink vs Spark for streaming, and outline testing, monitoring, and data quality checks?","channel":"data-engineering","subChannel":"general","difficulty":"advanced","tags":["data-engineering"],"companies":["Amazon","LinkedIn","Lyft"]},{"id":"q-1140","question":"Given daily 1 GB of web logs in JSON lines stored on S3 with fields user_id, timestamp, path, status, and optional referrer, design a beginner-friendly pipeline (Python or Node.js) that deduplicates by timestamp+user_id+path, validates required fields, normalizes timestamp to UTC, and writes date-partitioned Parquet to a data lake; include basic tests and monitoring?","channel":"data-engineering","subChannel":"general","difficulty":"beginner","tags":["data-engineering"],"companies":["Discord","NVIDIA","Stripe"]},{"id":"q-1272","question":"Design a data pipeline to ingest 2M GPU telemetry events per minute from a global fleet of AI training clusters into a data lake and a feature store. Events include host_id, region, timestamp, metric_type, and value. Requirements: immutable raw Parquet storage partitioned by region/hour; near-real-time metrics and anomaly alerts (1–2 minute latency) via a streaming engine; idempotent upserts into a feature store; schema evolution handling; late-arriving data; cost-aware storage/compute; monitoring and tests; compare Spark vs Flink for streaming components?","channel":"data-engineering","subChannel":"general","difficulty":"intermediate","tags":["data-engineering"],"companies":["Apple","NVIDIA"]},{"id":"q-457","question":"You need to process 10GB of CSV files daily and load them into a PostgreSQL database. The files contain user activity logs with timestamps, user IDs, and event types. How would you design an efficient ETL pipeline using Python?","channel":"data-engineering","subChannel":"general","difficulty":"beginner","tags":["data-engineering"],"companies":["Anthropic","Discord","MongoDB"]},{"id":"q-488","question":"You're building a real-time analytics pipeline for a food delivery app. How would you design a data pipeline to process 1M events/day with 5-minute latency, considering data quality, schema evolution, and cost optimization?","channel":"data-engineering","subChannel":"general","difficulty":"intermediate","tags":["data-engineering"],"companies":["Adobe","Google","Instacart"]},{"id":"q-518","question":"You have a 10GB CSV file with user activity logs that needs to be processed daily. The file contains user_id, timestamp, action_type, and metadata. How would you design a data pipeline to efficiently process this file and load it into a data warehouse?","channel":"data-engineering","subChannel":"general","difficulty":"beginner","tags":["data-engineering"],"companies":["Adobe","Airbnb","Oracle"]},{"id":"q-571","question":"How would you design a data pipeline to process 1M ride events per minute from Uber's real-time streaming system?","channel":"data-engineering","subChannel":"general","difficulty":"beginner","tags":["data-engineering"],"companies":["Meta","Twitter","Uber"]},{"id":"q-885","question":"You operate a multi-tenant SaaS analytics platform ingesting per-tenant event streams from Kafka into Snowflake. Each tenant has different event schemas that can evolve independently. Design a data pipeline to enforce per-tenant data contracts, support late-arriving events, and minimize schema drift while controlling storage costs. Include schema versioning, validation, and deployment safety steps?","channel":"data-engineering","subChannel":"general","difficulty":"intermediate","tags":["data-engineering"],"companies":["NVIDIA","Snowflake","Stripe"]},{"id":"q-915","question":"You ingest 200k newline-delimited JSON app events daily into S3. Each event has event_id, user_id, timestamp, event_type, and attributes. Design a beginner-friendly pipeline to deduplicate by event_id, hash user_id for privacy, validate required fields, and write Parquet data partitioned by date in a data lake. Address simple schema drift and testing?","channel":"data-engineering","subChannel":"general","difficulty":"beginner","tags":["data-engineering"],"companies":["Discord","MongoDB","Snap"]},{"id":"q-993","question":"Design a global, multi-tenant data ingestion system for a ride-hailing platform with streams for billing, trips, safety, and promotions. Each tenant defines a data contract; schemas evolve independently; late-arriving events up to 15 minutes must be accepted. Describe architecture using Apache Kafka, Schema Registry (Avro/JSON), an Iceberg/Delta lake sink, and a streaming processor (Flink/Spark). Include data model, schema evolution, backfill handling, testing, and observability?","channel":"data-engineering","subChannel":"general","difficulty":"advanced","tags":["data-engineering"],"companies":["Coinbase","DoorDash","Meta"]},{"id":"q-176","question":"How would you design a data pipeline that handles both batch and streaming workloads for real-time analytics?","channel":"data-engineering","subChannel":"streaming","difficulty":"beginner","tags":["streaming","kafka"],"companies":["Amazon","Google","Meta","Netflix","Uber"]},{"id":"q-222","question":"How would you design a Kafka Streams application to handle exactly-once processing with stateful aggregations while maintaining sub-second latency during peak loads of 100K events/sec?","channel":"data-engineering","subChannel":"streaming","difficulty":"advanced","tags":["kafka","flink","kinesis"],"companies":["Amazon","Confluent","Netflix","Stripe","Uber"]},{"id":"q-248","question":"How would you implement exactly-once processing in a data pipeline when both source (Kafka) and sink (database) can fail, ensuring no duplicate data or data loss during network partitions and system crashes?","channel":"data-engineering","subChannel":"streaming","difficulty":"intermediate","tags":["dag","orchestration","scheduling"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Snowflake"]},{"id":"q-1038","question":"Design a stack that supports push(x), pop(), top(), and getMin() in O(1) time per operation. Duplicates allowed. Explain the approach, discuss invariants and space usage, and provide a compact code sketch (Python or Java)?","channel":"data-structures","subChannel":"general","difficulty":"beginner","tags":["data-structures"],"companies":["Apple","Databricks","Tesla"]},{"id":"q-1213","question":"Design a dynamic autocomplete data structure for a code search tool that stores terms with frequencies; implement insertWord(word), eraseWord(word), and querySuggestions(prefix, k) returning up to k completions starting with prefix, ordered by descending frequency then lexicographically. Discuss a Trie-based design with per-node top-k structures and update costs?","channel":"data-structures","subChannel":"general","difficulty":"beginner","tags":["data-structures"],"companies":["Hashicorp","Hugging Face"]},{"id":"q-677","question":"Design a data structure to maintain dynamic counters for items, supporting add(key, delta), get(key), and getTopK(k) returning the k keys with highest counts, ties broken by key. In a real-time analytics scenario, such as tracking top active users by event count, describe the structure, updates, and complexity trade-offs?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Bloomberg","Discord","Netflix"]},{"id":"q-686","question":"Design a data structure that maintains a multiset of integers with insert(x), erase(x) for one occurrence, findMedian(), and findKthSmallest(k). Achieve O(log n) time per operation on average. Explain data layout, invariants, and handling duplicates and lazy deletions. For example: insert 1,2,3,4,5; erase 3; what is median and findKthSmallest(2)?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Apple","Oracle","Twitter"]},{"id":"q-697","question":"Design a time-weighted event multiset data structure. Supports insertEvent(ts, w), eraseEvent(ts, w) removing one occurrence, rangeSum(a, b) returning the sum of weights for events with timestamps in [a, b], and findKthWeightInRange(a, b, k) returning the k-th smallest weight among events with timestamps in [a, b]. Target O(log^2 n) per operation; handle duplicate timestamps and weights; discuss memory and trade-offs?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["DoorDash","Plaid","Scale Ai"]},{"id":"q-701","question":"Design a dynamic multiset of 2D points (duplicates allowed) with insertPoint(x,y), erasePoint(x,y) removing one occurrence, rangeCount(x1,y1,x2,y2), and rangeKthX(x1,y1,x2,y2,k) returning the k-th smallest x in the rectangle (tie by y). Target O(log^2 n) per op. Propose a segment tree over x; each node stores an ordered multiset of (y, unique_id). Explain duplicates handling, updates, rangeCount, and rangeKthX via binary search over x?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Apple","Discord","Snap"]},{"id":"q-710","question":"Design a data structure that maintains a dynamic multiset of strings with operations insert(word), erase(word) removing a single occurrence, countWithPrefix(prefix) returning how many words start with the prefix, and mostFrequentWithPrefix(prefix) returning the most frequent word among those starting with the prefix (tie-break lexicographically). What data structure would you implement, and what are the time complexities and invariants?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Apple","Scale Ai","Slack"]},{"id":"q-722","question":"Design a data structure for an array of integers that supports point updates update(i, val) and range maximum subarray sum queries maxSubarray(l, r) in O(log n). Explain the segment tree node data (sum, bestPref, bestSuff, bestSub) and the merge logic, including tie-breaking for leftmost subarray and handling entirely negative ranges. Example: start with [1,-2,3,4,-1], update index 2 to 5, query maxSubarray(0,4)?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Apple","Bloomberg"]},{"id":"q-727","question":"Design a dynamic data structure for weighted 3D points (x,y,t) with weight w. Support insertPoint(x,y,t,w) and erasePoint(x,y,t,w) (duplicates allowed), rangeSum3D(x1,x2,y1,y2,t1,t2) for total weight in the 3D box, and findKthLargestInRange(x1,x2,y1,y2,t1,t2,k) for the k-th largest weight inside the box. Target O(log^3 n) per op; O(log W * log^3 n) for kth; discuss coordinate compression, memory trade-offs, and handling duplicates?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Airbnb","Google","Meta"]},{"id":"q-739","question":"Design a dynamic 2D weighted point data structure that supports insertPoint(x,y,w), erasePoint(x,y,w) (duplicates allowed), rangeSum2D(x1,x2,y1,y2) for the total weight in the rectangle, and kthLargestInRectangle(x1,x2,y1,y2,k) for the k-th largest weight inside the rectangle. Aim for average O(log^2 n) per operation; discuss coordinate compression, memory trade-offs, and duplicates handling?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Citadel","Hugging Face","Snap"]},{"id":"q-746","question":"Design a dynamic multiset of integers that supports insert(x), erase(x) (one occurrence), countInRange(l, r) for the number of elements in [l, r], and kthSmallestInRange(l, r, k) returning the k-th smallest value among elements in [l, r]. Aim for expected O(log n) updates and O(log n * log U) queries. Explain data structure, balance, and duplicates handling?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Airbnb","Google","PayPal"]},{"id":"q-749","question":"Design a dynamic weighted string multiset with insertWord(word, w), eraseWord(word, w) (duplicates allowed), sumByPrefix(prefix) returning total weight of words starting with prefix, and kthLargestWeightInPrefix(prefix, k) returning the k-th largest weight among those words. Outline the data structure, invariants, and expected complexities; discuss handling of long words and memory trade-offs?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Google","IBM"]},{"id":"q-761","question":"Design a dynamic word-frequency histogram for a text stream. Implement addWord(word) to increment frequency, eraseWord(word) to decrement (removing word when count hits zero), getFrequency(word), and topKWords(n) returning the n most frequent distinct words (ties broken lexicographically). Target average O(log m) per update and O(k log m) for topK, where m is the number of distinct words. Explain approach and data structures you would use?","channel":"data-structures","subChannel":"general","difficulty":"beginner","tags":["data-structures"],"companies":["Adobe","Scale Ai"]},{"id":"q-774","question":"Design a data structure to manage a dynamic multiset of weighted intervals on the real line. Each interval is [l, r] with weight w; duplicates allowed. Implement insertInterval(l, r, w), eraseInterval(l, r, w) (one occurrence), rangeSumAt(x) returning the total weight of all intervals covering point x, and kthLargestWeightAt(x, k) returning the k-th largest weight among intervals covering x. Target average O(log n) update and O(log n) query; discuss coordinate compression, memory trade-offs, and handling duplicates?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Hashicorp","Slack"]},{"id":"q-782","question":"Design a fully dynamic data structure to maintain a set of linear cost functions y = m_i x + b_i. Support: addLine(id, m, b), removeLine(id) (one occurrence per id), queryMin(x) returning the minimum cost at x across active lines, and queryKthMin(x, k) returning the k-th smallest cost at x. Domain x in [Xmin, Xmax]. Aim for near O(log X) per operation; discuss how deletions are handled, precision, and memory trade-offs?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Apple","DoorDash","Tesla"]},{"id":"q-790","question":"Design a persistent 2D dynamic weighted point data structure that supports insertPoint(x,y,w) and erasePoint(x,y,w) (duplicates allowed). Extend with rangeSum2D(x1,x2,y1,y2,version) and kthLargestInRectangle(x1,x2,y1,y2,k,version). Each insertion creates a new version; queries run in O(log^2 n) time. Explain coordinate compression, memory management, and how duplicates are handled across versions?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Amazon","Databricks","Google"]},{"id":"q-801","question":"Design a fixed-window streaming data structure: push(x) appends an integer to the window; if the window exceeds size W, remove the oldest value. Implement getKthSmallest(k) to return the k-th smallest value in the current window in O(log W). Propose a concrete structure (e.g., an order-statistics tree with duplicates) and outline push/evict/getKthSmallest, including how duplicates and memory are handled?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Cloudflare","Plaid","Twitter"]},{"id":"q-805","question":"Design a dynamic forest data structure supporting: addNode(id, value), link(childId, parentId) to attach a child under a parent, cut(childId) to detach a subtree, update(id, delta) to adjust a node's value, pathQuery(u, v) for the sum of values along the path from u to v, and subtreeQuery(u) for the sum of values in the subtree rooted at u. Target amortized O(log n) per operation. Which approach would you pick (Link-Cut Tree vs Euler Tour Tree), and how would you handle edge cases like root changes and duplicate node values?","channel":"data-structures","subChannel":"general","difficulty":"advanced","tags":["data-structures"],"companies":["Lyft","Meta","Netflix"]},{"id":"q-815","question":"Design a dynamic data structure for a bipartite graph with left indices [1..N] and right indices [1..M]. Each edge (u,v) has weight w; duplicates allowed. Support: - addEdge(u,v,w), eraseEdge(u,v,w) (one occurrence) - rangeSum(uL,uR,vL,vR) total weight of edges with u in [uL,uR] and v in [vL,vR] - kthLargestEdgeWeight(uL,uR,vL,vR,k) the k-th largest edge weight in that submatrix. Aim for ~O(log N log M) per operation; discuss compression, duplicates, and memory trade-offs?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Apple","NVIDIA","Snowflake"]},{"id":"q-820","question":"Design a dynamic sequence structure 'RopeArray' storing an integer array supporting insertAt(i, val), eraseAt(i), rangeSum(l, r), rangeMax(l, r), and getAt(i). How would you implement it to achieve average O(log n) per operation using a balanced tree with implicit keys and augmented fields (size, sum, max), and how would you test with an example sequence?","channel":"data-structures","subChannel":"general","difficulty":"intermediate","tags":["data-structures"],"companies":["Amazon","Google","Microsoft"]},{"id":"q-832","question":"Design a data structure to maintain a dynamic multiset of words with three operations: insertWord(word), eraseWord(word) (one occurrence), and getAnagrams(word) that returns all current words that are anagrams of the given word (including duplicates). Explain how you would store the words, how to compute the canonical signature, and the expected time complexity for updates and queries. For example, after insertWord('listen') and insertWord('silent'), getAnagrams('tinsel') should return ['listen','silent']?","channel":"data-structures","subChannel":"general","difficulty":"beginner","tags":["data-structures"],"companies":["NVIDIA","Snowflake","Twitter"]},{"id":"q-1160","question":"How would you implement and maintain an indexing strategy for a database that experiences frequent schema changes and evolving query patterns, while ensuring minimal performance degradation during migrations?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["database-indexing","schema-migration","performance-optimization","index-lifecycle"],"companies":[]},{"id":"q-1161","question":"How would you implement and maintain an indexing strategy for a database that experiences frequent schema changes and evolving query patterns, ensuring optimal performance without requiring constant manual intervention?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["adaptive-indexing","database-automation","performance-monitoring","schema-evolution"],"companies":[]},{"id":"q-1162","question":"How would you implement and maintain an indexing strategy for a database that experiences frequent schema changes and evolving query patterns, ensuring optimal performance without requiring constant manual intervention?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["adaptive-indexing","schema-evolution","automated-maintenance","query-optimization"],"companies":[]},{"id":"q-643","question":"How would you design an indexing strategy for a time-series database that handles both recent data queries and long-term historical analysis, considering the trade-offs between write performance and query efficiency?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["time-series","index-optimization","partitioning","performance-tuning"],"companies":[]},{"id":"q-651","question":"How would you design an indexing strategy for a table with 10 million rows that has frequent read queries with multiple WHERE conditions, occasional bulk inserts, and needs to support both exact match and range queries on different columns?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["database-indexing","query-optimization","performance-tuning","composite-indexes","bulk-operations"],"companies":[]},{"id":"q-765","question":"How would you design an indexing strategy for a multi-tenant SaaS application where each tenant has isolated data but queries frequently need to aggregate across tenants for reporting, while ensuring query performance doesn't degrade as the number of tenants scales to thousands?","channel":"database","subChannel":"database","difficulty":"intermediate","tags":["multi-tenancy","index design","performance optimization","scalability"],"companies":[]},{"id":"q-630","question":"Explain the difference between a B-tree index and a hash index, and when would you choose one over the other?","channel":"database","subChannel":"index-types","difficulty":"intermediate","tags":["database-indexing","b-tree","hash-index","query-optimization"],"companies":["Google","Amazon","Microsoft","Meta","Netflix"]},{"id":"da-125","question":"Explain database indexing and when should you use it?","channel":"database","subChannel":"indexing","difficulty":"intermediate","tags":["sql","indexing"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"db-1","question":"Explain the differences between Clustered and Non-Clustered Indexes, including their performance implications, storage characteristics, and when to choose each type in database design?","channel":"database","subChannel":"indexing","difficulty":"beginner","tags":["sql","indexing","perf"],"companies":null},{"id":"q-170","question":"When would you choose a composite index over multiple single-column indexes in a relational database?","channel":"database","subChannel":"indexing","difficulty":"intermediate","tags":["index","optimization"],"companies":["Amazon","Goldman Sachs","Google","Meta","Microsoft"]},{"id":"q-288","question":"What is the main difference between B-tree and hash index in terms of range query performance?","channel":"database","subChannel":"indexing","difficulty":"beginner","tags":["btree","hash-index","composite"],"companies":["Amazon","Google","Meta"]},{"id":"q-365","question":"You're designing a real-time analytics system for Discord that processes millions of message events per minute. Your PostgreSQL database is experiencing severe write contention on the message_events table. How would you design a partitioning strategy using declarative partitioning, and what specific index optimizations would you implement to handle both time-series queries and user-based lookups efficiently?","channel":"database","subChannel":"indexing","difficulty":"advanced","tags":["joins","indexes","normalization","postgres"],"companies":["Amazon","Discord","Google","Netflix","Palantir","Stripe","Uber"]},{"id":"q-409","question":"You're designing a database for an e-commerce platform with frequent queries on (user_id, order_date) and (product_id, category). How would you choose between B-tree and hash indexes, and what composite index strategy would optimize both query patterns?","channel":"database","subChannel":"indexing","difficulty":"intermediate","tags":["btree","hash-index","composite"],"companies":["Gitlab","Tcs","Tempus"]},{"id":"q-420","question":"You're designing a user database for a chat application with 10M users. When would you choose a B-tree index over a hash index for the 'email' column, and what are the performance implications for login queries, user search, and profile updates?","channel":"database","subChannel":"indexing","difficulty":"beginner","tags":["btree","hash-index","composite"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-489","question":"You're designing a database for LinkedIn's feed system. Posts can be queried by user_id, created_at, and engagement_score. How would you optimize the indexing strategy for high-throughput reads and writes?","channel":"database","subChannel":"indexing","difficulty":"advanced","tags":["btree","hash-index","composite"],"companies":["Anthropic","LinkedIn","NVIDIA"]},{"id":"q-572","question":"You're designing a database for a high-frequency trading system. When would you choose a B-tree index over a hash index for composite queries on (symbol, timestamp, price)? What are the specific performance implications?","channel":"database","subChannel":"indexing","difficulty":"advanced","tags":["btree","hash-index","composite"],"companies":["IBM","NVIDIA"]},{"id":"q-599","question":"When would you choose a composite index over multiple single-column indexes, and what are the trade-offs?","channel":"database","subChannel":"indexing-strategies","difficulty":"intermediate","tags":["indexing","performance","query-optimization","database-design"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-618","question":"Explain the difference between clustered and non-clustered indexes and when you would choose each type. Provide a specific example scenario.","channel":"database","subChannel":"indexing-strategies","difficulty":"intermediate","tags":["database","indexing","performance","sql"],"companies":["Google","Microsoft","Amazon","Meta","Apple"]},{"id":"da-129","question":"What is the main difference between SQL and NoSQL databases in terms of data structure?","channel":"database","subChannel":"nosql","difficulty":"beginner","tags":["nosql","mongodb"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-242","question":"How do MongoDB's document structure and SQL's table rows differ in handling user data with varying attributes, and what are the performance implications for common user operations?","channel":"database","subChannel":"nosql","difficulty":"beginner","tags":["mongodb","dynamodb","cassandra","redis"],"companies":null},{"id":"q-331","question":"You're designing a multi-region e-commerce platform using DynamoDB. Your product catalog needs to support 10M items with eventual consistency across regions, but you must handle hot partitioning during flash sales. How would you design your partition key strategy and what trade-offs would you make between read performance and write throughput?","channel":"database","subChannel":"nosql","difficulty":"advanced","tags":["mongodb","dynamodb","cassandra","redis"],"companies":["Hashicorp","Meta","Oracle"]},{"id":"q-268","question":"How would you optimize a time-series analytics query that scans 100M+ rows across multiple date partitions in PostgreSQL when the WHERE clause cannot be pruned effectively due to complex temporal conditions?","channel":"database","subChannel":"query-optimization","difficulty":"advanced","tags":["explain","query-plan","partitioning"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-303","question":"How would you optimize a slow PostgreSQL query that joins 5 tables with millions of rows?","channel":"database","subChannel":"query-optimization","difficulty":"advanced","tags":["joins","indexes","normalization","postgres"],"companies":["Amazon","Google","Meta"]},{"id":"q-343","question":"You have a PostgreSQL table with 100M rows partitioned by date. A query filtering on a specific date range is still slow. What would you check in the EXPLAIN plan and how would you optimize it?","channel":"database","subChannel":"query-optimization","difficulty":"intermediate","tags":["explain","query-plan","partitioning"],"companies":["Affirm","Amazon","Google","Jane Street","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-380","question":"You're optimizing a query that's slow due to a large time-series table. The query filters by timestamp range and device_id. How would you analyze the query plan and what partitioning strategy would you recommend?","channel":"database","subChannel":"query-optimization","difficulty":"intermediate","tags":["explain","query-plan","partitioning"],"companies":["Hrt","Stripe","Tesla"]},{"id":"q-436","question":"You have a 100M row orders table with slow queries. The query plan shows sequential scans despite indexes on customer_id and order_date. How would you diagnose and fix this performance issue?","channel":"database","subChannel":"query-optimization","difficulty":"advanced","tags":["explain","query-plan","partitioning"],"companies":["Bloomberg","Salesforce","Slack"]},{"id":"q-546","question":"You're analyzing a slow query on a partitioned table. The EXPLAIN plan shows a full table scan instead of partition pruning. What could cause this and how would you fix it?","channel":"database","subChannel":"query-optimization","difficulty":"intermediate","tags":["explain","query-plan","partitioning"],"companies":["Microsoft","Tesla"]},{"id":"da-156","question":"What are the key differences between DELETE and TRUNCATE commands in SQL, including their impact on identity columns, foreign key constraints, and performance characteristics?","channel":"database","subChannel":"sql","difficulty":"beginner","tags":["sql","indexing"],"companies":["Amazon","Google","Microsoft","Netflix","Oracle","Snowflake"]},{"id":"q-172","question":"Design a database failover strategy for a high-traffic e-commerce platform using primary-replica PostgreSQL. How would you ensure zero-downtime failover while maintaining data consistency during peak traffic of 10,000 requests/second?","channel":"database","subChannel":"sql","difficulty":"intermediate","tags":["chaos","resilience"],"companies":["Amazon","Bloomberg","Microsoft","Netflix","Uber"]},{"id":"q-458","question":"You have a PostgreSQL database with orders (10M rows) and customers (1M rows). A query joining these tables is slow. How would you optimize it?","channel":"database","subChannel":"sql","difficulty":"intermediate","tags":["joins","indexes","normalization","postgres"],"companies":["Apple","Tesla","Uber"]},{"id":"da-128","question":"You have a banking system where users can transfer money between accounts. Design a transaction to handle a transfer of $500 from Account A (balance: $1000) to Account B (balance: $200). What happens if the system crashes after debiting Account A but before crediting Account B? How would you ensure data consistency?","channel":"database","subChannel":"transactions","difficulty":"intermediate","tags":["acid","transactions"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Stripe"]},{"id":"da-134","question":"You have a banking system where Account A transfers $100 to Account B, but during the transaction, Account B gets deleted by another process. The transfer uses READ COMMITTED isolation. What happens to the $100, and how would you prevent data inconsistency?","channel":"database","subChannel":"transactions","difficulty":"advanced","tags":["acid","transactions"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Stripe"]},{"id":"da-170","question":"You're building a banking system where users can transfer money between accounts. How would you design the transaction handling to ensure no money is lost or created during transfers, especially when the system crashes mid-transfer?","channel":"database","subChannel":"transactions","difficulty":"intermediate","tags":["acid","transactions"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Stripe"]},{"id":"da-172","question":"In a distributed database system, how would you implement a two-phase commit protocol to ensure atomicity across multiple nodes, and what are the key failure scenarios and recovery mechanisms you must handle?","channel":"database","subChannel":"transactions","difficulty":"advanced","tags":["acid","transactions"],"companies":null},{"id":"db-2","question":"How do ACID properties ensure data integrity in a banking transaction where $100 is transferred from Account A to Account B?","channel":"database","subChannel":"transactions","difficulty":"intermediate","tags":["acid","transactions","theory"],"companies":["Amazon","Goldman Sachs","Google","PayPal","Stripe"]},{"id":"q-190","question":"What is the difference between READ COMMITTED and REPEATABLE READ isolation levels in database transactions, and how does MVCC implementation affect their behavior?","channel":"database","subChannel":"transactions","difficulty":"beginner","tags":["acid","isolation-levels","mvcc"],"companies":["Amazon","Databricks","Google","Microsoft","Oracle","Snowflake"]},{"id":"q-317","question":"Explain how MVCC (Multi-Version Concurrency Control) works and how it prevents lost updates in a database system?","channel":"database","subChannel":"transactions","difficulty":"intermediate","tags":["acid","isolation-levels","mvcc"],"companies":["Microsoft","Plaid","Warner Bros"]},{"id":"q-353","question":"You're building a collaborative design tool where multiple users can edit the same document simultaneously. How would you use database transactions and isolation levels to prevent conflicts while maintaining good performance?","channel":"database","subChannel":"transactions","difficulty":"beginner","tags":["acid","isolation-levels","mvcc"],"companies":["Adobe","Amazon","Canva","Epic Games","Google","Meta","Microsoft","Netflix"]},{"id":"q-397","question":"In a high-transaction payment system using PostgreSQL, how would you design a transaction isolation strategy to prevent lost updates while maintaining high concurrency for account transfers?","channel":"database","subChannel":"transactions","difficulty":"advanced","tags":["acid","isolation-levels","mvcc"],"companies":["Amazon","Google","Netflix","PayPal","Square","Stripe"]},{"id":"q-428","question":"You're building a booking system for Airbnb where multiple users can reserve the same property simultaneously. How would you design the transaction handling to prevent double bookings while maintaining high availability?","channel":"database","subChannel":"transactions","difficulty":"intermediate","tags":["acid","isolation-levels","mvcc"],"companies":["Airbnb","Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"q-519","question":"You're designing a high-frequency trading system where transactions must see consistent data snapshots. How would you implement MVCC to handle concurrent reads while preventing write skew anomalies, and what isolation level would you choose?","channel":"database","subChannel":"transactions","difficulty":"advanced","tags":["acid","isolation-levels","mvcc"],"companies":["Lyft","Snap","Tesla"]},{"id":"q-1100","question":"In a Databricks data pipeline, ingest JSON events from S3 into Delta Lake with Auto Loader. Each event has a nested user object (id, email) and an optional pages array. Some events miss user.email. How would you design the pipeline to safely flatten nested fields, handle missing values, and upsert the latest user state into a Delta Silver table using an idempotent MERGE?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"beginner","tags":["databricks-data-engineer"],"companies":["MongoDB","Oracle"]},{"id":"q-1112","question":"Scenario: In a Databricks Delta Live Tables pipeline, ingest JSON events from a Kafka source into a Bronze table, where nested fields drift over time (e.g., payload.user.locale is added later, some events miss payload.user). You then transform to a Silver table used by billing and marketing. How would you implement a robust schema-evolution strategy and gating so new fields are captured without breaking existing downstream queries, and how would you test this in a run?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["databricks-data-engineer"],"companies":["DoorDash","Microsoft","Snap"]},{"id":"q-1144","question":"In a Databricks streaming pipeline ingesting tenant-scoped events from Kafka into Delta Lake, events may arrive late by up to 10 minutes. Describe a concrete end-to-end approach to upsert the latest state per (tenant_id, user_id) into a Silver table while preserving the full event history. Include: data model, CDC logic, watermarking and late data handling, an idempotent MERGE strategy, schema evolution handling, and governance considerations with Unity Catalog RBAC and data lineage?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"advanced","tags":["databricks-data-engineer"],"companies":["Airbnb","Cloudflare","Databricks"]},{"id":"q-1182","question":"In a multi-tenant Databricks lakehouse ingesting per-tenant telemetry from Kafka and S3 into a unified Silver Delta table, describe an end-to-end CDC strategy to implement SCD2-like history per tenant with idempotent MERGE, handle late data with a watermark, and enforce governance through Unity Catalog RBAC and dynamic PII masking. Include data model, CDC logic, testing plan, and how you’d validate lineage?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"advanced","tags":["databricks-data-engineer"],"companies":["Discord","Google","Snowflake"]},{"id":"q-1226","question":"In a Databricks Delta Live Tables pipeline that ingests clickstream events from a cloud bucket into a Delta table, data quality checks are defined via expectations. A batch arrives with corrupted event_time values that would fail the run. Outline a concrete approach to quarantine bad data, feed downstream tables only from valid rows, and store invalids for audit, while still handling late data and deduplication?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["databricks-data-engineer"],"companies":["Hashicorp","Zoom"]},{"id":"q-1264","question":"In a Databricks job ingesting daily Parquet files from S3 into Delta Lake, a new field 'campaign_id' may appear in newer files while older ones do not. Describe a concrete, beginner-friendly approach to ingest without data loss, allowing downstream joins, and handling the schema change gracefully. Include how to enable Delta schema evolution (mergeSchema/autoMerge), define a compatible target schema, and implement a minimal validation to drop rows missing essential fields?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"beginner","tags":["databricks-data-engineer"],"companies":["Anthropic","Coinbase","Uber"]},{"id":"q-906","question":"Scenario: A daily Delta Live Tables (DLT) pipeline ingests clickstream JSONs into a Bronze Delta table and then enriches with a users_dim to a Silver table. Build a beginner-friendly pipeline that: deduplicates by event_id, validates user_id via users_dim, filters to business hours 08:00–18:00, enriches with user fields, and writes to Silver partitioned by event_date. Outline minimal steps and rationale?","channel":"databricks-data-engineer","subChannel":"general","difficulty":"beginner","tags":["databricks-data-engineer"],"companies":["Apple","Netflix","Scale Ai"]},{"id":"q-1125","question":"You're building an incremental dbt model analytics.daily_revenue_by_product sourced from staging.sales_raw. Data can arrive late up to 2 days. How would you implement incremental upserts, reprocess late days without disturbing older data, and validate with tests and a snapshot of product price history? Provide a minimal SQL snippet illustrating the approach?","channel":"dbt-analytics-engineer","subChannel":"general","difficulty":"beginner","tags":["dbt-analytics-engineer"],"companies":["Apple","Hashicorp"]},{"id":"q-1165","question":"You're designing a dbt analytics pipeline for a ride-sharing platform. The raw events are in `staging.events_raw` with columns like `ride_id`, `city`, `ride_type`, `currency`, `amount`, `occurred_at`, and data can arrive up to 48 hours late. Build a beginner-friendly incremental model `analytics.daily_revenue` that computes USD revenue per day by `date`, `city`, and `ride_type`. Use a daily `pricing.exchange_rates` table to convert from local currency to USD. Describe how you'd implement incremental upserts, late-data handling (2-day window), schema-drift guards, and validation with tests and a snapshot. Also outline tests for late refunds and missing rates?","channel":"dbt-analytics-engineer","subChannel":"general","difficulty":"beginner","tags":["dbt-analytics-engineer"],"companies":["Google","PayPal"]},{"id":"q-1257","question":"Design a drift-aware dbt workflow across dev/staging/prod in Snowflake. How would you detect schema drift between sources and models using snapshots, tests, and sources, enforce a drift threshold, and automatically fail CI when drift exceeds the threshold? Describe the macro, tests, and alert/rollback mechanism, plus how you version thresholds?","channel":"dbt-analytics-engineer","subChannel":"general","difficulty":"advanced","tags":["dbt-analytics-engineer"],"companies":["Goldman Sachs","Google","Meta"]},{"id":"q-848","question":"You're designing a dbt analytics pipeline for an e-commerce platform. The 'staging.events_raw' table ingests page views and purchases and is partitioned by day. Data arrives both on time and as late as 24 hours. Design a practical incremental dbt model 'analytics.daily_sales' that aggregates revenue by day, category, and customer_segment. Explain how you'd implement incremental logic, handle late data, guard against schema drift, and validate with tests and snapshots?","channel":"dbt-analytics-engineer","subChannel":"general","difficulty":"advanced","tags":["dbt-analytics-engineer"],"companies":["Amazon","Anthropic","Tesla"]},{"id":"q-972","question":"In a dbt analytics project deployed to Snowflake, three tenants share a common model but data is isolated by schema prefixes (tenant_a_, tenant_b_, tenant_c_). Describe how you would structure tenancy-aware tests and a test runner to prevent cross-tenant data leakage during PR runs. Include how you configure sources, seeds, and per-tenant test filtering, and how you verify isolation in CI without touching production data?","channel":"dbt-analytics-engineer","subChannel":"general","difficulty":"advanced","tags":["dbt-analytics-engineer"],"companies":["DoorDash","Lyft","OpenAI"]},{"id":"q-1146","question":"You're building a data ingestion service that validates JSON records before persisting them. Validation steps include NonEmpty fields, Email format, and PasswordStrength. Validators must be pluggable: new validators can be added at runtime by registering them into a Registry without touching the core pipeline. Design a minimal interface and registry, and show how to compose and execute the pipeline with a sample config. Include how to add a new validator and run the pipeline, returning the first failure?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["IBM","Square","Tesla"]},{"id":"q-1201","question":"Design a runtime-pluggable per-message transformation system for a streaming pipeline. Messages include metadata that determines the transformation strategy (e.g., enrich, normalize, validate). Implement with a design pattern that lets you add new strategies without modifying the pipeline core. Provide minimal interfaces, a registry, and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["MongoDB","Plaid","Salesforce"]},{"id":"q-1236","question":"Design a runtime-pluggable, per-route transformer and throttling policy system for a real-time event router. Each route maps an event type to a transformer and a rate-limit policy; new transformers (enrich, redact, normalize) and new policies (token-bucket, fixed-window, leaky-bucket) must be addable at runtime without touching the router core. Which pattern would you adopt and how would you structure the minimal interfaces and registry?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Oracle","Snowflake"]},{"id":"q-1258","question":"Design a runtime-extensible notification dispatch system that handles multiple channels (email, SMS, push) where new transports and their backoff strategies can be added at runtime via a registry without touching the core dispatcher. Specify the minimal interfaces, how you register a new transport and a new backoff policy, and show a usage example including adding a WhatsApp transport and a geometric backoff?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Coinbase","DoorDash","Plaid"]},{"id":"q-1300","question":"Design a feature-flag evaluation engine for a large SaaS product. Flags support boolean, percentage rollout, user-segment, and A/B bucket strategies. Create a pluggable evaluator where new strategies can be added at runtime via a Registry without touching the core evaluator. Provide interfaces, a thread-safe registry, and a usage example with versioned strategy lookup?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["Discord","Google","Snowflake"]},{"id":"q-681","question":"You're building a multi-tenant API gateway for a Stripe-like payments service, backed by MongoDB storage and a Twitter-like feed. Each tenant has a per-minute rate limit. Describe a concrete solution using the Decorator pattern to enforce quotas, show how you'd implement atomic Redis updates, discuss burst handling and clock drift, and outline a minimal wrapper skeleton in code?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["MongoDB","Stripe","Twitter"]},{"id":"q-688","question":"You're building a feature flag system where flags can be evaluated as a hard boolean, a percentage rollout, or a targeted user segment. Design the architecture using a design pattern that lets you add new evaluation strategies without changing the caller. Which pattern would you choose and how would you implement it in code? Provide a minimal interface and usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Amazon","Google","Hashicorp"]},{"id":"q-695","question":"You're building a real-time data ingestion pipeline that must apply a sequence of transformations to each record. New transforms (normalization, enrichment, validation, anomaly detection) should be added as plugins without touching producer/consumer code. Design a pluggable Transform pipeline with per-tenant routing and hot-reload of configuration. Provide minimal interface and a usage example, including how to configure a few plugins and compose them for a stream?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Amazon","Google","Twitter"]},{"id":"q-706","question":"You're building an extensible data ingestion framework where new data formats (JSON, Parquet, ORC) must be supported without touching the core ingestion logic. Design the architecture using a pattern that decouples format parsing from the caller and lets you add new format handlers without changing the caller. Which pattern would you choose and how would you implement it in code? Provide a minimal interface and usage example?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["Amazon","Google","MongoDB"]},{"id":"q-714","question":"You're building a small HTTP client wrapper that fetches a user profile, but the server occasionally fails. The caller selects a retry policy by name (linear, exponential, jitter) and fetchUser should retry using that policy without changing fetchUser's code. Design the architecture using a design pattern that lets you add new retry strategies without modifying the caller. Provide a minimal interface and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Google","Lyft","Salesforce"]},{"id":"q-717","question":"You're building a real-time event processing pipeline that validates, enriches, and filters events before persisting. New validators, enrichers, and filters must be added at runtime without altering the core processor. Which design pattern enables this extensibility and how would you implement it? Provide minimal interfaces and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Snowflake","Stripe"]},{"id":"q-729","question":"You're building an image-processing pipeline that applies a sequence of filters (blur, brighten, sharpen) to images. The pipeline must run on both CPU and GPU backends, and new backends must be pluggable without touching filter implementations or orchestration code. Design an architecture that decouples filters from backends using a design pattern, enabling adding a backend such as Vulkan without modifying core code. Provide a minimal interface and usage example?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["Adobe","NVIDIA"]},{"id":"q-737","question":"In a messaging pipeline used by Zoom and Hugging Face, the system tokenizes, normalizes, and stores messages. You want to support swapping in different normalization strategies (lowercasing, diacritic removal, profanity filtering) without changing the pipeline code. Design the architecture using a design pattern that lets you add new normalization strategies without modifying the pipeline. Provide a minimal interface and a usage example. How would you implement this pattern to make additions painless?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Hugging Face","Zoom"]},{"id":"q-741","question":"In a telemetry alerting system for autonomous fleets, each customer needs a custom alert-threshold strategy for metrics like speed or battery: static value, percentile-based, or rolling window. The aggregator should surface alerts without depending on a concrete strategy. Design the architecture using a design pattern that lets you add new threshold strategies without modifying the aggregator. Provide a minimal interface and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["Tesla","Uber"]},{"id":"q-750","question":"You’re building a data export utility that must support multiple formats. New formats can come from external libraries with different APIs. Design an architecture using a pattern that lets you add new formats without changing the core exporter. Which pattern would you use and how would you implement it? Provide a minimal interface and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Anthropic","Cloudflare","Tesla"]},{"id":"q-763","question":"You're designing a data ingestion pipeline where raw inputs pass through optional enhancers (encryption, compression, watermarking) implemented as decorators around a base DataSource. You must add new decorators without touching the core pipeline or existing decorators. Which pattern would you use and how would you implement minimal interfaces to compose them? Provide a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["Instacart","Microsoft","Oracle"]},{"id":"q-769","question":"In a log analytics pipeline, you must support multiple formats (JSON, CSV, Protobuf) and multiple sinks (Elasticsearch, BigQuery, S3). Design an architecture using a design pattern that allows adding new formats or sinks without touching the producer. Provide minimal interfaces and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Lyft","MongoDB","Oracle"]},{"id":"q-781","question":"You're building a CLI tool that supports commands and subcommands, forming a tree (e.g., 'git remote add'). Design a Command interface that treats leaves (actual actions) and composites (groups of commands) uniformly. Implement LeafCommand and CommandGroup using the Composite pattern so a single call can execute a command or print help for a whole subtree without changing client code. Provide a minimal interface and usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Meta","Robinhood"]},{"id":"q-785","question":"You're building a pluggable HTTP request/response transformer pipeline inside a reverse proxy. Each Transformer can add, redact, or modify headers/body. The gateway must load new Transformers at runtime by name without redeploying. Design a minimal interface and registry-driven architecture that supports adding new transformer types without touching the gateway core. Provide a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Airbnb","Cloudflare","Meta"]},{"id":"q-793","question":"You're designing a streaming data processing framework where each record passes through a configurable pipeline of transformation steps. New transformations must be added at runtime without touching the orchestrator, and jobs select steps by name. Which design pattern and minimal interfaces would you use to register, compose, and execute transformations, ensuring type-safety and low churn when adding new steps? Provide a concise usage example?","channel":"design-patterns","subChannel":"general","difficulty":"advanced","tags":["design-patterns"],"companies":["Citadel","LinkedIn","Snowflake"]},{"id":"q-802","question":"Design a unit-test framework runner that supports multiple assertion styles (classic, fluent, should). The goal is to add a new assertion style (e.g., expect) at runtime without modifying the runner core. Which design pattern would be chosen and how would the minimal interfaces and a registry be structured? Provide a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Apple","Salesforce","Scale Ai"]},{"id":"q-809","question":"Design a health-check framework for a fleet-management service. The system aggregates health from multiple subsystems (database, message broker, geolocation API). New checks (checkDiskSpace, checkApiLatency) must be added at runtime without touching the aggregator. Which pattern supports this, and how would you implement minimal interfaces and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Lyft","Salesforce"]},{"id":"q-819","question":"You are designing a log export module for a distributed service. It must support exporting archives to multiple backends (S3, GCS, and an on-prem object store). New backends should be addable at runtime without touching the exporter or consumer code. Design the architecture using a design pattern that lets you plug in new backends via a registry. Provide a minimal interface and usage example?","channel":"design-patterns","subChannel":"general","difficulty":"intermediate","tags":["design-patterns"],"companies":["DoorDash","Netflix","Uber"]},{"id":"q-824","question":"Design a pluggable text-formatting pipeline for a CLI tool. The pipeline should allow new transforms to be added at runtime via a registry, without touching the core pipeline. Use a suitable pattern to compose these transforms in order; provide a minimal interface and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["Bloomberg","Hashicorp","MongoDB"]},{"id":"q-833","question":"You're building a streaming analytics dashboard where widgets render different metrics. New chart renderers can be added at runtime by third-party teams without modifying core widgets. Design the architecture using a design pattern that supports pluggable renderers via a registry. Provide a minimal interface and a usage example?","channel":"design-patterns","subChannel":"general","difficulty":"beginner","tags":["design-patterns"],"companies":["NVIDIA","Netflix","Tesla"]},{"id":"gh-16","question":"What is Infrastructure as Code and why has it become essential for modern DevOps practices?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["iac","terraform","ansible"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix","Salesforce"]},{"id":"gh-18","question":"What is Ansible and how does it work for infrastructure automation?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["iac","terraform","ansible"],"companies":["Amazon Web Services","Google Cloud","Microsoft","Red Hat","Southwest Airlines"]},{"id":"gh-29","question":"What is Configuration Management?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["config-mgmt","ansible","chef"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Netflix"]},{"id":"gh-30","question":"What is Puppet and how does it manage infrastructure configuration?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["config-mgmt","ansible","chef"],"companies":["Bank Of America","Cisco","Google","Microsoft","Staples"]},{"id":"gh-31","question":"What is Scalability in DevOps?","channel":"devops","subChannel":"automation","difficulty":"advanced","tags":["scale","ha"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-36","question":"How do different backup strategies balance storage efficiency, backup speed, and recovery time?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["backup","dr"],"companies":["Amazon","Google","LinkedIn","Microsoft","Uber"]},{"id":"gh-92","question":"How does a Service Catalog enable self-service infrastructure provisioning in an Internal Developer Platform?","channel":"devops","subChannel":"automation","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Spotify"]},{"id":"q-243","question":"How would you design a zero-downtime deployment strategy using Ansible that includes blue-green infrastructure setup, traffic management, and automated rollback capabilities?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["ansible","puppet","chef"],"companies":["Adobe","Amazon","Google","Microsoft","Netflix","Stripe"]},{"id":"q-269","question":"Compare Ansible, Puppet, and Chef configuration management tools, focusing on their architecture, state management approaches, and ideal use cases for enterprise environments?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["ansible","puppet","chef"],"companies":["Adobe","Amazon","Google","IBM","Microsoft","Netflix"]},{"id":"q-304","question":"How would you design a multi-environment configuration management strategy using Ansible that supports development, staging, and production environments with role-based access control?","channel":"devops","subChannel":"automation","difficulty":"advanced","tags":["ansible","puppet","chef"],"companies":["Amazon","Google","Meta"]},{"id":"q-381","question":"You have 10 web servers that all need Nginx installed and configured identically. How would you use Ansible to ensure this configuration is consistent across all servers?","channel":"devops","subChannel":"automation","difficulty":"beginner","tags":["ansible","puppet","chef"],"companies":["Deepmind","Google","MongoDB"]},{"id":"q-421","question":"You're managing infrastructure at scale with Ansible, Puppet, and Chef. How would you design a configuration management strategy that handles secret rotation across 1000+ servers while ensuring zero-downtime deployments?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["ansible","puppet","chef"],"companies":["Discord","Meta","Scale Ai"]},{"id":"q-437","question":"You're migrating from Puppet to Ansible for configuration management. How would you handle idempotency differences and what strategy would you use to ensure zero-downtime during the transition?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["ansible","puppet","chef"],"companies":["Adobe","Amazon","Cloudflare","Hashicorp","IBM","Microsoft","Netflix","Salesforce"]},{"id":"q-459","question":"You're managing infrastructure at scale with Ansible. How would you design a strategy to handle configuration drift across 1000+ servers while ensuring minimal downtime during updates?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["ansible","puppet","chef"],"companies":["Cloudflare","Discord","Tesla"]},{"id":"q-490","question":"You're migrating a 500-server fleet from Puppet to Ansible with zero downtime. How would you design the migration strategy to ensure configuration consistency and rollback capabilities?","channel":"devops","subChannel":"automation","difficulty":"advanced","tags":["ansible","puppet","chef"],"companies":["Adobe","Microsoft","PayPal"]},{"id":"q-573","question":"How would you design a GitOps workflow using Terraform and ArgoCD to manage infrastructure across multiple cloud providers while ensuring zero-downtime deployments?","channel":"devops","subChannel":"automation","difficulty":"intermediate","tags":["ansible","puppet","chef"],"companies":["Cloudflare","OpenAI"]},{"id":"do-2","question":"Compare Blue/Green vs Canary deployment strategies, including traffic routing, monitoring, rollback complexity, and cost implications for a microservices architecture?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["deployment","strategy","cicd","jenkins"],"companies":null},{"id":"gh-1","question":"What are the core principles and practices of DevOps, and how does it bridge the gap between development and operations teams?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["basics"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-10","question":"What is a CI/CD pipeline and how does it automate software delivery?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["cicd","automation"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-102","question":"What is GitHub Actions and how does it work?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Digital Ocean","Goldman Sachs","Google","Microsoft"]},{"id":"gh-104","question":"What is Canary Analysis and how does it work in production deployments?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-11","question":"What is Jenkins and how does it facilitate continuous integration and continuous delivery (CI/CD) in modern software development workflows?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["cicd","automation"],"companies":["Amazon","Deutsche Bank","Goldman Sachs","Microsoft","Netflix"]},{"id":"gh-2","question":"How would you design a DevOps pipeline that reduces deployment time by 60% while improving reliability and security?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["basics"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-3","question":"What is Continuous Integration and how does it improve software development quality?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["basics"],"companies":["Amazon","Google","Microsoft","Netflix","Stripe"]},{"id":"gh-64","question":"What are the four key DORA metrics for measuring DevOps performance and how are they calculated?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["metrics","kpi"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix","Salesforce"]},{"id":"gh-67","question":"How does Database DevOps integrate database schema changes into CI/CD pipelines while ensuring data integrity and minimizing downtime?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["db","devops"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Snowflake"]},{"id":"gh-68","question":"How would you implement comprehensive security practices in a DevOps pipeline including SAST/DAST, container security, and secrets management?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["security","network"],"companies":["Amazon","Cloudflare","Google","Microsoft","Netflix","Stripe"]},{"id":"gh-74","question":"How does DevOps culture transform traditional siloed development and operations into collaborative workflows?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["culture","soft-skills"],"companies":["Amazon","Google","LinkedIn","Microsoft","Netflix"]},{"id":"gh-75","question":"What DevOps practices are essential for implementing continuous delivery and fostering team collaboration?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["culture","soft-skills"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-90","question":"What is Blue/Green Deployment?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-177","question":"Explain the key differences between model serving and model deployment in ML systems, including specific technologies, scaling considerations, and real-world implementation patterns?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["mlops","deployment"],"companies":["Amazon","Databricks","Google","Meta","Microsoft","Netflix"]},{"id":"q-194","question":"How would you design a Terragrunt + Atlantis workflow that prevents state lock contention across 50+ microservice environments while maintaining DRY principles?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["dry","terragrunt","atlantis"],"companies":["Airbnb","Coinbase","Databricks","Stripe","Uber"]},{"id":"q-298","question":"Design a large-scale enterprise CI/CD system for an AWS-based application?","channel":"devops","subChannel":"cicd","difficulty":"advanced","tags":["ci-cd","aws","enterprise","containers","automation"],"companies":["Amazon","Google","Microsoft"]},{"id":"q-318","question":"How would you design a GitHub Actions workflow that runs tests in parallel across multiple matrix configurations while ensuring proper artifact management and failure handling?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["github-actions","jenkins","gitlab-ci"],"companies":["DoorDash","LinkedIn","Robinhood"]},{"id":"q-332","question":"You have a GitHub Actions workflow that's failing intermittently due to race conditions when multiple PRs trigger the same deployment pipeline. How would you design a solution to prevent concurrent deployments while maintaining fast feedback for developers?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["github-actions","jenkins","gitlab-ci"],"companies":["Amazon","Hulu","Jane Street"]},{"id":"q-398","question":"You have a GitHub Actions workflow that's failing intermittently due to rate limiting on a third-party API. How would you design a robust retry mechanism with exponential backoff while ensuring the workflow completes within the 6-hour timeout limit?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["github-actions","jenkins","gitlab-ci"],"companies":["Deepmind","Elastic","Webflow"]},{"id":"q-410","question":"You're setting up a CI/CD pipeline for a microservice that needs to run security scans, build a Docker image, and deploy to staging. How would you configure GitHub Actions to fail fast if security vulnerabilities are found, while still allowing the build to proceed for testing?","channel":"devops","subChannel":"cicd","difficulty":"beginner","tags":["github-actions","jenkins","gitlab-ci"],"companies":["Meta","Okta","PayPal"]},{"id":"q-444","question":"You have a GitHub Actions workflow that's failing intermittently due to rate limiting. How would you design a robust CI/CD pipeline that handles API rate limits, implements proper retry logic, and ensures consistent deployments across multiple environments?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["github-actions","jenkins","gitlab-ci"],"companies":["OpenAI","Tesla","Uber"]},{"id":"q-520","question":"You have a GitHub Actions workflow that's failing intermittently due to rate limiting when pulling Docker images. How would you design a robust solution that ensures consistent builds while minimizing costs?","channel":"devops","subChannel":"cicd","difficulty":"intermediate","tags":["github-actions","jenkins","gitlab-ci"],"companies":["Apple","Square"]},{"id":"q-1159","question":"Design a CI/CD pipeline for a containerized application that needs to support multiple environment-specific configurations (dev, staging, prod) while maintaining security best practices. How would you structure the pipeline to handle secrets management, image scanning, and environment-specific deployments without duplicating pipeline code?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["ci-cd","container-security","secrets-management","multi-environment","kubernetes"],"companies":[]},{"id":"q-640","question":"Design a multi-region CI/CD pipeline for a global SaaS application that must achieve 99.99% uptime with zero-downtime deployments. The pipeline should handle blue-green deployments across 5 regions, implement circuit breakers for regional failures, and maintain data consistency. How would you architect this pipeline and what specific tools and strategies would you use?","channel":"devops","subChannel":"devops","difficulty":"advanced","tags":["multi-region","blue-green","gitops","circuit-breaker","zero-downtime"],"companies":[]},{"id":"q-641","question":"Design a CI/CD pipeline for a monolithic application that needs to be gradually migrated to microservices. How would you structure the pipeline to support both the monolith and new microservices during the transition period, ensuring minimal downtime and feature parity?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["ci-cd","microservices","migration","pipeline-design","monolith"],"companies":[]},{"id":"q-644","question":"How would you design a CI/CD pipeline that implements feature flagging and progressive delivery to enable zero-downtime deployments for a high-traffic e-commerce platform?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["feature-flags","progressive-delivery","zero-downtime","canary-deployment","monitoring"],"companies":[]},{"id":"q-648","question":"How would you implement a custom Kubernetes scheduler to handle specialized workloads like GPU-intensive ML jobs, and what components would need to be modified compared to the default scheduler?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["kubernetes","scheduler","custom-scheduler","gpu","ml-workloads","devops"],"companies":[]},{"id":"q-652","question":"How would you design a CI/CD pipeline that implements progressive delivery with feature flags, ensuring zero-downtime deployments while maintaining data consistency across multiple database services?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["feature-flags","progressive-delivery","database-migration","zero-downtime","blue-green-deployment"],"companies":[]},{"id":"q-654","question":"How would you implement a custom Kubernetes scheduler to handle specific business requirements like cost optimization or geographic placement, and what are the key components you'd need to modify?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["kubernetes","scheduler","custom-scheduler","cost-optimization","devops"],"companies":[]},{"id":"q-655","question":"How would you design a CI/CD pipeline that implements infrastructure-as-code with blue-green deployments while ensuring zero-downtime database schema migrations?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["infrastructure-as-code","blue-green-deployment","database-migration","zero-downtime"],"companies":[]},{"id":"q-656","question":"How would you implement a custom Kubernetes scheduler to prioritize pods based on business criticality levels, and what components would you need to modify or extend?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["kubernetes","custom-scheduler","pod-priority","scheduling-framework","devops"],"companies":[]},{"id":"q-657","question":"How would you design a CI/CD pipeline that implements infrastructure-as-code with immutable infrastructure patterns, ensuring zero-downtime deployments while maintaining compliance and audit trails for a regulated industry?","channel":"devops","subChannel":"devops","difficulty":"intermediate","tags":["infrastructure-as-code","immutable-infrastructure","compliance","zero-downtime","audit-trails"],"companies":[]},{"id":"gh-37","question":"What is Cloud Native Architecture?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["cloud-native","microservices"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-4","question":"What is Docker and how does containerization differ from traditional virtualization in terms of architecture and resource efficiency?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["docker","containers"],"companies":["Amazon","Google","Microsoft","Netflix","PayPal","Uber"]},{"id":"gh-5","question":"Explain the Docker image and container lifecycle, including image layers, copy-on-write, container states, and resource isolation mechanisms?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["docker","containers"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"gh-6","question":"What is a Dockerfile and how does it enable containerized application deployment?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["docker","containers"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Netflix"]},{"id":"q-171","question":"You have a Docker container that keeps crashing and restarting in production. How would you systematically debug this issue without modifying the container image, and what specific Docker commands and monitoring techniques would you use?","channel":"devops","subChannel":"docker","difficulty":"intermediate","tags":["docker","containers"],"companies":["Amazon","Databricks","Google","Microsoft","Netflix","Snowflake"]},{"id":"q-191","question":"What is the purpose of a multi-stage Docker build and how does it reduce final image size?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["dockerfile","compose","multi-stage"],"companies":["Amazon","Capital One","Google","Microsoft","Uber"]},{"id":"q-289","question":"How do you implement multi-stage builds in Docker to optimize image size and security while maintaining build cache efficiency?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["dockerfile","compose","multi-stage"],"companies":["Amazon","Google","Netflix","Spotify","Uber"]},{"id":"q-344","question":"You're deploying a Node.js microservice to production and notice the Docker image is 850MB. How would you optimize it using multi-stage builds, and what are the key trade-offs between image size and build time?","channel":"devops","subChannel":"docker","difficulty":"intermediate","tags":["dockerfile","compose","multi-stage"],"companies":["Aurora","Shopify","Snowflake"]},{"id":"q-354","question":"You need to deploy a Node.js microservice to SAP's production environment. The current Dockerfile is 1.2GB and includes build tools. How would you optimize it using multi-stage builds to reduce the image size under 200MB?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["dockerfile","compose","multi-stage"],"companies":["Apple","Elastic","Sap"]},{"id":"q-670","question":"Given a monorepo with two services: a Node.js API and a Python worker, design multi-stage Dockerfiles to produce minimal production images, using BuildKit secrets for API keys at build time without bake-in. Write a docker-compose.yml to build and run both services on a shared network, mount a logs volume, and run as a non-root user. How would you implement end-to-end?","channel":"devops","subChannel":"docker","difficulty":"intermediate","tags":["dockerfile","compose","multi-stage"],"companies":["Anthropic","Google","LinkedIn"]},{"id":"q-671","question":"Given a minimal FastAPI app (main.py) with requirements.txt, write a 2-stage Dockerfile to build and run it in a slim final image. Ensure the app runs as a non-root user, and the runtime image only contains Python and the app. Create a docker-compose.yml that starts the web service and a Redis cache, exposes port 8000, and reads config from .env. How would you verify the image size and run locally?","channel":"devops","subChannel":"docker","difficulty":"beginner","tags":["dockerfile","compose","multi-stage"],"companies":["Apple","Meta","Salesforce"]},{"id":"gh-27","question":"Design a Git-based collaboration system for a 50-person distributed team. How would you implement branching strategies, conflict resolution, and CI/CD integration to ensure 99.9% uptime while handling 1000+ daily commits?","channel":"devops","subChannel":"gitops","difficulty":"advanced","tags":["git","vcs"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"gh-28","question":"What is Git Branching Strategy?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["git","vcs"],"companies":["Amazon","Goldman Sachs","Google","Meta","Microsoft"]},{"id":"gh-53","question":"What is GitOps and how does it work in practice?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["automation","tools"],"companies":["Amazon Web Services","Gitlab","Google","Microsoft","Netflix"]},{"id":"gh-54","question":"What is ArgoCD and how does it implement GitOps for Kubernetes deployments?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["automation","tools"],"companies":["Amazon","Google","Hashicorp","IBM","Microsoft","Netflix"]},{"id":"q-217","question":"How would you design a GitOps multi-cluster deployment strategy using ArgoCD that handles blue-green deployments with zero-downtime rollback across 50+ clusters while maintaining state consistency?","channel":"devops","subChannel":"gitops","difficulty":"advanced","tags":["argocd","flux","declarative"],"companies":["Amazon","Google","Microsoft","Red Hat","Uber"]},{"id":"q-366","question":"How would you design a GitOps workflow using ArgoCD to deploy a microservices application across multiple environments?","channel":"devops","subChannel":"gitops","difficulty":"intermediate","tags":["gitops","argocd","kubernetes","deployment","automation"],"companies":["Amazon","Google","Meta"]},{"id":"q-429","question":"You're setting up GitOps for a microservices deployment. How would you configure ArgoCD to automatically sync changes from your Git repository to Kubernetes, and what's the difference between declarative and imperative approaches in this context?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["argocd","flux","declarative"],"companies":["Amazon","DoorDash","Google","Hashicorp","Lyft","Microsoft","Netflix"]},{"id":"q-547","question":"You're implementing GitOps for a microservices application. How would you configure ArgoCD to automatically sync changes from your Git repository to Kubernetes, and what would you set as the sync policy to ensure safe deployments?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["argocd","flux","declarative"],"companies":["IBM","NVIDIA","Tesla"]},{"id":"q-668","question":"Describe a practical, automated secret rotation flow in a multi-cluster GitOps setup using ArgoCD and Flux. Include how Vault, ExternalSecret/SealedSecret, and per-cluster Secrets interact, what triggers rotation, how drift is prevented, and how rollback/auditing is handled across clusters?","channel":"devops","subChannel":"gitops","difficulty":"advanced","tags":["argocd","flux","declarative"],"companies":["Apple","Plaid","Zoom"]},{"id":"q-669","question":"You manage a single service deployed to Kubernetes with declarative manifests stored in git. Using both Argo CD and Flux in a GitOps pipeline, describe a practical beginner-friendly approach to implement blue-green or canary deployment, including the minimal YAML you'd configure in Argo CD to promote from staging to prod, and how you'd handle secrets?","channel":"devops","subChannel":"gitops","difficulty":"beginner","tags":["argocd","flux","declarative"],"companies":["Amazon","DoorDash","Google"]},{"id":"q-633","question":"Design a CI/CD pipeline for a microservices application with 10 services, where each service has its own repository. The pipeline must support parallel deployments, canary releases, and automatic rollback on failure. How would you structure the pipeline and what tools would you use?","channel":"devops","subChannel":"kubernetes-devops","difficulty":"advanced","tags":["CI/CD","microservices","kubernetes","gitops","canary-deployments"],"companies":["Google","Netflix","Uber","Spotify","Airbnb"]},{"id":"q-600","question":"Design a CI/CD pipeline for a microservices application that includes automated testing, security scanning, and deployment to multiple environments (dev, staging, prod). What are the key components and how would you ensure zero-downtime deployments?","channel":"devops","subChannel":"pipeline-architecture","difficulty":"intermediate","tags":["CI/CD","microservices","docker","kubernetes","security","zero-downtime"],"companies":["Google","Amazon","Microsoft","Netflix","Uber","Spotify"]},{"id":"q-602","question":"Design a CI/CD pipeline for a microservices application with the following requirements: automated testing, containerization, blue-green deployment, and rollback capabilities. What tools and stages would you include?","channel":"devops","subChannel":"pipeline-architecture","difficulty":"intermediate","tags":["CI/CD","microservices","kubernetes","docker","devops"],"companies":["Google","Amazon","Microsoft","Netflix","Uber","Spotify"]},{"id":"q-613","question":"Design a CI/CD pipeline for a microservices application with 10 services. How would you handle deployment strategies, testing, and rollback mechanisms?","channel":"devops","subChannel":"pipeline-architecture","difficulty":"intermediate","tags":["CI/CD","microservices","kubernetes","docker","deployment"],"companies":["Google","Amazon","Microsoft","Netflix","Uber","Spotify"]},{"id":"q-629","question":"Design a CI/CD pipeline for a microservices application that includes automated testing, security scanning, and multi-environment deployments. What components would you include and how would you structure the pipeline stages?","channel":"devops","subChannel":"pipeline-architecture","difficulty":"intermediate","tags":["cicd","microservices","devops","automation","security"],"companies":["Amazon","Google","Microsoft","Netflix","Spotify"]},{"id":"q-594","question":"How does Kubernetes decide which node to schedule a pod on, and what factors can influence this decision?","channel":"devops","subChannel":"pod-scheduling","difficulty":"intermediate","tags":["kubernetes","scheduling","kube-scheduler","node-selection","resource-management"],"companies":["Google","Amazon","Microsoft","Red Hat","VMware","IBM"]},{"id":"q-608","question":"How does Kubernetes handle pod scheduling when a node becomes resource-constrained, and what mechanisms can be used to ensure critical pods remain running?","channel":"devops","subChannel":"pod-scheduling","difficulty":"intermediate","tags":["kubernetes","scheduling","resource-management","priority","preemption"],"companies":["Google","Netflix","Uber","Amazon","Microsoft"]},{"id":"q-638","question":"Explain how Kubernetes scheduler decides which node to place a pod on, and what factors can cause a pod to remain in a Pending state?","channel":"devops","subChannel":"pod-scheduling","difficulty":"intermediate","tags":["kubernetes","scheduling","pod-management","troubleshooting","resource-allocation"],"companies":["Google","Amazon","Microsoft","Red Hat","VMware"]},{"id":"q-635","question":"How does Kubernetes handle pod scheduling when a node becomes unavailable, and what mechanisms ensure high availability?","channel":"devops","subChannel":"pod-scheduling-failover","difficulty":"intermediate","tags":["kubernetes","scheduling","high-availability","pod-management","failover"],"companies":["Google","Amazon","Microsoft","Red Hat","VMware","IBM"]},{"id":"q-620","question":"Explain the difference between node affinity, node selectors, and taints/tolerations in Kubernetes pod scheduling. When would you use each?","channel":"devops","subChannel":"scheduling-mechanisms","difficulty":"intermediate","tags":["kubernetes","pod-scheduling","node-affinity","taints-tolerations","devops"],"companies":["Google","Amazon","Microsoft","Netflix","Uber"]},{"id":"q-856","question":"You're running a Docker Swarm with services frontend, api, and worker. A feature-flag config is provided via Docker Config mounted at /etc/flags.json in all containers. You must rotate this config weekly with zero downtime. Describe the exact sequence of commands to create a new config version, rotate the services to use it, and implement a graceful reload inside apps so the new flags are picked up without losing requests. Include any Swarm update options you would tune?","channel":"docker-dca","subChannel":"general","difficulty":"beginner","tags":["docker-dca"],"companies":["Hashicorp","Snowflake"]},{"id":"q-862","question":"In a Docker Swarm with a stateful web app that uses Postgres, you must roll out version 3.2 with a DB schema migration and zero downtime. Propose a concrete upgrade plan that uses a start-first, one-task-at-a-time update, a separate migration container, and post-migration validation. Include exact Swarm commands and a minimal docker-compose snippet showing update_config?","channel":"docker-dca","subChannel":"general","difficulty":"advanced","tags":["docker-dca"],"companies":["IBM","PayPal"]},{"id":"q-1262","question":"You're given an array A of length n and an integer k. You must select exactly k non-overlapping, contiguous subarrays (non-empty) to maximize the sum of all selected elements. Return the maximum sum and the k subarrays (start and end indices). Propose a dynamic programming formulation with states and recurrences, include reconstruction, and discuss time/space complexity?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Hugging Face","Snap"]},{"id":"q-679","question":"In a warehouse grid of size n x m, each cell has a traversal cost. You can move only right or down from (0,0) to (n-1,m-1). You have a one-time token to halve the cost of exactly one visited cell. Design an O(nm) DP to compute the minimum path cost after optimally using the discount, and describe the recurrences and a space-optimized implementation?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Anthropic","Snap","Twitter"]},{"id":"q-691","question":"You're planning a delivery route along a straight street of n blocks. At block i you can advance up to jumps[i] blocks (at least 1). How many distinct routes reach block n-1 from block 0? If unreachable, return 0. Propose a dynamic-programming approach with dp[i] as ways to reach i and outline its time/space complexity, edge cases, and a brief correctness justification. How would you implement it?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["DoorDash","Meta","Square"]},{"id":"q-693","question":"You're building a daily workout planner. Over n days, you can pick Light (L) or Heavy (H) workouts, with a cooldown: after a Heavy, you must skip the next two days (no workouts). Given integers n and r, how many length-n sequences contain exactly r Heavy workouts and satisfy the cooldown rule? Provide a DP formulation with state dp[i][c][t] (days processed, cooldown days left, heavies used) and outline time/space complexity, edge cases, and a brief correctness justification?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Citadel","Google","Microsoft"]},{"id":"q-703","question":"You're navigating a warehouse grid of size n x m. Each cell (i, j) has a risk value r[i][j] ≥ 0, where higher means less safe. You may move only right or down from (0,0) to (n-1,m-1). Devise a dynamic-programming solution to minimize the maximum risk encountered on the path (i.e., minimize max(r[i][j]) along the path). Define a suitable dp[i][j], give the recurrence and base cases, describe reconstruction of the path, and analyze time/space complexity. How would you handle blocked cells by setting r[i][j] = INF?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["NVIDIA","Scale Ai","Stripe"]},{"id":"q-716","question":"You're building a text formatter. Given a list of word lengths L = [l1, l2, ..., ln] and a maximum line width W, wrap the words into lines so that all lines except the last incur a penalty of (W - usedWidth)^2, where usedWidth = sum of word lengths on the line plus spaces between words. The last line has 0 penalty. Propose a dynamic programming solution with dp[i] representing the minimum penalty for words i..n-1, specify the recurrence, reconstruction method, and time/space complexity. How would you implement it?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Anthropic","DoorDash","Square"]},{"id":"q-718","question":"You're given an array A[1..n] and an integer k. Partition into exactly k contiguous segments. The cost of a segment [t+1..i] is (sum(A[t+1..i]))^2. Return the minimum total cost and the partition indices. Propose DP: P as prefix sums, dp[i][j] = min_{t in [j-1..i-1]} dp[t][j-1] + (P[i]-P[t])^2, with base dp[0][0]=0. Explain reconstruction and discuss naive vs. optimized time, space, and edge cases?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Bloomberg","Netflix"]},{"id":"q-731","question":"You're given an array A of length n with non-negative integers representing daily story points. You must partition the days into consecutive weeks, each containing 2–7 days. The cost of a week is (sum of that week's points − W)^2 where W is a fixed target. Return the minimum total cost to cover all days or INF if impossible. Propose a DP with dp[i] as min cost for first i days; dp[i] = min_{k=2..7, i-k>=0} dp[i-k] + (sum(i-k+1..i) − W)^2, using prefix sums for O(1) range sums. Reconstruct weeks and analyze time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Databricks","Salesforce","Two Sigma"]},{"id":"q-736","question":"You're given an n x m grid. Each cell (i, j) has a color c[i][j] in [0, C-1] and a non-negative cost w[i][j]. Start at (0,0) and move to (n-1,m-1) with only right or down moves. You must visit at least one cell of every color that appears in the grid along your path. Return the minimum total cost to do so, or -1 if impossible. Describe a DP using dp[i][j][mask] where mask tracks visited colors; explain base cases, transitions from top/left, how to reconstruct the path, and complexity?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["Microsoft","Netflix","Plaid"]},{"id":"q-743","question":"You're given a list of n task durations L. Partition the tasks into consecutive days (each day at least one task); the cost of a day is the maximum duration on that day. Devise a DP to minimize the total cost across all days. Define dp[i] as the minimum cost for the first i tasks, provide the recurrence, reconstruction method, and complexity. How would you implement it?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Slack","Stripe","Twitter"]},{"id":"q-754","question":"Given a circular array v[1..n] of non-negative values and an integer d≥1, pick a subset of indices such that the cyclic distance between any two chosen indices is at least d. Maximize the sum of selected values; return both the maximum sum and the number of distinct optimal subsets. Constraints: n ≤ 2e5, v[i] ≤ 1e9. Describe an O(n) DP solution with two cases for circularity and how you'd reconstruct counts?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Apple","Netflix","Uber"]},{"id":"q-768","question":"You're given an array A of length n and an integer k. Partition A into exactly k non-empty contiguous subarrays. The cost of a subarray [t+1..i] is (max(A[t+1..i])) * (i-t). Return the minimum total cost and the partition indices. Propose DP: dp[i][j] = min_{t in [j-1..i-1]} dp[t][j-1] + max(A[t+1..i]) * (i-t). Explain reconstruction, base cases, and time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["Adobe","Robinhood","Salesforce"]},{"id":"q-777","question":"You're given an array A of non-negative integers representing task durations in order. You must schedule all n tasks into exactly m days. Each day can host a consecutive block with total duration <= D. The cost of a day is (sum of that day's durations)^2. Return the minimum total cost, or -1 if impossible? Propose a DP using dp[i][d] as min cost for first i tasks in d days, with transition dp[i][d] = min_{j<i, prefix[i]-prefix[j] <= D} dp[j][d-1] + (prefix[i]-prefix[j])^2. Include base cases, reconstruction, and time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Amazon","Apple","Robinhood"]},{"id":"q-786","question":"You have an array A of length n. Partition into exactly k non-empty contiguous blocks. The cost of a block [t+1..i] is (max(A[t+1..i])) * (sum(A[t+1..i])). Return the minimum total cost and the partition indices. Propose a DP formulation, reconstruction strategy, and complexity analysis. Assume 1-based indexing?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["Coinbase","Scale Ai","Snap"]},{"id":"q-792","question":"You're given an array prices[0..n-1]. You may complete at most k buy-sell transactions (one share at a time, can't hold more than one). Return the maximum profit and the days of each trade. Propose a DP formulation with states cash[i][t] and hold[i][t], include recurrences, base cases, and reconstruction, and discuss time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["Goldman Sachs","IBM","MongoDB"]},{"id":"q-797","question":"You have an array of task difficulties A of length n. Partition it into exactly m non-empty contiguous chapters. Each chapter cost equals the maximum difficulty within that chapter. Return the minimum total cost and a valid partition (chapter end indices). Propose a DP: dp[i][j] = min_{t in [j-1..i-1]} dp[t][j-1] + max(A[t..i-1]), with base dp[i][1] = max(A[0..i-1]). Explain reconstruction, base cases, and time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"beginner","tags":["dynamic-programming"],"companies":["Adobe","LinkedIn","OpenAI"]},{"id":"q-806","question":"You're given an n x m grid of digits grid[i][j] in [0..9]. You may move only right or down from (0,0) to (n-1,m-1). Define a path score as the number of times the next cell's digit is strictly larger than the previous cell's digit along the path. Return the maximum score and a valid path (as coordinates or directions). Propose a dynamic programming formulation with recurrences, base cases, and reconstruction, and discuss time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Google","Hugging Face","Tesla"]},{"id":"q-813","question":"You're given a tree with N nodes (N up to 2e5). Each node i has a value val[i]. Find a connected subtree of exactly K nodes that maximizes the sum of values. Return the maximum sum and the node set. Propose a DP formulation with dp[u][s] = max sum of a connected subtree of size s that contains u and lies entirely within u's subtree when the tree is rooted at 1; include reconstruction, base cases, and discuss time/space?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["Google","Microsoft"]},{"id":"q-821","question":"You're given a string s of length n consisting of lowercase letters. Partition s into at most k non-empty contiguous substrings. The cost of a substring is the number of distinct characters in that substring. Return the minimum total cost and one valid partition (end indices). Propose a DP formulation with recurrence dp[i][t] = min_{p in [t-1..i-1]} dp[p][t-1] + cost(p, i-1) where cost(p, q) is the number of distinct letters in s[p..q]. Explain reconstruction, base cases, and time/space complexity?","channel":"dynamic-programming","subChannel":"general","difficulty":"intermediate","tags":["dynamic-programming"],"companies":["Citadel","LinkedIn","Snap"]},{"id":"q-829","question":"You're given an array A of length n and an integer k. Partition A into exactly k non-empty contiguous subarrays. Each subarray's cost is max(A[l..r]) - min(A[l..r]). Return the minimum total cost and one valid partition (end indices). Propose a DP: dp[i][t] = min_{p in [t-1..i-1]} dp[p][t-1] + (max(A[p..i-1]) - min(A[p..i-1])); base: dp[i][1] = max(A[0..i-1]) - min(A[0..i-1]). Explain reconstruction, base cases, and time/space complexity?","channel":"dynamic-programming","subChannel":"general","difficulty":"advanced","tags":["dynamic-programming"],"companies":["DoorDash","Hugging Face","Netflix"]},{"id":"q-235","question":"How do you organize Cypress fixtures for component testing, and what are the key patterns for managing test data dependencies across multiple test suites?","channel":"e2e-testing","subChannel":"cypress","difficulty":"beginner","tags":["cypress","component-testing","fixtures"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"q-1173","question":"Design an end-to-end test for GDPR data deletion in an e-grocery platform: a synthetic user requests account deletion that must purge PII from cart, catalog, checkout, loyalty services, and analytics pipelines across three regions. Describe data setup, purge verification across stores, caches, and search indexes, audit logs, and idempotency after replay; outline concrete tooling (Playwright + REST mocks + Kafka) and how you handle eventual consistency and test isolation?","channel":"e2e-testing","subChannel":"general","difficulty":"intermediate","tags":["e2e-testing"],"companies":["Apple","DoorDash"]},{"id":"q-449","question":"How would you design an E2E testing strategy for a distributed edge computing platform that needs to validate functionality across 100+ global data centers with varying network conditions?","channel":"e2e-testing","subChannel":"general","difficulty":"advanced","tags":["e2e-testing"],"companies":["Cloudflare","Tesla"]},{"id":"q-460","question":"You're testing a login form with Playwright. The form has email and password fields, and a submit button. How would you write a basic E2E test to verify successful login and redirect to dashboard?","channel":"e2e-testing","subChannel":"general","difficulty":"beginner","tags":["e2e-testing"],"companies":["Lyft","MongoDB","NVIDIA"]},{"id":"q-491","question":"How would you set up a basic E2E test for a login form using Playwright?","channel":"e2e-testing","subChannel":"general","difficulty":"beginner","tags":["e2e-testing"],"companies":["IBM","Lyft","Snowflake"]},{"id":"q-521","question":"You're testing a React app with Playwright. Some tests fail intermittently due to API delays. How would you make your e2e tests more reliable without removing the API dependency?","channel":"e2e-testing","subChannel":"general","difficulty":"intermediate","tags":["e2e-testing"],"companies":["Google","Hugging Face"]},{"id":"q-548","question":"How would you design a scalable E2E testing strategy for a microservices architecture with 50+ services, ensuring test isolation and parallel execution while maintaining realistic user journeys?","channel":"e2e-testing","subChannel":"general","difficulty":"advanced","tags":["e2e-testing"],"companies":["LinkedIn","Scale Ai"]},{"id":"q-574","question":"How would you handle flaky E2E tests in a CI/CD pipeline? What strategies would you implement to ensure reliable test execution?","channel":"e2e-testing","subChannel":"general","difficulty":"intermediate","tags":["e2e-testing"],"companies":["LinkedIn","Meta","Oracle"]},{"id":"q-850","question":"In a Stripe-like billing system built on an event-driven microservice architecture, design an E2E test that validates the end-to-end flow from a user initiating a purchase to invoice settlement across regionally distributed services. Include how you verify eventual consistency, idempotency, and state replay safety after a simulated regional outage, with concrete tooling choices and steps?","channel":"e2e-testing","subChannel":"general","difficulty":"advanced","tags":["e2e-testing"],"companies":["Google","Stripe"]},{"id":"q-901","question":"Design a beginner-friendly E2E test for a React checkout flow: user visits a product page, adds to cart, proceeds to checkout, fills shipping details, and completes a payment via a sandbox API. Explain how you would ensure test isolation and determinism (seed/reset test data, mock payment endpoint), and show a minimal Playwright script snippet that asserts successful order confirmation and a backend order record?","channel":"e2e-testing","subChannel":"general","difficulty":"beginner","tags":["e2e-testing"],"companies":["MongoDB","Tesla","Twitter"]},{"id":"q-949","question":"Design an end-to-end test plan for a Netflix/Meta-like streaming service that delivers adaptive bitrate video across 4 regions. Include how you model test content, simulate varying network conditions, verify manifest/chunk fetch, DRM/licensing checks, on-device caching, and end-to-end telemetry; specify tooling, data isolation, and how you scale across regions while minimizing flakiness?","channel":"e2e-testing","subChannel":"general","difficulty":"advanced","tags":["e2e-testing"],"companies":["Meta","Netflix"]},{"id":"q-979","question":"Design an end-to-end test for a multi-tenant content platform that serves regionally personalized content with feature flags and A/B tests. The platform must ensure per-tenant data isolation, correct content personalization, flag-driven UI, and during regional outages. Outline the test scope, data management, tooling, and steps to verify end-to-end delivery across tenants and regions without flakiness?","channel":"e2e-testing","subChannel":"general","difficulty":"advanced","tags":["e2e-testing"],"companies":["Adobe","Meta","Salesforce"]},{"id":"q-279","question":"What are the key differences between getByRole() and getByText() selectors in Playwright, and when would you choose one over the other for reliable E2E testing?","channel":"e2e-testing","subChannel":"playwright","difficulty":"beginner","tags":["playwright","browser-automation","selectors"],"companies":["Adobe","Amazon","Microsoft","Netflix","Salesforce"]},{"id":"q-208","question":"What is the difference between Selenium WebDriver and Selenium Grid, and when would you use each in your testing strategy?","channel":"e2e-testing","subChannel":"selenium","difficulty":"beginner","tags":["selenium","webdriver","grid"],"companies":["Amazon","Google","Meta"]},{"id":"q-1062","question":"You're stewarding reliability for a 24/7 payments platform with two active regions and strict latency requirements. A recent outage exposed brittle failover and slow triage. Outline a practical plan: governance model (platform vs product teams), incident playbooks, auto-remediation, SRE metrics, release controls, and how you measure ROI while preserving feature velocity?","channel":"engineering-management","subChannel":"general","difficulty":"advanced","tags":["engineering-management"],"companies":["Citadel","Microsoft","Square"]},{"id":"q-1088","question":"Two squads share a single API surface: Platform Reliability (2 senior + 1 mid) and Growth Feature (4 engineers). Platform incidents increased MTTR by 40% last quarter; Growth feature is 70% complete but depends on unstable APIs and tight external deadlines. How would you structure quarterly planning to protect reliability, reallocate capacity, set SLOs and error budgets, and implement gating (flags, canaries, contracts) to finish the Growth feature without amplifying risk?","channel":"engineering-management","subChannel":"general","difficulty":"intermediate","tags":["engineering-management"],"companies":["Google","Robinhood","Uber"]},{"id":"q-1223","question":"You're steward of a shared data platform used by 8 squads across web, mobile, and ML workloads. A new event schema from one squad breaks downstream contracts and delays analytics dashboards. Propose a governance model: data contracts, versioned schemas, deprecation policy, and a cross-squad escalation process. Include concrete ownership, metrics, and a migration plan that minimizes customer impact while meeting quarterly release goals?","channel":"engineering-management","subChannel":"general","difficulty":"advanced","tags":["engineering-management"],"companies":["Anthropic","Instacart","Twitter"]},{"id":"q-461","question":"How would you handle a situation where your top engineer wants to work on a different project, but you need them to complete a critical deadline?","channel":"engineering-management","subChannel":"general","difficulty":"intermediate","tags":["engineering-management"],"companies":["Airbnb","Google"]},{"id":"q-492","question":"How would you handle a situation where your top engineer wants to work on a personal project during work hours, claiming it will benefit the company long-term?","channel":"engineering-management","subChannel":"general","difficulty":"intermediate","tags":["engineering-management"],"companies":["Microsoft","Snap"]},{"id":"q-522","question":"You're leading a team of 5 engineers. Two team members disagree on the technical approach for a critical feature. How do you handle this situation while maintaining team morale and meeting the deadline?","channel":"engineering-management","subChannel":"general","difficulty":"beginner","tags":["engineering-management"],"companies":["Google","Instacart"]},{"id":"q-549","question":"How would you handle a situation where your top engineer wants to work on a different project than what the team needs?","channel":"engineering-management","subChannel":"general","difficulty":"beginner","tags":["engineering-management"],"companies":["Apple","Hashicorp","Scale Ai"]},{"id":"q-575","question":"How do you balance technical debt with feature delivery when managing engineering teams?","channel":"engineering-management","subChannel":"general","difficulty":"beginner","tags":["engineering-management"],"companies":["Bloomberg","PayPal"]},{"id":"q-860","question":"When onboarding new engineers to a project with a legacy codebase and a new component library, operating on a 3-week sprint with shared CI, what concrete onboarding plan and gates would you implement in the first 4 weeks to accelerate learning while preserving code quality and preventing regressions?","channel":"engineering-management","subChannel":"general","difficulty":"beginner","tags":["engineering-management"],"companies":["Meta","Stripe"]},{"id":"q-184","question":"You're managing a critical microservices migration from monolith to Kubernetes with 3 teams. Team A (backend services) is 2 weeks behind due to database connection pooling issues, Team B (frontend) is on track but blocked by API contracts, and Team C (DevOps) needs production-ready Helm charts by EOW. How do you resolve the technical dependencies and get the migration back on schedule while maintaining service availability?","channel":"engineering-management","subChannel":"project-management","difficulty":"advanced","tags":["project","planning"],"companies":["Adobe","Amazon","Google","Microsoft","Netflix","Salesforce"]},{"id":"q-211","question":"How would you implement a technical debt repayment framework using the 20% time allocation model while balancing feature delivery deadlines?","channel":"engineering-management","subChannel":"project-management","difficulty":"intermediate","tags":["delegation","mentoring","growth"],"companies":["Google","LinkedIn","Microsoft","Robinhood","Stripe"]},{"id":"q-261","question":"Design a task delegation matrix system for a 15-person engineering team that balances skill development with project delivery SLAs. Include RACI implementation, automated task assignment algorithms, and success metrics. How would you handle edge cases like skill gaps and conflicting priorities?","channel":"engineering-management","subChannel":"team-leadership","difficulty":"beginner","tags":["delegation","mentoring","growth"],"companies":["Amazon","Google","Meta","Microsoft","Salesforce","Stripe"]},{"id":"q-281","question":"How do you influence technical decisions when you're not the technical lead, and what specific strategies do you use to build technical credibility across different stakeholder groups?","channel":"engineering-management","subChannel":"team-leadership","difficulty":"intermediate","tags":["communication","collaboration","influence"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-168","question":"Explain the CSS box model and how box-sizing affects layout calculations. What's the difference between border-box and content-box?","channel":"frontend","subChannel":"css","difficulty":"beginner","tags":["css","styling"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-363","question":"You have a navigation bar with 3 items that should be evenly spaced. The middle item needs to be centered while the first and last items stick to the edges. How would you implement this using CSS Flexbox?","channel":"frontend","subChannel":"css","difficulty":"beginner","tags":["css","flexbox","grid","animations"],"companies":["Amazon","Google","Hrt","Meta","Microsoft","Netflix"]},{"id":"q-408","question":"You're building a responsive dashboard with a complex grid layout that must support dynamic widget resizing, reordering via drag-and-drop, and maintain performance with 100+ widgets. How would you architect the CSS grid system to handle these requirements while ensuring smooth animations and preventing layout thrashing?","channel":"frontend","subChannel":"css","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"companies":["Affirm","Okta","Shopify"]},{"id":"q-661","question":"Design a responsive image gallery using CSS Grid that shows 4 columns on wide screens, 2 on tablets, and 1 on mobile. Each tile contains an image, title, and caption. Add a hover/focus animation that lifts the tile and deepens the shadow, and ensure keyboard accessibility and respect for reduced-motion preferences?","channel":"frontend","subChannel":"css","difficulty":"beginner","tags":["css","flexbox","grid","animations"],"companies":["Amazon","Snap","Square"]},{"id":"q-664","question":"Question: Create a responsive 3-column feature grid using CSS Grid that collapses to a single column on narrow viewports, with a hover animation that gently scales each card and reveals a caption with a slide-in effect, while keeping focus-visible styles and respecting prefers-reduced-motion?","channel":"frontend","subChannel":"css","difficulty":"beginner","tags":["css","flexbox","grid","animations"],"companies":["Apple","Meta"]},{"id":"q-642","question":"You're building a React form with multiple controlled inputs that need to share validation state. How would you implement a custom hook to manage form state and validation logic efficiently, and what are the key considerations for preventing unnecessary re-renders?","channel":"frontend","subChannel":"frontend","difficulty":"intermediate","tags":["react-hooks","form-validation","performance-optimization","custom-hooks","state-management"],"companies":[]},{"id":"q-762","question":"You're building a React dashboard with multiple components that need to share and update real-time data (like stock prices or live metrics). How would you implement a state management solution that minimizes re-renders while ensuring all components receive the latest data, and what specific React patterns would you use to prevent performance bottlenecks?","channel":"frontend","subChannel":"frontend","difficulty":"intermediate","tags":["react-state-management","performance-optimization","context-api","real-time-data","memoization"],"companies":[]},{"id":"fe-2","question":"Explain the JavaScript Event Loop architecture. How do microtasks and macrotasks differ in execution order, and what are the practical implications for async/await code?","channel":"frontend","subChannel":"javascript","difficulty":"beginner","tags":["js","async","core"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"fe-3","question":"Explain JavaScript closures with a practical use case and how they're used in real applications?","channel":"frontend","subChannel":"javascript","difficulty":"intermediate","tags":["js","scope","patterns"],"companies":["Amazon","Google","Meta"]},{"id":"fr-157","question":"What is the difference between `let`, `const`, and `var` in JavaScript, and how do their scoping rules and temporal dead zone affect real-world code?","channel":"frontend","subChannel":"javascript","difficulty":"beginner","tags":["js","core"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"fr-162","question":"Explain how JavaScript's event loop handles microtasks vs macrotasks. What happens when a Promise resolves inside a setTimeout callback?","channel":"frontend","subChannel":"javascript","difficulty":"advanced","tags":["js","core"],"companies":["Airbnb","Google","Meta","Netflix","Stripe"]},{"id":"fr-173","question":"What is the output of this code and explain the event loop behavior: console.log('A'); setTimeout(() => console.log('B'), 0); Promise.resolve().then(() => console.log('C')); Promise.resolve().then(() => console.log('D')); console.log('E'); How do microtask and macrotask queues interact in JavaScript's event loop?","channel":"frontend","subChannel":"javascript","difficulty":"advanced","tags":["js","core"],"companies":["Amazon","Google","Meta","Netflix","Stripe"]},{"id":"q-240","question":"What is a closure in JavaScript and how does it enable data encapsulation?","channel":"frontend","subChannel":"javascript","difficulty":"beginner","tags":["js","es6","closures","promises"],"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-351","question":"You're building a file upload component that processes multiple files in parallel. How would you implement a concurrent upload queue with a maximum of 3 simultaneous uploads using Promise.allSettled and closures?","channel":"frontend","subChannel":"javascript","difficulty":"intermediate","tags":["js","es6","closures","promises"],"companies":["Amazon","Anthropic","Microsoft"]},{"id":"q-462","question":"Implement a rate-limited API wrapper that queues requests when the limit is reached, using closures to maintain state and promises to handle request ordering?","channel":"frontend","subChannel":"javascript","difficulty":"advanced","tags":["js","es6","closures","promises"],"companies":["Google","Lyft","Scale Ai"]},{"id":"q-550","question":"Explain how closures work in JavaScript and provide a practical example of when you'd use one in a React component?","channel":"frontend","subChannel":"javascript","difficulty":"beginner","tags":["js","es6","closures","promises"],"companies":["Google","Oracle","Tesla"]},{"id":"fr-154","question":"What are the performance implications and layout shift consequences of loading large images without explicit dimensions, and how do modern CSS properties and loading strategies mitigate these issues?","channel":"frontend","subChannel":"performance","difficulty":"beginner","tags":["perf","optimization"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"fr-172","question":"How would you optimize rendering performance for a React component displaying a large list (10,000+ items) with frequent real-time updates?","channel":"frontend","subChannel":"performance","difficulty":"intermediate","tags":["perf","optimization"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-188","question":"How would you implement a performance budget system that automatically detects bundle regressions and enforces lazy-loading boundaries in a large-scale React application?","channel":"frontend","subChannel":"performance","difficulty":"advanced","tags":["lighthouse","bundle","lazy-loading"],"companies":["Airbnb","Atlassian","LinkedIn","Netflix","Uber"]},{"id":"q-301","question":"How would you optimize a React app's bundle size to achieve Lighthouse scores above 90, and what specific tools and metrics would you use to measure success?","channel":"frontend","subChannel":"performance","difficulty":"beginner","tags":["lighthouse","bundle","lazy-loading"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-329","question":"You're tasked with improving a React app's Lighthouse performance score from 65 to 90+. The bundle size is 2.1MB and Time to Interactive is 4.2s. What specific steps would you take to optimize the bundle and implement lazy loading?","channel":"frontend","subChannel":"performance","difficulty":"intermediate","tags":["lighthouse","bundle","lazy-loading"],"companies":["Amazon","Google","Mckinsey","Meta","Microsoft","Netflix","Scale Ai","Stripe"]},{"id":"q-378","question":"You're building a real-time trading dashboard at DE Shaw that needs to display 1000+ rapidly updating price cards. How would you optimize CSS layout and animations to maintain 60fps while cards are being added/removed/updated every 100ms?","channel":"frontend","subChannel":"performance","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"companies":["DE Shaw","Discord","Instacart"]},{"id":"q-390","question":"You're working on a React app that loads slowly. Your Lighthouse performance score is 45. What specific steps would you take to improve it, and how would you implement lazy loading for a heavy component?","channel":"frontend","subChannel":"performance","difficulty":"beginner","tags":["lighthouse","bundle","lazy-loading"],"companies":["Crowdstrike","Deepmind","NVIDIA"]},{"id":"q-395","question":"You're building a complex dashboard with a responsive grid layout that must support dynamic column insertion, reordering, and animated transitions. How would you implement this using CSS Grid and JavaScript while maintaining 60fps performance during large dataset updates (10,000+ items)?","channel":"frontend","subChannel":"performance","difficulty":"advanced","tags":["css","flexbox","grid","animations"],"companies":["Google","Meta","Microsoft","Netflix","Salesforce","Stripe"]},{"id":"q-523","question":"Your React app has a 85 Lighthouse performance score. The bundle analyzer shows a 2.8MB main chunk with heavy libraries like moment.js and lodash. How would you optimize this to reach 95+?","channel":"frontend","subChannel":"performance","difficulty":"intermediate","tags":["lighthouse","bundle","lazy-loading"],"companies":["Cloudflare","Hugging Face","Stripe"]},{"id":"q-576","question":"How would you optimize a React app's Lighthouse score from 65 to 90+ using bundle analysis and lazy loading?","channel":"frontend","subChannel":"performance","difficulty":"beginner","tags":["lighthouse","bundle","lazy-loading"],"companies":["Coinbase","DoorDash"]},{"id":"fe-1","question":"How does React's Virtual DOM diffing algorithm work during reconciliation, and what role do keys play in optimizing list updates?","channel":"frontend","subChannel":"react","difficulty":"intermediate","tags":["react","perf","internals"],"companies":["Airbnb","Google","Meta","Microsoft","Netflix"]},{"id":"fr-161","question":"How would you implement a React hook that tracks component render count and warns when it exceeds a threshold, while avoiding infinite render loops?","channel":"frontend","subChannel":"react","difficulty":"advanced","tags":["react","perf"],"companies":["Airbnb","Microsoft","Netflix","Stripe","Uber"]},{"id":"q-215","question":"How would you implement a custom useDebounce hook that works with React's concurrent features and prevents stale closures?","channel":"frontend","subChannel":"react","difficulty":"intermediate","tags":["react","hooks","context","redux"],"companies":["Amazon","Google","Meta","Microsoft","Uber"]},{"id":"q-239","question":"How would you implement a React useMemo hook to optimize a recursive Fibonacci function with memoization, and what are the key trade-offs between top-down memoization vs bottom-up tabulation in this context?","channel":"frontend","subChannel":"react","difficulty":"intermediate","tags":["dp","memoization","tabulation"],"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-315","question":"How would you optimize a React app's bundle size and loading performance using lazy loading, code splitting, and webpack optimization strategies?","channel":"frontend","subChannel":"react","difficulty":"intermediate","tags":["lighthouse","bundle","lazy-loading"],"companies":null},{"id":"q-434","question":"You're building a React app with multiple components needing access to user authentication state. When would you choose Context API over Redux, and what are the specific performance implications of each approach?","channel":"frontend","subChannel":"react","difficulty":"intermediate","tags":["react","hooks","context","redux"],"companies":["Anthropic","Microsoft","NVIDIA"]},{"id":"q-595","question":"Explain the difference between useState and useReducer hooks in React and when you would choose one over the other.","channel":"frontend","subChannel":"react-hooks","difficulty":"intermediate","tags":["react","hooks","state-management","useState","useReducer"],"companies":["Meta","Netflix","Airbnb","Uber","Spotify"]},{"id":"q-628","question":"Explain the differences between useState, useReducer, and Context API for state management in React. When would you choose each approach?","channel":"frontend","subChannel":"react-hooks","difficulty":"intermediate","tags":["react","state-management","hooks","context-api"],"companies":["Meta","Netflix","Airbnb","Uber","Spotify"]},{"id":"q-287","question":"How does a Service Worker intercept network requests and implement offline caching strategies?","channel":"frontend","subChannel":"web-apis","difficulty":"intermediate","tags":["dom","fetch","websocket","service-worker"],"companies":["Amazon","Google","Meta"]},{"id":"q-341","question":"You're building a real-time collaborative document editor. How would you implement a service worker to handle offline synchronization, WebSocket reconnection logic, and conflict resolution when multiple users edit simultaneously?","channel":"frontend","subChannel":"web-apis","difficulty":"advanced","tags":["dom","fetch","websocket","service-worker"],"companies":["Affirm","Broadcom","Roblox"]},{"id":"q-419","question":"You're building a real-time food delivery tracking app. How would you implement a WebSocket connection that handles network interruptions and maintains order status updates when the app goes offline?","channel":"frontend","subChannel":"web-apis","difficulty":"intermediate","tags":["dom","fetch","websocket","service-worker"],"companies":["Apple","DoorDash","MongoDB"]},{"id":"q-426","question":"You're building a real-time chat application that needs to work offline. How would you implement a service worker to cache messages and sync them when the user comes back online?","channel":"frontend","subChannel":"web-apis","difficulty":"beginner","tags":["dom","fetch","websocket","service-worker"],"companies":["Anthropic","Hugging Face","Snap"]},{"id":"q-493","question":"You're building a real-time grocery delivery tracking app for Instacart. How would you implement a service worker strategy to handle intermittent connectivity, ensure order updates are delivered via WebSockets, and maintain a consistent UI state across network drops?","channel":"frontend","subChannel":"web-apis","difficulty":"advanced","tags":["dom","fetch","websocket","service-worker"],"companies":["Instacart","MongoDB"]},{"id":"q-663","question":"You’re building a chat UI that loads initial messages with fetch('/api/messages'), caches assets via a service worker, and receives live updates over a WebSocket at '/ws'. Explain and implement: (1) pre-cache strategy and cache invalidation in the SW, (2) a fetch wrapper with timeout and offline fallback to cache, (3) DOM updates for incoming WebSocket messages, (4) reconciliation when offline vs online and message ordering?","channel":"frontend","subChannel":"web-apis","difficulty":"intermediate","tags":["dom","fetch","websocket","service-worker"],"companies":["Coinbase","Google","LinkedIn"]},{"id":"q-665","question":"Design and implement a minimal real-time dashboard that loads initial data via fetch('/api/data?limit=200'), then opens a WebSocket to wss://host/ws for live updates, and uses a Service Worker to cache the app shell and latest API responses for offline use. Describe how you batch DOM updates to minimize reflows, ensure reconnection logic, and implement a cache-first strategy with network fallback. Provide core code snippets and trade-offs?","channel":"frontend","subChannel":"web-apis","difficulty":"advanced","tags":["dom","fetch","websocket","service-worker"],"companies":["Apple","PayPal"]},{"id":"q-1003","question":"Design a multi-region DR plan for a Cloud Run API that reads from Cloud SQL and writes results to Cloud Storage and BigQuery. Define RPO/RTO targets, cross-region replication strategy for Cloud SQL, data residency constraints, traffic failover through a global load balancer, and automated DR tests. Include monitoring, IAM least privilege, and post-failover reconciliation steps?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"advanced","tags":["gcp-cloud-architect"],"companies":["Netflix","Tesla","Two Sigma"]},{"id":"q-1017","question":"Design a beginner-friendly ingestion workflow on GCP for daily CSV exports delivered via partner-signed URLs into a Cloud Storage bucket. Implement a Cloud Function (Python) triggered on finalization to validate, parse, and load aggregates into BigQuery, with structured Cloud Logging including a correlation_id. Outline per-project isolation (dev/stage/prod), idempotent replay, and a simple test plan?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-architect"],"companies":["Amazon","Snap","Snowflake"]},{"id":"q-1092","question":"Design a cross-tenant, multi-region data ingestion pipeline on Google Cloud to handle telemetry from partner apps. Data arrives as daily compressed NDJSON in per-tenant Cloud Storage buckets. Build end-to-end using Cloud Storage triggers or Pub/Sub, Dataflow (Beam) for parsing/transformations, and BigQuery with per-tenant datasets. Enforce least-privilege IAM, strict per-project isolation, Private Service Connect, data residency, auditable Cloud Logging, and idempotent replay with watermarking. Include architecture, data mapping, and a practical test plan?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"intermediate","tags":["gcp-cloud-architect"],"companies":["Microsoft","Snowflake"]},{"id":"q-1195","question":"Design a beginner data-retention automation on GCP for a daily CSV export that lands in a shared Cloud Storage bucket and is ingested into a partitioned BigQuery table. Implement per-environment isolation (dev/stage/prod) by separate buckets and datasets. Create a Cloud Scheduler job that triggers a Cloud Function (Python) to apply 30-day retention on storage objects, prune BigQuery partitions, and log using Cloud Logging with a correlation_id. Outline validation tests and rollback plan?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-architect"],"companies":["Coinbase","NVIDIA"]},{"id":"q-1233","question":"Design an advanced, per-tenant data lake on Google Cloud for a SaaS platform serving 100 enterprise customers. Ingest on‑prem JSON logs via Pub/Sub to regional Cloud Storage, and use Dataflow to write per‑tenant BigQuery datasets with CMEK; ensure data locality, least‑privilege IAM, and exfiltration controls via VPC Service Controls and Private Service Connect. Outline observability, auditability, and a test plan for IAM changes and retention?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"advanced","tags":["gcp-cloud-architect"],"companies":["Anthropic","Lyft","Robinhood"]},{"id":"q-878","question":"How would you implement a beginner-friendly, auditable deployment pipeline in Google Cloud for a Cloud Run app that reads from Cloud SQL and writes logs to Cloud Logging, ensuring least-privilege IAM, per-project isolation, and no public endpoints?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-architect"],"companies":["Cloudflare","Goldman Sachs","IBM"]},{"id":"q-907","question":"Design a private, regional data pipeline for a global fintech platform: events land in regional Pub/Sub topics, Dataflow performs streaming ETL, results stored in per-region BigQuery, and audit logs go to Cloud Logging. Enforce per-region IAM, least privilege, CMEK, Private Service Connect, and no public egress. Describe data flow, security controls, disaster recovery, and cost implications. How would you implement this pipeline?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"intermediate","tags":["gcp-cloud-architect"],"companies":["Goldman Sachs","Hugging Face","Instacart"]},{"id":"q-977","question":"In a beginner setup, you deploy a Cloud Run API behind Private Service Connect, with logs going to Cloud Logging and traces to Cloud Trace. Outline a practical observability plan: which metrics, logs, and traces to collect; how to build a useful dashboard; how to configure a low-noise alert for 5xx latency; and a simple test to validate instrumentation and alerting?","channel":"gcp-cloud-architect","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-architect"],"companies":["Instacart","PayPal"]},{"id":"q-1016","question":"Design a regional streaming pipeline for a fintech app: on‑prem and GKE emit events to region Pub/Sub topics; a Dataflow streaming job enforces exactly-once, writes partitioned regional BigQuery tables, and triggers Vertex AI scoring in near real-time. How would you achieve low latency, data residency, schema evolution, and reliable failure recovery?","channel":"gcp-cloud-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-cloud-engineer"],"companies":["Adobe","PayPal","Stripe"]},{"id":"q-1055","question":"Design an audit-logging pipeline for a payments platform on GCP with sub-100ms end-to-end write latency at multi-region scale (millions of events/sec). Ingest via Pub/Sub, process with Dataflow (Beam), and sink to BigQuery. Explain how you ensure idempotent writes (insertId), handle schema evolution, and provide auditor access across projects without exposing sensitive data. Also outline retries, backoffs, and monitoring?","channel":"gcp-cloud-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-cloud-engineer"],"companies":["Amazon","Stripe"]},{"id":"q-1105","question":"You're building a beginner-friendly ingestion pipeline: external partners upload daily CSVs to a Cloud Storage bucket; design a minimal flow using a Cloud Function triggered on object finalize to parse the CSV and load a daily summary as a single row into BigQuery. Include IAM permissions, how to trigger on new files, and how to ensure idempotent writes?","channel":"gcp-cloud-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-engineer"],"companies":["Discord","Microsoft","Snap"]},{"id":"q-1269","question":"Design a real-time data pipeline on GCP for a multi-tenant SaaS where each tenant's data must reside in a specified region, is encrypted with CMEK, and access is strictly controlled per-tenant using IAM Conditions and VPC Service Controls; use Pub/Sub, Dataflow, and BigQuery, ensure idempotent writes and exactly-once semantics, and include monitoring and incident response steps?","channel":"gcp-cloud-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-cloud-engineer"],"companies":["Google","PayPal","Salesforce"]},{"id":"q-904","question":"How would you configure a Cloud Run (fully managed) service to securely connect to a Cloud SQL PostgreSQL instance using a private connection, including IAM bindings and deployment steps to ensure the app talks via the Cloud SQL socket and never uses the instance's public IP?","channel":"gcp-cloud-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-cloud-engineer"],"companies":["OpenAI","Slack","Snap"]},{"id":"q-1222","question":"Design a real-time ad-click analytics pipeline in GCP that ingests Pub/Sub events via Dataflow into BigQuery, while implementing 90-day TTL on PII data, exporting audits to Cloud Storage, and handling schema evolution, late data, dedup, and rollback. Provide concrete architecture, data models, and operational steps?","channel":"gcp-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-data-engineer"],"companies":["Cloudflare","NVIDIA","Snap"]},{"id":"q-931","question":"A GCP pipeline ingests 1 TB of JSON user activity daily from Pub/Sub into BigQuery via Dataflow. New fields appear over time; you must evolve the schema without downtime. What approach would you use for schema drift and nested fields, and outline concrete steps to implement it?","channel":"gcp-data-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-data-engineer"],"companies":["Citadel","Discord","Uber"]},{"id":"q-962","question":"In a GCP streaming pipeline, Pub/Sub feeds millions of events into BigQuery via Dataflow. Out-of-order arrivals and duplicates occur. Design an idempotent sink using a staging table and a final partitioned table, leveraging insertId for dedup and a MERGE strategy to upsert into the final table. Outline concrete steps and trade-offs to implement?","channel":"gcp-data-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-data-engineer"],"companies":["Databricks","Google","Instacart"]},{"id":"q-1013","question":"You're managing a multi-tenant SaaS on GCP across five projects connected via Shared VPC. You must enforce per-tenant network isolation, IAM conditions, and budget governance while keeping CI/CD simple. Propose an end-to-end setup using Shared VPC, IAM Conditions, VPC Service Controls, Billing Budgets, and Cloud Asset Inventory, and outline testing and rollback steps?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-devops-engineer"],"companies":["Discord","DoorDash","Snap"]},{"id":"q-1041","question":"Design a scalable, compliant log routing pipeline on GCP that collects logs from Kubernetes clusters, Cloud Run, and Cloud Functions, redacts PII, and stores in BigQuery with environment separation. Include data flow sinks, IAM and CMEK governance, failure modes and retries, and an end-to-end testing plan?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-devops-engineer"],"companies":["Databricks","Square"]},{"id":"q-1155","question":"You're deploying a globally distributed service on GKE across three regions, with Cloud Run and Cloud Functions used for specific workloads. Design a deployment pipeline that enforces policy-as-code, encryption at rest via CMEK, drift detection, automated rollback, and cross-region failover. Describe tooling, data planes, tests, and how you handle outages and compliance?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-devops-engineer"],"companies":["Adobe","NVIDIA","Zoom"]},{"id":"q-1245","question":"You operate a global chat app with components on **GKE**, **Cloud Run**, and **Cloud Functions**. Latency spikes in one region go unnoticed in aggregated metrics. Design an end-to-end observability approach: (1) how to unify traces across runtimes, (2) how to instrument with **OpenTelemetry** and **OTLP** to a central collector, (3) how to build region-scoped dashboards and **SLO-based alerts**, and (4) how to validate during release with **canary** and **chaos testing**. Include tool choices, sample metrics, and a minimal config sketch?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-devops-engineer"],"companies":["Discord","Meta","Microsoft"]},{"id":"q-1281","question":"You're maintaining a Cloud Run Python service that reads an API key from Secret Manager. Implement a 30-day secret rotation using Cloud Scheduler to publish a rotation event to Pub/Sub, and enable the Cloud Run instance to fetch updated secret without a restart. Detail the IAM permissions, wiring, and a test plan to verify end-to-end rotation?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-devops-engineer"],"companies":["Hashicorp","Plaid","Robinhood"]},{"id":"q-877","question":"Design a cross-region disaster recovery plan for a streaming data pipeline on GCP (Pub/Sub, Dataflow, BigQuery) that must survive a regional outage with RTO < 15 minutes and RPO < 5 minutes. The primary region is us-central1; second region is us-east1. Include data paths, failover triggers, data integrity guarantees, and operational testing steps?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-devops-engineer"],"companies":["Amazon","Apple","Scale Ai"]},{"id":"q-921","question":"In a multi-tenant GKE deployment across two GCP projects, you must enforce strict per-tenant network isolation and controlled egress to external services. Design a scalable architecture using Shared VPC, Private Service Connect, and per-tenant firewall policies to ensure tenants only reach whitelisted external endpoints, while preventing cross-tenant access. Include identity management, auditing, drift control, and operational notes for adding new tenants?","channel":"gcp-devops-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-devops-engineer"],"companies":["Amazon","Tesla"]},{"id":"gcp-ml-engineer-data-prep-1768249406549-2","question":"When tracking experiments and model lineage across teams, which combination provides end-to-end provenance and reproducibility?","channel":"gcp-ml-engineer","subChannel":"data-prep","difficulty":"intermediate","tags":["Vertex AI","Metadata","Data Catalog","Experiment Tracking","GKE","Terraform","certification-mcq","domain-weight-16"],"companies":null},{"id":"q-1008","question":"You're building a real-time customer-review sentiment classifier on GCP. Design a beginner-friendly end-to-end pipeline using Vertex AI for training and hosting, Vertex AI Feature Store for online features, Dataflow for ETL, and Pub/Sub for ingestion. Describe data flow, feature materialization cadence, a canary rollout strategy, and basic drift monitoring with rollback triggers. Include cost considerations?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-ml-engineer"],"companies":["Oracle","Snowflake","Two Sigma"]},{"id":"q-1199","question":"Design a multi-tenant, privacy-preserving online inference and feature materialization pipeline on GCP for a cross-region ride-hailing platform. Each tenant has its own feature schema and data residency needs. Outline how you would manage per-tenant Feature Store namespaces, Canary deployments across tenants, live vs. batch feature materialization, drift/bias monitoring, provenance, and automated rollback with Vertex AI Endpoints, Dataflow, and Pub/Sub. Include concrete rollback criteria and cost considerations?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-ml-engineer"],"companies":["Amazon","Lyft"]},{"id":"q-1225","question":"Design a beginner-friendly end-to-end GCP pipeline for a price-optimization model. Use Vertex AI for training and hosting, Vertex AI Feature Store for online/offline features, Dataflow for ETL into BigQuery, and Pub/Sub for ingestion. Describe data flow, feature derivation cadence, training trigger cadence, online/offline feature consistency, and a simple rollback strategy if offline metrics degrade. Include a basic cost plan?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-ml-engineer"],"companies":["Cloudflare","PayPal"]},{"id":"q-882","question":"You run a real-time fraud-detection model on GCP at ~25k QPS with sub-20 ms P95 latency. Design a production pipeline using Vertex AI, Feature Store, Pub/Sub, and Dataflow that ingests events, materializes features, serves online predictions, and supports canary rollouts. Include data/model drift monitoring, automated rollback, and cost considerations?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-ml-engineer"],"companies":["Goldman Sachs","Snap"]},{"id":"q-905","question":"You operate a multi-tenant content recommender service on GCP used by advertisers. Each tenant has its own feature schema and data retention. Design a production ML pipeline (training and online serving) using Vertex AI, Feature Store, Pub/Sub, and Dataflow that supports **per-tenant namespaces**, **policy-based access**, **drift monitoring**, **automated rollback**, and **cost isolation**. Include data leakage prevention, schema evolution, and canary rollouts across regions?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-ml-engineer"],"companies":["Scale Ai","Tesla","Twitter"]},{"id":"q-922","question":"Design a real-time content moderation inference path on GCP that adds a Redis-based in‑memory cache in front of a Vertex AI online endpoint to reduce latency and cost. Outline what you cache (embeddings vs predictions), key schema (e.g., user_id, model_version, language), TTL and eviction policy, and how you invalidate cache on model deploy or feature updates. Include data privacy considerations and a plan for monitoring latency, cache hit rate, and drift. Provide a small Python sketch of the cache lookup?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"beginner","tags":["gcp-ml-engineer"],"companies":["Airbnb","Discord","Snap"]},{"id":"q-955","question":"Design a multi-tenant ML service on GCP that serves diverse customers with strict data isolation and retention policies. Propose a deployment and feature governance pattern using Vertex AI, Feature Store, Private Service Connect, Data Catalog, and Pub/Sub to isolate customer data, manage per-tenant feature lifecycles, perform drift monitoring, and enable tenant-specific canary rollouts with automated rollback and cost controls. Include concrete components, data flow, and rollback criteria?","channel":"gcp-ml-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-ml-engineer"],"companies":["Amazon","Meta"]},{"id":"q-1176","question":"In a multi-tenant GCP security environment, design an ephemeral admin-session workflow for Kubernetes and Cloud Run resources using IAP, Workload Identity Federation, and Binary Authorization. Include policy design, auditability, rollback, and how you'd verify there are no lingering grants after revocation?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-security-engineer"],"companies":["Discord","LinkedIn","Microsoft"]},{"id":"q-1194","question":"In a GCP multi-tenant fintech data lake, design end-to-end safeguards to prevent tenant data leakage when multiple tenants share datasets in BigQuery and Cloud Storage. Propose a guardrail that blocks cross-tenant access at the data-product level using IAM Conditions, per-data-product VPC Service Controls, and Private Service Connect to a shared analytics endpoint. Include testing with synthetic misconfigurations and a rollback/audit plan?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"advanced","tags":["gcp-security-engineer"],"companies":["Bloomberg","Plaid","Tesla"]},{"id":"q-863","question":"In a GCP data pipeline that streams PII from Pub/Sub through Dataflow to BigQuery and Cloud Storage, outline a concrete hardening plan: exact IAM bindings with least privilege, VPC Service Controls, private access to API endpoints, encryption key management, access reviews, and monitoring/alerting. Include how you’d validate controls in production?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-security-engineer"],"companies":["Adobe","Amazon","Meta"]},{"id":"q-899","question":"In a GCP data pipeline streaming PII from Pub/Sub through Dataflow to BigQuery and Cloud Storage, enable secure cross‑org sharing with an external analytics partner via Private Service Connect. Draft a concrete architecture: least‑privilege IAM bindings per data product, cross‑project scopes, PSC endpoints in a shared VPC, CMEK, DLP masking, and automated validation with synthetic data and revocation tests. End with auditable controls and rollback plan?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-security-engineer"],"companies":["Slack","Zoom"]},{"id":"q-911","question":"In a GCP data pipeline that streams PII from Pub/Sub through Dataflow to BigQuery and Cloud Storage across two orgs, enable time-bounded access for an external analytics partner without static credentials. Draft a concrete design using Workload Identity Federation, IAM conditions, ephemeral credentials, Private Service Connect, and VPC Service Controls. Include trust, token lifetimes, auditing, automated revocation tests, and rollback?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-security-engineer"],"companies":["Cloudflare","LinkedIn","PayPal"]},{"id":"q-945","question":"In a **Terraform-driven GCP** multi-tenant environment used by **Salesforce** and **Discord**, implement automated guardrails that block any public bucket or dataset and enforce least-privilege IAM at module boundaries. Describe how you’d implement **OPA constraints**, integrate with **CI/CD**, test with synthetic misconfigs, and provide rollback/auditability?","channel":"gcp-security-engineer","subChannel":"general","difficulty":"intermediate","tags":["gcp-security-engineer"],"companies":["Discord","Salesforce"]},{"id":"q-430","question":"How would you implement a basic AI agent using LangChain that can use tools to answer user questions about weather data?","channel":"generative-ai","subChannel":"agents","difficulty":"beginner","tags":["langchain","autogen","tool-use","planning"],"companies":["Amazon","Anthropic","Apple","Google","Microsoft","OpenAI","Snowflake"]},{"id":"q-445","question":"You're building a multi-agent system using LangChain and AutoGen for autonomous code generation. How would you design a robust tool-use framework that prevents malicious code execution while maintaining agent autonomy?","channel":"generative-ai","subChannel":"agents","difficulty":"advanced","tags":["langchain","autogen","tool-use","planning"],"companies":["Databricks","Google","Tesla"]},{"id":"q-322","question":"How would you measure and reduce hallucination in a large language model deployed for customer service?","channel":"generative-ai","subChannel":"evaluation","difficulty":"beginner","tags":["hallucination","faithfulness","relevance"],"companies":["Amazon","Google","IBM","Mckinsey","Meta","Microsoft","Salesforce"]},{"id":"q-385","question":"You're building a hallucination detection system for a production LLM service. Design a multi-layered evaluation pipeline that balances false positives/negatives while maintaining sub-100ms latency. How would you implement confidence scoring and fallback mechanisms?","channel":"generative-ai","subChannel":"evaluation","difficulty":"advanced","tags":["hallucination","faithfulness","relevance"],"companies":["Anthropic","Google","Stripe"]},{"id":"q-402","question":"How would you design a hallucination detection system for a medical AI assistant that evaluates faithfulness against verified drug databases while maintaining 99.9% accuracy?","channel":"generative-ai","subChannel":"evaluation","difficulty":"advanced","tags":["hallucination","faithfulness","relevance"],"companies":["Microsoft","Netflix","Veeva"]},{"id":"q-463","question":"How would you evaluate if an LLM's response is faithful to the provided source documents?","channel":"generative-ai","subChannel":"evaluation","difficulty":"beginner","tags":["hallucination","faithfulness","relevance"],"companies":["Cloudflare","Microsoft","PayPal"]},{"id":"q-494","question":"How would you design a comprehensive evaluation framework to detect hallucinations in a large language model deployed for customer support, considering both factual accuracy and faithfulness to provided context?","channel":"generative-ai","subChannel":"evaluation","difficulty":"advanced","tags":["hallucination","faithfulness","relevance"],"companies":["Discord","Meta","Plaid"]},{"id":"q-524","question":"How would you evaluate a generative AI model's tendency to hallucinate when answering factual questions about company policies?","channel":"generative-ai","subChannel":"evaluation","difficulty":"beginner","tags":["hallucination","faithfulness","relevance"],"companies":["Microsoft","Uber"]},{"id":"q-225","question":"When implementing LoRA fine-tuning for a 7B parameter LLM, how do you determine the optimal rank (r) and alpha values to balance performance and memory efficiency while maintaining model quality?","channel":"generative-ai","subChannel":"fine-tuning","difficulty":"intermediate","tags":["lora","qlora","peft","adapter"],"companies":["Amazon","Databricks","Google","Meta","Microsoft","NVIDIA"]},{"id":"q-250","question":"What is LoRA and how does it reduce parameters when fine-tuning large language models?","channel":"generative-ai","subChannel":"fine-tuning","difficulty":"beginner","tags":["lora","qlora","peft","adapter"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-197","question":"How would you implement efficient KV caching in a transformer decoder to reduce redundant computation during autoregressive generation?","channel":"generative-ai","subChannel":"llm-fundamentals","difficulty":"intermediate","tags":["transformer","attention","tokenization"],"companies":["Amazon","Google","Meta","Microsoft","OpenAI"]},{"id":"q-308","question":"How does the self-attention mechanism in transformers compute token relationships?","channel":"generative-ai","subChannel":"llm-fundamentals","difficulty":"intermediate","tags":["transformer","attention","tokenization"],"companies":["Amazon","Google","Meta"]},{"id":"q-371","question":"You're designing a custom tokenizer for a multilingual LLM that needs to handle code-switching between English and Chinese. How would you optimize the vocabulary to minimize token count while preserving semantic meaning, and what attention mechanism modifications would you consider?","channel":"generative-ai","subChannel":"llm-fundamentals","difficulty":"advanced","tags":["transformer","attention","tokenization"],"companies":["Meta","Microsoft","NVIDIA"]},{"id":"q-414","question":"Explain how the self-attention mechanism in a transformer works and why it's more effective than RNNs for processing long sequences?","channel":"generative-ai","subChannel":"llm-fundamentals","difficulty":"beginner","tags":["transformer","attention","tokenization"],"companies":["Amazon","Anduril","Google","Meta","Microsoft","NVIDIA","OpenAI","Tesla"]},{"id":"q-577","question":"How would you debug a transformer model where attention weights are becoming uniform across all tokens, leading to poor performance?","channel":"generative-ai","subChannel":"llm-fundamentals","difficulty":"intermediate","tags":["transformer","attention","tokenization"],"companies":["IBM","PayPal"]},{"id":"q-293","question":"How do you optimize chunking strategies for different document types in RAG systems?","channel":"generative-ai","subChannel":"rag","difficulty":"advanced","tags":["retrieval","embeddings","vector-db","chunking"],"companies":["Amazon","Google","Meta"]},{"id":"q-335","question":"You're building a RAG system for SAP's customer support. How would you chunk a 10-page technical manual to ensure relevant sections are retrieved?","channel":"generative-ai","subChannel":"rag","difficulty":"beginner","tags":["retrieval","embeddings","vector-db","chunking"],"companies":["Amazon","Google","IBM","Microsoft","MongoDB","Planetscale","Sap"]},{"id":"q-438","question":"You're building a RAG system for DoorDash's restaurant search. How would you design a hybrid retrieval strategy combining semantic and keyword search to handle queries like 'cheap Italian delivery near me' while maintaining sub-100ms latency?","channel":"generative-ai","subChannel":"rag","difficulty":"advanced","tags":["retrieval","embeddings","vector-db","chunking"],"companies":["Amazon","Apple","DoorDash","Google","Lyft","Meta","Microsoft","Netflix"]},{"id":"q-551","question":"You're building a RAG system for Discord's message search. Messages have varying lengths, code blocks, and threaded conversations. How would you design your chunking strategy and what embedding model would you choose?","channel":"generative-ai","subChannel":"rag","difficulty":"advanced","tags":["retrieval","embeddings","vector-db","chunking"],"companies":["Discord","Snowflake"]},{"id":"q-1145","question":"Design an online nonlinear ICA pipeline for a 12-mic, 6-camera live broadcast where mixing is nonlinear and time-varying due to the environment. Propose an invertible neural network demixing model, online training with forgetting, a temporal prior to capture dynamics, and strategies for permutation/scale alignment. Include evaluation plan and DSP constraints?","channel":"ica","subChannel":"general","difficulty":"advanced","tags":["ica"],"companies":["Adobe","Citadel","Coinbase"]},{"id":"q-1208","question":"Design a privacy-preserving, edge-based ICA pipeline to separate overlapping speech captured by a distributed 32‑mic array where raw audio never leaves devices and only anonymized components are aggregated. Describe per‑device whitening with partial channels, online demixing updates, secure aggregation methods, permutation/scale alignment across devices, latency targets, drift handling, and an evaluation plan with synthetic ground truth and transcripts?","channel":"ica","subChannel":"general","difficulty":"advanced","tags":["ica"],"companies":["Discord","Goldman Sachs","Instacart"]},{"id":"q-1231","question":"In a smart conference room, 6 microphones capture audio while 2 cameras provide synchronized lip-movement visuals. Propose an ICA-based pipeline to jointly separate independent audio sources and align them to speaker identities using visual cues as auxiliary information. Include (i) whitening and joint diagonalization strategy, (ii) how to integrate visual cues into the contrast to improve permutation recovery, (iii) online adaptation for moving speakers, and (iv) a concrete evaluation plan with ground-truth sources and lip-sync metrics?","channel":"ica","subChannel":"general","difficulty":"intermediate","tags":["ica"],"companies":["LinkedIn","Meta"]},{"id":"q-839","question":"**Advanced ICA Challenge**: Given a 3×N mixed signal matrix from sensors, outline a concrete plan to recover independent sources with FastICA. Include whitening steps, nonlinearity choice (e.g., g(u)=tanh(u)), convergence criteria, how you resolve sign/perm ambiguity, and how you compare to PCA on the same data. Include practical inputs and diagnostics?","channel":"ica","subChannel":"general","difficulty":"advanced","tags":["ica"],"companies":["IBM","Two Sigma","Uber"]},{"id":"q-875","question":"Given a 6-channel wearable time-series with non-stationary motion artifacts and slowly varying latent sources, design an online ICA workflow to separate the sources in real time. Specify streaming whitening, adaptive contrast functions, choice of nonlinearity, handling sign and permutation drift, and a robust validation plan against synthetic ground truth and a PCA baseline?","channel":"ica","subChannel":"general","difficulty":"intermediate","tags":["ica"],"companies":["Citadel","Salesforce"]},{"id":"q-910","question":"An 8-microphone array records a live conference with moving speakers and reverberation. Design a practical convolutive ICA pipeline to separate sources. Include: STFT-based mixing, choice between per-bin ICA vs joint diagonalization, permutation alignment across frequency bins, tracking non-stationary mixing, real-time feasibility, and evaluation plan (SDR/SIR, ground truth)?","channel":"ica","subChannel":"general","difficulty":"intermediate","tags":["ica"],"companies":["LinkedIn","OpenAI","Robinhood"]},{"id":"q-953","question":"Design a real-time, online complex-valued ICA pipeline to separate RF sources from an 8-antenna receiver in a dynamic multipath environment with drifting mixing. Describe (a) complex whitening + fixed-point ICA update, (b) the complex contrast and convergence rule, (c) tracking sign and permutation drift over time, and (d) a practical evaluation plan with synthetic ground truth and over-the-air tests under DSP constraints?","channel":"ica","subChannel":"general","difficulty":"intermediate","tags":["ica"],"companies":["IBM","Microsoft","NVIDIA"]},{"id":"q-1064","question":"Design and implement a streaming app's episode grid using a UICollectionView with a compositional layout that supports dynamic item sizes, infinite scrolling, and efficient image caching; use a modern iOS approach (Diffable Data Source, NSCache, prefetching), ensure accessibility and testability?","channel":"ios","subChannel":"general","difficulty":"intermediate","tags":["ios"],"companies":["Apple","Netflix","Tesla"]},{"id":"q-1164","question":"You're building a lightweight notes app for iOS. Implement a NotesEditor view (SwiftUI) that autosaves to disk as the user types, using a 500ms debounce. Persist to a local JSON file in the app's documents directory. Ensure rapid typing doesn't cause multiple disk writes, and provide a minimal unit test that verifies the file content is updated after a debounce period?","channel":"ios","subChannel":"general","difficulty":"beginner","tags":["ios"],"companies":["Discord","Google","Tesla"]},{"id":"q-1185","question":"In an iOS app, you are displaying a feed of user avatars in a UICollectionView with infinite scrolling. Explain how you would implement incremental image loading that cancels obsolete requests, caches images both in memory and on disk, uses Swift concurrency for loading, and ensures smooth scrolling under memory pressure, including prefetching and memory-pressure handling strategies?","channel":"ios","subChannel":"general","difficulty":"intermediate","tags":["ios"],"companies":["Airbnb","Bloomberg","Goldman Sachs"]},{"id":"q-464","question":"How would you implement a custom UICollectionViewFlowLayout that supports dynamic cell heights and sticky headers while maintaining smooth scrolling performance?","channel":"ios","subChannel":"general","difficulty":"intermediate","tags":["ios"],"companies":["Amazon","Lyft","Meta"]},{"id":"q-495","question":"How would you implement a simple UITableView with custom cells in iOS using Swift?","channel":"ios","subChannel":"general","difficulty":"beginner","tags":["ios"],"companies":["Oracle","Snowflake","Uber"]},{"id":"q-525","question":"You're building a food delivery app like DoorDash. How would you implement background location updates to track delivery drivers while balancing battery life and accuracy?","channel":"ios","subChannel":"general","difficulty":"intermediate","tags":["ios"],"companies":["DoorDash","Microsoft","Zoom"]},{"id":"q-578","question":"What's the difference between weak and unowned references in Swift, and when would you use each?","channel":"ios","subChannel":"general","difficulty":"beginner","tags":["ios"],"companies":["Meta","NVIDIA"]},{"id":"q-181","question":"Explain the difference between weak and unowned references in Swift and provide practical use cases for each?","channel":"ios","subChannel":"swift","difficulty":"intermediate","tags":["swift","language"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-257","question":"What is optional chaining in Swift and how does it compare to force unwrapping, optional binding, and optional chaining with method calls when accessing nested optional properties?","channel":"ios","subChannel":"swift","difficulty":"beginner","tags":["optionals","protocols","generics"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Stripe"]},{"id":"q-204","question":"How would you optimize a UITableView with 10,000+ complex cells using Auto Layout while maintaining 60fps scrolling and memory efficiency?","channel":"ios","subChannel":"uikit","difficulty":"advanced","tags":["autolayout","tableview","collectionview"],"companies":["Airbnb","Apple","Capital One","Lyft","Uber"]},{"id":"q-232","question":"How does Auto Layout constraint resolution work when creating a UITableView with dynamic cell heights?","channel":"ios","subChannel":"uikit","difficulty":"beginner","tags":["autolayout","tableview","collectionview"],"companies":["Airbnb","Apple","Google","Meta","Uber"]},{"id":"q-1075","question":"You're building a beginner-friendly KCA flow for a data science platform where notebooks run in isolated containers across tenants. The platform uses a cloud CA to issue short-lived client certificates (2 hours) via token-based enrollment (JWT) rather than CSR, with a gateway that validates certs and maps tenants. Describe the enrollment flow, renewal, and how the gateway handles clock skew, expired certs, and failed enrollments. Include a minimal test plan and example API calls?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Databricks","Hugging Face"]},{"id":"q-1082","question":"Design a beginner-friendly KCA workflow focusing on policy-driven certificate issuance for a multi-tenant SaaS gateway: tenants publish per-tenant certificate policies (allowed CNs, key type, validity). A central CA issues short-lived client certs, and edge gateways refresh policy every 60 minutes while rotating certs to avoid handshake failures. Explain enrollment, policy propagation, revocation, and provide a minimal test plan?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Adobe","Cloudflare","DoorDash"]},{"id":"q-1120","question":"Explain how you would implement a beginner-friendly KCA workflow for a multi-region SaaS where regional CAs issue per-service client certs with a 2-hour TTL. Include enrollment (CSR-based vs token-based), cross-region policy propagation, revocation, and how to validate certificates at the edge during region failover. Provide a minimal test plan and rollback strategy?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Apple","Databricks","Instacart"]},{"id":"q-1141","question":"For an industrial IoT fleet of 50k field devices with intermittent connectivity, design a KCA workflow where each device boots with a hardware-backed key and obtains a short-lived client certificate from a central CA via an attestation-enabled bootstrap. Include enrollment, attestation checks, certificate lifetimes (6 hours), automatic renewal after reconnection, revocation for decommissioned devices via OCSP/CRLs, offline root fallback, auditing, and a minimal test plan?","channel":"kca","subChannel":"general","difficulty":"intermediate","tags":["kca"],"companies":["Meta","NVIDIA"]},{"id":"q-1189","question":"Design a beginner-friendly KCA flow for a multi-tenant SaaS gateway that issues per-tenant, short-lived client certificates via token-based enrollment, but enforces per-tenant issuance quotas (e.g., 100 certs/hour with burst to 10x). Explain enrollment, quota enforcement, renewal, revocation, and audit logging, and provide a minimal test plan. Include how you handle quota exhaustion during spikes?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Meta","Slack","Uber"]},{"id":"q-844","question":"You have a CSV log with columns: user_id, event_timestamp (ISO 8601), and event_type. Write a Python function using pandas to compute the number of unique active users per day for a given timezone, returning a dict mapping 'YYYY-MM-DD' to count. Explain how you handle timezone normalization and missing data. Provide sample usage?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Coinbase","Databricks"]},{"id":"q-884","question":"You're operating a Kafka-to-Spark streaming job in production and observe sporadic latency spikes; detail a concrete diagnostic plan to identify bottlenecks and a remediation strategy, including metrics, tooling (OpenTelemetry, Prometheus, Grafana), and validation steps?","channel":"kca","subChannel":"general","difficulty":"intermediate","tags":["kca"],"companies":["Anthropic","DoorDash","Google"]},{"id":"q-889","question":"**How would you design a scalable KCA integration** for a multi-tenant SaaS using short-lived client certificates? Central CA in an HSM issues per-tenant CSRs, rotates certificates every 24h, and supports revocation via OCSP stapling and short CRLs with edge caching. Include audit trails, MFA for CA access, and clear renewal, compromise, and revocation workflows?","channel":"kca","subChannel":"general","difficulty":"advanced","tags":["kca"],"companies":["Cloudflare","Microsoft","Plaid"]},{"id":"q-952","question":"How would you design an on-demand KCA for service-to-service mTLS in a multi-tenant data platform (Stripe/Databricks) where a Kubernetes-hosted CA issues per-service CSRs, each cert valid for 5–15 minutes, supports cross-region trust, anomaly-driven revocation via telemetry, and full audit trails; include MFA protection and an offline root fallback?","channel":"kca","subChannel":"general","difficulty":"intermediate","tags":["kca"],"companies":["Databricks","Stripe"]},{"id":"q-997","question":"Design a beginner-friendly KCA flow for a SaaS API gateway where a cloud CA issues per-tenant, short-lived client certificates (4 hours) for app authentication. Outline provisioning (CSR-based enrollment or token-based enrollment), automatic renewal, revocation strategy, and how the gateway validates certs and records audit logs. Include failure modes and a minimal test plan?","channel":"kca","subChannel":"general","difficulty":"beginner","tags":["kca"],"companies":["Bloomberg","Netflix","OpenAI"]},{"id":"q-1138","question":"You are building a real-time KCNA feed service used by Snap, Meta, and Discord-scale clients to publish and deliver announcements across regions with sub-100ms tail latency. Describe the end-to-end architecture, data model for Announcement, ingestion and delivery pipeline, guarantees (at-least-once vs exactly-once), ordering, deduplication, failover, tests, and observability. How would you scale to 10k updates/sec with 99.999% uptime?","channel":"kcna","subChannel":"general","difficulty":"advanced","tags":["kcna"],"companies":["Discord","Meta","Snap"]},{"id":"q-1295","question":"**KCNA Consumer Backpressure & Gap Handling**: In a beginner-friendly KCNA consumer, design a pull-based ingestion path that preserves per-topic offsets, guarantees at-least-once processing, and recovers from transient network slowdowns without duplicating messages. Describe the API shape, offset persistence, retry/backoff strategy, and a minimal test plan including a canary scenario?","channel":"kcna","subChannel":"general","difficulty":"beginner","tags":["kcna"],"companies":["Discord","Plaid","Two Sigma"]},{"id":"q-941","question":"Scenario: A global chat platform with 2B MAUs must detect policy-violating content (spam, hate speech) in near real-time while preserving user privacy and multilingual support. Propose an end-to-end pipeline: ingestion, moderation models (rules + ML), latency SLOs (1-2s), privacy safeguards, backpressure handling, retries, and dead-letter queues. Compare on-device vs cloud inference and monitoring?","channel":"kcna","subChannel":"general","difficulty":"advanced","tags":["kcna"],"companies":["Slack","Twitter"]},{"id":"q-1021","question":"Design a globally distributed feature-flag engine for per-user rollout. Provide data model, consistency guarantees, and deployment strategy for scale across multiple regions. Include choice of storage (DynamoDB vs Redis), how regionOverrides and segments are merged, and hot-flip safety. Provide evaluation protocol and a concise pseudocode snippet for evaluateFeature(user, flag, context)?","channel":"kcsa","subChannel":"general","difficulty":"advanced","tags":["kcsa"],"companies":["Coinbase","Meta","Tesla"]},{"id":"q-1042","question":"Design a high-throughput, fault-tolerant event ingestion pipeline for a fraud-detection service. It must guarantee exactly-once processing, deduplicate events across shards, support backpressure, and provide end-to-end observability. Explain the data model for dedup IDs, queue choice (Kafka vs Kinesis), idempotent sinks, and how you'd test failure scenarios?","channel":"kcsa","subChannel":"general","difficulty":"advanced","tags":["kcsa"],"companies":["Meta","Plaid","Twitter"]},{"id":"q-1067","question":"In a Zoom-like multi-tenant Kubernetes cluster, you discover a pod running as root with a hostPath mounted. What concrete remediation plan would you implement using OPA Gatekeeper, Pod Security Standards, RBAC, NetworkPolicies, and image scanning? Include how you would verify tenant isolation with a minimal test that should fail if misconfigured?","channel":"kcsa","subChannel":"general","difficulty":"intermediate","tags":["kcsa"],"companies":["Scale Ai","Zoom"]},{"id":"q-1096","question":"In a simple analytics microservice, implement a Python function that reads a CSV file with headers user_id, action, timestamp (timestamp optional) and returns a dict mapping each user_id to the list of unique actions performed in chronological order; if timestamp is missing, preserve input order. Explain your approach and trade-offs?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["OpenAI","Oracle","Twitter"]},{"id":"q-1129","question":"Given a Kubernetes-deployed event-processing service that suddenly drops throughput from 10k to 6k after a feature release, outline a concrete, testable plan to diagnose and restore throughput. Include: **metrics** to monitor, **bottlenecks** to consider, and concrete, incremental changes like **rate limiting**, **backpressure**, and **idempotency**. Provide a safe rollback strategy and canary plan?","channel":"kcsa","subChannel":"general","difficulty":"intermediate","tags":["kcsa"],"companies":["Google","Scale Ai","Twitter"]},{"id":"q-1184","question":"You maintain a public API for ride estimates and expect bursts. Implement a per-API-key rate limiter that allows 60 requests per minute using an in-memory structure. Provide the core logic in JavaScript (Node.js) and briefly justify your data structure, test approach, and how you’d handle restart scenarios?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["Discord","Lyft","Slack"]},{"id":"q-1227","question":"In a tiny model-usage service, write a Python function that validates a JSON payload with user_id, model_id, action, and timestamp, then inserts a document into MongoDB with a created_at field. Ensure an index exists on (model_id, timestamp) and handle duplicate submissions gracefully (idempotent using a unique composite index on (user_id, model_id, timestamp)). Include basic error handling and a minimal test snippet?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["Apple","Hugging Face","MongoDB"]},{"id":"q-1246","question":"Design a policy for a shared Kubernetes cluster serving multiple teams, ensuring namespace isolation, least privilege RBAC, image provenance, Pod Security Standards, and auditable policies. Propose concrete constraints using RBAC, PSP/PSA, NetworkPolicy, and OPA Gatekeeper; include a sample ConstraintTemplate and a test that rejects nonconforming pods. Explain trade-offs and monitoring strategy?","channel":"kcsa","subChannel":"general","difficulty":"advanced","tags":["kcsa"],"companies":["Cloudflare","Google"]},{"id":"q-1298","question":"Design a globally-distributed rate limiter for a high-traffic service with per-tenant limits and cross-region fairness. Compare token-bucket and sliding-window approaches, specify data structures and caching, describe hot-path optimization, failure modes, and testing strategy. Assume latency budgets and real-time enforcement?","channel":"kcsa","subChannel":"general","difficulty":"advanced","tags":["kcsa"],"companies":["Amazon","LinkedIn","Meta"]},{"id":"q-836","question":"You are analyzing a web app's login events, captured as an array of objects: { userId: string, ts: string (ISO 8601) }. Write a JavaScript function that returns the top 3 users by login count in the past 24 hours. Tie-break with alphabetical userId. Provide a concise implementation and explain its time complexity?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["Meta","NVIDIA"]},{"id":"q-869","question":"In a high-traffic search suggestions feature, implement a Node.js module that debounces input by 300ms and caches per-query results in memory. Show cache invalidation and handle concurrent requests for the same key without duplicating work. Provide a compact, testable example with usage?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["Apple","Lyft","Zoom"]},{"id":"q-912","question":"**KCSA Beginner Question: Inventory Pagination** Scenario: In a warehouse app, design a minimal endpoint GET /items?limit=&offset= that returns items ordered by id, supports pagination, and scales with 10k+ rows. Explain data model, indexing, and error handling. How would you implement a function to validate and apply LIMIT/OFFSET in code, ensuring correctness?","channel":"kcsa","subChannel":"general","difficulty":"beginner","tags":["kcsa"],"companies":["Amazon","Apple"]},{"id":"q-947","question":"You're building a fintech API used by wallets and partner services to transfer funds; describe a secure, scalable auth and data-protection design for REST endpoints, including per-partner API keys, short-lived access tokens with rotating signing keys, mTLS between services, replay protection, and observability to detect abuse, plus failure modes and trade-offs?","channel":"kcsa","subChannel":"general","difficulty":"intermediate","tags":["kcsa"],"companies":["Coinbase","PayPal","Plaid"]},{"id":"gh-56","question":"What are the key deployment strategies in Kubernetes, and how do you configure them considering resource limits, health checks, and rollback scenarios?","channel":"kubernetes","subChannel":"deployments","difficulty":"intermediate","tags":["automation","tools"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix","Salesforce"]},{"id":"gh-7","question":"What is Kubernetes and how does it orchestrate containerized applications at scale?","channel":"kubernetes","subChannel":"deployments","difficulty":"beginner","tags":["k8s","orchestration"],"companies":["Airbnb","Amazon","Google","Microsoft","Uber"]},{"id":"gh-8","question":"Design a highly available Kubernetes cluster architecture. What are the main components, their interactions, and how do you ensure 99.95% uptime across multiple availability zones?","channel":"kubernetes","subChannel":"deployments","difficulty":"intermediate","tags":["k8s","orchestration"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-306","question":"How would you implement a canary deployment strategy in Kubernetes to minimize risk during application updates?","channel":"kubernetes","subChannel":"deployments","difficulty":"advanced","tags":["rolling-update","canary","blue-green"],"companies":["Amazon","Google","Meta"]},{"id":"q-334","question":"You're deploying a new version of a microservice in Kubernetes. Describe how you would perform a rolling update and what would you do if the new version starts failing health checks?","channel":"kubernetes","subChannel":"deployments","difficulty":"beginner","tags":["rolling-update","canary","blue-green"],"companies":["Amazon","Cisco","Google","Microsoft","Netflix","New Relic","Stripe"]},{"id":"q-369","question":"You're deploying a critical video processing service at Zoom. During a rolling update, 30% of users experience degraded performance while the new version is being deployed. How would you diagnose and resolve this issue, and what deployment strategy would you recommend instead?","channel":"kubernetes","subChannel":"deployments","difficulty":"intermediate","tags":["rolling-update","canary","blue-green"],"companies":["MongoDB","New Relic","Zoom"]},{"id":"q-465","question":"You're running a production Kubernetes cluster and notice pods are frequently getting OOMKilled despite having sufficient memory limits. How would you diagnose and resolve this issue?","channel":"kubernetes","subChannel":"general","difficulty":"intermediate","tags":["kubernetes"],"companies":["Adobe","Meta","Square"]},{"id":"q-526","question":"You're running a production Kubernetes cluster with 1000+ pods. Your monitoring shows that certain nodes are experiencing high memory pressure, causing pod evictions. How would you diagnose and resolve this issue systematically?","channel":"kubernetes","subChannel":"general","difficulty":"advanced","tags":["kubernetes"],"companies":["Bloomberg","Snap","Two Sigma"]},{"id":"q-552","question":"You're running a production Kubernetes cluster at scale and notice that some pods are experiencing intermittent network timeouts. How would you diagnose and resolve this issue, considering both application-level and cluster-level networking components?","channel":"kubernetes","subChannel":"general","difficulty":"advanced","tags":["kubernetes"],"companies":["Citadel","NVIDIA","Tesla"]},{"id":"q-579","question":"How would you debug a pod that's stuck in CrashLoopBackOff state in a production Kubernetes cluster?","channel":"kubernetes","subChannel":"general","difficulty":"intermediate","tags":["kubernetes"],"companies":["Cloudflare","Tesla"]},{"id":"de-135","question":"You have a Helm chart that needs to deploy different configurations for staging and production environments. The staging environment should use 2 replicas with 512Mi memory limit, while production should use 5 replicas with 2Gi memory limit. How would you structure your values files and templates to handle this requirement?","channel":"kubernetes","subChannel":"helm","difficulty":"intermediate","tags":["helm","k8s"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-49","question":"How does Helm manage Kubernetes application lifecycle through charts, releases, and templates?","channel":"kubernetes","subChannel":"helm","difficulty":"advanced","tags":["k8s","advanced"],"companies":["Amazon","Apple","Google","Hashicorp","Microsoft","Netflix"]},{"id":"q-400","question":"You're deploying a microservice using Helm and notice that the pod keeps crashing with 'ImagePullBackOff' error. The values.yaml specifies 'image.repository: my-service' and 'image.tag: latest'. How would you debug this issue and what's the proper way to configure image pull policies in production?","channel":"kubernetes","subChannel":"helm","difficulty":"intermediate","tags":["charts","values","templating"],"companies":["Adobe","Amazon","Google","Hashicorp","Jane Street","Microsoft","Netflix","Snowflake"]},{"id":"gh-55","question":"How does Tekton provide a cloud-native framework for building CI/CD pipelines on Kubernetes?","channel":"kubernetes","subChannel":"operators","difficulty":"beginner","tags":["automation","tools"],"companies":["Digitalocean","Google","IBM","Microsoft","Red Hat"]},{"id":"q-193","question":"What is the role of a Custom Resource Definition (CRD) in a Kubernetes Operator and how does it enable custom functionality?","channel":"kubernetes","subChannel":"operators","difficulty":"beginner","tags":["crds","controllers","reconciliation"],"companies":["Amazon","Datadog","Google","Microsoft","Prove"]},{"id":"q-291","question":"What is the role of a reconciliation loop in a Kubernetes operator controller?","channel":"kubernetes","subChannel":"operators","difficulty":"beginner","tags":["crds","controllers","reconciliation"],"companies":["Amazon","Google","Meta"]},{"id":"q-346","question":"You're building a Kubernetes operator for a custom resource that manages a fleet of microservices. Your controller is experiencing high memory usage and slow reconciliation loops. How would you design a solution to handle 10,000+ custom resources efficiently while ensuring proper event handling and preventing resource leaks?","channel":"kubernetes","subChannel":"operators","difficulty":"advanced","tags":["crds","controllers","reconciliation"],"companies":["Amazon","Cloudflare","Gitlab","Google","Hashicorp","Microsoft","MongoDB","Workday"]},{"id":"q-383","question":"You're building a Kubernetes operator for a custom database CRD. During reconciliation, you notice the controller is constantly updating the status even when no actual changes occur. How would you implement proper change detection and prevent unnecessary updates?","channel":"kubernetes","subChannel":"operators","difficulty":"intermediate","tags":["crds","controllers","reconciliation"],"companies":["AMD","Google","OpenAI"]},{"id":"gh-100","question":"What is a Sidecar Pattern in Kubernetes?","channel":"kubernetes","subChannel":"pods","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-48","question":"Explain how DaemonSets ensure pod distribution across Kubernetes nodes and describe the controller reconciliation loop that maintains this guarantee?","channel":"kubernetes","subChannel":"pods","difficulty":"advanced","tags":["k8s","advanced"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix","Snowflake"]},{"id":"gh-51","question":"What is Container Runtime Interface (CRI) and why is it important in Kubernetes?","channel":"kubernetes","subChannel":"pods","difficulty":"advanced","tags":["k8s","advanced"],"companies":["Amazon","Google","Microsoft"]},{"id":"gh-9","question":"What is a Pod in Kubernetes and why is it considered the smallest deployable unit?","channel":"kubernetes","subChannel":"pods","difficulty":"beginner","tags":["k8s","orchestration"],"companies":["Amazon","Google","LinkedIn","Microsoft","Uber"]},{"id":"q-173","question":"What is a Kubernetes Pod and what is its primary purpose?","channel":"kubernetes","subChannel":"pods","difficulty":"beginner","tags":["pods","containers"],"companies":null},{"id":"q-245","question":"How do init containers differ from sidecar containers in Kubernetes pod lifecycle and resource sharing patterns?","channel":"kubernetes","subChannel":"pods","difficulty":"beginner","tags":["containers","init-containers","sidecars"],"companies":["Amazon","Databricks","Google","Microsoft","Netflix","Stripe"]},{"id":"q-271","question":"Design a zero-downtime database migration system using Kubernetes multi-container pods with init containers, sidecars, and shared volumes. How would you handle schema validation, migration execution, rollback, and coordination while maintaining service availability?","channel":"kubernetes","subChannel":"pods","difficulty":"intermediate","tags":["containers","init-containers","sidecars"],"companies":["Amazon","Databricks","Google","Microsoft","Netflix","Stripe"]},{"id":"q-356","question":"You're deploying a security scanning sidecar with a main application pod. The sidecar must complete its vulnerability scan before the main container starts, then continue monitoring runtime threats. Design this pod configuration with shared volumes, health checks, and graceful shutdown. What key components ensure the security scanning completes before application startup?","channel":"kubernetes","subChannel":"pods","difficulty":"intermediate","tags":["containers","init-containers","sidecars"],"companies":null},{"id":"q-412","question":"You're deploying a web application that needs to run database migrations before the main container starts. How would you configure a Pod with an init container to handle this, and what happens if the init container fails?","channel":"kubernetes","subChannel":"pods","difficulty":"beginner","tags":["containers","init-containers","sidecars"],"companies":["Figma","NVIDIA","Okta"]},{"id":"q-511","question":"How does Kubernetes handle pod scheduling and what factors influence scheduling decisions?","channel":"kubernetes","subChannel":"pods","difficulty":"intermediate","tags":["kubernetes","scheduling","pods","resource-management","container-orchestration"],"companies":["Amazon","Google","Microsoft","Red Hat"]},{"id":"q-636","question":"What are init containers in Kubernetes and how do they differ from regular containers?","channel":"kubernetes","subChannel":"pods","difficulty":"intermediate","tags":["kubernetes","containers","pod-lifecycle","initialization"],"companies":["Amazon","Google","Microsoft"]},{"id":"q-637","question":"What are the key differences between init containers, sidecar containers, and static pods in Kubernetes?","channel":"kubernetes","subChannel":"pods","difficulty":"intermediate","tags":["kubernetes","containers","pod-lifecycle","deployment-patterns"],"companies":["Amazon","Google","Microsoft","Red Hat"]},{"id":"gh-101","question":"What is a Service Mesh Control Plane and how does it manage microservices communication?","channel":"kubernetes","subChannel":"services","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Salesforce","Uber"]},{"id":"gh-50","question":"How does Istio implement service mesh architecture using sidecar proxies, and what are the key components for traffic management, security, and observability?","channel":"kubernetes","subChannel":"services","difficulty":"advanced","tags":["k8s","advanced"],"companies":null},{"id":"q-219","question":"How would you design a zero-downtime service migration strategy using Kubernetes Service selectors and Endpoints controller to avoid connection drops during rolling updates?","channel":"kubernetes","subChannel":"services","difficulty":"advanced","tags":["clusterip","nodeport","loadbalancer","ingress"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-320","question":"You have a microservice deployed in Kubernetes that needs to be accessible both internally within the cluster and externally via a custom domain. How would you configure the service and ingress to achieve this, and what are the trade-offs between using ClusterIP, NodePort, and LoadBalancer service types?","channel":"kubernetes","subChannel":"services","difficulty":"advanced","tags":["clusterip","nodeport","loadbalancer","ingress"],"companies":["Elastic","Snowflake","Zoom"]},{"id":"gh-26","question":"What are the essential Linux commands every DevOps engineer should master for system administration, troubleshooting, and automation?","channel":"linux","subChannel":"commands","difficulty":"beginner","tags":["linux","shell"],"companies":["Amazon","Cloudflare","Google","Hashicorp","Microsoft","Netflix"]},{"id":"q-1000","question":"A Linux host runs several Docker containers; during peak load, API responses slow and some requests time out. Describe a beginner-friendly, concrete diagnostic workflow to (1) confirm whether host saturation is CPU, memory, or I/O, (2) identify the container most responsible, and (3) apply a safe mitigation (e.g., graceful restart or CPU/memory throttling) while monitoring impact. Include exact commands and expected outputs?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["Instacart","LinkedIn"]},{"id":"q-1142","question":"Scenario: A Linux server hosting a small web service used by customers suddenly shows disk usage climbing on the root filesystem. Provide a beginner-friendly, concrete diagnostic workflow to (1) locate the directories/files consuming the most space, (2) identify top offenders, and (3) apply a safe mitigation (e.g., rotate/compress/archive logs or purge old data) while keeping the service up. Include exact commands and expected outputs?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["DoorDash","Google","Salesforce"]},{"id":"q-1205","question":"You're operating a fleet of Linux hosts running a low-latency web API. Intermittent 100–200 ms latency spikes appear under load. Design a practical, end-to-end diagnostic plan using eBPF/BPFtrace or perf, iostat/vmstat, and container metrics to collect data, identify root cause (CPU scheduling, IO wait, or network), and propose minimal-disruption mitigations?","channel":"linux","subChannel":"general","difficulty":"advanced","tags":["linux"],"companies":["Salesforce","Snap"]},{"id":"q-1244","question":"Scenario: A Linux host runs a MongoDB primary in a high-traffic cluster. During peak hours, latency spikes and tail latency increases while CPU and memory appear stable. Using only default tooling, no downtime, describe a concrete, actionable diagnostic workflow to (1) determine if I/O wait, CPU, or memory is the bottleneck, (2) pinpoint the offending disk/device or process, and (3) apply a safe mitigation (e.g., adjust I/O scheduler, tune dirty writeback parameters, or throttle MongoDB) while monitoring impact. Include exact commands and expected outputs?","channel":"linux","subChannel":"general","difficulty":"intermediate","tags":["linux"],"companies":["Adobe","Databricks","MongoDB"]},{"id":"q-1266","question":"Context: Linux node in a Kubernetes cluster hosting a high-throughput data ingestion service. Intermittent tail latency spikes (>1s) appear during peak traffic, affecting processing. Without downtime, design a concrete troubleshooting workflow to (1) confirm whether CPU, I/O, or network is the bottleneck, (2) identify the exact subsystem or process responsible, and (3) implement a safe mitigation with minimal impact while maintaining observability. Include exact commands and realistic outputs?","channel":"linux","subChannel":"general","difficulty":"intermediate","tags":["linux"],"companies":["Airbnb","Anthropic","Snowflake"]},{"id":"q-466","question":"You're debugging a production Linux server where processes are randomly dying with 'Out of memory' errors, but `free -m` shows 8GB available RAM. How would you diagnose and fix this issue?","channel":"linux","subChannel":"general","difficulty":"advanced","tags":["linux"],"companies":["Amazon","Google","Tesla"]},{"id":"q-496","question":"How would you find all processes running on port 8080 and terminate them safely?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["Apple","Google"]},{"id":"q-527","question":"How would you find and kill a process that's using port 8080 on a Linux system?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["Amazon","Oracle","Two Sigma"]},{"id":"q-553","question":"You're troubleshooting a production server where a critical process keeps getting killed. How would you diagnose if it's an OOM kill versus other issues, and what specific commands would you use to investigate?","channel":"linux","subChannel":"general","difficulty":"intermediate","tags":["linux"],"companies":["Databricks","Scale Ai","Snowflake"]},{"id":"q-580","question":"How would you find all processes using a specific port and terminate one safely?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["Hashicorp","MongoDB","Twitter"]},{"id":"q-917","question":"Scenario: a Linux server hosting a web app experiences sporadic high response times during peak hours. Using only default tools and no downtime, describe a concrete, beginner-friendly diagnostic workflow to (1) determine whether CPU, memory, or I/O is the bottleneck, (2) identify the offending process, and (3) apply a safe mitigation (e.g., graceful restart) while monitoring impact. Include exact commands and expected outputs?","channel":"linux","subChannel":"general","difficulty":"beginner","tags":["linux"],"companies":["Microsoft","PayPal","Tesla"]},{"id":"q-1044","question":"On a Linux host running multiple tenant services, peak I/O from a data ingestion daemon saturates the disk, causing latency spikes for others. Propose a production plan to isolate and throttle disk I/O across tenants using systemd slices and cgroup v2 io.max. Include concrete unit and slice snippets, per-device limits for a SATA HDD and NVMe, and a test plan using fio and iostat to verify tail latency improvements under concurrent workloads?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"advanced","tags":["linux-foundation-sysadmin"],"companies":["Databricks","Microsoft","Twitter"]},{"id":"q-1056","question":"On a Linux host, a TLS proxy reads its certificate from /etc/ssl/certs/app.crt and currently reloads by restarting, causing brief downtime during renewal. Propose a zero-downtime rotation using a systemd.path trigger that fires on a new cert symlink, with a separate service unit for ExecReload and an atomic update scheme (swap in a new cert, then switch a symlink). Include concrete unit snippets and a test plan?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"advanced","tags":["linux-foundation-sysadmin"],"companies":["Apple","Two Sigma"]},{"id":"q-1122","question":"On a Linux host running multiple ML model servers in separate systemd slices using cgroup v2, a spike in one tenant consumes memory and triggers host memory pressure despite per-tenant limits. Propose a production plan to enforce strict isolation and backpressure using memory.max and memory.high, enable group OOM behavior, and implement eviction/playback strategies. Include concrete unit and cgroup settings and a test plan with a reproducible spike and validation steps?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"advanced","tags":["linux-foundation-sysadmin"],"companies":["Hugging Face","MongoDB","Tesla"]},{"id":"q-1230","question":"On a Linux host with a multi-tenant workload sharing a single 10GbE NIC configured with multiple receive queues, one tenant bursts UDP traffic and starves others, causing increased latency and packet loss. Propose a production plan to enforce tenant isolation and fairness using NIC multi-queue, RSS/XPS mapping, IRQ affinity, and per-tenant cgroups (v2) with io.max and tc shaping. Include concrete steps and a test plan with realistic traffic?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"intermediate","tags":["linux-foundation-sysadmin"],"companies":["DoorDash","MongoDB","Twitter"]},{"id":"q-881","question":"On a Linux host, a long-running daemon writes to `/var/log/myapp.log` and is managed by systemd, but log rotation occasionally causes logging to stop after rotation. Propose a practical fix to ensure logging continues after rotation without restarting the daemon. Include the exact approach and a sample logrotate config snippet and testing steps?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"beginner","tags":["linux-foundation-sysadmin"],"companies":["Apple","Meta","Plaid"]},{"id":"q-888","question":"A production Linux host runs a data-backup agent that uses /var/lib/backup/backup.lock to enforce a single instance. Sometimes a stale lock remains after a crash, blocking new runs; the agent also leaves non-terminating children on stop, risking partial backups. Propose a systemd‑based lifecycle fix: ensure one instance, auto-clean stale lock, and graceful stop with timeout and fallback to kill. Include concrete unit snippets and verification steps?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"advanced","tags":["linux-foundation-sysadmin"],"companies":["Goldman Sachs","Snowflake"]},{"id":"q-961","question":"On a Linux host, a memory-hungry log-harvester daemon managed by systemd sporadically triggers the kernel OOM killer during peak load, crashing the service and delaying alerts. Propose a production-safe plan to prevent OOM termination while preserving throughput. Include concrete systemd settings (MemoryLimit, MemorySwapMax, OOMScoreAdjust, Restart), kernel tuning (swap, swappiness), and a test plan with a reproducible high-memory scenario and verification steps?","channel":"linux-foundation-sysadmin","subChannel":"general","difficulty":"intermediate","tags":["linux-foundation-sysadmin"],"companies":["Databricks","Two Sigma"]},{"id":"linux-foundation-sysadmin-networking-1768260262823-4","question":"You suspect ARP storms on a host with interface eth1. To quickly verify ARP traffic and identify abnormal ARP activity on that interface, which command should you run?","channel":"linux-foundation-sysadmin","subChannel":"networking","difficulty":"intermediate","tags":["Networking","ARP","Linux","Kubernetes","certification-mcq","domain-weight-12"],"companies":null},{"id":"q-199","question":"When deploying LLM inference with vLLM and Triton Inference Server, how do you handle request batching across multiple GPU nodes while maintaining sub-100ms latency for individual requests?","channel":"llm-ops","subChannel":"deployment","difficulty":"advanced","tags":["vllm","tgi","triton","onnx"],"companies":["Amazon","Google","Meta","Microsoft","NVIDIA"]},{"id":"q-1045","question":"You're running a beginner LLM inference API used by multiple clients. Design a low-cost, safe plan to implement per-tenant model versioning and zero-downtime hot-swapping. Include routing to the correct version, how you deploy new versions, rollback strategy, and observability to verify no regressions before full rollout?","channel":"llm-ops","subChannel":"general","difficulty":"beginner","tags":["llm-ops"],"companies":["Discord","NVIDIA"]},{"id":"q-1060","question":"You're delivering a privacy-preserving, regionally scoped, multi-tenant LLM assistant used by teams across geographies. Describe an end-to-end design that ensures tenant isolation, data residency, and per-tenant policy enforcement while meeting sub-200ms latency for common prompts. Include routing, key management, redaction, auditability, and deletion workflows, plus how you'd validate compliance across regions?","channel":"llm-ops","subChannel":"general","difficulty":"intermediate","tags":["llm-ops"],"companies":["LinkedIn","NVIDIA","Zoom"]},{"id":"q-1147","question":"You're operating a multi-tenant, multi-region LLM inference service for regulated financial firms. Design an architecture that enforces per-tenant data residency and per-tenant model pools, plus dynamic model-version rollout with feature flags and safe rollback. Describe policy-driven routing, on-the-fly prompt sanitization, observability, and incident response. Include concrete data-plane components and a rollout sequence for a new model version?","channel":"llm-ops","subChannel":"general","difficulty":"advanced","tags":["llm-ops"],"companies":["Apple","Goldman Sachs","Plaid"]},{"id":"q-1263","question":"You operate a global LLM inference service across three regions and must upgrade models with zero downtime. Describe a concrete plan for rolling upgrades with canaries, traffic-splitting, warm-up, health checks, and fast rollback, ensuring SLA adherence and minimal cold-start impact during the switch?","channel":"llm-ops","subChannel":"general","difficulty":"intermediate","tags":["llm-ops"],"companies":["Databricks","Slack","Snap"]},{"id":"q-467","question":"You're deploying a LLM inference service that must handle 10,000 RPS with <100ms latency. How would you design the architecture to balance cost, performance, and reliability?","channel":"llm-ops","subChannel":"general","difficulty":"intermediate","tags":["llm-ops"],"companies":["Discord","Microsoft","Netflix"]},{"id":"q-497","question":"How would you design a distributed inference serving system for LLMs that handles 100K RPS with sub-100ms latency while managing GPU memory fragmentation and ensuring high availability?","channel":"llm-ops","subChannel":"general","difficulty":"advanced","tags":["llm-ops"],"companies":["Hugging Face","Tesla"]},{"id":"q-528","question":"You're deploying a LLM inference service that must handle 1000 concurrent requests with <500ms latency. Your current setup uses a single GPU with vLLM. How would you architect the system to meet these requirements?","channel":"llm-ops","subChannel":"general","difficulty":"intermediate","tags":["llm-ops"],"companies":["Airbnb","Hugging Face","Robinhood"]},{"id":"q-554","question":"You're deploying a multi-tenant LLM inference service that must handle 10,000 concurrent requests with sub-100ms latency. How would you design the request routing, model loading strategy, and autoscaling to meet these SLAs while optimizing GPU utilization?","channel":"llm-ops","subChannel":"general","difficulty":"advanced","tags":["llm-ops"],"companies":["DoorDash","IBM"]},{"id":"q-581","question":"How would you design a production LLM inference pipeline that handles 10K RPS with sub-200ms latency while managing GPU memory fragmentation and cold start issues?","channel":"llm-ops","subChannel":"general","difficulty":"advanced","tags":["llm-ops"],"companies":["Airbnb","Google"]},{"id":"q-849","question":"You operate a dual-tenant LLM inference service for sensitive internal docs and external users. Design a policy-driven routing and isolation architecture that guarantees tenant data separation, per-tenant model pools, on-the-fly prompt sanitization, and strict latency budgets under burst traffic. Include observability, data handling, and fail-open/closed strategies?","channel":"llm-ops","subChannel":"general","difficulty":"advanced","tags":["llm-ops"],"companies":["Cloudflare","Google","Instacart"]},{"id":"q-252","question":"What are the key techniques and trade-offs for optimizing large language models in production, including quantization strategies and their impact on performance?","channel":"llm-ops","subChannel":"optimization","difficulty":"beginner","tags":["quantization","pruning","distillation"],"companies":["Amazon","Apple","Google","Meta","Microsoft","NVIDIA"]},{"id":"q-422","question":"You're building a production LLM service handling 10K requests/second with transformer models experiencing memory spikes during multi-head attention. How would you optimize memory usage while maintaining throughput and latency requirements?","channel":"llm-ops","subChannel":"optimization","difficulty":"advanced","tags":["transformer","attention","tokenization"],"companies":null},{"id":"q-1177","question":"Scenario: a high-throughput edge service must enforce precise timeouts for thousands of connections. Design a lock-free, per-core timer wheel that manages up to 1,000,000 timers with microsecond granularity on a 4-socket server. API: add_timer(id, due_us, cb, ctx), cancel_timer(id), tick(). Requirements: no global locks, handle cancellation safely, cache-friendly layout, and crash-safe recovery. Include pseudo-code for add_timer, cancel_timer, and tick, plus a microbenchmark plan?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["DoorDash","Robinhood","Tesla"]},{"id":"q-1261","question":"Implement a cache-friendly transpose using tile-based approach for an N×N matrix with N a power of two. Provide a function to transpose A into B using 32×32 blocks, and a minimal test harness validating correctness. Explain how tiling reduces cache misses and how to pick block size relative to L1/L2 caches. Include a microbenchmark plan comparing with a naive transpose?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Microsoft","Plaid","Uber"]},{"id":"q-684","question":"Design a fixed-size ring buffer in C that stores bytes. Capacity N is a power of two (e.g., 1024). Show how to compute the next index using a mask (idx & (N-1)), and explain full vs empty detection using only head and tail counters. Provide enqueue and dequeue logic for a single-producer/single-consumer scenario?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Discord","Hugging Face","Instacart"]},{"id":"q-692","question":"Design a lock-free ring buffer that supports multiple producers and multiple consumers with bounded capacity. Provide enqueue/dequeue pseudo-code, explain how you avoid ABA, how memory reclamation is handled (hazard pointers or epochs), and why it scales under high contention. Include caveats on cache lines and false sharing. How would you validate under stress?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Anthropic","Databricks","Stripe"]},{"id":"q-694","question":"Design a cache-friendly, per-thread deque work-stealer for a multi-core task executor. Each worker maintains a fixed-size ring buffer for bottom push/pop; thieves steal from the top of other workers via CAS on a top index with a version counter. Explain ABA avoidance, memory ordering, and padding to avoid false sharing. Provide precise pseudo-code and a realistic burst workload scenario?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Coinbase","NVIDIA"]},{"id":"q-707","question":"Design a crash‑consistent, multi‑producer/multi‑consumer ring buffer backed by persistent memory PMEM. How would you ensure last enqueued item durability across power loss, implement recovery, and validate correctness? Provide concise enqueue/dequeue pseudocode with proper flush/fence ordering and discuss failure scenarios?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Airbnb","Coinbase","Two Sigma"]},{"id":"q-712","question":"Design a NUMA-aware in-memory index with per-node shards and a lock-free cross-node coordinator. Provide insertion and lookup with minimal locking, specify data layout (shards, padding, key/value encodings), and memory-order guarantees (fences, atomic ops). Describe a deadlock-free shard rebalancing protocol under high contention and outline tests with realistic Snowflake/Twitter-scale workloads?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Snowflake","Twitter"]},{"id":"q-723","question":"Design a software-based **TLB** for a 4-core 64-bit system with 4KiB pages. Each core has a private 128-entry **TLB** and a global page-table invalidation path. Provide lookup/refill pseudo-code, discuss eviction strategy (LRU vs. random), synchronization via **memory fences**, and cross-core shootdowns. Include a test under memory pressure and explain validation?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Instacart","Oracle","Tesla"]},{"id":"q-725","question":"Design a crash-consistent, in-memory index for a 4-byte key, 8-byte value store on an 8-core Linux machine. Use per-core log-structured segments and a Bloom filter; describe durable append ordering, startup recovery by replaying per-core logs, and validation under power-loss scenarios?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Goldman Sachs","LinkedIn","Plaid"]},{"id":"q-734","question":"Design an epoch-based reclamation scheme for a lock-free stack in a 64-bit, multi-threaded user-space library. Each thread publishes its local epoch; a global clock advances periodically. On pop, move the node to a retire-list with its epoch and reclaim only after all threads have observed an epoch older than that node. Include a stress test with high contention?","channel":"low-level","subChannel":"general","difficulty":"intermediate","tags":["low-level"],"companies":["Google","Lyft","Slack"]},{"id":"q-744","question":"In a 2-socket x86-64 server with MESI coherence, design a lock-free, multi-producer single-consumer ring buffer in shared memory for a 10 Gbps network path. Use per-slot sequence numbers to avoid ABA, with a fixed size N=1<<16 and 64-byte payload slots. Provide slot layout, push/pop pseudo-code with memory fences, discuss wrap-around and backpressure, and outline a minimal microbenchmark to validate throughput and data integrity under contention?","channel":"low-level","subChannel":"general","difficulty":"intermediate","tags":["low-level"],"companies":["Instacart","Tesla","Two Sigma"]},{"id":"q-752","question":"Design a crash-safe, persistent ring buffer in NVRAM for a 2-socket NUMA system with a PCIe NIC. Capacity N=1<<18, 128-byte payloads, per-slot 64-bit sequence to prevent ABA. Slot: [payload|seq|meta]. Enqueue: publish payload, fence, then update seq. Dequeue: verify seq before consume. Durability via per-slot commit log: flush payload and seq, then epoch commit. On crash, recover by replaying committed epochs and validating seq monotonicity. Provide a minimal microbenchmark to validate throughput and correctness under power loss?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Adobe","IBM","Tesla"]},{"id":"q-760","question":"On a dual-socket NUMA server, design a cross-NUMA, zero-copy ring buffer for a 40 Gbps path between two processes where producers live on socket A and a consumer on socket B. Use per-slot 64-bit sequence numbers to prevent ABA, 128-byte payload slots, and capacity 1<<18 with 64-byte alignment. Provide slot layout, enqueue/dequeue pseudo-code with memory fences and cache-line padding, wrap-around and backpressure handling, and outline a minimal microbenchmark to validate throughput and data integrity under cross-socket contention?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Amazon","Google"]},{"id":"q-772","question":"Design a cache-friendly fixed-size object pool for 128-byte blocks used by a multi-threaded producer-consumer path. Implement init, alloc, and free in C for a pool of 1<<20 blocks, each 128 bytes and 64-byte aligned. Use per-thread caches to reduce contention and a global lock-free free-list for overflow. Explain how you avoid false sharing, show the slot layout with a freelist pointer, and outline a microbenchmark to measure throughput and tail latency under contention?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Adobe","Netflix"]},{"id":"q-778","question":"Write a C function sum_prefetch that sums N 64-bit integers from an aligned array of length n using software prefetching to hide memory latency. Use 4-way unrolling and __builtin_prefetch to bring data 256 elements ahead. Ensure correctness for any length. Propose a microbenchmark plan to compare with a naive loop and discuss cache-line utilization and false sharing concerns?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Google","Tesla","Twitter"]},{"id":"q-784","question":"Design a deterministic, time-sliced barrier for a three-stage streaming pipeline on a 2-socket x86-64 system. Each stage runs on a fixed subset of cores; implement a barrier that advances phases only after every core finishes its assigned slice within a bounded time. Explain how to ensure bounded latency under cache-line contention, preserve MESI coherence, and prevent starvation. Provide pseudo-code for enter_barrier for a core and discuss validation?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Bloomberg","OpenAI"]},{"id":"q-794","question":"Design and implement a cache-friendly tiled matrix multiply for two large double-precision matrices stored in row-major order on a two-socket NUMA system. Propose a tile size of 32x32, provide C code for the tiled kernel with boundary handling, explain how to maximize L1/L2 reuse, NUMA locality (first-touch), avoid false sharing, and an inline 4-wide inner-loop unrolling. Include a microbenchmark plan comparing to a naive triple-nested loop and how you would measure throughput and cache behavior?","channel":"low-level","subChannel":"general","difficulty":"intermediate","tags":["low-level"],"companies":["Google","LinkedIn"]},{"id":"q-800","question":"Design a per-core, lock-free memory allocator for a shared-memory, NUMA-aware object store. Each core maintains a 2 MB local heap; allocations first attempt local allocation, with a fast cross-core path using atomic hand-offs; reclaimed memory is managed via hazard pointers and epoch-based reclamation. Provide allocate/free APIs, a sketch of the free-list structure, and a microbenchmark plan that shows fragmentation under steady-state load?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Discord","MongoDB","NVIDIA"]},{"id":"q-810","question":"Design a crash-consistent, bounded, multi-producer/multi-consumer queue backed by non-volatile memory. It must survive power loss, use per-slot sequence numbers to avoid ABA, provide push/pop pseudo-code with proper memory fences, and support epoch-based reclamation to avoid hazard pointers. Outline recovery on boot and a microbenchmark plan?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Airbnb","Plaid","Uber"]},{"id":"q-816","question":"Design a crash-consistent, persistent ring buffer for a multi-producer/multi-consumer event stream backed by non-volatile memory, with 1<<18 slots of 128-byte payloads; explain ABA avoidance via per-slot sequence numbers, two-phase publish with durable commit, and required flush/barrier order; describe recovery and a microbenchmark plan under simulated power loss?","channel":"low-level","subChannel":"general","difficulty":"advanced","tags":["low-level"],"companies":["Robinhood","Tesla"]},{"id":"q-826","question":"Design and implement a tiny spinlock in C11 for a shared memory region. Provide lock() and unlock() using stdatomic.h primitives, ensuring memory_order_acquire on successful lock and memory_order_release on unlock. Include a minimal two-thread test contending for the lock and explain your backoff/yield strategy and fairness limitations?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Goldman Sachs","Google","Snap"]},{"id":"q-834","question":"Design and implement a fixed-size object pool: a pre-allocated buffer partitioned into 1024 blocks of 64 bytes. Provide thread-safe allocate() and free() using a free-list stored in the blocks and a lightweight spinlock guarding the list. Include initialization and a small test snippet with 2 threads. Discuss fragmentation, cache locality, and how you'd validate concurrency?","channel":"low-level","subChannel":"general","difficulty":"beginner","tags":["low-level"],"companies":["Meta","Netflix","Uber"]},{"id":"q-358","question":"You're building a customer churn prediction model. Given a dataset with customer features (age, usage frequency, subscription type), how would you determine whether to use linear regression or logistic regression?","channel":"machine-learning","subChannel":"algorithms","difficulty":"beginner","tags":["regression","classification","clustering"],"companies":["Amazon","Datadog","Robinhood"]},{"id":"q-386","question":"You're building a fraud detection system for a large e-commerce platform. Your initial model using logistic regression has 85% accuracy but high false positives. How would you improve this system using ensemble methods, and what specific trade-offs would you consider between precision and recall?","channel":"machine-learning","subChannel":"algorithms","difficulty":"intermediate","tags":["regression","classification","clustering"],"companies":["Anthropic","Google","OpenAI"]},{"id":"q-201","question":"How does an LSTM cell's forget gate regulate information flow compared to a simple RNN?","channel":"machine-learning","subChannel":"deep-learning","difficulty":"beginner","tags":["lstm","gru","seq2seq"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-254","question":"When implementing a bidirectional GRU vs LSTM for sequence labeling, how do gradient clipping thresholds and batch size affect convergence and what are the memory trade-offs?","channel":"machine-learning","subChannel":"deep-learning","difficulty":"intermediate","tags":["lstm","gru","seq2seq"],"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-415","question":"You're training a CNN for Tesla's Autopilot lane detection. The model works well on clear roads but fails in rainy conditions. How would you modify the architecture and training process to handle weather variations while maintaining real-time performance?","channel":"machine-learning","subChannel":"deep-learning","difficulty":"intermediate","tags":["cnn","rnn","transformer","attention"],"companies":["Coinbase","Epic Games","Tesla"]},{"id":"q-195","question":"How would you implement a canary deployment strategy for a TensorFlow model using MLflow and Kubernetes, ensuring zero downtime and automatic rollback on performance degradation?","channel":"machine-learning","subChannel":"deployment","difficulty":"intermediate","tags":["mlflow","kubeflow","sagemaker"],"companies":["Amazon","Databricks","Google","Microsoft","Uber"]},{"id":"q-227","question":"How would you implement dynamic quantization-aware training with mixed-precision to optimize inference latency while maintaining model accuracy across varying hardware constraints?","channel":"machine-learning","subChannel":"deployment","difficulty":"advanced","tags":["quantization","pruning","distillation"],"companies":["Google","Meta","Microsoft","NVIDIA","Tesla"]},{"id":"q-309","question":"Design a complete MLOps pipeline using MLflow and Kubeflow for a production ML system handling 1M daily predictions with 99.9% availability. What components would you include and how would you ensure model governance and automated retraining?","channel":"machine-learning","subChannel":"deployment","difficulty":"advanced","tags":["mlflow","kubeflow","sagemaker"],"companies":null},{"id":"q-323","question":"How would you design an ML pipeline using Kubeflow that handles model versioning, A/B testing, and automated rollback for a fraud detection system at Coinbase?","channel":"machine-learning","subChannel":"deployment","difficulty":"advanced","tags":["mlflow","kubeflow","sagemaker"],"companies":["Coinbase","Cruise","Tesla"]},{"id":"q-347","question":"You're deploying a machine learning model using MLflow. How would you track experiments and ensure reproducibility when moving from development to production?","channel":"machine-learning","subChannel":"deployment","difficulty":"beginner","tags":["mlflow","kubeflow","sagemaker"],"companies":["MongoDB","Okta","Warner Bros"]},{"id":"q-223","question":"How would you design a production-scale evaluation pipeline that dynamically adjusts metrics based on class imbalance and business priorities while maintaining sub-second latency?","channel":"machine-learning","subChannel":"evaluation","difficulty":"advanced","tags":["precision","recall","auc-roc","f1"],"companies":["Amazon","Google","Meta","Netflix","Stripe"]},{"id":"q-336","question":"You're evaluating a movie recommendation system at Warner Bros. The system has 95% accuracy but poor precision for popular movies. How would you diagnose and fix this issue using precision-recall analysis?","channel":"machine-learning","subChannel":"evaluation","difficulty":"intermediate","tags":["precision","recall","auc-roc","f1"],"companies":["Expedia","Microsoft","Warner Bros"]},{"id":"q-1126","question":"You're deploying a real-time anomaly detector for edge CDN traffic at a cloud provider. Spikes during events cause distribution drift. Propose an online learning approach that adapts without catastrophic forgetting, maintains latency under 30 ms, and keeps calibration. Include data retention policy, drift detection, update rules, and monitoring dashboards?","channel":"machine-learning","subChannel":"general","difficulty":"intermediate","tags":["machine-learning"],"companies":["Cloudflare","Google"]},{"id":"q-1170","question":"You're training a binary classifier on a dataset with 1% positives. After a baseline model, overall accuracy is high but positive precision is very low. Describe a practical plan to diagnose whether the issue is threshold choice or true data imbalance, and implement a minimal pipeline with stratified splits, class weights or resampling, and threshold tuning; outline metrics and validation?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Adobe","Tesla","Two Sigma"]},{"id":"q-1220","question":"You're deploying a single on-device model for real-time video analytics on an edge device with 12 ms per frame latency and 200 MB RAM. The model must perform both object detection and semantic segmentation. Describe a concrete plan to meet latency while preserving accuracy: architecture choices (shared backbone, task heads, feature pyramids), training strategies (loss weighting, distillation, data augmentation), deployment optimizations (quantization, operator fusion, memory layout, early exits), and validation strategy (latency budgets, mAP, mIoU, robustness across weather)?","channel":"machine-learning","subChannel":"general","difficulty":"advanced","tags":["machine-learning"],"companies":["NVIDIA","Tesla","Twitter"]},{"id":"q-1290","question":"You’re training a binary classifier for signup conversion on a dataset with numeric features (age, session_time) and categorical features (device, country). A logistic regression baseline yields high AUROC but poor calibration on holdout. Outline a practical plan to diagnose and fix calibration, comparing Platt scaling and isotonic regression, data preprocessing tweaks, and how you’d validate the fix with a minimal code sketch?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Snowflake","Uber"]},{"id":"q-468","question":"You're training a neural network and notice the validation loss starts increasing while training loss continues decreasing. What's happening and how would you diagnose and fix it?","channel":"machine-learning","subChannel":"general","difficulty":"intermediate","tags":["machine-learning"],"companies":["Amazon","Google","OpenAI"]},{"id":"q-498","question":"You're building a simple spam classifier for emails. What's the difference between precision and recall, and which metric would you prioritize if false positives are more costly than false negatives?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Airbnb","IBM","Tesla"]},{"id":"q-529","question":"You're building a customer churn prediction model for a SaaS platform. What are the key steps you'd take from data preprocessing to model evaluation, and which metrics would you prioritize?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Databricks","Salesforce"]},{"id":"q-555","question":"Explain how gradient descent works and why it's fundamental to training neural networks?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Citadel","Microsoft","Tesla"]},{"id":"q-582","question":"Explain the difference between classification and regression in machine learning, and provide a simple example of when to use each?","channel":"machine-learning","subChannel":"general","difficulty":"beginner","tags":["machine-learning"],"companies":["Meta","Oracle"]},{"id":"q-273","question":"What's the difference between hyperparameters and parameters in machine learning, and why is cross-validation important for selecting optimal hyperparameters?","channel":"machine-learning","subChannel":"model-training","difficulty":"beginner","tags":["hyperparameter","cross-validation","regularization"],"companies":["Amazon","Google","Meta","Microsoft"]},{"id":"q-372","question":"You're training a CNN for Snapchat lens effects and notice your validation loss increases after epoch 3 while training loss decreases. What's happening and how would you implement a comprehensive solution including data augmentation, learning rate scheduling, and monitoring strategies?","channel":"machine-learning","subChannel":"model-training","difficulty":"beginner","tags":["hyperparameter","cross-validation","regularization"],"companies":null},{"id":"q-403","question":"You're training a large language model for Notion's AI features. Your model is overfitting on the training data but underperforming on validation. Design a comprehensive regularization strategy that addresses both L1/L2 regularization and more advanced techniques like dropout and early stopping. How would you implement cross-validation to ensure your hyperparameters generalize across different user data distributions?","channel":"machine-learning","subChannel":"model-training","difficulty":"advanced","tags":["hyperparameter","cross-validation","regularization"],"companies":["Chime","Google","Notion"]},{"id":"q-1133","question":"Scenario: a constraint-satisfaction problem with four tasks A,B,C,D each can be in domains {Pending, Running, Done}. Constraints: (A = Done) → (B = Running); (B = Running) → (C = Done); (C = Pending) → (D = Running); and (A = Pending) ∨ (D = Done). Is there a feasible assignment with at least one Running? Explain reasoning and outline a backtracking algorithm with forward-checking and 3-valued propagation to decide arbitrary such constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Bloomberg","Lyft"]},{"id":"q-1253","question":"Scenario: A deployment feature-flag policy defines three booleans F1, F2, F3 with these constraints: F1 -> F2, F2 -> F3, and exactly one of F1 and F3 is true, plus at least one flag is true. Is there a satisfying assignment? If yes, give one; if not, explain why. Then outline a tiny solver that encodes such constraints into a 2-SAT instance using an implication graph and SCC, with pseudocode?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Amazon","Meta","PayPal"]},{"id":"q-683","question":"You're managing a streaming DAG with tasks A,B,C,D; edges enforce: A before B; B before C; at most one of C or D can occur in a window of size H. Given a log of events with timestamps per task, implement an O(n log n) verifier to determine if the log is valid under these constraints and describe how you'd extend to multiple windows in a distributed system?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Databricks","Google"]},{"id":"q-685","question":"Context: In a data-cleaning pipeline, records have boolean attributes a, b, c, d. Rules are Horn clauses of the form X ∧ Y -> Z. Given a partial assignment, decide if a full assignment exists that satisfies all clauses. Design a linear-time forward-chaining solver, justify its correctness, and discuss incremental updates and cycles with a concrete four-variable example (two rules)?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Adobe","Databricks","Scale Ai"]},{"id":"q-699","question":"You have a Horn-clauses policy language for access control. Given the following rules and facts, determine if allow(alice,read,records) is entailed using forward-chaining to a least fixpoint. Rules: 1) grant(U,act,res) :- haveRole(U,R), privilege(R,act,res). 2) allow(U,act,res) :- grant(U,act,res). Facts: haveRole(alice,dataEngineer). privilege(dataEngineer,read,records). Show your derivation steps?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Adobe","Databricks","MongoDB"]},{"id":"q-702","question":"In a home security system, three sensors—door, window, and motion—report activity as booleans a, b, c for the last minute. The alert should fire only when exactly one sensor is active. How would you implement a function that takes a, b, c and returns true iff exactly one is true, and what are its time and space complexities?","channel":"math-logic","subChannel":"general","difficulty":"beginner","tags":["math-logic"],"companies":["Amazon","Google"]},{"id":"q-715","question":"In a distributed data-processing pipeline across three services Ingest (I), Compute (C), Persist (P), each event carries a 3-element vector clock. Given E1 at I with [2,0,1] and E2 at C with [1,3,0], decide whether E1 happened-before E2, E2 happened-before E1, or they are concurrent. Explain the rule and show the comparison. How would you scale this to N services and detect concurrency in large logs?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Amazon","Bloomberg","Slack"]},{"id":"q-719","question":"Design a tiny solver for three boolean inputs A, B, C given constraints: (A -> B) and (B -> C) and (A or C). Is there an assignment that satisfies all three? Explain your reasoning and outline a simple backtracking approach you would implement to check arbitrary small sets of such implications?","channel":"math-logic","subChannel":"general","difficulty":"beginner","tags":["math-logic"],"companies":["Adobe","Google","Scale Ai"]},{"id":"q-728","question":"Scenario: You’re building a tiny policy engine for feature flags with three booleans A, B, C. Constraints: A implies B, B implies C, and at least two of the three must be true. Is there an assignment that satisfies all constraints? If so, give one example and briefly justify. Then outline a straightforward backtracking approach to enumerate all satisfying assignments for any n flags and any such constraints?","channel":"math-logic","subChannel":"general","difficulty":"beginner","tags":["math-logic"],"companies":["Amazon","Instacart","Plaid"]},{"id":"q-733","question":"You’re auditing a rule-set for access policy. There are four booleans **X1**, **X2**, **X3**, **X4** with constraints: (X1 -> X2), (X1 ∨ X3), (X2 -> X4), and (X3 -> ¬X4). Is there a satisfying assignment? If yes, provide one; if not, explain why. Then outline a minimal backtracking strategy with unit propagation to verify arbitrary similar constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Microsoft","Netflix","Salesforce"]},{"id":"q-745","question":"You are building a tiny rule engine for feature toggles with three booleans A, B, C. Constraints: A → B, B → ¬C, and at least one of A, B, C must be true. Is there a satisfying assignment? Explain how you would verify it via brute-force backtracking across the eight possibilities and return one concrete example if it exists?","channel":"math-logic","subChannel":"general","difficulty":"beginner","tags":["math-logic"],"companies":["NVIDIA","Twitter"]},{"id":"q-753","question":"In a feature-flag synthesis task, you have booleans A1..A8. Constraints include: (Ai -> Aj) implications, (Ai XOR Aj) mutual exclusions, and (Ai OR Aj OR Ak) group obligations. The implication graph is acyclic and each node has at most two outgoing edges. Design a backtracking solver that exploits the DAG to decide satisfiability for up to 12 vars. Provide a concrete 8-variable instance and show the solution or UNSAT?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Apple","LinkedIn","Netflix"]},{"id":"q-758","question":"You manage feature flags for a distributed service. Let F1..F5 be booleans with constraints: (F1 -> F2), (F1 ∨ F3), (F2 ⊕ F4), (F3 -> F5), and (F4 -> ¬F5). Is there a satisfying assignment? If yes, provide one; if not, explain. Then outline a minimal backtracking strategy with forward checking to verify arbitrary similar constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Cloudflare","Discord","Snowflake"]},{"id":"q-771","question":"You are validating a tiny access-control policy with two booleans: A = 'account is active', B = 'email verified'. The policy must satisfy: (¬A -> B), (B -> A), and (A ∨ B). Is there a satisfying assignment for A and B? Explain your reasoning and outline a simple backtracking check to verify arbitrary small sets of such clauses?","channel":"math-logic","subChannel":"general","difficulty":"beginner","tags":["math-logic"],"companies":["NVIDIA","PayPal","Snowflake"]},{"id":"q-775","question":"You're building a constraint-solver for a feature-flag system across a microservices deployment. Given four flags S1..S4 with constraints: (S1 -> S2), (S2 -> S3), (S4 -> ¬S1), and (S1 ∨ S4) and (S2 ∨ S4). Is there a satisfying assignment? Provide one concrete assignment and outline a backtracking algorithm with unit propagation to verify arbitrary similar constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Slack","Two Sigma"]},{"id":"q-789","question":"Is there a truth assignment with exactly three flags true that satisfies all constraints A -> B; B -> C; D -> E; F -> G; not C -> H; A -> D? If yes, provide one and justify why it satisfies every implication?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Apple","Square","Twitter"]},{"id":"q-799","question":"Scenario: four booleans P, Q, R, S where P = user has role X, Q = grants read, R = has role Y, S = grants write. Constraints: (P -> Q), (R -> S), (P ∨ R), and at least two of {Q,S} must be true. Is there a satisfying assignment? If yes, give one; if not, explain why. Then outline a minimal backtracking strategy with unit propagation for arbitrary similar constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Cloudflare","DoorDash","Google"]},{"id":"q-812","question":"Instance-based SAT with mixed Horn and parity constraints: Variables A,B,C,D,E,F. Constraints: (A ∧ B) → C; (C ∧ D) → E; A ⊕ D ⊕ F = 1; (B ∧ E) → F. Is there an assignment to A..F that satisfies all constraints? If yes, provide one; then describe how you would build a solver that combines forward-chaining on Horn clauses with Gaussian elimination over GF(2) for parity constraints, including data structures and complexity considerations?","channel":"math-logic","subChannel":"general","difficulty":"advanced","tags":["math-logic"],"companies":["Citadel","Google","Lyft"]},{"id":"q-822","question":"Scenario: a tiny feature-toggle system for a data-annotation pipeline uses five booleans A–E: A = 'data augmentation enabled', B = 'sampling enabled', C = 'privacy mode on', D = 'live monitoring on', E = 'throttle rate limited'. Constraints: (A → B), (B → D), (C → ¬D), (A ∨ C), (D → E), (E → ¬A). Is there a satisfying assignment? If yes, give one; if not, explain why. Then outline a minimal backtracking strategy with unit propagation to verify arbitrary similar constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Databricks","Hugging Face","Square"]},{"id":"q-828","question":"Scenario: a feature-flag set uses four booleans A,B,C,D with rollout statuses True, False, Unknown (U). Constraints: (A → B), (C ∨ D), (A ∨ C), (B → ¬D). Is there a satisfying assignment allowing Unknowns? Explain reasoning and outline a backtracking approach using 3-valued logic to propagate U and verify arbitrary such constraint sets?","channel":"math-logic","subChannel":"general","difficulty":"intermediate","tags":["math-logic"],"companies":["Hashicorp","MongoDB","Robinhood"]},{"id":"q-180","question":"What is the primary purpose of DNS in computer networking and how does it enable internet communication?","channel":"networking","subChannel":"dns","difficulty":"beginner","tags":["dns","resolution"],"companies":["Amazon","Cisco","Google","Meta","Microsoft"]},{"id":"q-1031","question":"In a beginner-friendly scenario, a REST API behind a global CDN shows sporadic 1–2s latency for some users while synthetic tests pass. Outline a practical, end-to-end diagnostic plan to isolate DNS, TLS, caching, and client-network factors, including concrete commands and data you would collect and an initial fix you would try?","channel":"networking","subChannel":"general","difficulty":"beginner","tags":["networking"],"companies":["Discord","DoorDash","Snowflake"]},{"id":"q-1078","question":"In a small office network, a workstation intermittently cannot reach a public API behind Cloudflare during peak hours while other destinations are responsive; outline a practical, hands-on plan to diagnose using DNS (A/AAAA, TTLs), path tracing, TLS handshakes (ALPN/SNI), and edge routing behavior, with concrete mitigations to test?","channel":"networking","subChannel":"general","difficulty":"beginner","tags":["networking"],"companies":["Cloudflare","Tesla"]},{"id":"q-1089","question":"In a multi-region Kubernetes deployment using VXLAN overlays for pod networking, you notice intermittent packet loss and high tail latency when pods in region A talk to pods in region B. The overlay adds headers that push MTU beyond 1500 on inter-region links, causing fragmentation in some paths. You can adjust MTU, MSS clamping, and overlay parameters but cannot modify application code. How would you diagnose end-to-end and implement a robust fix that preserves ECMP load balancing and minimizes fragmentation? Provide concrete steps?","channel":"networking","subChannel":"general","difficulty":"advanced","tags":["networking"],"companies":["DoorDash","Google"]},{"id":"q-1163","question":"In a two-region service, IPv6 clients report higher latency and intermittent timeouts to a TLS-enabled API when accessed from IPv6 only networks. You cannot modify app code. Outline a practical diagnostic plan focusing on IPv6 path MTU discovery, ICMPv6/firewall behavior, and how to verify with traceroute6, tcpdump, and TLS handshake timings. Propose concrete mitigations like adjusting VPN MTU and enabling IPv4 fallback?","channel":"networking","subChannel":"general","difficulty":"beginner","tags":["networking"],"companies":["Discord","Robinhood","Snowflake"]},{"id":"q-1232","question":"In a two-region deployment (us-east-1, eu-west-1) with a TLS-enabled API behind a global load balancer, peak hours yield p95 latency spikes to 350 ms while basic tests pass. No app changes allowed. Provide a concrete diagnostic plan to distinguish TLS handshake delays, ALPN/SNI issues, path MTU fragmentation, and load balancer behavior, with exact commands and data you’d collect?","channel":"networking","subChannel":"general","difficulty":"beginner","tags":["networking"],"companies":["Hashicorp","MongoDB"]},{"id":"q-469","question":"Explain what happens when you type google.com into your browser and press Enter, focusing on the networking layers involved?","channel":"networking","subChannel":"general","difficulty":"beginner","tags":["networking"],"companies":["Discord","Goldman Sachs","IBM"]},{"id":"q-499","question":"How would you design a TCP load balancer that handles 1M concurrent connections with consistent hashing while preventing connection thrashing during backend failures?","channel":"networking","subChannel":"general","difficulty":"advanced","tags":["networking"],"companies":["Snowflake","Twitter"]},{"id":"q-583","question":"How would you design a load balancer to handle 1M concurrent connections with sub-10ms latency, considering TCP connection pooling, health checks, and graceful degradation?","channel":"networking","subChannel":"general","difficulty":"advanced","tags":["networking"],"companies":["Adobe","Goldman Sachs"]},{"id":"q-926","question":"In a multi-region deployment (US-East, EU-West) for a high-throughput service, end-to-end latency spikes to 150–300 ms during peak hours while synthetic tests pass. You observe edge drops and retransmissions. Provide a practical plan to diagnose and mitigate network-related factors, including path MTU discovery, ECN, TCP congestion control, TLS handshakes, SNI/ALPN behavior, and load-balancing strategy across regions, with data you’d collect and initial fixes?","channel":"networking","subChannel":"general","difficulty":"intermediate","tags":["networking"],"companies":["NVIDIA","Snowflake","Uber"]},{"id":"q-946","question":"In a globally distributed service behind a multi-region, ECMP-enabled load balancer, you observe sporadic high-tail latency while averages look fine. Explain the network mechanisms that could cause tail latency in this setup (per-path RTT variance, path MTU, reordering, retransmissions). Propose a concrete diagnostic workflow using production telemetry (eBPF per-flow histograms, NetFlow/SFlow, MTU checks) and practical remediation steps (MTU tuning, pacing, queue management)?","channel":"networking","subChannel":"general","difficulty":"advanced","tags":["networking"],"companies":["Coinbase","Salesforce","Two Sigma"]},{"id":"gh-72","question":"How would you design and implement network segmentation for a microservices architecture, including Zero Trust principles, east-west traffic monitoring, and compliance requirements?","channel":"networking","subChannel":"load-balancing","difficulty":"advanced","tags":["security","network"],"companies":["Amazon","Cloudflare","Google","Hashicorp","Microsoft","Stripe"]},{"id":"q-186","question":"How would you implement session affinity (sticky sessions) in HAProxy while maintaining high availability, and what are the trade-offs compared to stateless load balancing?","channel":"networking","subChannel":"load-balancing","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"companies":["Amazon","Bloomberg","Google","Microsoft","Netflix"]},{"id":"sd-1","question":"Explain load balancing strategies and when to use Layer 4 vs Layer 7. How do round-robin, least connections, and IP hash algorithms compare?","channel":"networking","subChannel":"load-balancing","difficulty":"advanced","tags":["infra","scale","networking"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"q-203","question":"How does TCP's congestion control algorithm interact with HTTP/2's multiplexing when multiple streams compete for bandwidth?","channel":"networking","subChannel":"tcp-ip","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"companies":["Amazon Aws","Cloudflare","Google","Microsoft","Netflix"]},{"id":"q-256","question":"How does QUIC solve TCP's head-of-line blocking problem in HTTP/2 multiplexing, and what are the implementation trade-offs?","channel":"networking","subChannel":"tcp-ip","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"q-275","question":"How does QUIC solve HTTP/2's head-of-line blocking issue over TCP, and what are the implementation trade-offs?","channel":"networking","subChannel":"tcp-ip","difficulty":"intermediate","tags":["tcp","udp","http2","quic"],"companies":["Amazon","Google","Meta","Microsoft"]},{"id":"q-1035","question":"In an advanced NLP interview, design an end-to-end multilingual QA system over English, Spanish, and Mandarin medical documents. The user asks in English. Outline architecture, data flow, privacy controls, latency targets, domain adaptation, and an evaluation plan. Include concrete components, trade-offs, and a short example of validation for a high-risk medical claim?","channel":"nlp","subChannel":"general","difficulty":"advanced","tags":["nlp"],"companies":["Adobe","IBM","MongoDB"]},{"id":"q-1101","question":"You're building a real-time brand-monitoring NLP service that ingests up to 100k tweets per minute in multiple languages. Design a scalable pipeline to classify sentiment and issue categories (e.g., billing, outages) with <300 ms latency per tweet, handle code-switching and slang, detect and adapt to drift, and provide a rollout plan including testing, monitoring, and rollback?","channel":"nlp","subChannel":"general","difficulty":"intermediate","tags":["nlp"],"companies":["Stripe","Twitter"]},{"id":"q-1215","question":"Design a beginner-friendly pipeline for a Slack-based support bot that lives in a single workspace. It should: (1) classify Slack messages into intents: 'password_reset', 'access_request', 'billing_issue', 'incident'. (2) retrieve and present the most relevant FAQ article from a 100-article KB in English or Spanish. (3) operate with minimal latency on a shared CPU, and include a simple drift-detection plan and a rollout strategy with a safe fallback. Provide concrete components, data flow, and a short code snippet showing the classifier and retriever?","channel":"nlp","subChannel":"general","difficulty":"beginner","tags":["nlp"],"companies":["Slack","Snap"]},{"id":"q-470","question":"How would you implement a sentiment analysis pipeline for customer reviews that handles negation and domain-specific slang? What preprocessing steps would you prioritize?","channel":"nlp","subChannel":"general","difficulty":"intermediate","tags":["nlp"],"companies":["DoorDash","IBM","Square"]},{"id":"q-500","question":"How would you implement basic text preprocessing for sentiment analysis, including tokenization, stop word removal, and stemming?","channel":"nlp","subChannel":"general","difficulty":"beginner","tags":["nlp"],"companies":["Airbnb","Apple","Google"]},{"id":"q-584","question":"How would you implement a transformer-based model for real-time text generation with attention mechanisms that handle variable-length sequences efficiently?","channel":"nlp","subChannel":"general","difficulty":"advanced","tags":["nlp"],"companies":["Databricks","Lyft","Tesla"]},{"id":"q-229","question":"What is the difference between tokenization and stemming in NLP text preprocessing, and when would you choose lemmatization over stemming?","channel":"nlp","subChannel":"text-processing","difficulty":"beginner","tags":["tokenization","stemming","ner"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-294","question":"How does the attention mechanism in transformers allow the model to handle variable-length sequences without recurrent connections?","channel":"nlp","subChannel":"transformers","difficulty":"intermediate","tags":["cnn","rnn","transformer","attention"],"companies":["Amazon","Google","Meta"]},{"id":"q-1124","question":"On a NUMA‑aware Linux host with a fixed‑size worker pool handling high‑frequency RPCs, cross‑socket memory traffic is a bottleneck. Propose a concrete plan to minimize inter‑socket traffic: pin threads to sockets, allocate per‑socket data, and choose memory policies (numa_bind/numa_alloc_onnode). Include measurement steps and success criteria?","channel":"operating-systems","subChannel":"general","difficulty":"advanced","tags":["operating-systems"],"companies":["Discord","Netflix","Salesforce"]},{"id":"q-1299","question":"Scenario: two threads share a global 32-bit counter. Thread A increments it in a tight loop; Thread B logs the value once per second. Without synchronization, describe a concrete interleaving that yields a stale read or lost update, and explain the cache/coherence mechanics behind it. Then outline the minimal fix and how it ensures atomicity and visibility (e.g., atomic fetch_add or a mutex)?","channel":"operating-systems","subChannel":"general","difficulty":"beginner","tags":["operating-systems"],"companies":["Instacart","Square"]},{"id":"q-448","question":"Explain how process scheduling works in an operating system. Which scheduling algorithm would you choose for a real-time system and why?","channel":"operating-systems","subChannel":"general","difficulty":"beginner","tags":["operating-systems"],"companies":["DoorDash","OpenAI","Snap"]},{"id":"q-471","question":"You're designing a GPU memory manager for CUDA applications. How would you implement a memory allocator that handles both unified memory and explicit device memory, considering fragmentation, coalescing, and the 48-bit address space limitations?","channel":"operating-systems","subChannel":"general","difficulty":"advanced","tags":["operating-systems"],"companies":["Amazon","NVIDIA"]},{"id":"q-530","question":"A process is stuck in 'D' state (uninterruptible sleep) during I/O operations. How would you debug this, what causes it, and how does it differ from 'Z' zombie state?","channel":"operating-systems","subChannel":"general","difficulty":"intermediate","tags":["operating-systems"],"companies":["Adobe","LinkedIn","Netflix"]},{"id":"q-556","question":"How would you debug a process that's consuming 100% CPU but not responding to signals? What tools and steps would you use?","channel":"operating-systems","subChannel":"general","difficulty":"intermediate","tags":["operating-systems"],"companies":["Snowflake","Two Sigma"]},{"id":"q-585","question":"How would you implement a lock-free concurrent queue using atomic operations and memory barriers? What are the trade-offs between ABA problem solutions?","channel":"operating-systems","subChannel":"general","difficulty":"advanced","tags":["operating-systems"],"companies":["Citadel","OpenAI","Square"]},{"id":"q-927","question":"In a system with a fixed-size circular buffer of size N shared by a producer and a consumer thread, implement a thread-safe producer-consumer solution using semaphores and a mutex in C. Include initialization, edge cases (buffer full/empty), and show how you would test for deadlocks and correctness under concurrent producers/consumers?","channel":"operating-systems","subChannel":"general","difficulty":"beginner","tags":["operating-systems"],"companies":["Adobe","OpenAI","Scale Ai"]},{"id":"q-995","question":"In a system using paging with a TLB, describe the end-to-end sequence when a 4 KB page accessed by a process is not mapped in RAM, from fault to resume, including the fault handler, page-table walk, TLB update, disk I/O to swap, and how the eviction policy decides which page to replace?","channel":"operating-systems","subChannel":"general","difficulty":"beginner","tags":["operating-systems"],"companies":["Lyft","NVIDIA","Stripe"]},{"id":"q-263","question":"How does demand paging optimize memory utilization in virtual memory systems, what triggers page faults, and which algorithms handle page replacement when physical memory is full?","channel":"operating-systems","subChannel":"memory","difficulty":"intermediate","tags":["virtual-memory","paging","segmentation","cache"],"companies":["Amazon","Apple","Google","Meta","Microsoft","Netflix"]},{"id":"q-1070","question":"You are building a latency-sensitive telemetry ingestion pipeline for autonomous fleets. Design an end-to-end data path from edge sensors to a real-time analytics sink. Include data schemas, serialization (protobuf vs Avro), transport (Kafka vs Kinesis), fault tolerance (idempotency, replay), schema evolution, and testing strategy. Explain trade-offs for throughput, latency, and reliability?","channel":"otca","subChannel":"general","difficulty":"advanced","tags":["otca"],"companies":["Lyft","NVIDIA","Tesla"]},{"id":"q-1090","question":"Design a real-time notification system for 1M+ concurrent users with end-to-end latency under 200ms. Describe architecture, data model, delivery guarantees, back-pressure, disaster recovery, and how you measure and enforce SLOs?","channel":"otca","subChannel":"general","difficulty":"advanced","tags":["otca"],"companies":["Apple","Cloudflare","Discord"]},{"id":"q-1115","question":"In a global OTCA stack for a large platform, design a fault-tolerant telemetry pipeline that ingests 10k events/sec, preserves dashboards with sub-30s freshness, and scales regionally. Describe data model, streaming, storage, and tracing choices (e.g., Kafka, OpenTelemetry, ClickHouse/BigQuery), backpressure handling, and testing strategy?","channel":"otca","subChannel":"general","difficulty":"advanced","tags":["otca"],"companies":["DoorDash","Meta","Twitter"]},{"id":"q-1171","question":"Design a multi-tenant OTCA telemetry pipeline with per-tenant quotas and privacy masking. Ingest 20k events/sec regionally via Kafka, route by tenant_id, and compute deduplicated aggregates in Flink. Hot metrics in Redis, long-term data in ClickHouse/BigQuery, traces via OpenTelemetry. Include idempotent writes, backpressure handling, and robust testing?","channel":"otca","subChannel":"general","difficulty":"intermediate","tags":["otca"],"companies":["Adobe","Coinbase","Google"]},{"id":"q-1219","question":"In a multi-tenant OTCA pipeline for a global fintech platform, how would you implement tenant-scoped telemetry collection that isolates data, preserves sub-second dashboards, and enforces per-tenant quotas? Describe data model, per-tenant exporters, sampling, storage with row-level security, and testing strategy?","channel":"otca","subChannel":"general","difficulty":"intermediate","tags":["otca"],"companies":["Goldman Sachs","PayPal"]},{"id":"q-1237","question":"In a multi-tenant OTCA telemetry stack for a global SaaS, migrate from a fixed event schema to an evolving, backward/forward-compatible schema while preserving per-tenant data residency. The system must sustain up to 60k events/sec with regional bursts. Describe data model, schema versioning, streaming backbone, storage strategy (raw + materialized), tracing, backpressure handling, tenant-level sampling, and testing plan?","channel":"otca","subChannel":"general","difficulty":"intermediate","tags":["otca"],"companies":["Databricks","MongoDB","Zoom"]},{"id":"q-1286","question":"In a global OTCA stack, design a fault-tolerant telemetry pipeline that ingests 20k events/sec per region from web/mobile clients, enforces per-tenant data residency, and uses adaptive sampling for long-tail tenants. Specify data model, streaming, storage, tracing, backpressure, and a test plan that validates burst behavior, schema evolution, and failover?","channel":"otca","subChannel":"general","difficulty":"advanced","tags":["otca"],"companies":["Meta","Snowflake"]},{"id":"q-838","question":"You’re building a minimal product API in Express. Implement routes GET /products and GET /products/:id that returns 404 when not found. Include input validation, safe DB access via parameterized queries, and robust error handling. Explain your approach and provide a concise code sample?","channel":"otca","subChannel":"general","difficulty":"beginner","tags":["otca"],"companies":["Airbnb","Discord","Meta"]},{"id":"q-908","question":"You have a global edge API gateway handling peak bursts. How would you implement a distributed token-bucket rate limiter per API key across regions using Redis? Outline the Lua script for atomic refill and consume (capacity 1000, refill 50 tokens/sec), how you expose headers, handle clock skew, and fallback when Redis is unavailable?","channel":"otca","subChannel":"general","difficulty":"intermediate","tags":["otca"],"companies":["Bloomberg","Cloudflare","Square"]},{"id":"q-1012","question":"In a churn prediction problem, you have 20k customers and 500 features (mix of binary indicators and continuous metrics). PCA will be used before a logistic regression model to predict churn. Describe an end-to-end plan to (1) handle missing values and mixed data types, (2) scale features appropriately, (3) choose the number of components with cross-validated downstream performance, (4) interpret the top loadings for business insight, and (5) guard against leakage and overfitting in a production pipeline?","channel":"pca","subChannel":"general","difficulty":"beginner","tags":["pca"],"companies":["DoorDash","NVIDIA","Plaid"]},{"id":"q-1068","question":"Design an online robust PCA for a streaming fraud-detection pipeline: 50k events/sec, 1000 features with missing values. Describe incremental component updates, robust outlier handling (robust PCA or GoDec variants), missing-data strategy, drift monitoring (eigenvalue gaps, loadings stability, score distribution), and how you’d validate downstream classifier performance under tight memory/time constraints?","channel":"pca","subChannel":"general","difficulty":"advanced","tags":["pca"],"companies":["Meta","Oracle","Tesla"]},{"id":"q-1104","question":"In a production streaming recommender system, you maintain an incremental PCA basis on 1M users and 3k features, updated hourly. Design an online robust PCA pipeline that adapts to non-stationary covariances, handles missing data, and detects concept drift. Describe algorithm choices (incremental/robust variants, forgetting factors), when to re-train vs update, how to align with past loadings, validation of downstream models after projection, and monitoring for numerical stability?","channel":"pca","subChannel":"general","difficulty":"advanced","tags":["pca"],"companies":["Airbnb","Goldman Sachs","Google"]},{"id":"q-1128","question":"You have 50k samples, 1k gene-expression features with many missing values. Design an end-to-end Sparse PCA pipeline to produce 40 interpretable components. How would you handle missing data, choose sparsity vs components, validate downstream models, and assess stability and biological coherence of loadings across folds?","channel":"pca","subChannel":"general","difficulty":"intermediate","tags":["pca"],"companies":["Adobe","Twitter","Two Sigma"]},{"id":"q-1153","question":"Design a PPCA-based dimensionality reduction pipeline for real-time telemetry data: 1B feature vectors daily, 500 real-valued features with missing values and skew, to feed a downstream anomaly detector. Explain fitting PPCA with EM, selecting k via BIC on a rolling window, comparing to standard PCA, handling streaming updates with forgetting factors, and validating in production?","channel":"pca","subChannel":"general","difficulty":"intermediate","tags":["pca"],"companies":["Salesforce","Zoom"]},{"id":"q-1175","question":"In a factory IoT setting, 20 devices stream 40 features each (numeric, with occasional missing values). You want a beginner-friendly PCA-based anomaly detector on the edge. Describe how you would handle missing values, decide the number of components, and translate top loadings into actionable maintenance signals for operators, while keeping the model lightweight on-device?","channel":"pca","subChannel":"general","difficulty":"beginner","tags":["pca"],"companies":["Apple","Twitter"]},{"id":"q-1218","question":"You have a 40-feature numeric customer-survey dataset with some missing values and skewed distributions. You want a beginner-friendly PCA-based feature set for a churn-classification model. Describe preprocessing steps (imputation, transformations, outlier handling), how to choose the number of components, and how to translate top loadings into concrete business signals for a dashboard while keeping the pipeline lightweight?","channel":"pca","subChannel":"general","difficulty":"beginner","tags":["pca"],"companies":["Databricks","Google"]},{"id":"q-1249","question":"You're building a real-time risk-scoring system for cross-border payments. Data arrives as numeric features with occasional missing values and a few graph-derived signals, streaming at high velocity. You need an incremental PCA that adapts to non-stationary distributions and yields 40 components. Describe how you would: (a) choose/update the number of components under drift, (b) perform online imputation without data leakage, (c) keep loadings interpretable for dashboards, (d) coordinate PCA updates with downstream models to control drift, and (e) design a robust rollback strategy with governance in production?","channel":"pca","subChannel":"general","difficulty":"advanced","tags":["pca"],"companies":["Cloudflare","Coinbase","Uber"]},{"id":"q-1288","question":"Design a daily-updated PCA-based representation for streaming telemetry with 300 features per vector, many missing values and sparse signals. Outline preprocessing, choice of incremental PCA approach (IPCA vs randomized SVD), when to refresh the basis, how to align new loadings with the existing basis, and how to validate the downstream anomaly detector after dimensionality reduction. Include concrete knobs (batch size, forgetting factor, drift thresholds)?","channel":"pca","subChannel":"general","difficulty":"intermediate","tags":["pca"],"companies":["Google","Snowflake"]},{"id":"q-837","question":"In a dataset with 120k samples and 200 features, after standardizing, you fit PCA and observe 95% variance explained by the first 8 components. How would you validate using PCA for downstream linear regression, decide the number of components, and interpret the top loadings? Consider missing values and large-scale data in your answer?","channel":"pca","subChannel":"general","difficulty":"intermediate","tags":["pca"],"companies":["Amazon","Google","Plaid"]},{"id":"q-934","question":"Suppose a streaming analytics pipeline ingests 10k new vectors daily, each with 180 features, and PCA was computed on historical data. Describe an end-to-end approach to decide when to refresh the PCA vs keep the existing basis, how to measure component drift, how to align new loadings with the old basis, how to handle missing values in streaming data, and how to validate downstream models after dimensionality reduction?","channel":"pca","subChannel":"general","difficulty":"intermediate","tags":["pca"],"companies":["Citadel","Discord","Hashicorp"]},{"id":"q-1117","question":"You're adding a real-time AI-powered product search for an Instacart-like app. With 8,000 concurrent users during lunch peak, design a beginner-friendly performance test that isolates the ML inference path from normal search, including cache warming and a clear success criteria?","channel":"performance-testing","subChannel":"general","difficulty":"beginner","tags":["performance-testing"],"companies":["Instacart","Snap","Zoom"]},{"id":"q-1210","question":"You're introducing a search API for a streaming e-commerce platform during a flash sale; expect 8k concurrent users, target median latency under 120ms and p99 under 250ms. The stack uses Redis caching with a relational DB. Design a beginner-friendly performance test plan to validate this, including tools, test data strategy, ramp pattern, metrics (p50, p90, p95, p99, error rate), and how you identify bottlenecks without affecting production?","channel":"performance-testing","subChannel":"general","difficulty":"beginner","tags":["performance-testing"],"companies":["DoorDash","Netflix","Snowflake"]},{"id":"q-472","question":"You're load testing a high-frequency trading platform that processes 100K requests/second. Your load generator becomes the bottleneck. How would you design a distributed load testing architecture to accurately simulate production traffic patterns?","channel":"performance-testing","subChannel":"general","difficulty":"advanced","tags":["performance-testing"],"companies":["Goldman Sachs","Two Sigma"]},{"id":"q-501","question":"You're testing a grocery delivery app like Instacart that handles 10,000 concurrent users during peak hours. How would you design a performance testing strategy to identify bottlenecks in the order processing pipeline?","channel":"performance-testing","subChannel":"general","difficulty":"advanced","tags":["performance-testing"],"companies":["Instacart","Tesla"]},{"id":"q-531","question":"You're load testing a food delivery platform's order processing system. How would you design a performance testing strategy to identify bottlenecks during peak lunch hours (12-2 PM) when order volume increases 10x?","channel":"performance-testing","subChannel":"general","difficulty":"advanced","tags":["performance-testing"],"companies":["Citadel","DoorDash"]},{"id":"q-557","question":"You're load testing a trading platform that processes 10,000 orders/second. Your load generator shows 95th percentile latency at 200ms, but actual users report 2-3 second delays. What's happening and how would you diagnose it?","channel":"performance-testing","subChannel":"general","difficulty":"intermediate","tags":["performance-testing"],"companies":["NVIDIA","Robinhood"]},{"id":"q-586","question":"How would you measure and optimize the performance of a REST API endpoint that's responding slowly?","channel":"performance-testing","subChannel":"general","difficulty":"beginner","tags":["performance-testing"],"companies":["Plaid","Uber"]},{"id":"q-996","question":"Design a performance testing plan for a MongoDB-backed ride-hailing backend where a single /alloc-trip endpoint coordinates availability updates and cross-service trip allocations under production-like bursts up to 50k RPS; outline how you would identify bottlenecks across DB, services, and network, and concrete steps to reduce tail latency?","channel":"performance-testing","subChannel":"general","difficulty":"intermediate","tags":["performance-testing"],"companies":["Google","MongoDB","Uber"]},{"id":"gh-40","question":"What is Performance Testing and how does it differ from Load and Stress Testing?","channel":"performance-testing","subChannel":"load-testing","difficulty":"beginner","tags":["perf","testing"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-41","question":"What are the different types of performance testing and when would you apply each type in a real-world scenario?","channel":"performance-testing","subChannel":"load-testing","difficulty":"intermediate","tags":["perf","testing"],"companies":["Amazon","Google","Meta"]},{"id":"q-237","question":"How would you design a distributed load testing setup using k6 with multiple cloud regions to simulate 100k concurrent users while avoiding rate limiting and ensuring accurate metrics collection?","channel":"performance-testing","subChannel":"load-testing","difficulty":"intermediate","tags":["jmeter","k6","gatling","locust"],"companies":["Amazon","Google","Netflix","Stripe","Uber"]},{"id":"q-210","question":"How would you implement comprehensive CPU profiling with flame graphs using clinic.js and async hooks to identify performance bottlenecks in a Node.js microservice handling concurrent requests, including production considerations and memory leak detection?","channel":"performance-testing","subChannel":"profiling","difficulty":"intermediate","tags":["cpu-profiling","memory-profiling","flame-graphs"],"companies":["Amazon","Cloudflare","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-280","question":"What is the difference between CPU profiling and memory profiling, and when would you use a flame graph?","channel":"performance-testing","subChannel":"profiling","difficulty":"beginner","tags":["cpu-profiling","memory-profiling","flame-graphs"],"companies":["Amazon","Google","Microsoft","Netflix"]},{"id":"q-1024","question":"You're building a prompt-routing system for a consumer-support assistant serving Apple, Airbnb, and Snap customers. It must decide auto-response, request clarification, or escalate to a human agent, based on intent, risk, PII presence, and policy compliance. Describe end-to-end design, including a 3-template prompt bank (concise, friendly, authoritative), a safety/brand-voice rubric, and a minimal Python prototype that routes auto vs escalate under edge cases. Include a testing plan?","channel":"prompt-engineering","subChannel":"general","difficulty":"intermediate","tags":["prompt-engineering"],"companies":["Airbnb","Apple","Snap"]},{"id":"q-1037","question":"You're building a dynamic prompt orchestration system for Scale AI and MongoDB enterprise-support chatbots. It must select from a bank of five templates (concise, empathetic, technical, authoritative, business-friendly) based on user intent, data sensitivity, and risk signals, while applying strict safety guardrails to prevent prompt injection and data leakage. Describe the architecture, routing rules, and a minimal Python prototype that demonstrates template selection and a veto guardrail for edge cases?","channel":"prompt-engineering","subChannel":"general","difficulty":"advanced","tags":["prompt-engineering"],"companies":["MongoDB","Scale Ai"]},{"id":"q-1119","question":"You're building a beginner-friendly prompt routing module for a multilingual customer-support chatbot serving Snowflake and Airbnb users. Design a two-step prompt selection: first classify intent (order_status, account_help, security_alert), then select a single template from (concise, friendly, authoritative) that preserves safety and privacy. Provide the concrete routing rules and a tiny Python prototype that demonstrates intent classification and template selection with sample inputs?","channel":"prompt-engineering","subChannel":"general","difficulty":"beginner","tags":["prompt-engineering"],"companies":["Airbnb","Snowflake"]},{"id":"q-1137","question":"Design a multilingual prompt evaluation pipeline for a Tesla/Square customer-support bot. It must detect language, route prompts to language-specific template banks, apply safety gates for PII and injection, and track drift metrics to trigger template updates. Provide architecture and a minimal Python prototype that returns a selected template and a veto flag?","channel":"prompt-engineering","subChannel":"general","difficulty":"intermediate","tags":["prompt-engineering"],"companies":["Square","Tesla"]},{"id":"q-1206","question":"You're building a prompt lifecycle service for a multi-tenant chat assistant used by Tesla support and MongoDB customers. It must manage versioned templates, canary rollouts, per-tenant experiments, and safe rollback if a new version underperforms or violates safety guards. Describe the architecture, data model, and provide a minimal Python prototype that resolves the tenant's latest approved version and supports rollback via a veto gate?","channel":"prompt-engineering","subChannel":"general","difficulty":"intermediate","tags":["prompt-engineering"],"companies":["MongoDB","Tesla"]},{"id":"q-1217","question":"You're building a budgeted prompt engine for a multilingual support bot. With a 60-token cap for prompts in English and Spanish, design a rule-based condenser that preserves intent, routes to one of three templates (concise, empathetic, clarifying), and rejects unsafe prompts. What would the architecture look like, and provide a minimal Python prototype that compresses input to fit the budget and demonstrates template routing?","channel":"prompt-engineering","subChannel":"general","difficulty":"beginner","tags":["prompt-engineering"],"companies":["Google","Lyft","Microsoft"]},{"id":"q-447","question":"You're building a prompt for a customer service chatbot that needs to extract order details from unstructured user messages. How would you design the prompt to handle variations like 'I need to cancel order #12345' vs 'Can't find my recent purchase 12345' while maintaining high accuracy?","channel":"prompt-engineering","subChannel":"general","difficulty":"intermediate","tags":["prompt-engineering"],"companies":["DoorDash","Google","NVIDIA"]},{"id":"q-450","question":"You're building a prompt optimization system for a large language model API. The system needs to automatically improve prompt performance while maintaining safety constraints. How would you design an architecture that balances prompt effectiveness with content safety, and what metrics would you track?","channel":"prompt-engineering","subChannel":"general","difficulty":"advanced","tags":["prompt-engineering"],"companies":["Apple","Robinhood","Tesla"]},{"id":"q-473","question":"You're building a chatbot for Instacart's customer service. How would you design a prompt template that handles both order status inquiries and refund requests while maintaining consistent tone and preventing prompt injection?","channel":"prompt-engineering","subChannel":"general","difficulty":"beginner","tags":["prompt-engineering"],"companies":["Goldman Sachs","Instacart","Netflix"]},{"id":"q-502","question":"How would you design a prompt engineering system to handle multi-turn conversations with context windows, ensuring consistent persona adherence while managing token limits and preventing prompt injection attacks?","channel":"prompt-engineering","subChannel":"general","difficulty":"advanced","tags":["prompt-engineering"],"companies":["IBM","Meta","Zoom"]},{"id":"q-532","question":"You're building a prompt engineering system for a cloud infrastructure tool. How would you design prompts to handle ambiguous user input like 'setup database' while maintaining context and preventing hallucination?","channel":"prompt-engineering","subChannel":"general","difficulty":"intermediate","tags":["prompt-engineering"],"companies":["Google","Hashicorp","Stripe"]},{"id":"q-558","question":"You're building a prompt optimization system for a large language model serving 10M+ daily requests. How would you design a system to automatically detect and mitigate prompt injection attacks while maintaining 99.9% uptime?","channel":"prompt-engineering","subChannel":"general","difficulty":"advanced","tags":["prompt-engineering"],"companies":["Coinbase","NVIDIA","PayPal"]},{"id":"q-587","question":"How would you design a prompt to extract structured data from unstructured text while handling edge cases and ensuring consistent output format?","channel":"prompt-engineering","subChannel":"general","difficulty":"beginner","tags":["prompt-engineering"],"companies":["Meta","Snowflake","Zoom"]},{"id":"q-892","question":"You're building a beginner-friendly prompt evaluation harness for a customer-support chatbot. Given user prompts about orders or refunds, design a lightweight, rule-based template selector that picks among three templates (concise, friendly, authoritative). How would you implement and test this with a tiny Python prototype that scores templates on safety, tone, and length?","channel":"prompt-engineering","subChannel":"general","difficulty":"beginner","tags":["prompt-engineering"],"companies":["Coinbase","Google","Lyft"]},{"id":"q-251","question":"How would you implement a DSPy optimizer to automatically improve few-shot prompts for a classification task using BootstrapFewShot with evaluation metrics?","channel":"prompt-engineering","subChannel":"optimization","difficulty":"intermediate","tags":["prompt-tuning","dspy","automatic-prompting"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-198","question":"How would you design a multi-layered guardrail system to prevent prompt injection and jailbreak attacks while maintaining legitimate user functionality, and what are the key trade-offs between security and user experience?","channel":"prompt-engineering","subChannel":"safety","difficulty":"beginner","tags":["jailbreak","guardrails","content-filtering"],"companies":["Amazon","Google","Meta"]},{"id":"q-226","question":"How would you design a prompt-engineering system that dynamically selects between chain-of-thought, few-shot, and zero-shot prompting based on real-time performance metrics and task complexity?","channel":"prompt-engineering","subChannel":"techniques","difficulty":"advanced","tags":["chain-of-thought","few-shot","zero-shot"],"companies":["Amazon","Google","Meta","Microsoft","OpenAI"]},{"id":"q-196","question":"How would you implement a rate-limited async HTTP client using aiohttp and asyncio.Semaphore to handle 1000 requests while respecting API limits?","channel":"python","subChannel":"async","difficulty":"intermediate","tags":["asyncio","aiohttp","concurrency"],"companies":["Amazon","Google","Meta"]},{"id":"q-224","question":"How would you implement a thread-safe singleton in Python with lazy initialization, proper type hints, and discuss the trade-offs between metaclass, decorator, and module-level approaches for a production system?","channel":"python","subChannel":"best-practices","difficulty":"advanced","tags":["pep8","typing","testing"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-178","question":"In Python, when do `is` and `==` return different results, and why does this happen with object identity vs equality?","channel":"python","subChannel":"fundamentals","difficulty":"intermediate","tags":["python","basics"],"companies":["Amazon","Google","Meta","Microsoft","Uber"]},{"id":"q-1085","question":"You’re building a real-time log processor in Python for a messaging app. You receive a stream of JSON lines like {\"user_id\": 123, \"event\": \"message_sent\", \"ts\": 1610000000}. Emit only the first event per (user_id, event) within a 60-second sliding window. Design a memory-bounded, generator-based pipeline that reads from an iterable of strings and yields deduplicated dicts in order. Include edge cases and memory considerations?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["Hugging Face","Slack"]},{"id":"q-1149","question":"In a streaming data etl, you're given a JSONL stream where each line is a JSON object with 'host' and 'value'. Implement a memory-efficient Python generator top_n_hosts(n, lines) that yields the top N hosts by total value after consuming the stream, without keeping the entire per-host totals in memory. Use a min-heap to maintain current top-N and skip invalid lines?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["Google","Meta"]},{"id":"q-1250","question":"Design an asynchronous NDJSON ingestion pipeline in Python that reads an async iterable of lines, validates each with a Pydantic model, and routes records to per-tenant partitions based on the 'tenant_id'. Implement bounded queues per partition with a total memory cap, guarantee per-tenant in-order processing, and a slower downstream sink that creates backpressure. Provide a test plan with skewed partitions and slow sinks?","channel":"python","subChannel":"general","difficulty":"advanced","tags":["python"],"companies":["Snowflake","Uber"]},{"id":"q-1275","question":"Design an advanced async Python pipeline: NDJSON lines arrive via a TCP socket, each is validated with a Pydantic model, then a deduplication stage uses a sliding-window Bloom filter to emit each event at most once in a 24-hour window. The pipeline must stay memory-bounded, support backpressure to the producer, and allow the downstream sink to pace itself. Provide a concrete test plan with clock skew and bursty traffic?","channel":"python","subChannel":"general","difficulty":"advanced","tags":["python"],"companies":["DoorDash","Hugging Face","Two Sigma"]},{"id":"q-1285","question":"Given a list of dictionaries representing users, implement normalize_users(users) that returns a list of User dataclass instances with fields id:int, name:str, signup_ts:datetime, is_active:bool. Coerce id from str to int, parse signup_ts ISO8601 strings, interpret is_active from common truthy values, and fill defaults for missing fields. If any record is invalid, raise ValueError with the indices of invalid records?","channel":"python","subChannel":"general","difficulty":"beginner","tags":["python"],"companies":["Apple","MongoDB","Uber"]},{"id":"q-474","question":"Write a Python function that takes a list of integers and returns the sum of all even numbers. How would you handle edge cases?","channel":"python","subChannel":"general","difficulty":"beginner","tags":["python"],"companies":["Bloomberg","Microsoft","Robinhood"]},{"id":"q-503","question":"How would you implement a distributed rate limiter using Redis with sliding window algorithm to handle 10,000 requests per second across multiple API servers?","channel":"python","subChannel":"general","difficulty":"advanced","tags":["python"],"companies":["Google","LinkedIn","Zoom"]},{"id":"q-559","question":"You're building a data processing pipeline that needs to handle large CSV files efficiently. How would you implement a memory-efficient solution using Python generators to process files that don't fit in RAM?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["Apple","Snap","Snowflake"]},{"id":"q-588","question":"How would you implement a rate limiter using Python's asyncio to prevent API abuse while maintaining high throughput?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["Apple","DoorDash","MongoDB"]},{"id":"q-852","question":"Design a memory-efficient streaming dedup pipeline in Python that reads a multi-GB log file line-by-line and prints only the first occurrence of each unique line, skipping duplicates, while persisting dedup state across restarts. Use a probabilistic data structure with a configurable false-positive rate and provide a minimal runnable snippet?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["IBM","MongoDB","Robinhood"]},{"id":"q-975","question":"Design an asynchronous NDJSON pipeline in Python that ingests lines of JSON from an async source, validates each line against a Pydantic model, applies a lightweight transform, and yields results to a downstream consumer. Ensure memory stays bounded when the consumer slows by using a bounded asyncio.Queue?","channel":"python","subChannel":"general","difficulty":"intermediate","tags":["python"],"companies":["Amazon","Coinbase","Stripe"]},{"id":"q-1048","question":"You're building a React Native field-ops app with intermittent connectivity that must display offline-first tasks with images and support incremental sync across devices. Describe architecture and provide a small implementation sketch using a local DB (WatermelonDB or Realm), a sync service, and conflict resolution. What edge cases and tests would you include?","channel":"react-native","subChannel":"general","difficulty":"intermediate","tags":["react-native"],"companies":["Google","Hugging Face","Tesla"]},{"id":"q-1065","question":"You're building a React Native app for live collaboration that streams up to 4 simultaneous camera feeds using WebRTC. Describe end-to-end architecture for capture, encoding, and transport, how you'd implement backpressure and frame pacing to sustain ~30fps per feed, and provide a small implementation sketch (camera hook + simple backpressure queue) in code?","channel":"react-native","subChannel":"general","difficulty":"intermediate","tags":["react-native"],"companies":["Discord","Google","NVIDIA"]},{"id":"q-1098","question":"You're building a React Native app for field technicians that must collect GPS and sensor data in the background every 15 minutes, even when the app is suspended. Describe a cross‑platform architecture using Android WorkManager and iOS BGTaskScheduler, a minimal RN bridge, and a small code sketch of a BackgroundTaskManager that schedules tasks, persists deadlines, and handles results. Include edge cases like battery saver, app termination, and user-initiated cancel?","channel":"react-native","subChannel":"general","difficulty":"advanced","tags":["react-native"],"companies":["Google","Microsoft"]},{"id":"q-1265","question":"You're building a real-time collaborative whiteboard in React Native that must support up to 1,000 participants with low latency and offline fallback. Describe an end-to-end architecture using WebRTC data channels for deltas, WebSocket signaling, and a CRDT for merging concurrent strokes. Include data model (stroke encoding, timestamps), backpressure handling, and a small code sketch implementing a delta encoder and an in-app delta queue that feeds an RN Canvas/Skia surface, with clear acceptance criteria?","channel":"react-native","subChannel":"general","difficulty":"advanced","tags":["react-native"],"companies":["Cloudflare","Two Sigma"]},{"id":"q-475","question":"You're building a React Native app with complex animations that need to run at 60fps. The app has multiple animated components including a custom carousel, gesture-driven interactions, and background video processing. How would you optimize performance to maintain smooth animations?","channel":"react-native","subChannel":"general","difficulty":"advanced","tags":["react-native"],"companies":["Amazon","Google","NVIDIA"]},{"id":"q-504","question":"How would you implement a custom button component in React Native that handles both iOS and Android platform-specific styling while maintaining consistent behavior?","channel":"react-native","subChannel":"general","difficulty":"beginner","tags":["react-native"],"companies":["Meta","Robinhood","Stripe"]},{"id":"q-533","question":"How would you optimize a React Native app with 50+ screens that's experiencing slow navigation and memory leaks, particularly on lower-end devices?","channel":"react-native","subChannel":"general","difficulty":"advanced","tags":["react-native"],"companies":["Citadel","PayPal"]},{"id":"q-560","question":"You're building a React Native app that needs to display a list of user profiles with images. The list should be performant with 1000+ items and support pull-to-refresh. How would you implement this using FlatList and what optimizations would you apply?","channel":"react-native","subChannel":"general","difficulty":"intermediate","tags":["react-native"],"companies":["Databricks","Microsoft"]},{"id":"q-589","question":"How do you handle different screen sizes and orientations in React Native?","channel":"react-native","subChannel":"general","difficulty":"beginner","tags":["react-native"],"companies":["Hashicorp","Instacart","LinkedIn"]},{"id":"q-183","question":"What are Native Modules in React Native, when should you use them, and what are the key performance and threading considerations?","channel":"react-native","subChannel":"native-modules","difficulty":"beginner","tags":["native","bridge"],"companies":null},{"id":"q-206","question":"How would you optimize React Native list performance with Hermes and Reanimated when dealing with 10k+ items containing complex animations?","channel":"react-native","subChannel":"performance","difficulty":"advanced","tags":["hermes","reanimated","profiling"],"companies":["Airbnb","Coinbase","Meta","Microsoft","Uber"]},{"id":"q-233","question":"How does the Hermes engine improve React Native app startup performance compared to JavaScriptCore, and what are the specific trade-offs?","channel":"react-native","subChannel":"performance","difficulty":"beginner","tags":["hermes","reanimated","profiling"],"companies":["Airbnb","Meta","Microsoft","Netflix","Salesforce","Shopify"]},{"id":"q-1023","question":"Design a centralized, tamper-evident logging pipeline for 6 RHEL hosts. Include: enable persistent journald, forward logs over TLS to a central collector, configure rotation/retention, protect in transit with certificate-based auth, and a rollback/validation plan that proves delivery during outages. Outline testing steps and failure scenarios?","channel":"rhcsa","subChannel":"general","difficulty":"advanced","tags":["rhcsa"],"companies":["Apple","Hashicorp"]},{"id":"q-1118","question":"On a RHEL 9 host, a service named app writes to /srv/app/data. After deployment, SELinux denials prevent writes. Without disabling SELinux, outline exact, implementable steps to restore functionality, including identifying the AVC, creating a targeted policy module with audit2allow, loading it, labeling the data directory, and validating the fix with a controlled write and audit checks?","channel":"rhcsa","subChannel":"general","difficulty":"advanced","tags":["rhcsa"],"companies":["Apple","Hugging Face","Twitter"]},{"id":"q-1148","question":"On a RHEL 8 server, implement a daily backup of /home/userdata to /backup/userdata-YYYYMMDD.tgz, exclude caches and temp dirs, preserve permissions, and generate a sha256 checksum. Schedule at 02:30 via cron and rotate backups to keep last 7 days. Provide commands and a script outline?","channel":"rhcsa","subChannel":"general","difficulty":"beginner","tags":["rhcsa"],"companies":["Goldman Sachs","Instacart","Lyft"]},{"id":"q-1169","question":"Design and implement an encrypted root on LVM for a production RH host. Boot partition remains unencrypted; the root filesystem sits on a LUKS2 container inside an LVM PV, with a keyfile for unattended boot. Provide a concrete, command-level plan including crypttab, fstab, initramfs (dracut) generation, and grub configuration to ensure the system boots automatically after rotation?","channel":"rhcsa","subChannel":"general","difficulty":"advanced","tags":["rhcsa"],"companies":["Bloomberg","Plaid","Snap"]},{"id":"q-1192","question":"On a RHEL8 host, set up a minimal Python HTTP server listening on port 8080, accessible only from 192.168.100.0/24. Use a non-root user, a systemd service, SELinux port labeling, and firewalld rules. Provide exact commands to create the service, configure semanage for port 8080, apply firewall rules, and test from a client. Address potential SELinux and port conflict caveats?","channel":"rhcsa","subChannel":"general","difficulty":"beginner","tags":["rhcsa"],"companies":["Instacart","LinkedIn"]},{"id":"q-1247","question":"On a RHEL 8 server, a web service listens on 127.0.0.1:9090. Configure firewalld to expose port 9090 only to the 10.1.0.0/24 management network, log drops, and persist across reboots. Provide exact commands, and describe test steps using curl from an allowed host and from a non-allowed host?","channel":"rhcsa","subChannel":"general","difficulty":"beginner","tags":["rhcsa"],"companies":["Amazon","Snap"]},{"id":"q-933","question":"On a fresh RHEL 9 installation with a 120 GB disk, implement an LVM layout: ROOT 40G, HOME 40G, VAR 40G, all using XFS. Create PV, VG, and LVs, format, and mount at /, /home, /var with fstab. Enable and configure firewalld to allow http and https. Ensure SELinux is enforcing. Create a non-root user 'dev' and add to the wheel group with sudo privileges. Show commands and rationale?","channel":"rhcsa","subChannel":"general","difficulty":"intermediate","tags":["rhcsa"],"companies":["Adobe","IBM","Microsoft"]},{"id":"gh-24","question":"What is DevSecOps and how does it differ from traditional DevOps security approaches?","channel":"security","subChannel":"application-security","difficulty":"advanced","tags":["security","devsecops"],"companies":["Amazon","Coinbase","Google","Microsoft","Uber"]},{"id":"gh-44","question":"How do you implement a comprehensive API security strategy that protects against common vulnerabilities while maintaining developer productivity?","channel":"security","subChannel":"application-security","difficulty":"beginner","tags":["api","service-mesh"],"companies":["Amazon","Microsoft","Morgan Stanley","PayPal","Stripe"]},{"id":"gh-69","question":"How does Zero Trust Security implement identity-based access control with micro-segmentation using modern cloud infrastructure and identity providers?","channel":"security","subChannel":"application-security","difficulty":"advanced","tags":["security","network"],"companies":null},{"id":"q-230","question":"How would you implement a Content Security Policy (CSP) with nonce-based inline script protection to prevent XSS while maintaining compatibility with third-party analytics?","channel":"security","subChannel":"application-security","difficulty":"intermediate","tags":["xss","csrf","sqli","ssrf"],"companies":["Airbnb","Google","Microsoft","Stripe","Uber"]},{"id":"q-276","question":"How would you design a secure job scheduling system for a microservices environment that prevents privilege escalation while ensuring reliable execution across distributed services?","channel":"security","subChannel":"application-security","difficulty":"advanced","tags":["systemd","cron","users","permissions"],"companies":null},{"id":"q-283","question":"What is the difference between XSS and CSRF attacks?","channel":"security","subChannel":"application-security","difficulty":"beginner","tags":["xss","csrf","sqli","ssrf"],"companies":["Amazon","Google","Meta"]},{"id":"q-359","question":"You discover a reflected XSS vulnerability in a search feature. The search term is displayed back to the user without sanitization. How would you fix this, and what's the difference between reflected XSS and stored XSS in terms of impact and remediation?","channel":"security","subChannel":"application-security","difficulty":"intermediate","tags":["xss","csrf","sqli","ssrf"],"companies":["Fortinet","Google","Tesla"]},{"id":"q-404","question":"You're building a financial trading platform at Jane Street. How would you design a secure authentication and authorization system that prevents XSS, CSRF, SQLi, and SSRF attacks while maintaining high performance for real-time trading data?","channel":"security","subChannel":"application-security","difficulty":"advanced","tags":["xss","csrf","sqli","ssrf"],"companies":["Canva","Jane Street","Miro"]},{"id":"q-423","question":"You discovered a critical security vulnerability in your team's production system that could expose customer data, but fixing it requires delaying a major product launch. How would you handle this situation, considering CVSS scoring, stakeholder communication, and risk-benefit analysis?","channel":"security","subChannel":"application-security","difficulty":"advanced","tags":["ownership","bias-for-action","customer-obsession"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-202","question":"How do passkeys implement passwordless authentication using public-key cryptography?","channel":"security","subChannel":"authentication","difficulty":"beginner","tags":["mfa","passkeys","zero-trust"],"companies":["Apple","Google","Meta","Microsoft","Okta"]},{"id":"q-241","question":"How would you implement JWT authentication with RS256 signing and refresh token rotation to prevent token replay attacks?","channel":"security","subChannel":"authentication","difficulty":"intermediate","tags":["jwt","oauth2","oidc","saml"],"companies":["Airbnb","Amazon","Apple","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-302","question":"Explain the technical differences between OAuth 2.0 authorization flows and OpenID Connect authentication, including token structures, validation patterns, and security considerations?","channel":"security","subChannel":"authentication","difficulty":"beginner","tags":["jwt","oauth2","oidc","saml"],"companies":["Amazon","Google","Meta","Microsoft","Salesforce","Stripe"]},{"id":"q-324","question":"How would you design a zero-trust video conferencing platform using WebAuthn passkeys with continuous authentication for enterprise users?","channel":"security","subChannel":"authentication","difficulty":"advanced","tags":["mfa","passkeys","zero-trust"],"companies":["Snowflake","Spotify","Zoom"]},{"id":"q-387","question":"Design a zero-trust authentication system for Snowflake's data warehouse that supports MFA, passkeys, and handles 100M+ daily auth requests. How would you prevent replay attacks while ensuring sub-100ms latency?","channel":"security","subChannel":"authentication","difficulty":"advanced","tags":["mfa","passkeys","zero-trust"],"companies":["Infosys","New Relic","Snowflake"]},{"id":"gh-70","question":"How does the TLS 1.3 handshake establish secure communication and what cryptographic mechanisms ensure perfect forward secrecy?","channel":"security","subChannel":"encryption","difficulty":"advanced","tags":["security","network"],"companies":["Amazon","Cloudflare","Google","Hashicorp","Netflix","Square"]},{"id":"q-179","question":"Explain how Perfect Forward Secrecy (PFS) works in TLS, describe the ECDHE key exchange mechanism, and analyze the security trade-offs compared to RSA key exchange?","channel":"security","subChannel":"encryption","difficulty":"intermediate","tags":["encryption","crypto"],"companies":["Amazon","Apple","Cloudflare","Google","Microsoft","Stripe"]},{"id":"q-295","question":"How does AES-256-GCM provide both confidentiality and integrity in a single cryptographic operation?","channel":"security","subChannel":"encryption","difficulty":"advanced","tags":["aes","rsa","tls","hashing"],"companies":["Amazon","Google","Meta"]},{"id":"q-310","question":"How does TLS 1.3 improve security compared to TLS 1.2?","channel":"security","subChannel":"encryption","difficulty":"intermediate","tags":["aes","rsa","tls","hashing"],"companies":["Amazon","Google","Meta"]},{"id":"q-337","question":"Design a secure key exchange system for autonomous vehicle communication between cars and infrastructure. How would you handle forward secrecy and key rotation in a high-mobility environment?","channel":"security","subChannel":"encryption","difficulty":"advanced","tags":["aes","rsa","tls","hashing"],"companies":["Apple","Cruise","Uber"]},{"id":"q-348","question":"You're designing a secure booking system for Expedia that handles payment data. How would you implement a hybrid encryption scheme using RSA for key exchange and AES-256-GCM for data encryption, and what specific security considerations would you address for PCI DSS compliance?","channel":"security","subChannel":"encryption","difficulty":"advanced","tags":["aes","rsa","tls","hashing"],"companies":["Amazon","Apple","Expedia","Microsoft","OpenAI","PayPal","Square","Stripe"]},{"id":"q-1234","question":"You operate a CDN edge platform that lets customers deploy WebAssembly modules for request processing. Outline a practical, auditable approach to securely load, validate, and sandbox these modules, covering authentication (signatures/attestation), host-function access, resource quotas, revocation, and incident response?","channel":"security","subChannel":"general","difficulty":"advanced","tags":["security"],"companies":["Apple","Cloudflare","Microsoft"]},{"id":"q-476","question":"How would you prevent SQL injection in a web application and what are the common attack vectors?","channel":"security","subChannel":"general","difficulty":"beginner","tags":["security"],"companies":["Lyft","Netflix"]},{"id":"q-505","question":"You're building a payment processing API that must handle PCI compliance. How would you design the architecture to ensure sensitive card data never touches your servers while maintaining low latency for payment validation?","channel":"security","subChannel":"general","difficulty":"advanced","tags":["security"],"companies":["Hugging Face","Microsoft","Square"]},{"id":"q-534","question":"How would you implement secure session management in a distributed web application to prevent session hijacking and fixation attacks?","channel":"security","subChannel":"general","difficulty":"intermediate","tags":["security"],"companies":["Airbnb","Google","Two Sigma"]},{"id":"q-561","question":"How would you implement secure session management for a web application using JWT tokens, and what are the key security considerations?","channel":"security","subChannel":"general","difficulty":"intermediate","tags":["security"],"companies":["Discord","MongoDB"]},{"id":"gh-71","question":"How does a Web Application Firewall (WAF) protect against OWASP Top 10 attacks at the application layer?","channel":"security","subChannel":"owasp","difficulty":"advanced","tags":["security","network"],"companies":["Akamai","Amazon","Cloudflare","Google","Microsoft"]},{"id":"q-255","question":"How would you implement OWASP ASVS L3 input validation for a REST API endpoint that accepts JSON payloads with nested objects?","channel":"security","subChannel":"owasp","difficulty":"intermediate","tags":["top10","asvs","samm"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-373","question":"How would you implement a comprehensive defense-in-depth strategy to prevent SQL injection attacks in a modern web application following OWASP Top 10 guidelines?","channel":"security","subChannel":"owasp","difficulty":"beginner","tags":["top10","asvs","samm"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"q-1086","question":"Design a Snowflake CDC pattern for an SCD2 customer_dim using a stream on the source table. Explain how to implement an idempotent upsert via MERGE, how deletes are represented, and how to handle late-arriving changes to preserve history?","channel":"snowflake-core","subChannel":"general","difficulty":"intermediate","tags":["snowflake-core"],"companies":["Google","NVIDIA"]},{"id":"q-1152","question":"Design a least-privilege access layer in Snowflake for a multi-tenant data lake spanning five domains (marketing, sales, finance, analytics, operations). Describe how you would implement ROW ACCESS POLICIES and MASKING POLICIES on a payments table (columns: id, customer_id, amount, card_number, region) to restrict data by region and user role, and how you would audit access?","channel":"snowflake-core","subChannel":"general","difficulty":"advanced","tags":["snowflake-core"],"companies":["Adobe","Databricks","Lyft"]},{"id":"q-1239","question":"You’re building a beginner Snowflake task: a large SALES table is routinely queried with date-range filters. Propose a minimal clustering solution to improve pruning. Include exact commands to add a single clustering key on SALE_DATE, how to monitor its effectiveness, and how to decide if reclustering is needed. Keep changes focused and explain validation steps with a simple test?","channel":"snowflake-core","subChannel":"general","difficulty":"beginner","tags":["snowflake-core"],"companies":["Hugging Face","PayPal"]},{"id":"q-868","question":"Design a cross-account data-sharing solution in Snowflake for a multinational fintech requiring regional affiliates to access a shared dataset containing PII. How would you implement Secure Data Sharing, dynamic data masking, region-specific RBAC, and auditable access, while enabling updates to masking policies without breaking consumer queries?","channel":"snowflake-core","subChannel":"general","difficulty":"advanced","tags":["snowflake-core"],"companies":["Coinbase","Microsoft"]},{"id":"q-981","question":"How would you configure Snowflake so regional analysts can run ad-hoc queries on a shared dataset while ensuring isolation, predictable performance, and cost control? Include concrete settings for: (a) warehouse topology (min/max clusters, auto-suspend/resume), (b) RBAC (roles, grant scopes on databases/schemas/tables), (c) cost governance (resource monitors and credit caps), (d) a sample GRANT script giving REGIONAL_ANALYST access to only SALES and EVENTS schemas, and (e) auditing and reproducibility considerations?","channel":"snowflake-core","subChannel":"general","difficulty":"beginner","tags":["snowflake-core"],"companies":["Anthropic","Cloudflare","Robinhood"]},{"id":"q-305","question":"How would you determine the required capacity for a service expecting 10x traffic growth during a product launch?","channel":"sre","subChannel":"capacity-planning","difficulty":"beginner","tags":["forecasting","autoscaling","load-testing"],"companies":["Amazon","Google","Meta"]},{"id":"sr-131","question":"You're managing a microservices platform with 50 services. Service A has a 95th percentile latency of 200ms and handles 10,000 RPS. It calls Service B (50ms, 5,000 RPS) and Service C (100ms, 3,000 RPS). During Black Friday, you expect 5x traffic. Service A's CPU utilization is currently 60%, memory at 70%. How do you plan capacity to maintain <500ms 95th percentile end-to-end latency?","channel":"sre","subChannel":"capacity-planning","difficulty":"advanced","tags":["capacity","scaling"],"companies":["Amazon","Google","Meta","Microsoft","Uber"]},{"id":"sr-143","question":"Your web application currently handles 1000 requests per minute during peak hours. Each request takes an average of 200ms to process. If you expect traffic to double in the next 6 months, how many additional server instances do you need if each server can handle 50 concurrent requests?","channel":"sre","subChannel":"capacity-planning","difficulty":"beginner","tags":["capacity","scaling"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"sr-149","question":"You're designing capacity planning for a microservices platform handling 10M daily active users. Each user generates 50 API calls/day with 80% during peak hours. How many instances do you need for each service?","channel":"sre","subChannel":"capacity-planning","difficulty":"advanced","tags":["capacity","scaling"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-218","question":"How would you design a chaos engineering experiment to test database failover while maintaining transaction consistency across a microservices architecture?","channel":"sre","subChannel":"chaos-engineering","difficulty":"advanced","tags":["chaos-monkey","litmus","gremlin"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-399","question":"You're using Litmus Chaos to test a microservices application. One of your chaos experiments is causing unexpected cascading failures across multiple services. How would you debug this issue and what specific steps would you take to limit the blast radius?","channel":"sre","subChannel":"chaos-engineering","difficulty":"intermediate","tags":["chaos-monkey","litmus","gremlin"],"companies":["Airtable","Fortinet","Tempus"]},{"id":"sr-146","question":"Design a chaos engineering experiment to test the resilience of a microservices-based e-commerce platform during a database partition event. How would you ensure the experiment doesn't cause customer data loss while still providing meaningful insights?","channel":"sre","subChannel":"chaos-engineering","difficulty":"advanced","tags":["chaos","resilience"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"sr-150","question":"You're implementing chaos engineering for a distributed payment system processing $10M daily transactions. Design a chaos experiment to test resilience against Byzantine failures where 30% of payment validation nodes provide conflicting consensus results. How would you ensure financial accuracy while testing system behavior under adversarial conditions?","channel":"sre","subChannel":"chaos-engineering","difficulty":"advanced","tags":["chaos","resilience"],"companies":["Amazon","Coinbase","Microsoft","Netflix","Stripe"]},{"id":"sr-153","question":"You're implementing chaos engineering for a microservices architecture. Your payment service has a 99.9% SLA. During a chaos experiment, you inject 500ms latency into 20% of requests to the database. The service starts timing out after 1 second. What's the most critical metric to monitor first, and what would indicate the experiment should be stopped immediately?","channel":"sre","subChannel":"chaos-engineering","difficulty":"intermediate","tags":["chaos","resilience"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-477","question":"You're running a chaos experiment in production. How do you determine the blast radius and ensure you don't impact customer experience while still getting meaningful failure data?","channel":"sre","subChannel":"general","difficulty":"intermediate","tags":["sre"],"companies":["Goldman Sachs","Google","LinkedIn"]},{"id":"q-506","question":"You're on-call and receive an alert that a critical service is experiencing 99% error rate. What are your immediate first steps and how do you approach incident response?","channel":"sre","subChannel":"general","difficulty":"beginner","tags":["sre"],"companies":["IBM","Scale Ai"]},{"id":"q-535","question":"You're an SRE at Netflix and notice your CDN cache hit ratio dropped from 95% to 70% during peak hours. How would you diagnose and resolve this issue?","channel":"sre","subChannel":"general","difficulty":"advanced","tags":["sre"],"companies":["Discord","Netflix","Snowflake"]},{"id":"q-590","question":"How would you design a canary deployment strategy for a microservice handling 10K RPS with 99.99% SLA requirements?","channel":"sre","subChannel":"general","difficulty":"advanced","tags":["sre"],"companies":["Bloomberg","Google","Twitter"]},{"id":"gh-65","question":"What is Mean Time to Recovery (MTTR), how do you calculate it, and what specific strategies would you implement to optimize it for SRE teams?","channel":"sre","subChannel":"incident-management","difficulty":"beginner","tags":["metrics","kpi"],"companies":null},{"id":"gh-97","question":"How do you design incident response playbooks that balance automation with human oversight for SRE teams?","channel":"sre","subChannel":"incident-management","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-262","question":"Describe a critical production outage you managed during peak traffic. How did you coordinate the response, communicate with stakeholders, and implement both immediate fixes and long-term preventive measures?","channel":"sre","subChannel":"incident-management","difficulty":"advanced","tags":["situation","task","action","result"],"companies":["Amazon","Cloudflare","Google","Microsoft","Netflix","Oracle"]},{"id":"q-319","question":"You are on-call and receive a high-severity PagerDuty alert for a production service degradation. What are your immediate steps and how do you coordinate with the team?","channel":"sre","subChannel":"incident-management","difficulty":"advanced","tags":["pagerduty","runbooks","postmortem"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Servicenow","Stripe","Wipro"]},{"id":"q-367","question":"You're managing a multi-cluster GitOps setup at Warner Bros with 50+ microservices. ArgoCD suddenly starts showing 'Unknown' sync status for critical services during peak traffic. How would you diagnose and resolve this production incident while ensuring zero downtime?","channel":"sre","subChannel":"incident-management","difficulty":"advanced","tags":["argocd","flux","declarative"],"companies":["Amazon","Google","Hashicorp","LinkedIn","Microsoft","Netflix","Salesforce","Warner Bros"]},{"id":"q-368","question":"You're on-call at Tesla when the vehicle telemetry pipeline shows 95% packet loss. Your PagerDuty alert shows the Kafka cluster is healthy, but the downstream processing service is crashing. What's your immediate triage process and how do you determine if this is a network, application, or data format issue?","channel":"sre","subChannel":"incident-management","difficulty":"intermediate","tags":["pagerduty","runbooks","postmortem"],"companies":["Discord","Tesla","Zscaler"]},{"id":"sr-126","question":"How would you design and implement a comprehensive blameless postmortem process that includes incident response coordination, root cause analysis using 5 Whys and fishbone diagrams, and actionable improvement tracking?","channel":"sre","subChannel":"incident-management","difficulty":"advanced","tags":["incident","postmortem"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"sr-142","question":"You receive a PagerDuty alert at 3 AM: 'Production API is returning 500 errors'. What are your first three steps in handling this incident, and what specific tools and metrics would you use to assess impact and coordinate response?","channel":"sre","subChannel":"incident-management","difficulty":"beginner","tags":["incident","postmortem"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"gh-19","question":"What is monitoring in DevOps and how does it differ from observability?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["observability","monitoring","logging"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-20","question":"Design a comprehensive logging architecture using the ELK Stack with File Beats for a high-traffic e-commerce platform processing 50,000 requests per minute. How would you ensure data integrity and real-time monitoring?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["observability","monitoring","logging"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"gh-21","question":"How does Prometheus implement a pull-based monitoring system, and what are the key components in its architecture?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["observability","monitoring","logging"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-22","question":"What is Grafana and how does it integrate with different data sources for monitoring and visualization?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["observability","monitoring","logging"],"companies":["Airbnb","LinkedIn","Microsoft","Stripe","Uber"]},{"id":"gh-23","question":"Explain the key differences between monitoring and logging in DevOps, and when would you use each?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["observability","monitoring","logging"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-61","question":"What are Service Level Indicators (SLIs) and how do they differ from SLOs?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["sre","reliability"],"companies":["Amazon","Google","Meta"]},{"id":"gh-77","question":"How would you design a comprehensive monitoring strategy for a distributed system, including tool selection, SLI/SLO definition, and alerting implementation?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["monitoring","infra"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"gh-78","question":"How would you design a comprehensive monitoring strategy for a production microservices system, including SLI/SLO definitions and alerting thresholds?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["monitoring","infra"],"companies":["Amazon","Cloudflare","Google","Microsoft","Netflix","Stripe"]},{"id":"gh-79","question":"What is Application Performance Monitoring?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["monitoring","infra"],"companies":["Amazon","Datadog","Google","Microsoft","Splunk"]},{"id":"gh-95","question":"What is a Service Level Indicator (SLI)?","channel":"sre","subChannel":"observability","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Citadel","Goldman Sachs","Google","Microsoft"]},{"id":"gh-99","question":"What is Tracing in Observability?","channel":"sre","subChannel":"observability","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Goldman Sachs","Netflix","Stripe","Uber"]},{"id":"q-192","question":"How would you implement OpenTelemetry instrumentation to capture RED metrics (Rate, Errors, Duration) for a microservice using Prometheus as the backend?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["prometheus","grafana","opentelemetry"],"companies":["Chronosphere","Datadog","Grafana Labs","Microsoft","New Relic"]},{"id":"q-244","question":"What is the difference between metrics, logs, and traces in observability, and how do OpenTelemetry collectors correlate them?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["prometheus","grafana","opentelemetry"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"q-345","question":"You're monitoring a streaming service that suddenly experiences 500 errors. How would you use Prometheus and Grafana to quickly identify the root cause?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["prometheus","grafana","opentelemetry"],"companies":["Amazon","Cloudflare","Google","Infosys","Microsoft","Netflix","Warner Bros"]},{"id":"q-382","question":"You're the SRE lead for a rocket launch telemetry system. Prometheus is showing high memory usage on your OpenTelemetry collector during peak launch events, causing metric loss. How would you architect a solution to handle 100K+ metrics/second while ensuring zero data loss during critical launch windows?","channel":"sre","subChannel":"observability","difficulty":"advanced","tags":["prometheus","grafana","opentelemetry"],"companies":["Notion","OpenAI","SpaceX"]},{"id":"q-391","question":"You're an SRE at HashiCorp and your Prometheus alerts are firing every 5 minutes due to a memory leak in a Go service using OpenTelemetry. How would you debug this using the observability stack?","channel":"sre","subChannel":"observability","difficulty":"intermediate","tags":["prometheus","grafana","opentelemetry"],"companies":["Hashicorp","Instacart","Western Digital"]},{"id":"q-411","question":"You're on-call and receive an alert: 'API response time increased from 200ms to 2s over the last 5 minutes'. Using Prometheus, Grafana, and OpenTelemetry, how would you diagnose this issue?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["prometheus","grafana","opentelemetry"],"companies":["Amazon","Cloudflare","Google","Intel","Microsoft","Netflix","Palo Alto Networks","Stripe"]},{"id":"sr-124","question":"How would you implement the four golden signals of monitoring in a production microservices architecture, and what trade-offs would you consider when designing your observability strategy?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["metrics","monitoring"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"sr-133","question":"How do you implement the three pillars of observability (logs, metrics, traces) in a microservices architecture, and what are the key trade-offs between them?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["metrics","monitoring"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Snowflake"]},{"id":"sr-155","question":"What is the difference between metrics, logs, and traces in observability, and when would you use each?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["metrics","monitoring"],"companies":["Amazon","Bloomberg","Datadog","Goldman Sachs","Google","Microsoft","Netflix","New Relic","Splunk","Uber"]},{"id":"sre-1","question":"How would you design and implement SRE monitoring with SLIs, SLOs, and SLAs for a high-traffic e-commerce platform? What specific metrics would you track and how would they drive engineering decisions?","channel":"sre","subChannel":"observability","difficulty":"beginner","tags":["metrics","policy","definitions","observability"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"gh-103","question":"What is a Self-Healing System and how does it work in distributed architectures?","channel":"sre","subChannel":"reliability","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Uber"]},{"id":"gh-35","question":"Design a backup and disaster recovery strategy for a high-availability e-commerce platform processing 10,000 transactions/minute with 99.99% uptime SLA. What are your RTO/RPO targets and how would you implement multi-region failover?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["backup","dr"],"companies":["Amazon","Google","Meta"]},{"id":"gh-59","question":"What is Site Reliability Engineering and how does it differ from traditional operations?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["sre","reliability"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-60","question":"How do you design and implement Service Level Objectives (SLOs) with proper SLI definitions, error budgets, and monitoring strategies?","channel":"sre","subChannel":"reliability","difficulty":"intermediate","tags":["sre","reliability"],"companies":null},{"id":"gh-62","question":"What is an Error Budget and how does it impact SRE decision-making?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["sre","reliability"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-63","question":"What is Toil in Site Reliability Engineering and how should SREs approach managing it?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["sre","reliability"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-93","question":"How do you implement and monitor Service Level Agreements (SLAs) in a distributed system, including specific metrics, tools, and alerting strategies?","channel":"sre","subChannel":"reliability","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Cloudflare","Datadog","Google","Microsoft","Netflix"]},{"id":"gh-94","question":"What is a Service Level Objective (SLO) and how does it differ from an SLA?","channel":"sre","subChannel":"reliability","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-270","question":"Your microservice has a 99.9% availability SLO over 30 days with a 1-hour burn rate alert threshold. If you experience a 10-minute outage at 10% traffic, how much error budget remains and what's the burn rate? Should you alert?","channel":"sre","subChannel":"reliability","difficulty":"intermediate","tags":["slo","sli","error-budget"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"q-290","question":"Explain the relationship between SLIs, SLOs, and SLAs in reliability engineering, including how you would implement error budgets and monitor burn rate?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["slo","sli","error-budget"],"companies":["Amazon","Apple","Cloudflare","Google","Microsoft","Netflix"]},{"id":"q-333","question":"Your SLO for API response time is 99.9% with a 500ms threshold. You're at 99.7% and the error budget is exhausted. The product team wants to ship a new feature that will increase traffic by 20%. How do you handle this situation?","channel":"sre","subChannel":"reliability","difficulty":"intermediate","tags":["slo","sli","error-budget"],"companies":["Atlassian","Databricks","Unity"]},{"id":"q-355","question":"Your SLO is 99.9% for API latency (p95 < 200ms). You're at 99.85% and have 15% error budget remaining. A critical security patch requires 30% traffic shift to new version with unknown latency characteristics. How do you proceed while maintaining service reliability?","channel":"sre","subChannel":"reliability","difficulty":"advanced","tags":["slo","sli","error-budget"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"sr-130","question":"Your web service has an SLO of 99.9% availability over 30 days. You've had 3 outages: 45 minutes, 20 minutes, and 15 minutes. What's your current availability, error budget status, and what immediate actions would you take to prevent SLO breach?","channel":"sre","subChannel":"reliability","difficulty":"intermediate","tags":["slo","sli","error-budget"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"sr-147","question":"Your distributed system has 5 microservices with the following failure rates: Service A (0.1%), Service B (0.2%), Service C (0.05%), Service D (0.15%), Service E (0.25%). Design a fault-tolerant architecture to achieve 99.5% SLO with specific implementation details?","channel":"sre","subChannel":"reliability","difficulty":"advanced","tags":["reliability","incident"],"companies":["Amazon","Databricks","Google","Meta","Microsoft","Netflix"]},{"id":"sr-154","question":"Your API serves 10M requests/day with a 99.9% availability SLO and 30-day error budget. After a 4-hour outage affecting 100% of traffic, calculate the remaining error budget and explain how you'd handle post-incident SLO adjustments, error budget recovery strategies, and burn rate monitoring?","channel":"sre","subChannel":"reliability","difficulty":"intermediate","tags":["slo","sli","error-budget"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"sr-169","question":"Your API service has an SLO of 99.9% availability. If you have 5 incidents this month with downtimes of 10min, 5min, 15min, 8min, and 12min, did you meet your SLO and what's the remaining error budget for the rest of the month?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["slo","sli","error-budget"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Salesforce"]},{"id":"sre-2","question":"How do you calculate and manage Error Budgets for a microservices architecture with multiple SLOs, and what strategies do you use for burn rate monitoring and recovery?","channel":"sre","subChannel":"reliability","difficulty":"beginner","tags":["management","concept","risk"],"companies":["Adobe","Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"gh-45","question":"How do rate limiting algorithms like Token Bucket and Leaky Bucket control API request flow and what are their trade-offs?","channel":"system-design","subChannel":"api-design","difficulty":"beginner","tags":["api","service-mesh"],"companies":["Amazon","Google","Microsoft","Stripe","Uber"]},{"id":"q-406","question":"Design a REST API for a cryptocurrency exchange that handles 100,000 trades per day with real-time price updates. How would you ensure data consistency and handle high-frequency trading requests?","channel":"system-design","subChannel":"api-design","difficulty":"beginner","tags":["api","rest","grpc","graphql"],"companies":["Coinbase","Oracle","Twilio"]},{"id":"q-424","question":"Design a RESTful API for a hotel booking system. What endpoints would you create and how would you handle concurrent bookings for the same room?","channel":"system-design","subChannel":"api-design","difficulty":"beginner","tags":["api","rest","grpc","graphql"],"companies":["Airbnb","Amazon","Booking.com","Google","Microsoft"]},{"id":"q-507","question":"Design a unified API gateway for Databricks that supports REST, gRPC, and GraphQL with protocol translation, rate limiting, and unified authentication?","channel":"system-design","subChannel":"api-design","difficulty":"advanced","tags":["api","rest","grpc","graphql"],"companies":["Databricks","IBM"]},{"id":"sy-151","question":"Design a rate limiting API for a multi-tenant SaaS platform where different customers have different rate limits (free: 100 req/hour, premium: 1000 req/hour, enterprise: custom). How would you design the API endpoints and data structures to efficiently track and enforce these limits?","channel":"system-design","subChannel":"api-design","difficulty":"intermediate","tags":["api","rest"],"companies":["Amazon","Google","Microsoft","Stripe","Uber"]},{"id":"q-604","question":"Design a rate limiting system for a public API that can handle 10,000 requests per second with different rate limits for free and paid tiers (100 requests/minute for free, 1000 requests/minute for paid). How would you implement this to ensure fairness and prevent abuse?","channel":"system-design","subChannel":"api-rate-limiting","difficulty":"intermediate","tags":["rate-limiting","api-design","distributed-systems","redis","token-bucket"],"companies":["Twitter","Stripe","GitHub","Google","Amazon"]},{"id":"q-597","question":"Design a distributed caching system for a global e-commerce platform that handles 100,000 requests per second with 99.9% availability. How would you handle cache consistency, invalidation strategies, and failover across multiple geographic regions?","channel":"system-design","subChannel":"cache-architecture","difficulty":"advanced","tags":["distributed-systems","caching","redis","high-availability","consistency","scalability"],"companies":["Amazon","Google","Meta","Netflix","Uber","Airbnb","Spotify","Twitter"]},{"id":"q-603","question":"Design a distributed caching system for a global e-commerce platform that serves 10 million daily active users. The system must handle product catalog caching with 99.99% availability, sub-millisecond latency for hot items, and cache consistency across multiple data centers.","channel":"system-design","subChannel":"cache-architecture","difficulty":"advanced","tags":["distributed-systems","caching","redis","high-availability","consistency"],"companies":["Amazon","Netflix","Google","Meta","Microsoft","Uber","Airbnb"]},{"id":"q-621","question":"Design a distributed caching system for a social media platform that needs to handle 10 million active users with 99.9% availability. How would you ensure cache consistency across multiple data centers while minimizing latency?","channel":"system-design","subChannel":"cache-architecture","difficulty":"intermediate","tags":["distributed-systems","caching","consistency","scalability","high-availability"],"companies":["Facebook","Twitter","LinkedIn","Reddit","Instagram"]},{"id":"q-634","question":"Design a distributed caching system for a global e-commerce platform that serves 10 million requests per second with 99.99% availability. The system must handle cache consistency across multiple data centers, support cache warming for popular products, and provide graceful degradation when cache nodes fail.","channel":"system-design","subChannel":"cache-architecture","difficulty":"advanced","tags":["distributed-systems","caching","consistency","high-availability","scalability"],"companies":["Amazon","Netflix","Google","Meta","Microsoft","Uber"]},{"id":"q-169","question":"Design a caching strategy for a high-traffic e-commerce platform handling 10,000 RPS. Compare cache-aside vs read-through patterns, including write-through considerations, consistency guarantees, and performance implications. When would you choose each pattern and what are the trade-offs?","channel":"system-design","subChannel":"caching","difficulty":"beginner","tags":["cache","redis"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-213","question":"Design a multi-tier caching strategy for a 99.9% availability e-commerce platform handling 10M requests/day with 100ms P99 latency. How would you implement cache warming, invalidation, and fallback mechanisms?","channel":"system-design","subChannel":"caching","difficulty":"advanced","tags":["cache","redis","memcached","cdn"],"companies":null},{"id":"q-231","question":"How would you design a multi-region CDN cache purging system that guarantees content propagation within 5 seconds while handling 10,000 concurrent invalidations per second?","channel":"system-design","subChannel":"caching","difficulty":"intermediate","tags":["edge","caching","purging"],"companies":["Amazon","Cloudflare","Google","Meta","Microsoft","Netflix"]},{"id":"q-299","question":"How would you design a caching layer for a high-traffic e-commerce website?","channel":"system-design","subChannel":"caching","difficulty":"beginner","tags":["cache","redis","memcached","cdn"],"companies":["Amazon","Google","Meta"]},{"id":"q-392","question":"Design a distributed caching layer for Fortinet's threat intelligence system that serves 50M security devices with real-time malware signatures and threat data. How would you ensure cache consistency across global edge locations while maintaining sub-50ms response times?","channel":"system-design","subChannel":"caching","difficulty":"advanced","tags":["cache","redis","memcached","cdn"],"companies":["Fortinet","Microsoft","Tesla"]},{"id":"q-417","question":"Design a distributed caching strategy for a global e-commerce platform handling 10M daily users with frequent price/inventory updates. How would you ensure cache consistency, handle invalidation, and optimize performance across regions?","channel":"system-design","subChannel":"caching","difficulty":"intermediate","tags":["cache","redis","memcached","cdn"],"companies":null},{"id":"q-441","question":"Design a distributed caching layer for a social media feed serving 10M DAU with 99.9% availability. How would you handle cache invalidation across multiple data centers?","channel":"system-design","subChannel":"caching","difficulty":"advanced","tags":["cache","redis","memcached","cdn"],"companies":["Apple","LinkedIn","Two Sigma"]},{"id":"q-478","question":"Design a caching layer for a product catalog API serving 10K requests/second with 100K products. How would you handle cache invalidation and ensure data consistency?","channel":"system-design","subChannel":"caching","difficulty":"beginner","tags":["cache","redis","memcached","cdn"],"companies":["Instacart","Plaid"]},{"id":"q-601","question":"Design a communication strategy for a microservices-based e-commerce platform where the Order Service needs to notify the Inventory Service, Payment Service, and Notification Service when a new order is placed. How would you handle communication failures and ensure data consistency?","channel":"system-design","subChannel":"distributed-communication","difficulty":"intermediate","tags":["microservices","event-driven","distributed-systems","message-brokers","saga-pattern"],"companies":["Amazon","Netflix","Uber","Spotify","Airbnb"]},{"id":"q-625","question":"Design a distributed rate limiter for a high-traffic API that can handle 10,000 requests per second with per-user, per-IP, and per-endpoint limits. How would you ensure accuracy and prevent race conditions across multiple servers?","channel":"system-design","subChannel":"distributed-rate-limiting","difficulty":"intermediate","tags":["rate-limiting","distributed-systems","api-gateway","redis","token-bucket"],"companies":["Google","Amazon","Meta","Microsoft","Netflix"]},{"id":"gh-43","question":"Design an API Gateway for a high-traffic e-commerce platform handling 10M daily requests. How would you implement rate limiting, circuit breakers, and service discovery while ensuring 99.9% availability and sub-100ms latency?","channel":"system-design","subChannel":"distributed-systems","difficulty":"intermediate","tags":["api","service-mesh"],"companies":null},{"id":"q-189","question":"How would you design a distributed transaction system using the Saga pattern for an e-commerce platform handling inventory, payment, and shipping services, ensuring exactly-once processing and eventual consistency?","channel":"system-design","subChannel":"distributed-systems","difficulty":"beginner","tags":["saga","cqrs","event-sourcing"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-238","question":"How does Raft consensus algorithm ensure leader election and log replication in distributed systems?","channel":"system-design","subChannel":"distributed-systems","difficulty":"beginner","tags":["dist-sys","cap-theorem","consensus"],"companies":["Airbnb","Amazon","Apple","Cockroach Labs","Etcd","Google","Meta","Microsoft","Netflix","Uber"]},{"id":"q-260","question":"Design a scalable Selenium Grid architecture to handle 10,000 concurrent test sessions with 99.9% uptime, ensuring zero memory leaks through automatic session lifecycle management, real-time monitoring, and graceful node failure recovery across multiple data centers?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["selenium","webdriver","grid"],"companies":["Amazon","Google","Microsoft","Netflix","Salesforce","Snowflake"]},{"id":"q-282","question":"Design an event sourcing system for a high-throughput e-commerce platform handling 10,000 orders/second with 99.99% availability. How would you implement the event store, handle versioning, and ensure event ordering while supporting replay and recovery?","channel":"system-design","subChannel":"distributed-systems","difficulty":"intermediate","tags":["event-sourcing","distributed-systems","architecture","cqrs","immutability"],"companies":["Amazon","Databricks","Microsoft","Netflix","Salesforce","Stripe"]},{"id":"q-313","question":"How would you design a distributed chat system like Slack that handles real-time messaging with strong consistency guarantees across global deployments?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["dist-sys","cap-theorem","consensus"],"companies":null},{"id":"q-352","question":"Design a distributed order processing system using Saga pattern for a high-frequency trading platform. How would you handle compensation transactions when a market data feed fails mid-transaction?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["saga","cqrs","event-sourcing"],"companies":["Citadel","Tcs","Western Digital"]},{"id":"q-435","question":"You're building a ride-sharing service similar to Lyft. How would you design the database architecture to handle 10,000 concurrent rides with real-time location updates? What sharding strategy would you use?","channel":"system-design","subChannel":"distributed-systems","difficulty":"beginner","tags":["scaling","sharding","replication"],"companies":["Amazon","Google","Lyft","Meta","Netflix","Salesforce","Uber"]},{"id":"q-536","question":"Design a distributed consensus service for a ride-sharing platform handling 10M concurrent rides with real-time location updates. How do you ensure consistency across geo-distributed data centers while maintaining <100ms latency?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["dist-sys","cap-theorem","consensus"],"companies":["LinkedIn","Lyft","Meta"]},{"id":"q-612","question":"How would you design a communication pattern for a microservices architecture where services need to maintain real-time data consistency while handling high-throughput requests?","channel":"system-design","subChannel":"distributed-systems","difficulty":"intermediate","tags":["microservices","communication-patterns","event-driven","consistency","message-queues"],"companies":["Netflix","Uber","Amazon","Twitter"]},{"id":"sd-2","question":"Design a distributed caching system using Consistent Hashing. How would you handle node failures, load balancing, and ensure minimal data movement when scaling from 10 to 100 nodes?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["hashing","dist-sys","caching"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"sd-3","question":"Explain the CAP Theorem. Can you really 'choose two' and what are the practical tradeoffs?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["theory","dist-sys","database"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"sd-4","question":"Design a database sharding strategy for a social media platform with 100M+ users. How would you handle data distribution, cross-shard queries, and rebalancing?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["db","scale","architecture"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"sd-5","question":"Design a distributed rate limiter for a microservices API handling 10,000 RPS with 99.9% availability using Redis Cluster. How would you handle cache invalidation, circuit breakers, and multi-region consistency?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["security","api","algorithms"],"companies":["Amazon","Cloudflare","Google","Meta","Netflix","Stripe"]},{"id":"sy-132","question":"Design a distributed rate limiting system that can handle 1M+ requests per second across multiple data centers while maintaining consistency and low latency. How would you handle burst traffic, different rate limiting algorithms (token bucket, sliding window), and ensure fair distribution across users?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["api","rest"],"companies":["Amazon","Google","Meta","Microsoft","Uber"]},{"id":"sy-137","question":"Design a distributed system that provides exactly-once processing guarantees for event streams with out-of-order delivery and network partitions. How would you handle idempotency, deduplication, and causal consistency across multiple processing nodes?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["dist-sys","architecture"],"companies":["Goldman Sachs","LinkedIn","Netflix","Stripe","Uber"]},{"id":"sy-138","question":"Design a distributed rate limiting system that can handle 10M requests per minute across 100+ microservices with different rate limit policies per service. How would you ensure high availability, consistency, and sub-millisecond latency while handling failures and scaling?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["api","rest"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"sy-139","question":"Design a rate limiting system for a multi-tenant API serving 100M+ daily calls across 5 regions, supporting tiered rate limits (1000-100K RPS), burst capacity (3x sustained rate), sub-50ms latency, and 99.99% availability using distributed token bucket algorithm?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["api","rest"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"sy-140","question":"Design a rate limiting service that can handle 10 million requests per second with distributed consistency across multiple data centers. The service should support multiple rate limiting strategies (token bucket, sliding window, fixed window) and provide sub-millisecond latency. How would you architect this to handle bursts, prevent thundering herd problems, and ensure accurate global rate limits?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["api","rest"],"companies":["Amazon","Google","Meta","Microsoft","Stripe"]},{"id":"sy-141","question":"Design a globally distributed serverless platform for real-time collaborative document editing with offline support and conflict resolution. How would you handle data consistency, versioning, and low-latency synchronization across AWS regions while maintaining sub-50ms response times?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["infra","scale"],"companies":["Amazon","Dropbox","Google","Meta","Microsoft"]},{"id":"sy-158","question":"Design a distributed rate limiter that can handle 1M requests/second across 100 data centers with <10ms latency. How do you ensure accurate rate limiting while avoiding coordination overhead?","channel":"system-design","subChannel":"distributed-systems","difficulty":"advanced","tags":["dist-sys","architecture"],"companies":["Amazon","Google","Meta","Microsoft","Uber"]},{"id":"q-622","question":"How would you design communication between microservices when you need to ensure data consistency across multiple services, and what patterns would you consider?","channel":"system-design","subChannel":"distributed-transactions","difficulty":"intermediate","tags":["microservices","distributed-systems","data-consistency","saga-pattern","event-driven"],"companies":["Netflix","Amazon","Uber","LinkedIn","Spotify"]},{"id":"gh-14","question":"How would you design a scalable cloud platform architecture that integrates compute, storage, networking, and database services?","channel":"system-design","subChannel":"infrastructure","difficulty":"beginner","tags":["cloud","aws","azure","gcp"],"companies":["Amazon","Google","Meta"]},{"id":"gh-84","question":"Design a cloud-native modernization strategy for a 10M-user monolithic e-commerce platform requiring 99.9% uptime. How would you migrate to microservices while maintaining business continuity and optimizing costs?","channel":"system-design","subChannel":"infrastructure","difficulty":"beginner","tags":["migration","cloud"],"companies":null},{"id":"gh-91","question":"How would you design a comprehensive feature flagging system that supports both server-side and client-side flags with proper performance considerations?","channel":"system-design","subChannel":"infrastructure","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-265","question":"How would you design a unified system monitoring dashboard that aggregates real-time process metrics, system call tracing, and network connection data from htop, strace, and lsof?","channel":"system-design","subChannel":"infrastructure","difficulty":"intermediate","tags":["top","htop","strace","lsof"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-316","question":"How would you design a database architecture to handle 10 million users with 99.99% uptime? What sharding and replication strategies would you use?","channel":"system-design","subChannel":"infrastructure","difficulty":"beginner","tags":["scaling","sharding","replication"],"companies":["Chime","Salesforce","Snowflake"]},{"id":"q-327","question":"Design a simple API rate limiter that can handle 10,000 requests per second. How would you prevent abuse while ensuring legitimate users aren't blocked?","channel":"system-design","subChannel":"infrastructure","difficulty":"beginner","tags":["infra","scale","distributed"],"companies":["Salesforce","Square","Supabase"]},{"id":"q-562","question":"Design a real-time vehicle telemetry system for Tesla's fleet of 10M cars collecting sensor data at 100Hz?","channel":"system-design","subChannel":"infrastructure","difficulty":"advanced","tags":["infra","scale","distributed"],"companies":["Apple","Tesla"]},{"id":"q-619","question":"What is an ambient mesh and how does it differ from traditional service mesh architectures?","channel":"system-design","subChannel":"infrastructure","difficulty":"intermediate","tags":["service-mesh","kubernetes","infrastructure","networking"],"companies":["Google","IBM","Microsoft"]},{"id":"sy-169","question":"Design a URL shortening service that handles 1 billion URLs with 10M daily requests, achieving 99.99% uptime. How would you architect the system for high availability and scalability?","channel":"system-design","subChannel":"infrastructure","difficulty":"beginner","tags":["infra","scale"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-607","question":"Design a communication strategy for a microservices architecture where you have 10+ services that need to exchange data. What patterns would you use and why?","channel":"system-design","subChannel":"inter-service-communication","difficulty":"intermediate","tags":["microservices","communication-patterns","system-design","event-driven","api-gateway"],"companies":["Netflix","Amazon","Uber","Spotify","Airbnb"]},{"id":"q-617","question":"Design a communication pattern for a microservices architecture where an order service needs to notify inventory, payment, and shipping services when a new order is placed. Discuss the trade-offs between synchronous REST calls, message queues, and event streaming.","channel":"system-design","subChannel":"inter-service-communication","difficulty":"intermediate","tags":["microservices","communication-patterns","distributed-systems","message-queues","event-streaming"],"companies":["Netflix","Amazon","Uber","LinkedIn","Spotify"]},{"id":"gh-33","question":"How do different load balancing algorithms distribute traffic across servers, and what are the trade-offs between performance and resource utilization?","channel":"system-design","subChannel":"load-balancing","difficulty":"advanced","tags":["scale","ha"],"companies":["Amazon","Goldman Sachs","Google","Microsoft","Netflix"]},{"id":"q-285","question":"How would you design a load balancer that handles 1M concurrent connections using NGINX vs HAProxy?","channel":"system-design","subChannel":"load-balancing","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"companies":["Amazon","Google","Meta"]},{"id":"q-376","question":"Design a load balancing system for a global e-commerce platform handling 50M concurrent users during Black Friday sales. How would you ensure zero downtime while handling 10x traffic spikes?","channel":"system-design","subChannel":"load-balancing","difficulty":"advanced","tags":["lb","traffic","nginx","haproxy"],"companies":["Hashicorp","Thoughtworks","Workday"]},{"id":"q-393","question":"Design a global load balancer for Google Cloud that handles 10M concurrent connections with sub-10ms failover across 5 regions. How would you ensure zero-downtime deployments while maintaining 99.999% availability?","channel":"system-design","subChannel":"load-balancing","difficulty":"advanced","tags":["lb","traffic","nginx","haproxy"],"companies":null},{"id":"q-591","question":"How would you design a load balancer for a microservices architecture handling 10,000 requests per second with 99.99% uptime?","channel":"system-design","subChannel":"load-balancing","difficulty":"intermediate","tags":["lb","traffic","nginx","haproxy"],"companies":["Anthropic","Oracle","Tesla"]},{"id":"q-598","question":"Design a load balancer for a high-traffic e-commerce platform that must handle 100,000 requests per second with 99.99% uptime. Explain how you would choose between round-robin, least connections, and weighted round-robin algorithms, and describe your failover strategy.","channel":"system-design","subChannel":"load-balancing-algorithms","difficulty":"intermediate","tags":["load-balancing","system-design","scalability","high-availability","algorithms"],"companies":["Amazon","Google","Meta","Netflix","Microsoft","Uber","Airbnb"]},{"id":"q-605","question":"Design a load balancer for a high-traffic e-commerce website that must handle 100,000 requests per second with 99.99% uptime. Explain which load balancing algorithm you would choose and why, considering factors like session persistence, health checks, and failover mechanisms.","channel":"system-design","subChannel":"load-balancing-algorithms","difficulty":"intermediate","tags":["load-balancing","system-design","scalability","high-availability","algorithms"],"companies":["Amazon","Google","Netflix","Meta","Microsoft","Apple"]},{"id":"q-615","question":"Design a load balancer for a high-traffic e-commerce website. Which load balancing algorithm would you choose and why? How would you handle session persistence and failover?","channel":"system-design","subChannel":"load-balancing-algorithms","difficulty":"intermediate","tags":["load-balancing","system-design","high-availability","scalability","algorithms"],"companies":["Amazon","Google","Meta","Netflix","Uber","Airbnb"]},{"id":"q-609","question":"Design a load balancer for a high-traffic e-commerce platform. Which load balancing algorithm would you choose and why? Consider factors like session persistence, server health, and traffic distribution.","channel":"system-design","subChannel":"load-balancing-strategies","difficulty":"intermediate","tags":["load-balancing","algorithms","system-design","high-availability","scalability"],"companies":["Amazon","Google","Netflix","Meta","Microsoft","Apple"]},{"id":"q-610","question":"Design a load balancer for a high-traffic e-commerce platform. Which load balancing algorithm would you choose and why? Consider the trade-offs between different algorithms.","channel":"system-design","subChannel":"load-balancing-strategies","difficulty":"intermediate","tags":["load-balancing","algorithms","system-design","scalability","high-availability"],"companies":["Amazon","Google","Netflix","Meta","Microsoft"]},{"id":"q-266","question":"Design a distributed message queue system that handles 1M events/sec with exactly-once delivery, sub-second latency, and 99.99% availability. How would you ensure data consistency across partitions while handling consumer failures and network partitions?","channel":"system-design","subChannel":"message-queues","difficulty":"intermediate","tags":["kafka","rabbitmq","sqs","pubsub"],"companies":["Amazon","Google","Meta","Microsoft","Netflix"]},{"id":"q-361","question":"Design a distributed message queue system for processing 10M financial transactions per hour with exactly-once delivery guarantees across multiple data centers. How would you handle message ordering, deduplication, and cross-region consistency?","channel":"system-design","subChannel":"message-queues","difficulty":"advanced","tags":["kafka","rabbitmq","sqs","pubsub"],"companies":["Amazon","Broadcom","Google","Netflix","PayPal","Robinhood","Stripe","Western Digital"]},{"id":"q-432","question":"Design a food delivery app's order processing system using message queues to handle 10,000 orders per minute with exactly-once processing?","channel":"system-design","subChannel":"message-queues","difficulty":"beginner","tags":["kafka","rabbitmq","sqs","pubsub"],"companies":["Lyft","Microsoft","Oracle"]},{"id":"q-623","question":"Design a communication strategy for a microservices architecture where some services need real-time updates while others can tolerate eventual consistency. What patterns would you use and how would you handle service discovery and load balancing?","channel":"system-design","subChannel":"microservices-architecture","difficulty":"intermediate","tags":["microservices","communication-patterns","service-discovery","load-balancing","consistency"],"companies":["Netflix","Amazon","Uber","Spotify","Airbnb"]},{"id":"q-616","question":"Design a CI/CD pipeline for a microservices application with 10 services, each with its own repository. The pipeline must support parallel deployments, canary releases, automated testing, and rollback capabilities. How would you ensure zero-downtime deployments and maintain consistency across services?","channel":"system-design","subChannel":"pipeline-architecture","difficulty":"advanced","tags":["cicd","microservices","kubernetes","devops","gitops"],"companies":["Google","Netflix","Amazon","Microsoft","Uber","Airbnb"]},{"id":"q-631","question":"Design a CI/CD pipeline for a microservices application with 10 services. Each service has its own repository and needs automated testing, security scanning, and deployment to both staging and production environments. How would you ensure fast feedback loops while maintaining quality and security?","channel":"system-design","subChannel":"pipeline-architecture","difficulty":"intermediate","tags":["cicd","microservices","devops","security","automation"],"companies":["Google","Amazon","Microsoft","Netflix","Spotify","Uber"]},{"id":"q-626","question":"Compare and contrast synchronous vs asynchronous communication patterns in microservices, and when would you choose one over the other?","channel":"system-design","subChannel":"service-communication","difficulty":"intermediate","tags":["microservices","communication-patterns","system-design","architecture"],"companies":["Netflix","Amazon","Uber","Spotify","Airbnb"]},{"id":"q-632","question":"Design a communication strategy for a microservices architecture where you have an Order Service, Payment Service, and Inventory Service. The Order Service needs to coordinate with both Payment and Inventory services to process an order. What communication patterns would you use and why?","channel":"system-design","subChannel":"service-communication","difficulty":"intermediate","tags":["microservices","communication-patterns","system-design","async-messaging","api-design"],"companies":["Netflix","Amazon","Uber","Spotify","Airbnb"]},{"id":"q-639","question":"How would you design a distributed caching system for a real-time analytics platform that processes streaming event data from millions of IoT devices, requiring sub-10ms query latency for time-series aggregations while handling high write throughput and ensuring data freshness?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["distributed-caching","time-series","real-time-analytics","iot","write-through"],"companies":[]},{"id":"q-645","question":"Design a distributed caching system for a real-time collaborative editing platform (like Google Docs) that must handle concurrent edits from thousands of users on the same document while maintaining strong consistency and sub-10ms latency. How would you handle conflict resolution, version control, and cache invalidation when multiple users edit the same document simultaneously?","channel":"system-design","subChannel":"system-design","difficulty":"advanced","tags":["distributed-caching","real-time-collaboration","conflict-resolution","operational-transformation","strong-consistency"],"companies":[]},{"id":"q-646","question":"Design a rate limiting system for a real-time chat application that needs to handle different types of messages with varying limits: text messages (100/min), file uploads (10/min), and API calls (1000/min). How would you implement a multi-tier rate limiter that prevents spam while ensuring critical messages (like emergency alerts) are always delivered?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["rate-limiting","real-time-systems","token-bucket","redis","priority-queues"],"companies":[]},{"id":"q-647","question":"Design a rate limiting system for a video streaming platform that needs to limit API calls based on both user subscription tier (free: 1000 calls/day, premium: 10000 calls/day) AND content type (video uploads: 10/hour, metadata queries: 100/minute). How would you implement multi-dimensional rate limiting while ensuring fair usage and preventing abuse?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["rate-limiting","redis","multi-dimensional","api-gateway","token-bucket"],"companies":[]},{"id":"q-649","question":"How would you design a communication pattern for a microservices architecture where services need to handle both request-response interactions and event-driven updates, while ensuring backward compatibility during API version transitions?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["microservices","api-versioning","hybrid-communication","backward-compatibility","system-design"],"companies":[]},{"id":"q-650","question":"Design a rate limiting system for a video streaming platform that needs to limit API calls based on both user tier (free/premium) and content type (metadata vs video transcoding requests). How would you implement a multi-dimensional rate limiter that can handle 100K concurrent users with different limits per content type while preventing abuse and ensuring fair resource allocation?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["rate-limiting","redis","multi-dimensional","user-tiers","content-aware"],"companies":[]},{"id":"q-658","question":"How would you design a multi-tier distributed caching strategy for a microservices architecture where different services have varying access patterns and consistency requirements?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["distributed-caching","microservices","cache-tiers","consistency-patterns"],"companies":[]},{"id":"q-764","question":"Design a rate limiting system for a content delivery network (CDN) that needs to enforce different limits based on content type and geographic region. Static assets (images, CSS) can serve 10,000 req/min globally, while dynamic API endpoints have stricter limits: 1,000 req/min per region for North America, 500 req/min for Europe, and 200 req/min for Asia-Pacific. How would you implement a hierarchical rate limiter that balances global fairness with regional capacity constraints?","channel":"system-design","subChannel":"system-design","difficulty":"intermediate","tags":["rate-limiting","cdn","geo-distribution","redis","hierarchical-limits"],"companies":[]},{"id":"q-1015","question":"Design a TensorFlow 2.x data pipeline for a document-classification model trained on 8 GPUs with MirroredStrategy. Data comes from two sources: TFRecords with image_raw and a CSV with per-record numeric metadata. Build a single tf.data pipeline that yields a dict {'image': image_tensor, 'meta': meta_tensor}, with image decoded and resized to 224x224 and scaled to [0,1], metadata normalized, deterministic per-epoch shuffling with a fixed seed, interleaving sources with parallelism, caching, and prefetching. Then implement gradient accumulation to reach a global batch size of 1024 while per-replica batch size is 128, and outline reproducibility checks and simple throughput measurements. Provide key code blocks?","channel":"tensorflow-developer","subChannel":"general","difficulty":"intermediate","tags":["tensorflow-developer"],"companies":["Bloomberg","Meta","Microsoft"]},{"id":"q-1072","question":"You're deploying a TensorFlow 2.x recommender with dense features and a massive sparse feature 'item_id'. The item vocabulary comes from Redis and updates in real time without downtime. Describe a practical serving approach that keeps latency under 20 ms, handles unseen IDs gracefully, and updates embeddings without restarting the service. Include a minimal code sketch showing how to load a Redis-backed vocabulary into a tf.lookup MutableHashTable and map incoming IDs to embeddings inside a tf.function?","channel":"tensorflow-developer","subChannel":"general","difficulty":"intermediate","tags":["tensorflow-developer"],"companies":["Adobe","Tesla"]},{"id":"q-1103","question":"Scenario: You have a dataset of short audio clips stored as WAV files in data/train/{class}/*.wav. As a beginner TensorFlow developer, implement a minimal end-to-end solution: (1) a tf.data pipeline that reads file paths and infers the label from the parent directory, (2) loads WAVs as mono, (3) pads/trims to 16000 samples, (4) normalizes to [-1,1], (5) shuffles with a fixed seed, (6) caches and prefetches, (7) batches 32. Then define a tiny Conv1D classifier for 2 classes and show how to train with model.fit using the pipeline. Include only the essential code blocks?","channel":"tensorflow-developer","subChannel":"general","difficulty":"beginner","tags":["tensorflow-developer"],"companies":["Meta","MongoDB"]},{"id":"q-1168","question":"You’re building a TensorFlow model that jointly processes images and captions stored in a CSV with columns: image_path, caption, label. Implement an efficient tf.data pipeline that (1) reads the CSV, (2) loads and decodes images from disk with aspect-ratio-preserving resize to 224x224, (3) tokenizes captions using a saved BPE tokenizer loaded from a file, (4) pads captions to the max length within each batch, (5) caches, (6) shuffles with a fixed seed, (7) batches 64, (8) runs under a multi-GPU distribution strategy. Provide the core code blocks and discuss performance trade-offs?","channel":"tensorflow-developer","subChannel":"general","difficulty":"intermediate","tags":["tensorflow-developer"],"companies":["Amazon","Google"]},{"id":"q-1252","question":"You are training a large Transformer-based recommender model on multiple GPUs with a custom training loop in TensorFlow 2.x. The per-device batch is 256, but you want an effective global batch of 4096. Describe and implement how to use gradient accumulation to achieve this, including how to adjust the learning rate, BN handling, and mixed-precision considerations?","channel":"tensorflow-developer","subChannel":"general","difficulty":"advanced","tags":["tensorflow-developer"],"companies":["NVIDIA","Snap"]},{"id":"q-857","question":"You’re deploying a multimodal TensorFlow 2.x Keras model that consumes an image [N,224,224,3] and a text embedding [N,128] to TensorFlow Serving on Kubernetes. Explain how to export a SavedModel with a serving_default signature that accepts a dict input {'image': ..., 'text': ...} and a separate 'predict_dense' signature for A/B testing. Include concrete input signatures, how to create concrete_functions, and how to manage versioning for backward compatibility?","channel":"tensorflow-developer","subChannel":"general","difficulty":"advanced","tags":["tensorflow-developer"],"companies":["DoorDash","Meta","Slack"]},{"id":"q-943","question":"You're running distributed TensorFlow training with tf.distribute.MultiWorkerMirroredStrategy across 8 workers. Intermittent batch loss suggests non-deterministic per-worker data sharding and uneven batch boundaries. Describe a concrete fix: deterministic sharding, fixed seeds, per-replica batch sizing, and validation steps; specify exact API calls, TF_CONFIG handling, and how you'll verify convergence is repeatable?","channel":"tensorflow-developer","subChannel":"general","difficulty":"advanced","tags":["tensorflow-developer"],"companies":["Airbnb","Citadel"]},{"id":"q-966","question":"How would you deploy a text classifier in TF2 that must support vocab expansion without retraining? Provide a single SavedModel with two signatures: 'predict' for input {'texts': tf.Tensor<String>} and 'extend_vocab' for {'new_tokens': tf.Tensor<String>, 'vectors': tf.Tensor<float>}. Explain embedding resizing, token→id mapping, stateful management, and versioning; include a minimal code outline?","channel":"tensorflow-developer","subChannel":"general","difficulty":"intermediate","tags":["tensorflow-developer"],"companies":["Citadel","Hugging Face","Oracle"]},{"id":"q-992","question":"You’re building a beginner TensorFlow image classifier. The dataset sits under data/train with subfolders per class (e.g., cat/dog). Write a minimal tf.data pipeline that (1) reads image files with automatic label inference, (2) decodes and resizes to 224x224, (3) scales pixels to [0,1], (4) shuffles with a fixed seed for reproducibility, (5) batches 32, and (6) caches to speed training. Include the key code blocks?","channel":"tensorflow-developer","subChannel":"general","difficulty":"beginner","tags":["tensorflow-developer"],"companies":["Anthropic","Snowflake","Tesla"]},{"id":"do-3","question":"What is Infrastructure as Code (IaC) and why is Terraform preferred over manual infrastructure management?","channel":"terraform","subChannel":"basics","difficulty":"beginner","tags":["infra","automation","terraform"],"companies":["Airbnb","Amazon","Google","Meta","Microsoft","Netflix","Stripe","Uber"]},{"id":"gh-17","question":"What is Terraform and how does it implement Infrastructure as Code (IaC) workflows?","channel":"terraform","subChannel":"basics","difficulty":"beginner","tags":["iac","terraform","ansible"],"companies":["Airbnb","Databricks","Goldman Sachs","Microsoft","Snowflake"]},{"id":"de-137","question":"You have a Terraform configuration that creates an AWS S3 bucket. After running 'terraform apply', you realize you need to add versioning to the bucket. What's the safest way to modify your existing infrastructure?","channel":"terraform","subChannel":"best-practices","difficulty":"beginner","tags":["terraform","iac"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix"]},{"id":"q-272","question":"How would you implement a DRY Terraform configuration using Terragrunt and Atlantis for multi-environment deployments?","channel":"terraform","subChannel":"best-practices","difficulty":"intermediate","tags":["dry","terragrunt","atlantis"],"companies":["Amazon","Google","Netflix","Stripe"]},{"id":"q-284","question":"Design a production-grade Terraform architecture for a multi-environment AWS infrastructure with 100+ resources, including state management, CI/CD integration, and security controls. How would you handle state locking, workspace strategy, and deployment validation?","channel":"terraform","subChannel":"best-practices","difficulty":"advanced","tags":["infrastructure-as-code","automation","best-practices"],"companies":["Amazon","Google","Hashicorp","Microsoft","Netflix","Snowflake"]},{"id":"q-1049","question":"In a multi-account AWS setup, a core Terraform module is versioned in a private registry and consumed by 12 workspaces. A regional failover requires a safe rollback to the previous core module version without drift. Describe the end-to-end strategy, including version pinning, CI validation, and state/rollback mechanisms?","channel":"terraform","subChannel":"general","difficulty":"advanced","tags":["terraform"],"companies":["Citadel","Goldman Sachs","Lyft"]},{"id":"q-1197","question":"In a multi-account AWS setup, a single Terraform repo provisions VPCs and IAM roles per environment using provider aliases. A governance rule requires per-environment tagging and automatic drift detection that blocks non-Terraform changes. Describe a concrete pattern to enforce per-account isolation, tagging, and drift guardrails, including provider aliasing, remote state per environment, and a PR-based drift test workflow?","channel":"terraform","subChannel":"general","difficulty":"intermediate","tags":["terraform"],"companies":["Citadel","Twitter"]},{"id":"q-1271","question":"You have a Terraform project that provisions an AWS VPC and a small app stack. You want developers to run the same config against their own environments using per-environment secrets (DB_PASSWORD, APP_SSH_KEY) that are never stored in git. Outline a minimal structure (files, vars, and commands) to supply these secrets safely, and explain how you prevent secrets from triggering plan changes or drift?","channel":"terraform","subChannel":"general","difficulty":"beginner","tags":["terraform"],"companies":["LinkedIn","Microsoft","Twitter"]},{"id":"q-479","question":"You're managing a multi-region infrastructure with 50+ Terraform modules. How would you design a strategy to handle state locking, drift detection, and safe deployments across regions while minimizing downtime?","channel":"terraform","subChannel":"general","difficulty":"advanced","tags":["terraform"],"companies":["Microsoft","Uber"]},{"id":"q-508","question":"You have a Terraform configuration that creates multiple EC2 instances across different availability zones. How would you implement a blue-green deployment strategy using Terraform workspaces and what are the key considerations?","channel":"terraform","subChannel":"general","difficulty":"intermediate","tags":["terraform"],"companies":["Citadel","PayPal","Scale Ai"]},{"id":"q-563","question":"You're deploying a simple web application using Terraform. How would you create an AWS EC2 instance with a security group that allows HTTP traffic on port 80?","channel":"terraform","subChannel":"general","difficulty":"beginner","tags":["terraform"],"companies":["Coinbase","Discord","Slack"]},{"id":"q-592","question":"How would you use Terraform variables to manage different environments (dev/staging/prod) while keeping your configuration DRY?","channel":"terraform","subChannel":"general","difficulty":"beginner","tags":["terraform"],"companies":["Oracle","Snowflake","Stripe"]},{"id":"q-854","question":"In a Terraform Cloud setup spanning AWS and GCP, you must enforce a cross-cloud policy: every resource must carry a non-empty 'cost-center' tag and new regions must not auto-create default VPCs. How would you implement drift detection, policy gating, and automatic remediation across workspaces without downtime?","channel":"terraform","subChannel":"general","difficulty":"intermediate","tags":["terraform"],"companies":["Amazon","Discord","Google"]},{"id":"q-983","question":"In a Terraform project that provisions an AWS S3 bucket, add a new boolean variable enable_sse to toggle server-side encryption; when enable_sse is true, the bucket should have server-side encryption AES256 enabled. How would you implement this in the bucket resource using Terraform 0.12+ syntax, ensuring existing deployments remain stable and the plan doesn't force unnecessary changes?","channel":"terraform","subChannel":"general","difficulty":"beginner","tags":["terraform"],"companies":["Microsoft","Tesla"]},{"id":"gh-105","question":"What is Infrastructure Drift and how do you detect and prevent it?","channel":"terraform","subChannel":"state-management","difficulty":"advanced","tags":["advanced","cloud"],"companies":["Amazon","Google","Microsoft","Netflix","Stripe"]},{"id":"q-175","question":"You have a Terraform configuration with multiple developers working on the same infrastructure. How would you implement remote state locking to prevent state corruption and enable team collaboration?","channel":"terraform","subChannel":"state-management","difficulty":"intermediate","tags":["state","backend"],"companies":["Amazon","Google","Microsoft","Stripe","Uber"]},{"id":"q-221","question":"How would you implement a zero-downtime blue-green deployment strategy using Terraform workspaces, remote state locking, and Atlantis for production-scale microservices?","channel":"terraform","subChannel":"state-management","difficulty":"advanced","tags":["dry","terragrunt","atlantis"],"companies":["Amazon","Google Cloud","Microsoft","Stripe","Uber"]},{"id":"q-247","question":"How does Terraform remote state prevent conflicts when multiple team members work on the same infrastructure, and what are the key mechanisms involved?","channel":"terraform","subChannel":"state-management","difficulty":"beginner","tags":["remote-state","locking","workspaces"],"companies":["Amazon","Hashicorp","Microsoft","Netflix","Stripe"]},{"id":"q-1009","question":"Scenario: a single repo provisions per-tenant AWS resources for many tenants. To isolate state without workspaces, use a shared S3 backend with a DynamoDB lock table and a tenant-scoped key. Describe the backend config (bucket, region, dynamodb_table, key pattern per tenant), how you detect drift across tenants, and CI gating for dev-to-prod promotions (plan -out, tests, approve, apply)?","channel":"terraform-associate","subChannel":"general","difficulty":"advanced","tags":["terraform-associate"],"companies":["Amazon","Coinbase","Databricks"]},{"id":"q-1154","question":"In a Terraform module that provisions an AWS RDS instance, operators sometimes alter maintenance_window directly in AWS, creating drift. You want Terraform to ignore external changes to maintenance_window but still apply code-driven updates (e.g., allocated_storage). How would you implement this using a lifecycle block? Provide a minimal aws_db_instance snippet showing ignore_changes for maintenance_window and outline tradeoffs?","channel":"terraform-associate","subChannel":"general","difficulty":"intermediate","tags":["terraform-associate"],"companies":["Salesforce","Scale Ai","Tesla"]},{"id":"q-1172","question":"In AWS us-east-1, you must provision 3 private subnets in a single VPC across 3 AZs using one module. Define a map variable with AZs and CIDRs, create the subnets with for_each, attach appropriate tags, and output the subnet IDs. Then show how to reference these IDs in a resource that requires subnet_id (eg NAT Gateway) and justify for_each vs count?","channel":"terraform-associate","subChannel":"general","difficulty":"beginner","tags":["terraform-associate"],"companies":["Netflix","Oracle"]},{"id":"q-1202","question":"Scenario: you must bring under Terraform management a set of existing AWS S3 buckets across teams. Some buckets already exist and must be imported; you will manage encryption and versioning with a single module using for_each over a bucket map. How would you import, structure, and promote changes safely via CI?","channel":"terraform-associate","subChannel":"general","difficulty":"advanced","tags":["terraform-associate"],"companies":["Amazon","NVIDIA","Robinhood"]},{"id":"q-864","question":"In Terraform, you need to manage two AWS accounts in a single repo: prod (provider aws.prod) and audit (provider aws.audit). Create an S3 bucket in prod and a cross-account IAM policy in audit that grants read access to that bucket. How do you configure aliased providers, reference the prod bucket ARN from the audit module, and enforce deterministic apply order (e.g., data fetch before policy) with minimal risk? Include a minimal config outline?","channel":"terraform-associate","subChannel":"general","difficulty":"intermediate","tags":["terraform-associate"],"companies":["Snap","Snowflake","Square"]},{"id":"q-960","question":"In a single Terraform repo that provisions prod, staging, and dev AWS environments, how would you configure a single S3 backend to isolate state for each environment without using separate Terraform workspaces? Provide the exact backend config (bucket, region, dynamodb_lock_table, key per env) and explain how you would promote changes from dev to prod, including drift handling and CI plan/apply steps?","channel":"terraform-associate","subChannel":"general","difficulty":"intermediate","tags":["terraform-associate"],"companies":["Bloomberg","Google","Hashicorp"]},{"id":"q-1033","question":"You build a small service that fetches user profiles via GET /api/users/{id} and caches results in memory for 5 minutes. Write concrete tests that verify: (1) a cache miss calls the API, stores the result with TTL; (2) a cache hit returns cached value without API call; (3) TTL expiry triggers a fresh API call to refresh cache. Provide example test code?","channel":"testing","subChannel":"general","difficulty":"beginner","tags":["testing"],"companies":["Google","Lyft","Netflix"]},{"id":"q-1076","question":"You implement a debounce utility in frontend code: debounce(fn, wait) returns a wrapper that ensures fn is called at most once per wait ms, using the last invocation's arguments. Write a focused test that demonstrates rapid successive calls do not trigger fn more than once, and that a final call after waiting triggers with the latest args?","channel":"testing","subChannel":"general","difficulty":"beginner","tags":["testing"],"companies":["DoorDash","Instacart","Oracle"]},{"id":"q-1287","question":"Design a testing strategy for a real-time data pipeline built with Apache Flink processing millions of events per second, ensuring exactly-once semantics across sources and sinks, handling out-of-order and late data, with stateful operators and checkpointing. Outline how you'd structure unit, integration, and end-to-end tests, simulate late data and failures, verify sink idempotence and recovery guarantees, and specify concrete tools and success criteria?","channel":"testing","subChannel":"general","difficulty":"advanced","tags":["testing"],"companies":["Amazon","Google","Scale Ai"]},{"id":"q-480","question":"How would you design a comprehensive testing strategy for a distributed microservices architecture handling 10M requests/day, ensuring 99.9% uptime while maintaining fast CI/CD pipelines?","channel":"testing","subChannel":"general","difficulty":"advanced","tags":["testing"],"companies":["Bloomberg","LinkedIn","NVIDIA"]},{"id":"q-509","question":"How would you test a REST API endpoint that creates a user account, including validation, error handling, and database integration?","channel":"testing","subChannel":"general","difficulty":"intermediate","tags":["testing"],"companies":["Amazon","Coinbase","Tesla"]},{"id":"q-537","question":"You're testing a real-time chat application that uses WebSockets. How would you design a test strategy to verify message ordering, connection resilience, and concurrent user scenarios?","channel":"testing","subChannel":"general","difficulty":"intermediate","tags":["testing"],"companies":["NVIDIA","Twitter","Two Sigma"]},{"id":"q-593","question":"How would you test a function that makes HTTP requests to an external API? What testing strategies would you use?","channel":"testing","subChannel":"general","difficulty":"intermediate","tags":["testing"],"companies":["Apple","Microsoft"]},{"id":"q-990","question":"You maintain a Node.js API function getUser(userId) that reads from MongoDB via Mongoose and caches the result in an in-memory TTL cache (60s). Write a practical test plan and code to verify: (1) first call hits DB and caches, (2) second call returns cached value, (3) after TTL expires a new DB hit occurs and cache updates, (4) DB error propagates to caller. Use Jest with minimal mocks and demonstrate time-control?","channel":"testing","subChannel":"general","difficulty":"beginner","tags":["testing"],"companies":["Airbnb","MongoDB"]},{"id":"q-259","question":"How would you design integration tests for a Saga pattern implementation across 5 microservices to ensure exactly-once transaction processing and proper compensation handling during partial failures?","channel":"testing","subChannel":"integration-testing","difficulty":"advanced","tags":["api-testing","database-testing","mocking"],"companies":["Airbnb","Amazon","LinkedIn","Netflix","Spotify","Twitter","Uber"]},{"id":"q-207","question":"How would you implement a test-driven development workflow for a REST API endpoint using Jest and Supertest, following the red-green-refactor cycle with proper test organization and mocking strategies?","channel":"testing","subChannel":"tdd","difficulty":"intermediate","tags":["test-driven","red-green-refactor","test-first"],"companies":["Amazon","Google","Meta","Microsoft","Netflix","Stripe"]},{"id":"q-360","question":"You're building a simple calculator class. Write a failing test first, then implement the add method using TDD. What's the red-green-refactor cycle?","channel":"testing","subChannel":"tdd","difficulty":"beginner","tags":["test-driven","red-green-refactor","test-first"],"companies":["Amazon","Anthropic","Google","Meta","Microsoft","Salesforce","Stripe"]},{"id":"q-405","question":"You're building a real-time collaborative drawing feature where multiple users can simultaneously edit a canvas. How would you apply TDD to test the conflict resolution mechanism when two users edit the same element at the same time?","channel":"testing","subChannel":"tdd","difficulty":"intermediate","tags":["test-driven","red-green-refactor","test-first"],"companies":["Canva","Unity","Zoom"]},{"id":"q-234","question":"How would you design a scalable test architecture for a microservices application handling 10,000+ concurrent tests across multiple environments while ensuring test isolation, performance, and CI/CD integration?","channel":"testing","subChannel":"test-strategies","difficulty":"advanced","tags":["jest","mocha","pytest","junit"],"companies":["Amazon","Google","Microsoft","Netflix","Salesforce","Stripe"]},{"id":"q-278","question":"How would you design a comprehensive testing strategy for a microservices architecture that scales to handle millions of requests per second while ensuring 99.99% availability?","channel":"testing","subChannel":"test-strategies","difficulty":"advanced","tags":["test-pyramid","coverage","mutation-testing"],"companies":["Amazon","Google","Meta","Netflix"]},{"id":"q-325","question":"How would you implement mutation testing to validate your test suite's quality and what's the relationship between mutation testing and code coverage?","channel":"testing","subChannel":"test-strategies","difficulty":"advanced","tags":["test-pyramid","coverage","mutation-testing"],"companies":["Epic Systems","Jane Street","Western Digital"]},{"id":"q-349","question":"You're building a distributed event streaming platform similar to Kafka. How would you design a comprehensive testing strategy that ensures message ordering guarantees, exactly-once semantics, and fault tolerance across a cluster of brokers?","channel":"testing","subChannel":"test-strategies","difficulty":"advanced","tags":["test-pyramid","coverage","mutation-testing"],"companies":["Confluent","Epic Games","Meta"]},{"id":"q-374","question":"You're testing a ServiceNow form validation module. How would you structure your test pyramid and what coverage metrics would you track?","channel":"testing","subChannel":"test-strategies","difficulty":"beginner","tags":["test-pyramid","coverage","mutation-testing"],"companies":["Amazon","Google","Microsoft","Netflix","Okta","Salesforce","Servicenow"]},{"id":"q-416","question":"You're building a React component library. How would you structure your test pyramid and what specific coverage metrics would you target for each layer?","channel":"testing","subChannel":"test-strategies","difficulty":"beginner","tags":["test-pyramid","coverage","mutation-testing"],"companies":["Broadcom","Hugging Face","Meta"]},{"id":"q-296","question":"In Jest, how would you implement advanced mocking patterns including sequential return values, async behavior, and proper mock lifecycle management for comprehensive test coverage?","channel":"testing","subChannel":"unit-testing","difficulty":"intermediate","tags":["jest","mocha","pytest","junit"],"companies":["Google","Meta","Netflix","Salesforce","Stripe"]},{"id":"q-311","question":"How do you mock a function in Jest that's called within another function under test?","channel":"testing","subChannel":"unit-testing","difficulty":"advanced","tags":["jest","mocha","pytest","junit"],"companies":["Amazon","Google","Meta"]},{"id":"q-338","question":"You're testing a React component that fetches user data from an API. How would you write a unit test using Jest to mock the API call and verify the component renders the user's name correctly?","channel":"testing","subChannel":"unit-testing","difficulty":"beginner","tags":["jest","mocha","pytest","junit"],"companies":["Cisco","Hulu","Postman"]},{"id":"q-388","question":"You're testing a REST API endpoint that returns user data. Write a basic unit test using Jest that verifies the endpoint returns a 200 status code and the response contains a 'name' field. What's the most important assertion to include?","channel":"testing","subChannel":"unit-testing","difficulty":"beginner","tags":["jest","mocha","pytest","junit"],"companies":["Postman","Retool","Supabase"]},{"id":"q-1002","question":"In a Unix environment logs are stored in /var/log/app/*.log with lines formatted as timestamp|user|action|resource. Write a practical one-liner using standard UNIX tools to output the top 5 users by total actions in the last 24 hours. Explain how you would handle log rotation and malformed lines?","channel":"unix","subChannel":"general","difficulty":"beginner","tags":["unix"],"companies":["Amazon","Robinhood"]},{"id":"q-1032","question":"How would you capture stdout and stderr of a simple shell command into separate log files while still displaying live output in the terminal? Provide a concrete Bash command and brief justification?","channel":"unix","subChannel":"general","difficulty":"beginner","tags":["unix"],"companies":["Databricks","LinkedIn","Uber"]},{"id":"q-1069","question":"In a Unix environment, logs live under /var/log/metrics/*.log and are hourly rotated to .log and .log.gz. Each line is like [YYYY-MM-DD HH:MM:SS] LEVEL: message. Propose a robust, portable approach (one-liner preferred) to output the number of ERROR events per hour for the last 6 hours, handling missing files and rotations without external dependencies?","channel":"unix","subChannel":"general","difficulty":"advanced","tags":["unix"],"companies":["Adobe","Meta","Plaid"]},{"id":"q-1123","question":"In a Unix environment, multiple services write JSON logs under /var/log/diag/*.log and rotated hourly to *.log.gz. Each line is a JSON object like {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"svc\":\"name\",\"lvl\":\"ERROR\",\"msg\":\"...\"}; Propose a robust one-liner (no external dependencies beyond standard UNIX tools) to output the number of ERROR events per hour for the last 4 hours, aggregated across all services, and tolerant of missing files and rotated archives?","channel":"unix","subChannel":"general","difficulty":"intermediate","tags":["unix"],"companies":["Apple","OpenAI","Snap"]},{"id":"q-1139","question":"Scenario: JSON logs at /var/log/diag/*.log, rotated hourly to *.log.gz. Each line: {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"svc\":\"name\",\"lvl\":\"ERROR\",\"msg\":\"...\"}. Propose a robust one-liner (no external deps beyond standard UNIX tools) that outputs the per-hour 99th percentile of message length for the last 4 hours, across all services, deduplicating identical messages per hour, and tolerant of missing files and gz archives?","channel":"unix","subChannel":"general","difficulty":"advanced","tags":["unix"],"companies":["OpenAI","Plaid","Uber"]},{"id":"q-1224","question":"Scenario: In a Unix cluster, logs are emitted as JSON lines under /var/log/cluster/*/*.log and rotated hourly to *.log.gz. Each line contains {\"ts\":\"YYYY-MM-DDTHH:MM:SSZ\",\"tenant\":\"tenant-id\",\"svc\":\"service\",\"lvl\":\"LEVEL\",\"msg\":\"...\"}; Propose a robust one-liner (no external deps beyond standard UNIX tools) to identify the top 3 tenants by error rate (ERROR / total events) for the last 6 hours, aggregated across all services, tolerant of missing files and gz archives?","channel":"unix","subChannel":"general","difficulty":"advanced","tags":["unix"],"companies":["Apple","Coinbase","PayPal"]},{"id":"q-1241","question":"Scenario: In a multi-user Unix workspace, /home contains subdirectories per user with various files. Some are large, some are temporary. Provide a robust one-liner (no external dependencies) that lists the five largest regular files under /home (recursively), excluding hidden files and symlinks, printing each as 'size<TAB>path' with sizes in human-readable form. Explain how you ensure safety against spaces and newlines in filenames?","channel":"unix","subChannel":"general","difficulty":"beginner","tags":["unix"],"companies":["Databricks","Lyft","Tesla"]},{"id":"q-481","question":"You're debugging a production system where processes are hanging. Using only Unix tools, how would you identify which processes are blocked on I/O, what they're waiting for, and safely terminate them without causing data corruption?","channel":"unix","subChannel":"general","difficulty":"advanced","tags":["unix"],"companies":["Snap","Snowflake"]},{"id":"q-510","question":"You're debugging a production issue where a process is stuck in uninterruptible sleep (D state). How would you identify and handle this situation?","channel":"unix","subChannel":"general","difficulty":"intermediate","tags":["unix"],"companies":["OpenAI","Tesla"]},{"id":"q-538","question":"You notice a process is consuming excessive CPU on a production server. How would you diagnose and troubleshoot this issue using Unix commands?","channel":"unix","subChannel":"general","difficulty":"intermediate","tags":["unix"],"companies":["Citadel","Goldman Sachs","Microsoft"]},{"id":"q-564","question":"You're debugging a production system where processes are hanging. Using only Unix tools, how would you identify which processes are stuck in uninterruptible sleep (D state) and what could be causing this?","channel":"unix","subChannel":"general","difficulty":"advanced","tags":["unix"],"companies":["Adobe","OpenAI","Square"]},{"id":"q-894","question":"On a Linux host, /var/log/myapp.log is written by multiple processes. Implement a robust log rotation that triggers when the file reaches 100MB, keeps 7 rotated files, compresses older logs, and ensures no log loss while writers continue. Describe the approach, commands, and failure modes for concurrent writers?","channel":"unix","subChannel":"general","difficulty":"intermediate","tags":["unix"],"companies":["Coinbase","Discord","OpenAI"]},{"id":"q-264","question":"How do Unix pipes enable inter-process communication and what are their performance implications?","channel":"unix","subChannel":"system-programming","difficulty":"beginner","tags":["posix","signals","pipes","sockets"],"companies":["Amazon","Apple","Google","Meta","Microsoft"]},{"id":"q-1014","question":"Scenario: A multinational SaaS runs Vault with cross-region replication. Tenants use Vault's DB Secrets Engine for Postgres with per-tenant roles and short TTLs. Explain how you would enforce per-tenant rotation and immediate revocation on disable, while preventing cross-tenant leakage during DR failover?","channel":"vault-associate","subChannel":"general","difficulty":"advanced","tags":["vault-associate"],"companies":["Adobe","Goldman Sachs","MongoDB"]},{"id":"q-1054","question":"Scenario: A multi-tenant SaaS stores per-tenant API keys in Vault KV v2 with versioning. A rotation accidentally overwrote the previous key. Describe exactly how you would recover the previous version, which Vault paths and commands you'd use, and what policy controls you would enforce to prevent accidental deletions and ensure auditability?","channel":"vault-associate","subChannel":"general","difficulty":"beginner","tags":["vault-associate"],"companies":["Coinbase","Hugging Face","Tesla"]},{"id":"q-1094","question":"Design a per-tenant envelope encryption workflow using Vault Transit: each tenant has a dedicated Transit key; generate a per-tenant DEK, encrypt data with the DEK, and store the ciphertext. How would you rotate the Transit key without downtime, rewrap existing ciphertext to the new version, handle tenant disablement (revocation), and maintain end-to-end auditability? Include specific Vault paths and commands?","channel":"vault-associate","subChannel":"general","difficulty":"intermediate","tags":["vault-associate"],"companies":["Hashicorp","Instacart","Twitter"]},{"id":"q-1174","question":"In a multi-tenant SaaS, you store per-tenant data encryption keys in Vault Transit with a dedicated key per tenant and daily rotation. Describe how you would implement per-tenant key lifecycle (creation, rotation without downtime, data rewrap for existing data, and immediate revocation when a tenant is disabled) and how you would monitor/audit across services?","channel":"vault-associate","subChannel":"general","difficulty":"intermediate","tags":["vault-associate"],"companies":["Hugging Face","MongoDB","Stripe"]},{"id":"q-1229","question":"You’re building a multi-tenant SaaS and plan to encrypt data at rest using Vault's Transit engine. Describe how you would enable Transit, create per-tenant keys, implement encryption/decryption via the API, and perform zero-downtime key rotation while preserving ciphertext integrity. Include policy considerations to prevent data leakage and how you validate rotation?","channel":"vault-associate","subChannel":"general","difficulty":"beginner","tags":["vault-associate"],"companies":["Hugging Face","Meta","Tesla"]},{"id":"q-971","question":"In a PCI-compliant SaaS, each tenant uses Vault's database secret engine with a dedicated role to issue per-tenant PostgreSQL credentials. TTLs are short (1h). Describe how you would configure per-tenant roles, handle rotation without downtime, and ensure immediate revocation when a tenant is disabled?","channel":"vault-associate","subChannel":"general","difficulty":"intermediate","tags":["vault-associate"],"companies":["Anthropic","Google","Stripe"]}]