{"questions":[{"id":"q-472","question":"You're load testing a high-frequency trading platform that processes 100K requests/second. Your load generator becomes the bottleneck. How would you design a distributed load testing architecture to accurately simulate production traffic patterns?","answer":"Use a coordinated multi-region load generator fleet with event-driven architecture. Implement JMeter/Gatling clusters behind Kafka for distributed orchestration, use containerized agents with auto-scaling capabilities, and leverage cloud-native infrastructure for horizontal scaling.","explanation":"## Architecture Design\n- Deploy load generators across multiple AWS regions to distribute load and minimize latency\n- Use Kafka for real-time coordination and data distribution between generators\n- Implement container-based agents with Kubernetes auto-scaling for dynamic resource management\n\n## Traffic Simulation\n- Capture production traffic patterns using tcpdump/Wireshark for realistic request modeling\n- Replay actual request sequences with proper timing to match production behavior\n- Simulate realistic session patterns and user behavior to ensure accurate testing\n\n## Bottleneck Elimination\n- Monitor CPU, memory, and network metrics on each generator in real-time\n- Use horizontal pod autoscaling based on throughput metrics to maintain optimal performance\n- Implement circuit breakers to prevent cascade failures across the generator fleet\n\n## Validation\n- Compare load test results against production metrics to ensure accuracy\n- Validate that no single generator becomes a bottleneck through distributed monitoring\n- Conduct iterative testing to fine-tune the architecture for optimal performance","diagram":"flowchart TD\n  A[Production Traffic Capture] --> B[Kafka Message Queue]\n  B --> C[Regional Load Generator Clusters]\n  C --> D[Containerized JMeter/Gatling Agents]\n  D --> E[System Under Test]\n  C --> F[Monitoring & Metrics]\n  F --> G[Auto-scaling Controller]\n  G --> C","difficulty":"advanced","tags":["performance-testing"],"channel":"performance-testing","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2026-01-09T09:04:59.024Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-501","question":"You're testing a grocery delivery app like Instacart that handles 10,000 concurrent users during peak hours. How would you design a performance testing strategy to identify bottlenecks in the order processing pipeline?","answer":"Design a multi-layered testing approach using JMeter/Gatling for load testing, k6 for spike testing, and Locust for soak testing. Focus on database connection pooling, Redis caching efficiency, and AP","explanation":"## Performance Testing Strategy\n\n### Load Testing Setup\n- Use JMeter/Gatling for sustained load testing\n- Simulate 10,000 concurrent users with realistic user behavior patterns\n- Test order placement, inventory checks, and payment processing\n\n### Key Metrics to Monitor\n- **Response times**: p50, p95, p99 percentiles\n- **Throughput**: requests per second\n- **Error rates**: 4xx/5xx responses\n- **Resource utilization**: CPU, memory, disk I/O\n\n### Bottleneck Identification\n- Database connection pool exhaustion\n- Redis cache hit ratios and eviction policies\n- API gateway rate limiting and circuit breaking\n- Message queue backlog in order processing\n\n### Tools and Implementation\n```bash\n# Distributed load testing with Docker\ndocker run --rm -v $(pwd):/tests \\\n  justb4/jmeter:latest \\\n  -n -t /tests/order_processing.jmx \\\n  -l results.jtl\n```\n\n### Production Readiness\n- Conduct performance testing in staging environment\n- Use production-like data volumes and network conditions\n- Implement chaos engineering for failure scenarios\n- Establish performance SLAs and alerting thresholds","diagram":"flowchart TD\n  A[Load Generator] --> B[API Gateway]\n  B --> C[Order Service]\n  C --> D[Database]\n  C --> E[Redis Cache]\n  C --> F[Message Queue]\n  F --> G[Inventory Service]\n  F --> H[Payment Service]\n  I[Monitoring] --> B\n  I --> C\n  I --> D\n  I --> E","difficulty":"advanced","tags":["performance-testing"],"channel":"performance-testing","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"lastUpdated":"2025-12-27T05:31:07.899Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-531","question":"You're load testing a food delivery platform's order processing system. How would you design a performance testing strategy to identify bottlenecks during peak lunch hours (12-2 PM) when order volume increases 10x?","answer":"Implement a **gradual load ramp-up strategy** using JMeter or Gatling with **realistic user scenarios**. Monitor **key performance metrics**: response times, throughput, error rates, and **system resource utilization** (CPU, memory, database connections).","explanation":"## Performance Testing Strategy for Peak Lunch Hours\n\n### Load Profile Design\n- **Baseline Testing**: Establish normal traffic patterns (1,000 requests/minute)\n- **Peak Simulation**: Replicate 10x load increase during 12-2 PM window (10,000 requests/minute)\n- **Stress Testing**: Push beyond peak capacity to identify failure points (15,000 requests/minute)\n- **Soak Testing**: Maintain sustained peak load for 2 hours to detect memory leaks and performance degradation\n\n### Key Metrics to Monitor\n- **Response Times**: P50, P95, and P99 percentiles across all endpoints\n- **Throughput**: Orders processed per second and system capacity limits\n- **Error Rates**: HTTP 5xx errors, timeout failures, and business logic exceptions\n- **Resource Utilization**: CPU, memory consumption, disk I/O, and network bandwidth\n- **Database Performance**: Connection pool usage, query latency, and lock contention\n\n### Test Scenarios\n```gherkin\nScenario: Order placement during peak hours\n  Given user is authenticated\n  When user places order with multiple items\n  Then system responds within acceptable time limits\n  And order is successfully processed\n```","diagram":"flowchart TD\n  A[Load Generator] --> B[API Gateway]\n  B --> C[Order Service]\n  C --> D[Database]\n  C --> E[Inventory Service]\n  E --> F[Cache Layer]\n  C --> G[Notification Service]\n  G --> H[Message Queue]\n  D --> I[Monitoring]\n  F --> I\n  H --> I","difficulty":"advanced","tags":["performance-testing"],"channel":"performance-testing","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":["load testing","performance testing","bottlenecks","jmeter","gatling","metrics","resource utilization"],"voiceSuitable":true,"lastUpdated":"2026-01-09T08:44:25.384Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-557","question":"You're load testing a trading platform that processes 10,000 orders/second. Your load generator shows 95th percentile latency at 200ms, but actual users report 2-3 second delays. What's happening and how would you diagnose it?","answer":"This is a coordinated omission problem where your load generator waits for responses before sending new requests, artificially inflating throughput metrics. Use constant arrival rate testing with tools like k6 or JMeter to maintain consistent RPS regardless of response times.","explanation":"## Root Cause Analysis\n\nThe discrepancy between your load generator's 200ms 95th percentile latency and users' 2-3 second delays is a classic coordinated omission issue. Your load generator waits for responses before sending new requests, which means when the system slows down, your test rate also decreases, hiding the real performance problems.\n\n- **Coordinated omission**: Load generator throttles itself when system slows down\n- **Queue depth buildup**: Requests back up, causing cascading delays\n- **Resource saturation**: CPU, memory, database connections become bottlenecks\n- **Network congestion**: Real users experience network delays not present in test environment\n\n## Diagnostic Approach\n\nUse proper load testing tools that maintain constant arrival rates:\n\n- **k6**: Use `--rps` flag for constant requests per second, or `http.batch()` for concurrent requests\n- **JMeter**: Configure Constant Throughput Timer with \"all active threads\" selected\n- **wrk**: Use `--rate` parameter for fixed connection rate\n- **Gatling**: Use `constantUsersPerSec` injection profile\n\n## Testing Strategy\n\n1. **Baseline testing**: Start with 50% of expected load, measure true latency\n2. **Constant arrival rate**: Maintain 10,000 RPS regardless of response times\n3. **Resource monitoring**: Track CPU, memory, disk I/O, network bandwidth\n4. **Application metrics**: Monitor queue depths, thread pools, database connections\n5. **Network simulation**: Add realistic network delays and packet loss\n\nThe key is testing what happens when requests arrive faster than the system can process them, which reveals the true user experience under load.","diagram":"flowchart TD\n  A[Load Generator] --> B{Test Type}\n  B -->|Fixed Concurrency| C[Coordinated Omission]\n  B -->|Constant Arrival Rate| D[Realistic Load]\n  C --> E[Artificially High Throughput]\n  D --> F[Accurate Latency]\n  E --> G[Misleading Results]\n  F --> H[True Performance]\n  G --> I[Production Issues]\n  H --> J[Reliable Predictions]","difficulty":"intermediate","tags":["performance-testing"],"channel":"performance-testing","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":["coordinated omission","load generator","95th percentile latency","constant arrival rate","throughput"],"voiceSuitable":true,"lastUpdated":"2025-12-29T06:42:47.163Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-586","question":"How would you measure and optimize the performance of a REST API endpoint that's responding slowly?","answer":"Use **response time** metrics with tools like Postman or curl. Measure **throughput** (requests/second) and **CPU/memory** usage. Optimize by adding **caching**, **database indexing**, and **connection pooling**.","explanation":"## Key Metrics\n- **Response time**: Measure average, p95, and p99 latencies\n- **Throughput**: Track requests per second capacity\n- **Error rate**: Monitor failed requests percentage\n- **Resource utilization**: Monitor CPU, memory, and network I/O\n\n## Optimization Techniques\n- **Caching**: Implement Redis for frequently accessed data\n- **Database optimization**: Add indexes and optimize queries\n- **Connection pooling**: Reuse database connections efficiently\n- **Load balancing**: Distribute traffic across multiple servers\n\n## Tools\n- **Monitoring**: New Relic, DataDog, Prometheus\n- **Load testing**: JMeter, k6, Artillery\n- **Profiling**: Node.js profiler, Chrome DevTools","diagram":"flowchart TD\n  A[API Request] --> B[Measure Response Time]\n  B --> C[Check Resource Usage]\n  C --> D{Performance OK?}\n  D -->|No| E[Apply Optimization]\n  E --> F[Add Caching]\n  F --> G[Optimize Database]\n  G --> H[Monitor Results]\n  D -->|Yes| I[Continue Monitoring]","difficulty":"beginner","tags":["performance-testing"],"channel":"performance-testing","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":["response time","throughput","caching","database indexing","monitoring","bottleneck analysis","load testing"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:50:58.877Z","createdAt":"2025-12-27T01:14:19.949Z"},{"id":"gh-40","question":"What is Performance Testing and how does it differ from Load and Stress Testing?","answer":"Performance testing evaluates system responsiveness, stability, and scalability under various workloads to identify bottlenecks and validate requirements.","explanation":"Performance Testing is a comprehensive testing approach that evaluates how a system performs under different conditions. It encompasses several testing types:\n\n**Key Performance Testing Types:**\n1. **Load Testing:** Tests system performance under expected user loads\n2. **Stress Testing:** Pushes system beyond normal capacity to find breaking points\n3. **Endurance Testing:** Validates performance over extended periods\n4. **Spike Testing:** Tests response to sudden traffic increases\n\n**Essential Performance Metrics:**\n- **Response Time:** Time taken to process requests\n- **Throughput:** Number of transactions per time unit\n- **Resource Utilization:** CPU, memory, disk, network usage\n- **Concurrency:** Number of simultaneous users handled\n- **Error Rate:** Percentage of failed requests\n\n**Common Tools:**\n- Apache JMeter, Gatling, k6 for load generation\n- New Relic, Datadog for monitoring\n- Grafana for visualization\n\n**Real-world Example:**\nAn e-commerce site performs load testing before Black Friday to ensure it can handle 10,000 concurrent users with <2 second response times.","diagram":"graph TD\n    A[Performance Testing] --> B[Load Testing]\n    A --> C[Stress Testing]\n    A --> D[Endurance Testing]\n    A --> E[Spike Testing]\n    \n    B --> F[Expected Load]\n    C --> G[Beyond Capacity]\n    D --> H[Extended Duration]\n    E --> I[Sudden Traffic Spikes]\n    \n    F --> J[Response Time < 2s]\n    G --> K[Find Breaking Point]\n    H --> L[Memory Leaks]\n    I --> M[Auto-scaling]\n    \n    style A fill:#e1f5fe\n    style B fill:#f3e5f5\n    style C fill:#ffebee\n    style D fill:#e8f5e8\n    style E fill:#fff3e0","difficulty":"beginner","tags":["perf","testing"],"channel":"performance-testing","subChannel":"load-testing","sourceUrl":null,"videos":null,"companies":["Amazon","Google","Meta","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["performance testing","load testing","stress testing","responsiveness","stability","scalability","bottlenecks"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:45:48.882Z","createdAt":"2025-12-26 12:51:05"},{"id":"gh-41","question":"What are the different types of performance testing and when would you apply each type in a real-world scenario?","answer":"Load testing, stress testing, spike testing, volume testing, endurance testing, and scalability testing—each validates different performance aspects under varying conditions and system loads.","explanation":"## Why Asked\nTests understanding of comprehensive performance strategy and when to apply each testing type.\n\n## Key Concepts\nLoad testing, stress testing, spike testing, volume testing, endurance testing, scalability testing, performance metrics.\n\n## Code Example\n```\n// Load test with Artillery\ncrypto:\n  target: 'https://api.example.com'\n  phases:\n    - duration: 60\n      arrivalRate: 100\n```\n\n## Follow-up Questions\nHow do you determine which type to use first?\nWhat metrics matter most for each test type?","diagram":"flowchart TD\n  A[Load Testing] --> B[Normal Load]\n  C[Stress Testing] --> D[Beyond Capacity]\n  E[Spike Testing] --> F[Sudden Traffic]\n  G[Volume Testing] --> H[Large Data]\n  I[Endurance Testing] --> J[Long Duration]\n  K[Scalability Testing] --> L[Growth Capacity]","difficulty":"intermediate","tags":["perf","testing"],"channel":"performance-testing","subChannel":"load-testing","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Meta"],"eli5":"Imagine you're testing how many friends can play on your playground at once! Load testing is like seeing if 10 kids can swing normally. Stress testing is piling on 50 kids to find out when the swings break. Spike testing is when suddenly 100 kids show up at recess - can the playground handle it? Volume testing is filling the sandbox with tons of sand to see if it still works. Endurance testing is playing all day long to make sure nothing gets tired. Scalability testing is asking: if we build more swings, can even more kids play? Each test helps us know our playground is strong enough for all the fun!","relevanceScore":null,"voiceKeywords":["load testing","stress testing","spike testing","volume testing","endurance testing","scalability testing","performance validation"],"voiceSuitable":true,"lastUpdated":"2026-01-08T11:44:56.901Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-237","question":"How would you design a distributed load testing setup using k6 with multiple cloud regions to simulate 100k concurrent users while avoiding rate limiting and ensuring accurate metrics collection?","answer":"Use k6 cloud with distributed execution across regions, implement exponential ramp-up, and aggregate results via cloud backend with custom metrics.","explanation":"## Concept Overview\nDistributed load testing spreads traffic across multiple cloud regions to simulate realistic global user patterns while avoiding single-point bottlenecks and rate limiting.\n\n## Implementation Details\n- **Architecture**: Master controller orchestrates multiple k6 instances across AWS/GCP regions\n- **Traffic Distribution**: 30% US-East, 25% EU-West, 20% AP-Southeast, 15% US-West, 10% AP-Northeast\n- **Ramp Strategy**: Exponential ramp-up (1k→10k→50k→100k) over 15 minutes\n- **Metrics Pipeline**: Custom k6 extensions send metrics to InfluxDB via Telegraf\n\n## Code Example\n```javascript\nimport http from 'k6/http';\nimport { Rate } from 'k6/metrics';\n\nconst errorRate = new Rate('errors');\n\nexport let options = {\n  stages: [\n    { duration: '2m', target: 1000 },\n    { duration: '5m', target: 10000 },\n    { duration: '8m', target: 50000 },\n    { duration: '10m', target: 100000 },\n  ],\n  cloud: {\n    distribution: {\n      'amazon:us-east-1': { load: 0.3 },\n      'amazon:eu-west-1': { load: 0.25 },\n      'amazon:ap-southeast-1': { load: 0.2 },\n    },\n  },\n};\n\nexport default function() {\n  const response = http.get('https://api.example.com/users');\n  errorRate.add(response.status >= 400);\n}\n```\n\n## Common Pitfalls\n- **Rate Limiting**: Implement jitter between requests (50-200ms)\n- **IP Blocking**: Use rotating proxy pools or residential IPs\n- **Metrics Accuracy**: Synchronize NTP across all instances\n- **Resource Exhaustion**: Monitor CPU/memory on k6 instances, auto-scale as needed","diagram":"graph TD\n    A[Master Controller] --> B[k6 Cloud Orchestrator]\n    B --> C[US-East Region]\n    B --> D[EU-West Region]\n    B --> E[AP-Southeast Region]\n    B --> F[US-West Region]\n    B --> G[AP-Northeast Region]\n    C --> H[Load Balancer]\n    D --> H\n    E --> H\n    F --> H\n    G --> H\n    H --> I[Target Application]\n    C --> J[InfluxDB]\n    D --> J\n    E --> J\n    F --> J\n    G --> J\n    J --> K[Grafana Dashboard]\n    A --> L[Results Aggregator]\n    L --> K","difficulty":"intermediate","tags":["jmeter","k6","gatling","locust"],"channel":"performance-testing","subChannel":"load-testing","sourceUrl":null,"videos":null,"companies":["Amazon","Google","Netflix","Stripe","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":["k6 cloud","distributed execution","exponential ramp-up","rate limiting","metrics aggregation","cloud regions"],"voiceSuitable":true,"lastUpdated":"2025-12-27T04:54:50.333Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-210","question":"How would you implement comprehensive CPU profiling with flame graphs using clinic.js and async hooks to identify performance bottlenecks in a Node.js microservice handling concurrent requests, including production considerations and memory leak detection?","answer":"Use clinic.js doctor -- node app.js for CPU profiling, clinic.js flame -- node app.js for flame graphs, and async hooks for request lifecycle tracking. Analyze hot paths, identify blocking operations, and monitor memory allocation patterns. Profile with --inspect flag for production debugging.","explanation":"## Implementation Approach\nUse clinic.js suite for comprehensive profiling:\n- `clinic doctor -- node app.js` - Overall health analysis\n- `clinic flame -- node app.js` - CPU flame graph generation\n- `clinic bubbleprof -- node app.js` - Async delay visualization\n\n## Key Commands\n```bash\n# Production-safe profiling\nclinic doctor -- node --inspect=0.0.0.0:9229 app.js\nclinic flame -- node --inspect=0.0.0.0:9229 app.js\n\n# Memory leak detection\nnode --inspect app.js\n# Chrome DevTools > Memory > Allocation Timeline\n```\n\n## Async Hooks Profiling\n```javascript\nconst asyncHooks = require('async_hooks');\nconst hooks = asyncHooks.createHook({\n  init(asyncId, type) {\n    console.log(`Init: ${type} ${asyncId}`);\n  },\n  destroy(asyncId) {\n    console.log(`Destroy: ${asyncId}`);\n  }\n});\nhooks.enable();\n```\n\n## Production Considerations\n- Profile with sampling (1-2% overhead) vs continuous profiling\n- Use `--max-old-space-size` and `--max-executable-size` limits\n- Implement health checks to disable profiling under load\n- Consider APM tools like New Relic for continuous monitoring\n\n## Flame Graph Analysis\n- Focus on red/yellow hot spots > 10% CPU\n- Identify synchronous blocking operations\n- Look for excessive Promise allocations\n- Check event loop lag in async operations\n- Analyze garbage collection patterns","diagram":"graph TD\n    A[Client Request] --> B[Express Router]\n    B --> C[Middleware Chain]\n    C --> D[Business Logic]\n    D --> E[Database Query]\n    E --> F[Response]\n    \n    G[CPU Profiler] --> H[Sampling Thread]\n    H --> I[Call Stack Capture]\n    I --> J[Flame Graph Generation]\n    J --> K[Bottleneck Analysis]\n    \n    L[Hot Path] --> M[Function A]\n    M --> N[Function B]\n    N --> O[Database Call]\n    \n    style G fill:#ff6b6b\n    style L fill:#ffd93d\n    style O fill:#6bcf7f","difficulty":"intermediate","tags":["cpu-profiling","memory-profiling","flame-graphs"],"channel":"performance-testing","subChannel":"profiling","sourceUrl":null,"videos":null,"companies":["Amazon","Cloudflare","Meta","Microsoft","Netflix","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":["cpu profiling","flame graphs","clinic.js","async hooks","performance bottlenecks","memory leaks","microservice"],"voiceSuitable":true,"lastUpdated":"2025-12-27T05:52:51.537Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-280","question":"What is the difference between CPU profiling and memory profiling, and when would you use a flame graph?","answer":"CPU profiling measures execution time spent in functions, while memory profiling tracks memory allocation patterns and usage. Flame graphs are used to visualize CPU bottlenecks and identify performance hotspots.","explanation":"## Concept\nPerformance profiling analyzes runtime behavior to identify bottlenecks. CPU profiling shows where your application spends execution time, while memory profiling reveals memory allocation patterns, leaks, and usage trends.\n\n## Implementation\n**CPU Profiling**: Tools collect stack traces periodically to build a profile\n```bash\n# Node.js example\nnode --prof app.js\nnode --prof-process isolate-*.log > processed.txt\n```\n\n**Memory Profiling**: Track heap allocations and garbage collection\n```javascript\n// Chrome DevTools\nconsole.profile('CPU-analysis');\nconsole.memory;\n```\n\n## Trade-offs\nCPU profiling adds minimal overhead but provides execution insights. Memory profiling can significantly impact performance due to tracking overhead. Flame graphs offer intuitive visualization but require sampling-based data collection.","diagram":"graph TD\n    A[Performance Issue] --> B{Type?}\n    B -->|Slow execution| C[CPU Profiling]\n    B -->|High memory usage| D[Memory Profiling]\n    C --> E[Collect Stack Traces]\n    D --> F[Heap Analysis]\n    E --> G[Flame Graph Visualization]\n    F --> H[Memory Maps]\n    G --> I[Identify Hot Functions]\n    H --> J[Find Leaks]","difficulty":"beginner","tags":["cpu-profiling","memory-profiling","flame-graphs"],"channel":"performance-testing","subChannel":"profiling","sourceUrl":"https://nodejs.dev/en/learn/diagnostics/flame-graphs","videos":{"shortVideo":"https://www.youtube.com/watch?v=YaRrmdMa_Cg","longVideo":"https://www.youtube.com/watch?v=VMpTU15rIZY"},"companies":["Amazon","Google","Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":["cpu profiling","memory profiling","flame graph","bottlenecks","performance analysis"],"voiceSuitable":true,"lastUpdated":"2025-12-30T01:44:20.185Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["general","load-testing","profiling"],"companies":["Amazon","Citadel","Cloudflare","DoorDash","Goldman Sachs","Google","Instacart","Meta","Microsoft","NVIDIA","Netflix","Plaid","Robinhood","Stripe","Tesla","Two Sigma","Uber"],"stats":{"total":10,"beginner":3,"intermediate":4,"advanced":3,"newThisWeek":0}}