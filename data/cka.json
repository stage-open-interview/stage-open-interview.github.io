{"questions":[{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","answer":"Identify the two healthy etcd members and verify quorum with etcdctl member list; check cluster-health. Stop the out-of-quorum member, restore the missing member from the latest snapshot using etcdctl","explanation":"## Why This Is Asked\nTests practical DR/HA recovery for etcd and API availability in multi-AZ. Requires exact commands and sequencing.\n\n## Key Concepts\n- etcd quorum and member lifecycle\n- Snapshot restore with initial-cluster state\n- HA API server restart order across AZs\n- DR readiness, RPO/RTO implications\n\n## Code Example\n```javascript\n// Illustrative DR restore flow (non-production, for understanding)\nconst {execSync} = require('child_process')\nexecSync(\"etcdctl snapshot restore snapshot.db --name etcd2 --initial-cluster 'etcd0=https://A:2380,etcd1=https://A2:2380,etcd2=https://B:2380' --initial-cluster-state=new\", {stdio:'inherit'})\n```\n\n## Follow-up Questions\n- How would you test this upgrade procedure to minimize downtime?\n- What are risks of multi-AZ etcd topologies and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:20:40.941Z","createdAt":"2026-01-12T22:20:40.941Z"},{"id":"q-1368","question":"In a 3-node etcd-backed Kubernetes cluster, one node loses network connectivity and becomes partitioned while the other two remain healthy. How do you preserve availability and data integrity, avoid split-brain, and recover the partitioned member? Outline health checks, how you isolate the partition, recovery steps, and verification?","answer":"Assess quorum and health via etcdctl: member list and endpoint status. If a node is partitioned, fence it by stopping its etcd service or blocking its traffic so the two healthy members keep quorum. A","explanation":"## Why This Is Asked\nAssessing HA in etcd is critical for production clusters; this question tests practical recovery, fencing, and verification under partition scenarios.\n\n## Key Concepts\n- etcd quorum in a 3-node cluster\n- Fence/isolate to avoid split-brain\n- Recovery: rejoin member and verify\n- Validation: health checks and data consistency\n\n## Code Example\n```bash\netcdctl member list\netcdctl endpoint health\n```\n\n## Follow-up Questions\n- How would you simulate a partition in a staging cluster and validate failover?\n- Which metrics indicate a healthy etcd cluster after recovery?","diagram":"flowchart TD\n  A[Partition Detected] --> B[Fence Isolated Member]\n  B --> C[Two-Node Quorum Maintained]\n  C --> D[Network Fixed]\n  D --> E[Isolated Member Rejoined]\n  E --> F[Health Verified]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T13:20:24.108Z","createdAt":"2026-01-13T13:20:24.108Z"},{"id":"q-1395","question":"In a 3-node Kubernetes cluster, deploy a stateless web app using a Deployment with 3 replicas and a ClusterIP Service. Include readiness and liveness probes, CPU/memory requests and limits, and populate APP_MODE via a ConfigMap and DB_PASSWORD from a Secret. Describe the steps to perform a rolling update to 4 replicas with zero downtime and how you would verify the rollout across nodes?","answer":"Define a Deployment with 3 replicas and a ClusterIP Service. Add readinessProbe and livenessProbe, and set resources: requests cpu: 100m, memory: 128Mi; limits cpu: 500m, memory: 256Mi. Populate APP_M","explanation":"## Why This Is Asked\n\nTests practical Kubernetes administration skills: creating Deployments and Services, configuring probes and resources, wiring ConfigMaps and Secrets, and performing safe rolling updates with observable verification.\n\n## Key Concepts\n\n- Deployments and Services\n- Probes (readiness and liveness)\n- Resource requests/limits\n- ConfigMap and Secret usage\n- RollingUpdate strategy and rollout verification\n\n## Code Example\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"256Mi\"\n```\n\n## Follow-up Questions\n\n- How would you attach APP_MODE ConfigMap and DB_PASSWORD Secret as environment variables?\n- How would you monitor the rollout and diagnose a failed update?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T15:36:31.463Z","createdAt":"2026-01-13T15:36:31.464Z"},{"id":"q-1418","question":"Enable at-rest encryption for Kubernetes Secrets using a KMS (envelope) provider on an existing 3-control-plane cluster. Describe exact steps to configure the EncryptionConfig, rotate KEKs without downtime, trigger re-encryption of existing Secrets, and verify that new and existing Secrets are stored encrypted at rest (without decrypting at-rest data). Include concrete commands and caveats?","answer":"1) Create encryption-config.yaml with a kms provider for secrets and place on API servers. 2) Update API server manifest to --encryption-provider-config and restart. 3) Add a new KEK to the provider c","explanation":"## Why This Is Asked\nThis tests practical enablement of encryption at rest for Secrets using a KMS provider, including live-rotation and data re-encryption without downtime.\n\n## Key Concepts\n- Encryption at rest for Secrets\n- KMS envelope provider and key rotation\n- Re-encryption strategy without API downtime\n- Verification via ciphertext in etcd and API behavior\n- Operational risk and rollback\n\n## Code Example\n```yaml\n# encryption-config.yaml (high-level)\napiVersion: v1\nkind: EncryptionConfig\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      # kms configuration here\n  - aesgcm:\n      keys:\n      - name: key1\n```\n\n```bash\n# Basic commands (illustrative)\n# 1) Update API server to use config\n#Systemctl restart kube-apiserver\n# 2) Rotate KEK\n# edit encryption-config.yaml to add new KEK and restart\n# 3) Re-encrypt existing data\nkubectl get secret --all-namespaces -o json | kubectl apply -f -\n```\n\n## Follow-up Questions\n- How would you automate rotation across clusters and verify no data loss?\n- How would you test DR for key material and encryption config without affecting live workloads?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T16:41:51.999Z","createdAt":"2026-01-13T16:41:52.001Z"},{"id":"q-1452","question":"You operate a 3-node Kubernetes cluster with a StatefulSet of 3 replicas backed by PVs. A critical fix requires upgrading to image app:v2 with zero downtime. Outline a precise upgrade plan: set a PodDisruptionBudget to minAvailable 2, apply a RollingUpdate with partition=2, ensure readiness probes tolerate brief pod restarts, and verify data integrity during rollout with concrete kubectl commands?","answer":"Patch the StatefulSet with partition=2 so pods 0–1 upgrade first, keeping one online. Create a PodDisruptionBudget with minAvailable: 2. Upgrade: kubectl patch statefulset my-app -p '{\"spec\":{\"updateS","explanation":"## Why This Is Asked\nTests understanding of zero-downtime upgrades for StatefulSets, combined with PDBs, readiness, and data safety.\n\n## Key Concepts\n- StatefulSet RollingUpdate with partition control\n- PodDisruptionBudget for high availability\n- PV/PVC durability and readiness probes\n\n## Code Example\n```javascript\nfunction patchPayload(partition){\n  return {\"spec\": {\"updateStrategy\": {\"type\": \"RollingUpdate\", \"rollingUpdate\": {\"partition\": partition}}}};\n}\n```\n\n## Follow-up Questions\n- How would you verify data integrity during rollout? \n- What risks exist if a pod reschedules on another node during upgrade?","diagram":"flowchart TD\n  A[StatefulSet Upgrade] --> B[Apply PDB]\n  B --> C[Patch StatefulSet]\n  C --> D[Rollout]\n  D --> E[Verify]\n  E --> F[Finish]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T17:47:32.315Z","createdAt":"2026-01-13T17:47:32.315Z"},{"id":"q-1562","question":"How would you design a Kubernetes Job named app-init-seed that seeds app data on first run? The Job should use an Alpine-based image, mount a PVC at /data, load a script from a ConfigMap at /scripts/seed.sh, skip if /data/.seeded exists, optionally fetch seed.json from https://example.com using API key from a Secret, and write a log and the marker file upon success; include full YAML and apply steps?","answer":"Implement a Kubernetes Job named app-init-seed that seeds data on first run. Use an Alpine-based image, mount a PVC at /data, and load a script from a ConfigMap at /scripts/seed.sh. If /data/.seeded exists, skip processing. Optionally fetch seed.json from https://example.com using an API key from a Secret, then write a log and create the marker file upon success.","explanation":"## Why This Is Asked\nThis question tests practical understanding of Kubernetes Jobs, volume mounts, ConfigMaps, Secrets, idempotent operations, and error handling in a cluster environment. It also evaluates the ability to design resilient solutions with proper backoff limits and restart policies.\n\n## Key Concepts\n- Kubernetes Job lifecycle and management\n- Volume mounts for Persistent Volume Claims (PVCs)\n- ConfigMap and Secret integration\n- Idempotent seeding through marker files\n- BackoffLimit and restartPolicy configuration\n- Network operations with curl using --fail and --retry flags\n\n## Code Example\n```yaml\n# YAML Job example\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: app-init-seed\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 4\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: seed-container\n        image: alpine:3.18\n        command: [\"/bin/sh\", \"/scripts/seed.sh\"]\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n        - name: script-volume\n          mountPath: /scripts\n        env:\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: api-secret\n              key: api-key\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: app-data-pvc\n      - name: script-volume\n        configMap:\n          name: seed-script\n```\n\n## Apply Steps\n1. Create the ConfigMap with the seed script\n2. Create the Secret with the API key\n3. Ensure the PVC exists\n4. Apply the Job manifest: `kubectl apply -f app-init-seed-job.yaml`\n5. Monitor progress: `kubectl get jobs -w`","diagram":"flowchart TD\n  A[Job app-init-seed] --> B[Mount /data PVC]\n  B --> C{Seeded?}\n  C -- Yes --> D[Exit]\n  C -- No --> E[Fetch seed.json]\n  E --> F[Write /data/seed.json]\n  F --> G[Create /data/.seeded]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T04:57:44.958Z","createdAt":"2026-01-13T21:47:26.329Z"},{"id":"q-1737","question":"You're deploying a 3-replica Deployment in Kubernetes for a payment app. Suddenly 2 pods crash with CrashLoopBackOff. Describe a practical debugging workflow to identify if the issue is container startup, config, resources, or image, and outline the exact kubectl commands and file checks you would perform. Include how you would propose a minimal fix and a rollback plan?","answer":"Debug CrashLoopBackOff by isolating startup, config, resources, or image issues. Run: kubectl get pods -l app=payment; kubectl describe pod <pod>; kubectl logs <pod>; kubectl logs <pod> --previous; ku","explanation":"## Why This Is Asked\n\nTests practical debugging steps for Kubernetes CrashLoopBackOff, focusing on actionable commands.\n\n## Key Concepts\n\n- CrashLoopBackOff diagnosis\n- kubectl tooling (describe, logs, events)\n- ConfigMap/Secret patching\n- Rollback strategies\n\n## Code Example\n\n```bash\nkubectl get pods -l app=payment\n```\n\n## Follow-up Questions\n\n- How would you distinguish image pull errors from runtime crashes?\n- What are the risks of rolling back a deployment in production?","diagram":"flowchart TD\n  A[CrashLoopBackOff] --> B[Check pod status and events]\n  B --> C[Describe pod]\n  C --> D[Logs and previous logs]\n  D --> E[Probe/config/resources checks]\n  E --> F[Apply minimal fix]\n  F --> G[Rollout undo or restart]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:59:22.220Z","createdAt":"2026-01-14T08:59:22.220Z"},{"id":"q-1764","question":"Advanced: In a 5-node Kubernetes cluster where etcd memory usage has spiked after a noisy deployment, outline a production-safe remediation plan: verify health with etcdctl, diagnose via metrics, perform defrag/compact, take a snapshot, and adjust API watch load while preserving API server availability. What steps would you take?","answer":"Start by verifying health with etcdctl: endpoint status, member list, and health metrics; check RAM use and watch counts. Defragment and compact to reclaim space. Take a consistent snapshot for rollba","explanation":"## Why This Is Asked\nAssesses practical triage of etcd memory pressure in a live cluster, including safe backup/rollback and minimizing downtime.\n\n## Key Concepts\n- etcd health and metrics\n- defragmentation, compaction, backups\n- API server watch behavior and watch-cache\n- scalable rollback strategies\n\n## Code Example\n```javascript\n// Example: sequence of remediation steps\n```\n\n## Follow-up Questions\n- How would you validate remediation success after rollout?\n- What monitoring alerts would you configure to catch recurrence?\n","diagram":"flowchart TD\n  A(Check health via etcdctl) --> B(Assess memory hotspots)\n  B --> C(Defrag and compact)\n  C --> D(Take snapshot)\n  D --> E(Adjust resources/watch load)\n","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:48:51.723Z","createdAt":"2026-01-14T09:48:51.723Z"},{"id":"q-1810","question":"You're operating a 5-node Kubernetes cluster with a validating webhook named cfg.example.com enforcing a label requirement on Deployments in all namespaces. A critical patch must be applied in prod-adv while the webhook service is temporarily unavailable. Outline a safe, auditable plan to bypass the webhook with exact kubectl commands to identify, disable, apply, and revert?","answer":"Patch the ValidatingWebhookConfiguration to Ignore on failure, apply the patch in prod-adv, then revert to Fail and verify with events and rollout. Commands: kubectl get validatingwebhookconfiguration","explanation":"## Why This Is Asked\nTests understanding of Kubernetes admission control and safe rollbacks under outage.\n\n## Key Concepts\n- ValidatingWebhookConfiguration\n- FailurePolicy: Ignore vs Fail\n- Safe patch deployment\n- Auditable rollback\n\n## Code Example\n```yaml\n# minimal patch example framework\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: cfg.example.com\n  \n# actual patch differs per cluster\n```\n\n## Follow-up Questions\n- How would you validate no partial patches linger?\n- What are risks if you forget to revert? ","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T11:45:33.451Z","createdAt":"2026-01-14T11:45:33.451Z"},{"id":"q-1885","question":"In a high-traffic delivery platform, you deploy a Kubernetes-based worker pool for async order processing. Explain how you would implement a robust, rate-limited queue with backpressure, idempotent workers, and at-least-once delivery, using Kubernetes primitives and common tools. Include how you handle spikes, retries, and data-store consistency?","answer":"Use a Kafka or Redis Streams backed queue with stateless workers behind a HorizontalPodAutoscaler. Enforce backpressure with a token-bucket limiter shared via Redis. Ensure idempotence by recording pr","explanation":"## Why This Is Asked\nTests practical Kubernetes design for async processing, backpressure, idempotency, and delivery guarantees in production-like scenarios.\n\n## Key Concepts\n- Durable queues (Kafka/Redis Streams)\n- Backpressure and rate limiting\n- Idempotent workers and at-least-once delivery\n- Backoff strategies and DLQ\n- Data-store consistency with upserts\n\n## Code Example\n```javascript\n// Pseudo-code: worker handling with idempotency checks\nfunction handle(msg) {\n  if (db.hasProcessed(msg.id)) return;\n  const res = process(msg);\n  db.upsert({ id: msg.id, result: res });\n  ack(msg);\n}\n```\n\n## Follow-up Questions\n- How would you test exactly-once vs at-least-once guarantees?\n- How would you observe and alert on backpressure and DLQ growth?\n","diagram":"flowchart TD\n  A[Ingest] --> B[Enqueue]\n  B --> C[Workers]\n  C --> D[Persist/ACK]\n  D --> E[DLQ]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:45:54.277Z","createdAt":"2026-01-14T15:45:54.277Z"},{"id":"q-1932","question":"Describe a **concrete, production-ready plan** for zero-downtime deployments in a Lyft-scale Kubernetes cluster with ~40 microservices, multiple data stores, and strict uptime. How would you implement **blue/green or canary releases**, traffic shaping, and automated rollbacks? Include rollout strategy, readiness checks, RBAC, DR, and a compact manifest example comparing Istio and Linkerd approaches?","answer":"Plan calls for immutable deployments with Canary or Blue/Green, progressive traffic shifts (start 1–5% canary and ramp), readiness/liveness probes, and PodDisruptionBudget with automated rollback on f","explanation":"## Why This Is Asked\nTests practical mastery of deployment strategies in large Kubernetes environments, emphasizing real-world constraints, traffic control, observability, and DR.\n\n## Key Concepts\n- Canary and blue/green deployments\n- Traffic shaping with service mesh (Istio/Linkerd)\n- Readiness/Liveness probes, PodDisruptionBudget\n- Rollbacks, error budgets, observability\n- DR planning, RBAC\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payments\nspec:\n  replicas: 4\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  template:\n    metadata:\n      labels:\n        app: payments\n    spec:\n      containers:\n      - name: payments\n        image: myrepo/payments:canary-1\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n```\n\n## Follow-up Questions\n- How would you measure canary success and trigger rollback?\n- What metrics and alerting would you configure?\n","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:46:42.475Z","createdAt":"2026-01-14T17:46:42.475Z"},{"id":"q-1946","question":"On a 3-node Kubernetes cluster, a Deployment’s Pods stay Pending while 2 nodes are Ready. The scheduler shows a NoSchedule taint on node-1. Explain exact commands to identify the taint, check the pod’s tolerations, and either remove the taint or add a matching toleration so the workload schedules. How do you validate after changes?","answer":"Check taint and pods: kubectl get nodes -o wide and kubectl describe node node-1 to confirm the taint. To remove: kubectl taint nodes node-1 NoSchedule-. Or add toleration to the Pod/Deployment: toler","explanation":"## Why This Is Asked\nTests practical ability to diagnose and fix scheduling using taints/tolerations in a real cluster.\n\n## Key Concepts\n- taints and tolerations\n- kubectl diagnostics\n- Deployment rollout verification\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  template:\n    spec:\n      tolerations:\n      - key: \"node-role.kubernetes.io/node\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n```\n\n## Follow-up Questions\n- How would you limit the toleration to a subset of pods?\n- What are risks of removing a NoSchedule taint on a node?","diagram":"flowchart TD\n  A[Identify taint] --> B[Decide action]\n  B --> C{Remove taint?}\n  C -->|Yes| D[Apply taint removal]\n  C -->|No| E[Tolerations added]\n  D --> F[Rollout verify]\n  E --> F","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:43:56.873Z","createdAt":"2026-01-14T18:43:56.875Z"},{"id":"q-1972","question":"You maintain a Node.js app deployed as a 3-replica Kubernetes Deployment behind a service. A security patch requires updating the container image from v1.0.1 to v1.0.2 with zero downtime. List exact kubectl steps to perform a safe rolling update, how you confirm readiness, and how you rollback if the rollout fails?","answer":"Use kubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2; wait for rollout to complete with kubectl rollout status deployment/myapp; verify all pods are Ready and running the new image with ku","explanation":"## Why This Is Asked\n\nTests practical, safe rolling update knowledge in real Kubernetes workflows.\n\n## Key Concepts\n\n- RollingUpdate strategy\n- Readiness/Liveness probes\n- Rollback with rollout undo\n- kubectl use in production-like tasks\n\n## Code Example\n\n```javascript\nkubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2\n```\n\n## Follow-up Questions\n\n- What would you do if a pod crashes after update?\n- How would you adjust probes/thresholds to prevent future issues?\n","diagram":"flowchart TD\n  A[Deployment] --> B[RollingUpdate]\n  B --> C{Status}\n  C -->|Success| D[Done]\n  C -->|Failure| E[Rollback]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:28:07.727Z","createdAt":"2026-01-14T19:28:07.727Z"},{"id":"q-2027","question":"You're managing a shared Kubernetes cluster with namespaces prod, analytics, and dev. A nightly analytics batch job sometimes starves frontend pods during peak hours, triggering evictions. Design an end-to-end remediation plan: tune pod requests/limits, enforce defaults with a LimitRange, cap total usage with a ResourceQuota, ensure guaranteed QoS, evaluate VerticalPodAutoscaler vs HorizontalPodAutoscaler, and outline validation steps to prevent regressions?","answer":"Set explicit requests and limits for all affected pods to prevent the analytics job from exhausting shared resources; implement a LimitRange in the analytics namespace to enforce default values; add a ResourceQuota per namespace to cap total resource consumption; configure Guaranteed QoS for critical frontend pods by setting requests equal to limits; evaluate HorizontalPodAutoscaler for frontend pods to scale during peak demand and VerticalPodAutoscaler for the analytics job to right-size its resource allocation; implement canary deployments and load testing to validate the solution.","explanation":"## Why This Is Asked\nTests resource management expertise and real-world trade-offs involving quotas, QoS classes, and autoscaling strategies across Kubernetes namespaces.\n\n## Key Concepts\n- Kubernetes QoS classes (Guaranteed, Burstable, Best-Effort)\n- ResourceQuota and LimitRange for namespace governance\n- HorizontalPodAutoscaler (HPA) for scaling out\n- VerticalPodAutoscaler (VPA) for right-sizing resources\n- Canary validation and load testing strategies\n\n## Code Example\n```yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: analytics-defaults\n  namespace: analytics\nspec:\n  limits:\n  - default:\n      cpu: 500m\n      memory: 512Mi\n    defaultRequest:\n      cpu: 100m\n      memory: 128Mi\n    type: Container\n```","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:29:18.467Z","createdAt":"2026-01-14T21:35:41.722Z"},{"id":"q-2134","question":"You manage a Databricks/OpenAI-like platform on Kubernetes. A Spark streaming job processes 1TB/day and faces sporadic node preemption causing data loss without checkpoints. Design a fault-tolerant deployment (manifests and configurations) and explain trade-offs between Kubernetes Job vs. StatefulSet, backoff strategies, taints/tolerations, and Spark dynamic allocation. What would you implement and why?","answer":"Design a fault-tolerant Spark-on-Kubernetes deployment: run the streaming job with dynamic allocation; enable checkpointing to durable storage; use taints/tolerations and a PodDisruptionBudget; set ba","explanation":"## Why This Is Asked\nThis question probes real-world Kubernetes/Spark fault-tolerance, scheduling, and stateful workload design—crucial on large platforms like Databricks/OpenAI.\n\n## Key Concepts\n- Spark on Kubernetes (CRs, dynamic allocation)\n- Checkpointing and exactly-once semantics\n- PodDisruptionBudget, taints/tolerations, restart policies\n- Observability and alerts (Prometheus)\n\n## Code Example\n```javascript\n// Example SparkApplication spec (pseudo)\nconst sparkApp = {\n  apiVersion: \"sparkoperator.k8s.io/v1beta2\",\n  kind: \"SparkApplication\",\n  metadata: { name: \"stream-1\" },\n  spec: {\n    mode: \"cluster\",\n    image: \"spark:3.2\",\n    mainClass: \"com.example.Stream\",\n    mainApplicationFile: \"local:///stream.jar\",\n    sparkVersion: \"3.2.0\",\n    restartPolicy: { type: \"OnFailure\", onFailureRetries: 3, onFailureRetryInterval: 10 },\n    dynamicAllocation: { enabled: true },\n    backpressureEnabled: true,\n    checkpointLocation: \"s3://bucket/checkpoints\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test the fault-tolerance guarantees?\n- What changes if the storage is GCS vs S3?","diagram":"flowchart TD\n  Client --> APIServer\n  APIServer --> etcd\n  APIServer --> Scheduler\n  Scheduler --> Worker\n  Worker --> CheckpointStorage","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:17:04.104Z","createdAt":"2026-01-15T04:17:04.104Z"},{"id":"q-2152","question":"On a Kubernetes cluster running Spark jobs via Spark on Kubernetes, a 12-pod job reports intermittent OOM errors during shuffle-heavy stages on medium-sized datasets. Provide a concrete debugging plan: how you verify memory limits, adjust executor/driver memory and overhead, tune JVM GC, and validate changes with metrics and a controlled benchmark run?","answer":"Begin by confirming per-pod memory limits and actual usage with kubectl describe pod and metrics; then tune Spark: set spark.executor.memory and spark.driver.memory to safe values, add memoryOverhead,","explanation":"## Why This Is Asked\n\nTests ability to reason about Kubernetes resources and Spark on Kubernetes, and perform practical memory tuning with metrics, GC, and observability.\n\n## Key Concepts\n\n- Kubernetes resource requests/limits\n- Spark memory tuning (driver/executor memory, memoryOverhead, spark.memory.fraction)\n- JVM GC options and GC logging\n- Shuffle-heavy workloads and GC pressure\n- Observability (Spark UI, kubectl top, metrics)\n\n## Code Example\n\n```javascript\n// Kubernetes patch example (pseudo)\nconst patch = {\n  spec: {\n    template: {\n      spec: {\n        containers: [\n          { name: \"executor\",\n            resources: { requests: { memory: \"12Gi\" }, limits: { memory: \"12Gi\" } }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you detect a memory leak vs normal GC pauses?\n- How would you verify stability after changes with a canary run?","diagram":"flowchart TD\n  A[Cluster] --> B[Diagnose OOM]\n  B --> C{Adjust Resources}\n  C --> D[Apply Quotas]\n  C --> E[Restart Pods]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:34:36.507Z","createdAt":"2026-01-15T05:34:36.507Z"},{"id":"q-2197","question":"In a Kubernetes cluster running mixed workloads, a critical data-processing job occasionally starves QoS pods during peak load. Provide a concrete plan to enforce SLA guarantees: specify resource requests/limits with appropriate QoS, enable Pod Priority and Preemption, configure HorizontalPodAutoscaler and ClusterAutoscaler, and outline validation steps to prove SLAs hold under load?","answer":"Plan: assign meaningful resource requests/limits per pod to establish QoS, enable Pod Priority and Preemption, configure HorizontalPodAutoscaler and ClusterAutoscaler for demand, apply Namespace quota","explanation":"Why This Is Asked\nEvaluates ability to translate SLAs into concrete Kubernetes controls under real-world pressure.\n\n## Key Concepts\n- QoS classes and resource requests/limits\n- Pod Priority and Preemption\n- HorizontalPodAutoscaler and ClusterAutoscaler\n- Namespace quotas and taints for isolation\n- Validation: load testing, SLIs/SLOs, monitoring signals\n\n## Code Example\n```javascript\n// Example: Resource requests/limits snippet\nconst pod = {\n  apiVersion: \"v1\",\n  kind: \"Pod\",\n  metadata: { name: \"data-job\" },\n  spec: {\n    priorityClassName: \"high-prio\",\n    containers: [{\n      name: \"worker\",\n      image: \"registry/data-job:latest\",\n      resources: {\n        requests: { cpu: \"500m\", memory: \"1Gi\" },\n        limits: { cpu: \"1000m\", memory: \"2Gi\" }\n      }\n    }]\n  }\n}\n```\n\n## Follow-up Questions\n- How would you measure SLA adherence across namespaces?\n- What trade-offs exist between aggressive autoscaling vs. cost, and how would you cap bursts?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T07:04:20.415Z","createdAt":"2026-01-15T07:04:20.415Z"},{"id":"q-2282","question":"Implement namespace-scoped network isolation for namespace 'team-a' using Kubernetes NetworkPolicy. Ensure pods in team-a can reach only the DNS service and a single internal log sink at 'log-sink.logging.svc.cluster.local:9200', and cannot reach other namespaces or external hosts. Provide the manifests (default-deny and allow rules), kubectl commands to apply, and verify using a tester pod with targeted tests for DNS, log sink, and external access?","answer":"Implement a default-deny egress policy for namespace team-a, then add two allow rules: (1) DNS egress to kube-dns in kube-system on port 53 (TCP/UDP), (2) access to log-sink.logging.svc.cluster.local:","explanation":"## Why This Is Asked\nTests ability to design and implement strict network isolation, understand default-deny semantics, DNS, and inter-namespace access; requires translating policy into concrete manifests and validation steps.\n\n## Key Concepts\n- NetworkPolicy basics: podSelector, namespaceSelector, policyTypes\n- default-deny, explicit egress allows\n- DNS egress patterns to kube-system kube-dns pods\n- Testing with tester pod using dig and curl\n- Drift monitoring and auditing\n\n## Code Example\n```yaml\n# Default deny (egress)\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: team-a-egress-deny\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress: []\n```\n```yaml\n# Allow DNS and Log Sink\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: team-a-egress-allow-dns-log\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n      podSelector:\n        matchLabels:\n          k8s-app: kube-dns\n    ports:\n    - protocol: TCP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: logging\n    ports:\n    - protocol: TCP\n      port: 9200\n```","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T10:42:58.509Z","createdAt":"2026-01-15T10:42:58.509Z"},{"id":"q-2304","question":"You're administering a 3-namespace Kubernetes cluster hosting two teams. There are no NetworkPolicies today. Draft and implement a precise plan to enforce per-namespace default-deny, permit intra-namespace traffic for all pods, and allow outbound HTTPS to api.external.com:443, while blocking cross-namespace pod communication. Provide exact YAMLs for the policies, commands to verify with curl from representative pods, and rollback steps?","answer":"Implement a per-namespace default-deny NetworkPolicy, then add two policies that allow all traffic within each namespace and an egress rule allowing outbound HTTPS to api.external.com:443. Do not allo","explanation":"## Why This Is Asked\nTests practical network segmentation skills and ability to translate security policies into concrete YAML, plus verification and rollback.\n\n## Key Concepts\n- Kubernetes NetworkPolicy basics\n- default-deny pattern\n- intra-namespace traffic\n- egress controls and limitations\n- validation and rollback\n\n## Code Example\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n```\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: intra-team-a\n  namespace: team-a\nspec:\n  podSelector: {}\n  ingress:\n  - from:\n    - podSelector: {}\n  egress:\n  - to:\n    - podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n```\n```yaml\n# Calico may support FQDN. Standard NP uses IP blocks; replace with FQDN if available.\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-external-api\n  namespace: team-a\nspec:\n  podSelector: {}\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 203.0.113.0/24\n    ports:\n    - protocol: TCP\n      port: 443\n  policyTypes:\n  - Egress\n```\n\n## Follow-up Questions\n- How would you adapt these policies to support a new namespace while preserving least privilege?\n- What metrics would you monitor to detect policy misconfigurations during rollout?","diagram":"flowchart TD\n  N1[Namespace: team-a]\n  N2[Namespace: team-b]\n  D[DefaultDeny]\n  A1[Allow intra-namespace: team-a]\n  A2[Allow intra-namespace: team-b]\n  E[Allow egress to api.external.com:443]\n  Cross[Cross-namespace traffic blocked]\n  N1 --> D\n  N2 --> D\n  D --> A1\n  D --> A2\n  D --> E\n  Cross --> D\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T11:31:56.544Z","createdAt":"2026-01-15T11:31:56.544Z"},{"id":"q-2338","question":"How would you identify memory pressure causing OOMKilled pods in a 3-node Kubernetes cluster (kubectl top, pod events, and logs), compare usage to requests/limits, profile memory if possible, and implement a fix with proper requests/limits, ResourceQuota, and a canary rolling update (maxUnavailable:1) plus a LivenessProbe, then validate with a soak test?","answer":"Begin by inspecting metrics and events: kubectl top to confirm memory pressure, kubectl describe pod to see OOMKilled, and logs for leaks. Compare memory usage against requests/limits to gauge QoS. Pr","explanation":"## Why This Is Asked\n\nTests practical diagnostic skills under production-like pressure, using standard Kubernetes tooling and production-ready safeguards.\n\n## Key Concepts\n\n- Memory pressure and OOMKilled events\n- Requests/limits and QoS classes\n- ResourceQuota and LimitRange\n- Canary rollouts and maxUnavailable\n- LivenessProbe and readiness\n\n## Code Example\n\n```yaml\n# ResourceQuota example\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: mem-quot\nspec:\n  hard:\n    requests.memory: 16Gi\n    limits.memory: 32Gi\n```\n\n```yaml\n# Deployment rolling update\napiVersion: apps/v1\nkind: Deployment\nspec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 25%\n```\n\n## Follow-up Questions\n\n- How would you detect a memory leak vs transient spike?\n- What metrics and alerts would you add for ongoing health?\n- How would you automate this process in a future incident?\n","diagram":"flowchart TD\n  Identify[Identify] --> Collect[Collect Metrics]\n  Collect --> Analyze[Analyze & Hypotheses]\n  Analyze --> Implement[Implement Fixes]\n  Implement --> Validate[Validate & Monitor]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T13:12:59.224Z","createdAt":"2026-01-15T13:12:59.224Z"},{"id":"q-2395","question":"In a shared Kubernetes cluster serving teams at Slack, IBM, and Salesforce, design a namespace-per-tenant isolation strategy with quotas and security controls. Include ResourceQuota, LimitRange, NetworkPolicy, PodSecurity admission, and RBAC. Propose a GitOps deployment flow per-namespace and an observability plan. Compare against a single-namespace approach and justify your choice?","answer":"Namespace-per-tenant with hard ResourceQuota and LimitRange, a default-deny NetworkPolicy, PodSecurity admission, and RBAC scoping admin roles to each tenant with separate ServiceAccounts. Enforce ima","explanation":"## Why This Is Asked\n\nTests ability to design scalable, isolated multi-tenant architecture on Kubernetes with policy enforcement and GitOps.\n\n## Key Concepts\n\n- ResourceQuota\n- LimitRange\n- NetworkPolicy\n- PodSecurity Standards\n- RBAC scope\n- Gatekeeper / OPA\n- GitOps (ArgoCD)\n- Observability (Prometheus, Grafana)\n\n## Code Example\n\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: tenant-a-quota\n  namespace: tenant-a\nspec:\n  hard:\n    requests.cpu: \"4\"\n    requests.memory: 8Gi\n    limits.cpu: \"8\"\n    limits.memory: 16Gi\n    pods: \"20\"\n```\n\n## Follow-up Questions\n\n- How would you test quota enforcement and policy compliance across tenants?\n- How would you evaluate trade-offs between namespace-per-tenant and fewer, larger tenants?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Salesforce","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T16:44:54.004Z","createdAt":"2026-01-15T16:44:54.004Z"},{"id":"q-2519","question":"In a Kubernetes cluster, a Deployment named web-app with 3 replicas in namespace prod suddenly fails after a ConfigMap update that injects environment variables. Pods crash due to a missing DB_PASSWORD from the ConfigMap. Describe exact steps and commands to diagnose, patch the ConfigMap, and roll out a fix with minimal downtime while ensuring the deployment restarts cleanly?","answer":"Triaging with: kubectl describe pod -n prod -l app=web-app; kubectl logs -n prod <pod>. Inspect the ConfigMap: kubectl get configmap web-app-config -n prod -o yaml. If DB_PASSWORD is missing, patch: k","explanation":"## Why This Is Asked\n\nTests practical Kubernetes troubleshooting skills for a real config drift issue, focusing on ConfigMaps, envFrom, and rolling updates.\n\n## Key Concepts\n\n- Diagnosing with describe/logs\n- Inspecting and patching ConfigMaps\n- Rolling restart and wait for readiness\n- Safe downtime and service validation\n\n## Code Example\n\n```bash\nkubectl describe pod -n prod -l app=web-app\nkubectl logs -n dev <pod>\nkubectl get configmap web-app-config -n prod -o yaml\nkubectl patch configmap web-app-config -n prod --type merge -p '{\"data\":{\"DB_PASSWORD\":\"secret\"}}'\nkubectl rollout restart deployment/web-app -n prod\nkubectl rollout status deployment/web-app -n prod\n```\n\n## Follow-up Questions\n\n- How would you automate this rollback if patching the ConfigMap introduces an error?\n- What checks ensure you don’t expose secrets via ConfigMaps?","diagram":"flowchart TD\n  A[ConfigMap updated] --> B[ Pods crash ]\n  B --> C[Patch ConfigMap]\n  C --> D[Rollout restart]\n  D --> E[Pods healthy]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Hashicorp","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T21:30:38.020Z","createdAt":"2026-01-15T21:30:38.020Z"},{"id":"q-2553","question":"In a two-region Kubernetes cluster with 3 nodes per region and a PostgreSQL StatefulSet backed by PVs, deploy a new service image with zero downtime using canary or blue-green. Detail exact rollout steps, traffic shaping, health checks, and data-consistency verification during rollout?","answer":"Implement a canary rollout using Argo Rollouts with progressive traffic shifting. Configure a Rollout resource to upgrade from app:v1 to app:v2 through incremental stages: 10%, 50%, and 100% traffic allocation, with 5-minute verification pauses between each stage. Gate promotions on both readiness probes and custom application metrics. Route traffic using Istio VirtualService to direct the specified percentage to the canary pods, gradually increasing to full traffic upon successful validation. Continuously monitor PostgreSQL replication lag and execute cross-region data consistency checks before each traffic increment to ensure database integrity.","explanation":"## Why This Is Asked\nThis scenario tests real-world deployment of stateful services across multi-region Kubernetes clusters with zero downtime requirements, including sophisticated traffic management and database integrity validation.\n\n## Key Concepts\n- Canary deployment strategies with progressive traffic shifting\n- Argo Rollouts integration with Istio VirtualService for traffic splitting\n- Readiness probes and custom metrics for automated promotion gating\n- PostgreSQL replication health monitoring and cross-region data consistency verification\n\n## Code Example\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: app-rollout\nspec:\n  replicas: 6\n  strategy:\n    canary:\n      steps:\n      - setWeight: 10\n      - pause: {duration: 5m}\n      - setWeight: 50\n      - pause: {duration: 5m}\n      - setWeight: 100\n      trafficRouting:\n        istio:\n          virtualService:\n            name: app-vs\n            routes:\n            - primary\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: app\n        image: app:v2\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n```","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:26:38.435Z","createdAt":"2026-01-15T22:41:59.551Z"},{"id":"q-2584","question":"**Advanced Kubernetes Debugger**: You manage a 12-node cluster on AWS EKS running three microservices. During a surge, a critical deployment experiences OOMKilled. Provide a concrete, end-to-end debugging plan and rollback strategy: include metrics you’d capture, commands you’d run, and exact changes (requests/limits, HPA, PDB, rollout)?","answer":"To debug OOMKilled pods in an EKS cluster during a surge, follow this structured approach:\n\n**1. Immediate Diagnosis**\n- Identify failing pods: `kubectl get pods -n <namespace> --field-selector=status.phase=Failed`\n- Examine pod details and termination reasons: `kubectl describe pod <pod-name> -n <namespace>`\n- Review cluster events: `kubectl get events -n <namespace> --sort-by='.lastTimestamp'`\n- Capture real-time metrics: `kubectl top pod -n <namespace> --containers`\n\n**2. Resource Analysis**\n- Compare actual usage against current requests/limits: `kubectl describe pod <pod-name> -n <namespace> | grep -A 10 \"Containers:\"`\n- Fetch historical metrics: `kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/namespaces/<namespace>/pods\"`\n\n**3. Resource Configuration Updates**\nSet conservative resource specifications:\n```yaml\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n```\n\n**4. Scalability and Resilience**\n- Configure HPA: `kubectl autoscale deployment <name> --cpu-percent=70 --min=2 --max=10 -n <namespace>`\n- Add PodDisruptionBudget: `kubectl apply -f pdb.yaml` with `minAvailable: 1`\n\n**5. Controlled Rollout**\n- Execute restart: `kubectl rollout restart deployment/<name> -n <namespace>`\n- Monitor progress: `kubectl rollout status deployment/<name> -n <namespace> --timeout=300s`\n- Validate pod health: `kubectl get pods -w -n <namespace> --field-selector=status.phase=Running`\n\n**6. Rollback Strategy**\n- If issues persist: `kubectl rollout undo deployment/<name> -n <namespace>`\n- Verify rollback: `kubectl rollout status deployment/<name> -n <namespace>`","explanation":"## Why This Is Asked\nThis question evaluates practical Kubernetes troubleshooting skills under pressure, testing your ability to diagnose OOM issues and implement systematic fixes in production environments.\n\n## Key Concepts\n- **OOMKilled Diagnosis**: Understanding memory pressure scenarios and termination reasons\n- **Resource Management**: Proper configuration of requests/limits for optimal scheduling and stability\n- **Observability Tools**: Leveraging kubectl commands and metrics for real-time debugging\n- **Auto-scaling**: HorizontalPodAutoscaler configuration for dynamic resource allocation\n- **Availability Controls**: PodDisruptionBudgets for maintaining service continuity\n- **Deployment Strategies**: Controlled rollouts and rollback mechanisms for zero-downtime updates\n\n## Code Example\n```yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb\nspec:\n  minAvailable: 1\n  selector:\n    matchLabels:\n      app: myapp\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"200m\"\n```\n\n## Implementation Strategy\nThe response provides a comprehensive debugging methodology that covers immediate diagnosis, root cause analysis, systematic fixes, and validation procedures, demonstrating production-ready Kubernetes expertise.","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:12:32.327Z","createdAt":"2026-01-15T23:43:31.967Z"},{"id":"q-2656","question":"In a three-AZ Kubernetes cluster, design an operator to keep replicas of Deployments labeled app=svc spread across zones, even during node drains. Describe the CRD you would add, the reconcile logic, and how you would validate distribution with tests. Provide a minimal manifest example?","answer":"Explain how to build a Kubernetes operator (Go) that enforces zone-aware pod distribution for Deployments labeled app=svc in a multi-AZ cluster. Include a CRD (ZoneSpread) to declare minDistributions,","explanation":"## Why This Is Asked\nTests practical operator design and CRD usage for real-world cluster reliability.\n\n## Key Concepts\n- Kubernetes operators and the controller pattern\n- PodTopologySpread / TopologySpreadConstraints\n- CustomResourceDefinitions and idempotent reconcile\n- Handling node drains and eviction risk in production\n- Testing: envtest, fake clients, and integration tests\n\n## Code Example\n```yaml\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: zonespreads.acme.example.com\nspec:\n  group: acme.example.com\n  versions:\n  - name: v1beta1\n    served: true\n    storage: true\n    schema:\n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              minDistributions:\n                type: object\n                additionalProperties:\n                  type: integer\n  scope: Namespaced\n  names:\n    plural: zonespreads\n    singular: zonespread\n    kind: ZoneSpread\n```\n\n## Follow-up Questions\n- How would you test behavior during an AZ failure and node drain?\n- What are the trade-offs of using a CRD-driven reconciler vs. relying on built-in topology spread constraints?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","LinkedIn","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:41:43.115Z","createdAt":"2026-01-16T05:41:43.115Z"},{"id":"q-2721","question":"In a 6-node Kubernetes cluster, a critical stateless service is upgraded via RollingUpdate. Ensure availability never drops below 80% of replicas during the upgrade. Outline a concrete rollout plan with specific values for maxUnavailable, maxSurge, and a PodDisruptionBudget, plus readiness probes, preStop hooks, and a rollback strategy. Include how you'd verify rollout status and handle failure?","answer":"During the upgrade, configure RollingUpdate with maxUnavailable: 1 and maxSurge: 1 for a 6-replica deployment (ensures at least 5 pods up). Enforce a PodDisruptionBudget with minAvailable: 5. Implemen","explanation":"Why asked: tests knowledge of safe upgrades and HA. Key concepts: RollingUpdate strategy, maxUnavailable, maxSurge, PodDisruptionBudget, readiness/liveness probes, preStop, rollback. Code snippets: Deployment and PDB YAML. Follow-up: simulate upgrade, compare rollout status, and adjust thresholds.","diagram":"flowchart TD\n  A[Upgrade Plan] --> B[Set RollingUpdate strategy]\n  B --> C[Apply PodDisruptionBudget]\n  C --> D[Configure probes and preStop]\n  D --> E[Verify rollout and monitor]\n  E --> F[Rollback if failure]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T09:35:03.220Z","createdAt":"2026-01-16T09:35:03.222Z"},{"id":"q-2939","question":"Design a production-grade Kubernetes cluster with a three-node HA control plane across AZs. Explain how you ensure etcd backups and retention, implement per-tenant RBAC, enforce NetworkPolicy isolation, and deploy canaries with automated rollback. Include concrete commands, monitoring checks, and rollback criteria?","answer":"Design a 3-node HA control plane across AZs with etcd snapshots every 5 minutes and 30-day retention. Enforce per-namespace RBAC with Roles and RoleBindings, isolate tenants with NetworkPolicy (Calico","explanation":"## Why This Is Asked\nThis question probes depth in cluster HA, RBAC, network isolation, and safe canary deployments under real-world constraints.\n\n## Key Concepts\n- HA control plane architecture across AZs\n- etcd backup strategy and retention\n- Namespace-scoped RBAC with Roles/Bindings\n- NetworkPolicy-based tenant isolation (Calico or equivalent)\n- Canary deployments and automated rollbacks with monitoring\n\n## Code Example\n```javascript\n// Pseudo canary rollout helper\nasync function canaryRollout(service, version, pct){\n  // shift traffic\n  await shiftTraffic(service, version, pct);\n  // health check\n  const ok = await checkHealth(service);\n  if (!ok) await rollback(service, version);\n}\n```\n\n## Follow-up Questions\n- How would you measure canary success and rollback safety at scale?\n- How would you evolve RBAC and namespace isolation as tenants grow?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T18:44:54.200Z","createdAt":"2026-01-16T18:44:54.200Z"},{"id":"q-3024","question":"You're operating a multi-tenant Kubernetes cluster with DoorDash-like traffic. A new service must scale from 2 to 40 pods at peak while minimizing waste. Describe how you would configure ResourceQuota, LimitRange, HPA, and PodDisruptionBudget, plus how you would implement canary deployments and observability to ensure zero-downtime during node maintenance?","answer":"Implement per-namespace ResourceQuota and LimitRange policies with container requests and limits derived from load testing (e.g., 300m CPU, 512Mi RAM per pod). Configure Horizontal Pod Autoscaler using both CPU and custom metrics, setting minimum replicas to 2 and maximum to 40. Establish PodDisruptionBudget to maintain 80% availability during node maintenance. Deploy using a canary strategy with progressive traffic splitting while monitoring key business metrics. Implement comprehensive observability with Prometheus metrics collection, Grafana dashboards, and alerting on deployment success rates, error rates, and response times.","explanation":"## Why This Is Asked\nThis question evaluates practical Kubernetes governance capabilities through resource quotas and limits, autoscaling strategies using HPA with custom metrics, availability controls via PodDisruptionBudget, and safe deployment practices using canary releases under real-world traffic conditions. It also assesses observability implementation and operational hygiene during maintenance windows.\n\n## Key Concepts\n- ResourceQuota and LimitRange for resource governance\n- Horizontal Pod Autoscaler with custom metrics for scaling\n- PodDisruptionBudget for availability guarantees\n- Canary deployments for zero-downtime releases\n- Observability stack with Prometheus and Grafana\n- Load testing for resource capacity planning\n- Traffic splitting strategies for gradual rollouts\n- Alerting on key performance and business metrics","diagram":"flowchart TD\n  Ns[Namespace] --> Q[ResourceQuota]\n  Q --> L[LimitRange]\n  Ns --> H[HPA: min 2, max 40]\n  H --> P[Pods]\n  P --> B[PDB: minAvailable 70%]\n  B --> Can[CanaryDeployment]\n  Can --> O[Observability: Prometheus/Grafana]\n  O --> M[Maintenance taints]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","DoorDash","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:44:41.201Z","createdAt":"2026-01-16T21:41:52.978Z"},{"id":"q-3117","question":"A Deployment in namespace default has 3 replicas, and one pod is CrashLoopBackOff after a rollout. List exact commands and checks you would perform to diagnose, including how you view logs, events, and the container state, and how you verify the fix with a safe rollout?","answer":"Run kubectl get pods -n default; kubectl describe pod <pod> -n default; kubectl logs <pod> -c <container> --previous; kubectl get events -n default; kubectl rollout status deployment/<name> -n default","explanation":"## Why This Is Asked\nThe question probes practical troubleshooting steps, move quickly from symptom to evidence, and confirms use of kubectl basics in real life.\n\n## Key Concepts\n- kubectl pod inspection, events, logs, and rollout status\n- diagnosing CrashLoopBackOff and image issues\n- safe rollout strategy and verification\n\n## Code Example\n\n```bash\nkubectl get pods -n default\nkubectl describe pod <pod> -n default\nkubectl logs <pod> -c <container> --previous\nkubectl get events -n default\nkubectl rollout status deployment/<name> -n default\n```\n\n## Follow-up Questions\n- What would you check if logs show OOMKilled?\n- How would you revert a faulty rollout without downtime?","diagram":"flowchart TD\n  A[Pod crash] --> B[Describe pod]\n  B --> C[Check logs]\n  C --> D[Check events/rollout]\n  D --> E[Apply fix and verify]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Oracle","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:01:07.773Z","createdAt":"2026-01-17T04:01:07.773Z"},{"id":"q-3141","question":"Implement namespace-scoped RBAC in a 5-namespace cluster to run a batch Job in tenant-a that must not read Secrets unless explicitly allowed. Outline concrete Roles, RoleBindings, and test steps with exact kubectl commands and YAML to verify denial and controlled grant, including can-i checks and a sample Job manifest?","answer":"Create namespace tenant-a; create serviceaccount batch-sa in tenant-a; define Role read-pods-cm with verbs get/list in tenant-a for pods and configmaps only; bind via RoleBinding batch-sa-read-pods-cm","explanation":"## Why This Is Asked\n\nTests ability to design precise, namespace-scoped RBAC changes and validate with can-i commands, a common real-world task in security-conscious orgs.\n\n## Key Concepts\n\n- Namespace-scoped RBAC\n- Roles vs RoleBindings\n- can-i validation\n- Audit-friendly changes\n\n## Code Example\n\n```yaml\n# Role\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: read-pods-cm\n  namespace: tenant-a\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\",\"configmaps\"]\n  verbs: [\"get\",\"list\"]\n\n# RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: batch-sa-read-pods-cm\n  namespace: tenant-a\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: read-pods-cm\nsubjects:\n- kind: ServiceAccount\n  name: batch-sa\n  namespace: tenant-a\n```\n\n```yaml\n# Optional: test manifest to simulate a batch job using the SA (not granting secrets yet)\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: test-job\n  namespace: tenant-a\nspec:\n  template:\n    spec:\n      serviceAccountName: batch-sa\n      containers:\n      - name: test\n        image: busybox\n        command: [\"sh\", \"-c\", \"echo hello\"]\n      restartPolicy: Never\n```\n\n## Follow-up Questions\n\n- How would you audit RBAC changes across namespaces?\n- How would you handle temporary elevated access without permanent grants?\n","diagram":"flowchart TD\n  A[Tenant-A Namespace] --> B[batch-sa]\n  B --> C[Role: read-pods-cm]\n  C --> D[RoleBinding: batch-sa-read-pods-cm]\n  D --> E[can-i test: deny]\n  E --> F[grant: add Role for secrets and rebind]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Goldman Sachs","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:41:50.197Z","createdAt":"2026-01-17T04:41:50.197Z"},{"id":"q-3299","question":"In a 5-node cluster with 3 control-plane nodes and 2 workers, upgrading from v1.26 to v1.28 with zero downtime and CRD migrations. Provide a concrete, command-driven upgrade plan: pre-checks, etcd backup, upgrade order, drain strategy, CRD handling, and post-upgrade validation. What exact steps ensure zero-downtime during the upgrade?","answer":"Take an etcd backup, verify the upgrade plan, then drain and upgrade control-plane nodes one by one, applying kubeadm upgrade apply on each. After masters, upgrade workers; reproduce readiness checks ","explanation":"## Why This Is Asked\nThis question probes practical mastery of safe in-cluster upgrades, downtime controls, etcd backup, CRD migrations, and post-upgrade validation.\n\n## Key Concepts\n- etcd backup and restore\n- Rolling upgrades and drain strategies\n- CRD lifecycle and API versions\n\n## Code Example\n```javascript\n// sample commands\netcdctl snapshot save /tmp/snap.db\nkubectl get nodes\n```\n\n## Follow-up Questions\n- How would you verify CRD migrations without downtime?\n- How do you handle webhook config migration during upgrade?","diagram":"flowchart TD\n  A[Etcd Backup] --> B[Upgrade Plan]\n  B --> C[Upgrade Control-Plane]\n  C --> D[Upgrade Workers]\n  D --> E[Post-Upgrade Validation]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","LinkedIn","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T10:37:39.785Z","createdAt":"2026-01-17T10:37:39.786Z"},{"id":"q-3351","question":"Explain a concrete, production‑readiness plan to run a 3‑node **etcd** cluster across **AZs** with a primary region and disaster recovery in a separate region. Include deployment topology, TLS/mTLS, backup/restore (etcdctl snapshot), upgrade strategy, monitoring, and a tested failover process. What commands and checks would you rely on?","answer":"Maintain an odd-quorum 3-node etcd across AZs with TLS/mTLS and cert rotation. Automate backups using etcdctl snapshot to object storage (daily, rotated). Keep a hot DR cluster in a separate region an","explanation":"## Why This Is Asked\n\nAssesses practical HA/DR pragmatics for critical etcd data in real clusters.\n\n## Key Concepts\n\n- etcd quorum and multi-AZ topology\n- TLS/mTLS, cert management\n- Backups, rotation, restore drills\n- DR failover playbooks and verification\n\n## Code Example\n\n```javascript\n// Example: snapshot save to object store\nETCDCTL_API=3 etcdctl snapshot save s3://bucket/etcd-snap-$(date +%Y%m%d).snap --endpoints=https://host1:2379 --cacert ca.pem --cert server.pem --key key.pem\n```\n\n## Follow-up Questions\n\n- How would you monitor etcd health during upgrades?\n- What changes would you make to support regional DR while minimizing RPO/RTO?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Lyft","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T13:07:40.495Z","createdAt":"2026-01-17T13:07:40.495Z"},{"id":"q-3374","question":"Scenario: In a 5-node cluster (3 workers, 2 control-planes) with many namespaces, introduce a new requirement to strictly enforce tenant-level network egress controls using Calico without downtime. Outline a concrete rollout plan to implement namespace-scoped egress policies with default deny, ensuring existing pods can still reach DNS, API server, and private registry. Include policy snippets, rollout steps, and verification methods?","answer":"Label each tenant namespace; apply a canary Calico NetworkPolicy per-namespace that allows DNS, kubernetes API server, and private registry traffic, then enforce a cluster-wide default deny egress. Va","explanation":"## Why This Is Asked\nTests practical knowledge of Calico NetworkPolicy, namespace-scoped controls, and safe multi-tenant rollouts without downtime.\n\n## Key Concepts\n- Calico NetworkPolicy and per-namespace scoping\n- Default deny egress baseline\n- Canary rollout across namespaces\n- In-cluster validation using test pods\n- Rollback and monitoring strategies\n\n## Code Example\n```javascript\n// Calico namespace policy (illustrative)\n{\n  apiVersion: \"projectcalico.org/v3\",\n  kind: \"NetworkPolicy\",\n  metadata: { name: \"ns-egress-allow-core\", namespace: \"tenant-a\" },\n  spec: {\n    types: [\"Egress\"],\n    egress: [\n      { destination: { ports: [{ protocol: \"UDP\", port: 53 }] } },\n      { destination: { nets: [\"10.0.0.0/8\"], ports: [{ protocol: \"TCP\", port: 443 }] } },\n      { action: \"Allow\", destination: { nets: [\"<PRIVATE_REGISTRY_CIDR>\"] } }\n    ]\n  }\n}\n```\n\n## Follow-up Questions\n- How would you validate a rollback and define rollback criteria?\n- What monitoring would you add to detect policy misconfigurations early?","diagram":"flowchart TD\n  A[Start] --> B[Label tenants namespaces]\n  B --> C[Create per-namespace policy]\n  C --> D[Set default deny egress]\n  D --> E[Validate with test pods]\n  E --> F[Canary rollout across namespaces]\n  F --> G[Monitor events]\n  G --> H[Complete]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T13:48:18.763Z","createdAt":"2026-01-17T13:48:18.763Z"},{"id":"q-3400","question":"You're running a 3-member MongoDB replica set as a StatefulSet on Kubernetes. A long-running backup is required to be consistent and zero-downtime, using Kubernetes VolumeSnapshots for the PVCs. Outline a precise, end-to-end plan to produce a crash-consistent snapshot: coordinate a primary fsyncLock, snapshot all MongoDB PVCs, and fsyncUnlock; handle possible primary failover during the window; and validate the snapshot and readiness for DR?","answer":"Identify the primary with rs.status(); on primary run db.fsyncLock(); create VolumeSnapshots for each mongo-data PVC (one per StatefulSet pod); wait for all snapshots to become ReadyToUse; run db.fsyn","explanation":"## Why This Is Asked\nTests ability to design crash-consistent, zero-downtime backups for StatefulSet-based MongoDB replicas using Kubernetes VolumeSnapshot.\n\n## Key Concepts\n- fsyncLock semantics and risks\n- VolumeSnapshot lifecycle for StatefulSets\n- Crash-consistent backups across replica sets\n- Post-backup validation and DR readiness\n\n## Code Example\n```bash\n# on primary\nrs.status()\ndb.fsyncLock()\n```\n\n```yaml\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: mongo-0-snap\nspec:\n  volumeSnapshotClassName: csi-hostpath-snap\n  source:\n    persistentVolumeClaimName: mongo-0-data\n```\n\n## Follow-up Questions\n- How would you automate snapshot timing with a Kubernetes Job?\n- How would you test restores across all replicas?","diagram":"flowchart TD\n  A[Primary] --> B[db.fsyncLock()]\n  B --> C[VolumeSnapshots for PVCs]\n  C --> D[db.fsyncUnlock()]\n  D --> E[Validation & DR readiness]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T14:38:41.445Z","createdAt":"2026-01-17T14:38:41.445Z"},{"id":"q-3408","question":"You're given a 1-node Kubernetes cluster with a Deployment named web-app that reports ImagePullBackOff. Describe the exact, practical steps you would take to diagnose the image pull error, configure registry authentication with imagePullSecrets, update the Deployment manifest, and verify the pod becomes Ready?","answer":"Run: kubectl get pods -n default; kubectl describe pod web-app-<pod> -n default to confirm ImagePullBackOff. Check events: kubectl get events -n default --sort-by=.lastTimestamp. Verify image name and","explanation":"## Why This Is Asked\n\nThis question probes practical Kubernetes troubleshooting at beginner level, focusing on diagnosing image pull failures with real commands and concepts like image names, tags, and registry auth.\n\n## Key Concepts\n\n- Kubernetes Deployments and Pods\n- kubectl commands for troubleshooting\n- ImagePullBackOff errors\n- imagePullSecrets and private registries\n- Rollout status and service validation\n\n## Code Example\n\n```javascript\n// Conceptual patch example to attach an imagePullSecret programmatically\npatchDeploymentImagePullSecrets('default','web-app','reg-creds');\n```\n\n## Follow-up Questions\n\n- How do you handle images with multiple registries?\n- What pitfalls exist with imagePullSecrets across namespaces?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T15:27:47.469Z","createdAt":"2026-01-17T15:27:47.471Z"},{"id":"q-3571","question":"You're operating a 5-node Kubernetes cluster (3 control-plane, 2 workers). A suspected abuse of cluster privileges is detected via noisy API activity. Outline a concrete plan to enable rigorous auditing, contain the risk, and verify no unauthorized actions occur without disrupting legitimate workloads. Include exact commands or file samples for audit policy, apiserver flags, log forwarding, and validation steps?","answer":"Enable comprehensive Kubernetes auditing by first creating an audit policy that captures critical security events. Apply audit-policy.yaml with Metadata-level logging for system namespaces and Request-level logging for sensitive resources including pods, secrets, service accounts, and RBAC objects. Restart the API server with --audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit.log --audit-log-maxage=30 --audit-log-maxbackup=10 --audit-log-maxsize=100. Configure log forwarding using Fluent Bit with a dedicated input processor for audit logs, shipping to your SIEM with proper parsing and alerting rules. Implement immediate containment by applying emergency deny-all NetworkPolicies to non-essential namespaces and conducting a thorough service account permission review. Validate the setup by testing with kubectl auth can-i commands, monitoring audit log generation in real-time, and establishing baseline API patterns to detect anomalies.","explanation":"## Why This Is Asked\nTests ability to design a comprehensive audit and containment strategy with specific implementation details and validation methods.\n\n## Key Concepts\n- Kubernetes audit policy configuration\n- API server audit logging parameters\n- Log aggregation and SIEM integration\n- RBAC containment strategies\n- NetworkPolicy-based isolation\n- Audit log validation and monitoring\n\n## Code Example\n```yaml\n# audit-policy.yaml example\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: Metadata\n  namespaces: [\"kube-system\", \"kube-public\"]\n- level: Request\n  resources:\n  - group: \"\"\n    resources: [\"pods\", \"secrets\", \"serviceaccounts\"]\n  - group: \"rbac.authorization.k8s.io\"\n    resources: [\"roles\", \"rolebindings\"]\n```","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Meta","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:43:26.644Z","createdAt":"2026-01-17T21:37:21.460Z"},{"id":"q-3606","question":"Scenario: A 5-node Kubernetes cluster experiences intermittent DNS failures after a rolling CoreDNS upgrade that disrupts frontend service resolution. Describe concrete steps to diagnose and fix, including how to inspect CoreDNS pods and ConfigMap, how to test DNS from a pod, how to adjust the Corefile (cache TTL, forwarders), and how to validate under load?","answer":"Describe concrete steps to diagnose intermittent DNS failures after a CoreDNS rolling upgrade in a 5-node cluster: check CoreDNS pod status and logs, inspect CoreDNS ConfigMap and Corefile configuration, test DNS resolution from within pods using nslookup and dig, analyze cache settings and forwarders, adjust Corefile parameters (cache TTL, upstream servers), implement rollout strategies, and validate DNS performance under load using testing tools.","explanation":"## Why This Is Asked\n\nThis question probes practical Kubernetes DNS troubleshooting, CoreDNS configuration, and upgrade reliability—core CKAs must resolve DNS under real-world churn.\n\n## Key Concepts\n\n- CoreDNS deployment and Corefile configuration\n- DNS testing from within pods (nslookup, dig)\n- ConfigMap editing and rollout strategies\n- Observability: logs, events, rollouts, metrics\n- Load testing and performance validation\n\n## Code Example\n\n```bash\nkubectl get pods -n kube-system -l k8s-app=coredns\nkubectl -n kube-system get configmap coredns -o yaml\nkubectl rollout restart deploy/coredns -n kube-system\n```","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Lyft","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:28:59.794Z","createdAt":"2026-01-17T23:31:38.579Z"},{"id":"q-3700","question":"You manage a 3-node Kubernetes cluster with a StatefulSet named 'db' consisting of 3 replicas, each using PVCs provisioned by the CSI storage class 'fast-ssd'. A data-intensive resize from 100Gi to 150Gi must be done with zero downtime. Outline a concrete plan: confirm expansion support, resize all PVCs, grow the filesystem inside pods, perform a rolling restart with a PodDisruptionBudget, verify data integrity, and specify rollback steps if expansion fails?","answer":"Verify fast-ssd supports online expansion and PVCs are bound. Patch each PVC to 150Gi one by one, then grow the filesystem inside each pod (db-0, db-1, db-2) to utilize the new space. Trigger a rollin","explanation":"## Why This Is Asked\nTests practical, zero-downtime storage resizing in a StatefulSet using CSI volumes, including proper sequencing and rollback.\n\n## Key Concepts\n- CSI online volume expansion\n- StatefulSet rolling updates with PodDisruptionBudget\n- Filesystem resize inside container\n- Data integrity verification and rollback\n\n## Code Example\n```javascript\n# Kubernetes sanity\nkubectl get sc fast-ssd -o jsonpath='{.allowVolumeExpansion}'\n\n# Expand PVCs\nkubectl patch pvc db-0 -n default -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"150Gi\"}}}}'\nkubectl patch pvc db-1 -n default -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"150Gi\"}}}}'\nkubectl patch pvc db-2 -n default -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"150Gi\"}}}}'\n\n# Rolling restart (FS resize depends on driver; may auto-resize)\nkubectl rollout restart statefulset/db -n default\n\n# Data integrity check (DB-specific)\n# e.g., run a consistency/replication check script\n```\n\n## Follow-up Questions\n- How would you validate no data loss during expansion?\n- How would you automate this in a CI/CD pipeline with idempotent steps?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Oracle","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:47:34.502Z","createdAt":"2026-01-18T05:47:34.502Z"},{"id":"q-3703","question":"In a 4-node Kubernetes cluster, enable mutual TLS across all namespaces using Linkerd, enforce mTLS by default, and verify that only services with Linkerd sidecars can communicate with a backend API on port 8080 while a plain pod cannot. Provide exact commands to install Linkerd, inject sidecars, deploy apps, and perform tests?","answer":"Install Linkerd control plane and check: curl -sL https://run.linkerd.io/install | sh; linkerd install | kubectl apply -f -; linkerd check; enable auto-injection on app namespace: kubectl label ns app","explanation":"## Why This Is Asked\nTests practical service-mesh setup, mTLS enforcement, and verification of sidecar behavior in real clusters.\n\n## Key Concepts\n- Linkerd installation and validation\n- Namespace auto-injection and sidecar presence\n- mTLS enforcement and trust domain verification\n- In-cluster end-to-end testing with injected vs plain pods\n\n## Code Example\n```javascript\n# Install and check\ncurl -sL https://run.linkerd.io/install | sh\nlinkerd install | kubectl apply -f -\nlinkerd check\n\n# Enable auto-injection and roll out\nkubectl label ns app linkerd.io/inject=enabled\nkubectl rollout restart deploy -n app\n\n# Verify sidecars\nkubectl get pods -n app -o jsonpath='{.items[*].spec.containers[*].name}'\n\n# Tests\n# Injected pod test\nkubectl run test-injected --rm -it --image=busybox -n app -- sh\n# inside pod: wget or curl to backend\ncurl http://backend:8080/health\n\n# Plain pod test\nkubectl run test-plain --rm -it --image=busybox -n app -- sh\n# inside pod: curl to backend (should fail due to mTLS)\ncurl http://backend:8080/health\n```\n\n## Follow-up Questions\n- How would you rotate the trust anchor without downtime?\n- How would you monitor and alert if sidecar injection drifts across namespaces?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T06:43:16.591Z","createdAt":"2026-01-18T06:43:16.591Z"},{"id":"q-3779","question":"You're given a Kubernetes cluster with Deployment web-api (3 replicas). One pod shows CrashLoopBackOff; describe the exact diagnostic steps (commands, log files, and configs) you would perform to identify the root cause, verify the fix, and restore the deployment to healthy. Include how you'd inspect events, container exit codes, and readiness probes?","answer":"I would run kubectl describe pod <pod> to capture crash reason, then kubectl logs <pod> --previous to view the exit message, followed by kubectl get events --sort-by='.lastTimestamp' to surface failur","explanation":"## Why This Is Asked\n\nThis question evaluates practical, repeatable debugging workflows in Kubernetes, not high-level theory. It checks familiarity with kubectl, pod lifecycle, and safe rollout practices.\n\n## Key Concepts\n\n- CrashLoopBackOff diagnosis\n- kubectl describe, logs, and get events\n- Readiness/Liveness probes and probe misconfig\n- ConfigMaps/Secrets and image/env validation\n\n## Code Example\n\n```javascript\nkubectl describe pod web-api-abc\nkubectl logs web-api-abc --previous\nkubectl get events --sort-by='.lastTimestamp'\nkubectl rollout status deployment/web-api\n```\n\n## Follow-up Questions\n\n- How would you adjust a failing readiness probe without causing downtime?\n- What checks prevent recurrence when deploying new images?","diagram":"flowchart TD\n  A[CrashLoopBackOff] --> B[Diagnose Pod]\n  B --> C[Check logs]\n  B --> D[Check events]\n  B --> E[Check probes]\n  E --> F[Apply fix]\n  F --> G[Rollout status]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","MongoDB","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T09:32:30.512Z","createdAt":"2026-01-18T09:32:30.512Z"},{"id":"q-3856","question":"In a Kubernetes cluster with a StatefulSet running 3 PostgreSQL pods across three AZs, you observe intermittent 10–20s startup delays and rollout stalls during updates. Describe exact, actionable steps you would take to diagnose and remediate while preserving availability?","answer":"Inspect events and pod descriptions. Confirm readiness and startupProbe settings, adjust startupProbe to tolerate longer init times, and ensure livenessProbe doesn't target unhealthy pods. Apply a Pod","explanation":"## Why This Is Asked\nRealistic production troubleshooting asks for concrete steps across probes, updates, and storage to preserve availability.\n\n## Key Concepts\n- Probes: readiness, startup, liveness\n- StatefulSets and RollingUpdate partition\n- PodDisruptionBudget\n- PVCs and storageClass WaitForFirstConsumer\n- Canary or staged rollout\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: pg\nspec:\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      partition: 0\n  template:\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:13\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 5432\n          initialDelaySeconds: 15\n          periodSeconds: 5\n        startupProbe:\n          exec:\n            command: [\"bash\",\"-lc\",\"pg_isready -U postgres\"]\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n```\n\n## Follow-up Questions\n- How would you test changes in a staging namespace?\n- How would you monitor rollout progress and rollback if issues arise?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T13:00:37.629Z","createdAt":"2026-01-18T13:00:37.630Z"},{"id":"q-3950","question":"Scenario: A 3-replica Deployment behind a ClusterIP Service experiences sporadic pod restarts with OOMKilled during peak load. Provide a concrete debugging plan and implement fixes: add memory requests/limits, readinessProbe and livenessProbe, and a horizontal autoscaler. Include exact kubectl commands and YAML fragments you would apply?","answer":"Start by collecting pod events and logs: kubectl describe pod <pod>; kubectl logs <pod> -c <container> --previous; kubectl top pod <pod>. If memory overuse, patch the Deployment with resources: reques","explanation":"\"## Why This Is Asked\"\\n\\nTests practical Kubernetes debugging and implementation steps candidates would perform in real environments, focusing on convex changes to stabilize a service during peak load.\\n\\n\"## Key Concepts\"\\n\\n- Resource requests/limits and their impact on scheduling and OOM protection\\n- Pod lifecycle probes (readiness and liveness)\\n- Diagnostic commands (describe, logs, top)\\n- Horizontal Pod Autoscaler basics and redeploy workflow\\n\\n\"## Code Example\"\\n\\n```yaml\\nresources:\\n  requests:\\n    memory: 128Mi\\n    cpu: 100m\\n  limits:\\n    memory: 256Mi\\n    cpu: 250m\\nreadinessProbe:\\n  httpGet:\\n    path: /health\\n    port: 8080\\nlivenessProbe:\\n  httpGet:\\n    path: /health\\n    port: 8080\\n  initialDelaySeconds: 30\\n  periodSeconds: 15\\n```\\n\\n\"## Follow-up Questions\"\\n\\n- How would you test changes in a staging environment before production cutover?\\n- How would you apply cluster-wide defaults for resource usage (LimitRange/ResourceQuota) per namespace?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T16:46:21.466Z","createdAt":"2026-01-18T16:46:21.466Z"},{"id":"q-4035","question":"You deploy a 3-replica Deployment for a Node.js app on Kubernetes; pods crash during startup and show CrashLoopBackOff. Describe a practical debugging workflow using kubectl and provide a minimal readinessProbe and livenessProbe for port 3000 /health to ensure traffic only reaches healthy pods?","answer":"Begin by checking `kubectl describe pod <pod>` to identify CrashLoopBackOff events and examine pod status, then use `kubectl logs -p <pod>` to view previous container logs and identify startup errors. Verify the image exists, the command is correct, and environment variables are properly configured. Add a readinessProbe on port 3000 at /health to ensure traffic only reaches pods that have successfully started.","explanation":"## Why This Is Asked\nThis question tests practical debugging skills for Kubernetes pod startup failures and the ability to implement proper health checks to ensure service reliability.\n\n## Key Concepts\n- CrashLoopBackOff diagnosis using `kubectl describe pod` and `kubectl logs`\n- Distinguishing between readiness and liveness probes for different failure scenarios\n- Minimal, safe probe configuration to prevent routing traffic to unhealthy pods\n\n## Code Example\n```javascript\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: node-app\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: app\n        image: mynode:latest\n        ports:\n        - containerPort: 3000\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 15\n          periodSeconds: 20\n```","diagram":"flowchart TD\n  A[Diagnose Pod] --> B[Describe Pod]\n  B --> C[Check Logs]\n  C --> D[Add Probes]\n  D --> E[Rollout Status]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T05:04:36.105Z","createdAt":"2026-01-18T20:46:13.839Z"},{"id":"q-4163","question":"Scenario: In production, a Deployment named order-processor in namespace prod uses a ConfigMap named app-config with LOG_LEVEL and a Secret app-secret with API_KEY. The Pod fails to start because API_KEY is missing. Provide a practical fix: 1) ensure Secret exists and mounted, 2) wire LOG_LEVEL and API_KEY into env vars from ConfigMap/Secret, 3) add readinessProbe on port 8080 and a livenessProbe, 4) outline a 0-downtime rollout approach and verification steps?","answer":"Create or verify the Secret and patch the Deployment to pull LOG_LEVEL from the ConfigMap and API_KEY from the Secret via envFrom/valueFrom. Add readiness and liveness probes (httpGet /health on 8080)","explanation":"## Why This Is Asked\nThis question tests practical Kubernetes ops: wiring config and secrets, ensuring startup with proper probes, and performing safe rolling updates. It emphasizes real-world constraints like zero-downtime deploys and quick verification.\n\n## Key Concepts\n- ConfigMap/Secret envFrom and valueFrom\n- Probes: readiness and liveness\n- Rolling updates and maxUnavailable\n- Verification: kubectl rollout status, in-cluster health checks\n- Secrets handling and least-privilege access\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-processor\n  namespace: prod\nspec:\n  template:\n    spec:\n      containers:\n      - name: order-processor\n        image: example/order-processor:latest\n        env:\n        - name: LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: app-config\n              key: LOG_LEVEL\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: app-secret\n              key: API_KEY\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 20\n```","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T05:50:46.914Z","createdAt":"2026-01-19T05:50:46.914Z"},{"id":"q-4183","question":"You have a Kubernetes Deployment running in a single-node cluster. A pod restarts with OOMKilled after a few minutes. Describe exact, concrete steps you would take to diagnose and fix the issue, including commands, YAML changes, and how you would verify the fix?","answer":"Diagnose a pod OOMKilled in Kubernetes: review events and pod description, check current resource requests/limits with kubectl describe pod, and inspect node memory with kubectl top node. If memory li","explanation":"## Why This Is Asked\n\nTests practical troubleshooting ability: how to use kubectl to diagnose OOMKilled, read events, inspect resources, and adapt manifests with safe rollout\n\n## Key Concepts\n\n- OOMKilled, resource requests/limits, node memory\n- kubectl describe/logs/top, kubectl get events\n- Deployment YAML changes, kubectl apply, rollout restart\n- Validation: pod stability, rollout status\n\n## Code Example\n\n```bash\nkubectl describe pod <pod-name>\nkubectl logs <pod-name> --previous\nkubectl top node\nkubectl get events --sort-by=.lastTimestamp\n```\n\n## Follow-up Questions\n\n- How would you prevent OOMKilled in a multi‑node cluster (limits, requests, HPA)?\n- When would you choose vertical vs horizontal scaling to resolve memory pressure?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","OpenAI","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T07:00:08.036Z","createdAt":"2026-01-19T07:00:08.036Z"},{"id":"q-4288","question":"A 4-node Kubernetes cluster serves a stateless web app behind a LoadBalancer Service. After applying a hotfix, 25–30% of pods crash with CrashLoopBackOff and requests show 5xx errors. Outline a real-world diagnosis and rollback plan, including exact kubectl commands to inspect rollout status, pods, events, ConfigMaps/Secrets, verify readiness/liveness probes, adjust resource requests/limits, and implement a canary rollout to shift traffic safely?","answer":"kubectl rollout status deployment/web; kubectl get pods -l app=web -o wide; kubectl describe pod <pod>; kubectl get events --sort-by=.lastTimestamp; kubectl get configmap web-config -o yaml; adjust re","explanation":"## Why This Is Asked\nTests hands-on Kubernetes troubleshooting under outage conditions, emphasizing practical diagnosis, rollback, and canary rollout strategies in production-like settings.\n\n## Key Concepts\n- Rollout management and safe updates\n- CrashLoopBackOff debugging techniques\n- ConfigMaps/Secrets impact on pods\n- Readiness and Liveness probes configuration\n- Canary/blue-green deployment patterns\n- Observability for rollout decisions\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 4\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  template:\n    spec:\n      containers:\n      - name: web\n        image: repo/web:hotfix\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n        envFrom:\n        - configMapRef:\n            name: web-config\n```\n\n## Follow-up Questions\n- What signals would you monitor to confirm canary success?\n- How would you automate rollback in a multi-namespace environment?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","LinkedIn","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T11:36:32.509Z","createdAt":"2026-01-19T11:36:32.509Z"},{"id":"q-4388","question":"Scenario: A 3-node, etcd-backed Kubernetes control plane on bare metal managed by kubeadm has suffered a regional outage that left only one master up. Provide a precise disaster-recovery plan to restore a healthy 3-member etcd quorum and API control plane within 20 minutes, including etcd snapshot restoration, rejoining control-plane nodes, updating manifests, and verification steps with exact commands?","answer":"On surviving master: restore etcd from latest snapshot to /var/lib/etcd, start etcd with the restored member in the quorum, then kubeadm reset the failed master and kubeadm init with the same --contro","explanation":"## Why This Is Asked\n\nTests hands-on DR skills for control-plane repair, including etcd backup/restore, member reconfiguration, and kubeadm bootstrap under time pressure.\n\n## Key Concepts\n\n- etcd snapshot/restore\n- control-plane HA\n- kubeadm reset/init\n- static pod bootstrap and API server repair\n\n## Code Example\n\n```bash\n# On surviving master\netcdctl snapshot restore /var/backups/etcd/snapshot.db \\\n  --name=master1 --initial-cluster master1=https://10.0.0.1:2380,master2=https://10.0.0.2:2380,master3=https://10.0.0.3:2380 \\\n  --data-dir=/var/lib/etcd\nsystemctl restart etcd\n```\n\n```bash\n# Rebuild control plane\nkubeadm reset -f\nkubeadm init --control-plane-endpoint \"k8s-master:6443\" --upload-certs\n```\n\n## Follow-up Questions\n\n- How would you validate cluster health after recovery?\n- What are failure modes if time skew is present across masters?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T16:53:28.548Z","createdAt":"2026-01-19T16:53:28.548Z"},{"id":"q-4450","question":"CRD Migration in a 3-AZ cluster with a StatefulSet of 5 PV-backed pods: migrate CRDs from v1alpha1 to v1 without downtime or data loss. Provide a concrete end-to-end plan: conversion webhook strategy, canary rollout per CRD, etcd backup/restore, upgrade order (APIServer, controller-manager, operator), and rollback criteria with exact kubectl commands?","answer":"Backup etcd (etcdctl snapshot save) and validate integrity; enable a conversion webhook to migrate v1alpha1 to v1; perform canary upgrades on a subset of CRs, monitor status with kubectl get crd/statu","explanation":"## Why This Is Asked\nTests practical planning under real-world constraints: CRD migrations with zero downtime, data integrity, and safe rollback.\n\n## Key Concepts\n- CRD versioning and conversion webhooks\n- Canary/blue-green rollout for CRs\n- etcd backup/restore procedures\n- Upgrade sequencing of API components\n- Rollback criteria and verification\n\n## Code Example\n```javascript\n# Example commands for the plan\netcdctl snapshot save backup.db\nkubectl get crd your CRD -o yaml | yq '.spec.versions[]|select(.name==\"v1\").served = true'\nkubectl apply -f webhook.yaml\nkubectl rollout status deployment/kube-controller-manager\n```\n\n## Follow-up Questions\n- How would you test the migration in a staging cluster before prod?\n- What metrics would indicate an unsafe migration and trigger rollback?","diagram":"flowchart TD\n  A[Start] --> B[Backup etcd]\n  B --> C[Enable conversion webhook]\n  C --> D[Canary CRD upgrade]\n  D --> E[Monitor CRs/status]\n  E --> F[Rollout to all CRs]\n  F --> G[Upgrade API components]\n  G --> H[Post-upgrade validation]\n  H --> I[Rollback if failure]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T19:33:34.946Z","createdAt":"2026-01-19T19:33:34.946Z"},{"id":"q-4620","question":"In a 3-node Kubernetes cluster, a frontend Deployment that calls an external API experiences intermittent DNS failures after a cluster upgrade. Outline a concrete troubleshooting and fix plan focusing on CoreDNS health, DNS policy, and a safe rollout that preserves uptime. Include exact commands to verify CoreDNS, modify CoreDNS config to enable caching or upstreams, and verify end-to-end DNS resolution from a pod?","answer":"Check CoreDNS health and Corefile; enable DNS caching and upstreams, then safely rollout frontend. Commands: \n- kubectl get pods -n kube-system -l k8s-app=kube-dns\n- kubectl logs -n kube-system -l k8s","explanation":"## Why This Is Asked\nTests practical DNS troubleshooting in a real cluster upgrade scenario, focusing on CoreDNS health, config changes, and safe rollouts.\n\n## Key Concepts\n- CoreDNS health and ConfigMap editing\n- DNS caching and upstream configuration\n- Safe rolling updates and rollout verification\n- In-cluster DNS validation with dig/curl\n\n## Code Example\n```javascript\n// CoreDNS Corefile patch (illustrative)\n.:53 {\n  log\n  errors\n  cache 30\n  forward . 1.1.1.1 8.8.8.8\n}\n```\n\n## Follow-up Questions\n- How would you rollback CoreDNS changes if issues persist?\n- How can you automate this diagnosis in a cluster-wide incident runbook?","diagram":"flowchart TD\n  A(CoreDNS Health) --> B(Edit CoreDNS Corefile)\n  B --> C(Rollout Frontend)\n  C --> D(Test DNS Resolution)\n  D --> E(Verify Uptime)","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T04:38:20.582Z","createdAt":"2026-01-20T04:38:20.582Z"},{"id":"q-4755","question":"Scenario: A 5-node Kubernetes control-plane cluster (3 masters, 2 workers) experiences an unhealthy etcd member. You must perform disaster recovery by restoring from the latest snapshot to a new member and rejoining with minimal downtime. Outline a concrete, command-driven runbook: health checks, member add/remove, etcd snapshot restore, updating the etcd manifest, restarting API server, and post-restore validation?","answer":"Plan: 1) etcd health check: etcdctl endpoint health. 2) Identify unhealthy member and add a fresh member; remove the bad one. 3) Stop etcd on the failed node; restore latest snapshot to /var/lib/etcd/","explanation":"## Why This Is Asked\nTests disaster-recovery skills on control plane with minimal downtime.\n\n## Key Concepts\n- etcd backup/restore, member lifecycle, and control‑plane manifests\n- API server availability validation and data-consistency checks\n\n## Code Example\n```bash\n# health\nETCDCTL_API=3 etcdctl endpoint health --endpoints=https://127.0.0.1:2379 \\\\ --cacert /etc/kubernetes/pki/etcd/ca.pem \\\\ --cert /etc/kubernetes/pki/etcd/server.pem \\\\ --key /etc/kubernetes/pki/etcd/server-key.pem\n```\n\n## Follow-up Questions\n- How would you test DR in a staging cluster?\n- What if restore diverges from the current member set?","diagram":"flowchart TD\nA[Unhealthy etcd member] --> B[Add new member]\nB --> C[Update etcd manifest]\nC --> D[Restart API server]\nD --> E[Validate cluster]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T11:01:12.219Z","createdAt":"2026-01-20T11:01:12.219Z"},{"id":"q-4896","question":"In a 3-node Kubernetes StatefulSet running a MongoDB replica set with PVs, upgrade image from mongo:4.4 to mongo:5.0 with zero downtime and no data loss. Provide a concrete, step-by-step upgrade plan that uses a PodDisruptionBudget, performs primary stepping and elections, validates data consistency after each step, and includes rollback instructions if the upgrade encounters issues. Include exact kubectl and mongo shell commands?","answer":"Ensure replica set majority before upgrade. Use a PodDisruptionBudget of minAvailable: 2. Run: kubectl set image statefulset/mongodb mongodb=mongo:5.0 --record. After each pod restarts, run rs.stepDow","explanation":"## Why This Is Asked\nTests practical upgrade discipline for stateful apps with PVs, ensuring zero downtime and data safety during a rolling image upgrade in a MongoDB replica set.\n\n## Key Concepts\n- StatefulSet rolling upgrades with PVCs\n- PodDisruptionBudget to preserve quorum\n- MongoDB replica set health (rs.status, rs.stepDown)\n- Data validation and rollback strategies\n\n## Code Example\n```bash\n# Create a PodDisruptionBudget preserving 2 of 3 pods\nkubectl apply -f - <<'YAML'\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: mongodb-pdb\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: mongodb\nYAML\n\n# Upgrade image one pod at a time\nkubectl set image statefulset/mongodb mongodb=mongo:5.0 --record\n\n# After a pod restarts, force primary to step down to trigger election\nkubectl exec -it mongodb-0 -- mongo --eval 'rs.stepDown()'\nkubectl exec -it mongodb-1 -- mongo --eval 'rs.status()'\n```\n\n## Follow-up Questions\n- What if a primary does not step down or election stalls?\n- How would you adapt this plan for multi-region clusters with latency considerations?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T17:54:16.176Z","createdAt":"2026-01-20T17:54:16.176Z"},{"id":"q-4912","question":"You have a 6-node cluster running Deployment web-app with 6 replicas. Implement autoscaling to handle traffic spikes and maintain availability during node maintenance. Provide exact commands and manifests: HorizontalPodAutoscaler with minReplicas 4, maxReplicas 20, targetCPUUtilizationPercentage 70; container resources: requests CPU 200m memory 256Mi; limits CPU 500m memory 512Mi; enable ClusterAutoscaler with minNodes 3, maxNodes 12; include a load test and verification steps?","answer":"Configure HPA on deployment web-app with minReplicas 4, maxReplicas 20 and target CPU 70%. Set container resources: requests CPU 200m memory 256Mi; limits 500m memory 512Mi. Deploy CA with minNodes 3,","explanation":"## Why This Is Asked\nTests practical autoscaling setup and verification under real load.\n\n## Key Concepts\n- HorizontalPodAutoscaler\n- Resource requests/limits\n- Cluster Autoscaler\n- Load testing and validation\n\n## Code Example\n```yaml\n# Deployment (resources shown)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 6\n  template:\n    spec:\n      containers:\n      - name: web-app\n        image: web-app:latest\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n```\n\n```yaml\n# Horizontal Pod Autoscaler\napiVersion: autoscaling/v2beta2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 4\n  maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n```\n\n# Cluster Autoscaler is cloud-provider specific and installed per cluster.\n```\n  ","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T19:02:29.334Z","createdAt":"2026-01-20T19:02:29.334Z"},{"id":"q-4991","question":"You manage a 5-rep StatefulSet on a 3-node Kubernetes cluster on AWS with EBS-backed PVCs. During a rolling update, pods fail to attach volumes, leaving the service degraded. Describe a practical end-to-end diagnostic and remediation plan that preserves data safety and minimizes downtime, including storage class, CSI logs, and deployment strategy considerations?","answer":"During a rolling update of a 5-replica StatefulSet on a 3-node Kubernetes cluster with EBS-backed PVCs, pods fail to attach volumes, leaving the service degraded. Diagnosis: describe pod, PVC, PV, and AWS VolumeAttachment events; check CSI driver logs; verify StorageClass configuration and volumeBindingMode; validate AWS EBS volume status and availability zone constraints. Remediation: pause the rollout, resolve volume attachment issues (often related to node availability zone mismatches or CSI driver problems), ensure proper PodDisruptionBudget configuration, consider using maxUnavailable strategy, and resume update with monitoring.","explanation":"## Why This Is Asked\n\nThis question evaluates practical diagnostic skills for stateful workloads during cluster operations, testing understanding of PV/PVC lifecycle, CSI driver behavior, and AWS storage integration.\n\n## Key Concepts\n\n- StatefulSet rolling updates and PodDisruptionBudget configuration\n- PVC/PV lifecycle management and StorageClass volumeBindingMode\n- CSI driver troubleshooting and VolumeAttachment status monitoring\n- AWS EBS gp3 volume sizing and availability zone constraints\n- Data safety through snapshots and backup strategies\n\n## Code Example\n\n```bash\nkubectl describe pod <pod-name> -n <namespace>\nkubectl get pvc,pv -o wide\nkubectl logs -l app=csi-driver -n kube-system\naws ec2 describe-volumes --volume-ids <volume-id>\n```","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:49:38.192Z","createdAt":"2026-01-20T22:43:49.448Z"},{"id":"q-5060","question":"On a 5-node control-plane cluster, one etcd member fails due to data corruption. Describe an exact disaster-recovery sequence to restore to the latest consistent snapshot and rejoin quorum with minimal API downtime. Include how to identify the last good snapshot, perform member restore, update initial-cluster, restart API servers, and verify API availability with kubectl and etcdctl health checks?","answer":"Identify the last good etcd snapshot with etcdctl snapshot status; stop etcd on the corrupted member; restore from the snapshot to a fresh data-dir; configure initial-cluster with all members; start e","explanation":"## Why This Is Asked\nDisaster recovery of etcd is critical to minimize downtime and data loss in Kubernetes control planes.\n\n## Key Concepts\n- etcd backup/restore using snapshots\n- Quorum management and member reconfiguration\n- apiserver downtime and validation via kubectl and etcdctl\n\n## Code Example\n```javascript\n// Example: check snapshot status\nETCDCTL_API=3 etcdctl snapshot status /path/to/snapshot.db\n```\n\n```javascript\n// Example: restore\nETCDCTL_API=3 etcdctl snapshot restore /path/to/snapshot.db --data-dir=/var/lib/etcd --name=cntr1 --initial-cluster='cntr1=https://ip1:2380,cntr2=https://ip2:2380,cntr3=https://ip3:2380,cntr4=https://ip4:2380,cntr5=https://ip5:2380'\n```\n\n## Follow-up Questions\n- How would you automate DR drills? \n- What are risks with snapshot drift and how to mitigate?\n","diagram":"flowchart TD\n  A[Identify corrupted member] --> B[Check last good snapshot]\n  B --> C[Restore member from snapshot]\n  C --> D[Update initial-cluster]\n  D --> E[Restart etcd on all members]\n  E --> F[Restart kube-apiserver]\n  F --> G[Validate API availability]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T04:16:18.540Z","createdAt":"2026-01-21T04:16:18.540Z"},{"id":"q-5313","question":"In a Kubernetes cluster, a Deployment with 3 replicas logs frequent pod restarts over a 10‑minute window. Outline a practical, beginner‑friendly debugging plan using kubectl to identify root cause and implement a minimal fix, including verification steps?","answer":"Run kubectl get deploy and kubectl describe pod <pod> to see the current state; kubectl logs <pod> --previous reveals the crash reason; check restartCounts and exit codes. If OOM, raise cpu/memory req","explanation":"## Why This Is Asked\nUnderstanding how to approach a crash loop with basic CLI tools is fundamental for first-line Kubernetes troubleshooting.\n\n## Key Concepts\n- kubectl basics\n- Pod lifecycle and crash loops\n- Resource requests/limits\n- Probes (readiness/liveness) and status checks\n- Rollouts and verification\n\n## Code Example\n```javascript\n// Example snippet: quick check for resource spec presence\nfunction hasResources(manifest){\n  const c = manifest?.spec?.template?.spec?.containers?.[0];\n  return !!c?.resources;\n}\n```\n\n## Follow-up Questions\n- How would you automate this debugging flow in a script?\n- How would you differentiate app crashes from cluster resource constraints?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Databricks","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T16:06:36.392Z","createdAt":"2026-01-21T16:06:36.392Z"},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","answer":"Capture startup timings and initContainer logs, kubectl describe pod, and events; monitor readiness transitions and image pulls. If init work is heavy, move health checks to readiness, cache results, ","explanation":"## Why This Is Asked\nThis question probes practical troubleshooting of startup latency caused by init containers in a real Kubernetes setup, emphasizing observability, risk-aware fixes, and rollback discipline.\n\n## Key Concepts\n- Kubernetes readiness vs startup probes\n- InitContainers vs parallel init\n- Canary rollouts and rollback\n- Observability: pod events, container logs, metrics\n\n## Code Example\n```yaml\nreadinessProbe:\n  exec:\n    command: [\"bash\",\"-lc\",\"echo ok\"]\n  initialDelaySeconds: 5\n  periodSeconds: 10\n```\n\n## Follow-up Questions\n- How would you gate a rollout to avoid user impact during a fix?\n- What would you monitor post-rollout to ensure latency doesn't regress?","diagram":"flowchart TD\n  A[Baseline Timings] --> B{InitContainer}\n  B --> C[Measure Startup Latency]\n  C --> D[Diagnosis & Fix Plan]\n  D --> E[Rollout Canary]\n  E --> F[Validate Metrics]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Salesforce","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:55:35.532Z","createdAt":"2026-01-12T13:55:35.532Z"},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","answer":"Verify health with etcdctl endpoint health for all endpoints, then identify the corrupted member via etcdctl member list/status. Stop the faulty node, restore a known-good snapshot using etcdctl snaps","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- etcd health checks\n- Snapshot restore and initial-cluster config\n- Member lifecycle and data-dir safety\n- Validation of API and cluster state\n\n## Code Example\n```bash\netcdctl endpoint health --endpoints=https://node1:2379,https://node2:2379,https://node3:2379\n```\n\n## Follow-up Questions\n- How would you automate this DR runbook?\n","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:34:21.100Z","createdAt":"2026-01-12T14:34:21.100Z"},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","answer":"Capture API server latency from metrics, then list webhook configurations: kubectl get mutatingwebhookconfiguration, validatingwebhookconfiguration. Identify culprit by error rate and latency. Patch t","explanation":"## Why This Is Asked\n\nInterviews gauge practical debugging of admission webhooks and API responsiveness under failure, plus rollback discipline in a live cluster.\n\n## Key Concepts\n\n- apiserver metrics and profiling\n- MutatingWebhookConfiguration and ValidatingWebhookConfiguration\n- safe-disable/rollback patterns\n- impact on cluster availability and security\n\n## Code Example\n\n```bash\n# Disable a specific webhook by removing it from the MutatingWebhookConfiguration\nkubectl get mutatingwebhookconfiguration <name> -o json | \\\n  jq 'del(.webhooks[] | select(.name == \"<target-webhook-name>\"))' | \\\n  kubectl apply -f -\n```\n```\n\n## Follow-up Questions\n\n- How would you test disablement in a non-prod cluster with minimal risk?\n- How would you ensure a controlled rollback if the webhook changes cause issues?\n","diagram":"flowchart TD\n  A[Start] --> B[Check apiserver metrics]\n  B --> C{Culprit found?}\n  C -->|Yes| D[Patch MutatingWebhookConfiguration to remove culprit]\n  C -->|No| E[Check ValidatingWebhookConfiguration]\n  D --> F[Validate API responsiveness with kubectl get ns]\n  F --> G{Healthy?}\n  G -->|Yes| H[Document rollback plan and monitor]\n  G -->|No| I[Escalate and revert changes]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:25:48.349Z","createdAt":"2026-01-12T16:25:48.349Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber"],"stats":{"total":58,"beginner":14,"intermediate":22,"advanced":22,"newThisWeek":45}}