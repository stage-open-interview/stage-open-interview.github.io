{"questions":[{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","answer":"Identify the two healthy etcd members and verify quorum with etcdctl member list; check cluster-health. Stop the out-of-quorum member, restore the missing member from the latest snapshot using etcdctl","explanation":"## Why This Is Asked\nTests practical DR/HA recovery for etcd and API availability in multi-AZ. Requires exact commands and sequencing.\n\n## Key Concepts\n- etcd quorum and member lifecycle\n- Snapshot restore with initial-cluster state\n- HA API server restart order across AZs\n- DR readiness, RPO/RTO implications\n\n## Code Example\n```javascript\n// Illustrative DR restore flow (non-production, for understanding)\nconst {execSync} = require('child_process')\nexecSync(\"etcdctl snapshot restore snapshot.db --name etcd2 --initial-cluster 'etcd0=https://A:2380,etcd1=https://A2:2380,etcd2=https://B:2380' --initial-cluster-state=new\", {stdio:'inherit'})\n```\n\n## Follow-up Questions\n- How would you test this upgrade procedure to minimize downtime?\n- What are risks of multi-AZ etcd topologies and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:20:40.941Z","createdAt":"2026-01-12T22:20:40.941Z"},{"id":"q-1368","question":"In a 3-node etcd-backed Kubernetes cluster, one node loses network connectivity and becomes partitioned while the other two remain healthy. How do you preserve availability and data integrity, avoid split-brain, and recover the partitioned member? Outline health checks, how you isolate the partition, recovery steps, and verification?","answer":"Assess quorum and health via etcdctl: member list and endpoint status. If a node is partitioned, fence it by stopping its etcd service or blocking its traffic so the two healthy members keep quorum. A","explanation":"## Why This Is Asked\nAssessing HA in etcd is critical for production clusters; this question tests practical recovery, fencing, and verification under partition scenarios.\n\n## Key Concepts\n- etcd quorum in a 3-node cluster\n- Fence/isolate to avoid split-brain\n- Recovery: rejoin member and verify\n- Validation: health checks and data consistency\n\n## Code Example\n```bash\netcdctl member list\netcdctl endpoint health\n```\n\n## Follow-up Questions\n- How would you simulate a partition in a staging cluster and validate failover?\n- Which metrics indicate a healthy etcd cluster after recovery?","diagram":"flowchart TD\n  A[Partition Detected] --> B[Fence Isolated Member]\n  B --> C[Two-Node Quorum Maintained]\n  C --> D[Network Fixed]\n  D --> E[Isolated Member Rejoined]\n  E --> F[Health Verified]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:20:24.108Z","createdAt":"2026-01-13T13:20:24.108Z"},{"id":"q-1395","question":"In a 3-node Kubernetes cluster, deploy a stateless web app using a Deployment with 3 replicas and a ClusterIP Service. Include readiness and liveness probes, CPU/memory requests and limits, and populate APP_MODE via a ConfigMap and DB_PASSWORD from a Secret. Describe the steps to perform a rolling update to 4 replicas with zero downtime and how you would verify the rollout across nodes?","answer":"Define a Deployment with 3 replicas and a ClusterIP Service. Add readinessProbe and livenessProbe, and set resources: requests cpu: 100m, memory: 128Mi; limits cpu: 500m, memory: 256Mi. Populate APP_M","explanation":"## Why This Is Asked\n\nTests practical Kubernetes administration skills: creating Deployments and Services, configuring probes and resources, wiring ConfigMaps and Secrets, and performing safe rolling updates with observable verification.\n\n## Key Concepts\n\n- Deployments and Services\n- Probes (readiness and liveness)\n- Resource requests/limits\n- ConfigMap and Secret usage\n- RollingUpdate strategy and rollout verification\n\n## Code Example\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"256Mi\"\n```\n\n## Follow-up Questions\n\n- How would you attach APP_MODE ConfigMap and DB_PASSWORD Secret as environment variables?\n- How would you monitor the rollout and diagnose a failed update?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:36:31.463Z","createdAt":"2026-01-13T15:36:31.464Z"},{"id":"q-1418","question":"Enable at-rest encryption for Kubernetes Secrets using a KMS (envelope) provider on an existing 3-control-plane cluster. Describe exact steps to configure the EncryptionConfig, rotate KEKs without downtime, trigger re-encryption of existing Secrets, and verify that new and existing Secrets are stored encrypted at rest (without decrypting at-rest data). Include concrete commands and caveats?","answer":"1) Create encryption-config.yaml with a kms provider for secrets and place on API servers. 2) Update API server manifest to --encryption-provider-config and restart. 3) Add a new KEK to the provider c","explanation":"## Why This Is Asked\nThis tests practical enablement of encryption at rest for Secrets using a KMS provider, including live-rotation and data re-encryption without downtime.\n\n## Key Concepts\n- Encryption at rest for Secrets\n- KMS envelope provider and key rotation\n- Re-encryption strategy without API downtime\n- Verification via ciphertext in etcd and API behavior\n- Operational risk and rollback\n\n## Code Example\n```yaml\n# encryption-config.yaml (high-level)\napiVersion: v1\nkind: EncryptionConfig\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      # kms configuration here\n  - aesgcm:\n      keys:\n      - name: key1\n```\n\n```bash\n# Basic commands (illustrative)\n# 1) Update API server to use config\n#Systemctl restart kube-apiserver\n# 2) Rotate KEK\n# edit encryption-config.yaml to add new KEK and restart\n# 3) Re-encrypt existing data\nkubectl get secret --all-namespaces -o json | kubectl apply -f -\n```\n\n## Follow-up Questions\n- How would you automate rotation across clusters and verify no data loss?\n- How would you test DR for key material and encryption config without affecting live workloads?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T16:41:51.999Z","createdAt":"2026-01-13T16:41:52.001Z"},{"id":"q-1452","question":"You operate a 3-node Kubernetes cluster with a StatefulSet of 3 replicas backed by PVs. A critical fix requires upgrading to image app:v2 with zero downtime. Outline a precise upgrade plan: set a PodDisruptionBudget to minAvailable 2, apply a RollingUpdate with partition=2, ensure readiness probes tolerate brief pod restarts, and verify data integrity during rollout with concrete kubectl commands?","answer":"Patch the StatefulSet with partition=2 so pods 0–1 upgrade first, keeping one online. Create a PodDisruptionBudget with minAvailable: 2. Upgrade: kubectl patch statefulset my-app -p '{\"spec\":{\"updateS","explanation":"## Why This Is Asked\nTests understanding of zero-downtime upgrades for StatefulSets, combined with PDBs, readiness, and data safety.\n\n## Key Concepts\n- StatefulSet RollingUpdate with partition control\n- PodDisruptionBudget for high availability\n- PV/PVC durability and readiness probes\n\n## Code Example\n```javascript\nfunction patchPayload(partition){\n  return {\"spec\": {\"updateStrategy\": {\"type\": \"RollingUpdate\", \"rollingUpdate\": {\"partition\": partition}}}};\n}\n```\n\n## Follow-up Questions\n- How would you verify data integrity during rollout? \n- What risks exist if a pod reschedules on another node during upgrade?","diagram":"flowchart TD\n  A[StatefulSet Upgrade] --> B[Apply PDB]\n  B --> C[Patch StatefulSet]\n  C --> D[Rollout]\n  D --> E[Verify]\n  E --> F[Finish]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:47:32.315Z","createdAt":"2026-01-13T17:47:32.315Z"},{"id":"q-1562","question":"How would you design a Kubernetes Job named app-init-seed that seeds app data on first run? The Job should use an Alpine-based image, mount a PVC at /data, load a script from a ConfigMap at /scripts/seed.sh, skip if /data/.seeded exists, optionally fetch seed.json from https://example.com using API key from a Secret, and write a log and the marker file upon success; include full YAML and apply steps?","answer":"Implement a Kubernetes Job named app-init-seed that seeds data on first run. Use an Alpine-based image, mount a PVC at /data, and load a script from a ConfigMap at /scripts/seed.sh. If /data/.seeded exists, skip processing. Optionally fetch seed.json from https://example.com using an API key from a Secret, then write a log and create the marker file upon success.","explanation":"## Why This Is Asked\nThis question tests practical understanding of Kubernetes Jobs, volume mounts, ConfigMaps, Secrets, idempotent operations, and error handling in a cluster environment. It also evaluates the ability to design resilient solutions with proper backoff limits and restart policies.\n\n## Key Concepts\n- Kubernetes Job lifecycle and management\n- Volume mounts for Persistent Volume Claims (PVCs)\n- ConfigMap and Secret integration\n- Idempotent seeding through marker files\n- BackoffLimit and restartPolicy configuration\n- Network operations with curl using --fail and --retry flags\n\n## Code Example\n```yaml\n# YAML Job example\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: app-init-seed\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 4\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: seed-container\n        image: alpine:3.18\n        command: [\"/bin/sh\", \"/scripts/seed.sh\"]\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n        - name: script-volume\n          mountPath: /scripts\n        env:\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: api-secret\n              key: api-key\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: app-data-pvc\n      - name: script-volume\n        configMap:\n          name: seed-script\n```\n\n## Apply Steps\n1. Create the ConfigMap with the seed script\n2. Create the Secret with the API key\n3. Ensure the PVC exists\n4. Apply the Job manifest: `kubectl apply -f app-init-seed-job.yaml`\n5. Monitor progress: `kubectl get jobs -w`","diagram":"flowchart TD\n  A[Job app-init-seed] --> B[Mount /data PVC]\n  B --> C{Seeded?}\n  C -- Yes --> D[Exit]\n  C -- No --> E[Fetch seed.json]\n  E --> F[Write /data/seed.json]\n  F --> G[Create /data/.seeded]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:57:44.958Z","createdAt":"2026-01-13T21:47:26.329Z"},{"id":"q-1737","question":"You're deploying a 3-replica Deployment in Kubernetes for a payment app. Suddenly 2 pods crash with CrashLoopBackOff. Describe a practical debugging workflow to identify if the issue is container startup, config, resources, or image, and outline the exact kubectl commands and file checks you would perform. Include how you would propose a minimal fix and a rollback plan?","answer":"Debug CrashLoopBackOff by isolating startup, config, resources, or image issues. Run: kubectl get pods -l app=payment; kubectl describe pod <pod>; kubectl logs <pod>; kubectl logs <pod> --previous; ku","explanation":"## Why This Is Asked\n\nTests practical debugging steps for Kubernetes CrashLoopBackOff, focusing on actionable commands.\n\n## Key Concepts\n\n- CrashLoopBackOff diagnosis\n- kubectl tooling (describe, logs, events)\n- ConfigMap/Secret patching\n- Rollback strategies\n\n## Code Example\n\n```bash\nkubectl get pods -l app=payment\n```\n\n## Follow-up Questions\n\n- How would you distinguish image pull errors from runtime crashes?\n- What are the risks of rolling back a deployment in production?","diagram":"flowchart TD\n  A[CrashLoopBackOff] --> B[Check pod status and events]\n  B --> C[Describe pod]\n  C --> D[Logs and previous logs]\n  D --> E[Probe/config/resources checks]\n  E --> F[Apply minimal fix]\n  F --> G[Rollout undo or restart]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:59:22.220Z","createdAt":"2026-01-14T08:59:22.220Z"},{"id":"q-1764","question":"Advanced: In a 5-node Kubernetes cluster where etcd memory usage has spiked after a noisy deployment, outline a production-safe remediation plan: verify health with etcdctl, diagnose via metrics, perform defrag/compact, take a snapshot, and adjust API watch load while preserving API server availability. What steps would you take?","answer":"Start by verifying health with etcdctl: endpoint status, member list, and health metrics; check RAM use and watch counts. Defragment and compact to reclaim space. Take a consistent snapshot for rollba","explanation":"## Why This Is Asked\nAssesses practical triage of etcd memory pressure in a live cluster, including safe backup/rollback and minimizing downtime.\n\n## Key Concepts\n- etcd health and metrics\n- defragmentation, compaction, backups\n- API server watch behavior and watch-cache\n- scalable rollback strategies\n\n## Code Example\n```javascript\n// Example: sequence of remediation steps\n```\n\n## Follow-up Questions\n- How would you validate remediation success after rollout?\n- What monitoring alerts would you configure to catch recurrence?\n","diagram":"flowchart TD\n  A(Check health via etcdctl) --> B(Assess memory hotspots)\n  B --> C(Defrag and compact)\n  C --> D(Take snapshot)\n  D --> E(Adjust resources/watch load)\n","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:48:51.723Z","createdAt":"2026-01-14T09:48:51.723Z"},{"id":"q-1810","question":"You're operating a 5-node Kubernetes cluster with a validating webhook named cfg.example.com enforcing a label requirement on Deployments in all namespaces. A critical patch must be applied in prod-adv while the webhook service is temporarily unavailable. Outline a safe, auditable plan to bypass the webhook with exact kubectl commands to identify, disable, apply, and revert?","answer":"Patch the ValidatingWebhookConfiguration to Ignore on failure, apply the patch in prod-adv, then revert to Fail and verify with events and rollout. Commands: kubectl get validatingwebhookconfiguration","explanation":"## Why This Is Asked\nTests understanding of Kubernetes admission control and safe rollbacks under outage.\n\n## Key Concepts\n- ValidatingWebhookConfiguration\n- FailurePolicy: Ignore vs Fail\n- Safe patch deployment\n- Auditable rollback\n\n## Code Example\n```yaml\n# minimal patch example framework\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: cfg.example.com\n  \n# actual patch differs per cluster\n```\n\n## Follow-up Questions\n- How would you validate no partial patches linger?\n- What are risks if you forget to revert? ","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T11:45:33.451Z","createdAt":"2026-01-14T11:45:33.451Z"},{"id":"q-1885","question":"In a high-traffic delivery platform, you deploy a Kubernetes-based worker pool for async order processing. Explain how you would implement a robust, rate-limited queue with backpressure, idempotent workers, and at-least-once delivery, using Kubernetes primitives and common tools. Include how you handle spikes, retries, and data-store consistency?","answer":"Use a Kafka or Redis Streams backed queue with stateless workers behind a HorizontalPodAutoscaler. Enforce backpressure with a token-bucket limiter shared via Redis. Ensure idempotence by recording pr","explanation":"## Why This Is Asked\nTests practical Kubernetes design for async processing, backpressure, idempotency, and delivery guarantees in production-like scenarios.\n\n## Key Concepts\n- Durable queues (Kafka/Redis Streams)\n- Backpressure and rate limiting\n- Idempotent workers and at-least-once delivery\n- Backoff strategies and DLQ\n- Data-store consistency with upserts\n\n## Code Example\n```javascript\n// Pseudo-code: worker handling with idempotency checks\nfunction handle(msg) {\n  if (db.hasProcessed(msg.id)) return;\n  const res = process(msg);\n  db.upsert({ id: msg.id, result: res });\n  ack(msg);\n}\n```\n\n## Follow-up Questions\n- How would you test exactly-once vs at-least-once guarantees?\n- How would you observe and alert on backpressure and DLQ growth?\n","diagram":"flowchart TD\n  A[Ingest] --> B[Enqueue]\n  B --> C[Workers]\n  C --> D[Persist/ACK]\n  D --> E[DLQ]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:45:54.277Z","createdAt":"2026-01-14T15:45:54.277Z"},{"id":"q-1932","question":"Describe a **concrete, production-ready plan** for zero-downtime deployments in a Lyft-scale Kubernetes cluster with ~40 microservices, multiple data stores, and strict uptime. How would you implement **blue/green or canary releases**, traffic shaping, and automated rollbacks? Include rollout strategy, readiness checks, RBAC, DR, and a compact manifest example comparing Istio and Linkerd approaches?","answer":"Plan calls for immutable deployments with Canary or Blue/Green, progressive traffic shifts (start 1–5% canary and ramp), readiness/liveness probes, and PodDisruptionBudget with automated rollback on f","explanation":"## Why This Is Asked\nTests practical mastery of deployment strategies in large Kubernetes environments, emphasizing real-world constraints, traffic control, observability, and DR.\n\n## Key Concepts\n- Canary and blue/green deployments\n- Traffic shaping with service mesh (Istio/Linkerd)\n- Readiness/Liveness probes, PodDisruptionBudget\n- Rollbacks, error budgets, observability\n- DR planning, RBAC\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payments\nspec:\n  replicas: 4\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  template:\n    metadata:\n      labels:\n        app: payments\n    spec:\n      containers:\n      - name: payments\n        image: myrepo/payments:canary-1\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n```\n\n## Follow-up Questions\n- How would you measure canary success and trigger rollback?\n- What metrics and alerting would you configure?\n","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:46:42.475Z","createdAt":"2026-01-14T17:46:42.475Z"},{"id":"q-1946","question":"On a 3-node Kubernetes cluster, a Deployment’s Pods stay Pending while 2 nodes are Ready. The scheduler shows a NoSchedule taint on node-1. Explain exact commands to identify the taint, check the pod’s tolerations, and either remove the taint or add a matching toleration so the workload schedules. How do you validate after changes?","answer":"Check taint and pods: kubectl get nodes -o wide and kubectl describe node node-1 to confirm the taint. To remove: kubectl taint nodes node-1 NoSchedule-. Or add toleration to the Pod/Deployment: toler","explanation":"## Why This Is Asked\nTests practical ability to diagnose and fix scheduling using taints/tolerations in a real cluster.\n\n## Key Concepts\n- taints and tolerations\n- kubectl diagnostics\n- Deployment rollout verification\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  template:\n    spec:\n      tolerations:\n      - key: \"node-role.kubernetes.io/node\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n```\n\n## Follow-up Questions\n- How would you limit the toleration to a subset of pods?\n- What are risks of removing a NoSchedule taint on a node?","diagram":"flowchart TD\n  A[Identify taint] --> B[Decide action]\n  B --> C{Remove taint?}\n  C -->|Yes| D[Apply taint removal]\n  C -->|No| E[Tolerations added]\n  D --> F[Rollout verify]\n  E --> F","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:43:56.873Z","createdAt":"2026-01-14T18:43:56.875Z"},{"id":"q-1972","question":"You maintain a Node.js app deployed as a 3-replica Kubernetes Deployment behind a service. A security patch requires updating the container image from v1.0.1 to v1.0.2 with zero downtime. List exact kubectl steps to perform a safe rolling update, how you confirm readiness, and how you rollback if the rollout fails?","answer":"Use kubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2; wait for rollout to complete with kubectl rollout status deployment/myapp; verify all pods are Ready and running the new image with ku","explanation":"## Why This Is Asked\n\nTests practical, safe rolling update knowledge in real Kubernetes workflows.\n\n## Key Concepts\n\n- RollingUpdate strategy\n- Readiness/Liveness probes\n- Rollback with rollout undo\n- kubectl use in production-like tasks\n\n## Code Example\n\n```javascript\nkubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2\n```\n\n## Follow-up Questions\n\n- What would you do if a pod crashes after update?\n- How would you adjust probes/thresholds to prevent future issues?\n","diagram":"flowchart TD\n  A[Deployment] --> B[RollingUpdate]\n  B --> C{Status}\n  C -->|Success| D[Done]\n  C -->|Failure| E[Rollback]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:28:07.727Z","createdAt":"2026-01-14T19:28:07.727Z"},{"id":"q-2027","question":"You're managing a shared Kubernetes cluster with namespaces prod, analytics, and dev. A nightly analytics batch job sometimes starves frontend pods during peak hours, triggering evictions. Design an end-to-end remediation plan: tune pod requests/limits, enforce defaults with a LimitRange, cap total usage with a ResourceQuota, ensure guaranteed QoS, evaluate VerticalPodAutoscaler vs HorizontalPodAutoscaler, and outline validation steps to prevent regressions?","answer":"Set explicit requests and limits for all affected pods to prevent the analytics job from exhausting shared resources; implement a LimitRange in the analytics namespace to enforce default values; add a ResourceQuota per namespace to cap total resource consumption; configure Guaranteed QoS for critical frontend pods by setting requests equal to limits; evaluate HorizontalPodAutoscaler for frontend pods to scale during peak demand and VerticalPodAutoscaler for the analytics job to right-size its resource allocation; implement canary deployments and load testing to validate the solution.","explanation":"## Why This Is Asked\nTests resource management expertise and real-world trade-offs involving quotas, QoS classes, and autoscaling strategies across Kubernetes namespaces.\n\n## Key Concepts\n- Kubernetes QoS classes (Guaranteed, Burstable, Best-Effort)\n- ResourceQuota and LimitRange for namespace governance\n- HorizontalPodAutoscaler (HPA) for scaling out\n- VerticalPodAutoscaler (VPA) for right-sizing resources\n- Canary validation and load testing strategies\n\n## Code Example\n```yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: analytics-defaults\n  namespace: analytics\nspec:\n  limits:\n  - default:\n      cpu: 500m\n      memory: 512Mi\n    defaultRequest:\n      cpu: 100m\n      memory: 128Mi\n    type: Container\n```","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T06:29:18.467Z","createdAt":"2026-01-14T21:35:41.722Z"},{"id":"q-2134","question":"You manage a Databricks/OpenAI-like platform on Kubernetes. A Spark streaming job processes 1TB/day and faces sporadic node preemption causing data loss without checkpoints. Design a fault-tolerant deployment (manifests and configurations) and explain trade-offs between Kubernetes Job vs. StatefulSet, backoff strategies, taints/tolerations, and Spark dynamic allocation. What would you implement and why?","answer":"Design a fault-tolerant Spark-on-Kubernetes deployment: run the streaming job with dynamic allocation; enable checkpointing to durable storage; use taints/tolerations and a PodDisruptionBudget; set ba","explanation":"## Why This Is Asked\nThis question probes real-world Kubernetes/Spark fault-tolerance, scheduling, and stateful workload design—crucial on large platforms like Databricks/OpenAI.\n\n## Key Concepts\n- Spark on Kubernetes (CRs, dynamic allocation)\n- Checkpointing and exactly-once semantics\n- PodDisruptionBudget, taints/tolerations, restart policies\n- Observability and alerts (Prometheus)\n\n## Code Example\n```javascript\n// Example SparkApplication spec (pseudo)\nconst sparkApp = {\n  apiVersion: \"sparkoperator.k8s.io/v1beta2\",\n  kind: \"SparkApplication\",\n  metadata: { name: \"stream-1\" },\n  spec: {\n    mode: \"cluster\",\n    image: \"spark:3.2\",\n    mainClass: \"com.example.Stream\",\n    mainApplicationFile: \"local:///stream.jar\",\n    sparkVersion: \"3.2.0\",\n    restartPolicy: { type: \"OnFailure\", onFailureRetries: 3, onFailureRetryInterval: 10 },\n    dynamicAllocation: { enabled: true },\n    backpressureEnabled: true,\n    checkpointLocation: \"s3://bucket/checkpoints\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test the fault-tolerance guarantees?\n- What changes if the storage is GCS vs S3?","diagram":"flowchart TD\n  Client --> APIServer\n  APIServer --> etcd\n  APIServer --> Scheduler\n  Scheduler --> Worker\n  Worker --> CheckpointStorage","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:17:04.104Z","createdAt":"2026-01-15T04:17:04.104Z"},{"id":"q-2152","question":"On a Kubernetes cluster running Spark jobs via Spark on Kubernetes, a 12-pod job reports intermittent OOM errors during shuffle-heavy stages on medium-sized datasets. Provide a concrete debugging plan: how you verify memory limits, adjust executor/driver memory and overhead, tune JVM GC, and validate changes with metrics and a controlled benchmark run?","answer":"Begin by confirming per-pod memory limits and actual usage with kubectl describe pod and metrics; then tune Spark: set spark.executor.memory and spark.driver.memory to safe values, add memoryOverhead,","explanation":"## Why This Is Asked\n\nTests ability to reason about Kubernetes resources and Spark on Kubernetes, and perform practical memory tuning with metrics, GC, and observability.\n\n## Key Concepts\n\n- Kubernetes resource requests/limits\n- Spark memory tuning (driver/executor memory, memoryOverhead, spark.memory.fraction)\n- JVM GC options and GC logging\n- Shuffle-heavy workloads and GC pressure\n- Observability (Spark UI, kubectl top, metrics)\n\n## Code Example\n\n```javascript\n// Kubernetes patch example (pseudo)\nconst patch = {\n  spec: {\n    template: {\n      spec: {\n        containers: [\n          { name: \"executor\",\n            resources: { requests: { memory: \"12Gi\" }, limits: { memory: \"12Gi\" } }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you detect a memory leak vs normal GC pauses?\n- How would you verify stability after changes with a canary run?","diagram":"flowchart TD\n  A[Cluster] --> B[Diagnose OOM]\n  B --> C{Adjust Resources}\n  C --> D[Apply Quotas]\n  C --> E[Restart Pods]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:34:36.507Z","createdAt":"2026-01-15T05:34:36.507Z"},{"id":"q-2197","question":"In a Kubernetes cluster running mixed workloads, a critical data-processing job occasionally starves QoS pods during peak load. Provide a concrete plan to enforce SLA guarantees: specify resource requests/limits with appropriate QoS, enable Pod Priority and Preemption, configure HorizontalPodAutoscaler and ClusterAutoscaler, and outline validation steps to prove SLAs hold under load?","answer":"Plan: assign meaningful resource requests/limits per pod to establish QoS, enable Pod Priority and Preemption, configure HorizontalPodAutoscaler and ClusterAutoscaler for demand, apply Namespace quota","explanation":"Why This Is Asked\nEvaluates ability to translate SLAs into concrete Kubernetes controls under real-world pressure.\n\n## Key Concepts\n- QoS classes and resource requests/limits\n- Pod Priority and Preemption\n- HorizontalPodAutoscaler and ClusterAutoscaler\n- Namespace quotas and taints for isolation\n- Validation: load testing, SLIs/SLOs, monitoring signals\n\n## Code Example\n```javascript\n// Example: Resource requests/limits snippet\nconst pod = {\n  apiVersion: \"v1\",\n  kind: \"Pod\",\n  metadata: { name: \"data-job\" },\n  spec: {\n    priorityClassName: \"high-prio\",\n    containers: [{\n      name: \"worker\",\n      image: \"registry/data-job:latest\",\n      resources: {\n        requests: { cpu: \"500m\", memory: \"1Gi\" },\n        limits: { cpu: \"1000m\", memory: \"2Gi\" }\n      }\n    }]\n  }\n}\n```\n\n## Follow-up Questions\n- How would you measure SLA adherence across namespaces?\n- What trade-offs exist between aggressive autoscaling vs. cost, and how would you cap bursts?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T07:04:20.415Z","createdAt":"2026-01-15T07:04:20.415Z"},{"id":"q-2282","question":"Implement namespace-scoped network isolation for namespace 'team-a' using Kubernetes NetworkPolicy. Ensure pods in team-a can reach only the DNS service and a single internal log sink at 'log-sink.logging.svc.cluster.local:9200', and cannot reach other namespaces or external hosts. Provide the manifests (default-deny and allow rules), kubectl commands to apply, and verify using a tester pod with targeted tests for DNS, log sink, and external access?","answer":"Implement a default-deny egress policy for namespace team-a, then add two allow rules: (1) DNS egress to kube-dns in kube-system on port 53 (TCP/UDP), (2) access to log-sink.logging.svc.cluster.local:","explanation":"## Why This Is Asked\nTests ability to design and implement strict network isolation, understand default-deny semantics, DNS, and inter-namespace access; requires translating policy into concrete manifests and validation steps.\n\n## Key Concepts\n- NetworkPolicy basics: podSelector, namespaceSelector, policyTypes\n- default-deny, explicit egress allows\n- DNS egress patterns to kube-system kube-dns pods\n- Testing with tester pod using dig and curl\n- Drift monitoring and auditing\n\n## Code Example\n```yaml\n# Default deny (egress)\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: team-a-egress-deny\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress: []\n```\n```yaml\n# Allow DNS and Log Sink\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: team-a-egress-allow-dns-log\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n      podSelector:\n        matchLabels:\n          k8s-app: kube-dns\n    ports:\n    - protocol: TCP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: logging\n    ports:\n    - protocol: TCP\n      port: 9200\n```","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T10:42:58.509Z","createdAt":"2026-01-15T10:42:58.509Z"},{"id":"q-2304","question":"You're administering a 3-namespace Kubernetes cluster hosting two teams. There are no NetworkPolicies today. Draft and implement a precise plan to enforce per-namespace default-deny, permit intra-namespace traffic for all pods, and allow outbound HTTPS to api.external.com:443, while blocking cross-namespace pod communication. Provide exact YAMLs for the policies, commands to verify with curl from representative pods, and rollback steps?","answer":"Implement a per-namespace default-deny NetworkPolicy, then add two policies that allow all traffic within each namespace and an egress rule allowing outbound HTTPS to api.external.com:443. Do not allo","explanation":"## Why This Is Asked\nTests practical network segmentation skills and ability to translate security policies into concrete YAML, plus verification and rollback.\n\n## Key Concepts\n- Kubernetes NetworkPolicy basics\n- default-deny pattern\n- intra-namespace traffic\n- egress controls and limitations\n- validation and rollback\n\n## Code Example\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny\n  namespace: team-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n```\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: intra-team-a\n  namespace: team-a\nspec:\n  podSelector: {}\n  ingress:\n  - from:\n    - podSelector: {}\n  egress:\n  - to:\n    - podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n```\n```yaml\n# Calico may support FQDN. Standard NP uses IP blocks; replace with FQDN if available.\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-external-api\n  namespace: team-a\nspec:\n  podSelector: {}\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 203.0.113.0/24\n    ports:\n    - protocol: TCP\n      port: 443\n  policyTypes:\n  - Egress\n```\n\n## Follow-up Questions\n- How would you adapt these policies to support a new namespace while preserving least privilege?\n- What metrics would you monitor to detect policy misconfigurations during rollout?","diagram":"flowchart TD\n  N1[Namespace: team-a]\n  N2[Namespace: team-b]\n  D[DefaultDeny]\n  A1[Allow intra-namespace: team-a]\n  A2[Allow intra-namespace: team-b]\n  E[Allow egress to api.external.com:443]\n  Cross[Cross-namespace traffic blocked]\n  N1 --> D\n  N2 --> D\n  D --> A1\n  D --> A2\n  D --> E\n  Cross --> D\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T11:31:56.544Z","createdAt":"2026-01-15T11:31:56.544Z"},{"id":"q-2338","question":"How would you identify memory pressure causing OOMKilled pods in a 3-node Kubernetes cluster (kubectl top, pod events, and logs), compare usage to requests/limits, profile memory if possible, and implement a fix with proper requests/limits, ResourceQuota, and a canary rolling update (maxUnavailable:1) plus a LivenessProbe, then validate with a soak test?","answer":"Begin by inspecting metrics and events: kubectl top to confirm memory pressure, kubectl describe pod to see OOMKilled, and logs for leaks. Compare memory usage against requests/limits to gauge QoS. Pr","explanation":"## Why This Is Asked\n\nTests practical diagnostic skills under production-like pressure, using standard Kubernetes tooling and production-ready safeguards.\n\n## Key Concepts\n\n- Memory pressure and OOMKilled events\n- Requests/limits and QoS classes\n- ResourceQuota and LimitRange\n- Canary rollouts and maxUnavailable\n- LivenessProbe and readiness\n\n## Code Example\n\n```yaml\n# ResourceQuota example\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: mem-quot\nspec:\n  hard:\n    requests.memory: 16Gi\n    limits.memory: 32Gi\n```\n\n```yaml\n# Deployment rolling update\napiVersion: apps/v1\nkind: Deployment\nspec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 25%\n```\n\n## Follow-up Questions\n\n- How would you detect a memory leak vs transient spike?\n- What metrics and alerts would you add for ongoing health?\n- How would you automate this process in a future incident?\n","diagram":"flowchart TD\n  Identify[Identify] --> Collect[Collect Metrics]\n  Collect --> Analyze[Analyze & Hypotheses]\n  Analyze --> Implement[Implement Fixes]\n  Implement --> Validate[Validate & Monitor]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T13:12:59.224Z","createdAt":"2026-01-15T13:12:59.224Z"},{"id":"q-2395","question":"In a shared Kubernetes cluster serving teams at Slack, IBM, and Salesforce, design a namespace-per-tenant isolation strategy with quotas and security controls. Include ResourceQuota, LimitRange, NetworkPolicy, PodSecurity admission, and RBAC. Propose a GitOps deployment flow per-namespace and an observability plan. Compare against a single-namespace approach and justify your choice?","answer":"Namespace-per-tenant with hard ResourceQuota and LimitRange, a default-deny NetworkPolicy, PodSecurity admission, and RBAC scoping admin roles to each tenant with separate ServiceAccounts. Enforce ima","explanation":"## Why This Is Asked\n\nTests ability to design scalable, isolated multi-tenant architecture on Kubernetes with policy enforcement and GitOps.\n\n## Key Concepts\n\n- ResourceQuota\n- LimitRange\n- NetworkPolicy\n- PodSecurity Standards\n- RBAC scope\n- Gatekeeper / OPA\n- GitOps (ArgoCD)\n- Observability (Prometheus, Grafana)\n\n## Code Example\n\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: tenant-a-quota\n  namespace: tenant-a\nspec:\n  hard:\n    requests.cpu: \"4\"\n    requests.memory: 8Gi\n    limits.cpu: \"8\"\n    limits.memory: 16Gi\n    pods: \"20\"\n```\n\n## Follow-up Questions\n\n- How would you test quota enforcement and policy compliance across tenants?\n- How would you evaluate trade-offs between namespace-per-tenant and fewer, larger tenants?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Salesforce","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T16:44:54.004Z","createdAt":"2026-01-15T16:44:54.004Z"},{"id":"q-2519","question":"In a Kubernetes cluster, a Deployment named web-app with 3 replicas in namespace prod suddenly fails after a ConfigMap update that injects environment variables. Pods crash due to a missing DB_PASSWORD from the ConfigMap. Describe exact steps and commands to diagnose, patch the ConfigMap, and roll out a fix with minimal downtime while ensuring the deployment restarts cleanly?","answer":"Triaging with: kubectl describe pod -n prod -l app=web-app; kubectl logs -n prod <pod>. Inspect the ConfigMap: kubectl get configmap web-app-config -n prod -o yaml. If DB_PASSWORD is missing, patch: k","explanation":"## Why This Is Asked\n\nTests practical Kubernetes troubleshooting skills for a real config drift issue, focusing on ConfigMaps, envFrom, and rolling updates.\n\n## Key Concepts\n\n- Diagnosing with describe/logs\n- Inspecting and patching ConfigMaps\n- Rolling restart and wait for readiness\n- Safe downtime and service validation\n\n## Code Example\n\n```bash\nkubectl describe pod -n prod -l app=web-app\nkubectl logs -n dev <pod>\nkubectl get configmap web-app-config -n prod -o yaml\nkubectl patch configmap web-app-config -n prod --type merge -p '{\"data\":{\"DB_PASSWORD\":\"secret\"}}'\nkubectl rollout restart deployment/web-app -n prod\nkubectl rollout status deployment/web-app -n prod\n```\n\n## Follow-up Questions\n\n- How would you automate this rollback if patching the ConfigMap introduces an error?\n- What checks ensure you don’t expose secrets via ConfigMaps?","diagram":"flowchart TD\n  A[ConfigMap updated] --> B[ Pods crash ]\n  B --> C[Patch ConfigMap]\n  C --> D[Rollout restart]\n  D --> E[Pods healthy]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Hashicorp","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T21:30:38.020Z","createdAt":"2026-01-15T21:30:38.020Z"},{"id":"q-2553","question":"In a two-region Kubernetes cluster with 3 nodes per region and a PostgreSQL StatefulSet backed by PVs, deploy a new service image with zero downtime using canary or blue-green. Detail exact rollout steps, traffic shaping, health checks, and data-consistency verification during rollout?","answer":"Implement a canary rollout using Argo Rollouts with progressive traffic shifting. Configure a Rollout resource to upgrade from app:v1 to app:v2 through incremental stages: 10%, 50%, and 100% traffic allocation, with 5-minute verification pauses between each stage. Gate promotions on both readiness probes and custom application metrics. Route traffic using Istio VirtualService to direct the specified percentage to the canary pods, gradually increasing to full traffic upon successful validation. Continuously monitor PostgreSQL replication lag and execute cross-region data consistency checks before each traffic increment to ensure database integrity.","explanation":"## Why This Is Asked\nThis scenario tests real-world deployment of stateful services across multi-region Kubernetes clusters with zero downtime requirements, including sophisticated traffic management and database integrity validation.\n\n## Key Concepts\n- Canary deployment strategies with progressive traffic shifting\n- Argo Rollouts integration with Istio VirtualService for traffic splitting\n- Readiness probes and custom metrics for automated promotion gating\n- PostgreSQL replication health monitoring and cross-region data consistency verification\n\n## Code Example\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: app-rollout\nspec:\n  replicas: 6\n  strategy:\n    canary:\n      steps:\n      - setWeight: 10\n      - pause: {duration: 5m}\n      - setWeight: 50\n      - pause: {duration: 5m}\n      - setWeight: 100\n      trafficRouting:\n        istio:\n          virtualService:\n            name: app-vs\n            routes:\n            - primary\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: app\n        image: app:v2\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n```","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","IBM","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:26:38.435Z","createdAt":"2026-01-15T22:41:59.551Z"},{"id":"q-2584","question":"**Advanced Kubernetes Debugger**: You manage a 12-node cluster on AWS EKS running three microservices. During a surge, a critical deployment experiences OOMKilled. Provide a concrete, end-to-end debugging plan and rollback strategy: include metrics you’d capture, commands you’d run, and exact changes (requests/limits, HPA, PDB, rollout)?","answer":"To debug OOMKilled pods in an EKS cluster during a surge, follow this structured approach:\n\n**1. Immediate Diagnosis**\n- Identify failing pods: `kubectl get pods -n <namespace> --field-selector=status.phase=Failed`\n- Examine pod details and termination reasons: `kubectl describe pod <pod-name> -n <namespace>`\n- Review cluster events: `kubectl get events -n <namespace> --sort-by='.lastTimestamp'`\n- Capture real-time metrics: `kubectl top pod -n <namespace> --containers`\n\n**2. Resource Analysis**\n- Compare actual usage against current requests/limits: `kubectl describe pod <pod-name> -n <namespace> | grep -A 10 \"Containers:\"`\n- Fetch historical metrics: `kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/namespaces/<namespace>/pods\"`\n\n**3. Resource Configuration Updates**\nSet conservative resource specifications:\n```yaml\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n```\n\n**4. Scalability and Resilience**\n- Configure HPA: `kubectl autoscale deployment <name> --cpu-percent=70 --min=2 --max=10 -n <namespace>`\n- Add PodDisruptionBudget: `kubectl apply -f pdb.yaml` with `minAvailable: 1`\n\n**5. Controlled Rollout**\n- Execute restart: `kubectl rollout restart deployment/<name> -n <namespace>`\n- Monitor progress: `kubectl rollout status deployment/<name> -n <namespace> --timeout=300s`\n- Validate pod health: `kubectl get pods -w -n <namespace> --field-selector=status.phase=Running`\n\n**6. Rollback Strategy**\n- If issues persist: `kubectl rollout undo deployment/<name> -n <namespace>`\n- Verify rollback: `kubectl rollout status deployment/<name> -n <namespace>`","explanation":"## Why This Is Asked\nThis question evaluates practical Kubernetes troubleshooting skills under pressure, testing your ability to diagnose OOM issues and implement systematic fixes in production environments.\n\n## Key Concepts\n- **OOMKilled Diagnosis**: Understanding memory pressure scenarios and termination reasons\n- **Resource Management**: Proper configuration of requests/limits for optimal scheduling and stability\n- **Observability Tools**: Leveraging kubectl commands and metrics for real-time debugging\n- **Auto-scaling**: HorizontalPodAutoscaler configuration for dynamic resource allocation\n- **Availability Controls**: PodDisruptionBudgets for maintaining service continuity\n- **Deployment Strategies**: Controlled rollouts and rollback mechanisms for zero-downtime updates\n\n## Code Example\n```yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb\nspec:\n  minAvailable: 1\n  selector:\n    matchLabels:\n      app: myapp\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"200m\"\n```\n\n## Implementation Strategy\nThe response provides a comprehensive debugging methodology that covers immediate diagnosis, root cause analysis, systematic fixes, and validation procedures, demonstrating production-ready Kubernetes expertise.","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Meta","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:12:32.327Z","createdAt":"2026-01-15T23:43:31.967Z"},{"id":"q-2656","question":"In a three-AZ Kubernetes cluster, design an operator to keep replicas of Deployments labeled app=svc spread across zones, even during node drains. Describe the CRD you would add, the reconcile logic, and how you would validate distribution with tests. Provide a minimal manifest example?","answer":"Explain how to build a Kubernetes operator (Go) that enforces zone-aware pod distribution for Deployments labeled app=svc in a multi-AZ cluster. Include a CRD (ZoneSpread) to declare minDistributions,","explanation":"## Why This Is Asked\nTests practical operator design and CRD usage for real-world cluster reliability.\n\n## Key Concepts\n- Kubernetes operators and the controller pattern\n- PodTopologySpread / TopologySpreadConstraints\n- CustomResourceDefinitions and idempotent reconcile\n- Handling node drains and eviction risk in production\n- Testing: envtest, fake clients, and integration tests\n\n## Code Example\n```yaml\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: zonespreads.acme.example.com\nspec:\n  group: acme.example.com\n  versions:\n  - name: v1beta1\n    served: true\n    storage: true\n    schema:\n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              minDistributions:\n                type: object\n                additionalProperties:\n                  type: integer\n  scope: Namespaced\n  names:\n    plural: zonespreads\n    singular: zonespread\n    kind: ZoneSpread\n```\n\n## Follow-up Questions\n- How would you test behavior during an AZ failure and node drain?\n- What are the trade-offs of using a CRD-driven reconciler vs. relying on built-in topology spread constraints?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","LinkedIn","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:41:43.115Z","createdAt":"2026-01-16T05:41:43.115Z"},{"id":"q-2721","question":"In a 6-node Kubernetes cluster, a critical stateless service is upgraded via RollingUpdate. Ensure availability never drops below 80% of replicas during the upgrade. Outline a concrete rollout plan with specific values for maxUnavailable, maxSurge, and a PodDisruptionBudget, plus readiness probes, preStop hooks, and a rollback strategy. Include how you'd verify rollout status and handle failure?","answer":"During the upgrade, configure RollingUpdate with maxUnavailable: 1 and maxSurge: 1 for a 6-replica deployment (ensures at least 5 pods up). Enforce a PodDisruptionBudget with minAvailable: 5. Implemen","explanation":"Why asked: tests knowledge of safe upgrades and HA. Key concepts: RollingUpdate strategy, maxUnavailable, maxSurge, PodDisruptionBudget, readiness/liveness probes, preStop, rollback. Code snippets: Deployment and PDB YAML. Follow-up: simulate upgrade, compare rollout status, and adjust thresholds.","diagram":"flowchart TD\n  A[Upgrade Plan] --> B[Set RollingUpdate strategy]\n  B --> C[Apply PodDisruptionBudget]\n  C --> D[Configure probes and preStop]\n  D --> E[Verify rollout and monitor]\n  E --> F[Rollback if failure]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T09:35:03.220Z","createdAt":"2026-01-16T09:35:03.222Z"},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","answer":"Capture startup timings and initContainer logs, kubectl describe pod, and events; monitor readiness transitions and image pulls. If init work is heavy, move health checks to readiness, cache results, ","explanation":"## Why This Is Asked\nThis question probes practical troubleshooting of startup latency caused by init containers in a real Kubernetes setup, emphasizing observability, risk-aware fixes, and rollback discipline.\n\n## Key Concepts\n- Kubernetes readiness vs startup probes\n- InitContainers vs parallel init\n- Canary rollouts and rollback\n- Observability: pod events, container logs, metrics\n\n## Code Example\n```yaml\nreadinessProbe:\n  exec:\n    command: [\"bash\",\"-lc\",\"echo ok\"]\n  initialDelaySeconds: 5\n  periodSeconds: 10\n```\n\n## Follow-up Questions\n- How would you gate a rollout to avoid user impact during a fix?\n- What would you monitor post-rollout to ensure latency doesn't regress?","diagram":"flowchart TD\n  A[Baseline Timings] --> B{InitContainer}\n  B --> C[Measure Startup Latency]\n  C --> D[Diagnosis & Fix Plan]\n  D --> E[Rollout Canary]\n  E --> F[Validate Metrics]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Salesforce","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:55:35.532Z","createdAt":"2026-01-12T13:55:35.532Z"},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","answer":"Verify health with etcdctl endpoint health for all endpoints, then identify the corrupted member via etcdctl member list/status. Stop the faulty node, restore a known-good snapshot using etcdctl snaps","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- etcd health checks\n- Snapshot restore and initial-cluster config\n- Member lifecycle and data-dir safety\n- Validation of API and cluster state\n\n## Code Example\n```bash\netcdctl endpoint health --endpoints=https://node1:2379,https://node2:2379,https://node3:2379\n```\n\n## Follow-up Questions\n- How would you automate this DR runbook?\n","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:34:21.100Z","createdAt":"2026-01-12T14:34:21.100Z"},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","answer":"Capture API server latency from metrics, then list webhook configurations: kubectl get mutatingwebhookconfiguration, validatingwebhookconfiguration. Identify culprit by error rate and latency. Patch t","explanation":"## Why This Is Asked\n\nInterviews gauge practical debugging of admission webhooks and API responsiveness under failure, plus rollback discipline in a live cluster.\n\n## Key Concepts\n\n- apiserver metrics and profiling\n- MutatingWebhookConfiguration and ValidatingWebhookConfiguration\n- safe-disable/rollback patterns\n- impact on cluster availability and security\n\n## Code Example\n\n```bash\n# Disable a specific webhook by removing it from the MutatingWebhookConfiguration\nkubectl get mutatingwebhookconfiguration <name> -o json | \\\n  jq 'del(.webhooks[] | select(.name == \"<target-webhook-name>\"))' | \\\n  kubectl apply -f -\n```\n```\n\n## Follow-up Questions\n\n- How would you test disablement in a non-prod cluster with minimal risk?\n- How would you ensure a controlled rollback if the webhook changes cause issues?\n","diagram":"flowchart TD\n  A[Start] --> B[Check apiserver metrics]\n  B --> C{Culprit found?}\n  C -->|Yes| D[Patch MutatingWebhookConfiguration to remove culprit]\n  C -->|No| E[Check ValidatingWebhookConfiguration]\n  D --> F[Validate API responsiveness with kubectl get ns]\n  F --> G{Healthy?}\n  G -->|Yes| H[Document rollback plan and monitor]\n  G -->|No| I[Escalate and revert changes]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:25:48.349Z","createdAt":"2026-01-12T16:25:48.349Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Cloudflare","Databricks","DoorDash","Google","Hashicorp","Hugging Face","IBM","LinkedIn","Lyft","Meta","Microsoft","Netflix","OpenAI","Oracle","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Tesla","Twitter","Two Sigma","Uber"],"stats":{"total":29,"beginner":6,"intermediate":9,"advanced":14,"newThisWeek":29}}