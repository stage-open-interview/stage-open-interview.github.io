{"questions":[{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","answer":"Identify the two healthy etcd members and verify quorum with etcdctl member list; check cluster-health. Stop the out-of-quorum member, restore the missing member from the latest snapshot using etcdctl","explanation":"## Why This Is Asked\nTests practical DR/HA recovery for etcd and API availability in multi-AZ. Requires exact commands and sequencing.\n\n## Key Concepts\n- etcd quorum and member lifecycle\n- Snapshot restore with initial-cluster state\n- HA API server restart order across AZs\n- DR readiness, RPO/RTO implications\n\n## Code Example\n```javascript\n// Illustrative DR restore flow (non-production, for understanding)\nconst {execSync} = require('child_process')\nexecSync(\"etcdctl snapshot restore snapshot.db --name etcd2 --initial-cluster 'etcd0=https://A:2380,etcd1=https://A2:2380,etcd2=https://B:2380' --initial-cluster-state=new\", {stdio:'inherit'})\n```\n\n## Follow-up Questions\n- How would you test this upgrade procedure to minimize downtime?\n- What are risks of multi-AZ etcd topologies and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:20:40.941Z","createdAt":"2026-01-12T22:20:40.941Z"},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","answer":"Capture startup timings and initContainer logs, kubectl describe pod, and events; monitor readiness transitions and image pulls. If init work is heavy, move health checks to readiness, cache results, ","explanation":"## Why This Is Asked\nThis question probes practical troubleshooting of startup latency caused by init containers in a real Kubernetes setup, emphasizing observability, risk-aware fixes, and rollback discipline.\n\n## Key Concepts\n- Kubernetes readiness vs startup probes\n- InitContainers vs parallel init\n- Canary rollouts and rollback\n- Observability: pod events, container logs, metrics\n\n## Code Example\n```yaml\nreadinessProbe:\n  exec:\n    command: [\"bash\",\"-lc\",\"echo ok\"]\n  initialDelaySeconds: 5\n  periodSeconds: 10\n```\n\n## Follow-up Questions\n- How would you gate a rollout to avoid user impact during a fix?\n- What would you monitor post-rollout to ensure latency doesn't regress?","diagram":"flowchart TD\n  A[Baseline Timings] --> B{InitContainer}\n  B --> C[Measure Startup Latency]\n  C --> D[Diagnosis & Fix Plan]\n  D --> E[Rollout Canary]\n  E --> F[Validate Metrics]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Salesforce","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:55:35.532Z","createdAt":"2026-01-12T13:55:35.532Z"},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","answer":"Verify health with etcdctl endpoint health for all endpoints, then identify the corrupted member via etcdctl member list/status. Stop the faulty node, restore a known-good snapshot using etcdctl snaps","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- etcd health checks\n- Snapshot restore and initial-cluster config\n- Member lifecycle and data-dir safety\n- Validation of API and cluster state\n\n## Code Example\n```bash\netcdctl endpoint health --endpoints=https://node1:2379,https://node2:2379,https://node3:2379\n```\n\n## Follow-up Questions\n- How would you automate this DR runbook?\n","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:34:21.100Z","createdAt":"2026-01-12T14:34:21.100Z"},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","answer":"Capture API server latency from metrics, then list webhook configurations: kubectl get mutatingwebhookconfiguration, validatingwebhookconfiguration. Identify culprit by error rate and latency. Patch t","explanation":"## Why This Is Asked\n\nInterviews gauge practical debugging of admission webhooks and API responsiveness under failure, plus rollback discipline in a live cluster.\n\n## Key Concepts\n\n- apiserver metrics and profiling\n- MutatingWebhookConfiguration and ValidatingWebhookConfiguration\n- safe-disable/rollback patterns\n- impact on cluster availability and security\n\n## Code Example\n\n```bash\n# Disable a specific webhook by removing it from the MutatingWebhookConfiguration\nkubectl get mutatingwebhookconfiguration <name> -o json | \\\n  jq 'del(.webhooks[] | select(.name == \"<target-webhook-name>\"))' | \\\n  kubectl apply -f -\n```\n```\n\n## Follow-up Questions\n\n- How would you test disablement in a non-prod cluster with minimal risk?\n- How would you ensure a controlled rollback if the webhook changes cause issues?\n","diagram":"flowchart TD\n  A[Start] --> B[Check apiserver metrics]\n  B --> C{Culprit found?}\n  C -->|Yes| D[Patch MutatingWebhookConfiguration to remove culprit]\n  C -->|No| E[Check ValidatingWebhookConfiguration]\n  D --> F[Validate API responsiveness with kubectl get ns]\n  F --> G{Healthy?}\n  G -->|Yes| H[Document rollback plan and monitor]\n  G -->|No| I[Escalate and revert changes]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:25:48.349Z","createdAt":"2026-01-12T16:25:48.349Z"}],"subChannels":["general"],"companies":["Airbnb","Cloudflare","Databricks","Google","IBM","Netflix","Salesforce","Scale Ai","Snap"],"stats":{"total":4,"beginner":0,"intermediate":4,"advanced":0,"newThisWeek":4}}