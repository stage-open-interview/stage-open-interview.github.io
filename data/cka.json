{"questions":[{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","answer":"Identify the two healthy etcd members and verify quorum with etcdctl member list; check cluster-health. Stop the out-of-quorum member, restore the missing member from the latest snapshot using etcdctl","explanation":"## Why This Is Asked\nTests practical DR/HA recovery for etcd and API availability in multi-AZ. Requires exact commands and sequencing.\n\n## Key Concepts\n- etcd quorum and member lifecycle\n- Snapshot restore with initial-cluster state\n- HA API server restart order across AZs\n- DR readiness, RPO/RTO implications\n\n## Code Example\n```javascript\n// Illustrative DR restore flow (non-production, for understanding)\nconst {execSync} = require('child_process')\nexecSync(\"etcdctl snapshot restore snapshot.db --name etcd2 --initial-cluster 'etcd0=https://A:2380,etcd1=https://A2:2380,etcd2=https://B:2380' --initial-cluster-state=new\", {stdio:'inherit'})\n```\n\n## Follow-up Questions\n- How would you test this upgrade procedure to minimize downtime?\n- What are risks of multi-AZ etcd topologies and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:20:40.941Z","createdAt":"2026-01-12T22:20:40.941Z"},{"id":"q-1368","question":"In a 3-node etcd-backed Kubernetes cluster, one node loses network connectivity and becomes partitioned while the other two remain healthy. How do you preserve availability and data integrity, avoid split-brain, and recover the partitioned member? Outline health checks, how you isolate the partition, recovery steps, and verification?","answer":"Assess quorum and health via etcdctl: member list and endpoint status. If a node is partitioned, fence it by stopping its etcd service or blocking its traffic so the two healthy members keep quorum. A","explanation":"## Why This Is Asked\nAssessing HA in etcd is critical for production clusters; this question tests practical recovery, fencing, and verification under partition scenarios.\n\n## Key Concepts\n- etcd quorum in a 3-node cluster\n- Fence/isolate to avoid split-brain\n- Recovery: rejoin member and verify\n- Validation: health checks and data consistency\n\n## Code Example\n```bash\netcdctl member list\netcdctl endpoint health\n```\n\n## Follow-up Questions\n- How would you simulate a partition in a staging cluster and validate failover?\n- Which metrics indicate a healthy etcd cluster after recovery?","diagram":"flowchart TD\n  A[Partition Detected] --> B[Fence Isolated Member]\n  B --> C[Two-Node Quorum Maintained]\n  C --> D[Network Fixed]\n  D --> E[Isolated Member Rejoined]\n  E --> F[Health Verified]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:20:24.108Z","createdAt":"2026-01-13T13:20:24.108Z"},{"id":"q-1395","question":"In a 3-node Kubernetes cluster, deploy a stateless web app using a Deployment with 3 replicas and a ClusterIP Service. Include readiness and liveness probes, CPU/memory requests and limits, and populate APP_MODE via a ConfigMap and DB_PASSWORD from a Secret. Describe the steps to perform a rolling update to 4 replicas with zero downtime and how you would verify the rollout across nodes?","answer":"Define a Deployment with 3 replicas and a ClusterIP Service. Add readinessProbe and livenessProbe, and set resources: requests cpu: 100m, memory: 128Mi; limits cpu: 500m, memory: 256Mi. Populate APP_M","explanation":"## Why This Is Asked\n\nTests practical Kubernetes administration skills: creating Deployments and Services, configuring probes and resources, wiring ConfigMaps and Secrets, and performing safe rolling updates with observable verification.\n\n## Key Concepts\n\n- Deployments and Services\n- Probes (readiness and liveness)\n- Resource requests/limits\n- ConfigMap and Secret usage\n- RollingUpdate strategy and rollout verification\n\n## Code Example\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"256Mi\"\n```\n\n## Follow-up Questions\n\n- How would you attach APP_MODE ConfigMap and DB_PASSWORD Secret as environment variables?\n- How would you monitor the rollout and diagnose a failed update?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:36:31.463Z","createdAt":"2026-01-13T15:36:31.464Z"},{"id":"q-1418","question":"Enable at-rest encryption for Kubernetes Secrets using a KMS (envelope) provider on an existing 3-control-plane cluster. Describe exact steps to configure the EncryptionConfig, rotate KEKs without downtime, trigger re-encryption of existing Secrets, and verify that new and existing Secrets are stored encrypted at rest (without decrypting at-rest data). Include concrete commands and caveats?","answer":"1) Create encryption-config.yaml with a kms provider for secrets and place on API servers. 2) Update API server manifest to --encryption-provider-config and restart. 3) Add a new KEK to the provider c","explanation":"## Why This Is Asked\nThis tests practical enablement of encryption at rest for Secrets using a KMS provider, including live-rotation and data re-encryption without downtime.\n\n## Key Concepts\n- Encryption at rest for Secrets\n- KMS envelope provider and key rotation\n- Re-encryption strategy without API downtime\n- Verification via ciphertext in etcd and API behavior\n- Operational risk and rollback\n\n## Code Example\n```yaml\n# encryption-config.yaml (high-level)\napiVersion: v1\nkind: EncryptionConfig\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      # kms configuration here\n  - aesgcm:\n      keys:\n      - name: key1\n```\n\n```bash\n# Basic commands (illustrative)\n# 1) Update API server to use config\n#Systemctl restart kube-apiserver\n# 2) Rotate KEK\n# edit encryption-config.yaml to add new KEK and restart\n# 3) Re-encrypt existing data\nkubectl get secret --all-namespaces -o json | kubectl apply -f -\n```\n\n## Follow-up Questions\n- How would you automate rotation across clusters and verify no data loss?\n- How would you test DR for key material and encryption config without affecting live workloads?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T16:41:51.999Z","createdAt":"2026-01-13T16:41:52.001Z"},{"id":"q-1452","question":"You operate a 3-node Kubernetes cluster with a StatefulSet of 3 replicas backed by PVs. A critical fix requires upgrading to image app:v2 with zero downtime. Outline a precise upgrade plan: set a PodDisruptionBudget to minAvailable 2, apply a RollingUpdate with partition=2, ensure readiness probes tolerate brief pod restarts, and verify data integrity during rollout with concrete kubectl commands?","answer":"Patch the StatefulSet with partition=2 so pods 0–1 upgrade first, keeping one online. Create a PodDisruptionBudget with minAvailable: 2. Upgrade: kubectl patch statefulset my-app -p '{\"spec\":{\"updateS","explanation":"## Why This Is Asked\nTests understanding of zero-downtime upgrades for StatefulSets, combined with PDBs, readiness, and data safety.\n\n## Key Concepts\n- StatefulSet RollingUpdate with partition control\n- PodDisruptionBudget for high availability\n- PV/PVC durability and readiness probes\n\n## Code Example\n```javascript\nfunction patchPayload(partition){\n  return {\"spec\": {\"updateStrategy\": {\"type\": \"RollingUpdate\", \"rollingUpdate\": {\"partition\": partition}}}};\n}\n```\n\n## Follow-up Questions\n- How would you verify data integrity during rollout? \n- What risks exist if a pod reschedules on another node during upgrade?","diagram":"flowchart TD\n  A[StatefulSet Upgrade] --> B[Apply PDB]\n  B --> C[Patch StatefulSet]\n  C --> D[Rollout]\n  D --> E[Verify]\n  E --> F[Finish]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:47:32.315Z","createdAt":"2026-01-13T17:47:32.315Z"},{"id":"q-1562","question":"How would you design a Kubernetes Job named app-init-seed that seeds app data on first run? The Job should use an Alpine-based image, mount a PVC at /data, load a script from a ConfigMap at /scripts/seed.sh, skip if /data/.seeded exists, optionally fetch seed.json from https://example.com using API key from a Secret, and write a log and the marker file upon success; include full YAML and apply steps?","answer":"Implement a Kubernetes Job named app-init-seed that seeds data on first run. Use an Alpine-based image, mount a PVC at /data, and load a script from a ConfigMap at /scripts/seed.sh. If /data/.seeded exists, skip processing. Optionally fetch seed.json from https://example.com using an API key from a Secret, then write a log and create the marker file upon success.","explanation":"## Why This Is Asked\nThis question tests practical understanding of Kubernetes Jobs, volume mounts, ConfigMaps, Secrets, idempotent operations, and error handling in a cluster environment. It also evaluates the ability to design resilient solutions with proper backoff limits and restart policies.\n\n## Key Concepts\n- Kubernetes Job lifecycle and management\n- Volume mounts for Persistent Volume Claims (PVCs)\n- ConfigMap and Secret integration\n- Idempotent seeding through marker files\n- BackoffLimit and restartPolicy configuration\n- Network operations with curl using --fail and --retry flags\n\n## Code Example\n```yaml\n# YAML Job example\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: app-init-seed\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 4\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: seed-container\n        image: alpine:3.18\n        command: [\"/bin/sh\", \"/scripts/seed.sh\"]\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n        - name: script-volume\n          mountPath: /scripts\n        env:\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: api-secret\n              key: api-key\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: app-data-pvc\n      - name: script-volume\n        configMap:\n          name: seed-script\n```\n\n## Apply Steps\n1. Create the ConfigMap with the seed script\n2. Create the Secret with the API key\n3. Ensure the PVC exists\n4. Apply the Job manifest: `kubectl apply -f app-init-seed-job.yaml`\n5. Monitor progress: `kubectl get jobs -w`","diagram":"flowchart TD\n  A[Job app-init-seed] --> B[Mount /data PVC]\n  B --> C{Seeded?}\n  C -- Yes --> D[Exit]\n  C -- No --> E[Fetch seed.json]\n  E --> F[Write /data/seed.json]\n  F --> G[Create /data/.seeded]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:57:44.958Z","createdAt":"2026-01-13T21:47:26.329Z"},{"id":"q-1737","question":"You're deploying a 3-replica Deployment in Kubernetes for a payment app. Suddenly 2 pods crash with CrashLoopBackOff. Describe a practical debugging workflow to identify if the issue is container startup, config, resources, or image, and outline the exact kubectl commands and file checks you would perform. Include how you would propose a minimal fix and a rollback plan?","answer":"Debug CrashLoopBackOff by isolating startup, config, resources, or image issues. Run: kubectl get pods -l app=payment; kubectl describe pod <pod>; kubectl logs <pod>; kubectl logs <pod> --previous; ku","explanation":"## Why This Is Asked\n\nTests practical debugging steps for Kubernetes CrashLoopBackOff, focusing on actionable commands.\n\n## Key Concepts\n\n- CrashLoopBackOff diagnosis\n- kubectl tooling (describe, logs, events)\n- ConfigMap/Secret patching\n- Rollback strategies\n\n## Code Example\n\n```bash\nkubectl get pods -l app=payment\n```\n\n## Follow-up Questions\n\n- How would you distinguish image pull errors from runtime crashes?\n- What are the risks of rolling back a deployment in production?","diagram":"flowchart TD\n  A[CrashLoopBackOff] --> B[Check pod status and events]\n  B --> C[Describe pod]\n  C --> D[Logs and previous logs]\n  D --> E[Probe/config/resources checks]\n  E --> F[Apply minimal fix]\n  F --> G[Rollout undo or restart]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:59:22.220Z","createdAt":"2026-01-14T08:59:22.220Z"},{"id":"q-1764","question":"Advanced: In a 5-node Kubernetes cluster where etcd memory usage has spiked after a noisy deployment, outline a production-safe remediation plan: verify health with etcdctl, diagnose via metrics, perform defrag/compact, take a snapshot, and adjust API watch load while preserving API server availability. What steps would you take?","answer":"Start by verifying health with etcdctl: endpoint status, member list, and health metrics; check RAM use and watch counts. Defragment and compact to reclaim space. Take a consistent snapshot for rollba","explanation":"## Why This Is Asked\nAssesses practical triage of etcd memory pressure in a live cluster, including safe backup/rollback and minimizing downtime.\n\n## Key Concepts\n- etcd health and metrics\n- defragmentation, compaction, backups\n- API server watch behavior and watch-cache\n- scalable rollback strategies\n\n## Code Example\n```javascript\n// Example: sequence of remediation steps\n```\n\n## Follow-up Questions\n- How would you validate remediation success after rollout?\n- What monitoring alerts would you configure to catch recurrence?\n","diagram":"flowchart TD\n  A(Check health via etcdctl) --> B(Assess memory hotspots)\n  B --> C(Defrag and compact)\n  C --> D(Take snapshot)\n  D --> E(Adjust resources/watch load)\n","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:48:51.723Z","createdAt":"2026-01-14T09:48:51.723Z"},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","answer":"Capture startup timings and initContainer logs, kubectl describe pod, and events; monitor readiness transitions and image pulls. If init work is heavy, move health checks to readiness, cache results, ","explanation":"## Why This Is Asked\nThis question probes practical troubleshooting of startup latency caused by init containers in a real Kubernetes setup, emphasizing observability, risk-aware fixes, and rollback discipline.\n\n## Key Concepts\n- Kubernetes readiness vs startup probes\n- InitContainers vs parallel init\n- Canary rollouts and rollback\n- Observability: pod events, container logs, metrics\n\n## Code Example\n```yaml\nreadinessProbe:\n  exec:\n    command: [\"bash\",\"-lc\",\"echo ok\"]\n  initialDelaySeconds: 5\n  periodSeconds: 10\n```\n\n## Follow-up Questions\n- How would you gate a rollout to avoid user impact during a fix?\n- What would you monitor post-rollout to ensure latency doesn't regress?","diagram":"flowchart TD\n  A[Baseline Timings] --> B{InitContainer}\n  B --> C[Measure Startup Latency]\n  C --> D[Diagnosis & Fix Plan]\n  D --> E[Rollout Canary]\n  E --> F[Validate Metrics]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Salesforce","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:55:35.532Z","createdAt":"2026-01-12T13:55:35.532Z"},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","answer":"Verify health with etcdctl endpoint health for all endpoints, then identify the corrupted member via etcdctl member list/status. Stop the faulty node, restore a known-good snapshot using etcdctl snaps","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- etcd health checks\n- Snapshot restore and initial-cluster config\n- Member lifecycle and data-dir safety\n- Validation of API and cluster state\n\n## Code Example\n```bash\netcdctl endpoint health --endpoints=https://node1:2379,https://node2:2379,https://node3:2379\n```\n\n## Follow-up Questions\n- How would you automate this DR runbook?\n","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:34:21.100Z","createdAt":"2026-01-12T14:34:21.100Z"},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","answer":"Capture API server latency from metrics, then list webhook configurations: kubectl get mutatingwebhookconfiguration, validatingwebhookconfiguration. Identify culprit by error rate and latency. Patch t","explanation":"## Why This Is Asked\n\nInterviews gauge practical debugging of admission webhooks and API responsiveness under failure, plus rollback discipline in a live cluster.\n\n## Key Concepts\n\n- apiserver metrics and profiling\n- MutatingWebhookConfiguration and ValidatingWebhookConfiguration\n- safe-disable/rollback patterns\n- impact on cluster availability and security\n\n## Code Example\n\n```bash\n# Disable a specific webhook by removing it from the MutatingWebhookConfiguration\nkubectl get mutatingwebhookconfiguration <name> -o json | \\\n  jq 'del(.webhooks[] | select(.name == \"<target-webhook-name>\"))' | \\\n  kubectl apply -f -\n```\n```\n\n## Follow-up Questions\n\n- How would you test disablement in a non-prod cluster with minimal risk?\n- How would you ensure a controlled rollback if the webhook changes cause issues?\n","diagram":"flowchart TD\n  A[Start] --> B[Check apiserver metrics]\n  B --> C{Culprit found?}\n  C -->|Yes| D[Patch MutatingWebhookConfiguration to remove culprit]\n  C -->|No| E[Check ValidatingWebhookConfiguration]\n  D --> F[Validate API responsiveness with kubectl get ns]\n  F --> G{Healthy?}\n  G -->|Yes| H[Document rollback plan and monitor]\n  G -->|No| I[Escalate and revert changes]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:25:48.349Z","createdAt":"2026-01-12T16:25:48.349Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Apple","Cloudflare","Databricks","Google","IBM","Microsoft","Netflix","Oracle","Robinhood","Salesforce","Scale Ai","Snap","Snowflake","Tesla","Uber"],"stats":{"total":11,"beginner":3,"intermediate":5,"advanced":3,"newThisWeek":11}}