{"questions":[{"id":"q-1087","question":"You're running a 5-node HA Kubernetes control plane (3 in AZ-a, 2 in AZ-b) with a 3-member etcd cluster. After a regional outage, etcd loses quorum. Describe exact, command-level steps to restore quorum, rejoin the third member, and validate API availability across both AZs, including risk notes and DR readiness checks?","answer":"Identify the two healthy etcd members and verify quorum with etcdctl member list; check cluster-health. Stop the out-of-quorum member, restore the missing member from the latest snapshot using etcdctl","explanation":"## Why This Is Asked\nTests practical DR/HA recovery for etcd and API availability in multi-AZ. Requires exact commands and sequencing.\n\n## Key Concepts\n- etcd quorum and member lifecycle\n- Snapshot restore with initial-cluster state\n- HA API server restart order across AZs\n- DR readiness, RPO/RTO implications\n\n## Code Example\n```javascript\n// Illustrative DR restore flow (non-production, for understanding)\nconst {execSync} = require('child_process')\nexecSync(\"etcdctl snapshot restore snapshot.db --name etcd2 --initial-cluster 'etcd0=https://A:2380,etcd1=https://A2:2380,etcd2=https://B:2380' --initial-cluster-state=new\", {stdio:'inherit'})\n```\n\n## Follow-up Questions\n- How would you test this upgrade procedure to minimize downtime?\n- What are risks of multi-AZ etcd topologies and how would you mitigate them?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Scale Ai","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:20:40.941Z","createdAt":"2026-01-12T22:20:40.941Z"},{"id":"q-1368","question":"In a 3-node etcd-backed Kubernetes cluster, one node loses network connectivity and becomes partitioned while the other two remain healthy. How do you preserve availability and data integrity, avoid split-brain, and recover the partitioned member? Outline health checks, how you isolate the partition, recovery steps, and verification?","answer":"Assess quorum and health via etcdctl: member list and endpoint status. If a node is partitioned, fence it by stopping its etcd service or blocking its traffic so the two healthy members keep quorum. A","explanation":"## Why This Is Asked\nAssessing HA in etcd is critical for production clusters; this question tests practical recovery, fencing, and verification under partition scenarios.\n\n## Key Concepts\n- etcd quorum in a 3-node cluster\n- Fence/isolate to avoid split-brain\n- Recovery: rejoin member and verify\n- Validation: health checks and data consistency\n\n## Code Example\n```bash\netcdctl member list\netcdctl endpoint health\n```\n\n## Follow-up Questions\n- How would you simulate a partition in a staging cluster and validate failover?\n- Which metrics indicate a healthy etcd cluster after recovery?","diagram":"flowchart TD\n  A[Partition Detected] --> B[Fence Isolated Member]\n  B --> C[Two-Node Quorum Maintained]\n  C --> D[Network Fixed]\n  D --> E[Isolated Member Rejoined]\n  E --> F[Health Verified]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:20:24.108Z","createdAt":"2026-01-13T13:20:24.108Z"},{"id":"q-1395","question":"In a 3-node Kubernetes cluster, deploy a stateless web app using a Deployment with 3 replicas and a ClusterIP Service. Include readiness and liveness probes, CPU/memory requests and limits, and populate APP_MODE via a ConfigMap and DB_PASSWORD from a Secret. Describe the steps to perform a rolling update to 4 replicas with zero downtime and how you would verify the rollout across nodes?","answer":"Define a Deployment with 3 replicas and a ClusterIP Service. Add readinessProbe and livenessProbe, and set resources: requests cpu: 100m, memory: 128Mi; limits cpu: 500m, memory: 256Mi. Populate APP_M","explanation":"## Why This Is Asked\n\nTests practical Kubernetes administration skills: creating Deployments and Services, configuring probes and resources, wiring ConfigMaps and Secrets, and performing safe rolling updates with observable verification.\n\n## Key Concepts\n\n- Deployments and Services\n- Probes (readiness and liveness)\n- Resource requests/limits\n- ConfigMap and Secret usage\n- RollingUpdate strategy and rollout verification\n\n## Code Example\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"256Mi\"\n```\n\n## Follow-up Questions\n\n- How would you attach APP_MODE ConfigMap and DB_PASSWORD Secret as environment variables?\n- How would you monitor the rollout and diagnose a failed update?","diagram":null,"difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:36:31.463Z","createdAt":"2026-01-13T15:36:31.464Z"},{"id":"q-1418","question":"Enable at-rest encryption for Kubernetes Secrets using a KMS (envelope) provider on an existing 3-control-plane cluster. Describe exact steps to configure the EncryptionConfig, rotate KEKs without downtime, trigger re-encryption of existing Secrets, and verify that new and existing Secrets are stored encrypted at rest (without decrypting at-rest data). Include concrete commands and caveats?","answer":"1) Create encryption-config.yaml with a kms provider for secrets and place on API servers. 2) Update API server manifest to --encryption-provider-config and restart. 3) Add a new KEK to the provider c","explanation":"## Why This Is Asked\nThis tests practical enablement of encryption at rest for Secrets using a KMS provider, including live-rotation and data re-encryption without downtime.\n\n## Key Concepts\n- Encryption at rest for Secrets\n- KMS envelope provider and key rotation\n- Re-encryption strategy without API downtime\n- Verification via ciphertext in etcd and API behavior\n- Operational risk and rollback\n\n## Code Example\n```yaml\n# encryption-config.yaml (high-level)\napiVersion: v1\nkind: EncryptionConfig\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      # kms configuration here\n  - aesgcm:\n      keys:\n      - name: key1\n```\n\n```bash\n# Basic commands (illustrative)\n# 1) Update API server to use config\n#Systemctl restart kube-apiserver\n# 2) Rotate KEK\n# edit encryption-config.yaml to add new KEK and restart\n# 3) Re-encrypt existing data\nkubectl get secret --all-namespaces -o json | kubectl apply -f -\n```\n\n## Follow-up Questions\n- How would you automate rotation across clusters and verify no data loss?\n- How would you test DR for key material and encryption config without affecting live workloads?","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T16:41:51.999Z","createdAt":"2026-01-13T16:41:52.001Z"},{"id":"q-1452","question":"You operate a 3-node Kubernetes cluster with a StatefulSet of 3 replicas backed by PVs. A critical fix requires upgrading to image app:v2 with zero downtime. Outline a precise upgrade plan: set a PodDisruptionBudget to minAvailable 2, apply a RollingUpdate with partition=2, ensure readiness probes tolerate brief pod restarts, and verify data integrity during rollout with concrete kubectl commands?","answer":"Patch the StatefulSet with partition=2 so pods 0–1 upgrade first, keeping one online. Create a PodDisruptionBudget with minAvailable: 2. Upgrade: kubectl patch statefulset my-app -p '{\"spec\":{\"updateS","explanation":"## Why This Is Asked\nTests understanding of zero-downtime upgrades for StatefulSets, combined with PDBs, readiness, and data safety.\n\n## Key Concepts\n- StatefulSet RollingUpdate with partition control\n- PodDisruptionBudget for high availability\n- PV/PVC durability and readiness probes\n\n## Code Example\n```javascript\nfunction patchPayload(partition){\n  return {\"spec\": {\"updateStrategy\": {\"type\": \"RollingUpdate\", \"rollingUpdate\": {\"partition\": partition}}}};\n}\n```\n\n## Follow-up Questions\n- How would you verify data integrity during rollout? \n- What risks exist if a pod reschedules on another node during upgrade?","diagram":"flowchart TD\n  A[StatefulSet Upgrade] --> B[Apply PDB]\n  B --> C[Patch StatefulSet]\n  C --> D[Rollout]\n  D --> E[Verify]\n  E --> F[Finish]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:47:32.315Z","createdAt":"2026-01-13T17:47:32.315Z"},{"id":"q-1562","question":"How would you design a Kubernetes Job named app-init-seed that seeds app data on first run? The Job should use an Alpine-based image, mount a PVC at /data, load a script from a ConfigMap at /scripts/seed.sh, skip if /data/.seeded exists, optionally fetch seed.json from https://example.com using API key from a Secret, and write a log and the marker file upon success; include full YAML and apply steps?","answer":"Implement a Kubernetes Job named app-init-seed that seeds data on first run. Use an Alpine-based image, mount a PVC at /data, and load a script from a ConfigMap at /scripts/seed.sh. If /data/.seeded exists, skip processing. Optionally fetch seed.json from https://example.com using an API key from a Secret, then write a log and create the marker file upon success.","explanation":"## Why This Is Asked\nThis question tests practical understanding of Kubernetes Jobs, volume mounts, ConfigMaps, Secrets, idempotent operations, and error handling in a cluster environment. It also evaluates the ability to design resilient solutions with proper backoff limits and restart policies.\n\n## Key Concepts\n- Kubernetes Job lifecycle and management\n- Volume mounts for Persistent Volume Claims (PVCs)\n- ConfigMap and Secret integration\n- Idempotent seeding through marker files\n- BackoffLimit and restartPolicy configuration\n- Network operations with curl using --fail and --retry flags\n\n## Code Example\n```yaml\n# YAML Job example\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: app-init-seed\nspec:\n  completions: 1\n  parallelism: 1\n  backoffLimit: 4\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: seed-container\n        image: alpine:3.18\n        command: [\"/bin/sh\", \"/scripts/seed.sh\"]\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n        - name: script-volume\n          mountPath: /scripts\n        env:\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: api-secret\n              key: api-key\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: app-data-pvc\n      - name: script-volume\n        configMap:\n          name: seed-script\n```\n\n## Apply Steps\n1. Create the ConfigMap with the seed script\n2. Create the Secret with the API key\n3. Ensure the PVC exists\n4. Apply the Job manifest: `kubectl apply -f app-init-seed-job.yaml`\n5. Monitor progress: `kubectl get jobs -w`","diagram":"flowchart TD\n  A[Job app-init-seed] --> B[Mount /data PVC]\n  B --> C{Seeded?}\n  C -- Yes --> D[Exit]\n  C -- No --> E[Fetch seed.json]\n  E --> F[Write /data/seed.json]\n  F --> G[Create /data/.seeded]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:57:44.958Z","createdAt":"2026-01-13T21:47:26.329Z"},{"id":"q-1737","question":"You're deploying a 3-replica Deployment in Kubernetes for a payment app. Suddenly 2 pods crash with CrashLoopBackOff. Describe a practical debugging workflow to identify if the issue is container startup, config, resources, or image, and outline the exact kubectl commands and file checks you would perform. Include how you would propose a minimal fix and a rollback plan?","answer":"Debug CrashLoopBackOff by isolating startup, config, resources, or image issues. Run: kubectl get pods -l app=payment; kubectl describe pod <pod>; kubectl logs <pod>; kubectl logs <pod> --previous; ku","explanation":"## Why This Is Asked\n\nTests practical debugging steps for Kubernetes CrashLoopBackOff, focusing on actionable commands.\n\n## Key Concepts\n\n- CrashLoopBackOff diagnosis\n- kubectl tooling (describe, logs, events)\n- ConfigMap/Secret patching\n- Rollback strategies\n\n## Code Example\n\n```bash\nkubectl get pods -l app=payment\n```\n\n## Follow-up Questions\n\n- How would you distinguish image pull errors from runtime crashes?\n- What are the risks of rolling back a deployment in production?","diagram":"flowchart TD\n  A[CrashLoopBackOff] --> B[Check pod status and events]\n  B --> C[Describe pod]\n  C --> D[Logs and previous logs]\n  D --> E[Probe/config/resources checks]\n  E --> F[Apply minimal fix]\n  F --> G[Rollout undo or restart]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:59:22.220Z","createdAt":"2026-01-14T08:59:22.220Z"},{"id":"q-1764","question":"Advanced: In a 5-node Kubernetes cluster where etcd memory usage has spiked after a noisy deployment, outline a production-safe remediation plan: verify health with etcdctl, diagnose via metrics, perform defrag/compact, take a snapshot, and adjust API watch load while preserving API server availability. What steps would you take?","answer":"Start by verifying health with etcdctl: endpoint status, member list, and health metrics; check RAM use and watch counts. Defragment and compact to reclaim space. Take a consistent snapshot for rollba","explanation":"## Why This Is Asked\nAssesses practical triage of etcd memory pressure in a live cluster, including safe backup/rollback and minimizing downtime.\n\n## Key Concepts\n- etcd health and metrics\n- defragmentation, compaction, backups\n- API server watch behavior and watch-cache\n- scalable rollback strategies\n\n## Code Example\n```javascript\n// Example: sequence of remediation steps\n```\n\n## Follow-up Questions\n- How would you validate remediation success after rollout?\n- What monitoring alerts would you configure to catch recurrence?\n","diagram":"flowchart TD\n  A(Check health via etcdctl) --> B(Assess memory hotspots)\n  B --> C(Defrag and compact)\n  C --> D(Take snapshot)\n  D --> E(Adjust resources/watch load)\n","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Microsoft","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:48:51.723Z","createdAt":"2026-01-14T09:48:51.723Z"},{"id":"q-1810","question":"You're operating a 5-node Kubernetes cluster with a validating webhook named cfg.example.com enforcing a label requirement on Deployments in all namespaces. A critical patch must be applied in prod-adv while the webhook service is temporarily unavailable. Outline a safe, auditable plan to bypass the webhook with exact kubectl commands to identify, disable, apply, and revert?","answer":"Patch the ValidatingWebhookConfiguration to Ignore on failure, apply the patch in prod-adv, then revert to Fail and verify with events and rollout. Commands: kubectl get validatingwebhookconfiguration","explanation":"## Why This Is Asked\nTests understanding of Kubernetes admission control and safe rollbacks under outage.\n\n## Key Concepts\n- ValidatingWebhookConfiguration\n- FailurePolicy: Ignore vs Fail\n- Safe patch deployment\n- Auditable rollback\n\n## Code Example\n```yaml\n# minimal patch example framework\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: cfg.example.com\n  \n# actual patch differs per cluster\n```\n\n## Follow-up Questions\n- How would you validate no partial patches linger?\n- What are risks if you forget to revert? ","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Google","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T11:45:33.451Z","createdAt":"2026-01-14T11:45:33.451Z"},{"id":"q-1885","question":"In a high-traffic delivery platform, you deploy a Kubernetes-based worker pool for async order processing. Explain how you would implement a robust, rate-limited queue with backpressure, idempotent workers, and at-least-once delivery, using Kubernetes primitives and common tools. Include how you handle spikes, retries, and data-store consistency?","answer":"Use a Kafka or Redis Streams backed queue with stateless workers behind a HorizontalPodAutoscaler. Enforce backpressure with a token-bucket limiter shared via Redis. Ensure idempotence by recording pr","explanation":"## Why This Is Asked\nTests practical Kubernetes design for async processing, backpressure, idempotency, and delivery guarantees in production-like scenarios.\n\n## Key Concepts\n- Durable queues (Kafka/Redis Streams)\n- Backpressure and rate limiting\n- Idempotent workers and at-least-once delivery\n- Backoff strategies and DLQ\n- Data-store consistency with upserts\n\n## Code Example\n```javascript\n// Pseudo-code: worker handling with idempotency checks\nfunction handle(msg) {\n  if (db.hasProcessed(msg.id)) return;\n  const res = process(msg);\n  db.upsert({ id: msg.id, result: res });\n  ack(msg);\n}\n```\n\n## Follow-up Questions\n- How would you test exactly-once vs at-least-once guarantees?\n- How would you observe and alert on backpressure and DLQ growth?\n","diagram":"flowchart TD\n  A[Ingest] --> B[Enqueue]\n  B --> C[Workers]\n  C --> D[Persist/ACK]\n  D --> E[DLQ]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:45:54.277Z","createdAt":"2026-01-14T15:45:54.277Z"},{"id":"q-1932","question":"Describe a **concrete, production-ready plan** for zero-downtime deployments in a Lyft-scale Kubernetes cluster with ~40 microservices, multiple data stores, and strict uptime. How would you implement **blue/green or canary releases**, traffic shaping, and automated rollbacks? Include rollout strategy, readiness checks, RBAC, DR, and a compact manifest example comparing Istio and Linkerd approaches?","answer":"Plan calls for immutable deployments with Canary or Blue/Green, progressive traffic shifts (start 1–5% canary and ramp), readiness/liveness probes, and PodDisruptionBudget with automated rollback on f","explanation":"## Why This Is Asked\nTests practical mastery of deployment strategies in large Kubernetes environments, emphasizing real-world constraints, traffic control, observability, and DR.\n\n## Key Concepts\n- Canary and blue/green deployments\n- Traffic shaping with service mesh (Istio/Linkerd)\n- Readiness/Liveness probes, PodDisruptionBudget\n- Rollbacks, error budgets, observability\n- DR planning, RBAC\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: payments\nspec:\n  replicas: 4\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  template:\n    metadata:\n      labels:\n        app: payments\n    spec:\n      containers:\n      - name: payments\n        image: myrepo/payments:canary-1\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n```\n\n## Follow-up Questions\n- How would you measure canary success and trigger rollback?\n- What metrics and alerting would you configure?\n","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Tesla","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:46:42.475Z","createdAt":"2026-01-14T17:46:42.475Z"},{"id":"q-1946","question":"On a 3-node Kubernetes cluster, a Deployment’s Pods stay Pending while 2 nodes are Ready. The scheduler shows a NoSchedule taint on node-1. Explain exact commands to identify the taint, check the pod’s tolerations, and either remove the taint or add a matching toleration so the workload schedules. How do you validate after changes?","answer":"Check taint and pods: kubectl get nodes -o wide and kubectl describe node node-1 to confirm the taint. To remove: kubectl taint nodes node-1 NoSchedule-. Or add toleration to the Pod/Deployment: toler","explanation":"## Why This Is Asked\nTests practical ability to diagnose and fix scheduling using taints/tolerations in a real cluster.\n\n## Key Concepts\n- taints and tolerations\n- kubectl diagnostics\n- Deployment rollout verification\n\n## Code Example\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example\nspec:\n  template:\n    spec:\n      tolerations:\n      - key: \"node-role.kubernetes.io/node\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n```\n\n## Follow-up Questions\n- How would you limit the toleration to a subset of pods?\n- What are risks of removing a NoSchedule taint on a node?","diagram":"flowchart TD\n  A[Identify taint] --> B[Decide action]\n  B --> C{Remove taint?}\n  C -->|Yes| D[Apply taint removal]\n  C -->|No| E[Tolerations added]\n  D --> F[Rollout verify]\n  E --> F","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:43:56.873Z","createdAt":"2026-01-14T18:43:56.875Z"},{"id":"q-1972","question":"You maintain a Node.js app deployed as a 3-replica Kubernetes Deployment behind a service. A security patch requires updating the container image from v1.0.1 to v1.0.2 with zero downtime. List exact kubectl steps to perform a safe rolling update, how you confirm readiness, and how you rollback if the rollout fails?","answer":"Use kubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2; wait for rollout to complete with kubectl rollout status deployment/myapp; verify all pods are Ready and running the new image with ku","explanation":"## Why This Is Asked\n\nTests practical, safe rolling update knowledge in real Kubernetes workflows.\n\n## Key Concepts\n\n- RollingUpdate strategy\n- Readiness/Liveness probes\n- Rollback with rollout undo\n- kubectl use in production-like tasks\n\n## Code Example\n\n```javascript\nkubectl set image deployment/myapp myapp=myrepo/myapp:v1.0.2\n```\n\n## Follow-up Questions\n\n- What would you do if a pod crashes after update?\n- How would you adjust probes/thresholds to prevent future issues?\n","diagram":"flowchart TD\n  A[Deployment] --> B[RollingUpdate]\n  B --> C{Status}\n  C -->|Success| D[Done]\n  C -->|Failure| E[Rollback]","difficulty":"beginner","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:28:07.727Z","createdAt":"2026-01-14T19:28:07.727Z"},{"id":"q-2027","question":"You're managing a shared Kubernetes cluster with namespaces prod, analytics, and dev. A nightly analytics batch job sometimes starves frontend pods during peak hours, triggering evictions. Design an end-to-end remediation plan: tune pod requests/limits, enforce defaults with a LimitRange, cap total usage with a ResourceQuota, ensure guaranteed QoS, evaluate VerticalPodAutoscaler vs HorizontalPodAutoscaler, and outline validation steps to prevent regressions?","answer":"Set explicit requests and limits for all affected pods to prevent the analytics job from exhausting shared resources; implement a LimitRange in the analytics namespace to enforce default values; add a ResourceQuota per namespace to cap total resource consumption; configure Guaranteed QoS for critical frontend pods by setting requests equal to limits; evaluate HorizontalPodAutoscaler for frontend pods to scale during peak demand and VerticalPodAutoscaler for the analytics job to right-size its resource allocation; implement canary deployments and load testing to validate the solution.","explanation":"## Why This Is Asked\nTests resource management expertise and real-world trade-offs involving quotas, QoS classes, and autoscaling strategies across Kubernetes namespaces.\n\n## Key Concepts\n- Kubernetes QoS classes (Guaranteed, Burstable, Best-Effort)\n- ResourceQuota and LimitRange for namespace governance\n- HorizontalPodAutoscaler (HPA) for scaling out\n- VerticalPodAutoscaler (VPA) for right-sizing resources\n- Canary validation and load testing strategies\n\n## Code Example\n```yaml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: analytics-defaults\n  namespace: analytics\nspec:\n  limits:\n  - default:\n      cpu: 500m\n      memory: 512Mi\n    defaultRequest:\n      cpu: 250m\n      memory: 256Mi\n    type: Container\n```\n\n## Follow-up Questions\n- How would you test eviction behavior in a staging environment?\n- How would you monitor and alert on resource quota utilization?","diagram":null,"difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:50:09.378Z","createdAt":"2026-01-14T21:35:41.722Z"},{"id":"q-2134","question":"You manage a Databricks/OpenAI-like platform on Kubernetes. A Spark streaming job processes 1TB/day and faces sporadic node preemption causing data loss without checkpoints. Design a fault-tolerant deployment (manifests and configurations) and explain trade-offs between Kubernetes Job vs. StatefulSet, backoff strategies, taints/tolerations, and Spark dynamic allocation. What would you implement and why?","answer":"Design a fault-tolerant Spark-on-Kubernetes deployment: run the streaming job with dynamic allocation; enable checkpointing to durable storage; use taints/tolerations and a PodDisruptionBudget; set ba","explanation":"## Why This Is Asked\nThis question probes real-world Kubernetes/Spark fault-tolerance, scheduling, and stateful workload design—crucial on large platforms like Databricks/OpenAI.\n\n## Key Concepts\n- Spark on Kubernetes (CRs, dynamic allocation)\n- Checkpointing and exactly-once semantics\n- PodDisruptionBudget, taints/tolerations, restart policies\n- Observability and alerts (Prometheus)\n\n## Code Example\n```javascript\n// Example SparkApplication spec (pseudo)\nconst sparkApp = {\n  apiVersion: \"sparkoperator.k8s.io/v1beta2\",\n  kind: \"SparkApplication\",\n  metadata: { name: \"stream-1\" },\n  spec: {\n    mode: \"cluster\",\n    image: \"spark:3.2\",\n    mainClass: \"com.example.Stream\",\n    mainApplicationFile: \"local:///stream.jar\",\n    sparkVersion: \"3.2.0\",\n    restartPolicy: { type: \"OnFailure\", onFailureRetries: 3, onFailureRetryInterval: 10 },\n    dynamicAllocation: { enabled: true },\n    backpressureEnabled: true,\n    checkpointLocation: \"s3://bucket/checkpoints\"\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test the fault-tolerance guarantees?\n- What changes if the storage is GCS vs S3?","diagram":"flowchart TD\n  Client --> APIServer\n  APIServer --> etcd\n  APIServer --> Scheduler\n  Scheduler --> Worker\n  Worker --> CheckpointStorage","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:17:04.104Z","createdAt":"2026-01-15T04:17:04.104Z"},{"id":"q-2152","question":"On a Kubernetes cluster running Spark jobs via Spark on Kubernetes, a 12-pod job reports intermittent OOM errors during shuffle-heavy stages on medium-sized datasets. Provide a concrete debugging plan: how you verify memory limits, adjust executor/driver memory and overhead, tune JVM GC, and validate changes with metrics and a controlled benchmark run?","answer":"Begin by confirming per-pod memory limits and actual usage with kubectl describe pod and metrics; then tune Spark: set spark.executor.memory and spark.driver.memory to safe values, add memoryOverhead,","explanation":"## Why This Is Asked\n\nTests ability to reason about Kubernetes resources and Spark on Kubernetes, and perform practical memory tuning with metrics, GC, and observability.\n\n## Key Concepts\n\n- Kubernetes resource requests/limits\n- Spark memory tuning (driver/executor memory, memoryOverhead, spark.memory.fraction)\n- JVM GC options and GC logging\n- Shuffle-heavy workloads and GC pressure\n- Observability (Spark UI, kubectl top, metrics)\n\n## Code Example\n\n```javascript\n// Kubernetes patch example (pseudo)\nconst patch = {\n  spec: {\n    template: {\n      spec: {\n        containers: [\n          { name: \"executor\",\n            resources: { requests: { memory: \"12Gi\" }, limits: { memory: \"12Gi\" } }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you detect a memory leak vs normal GC pauses?\n- How would you verify stability after changes with a canary run?","diagram":"flowchart TD\n  A[Cluster] --> B[Diagnose OOM]\n  B --> C{Adjust Resources}\n  C --> D[Apply Quotas]\n  C --> E[Restart Pods]","difficulty":"advanced","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:34:36.507Z","createdAt":"2026-01-15T05:34:36.507Z"},{"id":"q-874","question":"In a Kubernetes cluster used by Salesforce/Cloudflare/Snap engineers, a Deployment's startup latency rose from 1–2s to 6–8s after introducing an initContainer that runs a health check before the application starts. Describe how you would diagnose, what metrics/logs to collect, and concrete fixes (e.g., moving checks to readiness, caching, parallel init, or canary rollout). Include rollback and validation steps?","answer":"Capture startup timings and initContainer logs, kubectl describe pod, and events; monitor readiness transitions and image pulls. If init work is heavy, move health checks to readiness, cache results, ","explanation":"## Why This Is Asked\nThis question probes practical troubleshooting of startup latency caused by init containers in a real Kubernetes setup, emphasizing observability, risk-aware fixes, and rollback discipline.\n\n## Key Concepts\n- Kubernetes readiness vs startup probes\n- InitContainers vs parallel init\n- Canary rollouts and rollback\n- Observability: pod events, container logs, metrics\n\n## Code Example\n```yaml\nreadinessProbe:\n  exec:\n    command: [\"bash\",\"-lc\",\"echo ok\"]\n  initialDelaySeconds: 5\n  periodSeconds: 10\n```\n\n## Follow-up Questions\n- How would you gate a rollout to avoid user impact during a fix?\n- What would you monitor post-rollout to ensure latency doesn't regress?","diagram":"flowchart TD\n  A[Baseline Timings] --> B{InitContainer}\n  B --> C[Measure Startup Latency]\n  C --> D[Diagnosis & Fix Plan]\n  D --> E[Rollout Canary]\n  E --> F[Validate Metrics]","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Salesforce","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:55:35.532Z","createdAt":"2026-01-12T13:55:35.532Z"},{"id":"q-893","question":"You manage a 3-node Kubernetes control plane backed by an etcd cluster. After a power outage, one etcd member reports corruption. Describe the exact steps to detect the corrupted member, restore from a known-good snapshot, rejoin the cluster, and validate API availability. Include concrete commands, risk notes, and how you would verify DR readiness?","answer":"Verify health with etcdctl endpoint health for all endpoints, then identify the corrupted member via etcdctl member list/status. Stop the faulty node, restore a known-good snapshot using etcdctl snaps","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- etcd health checks\n- Snapshot restore and initial-cluster config\n- Member lifecycle and data-dir safety\n- Validation of API and cluster state\n\n## Code Example\n```bash\netcdctl endpoint health --endpoints=https://node1:2379,https://node2:2379,https://node3:2379\n```\n\n## Follow-up Questions\n- How would you automate this DR runbook?\n","diagram":null,"difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:34:21.100Z","createdAt":"2026-01-12T14:34:21.100Z"},{"id":"q-936","question":"A 3-control-plane Kubernetes cluster on AWS experiences API server latency spikes after a webhook deployment. The admission webhook is malfunctioning and causing slow requests; outline precise steps to identify the failing webhook, safely disable it to restore API responsiveness, validate cluster availability, and prepare a rollback plan with minimal downtime?","answer":"Capture API server latency from metrics, then list webhook configurations: kubectl get mutatingwebhookconfiguration, validatingwebhookconfiguration. Identify culprit by error rate and latency. Patch t","explanation":"## Why This Is Asked\n\nInterviews gauge practical debugging of admission webhooks and API responsiveness under failure, plus rollback discipline in a live cluster.\n\n## Key Concepts\n\n- apiserver metrics and profiling\n- MutatingWebhookConfiguration and ValidatingWebhookConfiguration\n- safe-disable/rollback patterns\n- impact on cluster availability and security\n\n## Code Example\n\n```bash\n# Disable a specific webhook by removing it from the MutatingWebhookConfiguration\nkubectl get mutatingwebhookconfiguration <name> -o json | \\\n  jq 'del(.webhooks[] | select(.name == \"<target-webhook-name>\"))' | \\\n  kubectl apply -f -\n```\n```\n\n## Follow-up Questions\n\n- How would you test disablement in a non-prod cluster with minimal risk?\n- How would you ensure a controlled rollback if the webhook changes cause issues?\n","diagram":"flowchart TD\n  A[Start] --> B[Check apiserver metrics]\n  B --> C{Culprit found?}\n  C -->|Yes| D[Patch MutatingWebhookConfiguration to remove culprit]\n  C -->|No| E[Check ValidatingWebhookConfiguration]\n  D --> F[Validate API responsiveness with kubectl get ns]\n  F --> G{Healthy?}\n  G -->|Yes| H[Document rollback plan and monitor]\n  G -->|No| I[Escalate and revert changes]\n","difficulty":"intermediate","tags":["cka"],"channel":"cka","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:25:48.349Z","createdAt":"2026-01-12T16:25:48.349Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Cloudflare","Databricks","DoorDash","Google","IBM","Lyft","Meta","Microsoft","Netflix","OpenAI","Oracle","Robinhood","Salesforce","Scale Ai","Snap","Snowflake","Tesla","Twitter","Two Sigma","Uber"],"stats":{"total":19,"beginner":5,"intermediate":6,"advanced":8,"newThisWeek":19}}