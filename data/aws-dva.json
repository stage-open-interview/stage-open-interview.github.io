{"questions":[{"id":"q-1025","question":"In a multi-account AWS DVA data platform, streaming IoT telemetry into Kinesis Data Firehose feeding an S3 data lake with Glue catalog. Data schemas evolve and backfills are needed without full reprocessing. Design an end-to-end approach for schema evolution, idempotent writes, and backfill using Glue Schema Registry, Iceberg on S3, and partition pruning. Include data validation, DLQ, and observability?","answer":"Use Glue Schema Registry for versioned schemas, write to Iceberg tables on S3 to support schema evolution and upserts with a deterministic key, implement idempotent writes via a normalized primary key","explanation":"## Why This Is Asked\nTests ability to design scalable, cross-account data pipelines with evolving schemas.\n\n## Key Concepts\n- Glue Schema Registry versioned schemas\n- Iceberg on S3 for upserts and schema evolution\n- Deterministic keys for idempotent writes\n- Partition-driven backfill without full reprocessing\n- DLQ and data quality observability\n\n## Code Example\n```python\n# Pseudocode: write with Iceberg upsert using key\ndef upsert(record):\n  key = record['device_id']\n  iceberg.upsert(table='lake.telemetry', key=key, record=record)\n```\n\n## Follow-up Questions\n- How do you partition backfills to minimize shards?\n- How would you enforce cross-account access controls for Lake Formation?\n","diagram":"flowchart TD\n  Ingest[Kinesis Data Streams] --> Validate[Glue Schema Registry]\n  Validate --> Catalog[(Glue Catalog/Iceberg)]\n  Catalog --> Backfill[Incremental Backfill by Partition]\n  Backfill --> Observability[DLQ & CloudWatch Logs]\n","difficulty":"advanced","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Instacart","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T19:37:01.899Z","createdAt":"2026-01-12T19:37:01.899Z"},{"id":"q-1268","question":"Design an AWS data lake pattern for multi-tenant analytics where each tenant's data sits under /tenants/{tenantId} in S3 and is exposed to Athena and QuickSight. How would you implement strict tenant isolation, least-privilege access, and automated policy-driven discovery and auditing using Lake Formation, IAM, CMKs, and SCPs? Include governance, testing, and performance considerations?","answer":"Store tenant data in S3 under /tenants/{tenantId} and enforce isolation with Lake Formation grants tied to per-tenant tables. Use per-tenant IAM roles mapped to a central admin for governance, apply S","explanation":"## Why This Is Asked\nTests practical mastery of multi-tenant data governance, isolation, and scalable access control in a real analytics stack. It also probes knowledge of Lake Formation, IAM role mapping, encryption strategy, and cross-account governance.\n\n## Key Concepts\n- Lake Formation granular permissions on per-tenant resources\n- Prefix-based data isolation in S3\n- IAM role mapping per tenant and centralized admin\n- SCPs for cross-account restriction\n- Per-tenant KMS CMKs and Lake Formation audit logs\n\n## Code Example\n\n```yaml\nResources:\n  TenantReadsGrant:\n    Type: AWS::LakeFormation::Grant\n    Properties:\n      DataLakePrincipal:\n        DataLakePrincipalIdentifier: arn:aws:iam::ACCOUNT:role/TenantReader\n      Permissions: [SELECT]\n      Resource:\n        TableResource:\n          DatabaseName: tenant_db\n          TableName: events\n```\n\n## Follow-up Questions\n- How would you test data isolation across tenants? \n- How would you onboard new tenants at scale while preserving least privilege?","diagram":"flowchart TD\n  A[TenantId] --> B[S3: /tenants/{TenantId}/data]\n  B --> C[Lake Formation grants on per-tenant tables]\n  C --> D[Athena/QuickSight]\n  D --> E[Audit logs]","difficulty":"advanced","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Oracle","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T07:33:46.616Z","createdAt":"2026-01-13T07:33:46.616Z"},{"id":"q-1381","question":"A serverless data ingestion pipeline: an S3 PUT triggers a Lambda that transforms JSON logs into CSV and writes to a separate bucket; failed records go to a DLQ. Explain how you implement idempotent writes, choose between DLQ mechanisms (Lambda DLQ vs SQS), and set up minimal monitoring/alerts to catch processing failures?","answer":"Use a stable composite key from source object key and a per-record id, store seen IDs in DynamoDB, and upsert only when not seen to avoid duplicates. Route failures to an SQS DLQ for decoupled retries","explanation":"## Why This Is Asked\nTests practical handling of retries, deduplication, and observability in a common serverless ELT setup. It prompts decision between DLQ patterns and concrete idempotency strategy.\n\n## Key Concepts\n- Idempotent writes with deterministic IDs\n- Dead-letter queues: Lambda DLQ vs SQS DLQ\n- Observability: metrics, alarms, and alerting\n- Minimal tooling: DynamoDB for seen IDs, CloudWatch for alerts\n\n## Code Example\n```javascript\n// Lambda pseudo-code (Node.js)\nconst AWS = require('aws-sdk');\nconst ddb = new AWS.DynamoDB.DocumentClient();\nexports.handler = async (event) => {\n  for (const rec of event.Records) {\n    const body = JSON.parse(rec.body); // or rec.kinesis, etc.\n    const id = `${rec.s3.object.key}:${body.recordId}`;\n    // Idempotency: check or upsert\n    const exists = await ddb.get({TableName:'SeenIds', Key:{id}}).promise();\n    if (exists.Item) continue;\n    await ddb.put({TableName:'SeenIds', Item:{id}}).promise();\n    // transform and write to target bucket\n    // ... write CSV to target bucket\n  }\n  return {status: 'done'};\n};\n```\n\n## Follow-up Questions\n- How would you adapt for out-of-order arrivals?\n- What changes if the per-record id is not available in the source payload?","diagram":"flowchart TD\n  S3(S3 Put Event) --> L(Lambda)\n  L --> D{DLQ}\n  D --> S(Success Bucket)\n  L --> M(Metrics/Alerts)","difficulty":"beginner","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:44:34.734Z","createdAt":"2026-01-13T14:44:34.734Z"},{"id":"q-1436","question":"In a beginner AWS DVA workflow, JSON logs arrive to S3 at s3://data-logs/raw/. Propose a minimal pipeline where a Lambda validates each record against a JSON schema, writes valid records as Parquet to s3://data-logs/processed/YYYY/MM/DD/, and routes invalid ones to a DLQ. Explain idempotent writes, choose between Lambda DLQ vs SQS, and basic monitoring setup?","answer":"Use an S3-triggered Lambda to validate JSONs against a JSON schema. On success, write a Parquet file to s3://data-logs/processed/YYYY/MM/DD/ with a deterministic key (hash of content) for idempotency.","explanation":"## Why This Is Asked\nTests a practical, beginner-friendly approach to a common DVA pattern: simple validation, durable writes, and observability.\n\n## Key Concepts\n- JSON Schema validation\n- Idempotent writes via deterministic object keys\n- DLQ choices: Lambda DLQ vs SQS\n- Observability: CloudWatch metrics and alarms\n\n## Code Example\n```javascript\n// Example Lambda handler sketch validating JSON and routing\n```\n\n## Follow-up Questions\n- How would schema evolution be managed without breaking retrofits?\n- What adjustments for higher ingest rates or partition pruning would you consider?\n","diagram":null,"difficulty":"beginner","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Meta","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T16:57:20.985Z","createdAt":"2026-01-13T16:57:20.985Z"},{"id":"q-1549","question":"Design a secure, scalable cross-account analytics pattern for a multi-tenant data lake. Data for tenants live at /tenants/{tenantId}/ in S3 and must be queryable via Athena/QuickSight with strict isolation. Explain how Lake Formation, per-tenant LF permissions, and cross-account IAM roles control access from a central analytics account. Include encryption (CMKs), cross-account RAM/trust, schema evolution handling, and a testing plan for isolation and governance?","answer":"Implement a Lake Formation-based architecture with per-tenant databases and tables mapped to /tenants/{tenantId}/ S3 locations, accessible through tenant-specific IAM roles assumed from a central analytics account. Enforce strict isolation using Lake Formation fine-grained permissions, cross-account trust relationships, and tenant-specific customer-managed keys.","explanation":"## Why This Is Asked\nThis question evaluates expertise in designing multi-tenant data governance with strict isolation, cross-account analytics, and comprehensive security controls using Lake Formation, CMKs, and Resource Access Manager.\n\n## Key Concepts\n- Lake Formation fine-grained access control and permissions\n- Cross-account IAM roles with trust relationships\n- Customer-managed keys and S3 encryption strategies\n- Schema evolution handling and governance policies\n- Resource Access Manager for cross-account resource sharing\n\n## Code Example\n```javascript\n// Example: IAM trust policy snippet (pseudocode)\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"AWS\": \"arn:aws:iam::CENTRAL:role/AnalyticsRole\"},\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:PrincipalTag/TenantId\": \"${tenantId}\"\n        }\n      }\n    }\n  ]\n}\n```","diagram":"flowchart TD\nA[Tenant Account] -->|Assumes| B[Analytics Role in Central Account]\nB --> C[Lake Formation Permissions]\nC --> D[Athena/QuickSight Access to /tenants/{tenantId}/]\nD --> E[Audit via LF + CloudWatch]","difficulty":"advanced","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Meta","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:02:17.418Z","createdAt":"2026-01-13T21:38:07.194Z"},{"id":"q-1575","question":"In a multi-tenant data platform on AWS, tenants stream JSON events into a single Kinesis Data Stream; you aggregate into per-tenant Parquet files in S3 using Firehose. Design an end-to-end pipeline with idempotence, schema validation, and auditing. Include DLQ handling and isolation via Lake Formation. What are your concrete steps?","answer":"Design an end-to-end multi-tenant pipeline: a single Kinesis Data Stream ingests JSON; a Lambda deduplicates by tenant_id + event_id and writes per-tenant Parquet to S3 with daily partitions; register","explanation":"## Why This Is Asked\nThis question probes practical experience with multi-tenant data pipelines, schema governance, and robust error handling in AWS.\n\n## Key Concepts\n- Kinesis Data Streams, Firehose, S3 parquet partitions\n- Lambda dedup by composite key, idempotent writes\n- Glue Schema Registry, Lake Formation for isolation\n- DLQ strategy and observability\n\n## Code Example\n```python\nimport boto3\nimport time\n\n# Pseudo-idempotent dedup check using a DynamoDB table\ndef is_duplicate(tenant_id, event_id):\n    table = boto3.resource('dynamodb').Table('tenant_event_dedup')\n    try:\n        table.put_item(\n            Item={'tenant_id': tenant_id, 'event_id': event_id, 'ts': int(time.time())},\n            ConditionExpression='attribute_not_exists(tenant_id) AND attribute_not_exists(event_id)'\n        )\n        return False\n    except Exception:\n        return True\n```\n\n## Follow-up Questions\n- How would you validate schema evolution across partitions?\n- How would you monitor cross-tenant access and audit logs?","diagram":"flowchart TD\n  A[Kinesis Stream] --> B[Lambda Dedup & Transform]\n  B --> C[S3 per-tenant Parquet partitions]\n  C --> D[Glue Catalog & Lake Formation]\n  D --> E[Athena/Quicksight/Glue Analytics]","difficulty":"intermediate","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Lyft","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T22:42:59.619Z","createdAt":"2026-01-13T22:42:59.619Z"},{"id":"q-1617","question":"Design a per-tenant data lake access system on AWS where billions of Parquet files in S3 are consumed by Athena/Glue; describe how you would implement tenant isolation, masking, and row-level security using Lake Formation, and how you would validate auditing and performance under burst workloads?","answer":"Implement per-tenant isolation using Lake Formation LF-tags with policy-based grants, expose only non-sensitive columns through masked views, and enforce row-level security filters in Athena queries. Leverage CloudTrail, Lake Formation logs, and CloudWatch for comprehensive auditing, and validate performance through load testing utilizing Athena's query concurrency capabilities and S3 request metrics during burst workloads.","explanation":"## Why This Is Asked\nMulti-tenant data lakes require fine-grained access control, data masking, and robust auditing; this evaluates policy design and operational validation skills.\n\n## Key Concepts\n- Lake Formation LF-tags and permissions for tenant isolation\n- Data masking and restricted views in Athena/Glue\n- Auditing via CloudTrail, Lake Formation logs, and CloudWatch metrics\n- Performance validation under burst workloads\n\n## Code Example\n```sql\n-- Example: masked view for a tenant\nCREATE VIEW tenant_view AS\nSELECT tenant_id,\n       CASE WHEN is_sensitive(col1) THEN 'REDACTED' ELSE col1 END\n```","diagram":"flowchart TD\n  Ingest[Ingest to S3 Parquet] --> Catalog[Glue Catalog & LF Policies]\n  Catalog --> Query[Athena/Redshift Spectrum]\n  Access[Role-based LF perms] --> Query\n  Mask[Masking Views] --> Query\n  Audit[Audit Trails] --> Ingest","difficulty":"intermediate","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","IBM","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:28:49.686Z","createdAt":"2026-01-14T02:43:19.048Z"},{"id":"q-1637","question":"In a beginner AWS DVA ingestion pipeline, a CSV file uploads to s3://data/tenant-{tenantId}/uploads/YYYY/MM/DD/file.csv triggers a Lambda that validates the header has exactly [timestamp, tenant_id, metric], converts to Parquet, and writes to s3://data/tenant-{tenantId}/processed/YYYY/MM/DD/file.parquet; design for idempotent writes (no duplicates), choose a DLQ strategy, and add minimal CloudWatch alarms for failures. How would you implement this end-to-end, and why?","answer":"Trigger via S3 to Lambda; validate header exactly as [timestamp, tenant_id, metric], error otherwise. Convert CSV to Parquet and write to a partitioned path tenantId/date/file.parquet. Ensure idempote","explanation":"## Why This Is Asked\nTests end-to-end data ingestion basics: event triggers, schema validation, format conversion, partitioned storage, idempotency, DLQ choices, and basic observability.\n\n## Key Concepts\n- S3 event triggers and Lambda orchestration\n- CSV header validation against a strict schema\n- CSV to Parquet transformation and partitioned S3 storage\n- Idempotent writes using a dedupe key (e.g., digest) and a dedupe store\n- DLQ choice between Lambda DLQ vs SQS\n- Minimal CloudWatch alarms for errors and throttling\n\n## Code Example\n```javascript\n// Lambda handler sketch\nconst expected = ['timestamp','tenant_id','metric'];\nexports.handler = async (event) => {\n  // parse S3 event, read CSV, validate headers, convert to Parquet, write partitioned path\n  // implement dedupe via DynamoDB using a composite key (tenant/date/fileDigest)\n};\n```\n\n## Follow-up Questions\n- How would you scale for bursty uploads?\n- How would you test idempotency and DLQ behavior locally?","diagram":"flowchart TD\n  S3[Upload] --> Lambda[Trigger Lambda]\n  Lambda --> Validate[Validate header]\n  Validate --> Transform[CSV to Parquet]\n  Transform --> Write[Write to partitioned path]\n  Lambda --> DLQ[DLQ for errors]\n  DLQ --> Alarms[CloudWatch Alarms]","difficulty":"beginner","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","LinkedIn","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:22:55.624Z","createdAt":"2026-01-14T04:22:55.624Z"},{"id":"q-1706","question":"Design a beginner-friendly, end-to-end data quality check for a daily Parquet dataset stored in S3: s3://telemetry/processed/YYYY/MM/DD/. The data is produced by a Glue job from JSON input. Propose a minimal workflow (using Lambda, Glue, or Athena) that validates schema conformance, computes a day-over-day row-count delta, and emits a quality score JSON to s3://telemetry/quality-reports/YYYY/MM/DD/. Include how you would trigger, idempotency, and basic monitoring?","answer":"Leverage a daily Glue ETL to validate schema and output Parquet, plus an Athena-based delta check to compare day-over-day row counts. Emit a quality score JSON to s3://telemetry/quality-reports/YYYY/M","explanation":"## Why This Is Asked\nTests practical ability to design a simple quality pipeline with AWS primitives, focusing on schema validation, drift detection, and observability.\n\n## Key Concepts\n- Glue ETL and Crawlers\n- Parquet partitioning\n- Athena for ad-hoc checks\n- Idempotent checkpoint (DynamoDB)\n- CloudWatch alerts and dashboards\n\n## Code Example\n```javascript\n// Lightweight Lambda skeleton for quality report write\nexports.handler = async () => {\n  // read latest processed parquet manifests from S3\n  // fetch previous day count from DynamoDB\n  // compute delta and schema conformance\n  // write quality JSON to quality-reports path\n};\n```\n\n## Follow-up Questions\n- How would you handle late-arriving data?\n- How would you scale checks for larger datasets?\n","diagram":"flowchart TD\n  A[Ingest JSON] --> B[Glue ETL â†’ Parquet]\n  B --> C[Parquet in s3://telemetry/processed/YYYY/MM/DD]\n  C --> D[Athena checks: schema + row counts]\n  D --> E[Quality report in s3://telemetry/quality-reports/YYYY/MM/DD]\n  E --> F[CloudWatch alerts/ dashboards]","difficulty":"beginner","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Discord","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T07:41:59.302Z","createdAt":"2026-01-14T07:41:59.303Z"},{"id":"q-1772","question":"In a multi-account AWS data lake, ingested data lands in s3://lake/raw from several tenants via Kinesis Firehose into a shared account. Propose an end-to-end DVA pipeline that enforces per-tenant isolation, uses Lake Formation for access control, handles schema evolution with Parquet, and provides tenant-aware lineage and auditing. Include how you test isolation and how you monitor for cross-tenant data leakage?","answer":"Adopt per-tenant IAM roles and Lake Formation permissions mapped to a tenant tag in the data catalog; route raw data into partitioned Parquet under /tenants/{tenant}/year=YYYY/month=MM/day=DD; Glue jo","explanation":"## Why This Is Asked\n\nTests multi-account data-lake governance, tenant isolation, and lineage in a realistic AWS setup.\n\n## Key Concepts\n\n- Lake Formation data permissions per-tenant\n- Cross-account IAM roles and resource-based policies\n- Parquet with partition pruning and schema evolution\n- Data lineage, auditing, and governance\n\n## Code Example\n\n```javascript\n// Placeholder: high-level policy example\n```\n\n## Follow-up Questions\n\n- How would you validate no cross-tenant data leakage in production? \n- How would you swap tenants without downtime during schema changes?\n","diagram":"flowchart TD\n  A[Ingest Stream] --> B[S3 lake/raw]\n  B --> C[Lake Formation grants by tenant]\n  C --> D[Glue Data Catalog /tenants/{tenant}]\n  D --> E[Analytics / Athena / Quicksight]","difficulty":"advanced","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Google","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:35:30.591Z","createdAt":"2026-01-14T10:35:30.591Z"},{"id":"q-674","question":"You're building an AWS DVA data-analytics pipeline ingesting telemetry from 2000 devices/sec via Kinesis Data Streams. A Spark/Glue path processes windows and writes Parquet to S3; aggregation state in DynamoDB. Data loss or duplicates occur during retries and outages; costs spike at peak. Design a resilient, cost-efficient approach: shard sizing, processing path, idempotent writes, error handling with DLQ, and observability. What would you implement and why?","answer":"Scale by configuring 4 Kinesis shards to sustain ~4000 RPS; use a real-time analytics path (Kinesis Data Analytics or Spark) for windowed aggregation, then write Parquet to S3 via Glue streaming. Dedu","explanation":"## Why This Is Asked\n\nAssesses real-world ability to design a resilient streaming analytics pipeline on AWS, balancing throughput, cost, and correctness. Candidates must justify shard sizing, choice of processing path (KDA vs Glue streaming), idempotent writes, error handling, and observability.\n\n## Key Concepts\n\n- Streaming ingestion and scaling\n- Exactly-once semantics with DynamoDB\n- DLQ and backpressure\n- Observability and cost control\n\n## Code Example\n\n```javascript\n// Pseudocode: deduplicate by composite key and conditional writes\n```\n\n## Follow-up Questions\n\n- How would you migrate this to a multi-region setup?\n- How would you test failure modes and simulate burst traffic?","diagram":null,"difficulty":"intermediate","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-11T14:45:55.246Z","createdAt":"2026-01-11T14:45:55.246Z"},{"id":"q-916","question":"In an AWS-based DVA pipeline ingesting telemetry from 2000 devices/sec via Kinesis Data Streams, with a Spark/Glue path writing Parquet to S3 and cataloged in Glue, design an end-to-end strategy for robust schema evolution, data validation, and partitioning that minimizes reprocessing and supports backfills. Include schema registry, idempotence, DLQ, and observability?","answer":"Adopt Glue Schema Registry with versioned Avro schemas; Spark Structured Streaming validates records against the latest compatible schema and writes Parquet to S3 partitioned by device/hour. Route inc","explanation":"## Why This Is Asked\nThe question probes practical UX for evolving data schemas in streaming pipelines, ensuring data quality and low reprocessing costs during changes.\n\n## Key Concepts\n- Glue Schema Registry and versioning\n- Schema compatibility strategies (backward/forward)\n- Spark Structured Streaming validation and checkpointing\n- Idempotent writes and deduplication stores\n- DLQ routing and backfill procedures\n- Observability with CloudWatch and Glue metrics\n\n## Code Example\n```javascript\n// Spark reads latest compatible Avro schema from Glue, writes Parquet partitioned by device/hour\ndf.write\n  .partitionBy(\"device_id\", \"hour\")\n  .format(\"parquet\").save(\"s3://bucket/data/\");\n```\n\n## Follow-up Questions\n- How would you handle backward-incompatible schema changes without downtime?\n- What metrics signal schema drift or data quality issues?","diagram":null,"difficulty":"intermediate","tags":["aws-dva"],"channel":"aws-dva","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T15:29:41.744Z","createdAt":"2026-01-12T15:29:41.744Z"}],"subChannels":["general"],"companies":["Adobe","Amazon","Discord","DoorDash","Goldman Sachs","Google","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","OpenAI","Oracle","Robinhood","Salesforce","Slack","Snap","Snowflake","Tesla"],"stats":{"total":12,"beginner":4,"intermediate":4,"advanced":4,"newThisWeek":12}}