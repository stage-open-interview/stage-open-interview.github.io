{"questions":[{"id":"gcp-data-engineer-design-data-systems-1768195992962-0","question":"Your real-time analytics pipeline ingests events from Pub/Sub, processes them with a Dataflow streaming job, and writes per-event metrics to BigQuery for near real-time dashboards. You must guarantee exactly-once processing to avoid duplicate metrics due to retries. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Use Dataflow with Pub/Sub and write to BigQuery using streaming inserts without any deduplication handling\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Dataflow streaming with an insertId per row derived from the event's unique id to enable idempotent writes in BigQuery\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Pub/Sub with a Cloud Function that writes to BigQuery with insertId; duplicates may occur\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a batch pipeline that reads Pub/Sub via pull subscriptions and writes to BigQuery in batch mode\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct because deriving a unique insertId for each event ensures idempotent streaming writes to BigQuery. If the Dataflow worker retries a failed write, BigQuery uses the insertId to deduplicate and avoid duplicates. The other options either rely on non-idempotent streaming writes (a), rely on a non-deduplicating path (c), or abandon streaming guarantees by using batch processing (d).\n\n## Why Other Options Are Wrong\n- Option A: Streaming inserts without deduplication cannot guarantee exactly-once semantics when retries occur.\n- Option C: Cloud Functions can produce duplicates on retries unless you implement idempotency manually, which is error-prone at scale.\n- Option D: Batch processing cannot provide real-time or near-real-time semantics and misses the exactly-once guarantees in a streaming context.\n\n## Key Concepts\n- Exactly-once semantics in streaming pipelines\n- Idempotent writes with insertId for BigQuery streaming inserts\n- Dataflow and Pub/Sub integration for real-time analytics\n\n## Real-World Application\n- Used in production to ensure metrics dashboards reflect unique events even under retry scenarios, preventing inflated counts or duplicates.","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Dataflow","Pub/Sub","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:12.964Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-design-data-systems-1768195992962-1","question":"A Dataflow job consumes clickstream data from Pub/Sub and computes per-minute aggregates. Some events arrive late by up to 20 minutes. To include late data without delaying current window results, which pattern should you implement?","answer":"[{\"id\":\"a\",\"text\":\"Enable allowed lateness of 20 minutes and use appropriate triggers to emit results after window end\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Switch to a batch job that reprocesses the previous day’s data every night\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Discard late data to maintain the lowest latency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Run a separate corrective streaming job that reprocesses the late data after it arrives\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because allowing lateness (e.g., 20 minutes) and configuring triggers (such as AfterWatermark or AfterProcessingTime) enables the pipeline to include late events in the appropriate windows without waiting for the next day. \n\n## Why Other Options Are Wrong\n- Option B: Batch reprocessing introduces higher latency and does not handle real-time late data in current windows.\n- Option C: Dropping late data sacrifices data completeness and analytics accuracy.\n- Option D: A separate corrective job adds complexity and potential drift; handling lateness within the streaming window is more robust.\n\n## Key Concepts\n- Event-time processing in streaming pipelines\n- Allowed lateness and windowing triggers in Beam/Dataflow\n- Balancing latency and data completeness\n\n## Real-World Application\n- Enables accurate near-real-time dashboards even when some events arrive late due to network or device issues.","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:13.472Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-design-data-systems-1768195992962-2","question":"IoT telemetry daily volume reaches around 10 TB/day. You want long-term storage that keeps costs reasonable and enables fast ad-hoc analytics. Which BigQuery table design best supports time-series analysis at scale?","answer":"[{\"id\":\"a\",\"text\":\"Store in a single wide, non-partitioned BigQuery table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Partition the table by ingestion_date and cluster on device_id, ideally using ingestion-time partitioning\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store as a nested JSON string in a single column and parse at query time\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Bigtable for analytics instead of BigQuery\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct because partitioning by date and clustering on device_id improves query performance and cost efficiency for high-volume time-series analytics. Ingestion-time partitioning helps automate partitioning for streaming loads. \n\n## Why Other Options Are Wrong\n- Option A: Non-partitioned tables incur higher scan costs and slower queries on large datasets.\n- Option C: Storing JSON strings requires parsing at query time, increasing latency and cost; nested/structured columns in BigQuery are preferred.\n- Option D: Cloud Bigtable is optimized for wide-column NoSQL workloads, not ad-hoc analytics; BigQuery is typically better for analytics workloads at scale.\n\n## Key Concepts\n- Time-series data modeling in BigQuery\n- Ingestion-time partitioning and clustering for performance/cost\n- Analytical workloads vs NoSQL storage trade-offs\n\n## Real-World Application\n- Enables fast, cost-effective analytics on high-volume IoT telemetry with scalable querying and efficient data management.","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Dataflow","Pub/Sub","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:13.829Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-design-data-systems-1768267718835-0","question":"You are designing a streaming ETL pipeline ingesting from Pub/Sub, performing windowed aggregations, and writing to BigQuery in near real time. Which pattern and service combination is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Dataflow (Apache Beam) streaming pipeline with windowing and BigQueryIO\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Dataproc cluster running Spark Structured Streaming consuming Pub/Sub and writing to BigQuery\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cloud Functions triggered by Pub/Sub writing to BigQuery per event\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Composer orchestration running separate batch and streaming jobs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Dataflow (Apache Beam) streaming pipeline with windowing and BigQueryIO.\n\n## Why Other Options Are Wrong\n- B: Dataproc with Spark Streaming can handle Pub/Sub but is less suited for managed, autoscaling streaming pipelines at scale and often requires more operational overhead.\n- C: Cloud Functions are event-driven but not ideal for high-throughput, windowed aggregations and long-running stateful processing.\n- D: Cloud Composer orchestrates jobs but does not perform the actual streaming processing or windowed analytics.\n\n## Key Concepts\n- Streaming processing with event-time windowing\n- Watermarks and allowed lateness\n- Managed pipelines vs. DIY clusters\n\n## Real-World Application\n- Use Dataflow to implement real-time dashboards with late data handling and seamless Pub/Sub integration in production.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Pub/Sub","Kubernetes","Terraform","AWS","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:28:38.836Z","createdAt":"2026-01-13 01:28:39"},{"id":"gcp-data-engineer-design-data-systems-1768267718835-1","question":"In a streaming pipeline from Pub/Sub to BigQuery, how do you minimize duplicates given at-least-once delivery semantics?","answer":"[{\"id\":\"a\",\"text\":\"Use an insertId for each row and rely on BigQuery to deduplicate duplicates\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Implement a manual in-pipeline deduplication step in Dataflow\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on BigQuery streaming inserts to automatically deduplicate without insertId\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Batch the data via Cloud Storage and load daily with WRITE_TRUNCATE\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Use an insertId for each row and rely on BigQuery to deduplicate duplicates.\n\n## Why Other Options Are Wrong\n- B: A manual in-pipeline deduplication step increases complexity and latency; insertId-based dedup is the standard, scalable approach.\n- C: BigQuery streaming inserts do not guarantee zero duplicates without a proper dedup key like insertId.\n- D: Batch loads add latency and are not suitable for real-time streaming goals; dedup is best handled at ingestion time.\n\n## Key Concepts\n- Exactly-once vs at-least-once delivery semantics\n- InsertId as a deduplication key in BigQuery streaming\n- Idempotent writes in streaming pipelines\n\n## Real-World Application\n- Implement id-based deduplication to ensure reliable counts in real-time dashboards without overcount.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Dataflow","Pub/Sub","Kubernetes","Terraform","AWS","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:28:39.472Z","createdAt":"2026-01-13 01:28:39"},{"id":"gcp-data-engineer-design-data-systems-1768267718835-2","question":"You are designing a batch-to-Cloud data pipeline that ingests daily delta files from GCS into a partitioned BigQuery table. To make reprocessing idempotent, which loading approach is most robust?","answer":"[{\"id\":\"a\",\"text\":\"Load into a staging table and MERGE into the destination using a primary key\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Load directly into the destination with WRITE_APPEND and rely on downstream de-dup later\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use WRITE_TRUNCATE on the destination partition for each daily load\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Load into a single global table and rely on time-based partitioning for dedup\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Load into a staging table and MERGE into the destination using a primary key.\n\n## Why Other Options Are Wrong\n- B: APPEND can duplicate data if reprocessing occurs; a MERGE against a staging area ensures deduplication by primary key.\n- C: WRITE_TRUNCATE per partition is effective for that partition but can be brittle if reprocessing involves multiple partitions or late data; MERGE is more robust for full idempotency.\n- D: A single global table with partitioning can complicate dedup logic and increase risk of overlaps between reprocessed days.\n\n## Key Concepts\n- Idempotent loading patterns\n- Staging + MERGE strategy for dedup\n- Primary key-based dedup in BigQuery\n\n## Real-World Application\n- When reprocessing daily deltas, MERGE-based pipelines prevent duplicate rows across repeated loads.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","CloudStorage","Dataflow","Terraform","AWS","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:28:39.960Z","createdAt":"2026-01-13 01:28:40"},{"id":"gcp-data-engineer-design-data-systems-1768267718835-3","question":"To handle late data up to 4 hours after event time in a streaming windowed pipeline, which configuration is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Set allowed lateness to 4 hours and enable late data triggers for aggregations\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use fixed windows without lateness and drop late events\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use a global window with unbounded delay and no triggers\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable watermarking to ensure all data arrives before processing\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Set allowed lateness to 4 hours and enable late data triggers for aggregations.\n\n## Why Other Options Are Wrong\n- B: Dropping late data defeats the scenario requiring late-arriving events.\n- C: Global windows with unbounded delay are not practical for timely insights and waste resources.\n- D: Disabling watermarking undermines event-time processing guarantees and stability.\n\n## Key Concepts\n- Allowed lateness in windowing\n- Late data handling in streaming pipelines\n- Event-time vs processing-time semantics\n\n## Real-World Application\n- Ensures near-real-time dashboards still reflect late-arriving events up to 4 hours after the event time.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Pub/Sub","Kubernetes","Terraform","AWS","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:28:40.115Z","createdAt":"2026-01-13 01:28:40"},{"id":"gcp-data-engineer-design-data-systems-1768267718835-4","question":"You have multi-region producers publishing to Pub/Sub and a regional BigQuery dataset for analytics. To minimize cross-region egress and latency, what pattern is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Deploy Dataflow workers in the same region as the data sources and target the regional BigQuery dataset\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Publish to a single global Pub/Sub topic and write to a single BigQuery dataset located in us-central1\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Run a Dataproc cluster in each region and periodically merge results into BigQuery\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Run in multiple regions behind a global load balancer to write directly to regional BigQuery datasets\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. Deploy Dataflow workers in the same region as the data sources and target the regional BigQuery dataset.\n\n## Why Other Options Are Wrong\n- B: Cross-region egress from multiple regions to a single BigQuery region increases latency and egress costs; regional processing is better.\n- C: Multi-region Dataproc plus merge introduces more latency and operational overhead than a region-aligned Dataflow pattern.\n- D: Cloud Run writes directly to BigQuery can work, but it complicates multi-region consistency and is not as optimized for large-scale streaming pipelines as Dataflow in the same region.\n\n## Key Concepts\n- Data locality and egress costs\n- Regional processing patterns\n- Dataflow regionalization and BigQuery regional datasets\n\n## Real-World Application\n- Align data processing with data locality to reduce latency and avoid expensive cross-region data transfer.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Pub/Sub","Kubernetes","Terraform","AWS","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:28:40.273Z","createdAt":"2026-01-13 01:28:40"},{"id":"q-1222","question":"Design a real-time ad-click analytics pipeline in GCP that ingests Pub/Sub events via Dataflow into BigQuery, while implementing 90-day TTL on PII data, exporting audits to Cloud Storage, and handling schema evolution, late data, dedup, and rollback. Provide concrete architecture, data models, and operational steps?","answer":"Two-tier streaming: a BigQuery hot table partitioned by ingestion_date with 90-day partition expiration for PII, plus a daily Cloud Storage Parquet archive for audits. Dataflow templates ingest Pub/Su","explanation":"## Why This Is Asked\nEvaluates real-world trade-offs in latency, cost, and governance for streaming pipelines on GCP.\n\n## Key Concepts\n- Pub/Sub -> Dataflow streaming\n- BigQuery partition expiration (90 days)\n- Parquet archive in Cloud Storage\n- Schema evolution with nested fields\n- Deduplication and late data handling\n- Rollback/versioned templates\n\n## Code Example\n```javascript\n// Pseudo Beam skeleton: dedupe by event_id and write to two sinks\n```\n\n## Follow-up Questions\n- How to validate TTL and archiving with tests?\n- What monitoring and alerting would you add for duty-cycle failures?","diagram":"flowchart TD\n  PubSub[Pub/Sub] --> Dataflow[Dataflow Template]\n  Dataflow --> BigQueryHot[BigQuery: Ingest (90d TTL)]\n  Dataflow --> Archive[Cloud Storage: Parquet Archive]\n  BigQueryHot --> Monitoring[Monitoring & Audits]","difficulty":"intermediate","tags":["gcp-data-engineer"],"channel":"gcp-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","NVIDIA","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T05:33:44.453Z","createdAt":"2026-01-13T05:33:44.453Z"},{"id":"q-931","question":"A GCP pipeline ingests 1 TB of JSON user activity daily from Pub/Sub into BigQuery via Dataflow. New fields appear over time; you must evolve the schema without downtime. What approach would you use for schema drift and nested fields, and outline concrete steps to implement it?","answer":"Use a two-layer scheme: a stable BigQuery table with known fields and a separate extra_json column to capture drift. The Dataflow job maps incoming JSON to the known schema; unknown fields are stored ","explanation":"## Why This Is Asked\nThis question probes practical handling of evolving data in a streaming pipeline, balancing query stability with schema growth.\n\n## Key Concepts\n- Schema evolution in BigQuery\n- Semi-structured data (JSON)\n- Dataflow transforms for parsing\n- Backward compatibility\n- Metadata and cataloging\n\n## Code Example\n```javascript\nfunction parseEvent(json) {\n  const data = JSON.parse(json);\n  const known = {\n    userId: data.user_id || null,\n    eventTime: data.event_time || null,\n    country: data.country || null\n  };\n  const extraKeys = Object.keys(data).filter(k => !(k in known));\n  const extra = JSON.stringify(extraKeys.reduce((acc, k) => { acc[k] = data[k]; return acc; }, {}));\n  return { ...known, extra_json: extra };\n}\n```\n\n## Follow-up Questions\n- How would you migrate existing data to the new table version with minimal downtime?\n- How would you monitor for schema drift and alert when new fields appear?","diagram":null,"difficulty":"beginner","tags":["gcp-data-engineer"],"channel":"gcp-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Discord","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:41:21.360Z","createdAt":"2026-01-12T15:41:21.361Z"},{"id":"q-962","question":"In a GCP streaming pipeline, Pub/Sub feeds millions of events into BigQuery via Dataflow. Out-of-order arrivals and duplicates occur. Design an idempotent sink using a staging table and a final partitioned table, leveraging insertId for dedup and a MERGE strategy to upsert into the final table. Outline concrete steps and trade-offs to implement?","answer":"Use a staging BigQuery table where Dataflow writes with insertId derived from a stable key (user_id + event_id + event_time). Periodically MERGE from staging into a final partitioned table, deduplicat","explanation":"## Why This Is Asked\n\nTests practical data quality, idempotent sinks, and operational design using Dataflow + BigQuery features.\n\n## Key Concepts\n\n- Idempotent sink\n- insertId dedup\n- staging vs final table\n- MERGE in BigQuery\n- allowed lateness and partitioning\n- quotas and monitoring\n\n## Code Example\n\n```sql\nMERGE INTO dataset.final AS F\nUSING dataset.staging AS S\nON F.user_id = S.user_id AND F.event_time = S.event_time\nWHEN NOT MATCHED THEN INSERT (user_id, event_time, event_id, action, payload)\nWHEN MATCHED THEN UPDATE SET action = S.action, payload = S.payload;\n```\n\n## Follow-up Questions\n\n- How to handle tombstones?\n- How to scale MERGE with sharded partitions?\n- How would you instrument observability for dedup latency?","diagram":"flowchart TD\n  PubSub[Pub/Sub] --> Dataflow[Dataflow]\n  Dataflow --> Staging[StagingBQ]\n  Staging --> Final[FinalBQ]\n  Staging -->|MERGE| Final","difficulty":"intermediate","tags":["gcp-data-engineer"],"channel":"gcp-data-engineer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:23:31.180Z","createdAt":"2026-01-12T17:23:31.180Z"},{"id":"gcp-data-engineer-ingest-process-1768158927214-0","question":"Which architecture best achieves reliable, deduplicated, near-real-time writes from Pub/Sub to BigQuery while tolerating late data?","answer":"[{\"id\":\"a\",\"text\":\"Ingest events to Cloud Storage and perform batch loads from Cloud Storage to BigQuery every 5 minutes.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Publish events to Pub/Sub, process with Dataflow using per-key windows and insertId-based dedup, then write to BigQuery via streaming inserts.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Publish events directly to BigQuery streaming inserts from client applications.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Functions to buffer events in memory and periodically write to BigQuery.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Pub/Sub provides real-time ingestion, Dataflow enables per-key windowing and deduplication, and BigQuery streaming inserts support near-real-time writes alongside insertId-based dedup to minimize duplicates.\n\n## Why Other Options Are Wrong\n- Option A trades real-time visibility for batch latency and adds buffering complexity, delaying insight.\n- Option C cannot guarantee idempotent writes and raises risks of duplicates due to retries.\n- Option D relies on in-memory buffering which is unsafe for reliability and scaling and can lead to data loss on restarts.\n\n## Key Concepts\n- Streaming ingestion with Pub/Sub\n- Dataflow windowing and per-key processing\n- Deduplication with insertId in BigQuery streaming inserts\n- Handling late data via watermarking and windowing\n\n## Real-World Application\nUsed for real-time dashboards and anomaly detection where timely, deduplicated insights are critical.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:27.215Z","createdAt":"2026-01-11 19:15:27"},{"id":"gcp-data-engineer-ingest-process-1768158927214-1","question":"You're ingesting JSON sensors data with evolving schema into BigQuery. Which approach minimizes downtime and automatically updates the BigQuery table schema as new fields appear?","answer":"[{\"id\":\"a\",\"text\":\"Use BigQuery load jobs with auto-detect on every file and replace the table.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Implement a Dataflow pipeline with BigQueryIO and enable schema update options to ALLOW_FIELD_ADDITION.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a scheduled Cloud Storage-to-BigQuery Transfer with auto-detect.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Write to a new BigQuery table each day and merge manually.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Dataflow's BigQueryIO supports dynamic schema updates (e.g., ALLOW_FIELD_ADDITION), enabling automatic schema evolution as new fields appear in incoming JSON data, with minimal downtime.\n\n## Why Other Options Are Wrong\n- Option A can lead to table recreation or downtime and does not reliably handle ongoing schema evolution in streaming contexts.\n- Option C does not provide automated, reliable schema evolution for evolving JSON data in a streaming/batch mix.\n- Option D introduces unnecessary complexity and potential data fragmentation; merging would require custom tooling.\n\n## Key Concepts\n- BigQueryIO schema update options (ALLOW_FIELD_ADDITION)\n- Dynamic schema evolution in streaming pipelines\n- Dataflow as a flexible ingestion path for evolving schemas\n\n## Real-World Application\nCommon when IoT/wearable sensors introduce new fields over time, needing seamless table evolution without downtime.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:27.757Z","createdAt":"2026-01-11 19:15:28"},{"id":"gcp-data-engineer-ingest-process-1768158927214-2","question":"You need per-user event counts in 15-minute windows, with events potentially arriving late up to 10 minutes. Which Dataflow windowing/triggers setup is appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Use 15-minute fixed windows with no lateness.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use 15-minute fixed windows with allowed lateness 10 minutes and default trigger.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use 15-minute sliding windows with a 10-minute lag.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a global window with incremental accumulation.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because 15-minute fixed windows with allowed lateness of 10 minutes ensure late events are included up to the stated tolerance, while the default trigger finalizes the window after the lateness period.\n\n## Why Other Options Are Wrong\n- Option A drops late data, reducing correctness and insight.\n- Option C uses sliding windows which would create overlapping windows and complexity without necessity for per-15-minute aggregation.\n- Option D with a global window prevents per-interval aggregation and late data handling.\n\n## Key Concepts\n- Windowing and fixed windows\n- Allowed lateness and watermark behavior\n- Triggers and late data handling\n\n## Real-World Application\nUseful for dashboards showing per-user activity over recent intervals where data can arrive late due to network delays.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:28.234Z","createdAt":"2026-01-11 19:15:28"},{"id":"gcp-data-engineer-ingest-process-1768289188413-0","question":"Ingesting streaming data from a Pub/Sub topic to BigQuery for near real-time analytics, with per-minute aggregates, which architecture best balances scalability and fault tolerance?","answer":"[{\"id\":\"a\",\"text\":\"Cloud Functions triggered by Pub/Sub to append rows to BigQuery\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Dataflow streaming pipeline reading Pub/Sub and writing to BigQuery\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Cloud Run service polling Pub/Sub and writing to BigQuery\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Data Fusion in batch mode reading Pub/Sub\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct answer is option b. Dataflow streaming pipelines are designed for high-throughput, fault-tolerant ingestion from Pub/Sub and can efficiently perform windowed aggregations before writing to BigQuery.\n\n## Why Other Options Are Wrong\n\n- Option A: Cloud Functions may not scale to very high-throughput streaming workloads and can struggle with backpressure.\n- Option C: Cloud Run can scale but is not optimized for continuous streaming pipelines and may introduce processing delays under heavy load.\n- Option D: Data Fusion in batch mode does not provide the low-latency characteristics required for real-time analytics.\n\n## Key Concepts\n\n- Dataflow streaming pipelines\n- Pub/Sub as a streaming source\n- BigQuery as a sink\n- Windowed aggregation and fault tolerance\n\n## Real-World Application\n\n- Used for real-time dashboards, anomaly detection, and operational analytics where latency requirements prohibit batch-only processing.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","AWS S3","Dataflow","BigQuery","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:28.414Z","createdAt":"2026-01-13 07:26:28"},{"id":"gcp-data-engineer-ingest-process-1768289188413-1","question":"You have 1 TB daily of CSV logs stored in Cloud Storage. You want to parse, normalize, convert to Parquet, and store back in Cloud Storage for downstream BI tooling. Which approach is most scalable and maintainable?","answer":"[{\"id\":\"a\",\"text\":\"Dataproc cluster running Spark to read CSV and write Parquet\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Dataflow batch pipeline to read CSV from GCS, convert to Parquet, and write Parquet back to GCS\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"BigQuery load job to load CSV directly into a table without Parquet\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Functions to parse CSV lines and write to Parquet files in GCS\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct answer is option b. Dataflow batch pipelines efficiently handle large-scale file transforms, can output Parquet for optimized storage, and integrate smoothly with Cloud Storage for downstream BI tools.\n\n## Why Other Options Are Wrong\n\n- Option A: Dataproc/Spark can handle this workload but requires managing a cluster and may be less cost-efficient for this use case compared to a managed Dataflow batch job.\n- Option C: Loading CSV directly into BigQuery is viable but bypasses Parquet advantages (columnar storage, cost efficiency) for long-term storage and downstream tooling.\n- Option D: Cloud Functions are not suitable for processing multi-terabyte batches due to runtime limits and orchestration overhead.\n\n## Key Concepts\n\n- Dataflow batch processing\n- Schema normalization and Parquet output\n- Cloud Storage integration\n- Cost-efficient, columnar storage for analytics\n\n## Real-World Application\n\n- Ideal when building a scalable data lake where raw CSV landings are transformed into optimized Parquet files for lakehouse-style analytics.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","AWS S3","Dataflow","BigQuery","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:28.947Z","createdAt":"2026-01-13 07:26:29"},{"id":"gcp-data-engineer-ingest-process-1768289188413-2","question":"A streaming pipeline ingests JSON events from Pub/Sub that may be delivered more than once. To ensure idempotent ingestion into BigQuery, which approach is most reliable?","answer":"[{\"id\":\"a\",\"text\":\"Use a composite key in BigQuery as a primary key to enforce uniqueness\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Add an insertId for BigQuery streaming inserts to enable deduplication\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Enable Pub/Sub at-most-once delivery to prevent duplicates\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use an external idempotent sink like Spanner before BigQuery\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct answer is option b. Providing an insertId with BigQuery streaming inserts allows BigQuery to deduplicate based on the id, helping prevent duplicate rows from multi-delivery Pub/Sub.\n\n## Why Other Options Are Wrong\n\n- Option A: BigQuery does not enforce primary keys; there is no true PK constraint to prevent duplicates.\n- Option C: Pub/Sub is inherently at-least-once; you cannot rely on at-most-once delivery to eliminate duplicates.\n- Option D: Introducing Spanner would add unnecessary complexity and latency for a BigQuery ingestion path.\n\n## Key Concepts\n\n- Pub/Sub delivery semantics\n- BigQuery streaming inserts and insertId\n- Idempotent ingestion patterns\n\n## Real-World Application\n\n- Useful when streaming telemetry or logs where duplicate messages could otherwise corrupt analytics unless deduplicated at ingestion.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","AWS S3","Dataflow","BigQuery","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:29.454Z","createdAt":"2026-01-13 07:26:29"},{"id":"gcp-data-engineer-ingest-process-1768289188413-3","question":"In a Dataflow streaming pipeline, you need to accommodate late-arriving data within a one-hour window and trigger results at the end of each window. Which configuration achieves this behavior?","answer":"[{\"id\":\"a\",\"text\":\"Use FixedWindows with default triggers (no lateness)\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use FixedWindows with allowedLateness of 1 hour and AfterWatermark triggers\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use GlobalWindow with default triggers\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Pub/Sub delivery options to control lateness\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct answer is option b. FixedWindows with allowedLateness enables late data to be included within the specified lateness window, and AfterWatermark triggers ensure results are emitted when the window closes.\n\n## Why Other Options Are Wrong\n\n- Option A: No lateness means late data is ignored after the watermark passes.\n- Option C: GlobalWindow does not provide per-window aggregation with a defined end.\n- Option D: Pub/Sub delivery does not control windowing or lateness semantics in Dataflow.\n\n## Key Concepts\n\n- Windowing strategies in Dataflow\n- Allowed lateness and AfterWatermark triggers\n- Late data handling in streaming analytics\n\n## Real-World Application\n\n- Critical for scenarios like sensor data where late-arriving measurements must still be incorporated into near-real-time dashboards.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","AWS S3","Dataflow","BigQuery","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:29.635Z","createdAt":"2026-01-13 07:26:29"},{"id":"gcp-data-engineer-ingest-process-1768289188413-4","question":"IoT telemetry is ingested via Pub/Sub and must be stored in a partitioned BigQuery table by event_date and device_id, while supporting schema evolution. Which pattern best achieves this in a scalable, maintainable way?","answer":"[{\"id\":\"a\",\"text\":\"Cloud Functions writing to a non-partitioned BigQuery table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Dataflow streaming pipeline parsing JSON, computing event_date, and writing to a partitioned BigQuery table by event_date with device_id as a column\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Dataflow batch pipeline writing to a single non-partitioned table\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Data Fusion writing to Cloud SQL\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct answer is option b. A Dataflow streaming pipeline can parse JSON, derive event_date, and write to a partitioned BigQuery table (partitioned by event_date) while keeping fields like device_id as regular columns; this supports scale and schema evolution.\n\n## Why Other Options Are Wrong\n\n- Option A: Writing to a non-partitioned table limits query performance and partition pruning benefits.\n- Option C: Batch processing is not suitable for real-time IoT streams and may introduce latency.\n- Option D: Cloud SQL is not ideal for high-volume analytical workloads or schema evolution in analytics pipelines.\n\n## Key Concepts\n\n- Dataflow streaming with partitioned BigQuery tables\n- Event_date derivation and partition pruning\n- Schema evolution in BigQuery\n\n## Real-World Application\n\n- Common pattern for real-time IoT dashboards and analytics where data should be partitioned by date and device.\n","diagram":null,"difficulty":"intermediate","tags":["Terraform","Kubernetes","AWS S3","Dataflow","BigQuery","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:26:29.816Z","createdAt":"2026-01-13 07:26:29"},{"id":"gcp-data-engineer-maintain-automate-1768242952374-0","question":"A streaming ingestion pipeline writes records to BigQuery via Cloud Dataflow. After transient errors, the pipeline retries, causing duplicate rows in BigQuery. Which approach best guarantees idempotent writes at ingestion time without changing business logic?","answer":"[{\"id\":\"a\",\"text\":\"Configure BigQuery streaming inserts to use a per-row insertId so duplicates are ignored\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Implement a separate deduplication stage in a batch job that filters duplicates after write\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Disable retry on the Dataflow worker to avoid duplicates\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Pub/Sub exactly-once delivery to consumers\",\"isCorrect\":false}]","explanation":"Correct Answer: a) Using per-row insertId with BigQuery streaming inserts enables BigQuery to deduplicate on ingest, making retries harmless to data integrity. Why the others are wrong: b) Deduplicating after write adds latency and requires extra processing; it’s not ingestion-time idempotence. c) Turning off retries does not guarantee no duplicates and can lead to data loss; idempotence is still not ensured. d) Pub/Sub does not guarantee exactly-once delivery for downstream systems, and even with dedup, the downstream sink must implement idempotence.","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Cloud Composer","Kubernetes","Terraform","AWS-Kinesis","certification-mcq","domain-weight-18"],"channel":"gcp-data-engineer","subChannel":"maintain-automate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:35:52.375Z","createdAt":"2026-01-12 18:35:52"},{"id":"gcp-data-engineer-maintain-automate-1768242952374-1","question":"You manage several data pipelines across projects and need reliable scheduling, retries, and dependencies with code-as-configuration. Which GCP service is the best-fit for orchestrating these pipelines?","answer":"[{\"id\":\"a\",\"text\":\"Cloud Composer\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Dataflow templates\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Cloud Functions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Run\",\"isCorrect\":false}]","explanation":"Correct Answer: a) Cloud Composer (Airflow) excels at orchestrating multiple pipelines with rich dependency graphs, retries, and code-managed workflows. Why the others are wrong: b) Dataflow templates are for standardizing data processing jobs, not orchestration of multiple dependent pipelines. c) Cloud Functions are event-driven and not ideal for multi-pipeline DAG orchestration. d) Cloud Run runs containers and is not designed for DAG-based workflow orchestration.","diagram":null,"difficulty":"intermediate","tags":["GCP","Cloud Composer","Dataflow","BigQuery","Kubernetes","Terraform","AWS-Kinesis","certification-mcq","domain-weight-18"],"channel":"gcp-data-engineer","subChannel":"maintain-automate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:35:52.886Z","createdAt":"2026-01-12 18:35:53"},{"id":"gcp-data-engineer-maintain-automate-1768242952374-2","question":"You want to archive cold data from BigQuery to Cloud Storage to reduce costs while preserving historical data for audits. Which approach best achieves this with minimal operational overhead?","answer":"[{\"id\":\"a\",\"text\":\"Schedule a daily export of entire tables to Cloud Storage and disable queries\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable automatic table expiration to remove data without exporting\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Schedule exports of partitions older than retention to Cloud Storage and set partition expiration to remove from BigQuery\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Move data via Data Transfer Service on a recurring basis\",\"isCorrect\":false}]","explanation":"Correct Answer: c) Exporting only partitions older than retention to Cloud Storage and setting partition expiration in BigQuery achieves archival while maintaining accessibility to historical data, with minimal manual intervention. Why the others are wrong: a) Exporting entire tables is costly and unnecessary; b) Partition expiration alone deletes data but doesn’t archive it; d) Data Transfer Service isn’t designed for archival of BigQuery partitions and lacks fine-grained lifecycle controls.","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Cloud Storage","Dataflow","Kubernetes","Terraform","AWS-Kinesis","certification-mcq","domain-weight-18"],"channel":"gcp-data-engineer","subChannel":"maintain-automate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:35:53.375Z","createdAt":"2026-01-12 18:35:53"},{"id":"gcp-data-engineer-maintain-automate-1768242952374-3","question":"You run nightly batch jobs orchestrated by Airflow in Cloud Composer. A task often fails near the end; you want automatic retries that resume from the failed task rather than re-running the entire DAG. Which mechanism supports this best?","answer":"[{\"id\":\"a\",\"text\":\"Airflow task retries with retry_delay and depends_on_past\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Dataflow's automatic rewind to last checkpoint\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Manually triggering a rerun from the DAG editor\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Pub/Sub dead-letter retries\",\"isCorrect\":false}]","explanation":"Correct Answer: a) Airflow supports per-task retries with retry_delay, allowing the DAG to resume from the failed task and avoid re-running successful earlier tasks. Why the others are wrong: b) Dataflow rewinds are pipeline-internal and not DAG-level; c) Manual reruns are not automatic; d) DLQ retries do not apply to the entire workflow control flow.","diagram":null,"difficulty":"intermediate","tags":["GCP","Cloud Composer","Airflow","Dataflow","Kubernetes","Terraform","AWS-Kinesis","certification-mcq","domain-weight-18"],"channel":"gcp-data-engineer","subChannel":"maintain-automate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:35:53.534Z","createdAt":"2026-01-12 18:35:53"},{"id":"gcp-data-engineer-maintain-automate-1768242952374-4","question":"Your data platform spans multiple GCP projects and you need to enforce least-privilege access for ETL jobs while enabling cross-project data sharing. Which practice provides the strongest security posture with minimal operational burden?","answer":"[{\"id\":\"a\",\"text\":\"Create a dedicated service account per project with only the IAM roles needed by ETL jobs, and share datasets via authorized views when cross-project access is required\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Grant a single elevated admin role to all ETL users for simplicity\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Rely on broad VPC firewall rules instead of IAM controls\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Disable IAM and rely on encryption at rest alone\",\"isCorrect\":false}]","explanation":"Correct Answer: a) Using dedicated service accounts with least privilege and controlled dataset sharing (e.g., authorized views) provides strong security with clear boundaries and minimal risk. Why the others are wrong: b) Grants broad admin rights; c) Network controls cannot substitute proper IAM least privilege; d) Encryption alone does not provide access control, and IAM is required for least privilege.","diagram":null,"difficulty":"intermediate","tags":["GCP","IAM","BigQuery","Cloud Storage","Kubernetes","Terraform","AWS-Kinesis","certification-mcq","domain-weight-18"],"channel":"gcp-data-engineer","subChannel":"maintain-automate","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:35:53.697Z","createdAt":"2026-01-12 18:35:53"},{"id":"gcp-data-engineer-prepare-use-1768252962939-0","question":"You are building a near-real-time analytics platform for e-commerce events. You have events sent to Pub/Sub and need them ingested into BigQuery with low latency and minimal duplicates. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Build a Dataflow streaming pipeline that reads from Pub/Sub and writes to BigQuery using insertId-based deduplication.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Write a batch job that periodically reads Pub/Sub messages stored in Cloud Storage and loads to BigQuery.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Configure Pub/Sub to push directly to BigQuery as a sink.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a Cloud Function to write each Pub/Sub message to BigQuery synchronously.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA Dataflow streaming pipeline reads Pub/Sub and writes to BigQuery using insertId-based deduplication to approximate exactly-once semantics with low latency. This approach handles retries without producing duplicates when insertIds are used.\n\n## Why Other Options Are Wrong\n- Option B introduces batch latency and misses near-real-time value; Pub/Sub to BigQuery direct sinks are not natively supported; per-message Cloud Functions can incur duplication and higher latency.\n\n## Key Concepts\n- Streaming ingestion with insertId-based dedup\n- Pub/Sub to BigQuery via Dataflow\n- Exactly-once semantics in streaming pipelines\n\n## Real-World Application\n- Enables near-real-time dashboards for order events with controlled duplicates.","diagram":null,"difficulty":"intermediate","tags":["BigQuery","Dataflow","Pub/Sub","Cloud Storage","S3","EKS","Terraform","certification-mcq","domain-weight-15"],"channel":"gcp-data-engineer","subChannel":"prepare-use","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:22:42.941Z","createdAt":"2026-01-12 21:22:43"},{"id":"gcp-data-engineer-prepare-use-1768252962939-1","question":"A table with 2 TB daily of clickstream data is loaded as append-only and contains a date field event_date. You expect queries filtered by date and user_id across the last 30 days. Which schema optimization yields best performance and cost?","answer":"[{\"id\":\"a\",\"text\":\"Partition by ingestion_time and cluster by user_id, event_type\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Partition by event_date (DAY) and cluster by user_id, event_type\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Cluster only by user_id\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Create daily partitioned tables and UNION results\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is best: partitioning by the event_date field enables efficient pruning for date-filtered queries, and clustering on commonly filtered columns like user_id and event_type further reduces scanned data during last-30-days queries.\n\n## Why Other Options Are Wrong\n- A uses ingestion_time partitioning which may misalign with the actual event date and reduce pruning efficiency.\n- C clustering alone does not prune by date, leading to higher scanned data.\n- D creates many tables and requires unions, increasing maintenance and latency.\n\n## Key Concepts\n- Date-partitioning for time-bounded queries\n- Clustering on high-cardinality filters\n\n## Real-World Application\n- Improves latency and cost for frequent last-30-days analytics on large clickstream datasets.","diagram":null,"difficulty":"intermediate","tags":["BigQuery","Dataflow","Cloud Storage","S3","EKS","Terraform","certification-mcq","domain-weight-15"],"channel":"gcp-data-engineer","subChannel":"prepare-use","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:22:43.478Z","createdAt":"2026-01-12 21:22:43"},{"id":"gcp-data-engineer-prepare-use-1768252962939-2","question":"Your team stores raw logs in Cloud Storage and needs to perform heavy cleansing and feature extraction daily. Cost and throughput are concerns, and you may need complex transformations. Which approach is most practical and cost-effective for ongoing runs?","answer":"[{\"id\":\"a\",\"text\":\"Use BigQuery SQL to parse and cleanse data stored in Cloud Storage via external table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Dataflow (Apache Beam) to read from Cloud Storage, transform, and write to BigQuery\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Cloud Composer to orchestrate Python scripts that perform ETL in local memory\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Dataproc with Spark to process and write to BigQuery\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is the most practical: Dataflow handles large-scale ETL with flexible transformations and scales cost-effectively for daily runs, streaming or batch, and writes results to BigQuery.\n\n## Why Other Options Are Wrong\n- A external tables can simplify queries but may be slower and less flexible for heavy cleansing compared to a Beam pipeline.\n- C in-memory ETL via Composer is not scalable for large data volumes and can incur higher maintenance.\n- D Dataproc with Spark is powerful but often overkill and more costly for routine daily ETL unless you already rely on Spark ecosystems.\n\n## Key Concepts\n- Dataflow for scalable ETL\n- Cloud Storage as source for cleaning pipelines\n\n## Real-World Application\n- Automates nightly cleansing and feature extraction at scale with predictable costs.","diagram":null,"difficulty":"intermediate","tags":["BigQuery","Dataflow","Cloud Storage","S3","EKS","Terraform","certification-mcq","domain-weight-15"],"channel":"gcp-data-engineer","subChannel":"prepare-use","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:22:43.996Z","createdAt":"2026-01-12 21:22:44"},{"id":"gcp-data-engineer-prepare-use-1768252962939-3","question":"You need to orchestrate a nightly ETL with dependencies, retries, and alerting across multiple data sources. Which GCP managed service best fits this requirement?","answer":"[{\"id\":\"a\",\"text\":\"Cloud Functions with Cloud Scheduler\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Cloud Composer (Airflow)\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Dataflow job templates invoked by Cloud Scheduler\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cloud Run with cron\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is the best fit: Cloud Composer (Airflow) provides robust workflow orchestration with dependencies, retries, and alerting across heterogeneous data sources.\n\n## Why Other Options Are Wrong\n- A covers simple scheduling but lacks complex dependency management and centralized alerting.\n- C can coordinate tasks but isn’t as feature-rich for multi-source dependency graphs as Airflow.\n- D is suitable for simpler cron-like tasks but not ideal for complex ETL pipelines with dependencies.\n\n## Key Concepts\n- Orchestration with Airflow\n- Dependency graphs and retry policies\n\n## Real-World Application\n- Reliable nightly ETL with multi-source integration and observability.","diagram":null,"difficulty":"intermediate","tags":["BigQuery","Dataflow","Cloud Storage","S3","EKS","Terraform","certification-mcq","domain-weight-15"],"channel":"gcp-data-engineer","subChannel":"prepare-use","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:22:44.177Z","createdAt":"2026-01-12 21:22:44"},{"id":"gcp-data-engineer-prepare-use-1768252962939-4","question":"You regularly query a sum over revenue by product_id for the last 90 days, with new data arriving hourly. To speed these queries, which approach provides fast, consistent results with minimal maintenance?","answer":"[{\"id\":\"a\",\"text\":\"Create a materialized view with the aggregation and refresh hourly\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Run the aggregation on the fly in each query against the base table\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Build a separate daily summary table updated by a batch job each day\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Cache results in the BI tool\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption A is optimal: a materialized view maintains a pre-aggregated result that refreshes hourly, delivering fast query results with minimal maintenance for near real-time dashboards.\n\n## Why Other Options Are Wrong\n- B requires performing the aggregation every time, which is slower and more costly.\n- C introduces staleness by updating only daily and adds maintenance of a separate table.\n- D relies on BI tool caching which may not be consistent across users and sessions.\n\n## Key Concepts\n- Materialized views for pre-aggregated results\n- Incremental refresh strategies\n\n## Real-World Application\n- Accelerates executive dashboards showing revenue by product across the latest 90 days.","diagram":null,"difficulty":"intermediate","tags":["BigQuery","Dataflow","Cloud Storage","S3","EKS","Terraform","certification-mcq","domain-weight-15"],"channel":"gcp-data-engineer","subChannel":"prepare-use","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:22:44.495Z","createdAt":"2026-01-12 21:22:44"},{"id":"gcp-data-engineer-store-data-1768224509666-0","question":"A data lake stores daily Parquet logs in Cloud Storage and you want to query the most recent 24 months in BigQuery while keeping storage costs low. Which lifecycle strategy best balances cost and access?","answer":"[{\"id\":\"a\",\"text\":\"Keep all data in Standard storage with no lifecycle rules\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Move data older than 60 days to Nearline and data older than 365 days to Archive\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Move all data older than 30 days to Coldline\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Delete data after 24 months\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Option B is correct: use lifecycle rules to migrate data to cheaper storage as it ages, e.g., move data older than 60 days to Nearline and data older than 365 days to Archive, while keeping the most recent data in Standard for fast access.\n\n## Why Other Options Are Wrong\n- Option A keeps all data in Standard, increasing cost for rarely accessed older data.\n- Option C moves data to Coldline too aggressively for data that is still frequently accessed or queried, increasing retrieval costs.\n- Option D deletes data after 24 months, which would violate a 24-month retention requirement.\n\n## Key Concepts\n- Cloud Storage storage classes (Standard, Nearline, Coldline, Archive)\n- Lifecycle management to transition data across classes\n- Cost vs. access trade-offs in long-term storage\n\n## Real-World Application\n- Implement lifecycle rules in the Cloud Console or via gsutil to automatically move data based on age, ensuring last 24 months remain readily accessible while older data is cost-optimized.","diagram":null,"difficulty":"intermediate","tags":["GCP","CloudStorage","BigQuery","DataLifecycle","Terraform","certification-mcq","domain-weight-20"],"channel":"gcp-data-engineer","subChannel":"store-data","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:29.668Z","createdAt":"2026-01-12 13:28:30"},{"id":"gcp-data-engineer-store-data-1768224509666-1","question":"You have clickstream data with fields event_date (YYYY-MM-DD), country, user_id, and page. You load daily batches into a BigQuery table. You frequently query by a date range of the last 30 days and by country. Which table design yields the best cost to performance ratio?","answer":"[{\"id\":\"a\",\"text\":\"Partition the table by event_date only\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Partition the table by event_date and cluster by country\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Cluster the table by country only\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Partition by ingestion_time only\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Option B is correct: partition by event_date enables partition pruning for the 30-day window, and clustering by country localizes data for country-filtered queries, reducing scanned data and cost.\n\n## Why Other Options Are Wrong\n- Option A lacks clustering, so country filters may scan more data than necessary.\n- Option C lacks date-based partition pruning, leading to larger scanned ranges for date filters.\n- Option D (ingestion_time partitioning) does not align with business date filters and provides less effective pruning when querying by event_date.\n\n## Key Concepts\n- Partitioning by date for range queries\n- Clustering by frequently filtered fields (country)\n- Partition pruning reduces data scanned and cost\n\n## Real-World Application\n- Implement a BigQuery table with PARTITION BY event_date and CLUSTER BY country, then write queries with WHERE event_date BETWEEN ... AND ... AND country = ...","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Partitioning","Clustering","DataModeling","certification-mcq","domain-weight-20"],"channel":"gcp-data-engineer","subChannel":"store-data","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:30.189Z","createdAt":"2026-01-12 13:28:30"},{"id":"gcp-data-engineer-store-data-1768224509666-2","question":"For regulatory compliance, you need to ensure that objects stored in a Cloud Storage bucket are immutable for a defined retention period. Which feature provides this capability?","answer":"[{\"id\":\"a\",\"text\":\"Enable object versioning\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable bucket-level lifecycle to delete after a retention period\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable Object Lock retention policies\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Use signed URLs with long expiration\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Option C is correct: Object Lock retention policies enforce immutability for the objects for the specified retention period, satisfying regulatory retention requirements.\n\n## Why Other Options Are Wrong\n- Option A makes previous versions preservable but does not guarantee immutability of the current object during the retention window.\n- Option B can delete objects after a retention period but does not guarantee immutability during the period.\n- Option D does not address immutability or retention; it affects access control.\n\n## Key Concepts\n- Cloud Storage Object Lock\n- Retention policies for compliance\n- Immutable data guarantees\n\n## Real-World Application\n- Apply a retention policy to the bucket and enable Object Lock, set the retention period, and monitor to ensure compliance.","diagram":null,"difficulty":"intermediate","tags":["GCP","CloudStorage","Compliance","Terraform","certification-mcq","domain-weight-20"],"channel":"gcp-data-engineer","subChannel":"store-data","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:30.708Z","createdAt":"2026-01-12 13:28:30"},{"id":"gcp-data-engineer-store-data-1768224509666-3","question":"You manage a dataset containing binary assets (images/videos) and a separate metadata table in BigQuery for analytics. Which architecture provides efficient storage for assets and fast SQL querying of metadata together with scalable access to the assets?","answer":"[{\"id\":\"a\",\"text\":\"Store assets in Cloud Storage and metadata in BigQuery\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Store assets in BigQuery and metadata in Cloud Storage\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store both assets and metadata in BigQuery\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Store assets in Filestore and metadata in Spanner\",\"isCorrect\":false}]","explanation":"## Correct Answer\n- Option A is correct: Cloud Storage is optimized for large binary objects, while BigQuery stores structured metadata and supports SQL analytics, enabling efficient joins and analytics on metadata while serving the assets from object storage.\n\n## Why Other Options Are Wrong\n- Option B reverses the roles, misusing BigQuery for binary storage which is not cost-effective.\n- Option C duplicates binary data in BigQuery, which is expensive and unnecessary.\n- Option D uses a mix of services not aligned with common analytics patterns for binary assets and metadata.\n\n## Key Concepts\n- Separation of binary assets (Cloud Storage) vs structured data (BigQuery)\n- Efficient analytics via SQL on metadata\n- Scalable asset access via Cloud Storage integration with metadata store\n\n## Real-World Application\n- Implement a metadata catalog in BigQuery referencing Cloud Storage object URIs for asset retrieval in downstream apps.","diagram":null,"difficulty":"intermediate","tags":["GCP","CloudStorage","BigQuery","DataCatalog","Terraform","certification-mcq","domain-weight-20"],"channel":"gcp-data-engineer","subChannel":"store-data","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:30.888Z","createdAt":"2026-01-12 13:28:30"},{"id":"gcp-data-engineer-store-data-1768224509666-4","question":"You stream events from multiple sources into Pub/Sub and want to store them into BigQuery with strong deduplication guarantees. Which approach best ensures idempotent writes into BigQuery?","answer":"[{\"id\":\"a\",\"text\":\"Rely on Pub/Sub exactly-once delivery and use BigQuery streaming inserts with insertId\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Pub/Sub with a dead-letter queue and ignore duplicates in BigQuery\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Batch load from GCS every hour and MERGE into BigQuery\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Dataflow with a deduplication step and MERGE into BigQuery\",\"isCorrect\":true}]","explanation":"## Correct Answer\n- Option D is correct: a Dataflow pipeline can implement a deduplication step, producing upserts into BigQuery (MERGE or equivalent) based on a stable unique key, ensuring idempotent writes in a streaming context.\n\n## Why Other Options Are Wrong\n- Option A relies on Pub/Sub delivery guarantees and BigQuery insertId deduplication, which may not be sufficient in all failure scenarios and is more brittle than a controlled pipeline.\n- Option B’s dead-letter approach does not prevent duplicates in the main sink.\n- Option C introduces latency and potential windowing complexities; it is not as robust for real-time deduplication as a streaming Dataflow solution.\n\n## Key Concepts\n- Idempotent ingestion patterns\n- Dataflow pipelines with MERGE into BigQuery\n- Deduplication keys and upserts\n\n## Real-World Application\n- Implement a streaming Dataflow job that reads from Pub/Sub, applies a unique-id-based deduplication, and writes to BigQuery using MERGE semantics to avoid duplicates.","diagram":null,"difficulty":"intermediate","tags":["GCP","Pub/Sub","Dataflow","BigQuery","ETL","certification-mcq","domain-weight-20"],"channel":"gcp-data-engineer","subChannel":"store-data","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:28:31.067Z","createdAt":"2026-01-12 13:28:31"}],"subChannels":["design-data-systems","general","ingest-process","maintain-automate","prepare-use","store-data"],"companies":["Citadel","Cloudflare","Databricks","Discord","Google","Instacart","NVIDIA","Snap","Uber"],"stats":{"total":34,"beginner":1,"intermediate":33,"advanced":0,"newThisWeek":34}}