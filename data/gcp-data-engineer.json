{"questions":[{"id":"gcp-data-engineer-design-data-systems-1768195992962-0","question":"Your real-time analytics pipeline ingests events from Pub/Sub, processes them with a Dataflow streaming job, and writes per-event metrics to BigQuery for near real-time dashboards. You must guarantee exactly-once processing to avoid duplicate metrics due to retries. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Use Dataflow with Pub/Sub and write to BigQuery using streaming inserts without any deduplication handling\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use Dataflow streaming with an insertId per row derived from the event's unique id to enable idempotent writes in BigQuery\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Pub/Sub with a Cloud Function that writes to BigQuery with insertId; duplicates may occur\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a batch pipeline that reads Pub/Sub via pull subscriptions and writes to BigQuery in batch mode\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct because deriving a unique insertId for each event ensures idempotent streaming writes to BigQuery. If the Dataflow worker retries a failed write, BigQuery uses the insertId to deduplicate and avoid duplicates. The other options either rely on non-idempotent streaming writes (a), rely on a non-deduplicating path (c), or abandon streaming guarantees by using batch processing (d).\n\n## Why Other Options Are Wrong\n- Option A: Streaming inserts without deduplication cannot guarantee exactly-once semantics when retries occur.\n- Option C: Cloud Functions can produce duplicates on retries unless you implement idempotency manually, which is error-prone at scale.\n- Option D: Batch processing cannot provide real-time or near-real-time semantics and misses the exactly-once guarantees in a streaming context.\n\n## Key Concepts\n- Exactly-once semantics in streaming pipelines\n- Idempotent writes with insertId for BigQuery streaming inserts\n- Dataflow and Pub/Sub integration for real-time analytics\n\n## Real-World Application\n- Used in production to ensure metrics dashboards reflect unique events even under retry scenarios, preventing inflated counts or duplicates.","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Dataflow","Pub/Sub","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:12.964Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-design-data-systems-1768195992962-1","question":"A Dataflow job consumes clickstream data from Pub/Sub and computes per-minute aggregates. Some events arrive late by up to 20 minutes. To include late data without delaying current window results, which pattern should you implement?","answer":"[{\"id\":\"a\",\"text\":\"Enable allowed lateness of 20 minutes and use appropriate triggers to emit results after window end\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Switch to a batch job that reprocesses the previous dayâ€™s data every night\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Discard late data to maintain the lowest latency\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Run a separate corrective streaming job that reprocesses the late data after it arrives\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption a is correct because allowing lateness (e.g., 20 minutes) and configuring triggers (such as AfterWatermark or AfterProcessingTime) enables the pipeline to include late events in the appropriate windows without waiting for the next day. \n\n## Why Other Options Are Wrong\n- Option B: Batch reprocessing introduces higher latency and does not handle real-time late data in current windows.\n- Option C: Dropping late data sacrifices data completeness and analytics accuracy.\n- Option D: A separate corrective job adds complexity and potential drift; handling lateness within the streaming window is more robust.\n\n## Key Concepts\n- Event-time processing in streaming pipelines\n- Allowed lateness and windowing triggers in Beam/Dataflow\n- Balancing latency and data completeness\n\n## Real-World Application\n- Enables accurate near-real-time dashboards even when some events arrive late due to network or device issues.","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:13.472Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-design-data-systems-1768195992962-2","question":"IoT telemetry daily volume reaches around 10 TB/day. You want long-term storage that keeps costs reasonable and enables fast ad-hoc analytics. Which BigQuery table design best supports time-series analysis at scale?","answer":"[{\"id\":\"a\",\"text\":\"Store in a single wide, non-partitioned BigQuery table\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Partition the table by ingestion_date and cluster on device_id, ideally using ingestion-time partitioning\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store as a nested JSON string in a single column and parse at query time\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Bigtable for analytics instead of BigQuery\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption b is correct because partitioning by date and clustering on device_id improves query performance and cost efficiency for high-volume time-series analytics. Ingestion-time partitioning helps automate partitioning for streaming loads. \n\n## Why Other Options Are Wrong\n- Option A: Non-partitioned tables incur higher scan costs and slower queries on large datasets.\n- Option C: Storing JSON strings requires parsing at query time, increasing latency and cost; nested/structured columns in BigQuery are preferred.\n- Option D: Cloud Bigtable is optimized for wide-column NoSQL workloads, not ad-hoc analytics; BigQuery is typically better for analytics workloads at scale.\n\n## Key Concepts\n- Time-series data modeling in BigQuery\n- Ingestion-time partitioning and clustering for performance/cost\n- Analytical workloads vs NoSQL storage trade-offs\n\n## Real-World Application\n- Enables fast, cost-effective analytics on high-volume IoT telemetry with scalable querying and efficient data management.","diagram":null,"difficulty":"intermediate","tags":["GCP","BigQuery","Dataflow","Pub/Sub","AWS","Kubernetes","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-data-engineer","subChannel":"design-data-systems","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:33:13.829Z","createdAt":"2026-01-12 05:33:13"},{"id":"gcp-data-engineer-ingest-process-1768158927214-0","question":"Which architecture best achieves reliable, deduplicated, near-real-time writes from Pub/Sub to BigQuery while tolerating late data?","answer":"[{\"id\":\"a\",\"text\":\"Ingest events to Cloud Storage and perform batch loads from Cloud Storage to BigQuery every 5 minutes.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Publish events to Pub/Sub, process with Dataflow using per-key windows and insertId-based dedup, then write to BigQuery via streaming inserts.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Publish events directly to BigQuery streaming inserts from client applications.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud Functions to buffer events in memory and periodically write to BigQuery.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Pub/Sub provides real-time ingestion, Dataflow enables per-key windowing and deduplication, and BigQuery streaming inserts support near-real-time writes alongside insertId-based dedup to minimize duplicates.\n\n## Why Other Options Are Wrong\n- Option A trades real-time visibility for batch latency and adds buffering complexity, delaying insight.\n- Option C cannot guarantee idempotent writes and raises risks of duplicates due to retries.\n- Option D relies on in-memory buffering which is unsafe for reliability and scaling and can lead to data loss on restarts.\n\n## Key Concepts\n- Streaming ingestion with Pub/Sub\n- Dataflow windowing and per-key processing\n- Deduplication with insertId in BigQuery streaming inserts\n- Handling late data via watermarking and windowing\n\n## Real-World Application\nUsed for real-time dashboards and anomaly detection where timely, deduplicated insights are critical.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:27.215Z","createdAt":"2026-01-11 19:15:27"},{"id":"gcp-data-engineer-ingest-process-1768158927214-1","question":"You're ingesting JSON sensors data with evolving schema into BigQuery. Which approach minimizes downtime and automatically updates the BigQuery table schema as new fields appear?","answer":"[{\"id\":\"a\",\"text\":\"Use BigQuery load jobs with auto-detect on every file and replace the table.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Implement a Dataflow pipeline with BigQueryIO and enable schema update options to ALLOW_FIELD_ADDITION.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use a scheduled Cloud Storage-to-BigQuery Transfer with auto-detect.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Write to a new BigQuery table each day and merge manually.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Dataflow's BigQueryIO supports dynamic schema updates (e.g., ALLOW_FIELD_ADDITION), enabling automatic schema evolution as new fields appear in incoming JSON data, with minimal downtime.\n\n## Why Other Options Are Wrong\n- Option A can lead to table recreation or downtime and does not reliably handle ongoing schema evolution in streaming contexts.\n- Option C does not provide automated, reliable schema evolution for evolving JSON data in a streaming/batch mix.\n- Option D introduces unnecessary complexity and potential data fragmentation; merging would require custom tooling.\n\n## Key Concepts\n- BigQueryIO schema update options (ALLOW_FIELD_ADDITION)\n- Dynamic schema evolution in streaming pipelines\n- Dataflow as a flexible ingestion path for evolving schemas\n\n## Real-World Application\nCommon when IoT/wearable sensors introduce new fields over time, needing seamless table evolution without downtime.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:27.757Z","createdAt":"2026-01-11 19:15:28"},{"id":"gcp-data-engineer-ingest-process-1768158927214-2","question":"You need per-user event counts in 15-minute windows, with events potentially arriving late up to 10 minutes. Which Dataflow windowing/triggers setup is appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Use 15-minute fixed windows with no lateness.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use 15-minute fixed windows with allowed lateness 10 minutes and default trigger.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use 15-minute sliding windows with a 10-minute lag.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a global window with incremental accumulation.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because 15-minute fixed windows with allowed lateness of 10 minutes ensure late events are included up to the stated tolerance, while the default trigger finalizes the window after the lateness period.\n\n## Why Other Options Are Wrong\n- Option A drops late data, reducing correctness and insight.\n- Option C uses sliding windows which would create overlapping windows and complexity without necessity for per-15-minute aggregation.\n- Option D with a global window prevents per-interval aggregation and late data handling.\n\n## Key Concepts\n- Windowing and fixed windows\n- Allowed lateness and watermark behavior\n- Triggers and late data handling\n\n## Real-World Application\nUseful for dashboards showing per-user activity over recent intervals where data can arrive late due to network delays.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Dataflow","Pub/Sub","BigQuery","Terraform","Kubernetes","AWS-S3","AWS-Lambda","AWS-Kinesis","certification-mcq","domain-weight-25"],"channel":"gcp-data-engineer","subChannel":"ingest-process","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T19:15:28.234Z","createdAt":"2026-01-11 19:15:28"}],"subChannels":["design-data-systems","ingest-process"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}