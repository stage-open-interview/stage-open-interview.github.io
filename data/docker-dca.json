{"questions":[{"id":"q-1392","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API across an overlay network and ensure zero-downtime upgrades via canary, using update_config (start-first, parallelism 1). Outline the exact sequence of commands to init/join the swarm, create the overlay, deploy the service with update settings, and perform a canary upgrade with health checks. Include a minimal docker-compose snippet showing update_config?","answer":"Init swarm on node A: docker swarm init --advertise-addr <A>; join B/C: docker swarm join --token <tok> <A>:2377; overlay: docker network create -d overlay --attachable app-net; deploy: docker service","explanation":"## Why This Is Asked\nTests practical mastery of Swarm lifecycle, overlay networking, and zero-downtime upgrades in multi-datacenter setups.\n\n## Key Concepts\n- Docker Swarm init/join and multi-datacenter networking\n- Overlay networks and service deployment in Swarm\n- update_config for canary upgrades and health checks\n\n## Code Example\n```docker-compose\nversion: '3.8'\nservices:\n  api:\n    image: nginx:stable\n    networks:\n      - app-net\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\nnetworks:\n  app-net:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you handle service traffic shifting for canary without external LB?\n- What are failure_action and monitor thresholds used for in update_config?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Cloudflare","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:52:07.307Z","createdAt":"2026-01-13T14:52:07.307Z"},{"id":"q-1412","question":"Scenario: youâ€™re building a beginner-friendly Docker Compose setup for a FastAPI microservice with PostgreSQL on a single host. Create Dockerfiles for the app and an init script, plus a docker-compose.yml with a named volume for Postgres data, healthchecks, and a startup script that waits for PostgreSQL on port 5432 before starting the app. Explain the exact files, commands, and deployment sequence?","answer":"I would dockerize the FastAPI app with Python 3.11, add a Postgres container, and provide a docker-compose.yml with services app and db, a named volume pgdata, environment vars, and healthchecks. Incl","explanation":"## Why This Is Asked\nTests practical Docker Compose skills: multi-service setup, data persistence, healthchecks, startup dependencies.\n\n## Key Concepts\n- Dockerfile basics, Python 3.11\n- Postgres container with pgdata volume\n- docker-compose networks/depends_on healthchecks\n- wait-for-it pattern for DB readiness\n\n## Code Example\n```yaml\n# docker-compose.yaml (excerpt)\nversion: '3.9'\nservices:\n  app:\n    build: ./app\n    ports:\n      - '8000:8000'\n    depends_on:\n      - db\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      retries: 5\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: example\n    volumes:\n      - pgdata:/var/lib/postgresql/data\nvolumes:\n  pgdata:\n    name: pgdata\n```\n\n## Follow-up Questions\n- How would you add a migration step to initialize schemas?\n- How would you scale this with separate networks or secrets management?","diagram":"flowchart TD\nA[Developer writes app] --> B[Build Dockerfile]\nB --> C[Create docker-compose.yaml]\nC --> D[Start stack with docker compose up -d]\nD --> E[Healthchecks verify readiness]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:51:50.736Z","createdAt":"2026-01-13T15:51:50.737Z"},{"id":"q-1443","question":"In a 3-node Swarm across DC-A and DC-B, deploy a stateless API via overlay api-net with DC-affinity (2 replicas in DC-A and 1 in DC-B). Outline the exact CLI steps to init/join, create the overlay, and deploy two services with update_config (order: start-first, parallelism: 1). Describe a canary upgrade process that gradually updates replicas across DCs and validates with health checks. Include a minimal docker-compose snippet showing the two services, the overlay network, and update_config?","answer":"Init Swarm on DC-A; join DC-B; create overlay api-net; deploy two services: api-dcA with 2 replicas constrained to DC-A and api-dcB with 1 replica constrained to DC-B, both on api-net and update_confi","explanation":"## Why This Is Asked\nTests cross-DC orchestration, DC-aware placement, and canary upgrades using Docker Swarm update_config.\n\n## Key Concepts\n- Overlay networks spanning DCs\n- Placement constraints and spread/preference for DC distribution\n- update_config for staged upgrades\n- Canary rollout and health-check driven promotion\n\n## Code Example\n```javascript\nversion: \"3.8\"\nservices:\n  api-dcA:\n    image: myapi:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-A\n      networks:\n        - api-net\n  api-dcB:\n    image: myapi:latest\n    deploy:\n      replicas: 1\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-B\n      networks:\n        - api-net\nnetworks:\n  api-net:\n```\n\n## Follow-up Questions\n- How would you monitor canary success across DCs and automate rollback if latency spikes? \n- How would you adapt this for a rolling upgrade with multiple versions concurrently?","diagram":"flowchart TD\n  A[Init Swarm in DC-A] --> B[Join DC-B]\n  B --> C[Create overlay api-net]\n  C --> D[Deploy two services with update_config]\n  D --> E[Canary rollout across DCs]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:34:28.800Z","createdAt":"2026-01-13T17:34:28.803Z"},{"id":"q-1530","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API with TLS termination that uses Vault for dynamic TLS certificate rotation. Use Docker secrets to distribute certs, and implement a lightweight sidecar that refreshes certificates without dropping connections. Configure a canary-style rolling upgrade ensuring zero-downtime during cert rotations. Outline the exact steps: swarm init/join, overlay network creation, stack/deploy with secret handling, and the certificate rotation workflow with health checks?","answer":"Plan: initialize a 3-node Docker Swarm across two data centers, create an overlay network, deploy a stack with API and sidecar containers, mount Vault-issued certificates as Docker secrets and rotate them via the sidecar without container restarts, and perform a canary-style rolling upgrade ensuring zero-downtime during certificate rotations.","explanation":"## Why This Is Asked\nTests multi-datacenter Docker Swarm setup, TLS automation with HashiCorp Vault, Docker secrets management, and zero-downtime deployment strategies.\n\n## Key Concepts\n- Docker Swarm spanning multiple data centers\n- Docker secrets with external secret management (Vault)\n- Sidecar pattern for live certificate rotation\n- Update configuration with start-first for zero-downtime upgrades\n- Health checks and canary rollout strategies\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  api:\n    image: myorg/api:latest\n    ports:\n      - \"80:80\"\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n      healthcheck:\n        test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:80/health\"]\n        interval: 30s\n        timeout: 10s\n        retries: 3\n  sidecar:\n    image: myorg/cert-rotator:latest\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n      - source: vault_token\n        target: vault.token\n    deploy:\n      replicas: 1\nsecrets:\n  tls_cert:\n    external: true\n  vault_token:\n    external: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:10:39.873Z","createdAt":"2026-01-13T20:46:17.744Z"},{"id":"q-1579","question":"Design a secret-rotation workflow for a Docker Swarm stack that uses Vault to rotate a TLS cert and a database credential with zero downtime. Use Swarm secrets and a rolling update (start-first). Outline exact steps: swarm init/join, overlay network, create secrets, deploy stack, Vault rotate trigger, service update commands. Include a minimal docker-compose snippet showing secret usage and update_config?","answer":"Plan: Vault issues new TLS certificate and database credential; create new Swarm secrets (e.g., api-tls-v2, db-cred-v2); perform service updates with `docker service update --secret-add` then `--secret-rm`, using update_config with start-first strategy for zero downtime.\n\n## Implementation Steps\n\n1. **Initialize Swarm cluster**\n   ```bash\n   docker swarm init --advertise-addr <MANAGER-IP>\n   docker swarm join --token <TOKEN> <MANAGER-IP>:2377\n   ```\n\n2. **Create overlay network**\n   ```bash\n   docker network create --driver overlay --attachable app-network\n   ```\n\n3. **Create initial secrets from Vault**\n   ```bash\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v1 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v1 -\n   ```\n\n4. **Deploy stack with rolling update configuration**\n   ```yaml\n   version: '3.8'\n   services:\n     api:\n       image: myapp:latest\n       secrets:\n         - source: api-tls-v1\n           target: /app/tls.crt\n         - source: db-cred-v1\n           target: /app/db-cred\n       networks:\n         - app-network\n       update_config:\n         parallelism: 1\n         delay: 10s\n         order: start-first\n       healthcheck:\n           test: [\"CMD\", \"curl\", \"-f\", \"https://localhost:8443/health\"]\n           interval: 30s\n           timeout: 10s\n           retries: 3\n   ```\n\n5. **Vault rotation trigger**\n   - Vault generates new TLS certificate and database credential\n   - Automation script detects rotation event\n\n6. **Service update with new secrets**\n   ```bash\n   # Create new secret versions\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v2 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v2 -\n   \n   # Update service to add new secrets\n   docker service update api \\\n     --secret-add source=api-tls-v2,target=/app/tls.crt \\\n     --secret-add source=db-cred-v2,target=/app/db-cred\n   \n   # Remove old secrets after health checks pass\n   docker service update api \\\n     --secret-rm api-tls-v1 \\\n     --secret-rm db-cred-v1\n   ```","explanation":"## Why This Is Asked\nDemonstrates practical secret lifecycle management in Docker Swarm, integrating Vault for automated rotation with zero-downtime upgrades and proper secret versioning.\n\n## Key Concepts\n- Swarm secrets versioning and dynamic reattachment\n- Vault-based rotation triggers and secret provisioning\n- Rolling updates with start-first strategy to avoid downtime\n- Health checks to confirm new secrets are loaded before removing old ones\n- Atomic secret updates using add-then-remove pattern\n\n## Code Example\n```javascript\n// Pseudo-automation: rotate Vault-derived Swarm secrets\nasync function rotateSecrets(serviceName, vaultPath) {\n  // Fetch new credentials from Vault\n  const newCreds = await vault.read(vaultPath);\n  \n  // Create new Swarm secrets\n  const newSecrets = await createSwarmSecrets(newCreds);\n  \n  // Update service with new secrets\n  await updateService(serviceName, newSecrets);\n  \n  // Verify health before cleanup\n  await verifyServiceHealth(serviceName);\n  \n  // Remove old secrets\n  await cleanupOldSecrets(serviceName);\n}\n```","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:56:17.721Z","createdAt":"2026-01-13T22:45:30.688Z"},{"id":"q-1628","question":"Scenario: In a 3-node Swarm across two DCs, deploy an API service behind Traefik with image signing enforcement (cosign/DOCKER_CONTENT_TRUST) and implement a canary upgrade to v2 with a 10% traffic split via a separate api-v2-canary service. Outline exact commands, Swarm update_config usage, and docker-compose/service definitions to achieve zero-downtime upgrade and safe rollback?","answer":"Enable Docker Content Trust and cosign signing on all nodes (DOCKER_CONTENT_TRUST=1; cosign sign). Deploy api-v1 and a canary api-v2-canary behind Traefik with a 10% canary route. Use update_config { ","explanation":"## Why This Is Asked\nEvaluates image provenance, canary sequencing, and Swarm upgrade semantics in a multi-datacenter setup.\n\n## Key Concepts\n- Image signing with cosign and DOCKER_CONTENT_TRUST\n- Swarm update_config for controlled upgrades\n- Traffic splitting via an in-cluster reverse proxy (Traefik)\n- Canary pattern and safe rollback in production\n\n## Code Example\n```javascript\n// illustrative docker-compose-like snippet (Traefik routing hints)\nservices:\n  api-v1:\n    image: registry.example.com/api:v1\n    deploy:\n      replicas: 4\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v1.rule=Host(`api.example.com` )\"\n  api-v2-canary:\n    image: registry.example.com/api:v2-canary\n    deploy:\n      replicas: 1\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v2-canary.rule=Host(`canary.api.example.com` )\"\n```\n\n## Follow-up Questions\n- How would key rotation and automatic signing verification be automated?\n- How would you measure canary health and decide promotion/rollback automatically?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:16:19.227Z","createdAt":"2026-01-14T04:16:19.227Z"},{"id":"q-1653","question":"Scenario: On a single host, implement a beginner-friendly Docker Compose stack: a Node.js API that talks to Redis and a Fluent Bit logging service that reads logs from the API via a shared volume and forwards them to stdout. Provide a Dockerfile for the API, a docker-compose.yml with api, redis, fluent-bit, a logs volume, and healthchecks; explain the run steps and verification?","answer":"Create a docker-compose.yml with api, redis, and fluent-bit services on one host, plus a shared logs volume. The API writes to /var/log/app/app.log; Fluent Bit tails that file and forwards to stdout. ","explanation":"## Why This Is Asked\nTests practical docker-compose discipline: multi-service coordination, logging discipline, and health checks.\n\n## Key Concepts\n- docker-compose multi-service orchestration\n- log aggregation with Fluent Bit\n- log file sharing via volumes\n- minimal health checks for API service\n\n## Code Example\n```dockerfile\n# Dockerfile for API\nFROM node:18\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD node server.js\n```\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  api:\n    build: ./api\n    depends_on:\n      - redis\n    environment:\n      - REDIS_URL=redis://redis:6379\n    healthcheck:\n      test: curl -f http://localhost:3000/health || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - ./logs:/var/log/app\n  redis:\n    image: redis:7\n  fluent-bit:\n    image: fluent/fluent-bit:1.9\n    volumes:\n      - ./logs:/var/log/app\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf\n    depends_on:\n      - api\n```\n\n## Follow-up Questions\n- How would you extend this to ship logs to an external system\n- How would you ensure log retention and rotate the log files","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Instacart","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:35:42.804Z","createdAt":"2026-01-14T05:35:42.804Z"},{"id":"q-1688","question":"Beginner-level: design a local docker-compose stack for a Node.js API that uses Redis as a cache. Provide a Dockerfile for the API, a startup script that waits for Redis to be reachable on 6379 before starting, and a docker-compose.yml with healthchecks for both services on a shared network. Include exact file contents or minimal snippets, the commands to build and run, and how to validate a cache-hit endpoint?","answer":"Build a Node.js API image with a Dockerfile, and a start script wait-for-redis.sh that pings redis:6379 until ready, then runs node index.js. In docker-compose.yml, define services api and redis on a ","explanation":"Why This Is Asked\nTests ability to coordinate container startup and readiness in Compose using a startup gate and healthchecks.\n\nKey Concepts\n- Dockerfile for Node.js\n- startup gating with a wait script\n- docker-compose healthchecks\n- Docker networking and service discovery\n\nCode Example\n```javascript\n# Dockerfile\nFROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\n# Start directly with node (no quotes) for simplicity\nCMD node index.js\n```\n```javascript\n# wait-for-redis.sh (simplified)\nuntil nc -z  redis 6379; do\n  sleep 0.2\ndone\nexec \"$@\"\n```\n```javascript\n# docker-compose.yml\nversion: '3.9'\nservices:\n  api:\n    build: .\n    ports:\n      - 3000:3000\n    depends_on:\n      - redis\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    command: [\"sh\",\"/wait-for-redis.sh\",\"redis\",\"node\",\"index.js\"]\n  redis:\n    image: redis:7-alpine\n    ports:\n      - 6379:6379\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\nnetworks:\n  default:\n    name: appnet\n```\n\nFollow-up Questions\n- How would you adapt for an optional Redis cache with a fallback?\n- How would you test failure of Redis and verify API behavior?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","MongoDB","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:58:39.175Z","createdAt":"2026-01-14T06:58:39.175Z"},{"id":"q-1760","question":"In a three-node Docker Swarm spanning two data centers, introduce a new internal auth service that all APIs depend on. Roll it out with zero downtime and a canary, using update_config (start-first, parallelism 1), Docker Secrets, and a routing shim. Provide exact commands to init/join the swarm, create the overlay, deploy the stack, add the secret, and perform the canary upgrade with health checks?","answer":"Two-stage canary: deploy auth-v2 with 1 replica and route 5% of traffic to it; ensure health checks pass; then roll the main stack with update_config start-first, parallelism 1. Commands: docker swarm","explanation":"## Why This Is Asked\nRealistic multi-datacenter upgrades require controlled rollouts with canary, health checks, and secrets. This tests operational discipline and deep Docker Swarm knowledge.\n\n## Key Concepts\n- Swarm upgrades with update_config; - Canaries across regions; - Secrets management; - Overlay networking; - Health checks and rollback.\n\n## Code Example\n```javascript\nversion: '3.8'\nservices:\n  auth:\n    image: myrepo/auth:canary\n    secrets:\n      - source: auth-secret\n        target: /etc/auth/secret.json\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nsecrets:\n  auth-secret:\n    external: true\n```\n\n## Follow-up Questions\n- How would you automate canary traffic routing without a reverse proxy? \n- How would you verify no active sessions are dropped during promotion?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:46:53.036Z","createdAt":"2026-01-14T09:46:53.036Z"},{"id":"q-1786","question":"In a 3-node Docker Swarm spanning two data centers, deploy a GPU-accelerated model-serving API (TorchServe) using the NVIDIA runtime. Expose it behind an internal overlay network and a simple LB. Ensure zero-downtime upgrades with canary traffic shifts and a pre-warm sidecar to warm the new replica without serving traffic. Outline the steps for swarm init/join, overlay creation, service spec with GPU constraints, secret handling, and a separate migration container if needed. Include a minimal docker-compose snippet showing update_config (start-first, parallelism 1)?","answer":"Outline a GPU-enabled TorchServe deployment on a 3-node Swarm across 2 DCs. Use NVIDIA runtime and a service with GPU constraint (nvidia.com/gpu=1). Implement canary upgrades: deploy 1 new replica, ru","explanation":"## Why This Is Asked\nTests ability to orchestrate GPU-enabled deployments across DCs, implement safe upgrades, and coordinate sidecar pre-warming with a migration task.\n\n## Key Concepts\n- GPU scheduling in Swarm with NVIDIA runtime\n- Overlay networks across data centers\n- Canary rollout using update_config (start-first, single-threaded)\n- Sidecar pre-warm pattern for zero-downtime\n- Migration container for schema/model updates\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  model:\n    image: myorg/torchserve:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities:\n                -gpu\n                  count: 1\n```\n\n## Follow-up Questions\n- How would you monitor GPU utilization across nodes?\n- How would you handle model/version rollback in a canary rollout?","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create Overlay Network]\n  B --> C[Deploy TorchServe with NVIDIA runtime]\n  C --> D[Canary Upgrade: 1 new replica]\n  D --> E[Health Checks & Traffic Shift]\n  E --> F[Promote & Cleanup]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:48:28.317Z","createdAt":"2026-01-14T10:48:28.317Z"},{"id":"q-1832","question":"Design and implement a zero-downtime upgrade for a 4-node Docker Swarm across two data centers hosting a stateful Redis queue and a stateless worker service. The worker consumes messages encoded in a new proto format; the cluster uses TLS mutual authentication with Vault for cert rotation and Docker Secrets for credentials. Outline exact upgrade steps, a 10% canary rollout, health checks, and a rollback plan, and include a minimal docker-compose snippet showing update_config(order: start-first, parallelism: 1)?","answer":"Use a 4-node Swarm across two DCs, with a 10% canary of the worker upgraded to the new proto-format, while 90% stay on the legacy image. Deploy update_config: order: start-first; parallelism: 1. Route","explanation":"## Why This Is Asked\nTests real-world upgrade workflows in a distributed Swarm with cross-DC considerations, TLS cert rotation, and in-flight data.\n\n## Key Concepts\n- Swarm update_config with start-first and parallelism\n- Canary rollouts and rollback triggers\n- TLS mutual authentication, Vault cert rotation, Docker secrets\n- In-flight data migration and zero-downtime guarantees\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  worker:\n    image: myorg/worker:upgrade\n    deploy:\n      replicas: 4\n      update_config:\n        order: start-first\n        parallelism: 1\n    secrets:\n      - tls_cert\n      - db_creds\n    environment:\n      - PROTO_VERSION=v2\n```\n\n## Follow-up Questions\n- How would you validate canary health beyond a simple Liveness probe?\n- What rollback automation would you add to rapidly revert if metrics deteriorate?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Two Sigma","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T13:15:02.309Z","createdAt":"2026-01-14T13:15:02.310Z"},{"id":"q-1967","question":"In a production Swarm across two data centers with four nodes, implement end-to-end image provenance using Cosign. Sign CI artifacts, publish signatures to a registry, and enforce verification before deploys. Outline the exact steps: key management, signing workflow in CI, signature verification at pull-time, updating services with image digests, and a rollback plan if verification fails. Provide concrete Cosign commands and how to incorporate into a CI/CD pipeline?","answer":"CI builds, signs, and publishes; Swarm deploy uses digest; if cosign verify fails, rollback to previous digest. Commands: cosign generate-key-pair, cosign sign --key cosign.key registry.example.com/ap","explanation":"## Why This Is Asked\nAssesses practical image provenance, CI/CD integration, and rollback readiness in distributed Swarm.\n\n## Key Concepts\n- Image signing with Cosign; key management; digest-based deployments; runtime verification; rollback strategy.\n\n## Code Example\n```\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you automate key rotation and revocation?\n- How do you test the rollback in a canary deployment?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","DoorDash","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:00:51.280Z","createdAt":"2026-01-14T19:00:51.281Z"},{"id":"q-2016","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API behind a Traefik ingress with a Redis-backed cache layer and mutual TLS between services. Use Docker secrets/configs for TLS certs and cache creds. Apply zero-downtime upgrades via update_config (start-first, parallelism 1) and implement a canary upgrade path with health checks and automatic rollback. Outline the exact init/join commands, overlay creation, stack file, and upgrade sequence?","answer":"Initialize a three-node Swarm across two DCs, join the remaining nodes with generated tokens, create an overlay network, and deploy a Traefik-based API with a Redis cache layer. Use Docker secrets for","explanation":"## Why This Is Asked\nTests orchestration across DCs, zero-downtime upgrades, and secure service-to-service traffic with mTLS. It also probes secret/config management, canary rollout, and rollback handling.\n\n## Key Concepts\n- Swarm multi-DC deployment and node join tokens\n- Overlay networks and Traefik ingress with mTLS\n- Docker secrets/configs for TLS and credentials\n- update_config with start_first and parallelism, canary deployments\n\n## Code Example\n```yaml\n# docker-stack.yml (excerpt)\nversion: '3.8'\nservices:\n  api:\n    image: myapi:v2\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    secrets:\n      - redis-creds\n      - tls-cert\n    networks:\n      - app-net\n  cache:\n    image: redis:6\n    deploy:\n      replicas: 3\n    secrets:\n      - redis-creds\n    networks:\n      - app-net\nnetworks:\n  app-net:\n    external: true\nsecrets:\n  tls-cert:\n    external: true\n  redis-creds:\n    external: true\n```\n\n## Follow-up Questions\n- How would you implement automatic rollback on canary failure?\n- How do you measure canary success beyond HTTP 200s (latency, error rate)?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T20:53:37.375Z","createdAt":"2026-01-14T20:53:37.375Z"},{"id":"q-2022","question":"Scenario: On a single host, implement a blue-green deployment for a stateless API behind an Nginx reverse proxy using docker-compose. Start with green (v1) receiving all traffic; deploy blue (v2) and switch traffic to blue only after a 30-second health-check window confirms readiness, ensuring zero downtime. Provide: a) docker-compose.yml with two API services (api-green and api-blue) and Nginx, b) nginx.conf with a switchable upstream, c) a Bash script upgrade.sh that promotes blue by reconfiguring upstream and reloading Nginx, d) exact commands to bring up green, deploy blue, run the upgrade, and verify with curl?","answer":"Bootstrap green (v1) behind a single Nginx proxy. Deploy blue (v2) as a separate container and run healthchecks. When blue is healthy for 30s, swap nginx upstream to point to api-blue and reload Nginx","explanation":"## Why This Is Asked\nTests practical blue-green deployment on a single host, emphasizing health-driven promotion and service-rotations with minimal downtime.\n\n## Key Concepts\n- Blue-green deployment on a standalone host\n- Docker Compose for multi-service apps\n- Nginx upstream switching and live reload\n- Health checks and rollback safety\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  nginx:\n    container_name: nginx\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n  api-green:\n    image: myapi:v1\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\n  api-blue:\n    image: myapi:v2\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\nnetworks:\n  default:\n    driver: bridge\n```\n\n```nginx\nevents { worker_connections 1024; }\nhttp {\n  upstream api_green { server api-green:8080; }\n  server { listen 80; location / { proxy_pass http://api_green; } }\n}\n```\n\n```bash\n#!/usr/bin/env bash\nset -e\n# Start green (v1)\ndocker-compose up -d api-green nginx\n# Deploy blue (v2)\ndocker-compose up -d api-blue\n# Wait for blue health (simplified placeholder)\n# ... poll health until healthy for 30s ...\n# Promote blue\nsed -i 's/server api-green:8080;/server api-blue:8080;/' nginx.conf\ndocker exec -i nginx nginx -s reload\n```\n\n## Follow-up Questions\n- How would you automate the 30s health window and rollback if any check fails?\n- How would you extend this to three or more canaries and track traffic ratios over time?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T21:31:46.162Z","createdAt":"2026-01-14T21:31:46.162Z"},{"id":"q-2053","question":"In a four-node **Docker Swarm** spanning two data centers, deploy a stateless API with a Redis-backed rate limiter and a shared cache. Implement a canary upgrade of the API using update_config (start-first, parallelism 1), with a front-door that routes the canary subset using label-based routing. Outline exact commands: swarm init/join, overlay creation, stack deploy, and the health-check-driven promotion. Include a minimal docker-compose snippet showing update_config?","answer":"Initialize a 4-node Docker Swarm across two data centers and create an overlay network for cross-DC communication. Deploy the API stack with 3 production replicas and 1 canary replica, both configured with update_config using parallelism: 1 and order: start-first. Implement label-based routing through a front-door proxy that directs traffic to the canary based on service labels. Monitor health checks and promote the canary by updating the production service image after validation.","explanation":"## Why This Is Asked\nTests practical canary deployment strategies across distributed infrastructure with stateful dependencies (Redis rate limiter, shared cache) and intelligent traffic routing. Evaluates understanding of Swarm's update_config mechanics and health-driven promotion workflows.\n\n## Key Concepts\n- Docker Swarm update_config with start-first ordering\n- Canary deployment patterns and traffic splitting\n- Multi-datacenter overlay networking\n- Health check-based promotion strategies\n- Label-based service routing\n\n## Code Example\n```yaml\nversion: \"3.8\"\nservices:\n api:\n   image: myapi:2.0\n   deploy:\n     replicas: 3\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=production\"\n   networks:\n     - front\n   healthcheck:\n     test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n     interval: 30s\n     timeout: 10s\n     retries: 3\n canary:\n   image: myapi:2.0-canary\n   deploy:\n     replicas: 1\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=canary\"\n   networks:\n     - front\n redis:\n   image: redis:alpine\n   deploy:\n     replicas: 1\n   networks:\n     - front\nnetworks:\n front:\n   driver: overlay\n   attachable: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:40:42.873Z","createdAt":"2026-01-14T22:40:23.213Z"},{"id":"q-2120","question":"In a two-node Swarm, deploy a TLS-secured stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API settings, and a small sidecar that ships logs without affecting requests. Attach both services to a single overlay network and perform a canary upgrade with a rolling update (start-first, parallelism 1). Provide exact commands and a docker-compose.yml skeleton?","answer":"Initialize the Swarm cluster on node A with `docker swarm init --advertise-addr <IP1>`, then join node B using `docker swarm join --token <SWMTKN...> <IP1>:2377`. Create the overlay network with `docker network create -d overlay prod-net`.","explanation":"## Why This Is Asked\nThis question assesses practical mastery of Docker Swarm, including secrets management, overlay networking, and zero-downtime deployments through rolling updates.\n\n## Key Concepts\n- Swarm initialization and multi-node clustering\n- Overlay network creation and service attachment\n- Docker secrets and configs for secure configuration management\n- Rolling updates with health checks and canary-style deployments\n- Sidecar pattern for non-blocking log shipping\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  proxy:\n    image: nginx:alpine\n    ports:\n      - '443:443'\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n  api:\n    image: my-api:latest\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n  log-shipper:\n    image: log-shipper:latest\n    networks: [ prod-net ]\n    depends_on: [ api ]\n```\n\n## Additional Commands\n```bash\n# Create secrets\necho \"cert-content\" | docker secret create tls_cert -\necho \"key-content\" | docker secret create tls_key -\n\n# Create config\necho \"app-settings\" | docker config create app_config -\n\n# Deploy stack\ndocker stack deploy -c docker-compose.yml myapp\n```","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create overlay net]\n  B --> C[Create secrets/configs]\n  C --> D[Stack deploy]\n  D --> E[Canary upgrade]\n  E --> F[Promote canary]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:53:30.558Z","createdAt":"2026-01-15T02:28:35.499Z"},{"id":"q-2140","question":"In a two-datacenter Docker Swarm (2 nodes per DC), deploy a stateless API behind Traefik with TLS termination on an overlay network across DCs. Implement a canary rollout for a feature-flag change using a Swarm Config and route 10% of traffic to canary via Traefik labels. Outline exact swarm init/join commands, overlay creation, stack deploys, config creation, and the canary upgrade with health checks and rollback criteria?","answer":"Plan: Bring up both DCs as a single swarm, create an attachable overlay, deploy Traefik with TLS via Docker secrets, create a Swarm Config with the feature flag, launch two API stacks (prod and canary","explanation":"## Why This Is Asked\nTests cross-datacenter orchestration, canary traffic, and secret/config handling with Traefik in Swarm across DCs.\n\n## Key Concepts\n- Docker Swarm multi-DC overlay networking\n- Traefik dynamic routing and weights for canaries\n- Swarm Config vs Secret for feature flags\n- Health checks and safe rollback strategies\n\n## Code Example\n```bash\n# Swarm init (DC1)\ndocker swarm init --advertise-addr <dc1-ip>\n# Join DC2\n# docker swarm join ...\n\n\ndocker network create -d overlay --attachable traefik-net\n# Deploy Traefik with TLS secret and config-driven routes\n# ...\n```\n\n## Follow-up Questions\n- How would you test the rollover window and rollback boundaries?\n- How would you monitor traffic split and auto-promote canary on success?","diagram":"flowchart TD\nA[Two-DC Swarm] --> B[Overlay Network]\nB --> C[Traefik TLS]\nC --> D[Prod API]\nC --> E[Canary API]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:20:30.901Z","createdAt":"2026-01-15T04:20:30.901Z"},{"id":"q-856","question":"You're running a Docker Swarm with services frontend, api, and worker. A feature-flag config is provided via Docker Config mounted at /etc/flags.json in all containers. You must rotate this config weekly with zero downtime. Describe the exact sequence of commands to create a new config version, rotate the services to use it, and implement a graceful reload inside apps so the new flags are picked up without losing requests. Include any Swarm update options you would tune?","answer":"Create a new config file (e.g., /tmp/flags.v2.json) and docker config create flags.v2 /tmp/flags.v2.json. Then update each service: docker service update --config-rm flags.v1 --config-add flags.v2 --u","explanation":"## Why This Is Asked\nTo assess practical config rotation in Swarm and application reload behavior.\n\n## Key Concepts\n- Docker Config rotation\n- Rolling updates with update-parallelism and update-delay\n- Graceful reload semantics (SIGHUP or /reload)\n\n## Code Example\n```javascript\n// Node.js reload handler\nconst fs = require('fs');\nlet flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\nprocess.on('SIGHUP', () => {\n  flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\n  // apply flags to runtime features\n});\n```\n\n## Follow-up Questions\n- How would you test the zero-downtime rollout in a CI pipeline?\n- What failure scenarios would prompt you to revert the config rotation?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:38:40.484Z","createdAt":"2026-01-12T13:38:40.484Z"},{"id":"q-862","question":"In a Docker Swarm with a stateful web app that uses Postgres, you must roll out version 3.2 with a DB schema migration and zero downtime. Propose a concrete upgrade plan that uses a start-first, one-task-at-a-time update, a separate migration container, and post-migration validation. Include exact Swarm commands and a minimal docker-compose snippet showing update_config?","answer":"Plan: run DB migration first in a dedicated one-off container, then perform a start-first, one-task-at-a-time web upgrade. Commands: docker run --rm --network swarm_net migrate:3.2; docker service upd","explanation":"## Why This Is Asked\nAssesses ability to coordinate schema migrations with zero downtime, manage Swarm update strategies, and handle rollback safely.\n\n## Key Concepts\n- Start-first updates and parallelism control\n- Separate migration container orchestration\n- Post-migration validation and rollback\n- Health checks and observability during upgrade\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  web:\n    image: myapp:3.2\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 15s\n        order: start-first\n```\n\n## Follow-up Questions\n- How would you handle long-running migrations?\n- How ensure data consistency with read replicas during upgrade?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:43:29.032Z","createdAt":"2026-01-12T13:43:29.032Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Bloomberg","Cloudflare","Databricks","Discord","DoorDash","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Meta","Microsoft","MongoDB","Netflix","PayPal","Salesforce","Scale Ai","Snowflake","Stripe","Tesla","Twitter","Two Sigma","Zoom"],"stats":{"total":19,"beginner":6,"intermediate":5,"advanced":8,"newThisWeek":19}}