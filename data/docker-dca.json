{"questions":[{"id":"q-1392","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API across an overlay network and ensure zero-downtime upgrades via canary, using update_config (start-first, parallelism 1). Outline the exact sequence of commands to init/join the swarm, create the overlay, deploy the service with update settings, and perform a canary upgrade with health checks. Include a minimal docker-compose snippet showing update_config?","answer":"Init swarm on node A: docker swarm init --advertise-addr <A>; join B/C: docker swarm join --token <tok> <A>:2377; overlay: docker network create -d overlay --attachable app-net; deploy: docker service","explanation":"## Why This Is Asked\nTests practical mastery of Swarm lifecycle, overlay networking, and zero-downtime upgrades in multi-datacenter setups.\n\n## Key Concepts\n- Docker Swarm init/join and multi-datacenter networking\n- Overlay networks and service deployment in Swarm\n- update_config for canary upgrades and health checks\n\n## Code Example\n```docker-compose\nversion: '3.8'\nservices:\n  api:\n    image: nginx:stable\n    networks:\n      - app-net\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\nnetworks:\n  app-net:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you handle service traffic shifting for canary without external LB?\n- What are failure_action and monitor thresholds used for in update_config?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Cloudflare","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:52:07.307Z","createdAt":"2026-01-13T14:52:07.307Z"},{"id":"q-1412","question":"Scenario: youâ€™re building a beginner-friendly Docker Compose setup for a FastAPI microservice with PostgreSQL on a single host. Create Dockerfiles for the app and an init script, plus a docker-compose.yml with a named volume for Postgres data, healthchecks, and a startup script that waits for PostgreSQL on port 5432 before starting the app. Explain the exact files, commands, and deployment sequence?","answer":"I would dockerize the FastAPI app with Python 3.11, add a Postgres container, and provide a docker-compose.yml with services app and db, a named volume pgdata, environment vars, and healthchecks. Incl","explanation":"## Why This Is Asked\nTests practical Docker Compose skills: multi-service setup, data persistence, healthchecks, startup dependencies.\n\n## Key Concepts\n- Dockerfile basics, Python 3.11\n- Postgres container with pgdata volume\n- docker-compose networks/depends_on healthchecks\n- wait-for-it pattern for DB readiness\n\n## Code Example\n```yaml\n# docker-compose.yaml (excerpt)\nversion: '3.9'\nservices:\n  app:\n    build: ./app\n    ports:\n      - '8000:8000'\n    depends_on:\n      - db\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      retries: 5\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: example\n    volumes:\n      - pgdata:/var/lib/postgresql/data\nvolumes:\n  pgdata:\n    name: pgdata\n```\n\n## Follow-up Questions\n- How would you add a migration step to initialize schemas?\n- How would you scale this with separate networks or secrets management?","diagram":"flowchart TD\nA[Developer writes app] --> B[Build Dockerfile]\nB --> C[Create docker-compose.yaml]\nC --> D[Start stack with docker compose up -d]\nD --> E[Healthchecks verify readiness]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:51:50.736Z","createdAt":"2026-01-13T15:51:50.737Z"},{"id":"q-1443","question":"In a 3-node Swarm across DC-A and DC-B, deploy a stateless API via overlay api-net with DC-affinity (2 replicas in DC-A and 1 in DC-B). Outline the exact CLI steps to init/join, create the overlay, and deploy two services with update_config (order: start-first, parallelism: 1). Describe a canary upgrade process that gradually updates replicas across DCs and validates with health checks. Include a minimal docker-compose snippet showing the two services, the overlay network, and update_config?","answer":"Init Swarm on DC-A; join DC-B; create overlay api-net; deploy two services: api-dcA with 2 replicas constrained to DC-A and api-dcB with 1 replica constrained to DC-B, both on api-net and update_confi","explanation":"## Why This Is Asked\nTests cross-DC orchestration, DC-aware placement, and canary upgrades using Docker Swarm update_config.\n\n## Key Concepts\n- Overlay networks spanning DCs\n- Placement constraints and spread/preference for DC distribution\n- update_config for staged upgrades\n- Canary rollout and health-check driven promotion\n\n## Code Example\n```javascript\nversion: \"3.8\"\nservices:\n  api-dcA:\n    image: myapi:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-A\n      networks:\n        - api-net\n  api-dcB:\n    image: myapi:latest\n    deploy:\n      replicas: 1\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-B\n      networks:\n        - api-net\nnetworks:\n  api-net:\n```\n\n## Follow-up Questions\n- How would you monitor canary success across DCs and automate rollback if latency spikes? \n- How would you adapt this for a rolling upgrade with multiple versions concurrently?","diagram":"flowchart TD\n  A[Init Swarm in DC-A] --> B[Join DC-B]\n  B --> C[Create overlay api-net]\n  C --> D[Deploy two services with update_config]\n  D --> E[Canary rollout across DCs]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:34:28.800Z","createdAt":"2026-01-13T17:34:28.803Z"},{"id":"q-1530","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API with TLS termination that uses Vault for dynamic TLS certificate rotation. Use Docker secrets to distribute certs, and implement a lightweight sidecar that refreshes certificates without dropping connections. Configure a canary-style rolling upgrade ensuring zero-downtime during cert rotations. Outline the exact steps: swarm init/join, overlay network creation, stack/deploy with secret handling, and the certificate rotation workflow with health checks?","answer":"Plan: initialize a 3-node Docker Swarm across two data centers, create an overlay network, deploy a stack with API and sidecar containers, mount Vault-issued certificates as Docker secrets and rotate them via the sidecar without container restarts, and perform a canary-style rolling upgrade ensuring zero-downtime during certificate rotations.","explanation":"## Why This Is Asked\nTests multi-datacenter Docker Swarm setup, TLS automation with HashiCorp Vault, Docker secrets management, and zero-downtime deployment strategies.\n\n## Key Concepts\n- Docker Swarm spanning multiple data centers\n- Docker secrets with external secret management (Vault)\n- Sidecar pattern for live certificate rotation\n- Update configuration with start-first for zero-downtime upgrades\n- Health checks and canary rollout strategies\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  api:\n    image: myorg/api:latest\n    ports:\n      - \"80:80\"\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n      healthcheck:\n        test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:80/health\"]\n        interval: 30s\n        timeout: 10s\n        retries: 3\n  sidecar:\n    image: myorg/cert-rotator:latest\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n      - source: vault_token\n        target: vault.token\n    deploy:\n      replicas: 1\nsecrets:\n  tls_cert:\n    external: true\n  vault_token:\n    external: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:10:39.873Z","createdAt":"2026-01-13T20:46:17.744Z"},{"id":"q-1579","question":"Design a secret-rotation workflow for a Docker Swarm stack that uses Vault to rotate a TLS cert and a database credential with zero downtime. Use Swarm secrets and a rolling update (start-first). Outline exact steps: swarm init/join, overlay network, create secrets, deploy stack, Vault rotate trigger, service update commands. Include a minimal docker-compose snippet showing secret usage and update_config?","answer":"Plan: Vault issues new TLS certificate and database credential; create new Swarm secrets (e.g., api-tls-v2, db-cred-v2); perform service updates with `docker service update --secret-add` then `--secret-rm`, using update_config with start-first strategy for zero downtime.\n\n## Implementation Steps\n\n1. **Initialize Swarm cluster**\n   ```bash\n   docker swarm init --advertise-addr <MANAGER-IP>\n   docker swarm join --token <TOKEN> <MANAGER-IP>:2377\n   ```\n\n2. **Create overlay network**\n   ```bash\n   docker network create --driver overlay --attachable app-network\n   ```\n\n3. **Create initial secrets from Vault**\n   ```bash\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v1 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v1 -\n   ```\n\n4. **Deploy stack with rolling update configuration**\n   ```yaml\n   version: '3.8'\n   services:\n     api:\n       image: myapp:latest\n       secrets:\n         - source: api-tls-v1\n           target: /app/tls.crt\n         - source: db-cred-v1\n           target: /app/db-cred\n       networks:\n         - app-network\n       update_config:\n         parallelism: 1\n         delay: 10s\n         order: start-first\n       healthcheck:\n           test: [\"CMD\", \"curl\", \"-f\", \"https://localhost:8443/health\"]\n           interval: 30s\n           timeout: 10s\n           retries: 3\n   ```\n\n5. **Vault rotation trigger**\n   - Vault generates new TLS certificate and database credential\n   - Automation script detects rotation event\n\n6. **Service update with new secrets**\n   ```bash\n   # Create new secret versions\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v2 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v2 -\n   \n   # Update service to add new secrets\n   docker service update api \\\n     --secret-add source=api-tls-v2,target=/app/tls.crt \\\n     --secret-add source=db-cred-v2,target=/app/db-cred\n   \n   # Remove old secrets after health checks pass\n   docker service update api \\\n     --secret-rm api-tls-v1 \\\n     --secret-rm db-cred-v1\n   ```","explanation":"## Why This Is Asked\nDemonstrates practical secret lifecycle management in Docker Swarm, integrating Vault for automated rotation with zero-downtime upgrades and proper secret versioning.\n\n## Key Concepts\n- Swarm secrets versioning and dynamic reattachment\n- Vault-based rotation triggers and secret provisioning\n- Rolling updates with start-first strategy to avoid downtime\n- Health checks to confirm new secrets are loaded before removing old ones\n- Atomic secret updates using add-then-remove pattern\n\n## Code Example\n```javascript\n// Pseudo-automation: rotate Vault-derived Swarm secrets\nasync function rotateSecrets(serviceName, vaultPath) {\n  // Fetch new credentials from Vault\n  const newCreds = await vault.read(vaultPath);\n  \n  // Create new Swarm secrets\n  const newSecrets = await createSwarmSecrets(newCreds);\n  \n  // Update service with new secrets\n  await updateService(serviceName, newSecrets);\n  \n  // Verify health before cleanup\n  await verifyServiceHealth(serviceName);\n  \n  // Remove old secrets\n  await cleanupOldSecrets(serviceName);\n}\n```","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:56:17.721Z","createdAt":"2026-01-13T22:45:30.688Z"},{"id":"q-1628","question":"Scenario: In a 3-node Swarm across two DCs, deploy an API service behind Traefik with image signing enforcement (cosign/DOCKER_CONTENT_TRUST) and implement a canary upgrade to v2 with a 10% traffic split via a separate api-v2-canary service. Outline exact commands, Swarm update_config usage, and docker-compose/service definitions to achieve zero-downtime upgrade and safe rollback?","answer":"Enable Docker Content Trust and cosign signing on all nodes (DOCKER_CONTENT_TRUST=1; cosign sign). Deploy api-v1 and a canary api-v2-canary behind Traefik with a 10% canary route. Use update_config { ","explanation":"## Why This Is Asked\nEvaluates image provenance, canary sequencing, and Swarm upgrade semantics in a multi-datacenter setup.\n\n## Key Concepts\n- Image signing with cosign and DOCKER_CONTENT_TRUST\n- Swarm update_config for controlled upgrades\n- Traffic splitting via an in-cluster reverse proxy (Traefik)\n- Canary pattern and safe rollback in production\n\n## Code Example\n```javascript\n// illustrative docker-compose-like snippet (Traefik routing hints)\nservices:\n  api-v1:\n    image: registry.example.com/api:v1\n    deploy:\n      replicas: 4\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v1.rule=Host(`api.example.com` )\"\n  api-v2-canary:\n    image: registry.example.com/api:v2-canary\n    deploy:\n      replicas: 1\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v2-canary.rule=Host(`canary.api.example.com` )\"\n```\n\n## Follow-up Questions\n- How would key rotation and automatic signing verification be automated?\n- How would you measure canary health and decide promotion/rollback automatically?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:16:19.227Z","createdAt":"2026-01-14T04:16:19.227Z"},{"id":"q-1653","question":"Scenario: On a single host, implement a beginner-friendly Docker Compose stack: a Node.js API that talks to Redis and a Fluent Bit logging service that reads logs from the API via a shared volume and forwards them to stdout. Provide a Dockerfile for the API, a docker-compose.yml with api, redis, fluent-bit, a logs volume, and healthchecks; explain the run steps and verification?","answer":"Create a docker-compose.yml with api, redis, and fluent-bit services on one host, plus a shared logs volume. The API writes to /var/log/app/app.log; Fluent Bit tails that file and forwards to stdout. ","explanation":"## Why This Is Asked\nTests practical docker-compose discipline: multi-service coordination, logging discipline, and health checks.\n\n## Key Concepts\n- docker-compose multi-service orchestration\n- log aggregation with Fluent Bit\n- log file sharing via volumes\n- minimal health checks for API service\n\n## Code Example\n```dockerfile\n# Dockerfile for API\nFROM node:18\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD node server.js\n```\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  api:\n    build: ./api\n    depends_on:\n      - redis\n    environment:\n      - REDIS_URL=redis://redis:6379\n    healthcheck:\n      test: curl -f http://localhost:3000/health || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - ./logs:/var/log/app\n  redis:\n    image: redis:7\n  fluent-bit:\n    image: fluent/fluent-bit:1.9\n    volumes:\n      - ./logs:/var/log/app\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf\n    depends_on:\n      - api\n```\n\n## Follow-up Questions\n- How would you extend this to ship logs to an external system\n- How would you ensure log retention and rotate the log files","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Instacart","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:35:42.804Z","createdAt":"2026-01-14T05:35:42.804Z"},{"id":"q-1688","question":"Beginner-level: design a local docker-compose stack for a Node.js API that uses Redis as a cache. Provide a Dockerfile for the API, a startup script that waits for Redis to be reachable on 6379 before starting, and a docker-compose.yml with healthchecks for both services on a shared network. Include exact file contents or minimal snippets, the commands to build and run, and how to validate a cache-hit endpoint?","answer":"Build a Node.js API image with a Dockerfile, and a start script wait-for-redis.sh that pings redis:6379 until ready, then runs node index.js. In docker-compose.yml, define services api and redis on a ","explanation":"Why This Is Asked\nTests ability to coordinate container startup and readiness in Compose using a startup gate and healthchecks.\n\nKey Concepts\n- Dockerfile for Node.js\n- startup gating with a wait script\n- docker-compose healthchecks\n- Docker networking and service discovery\n\nCode Example\n```javascript\n# Dockerfile\nFROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\n# Start directly with node (no quotes) for simplicity\nCMD node index.js\n```\n```javascript\n# wait-for-redis.sh (simplified)\nuntil nc -z  redis 6379; do\n  sleep 0.2\ndone\nexec \"$@\"\n```\n```javascript\n# docker-compose.yml\nversion: '3.9'\nservices:\n  api:\n    build: .\n    ports:\n      - 3000:3000\n    depends_on:\n      - redis\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    command: [\"sh\",\"/wait-for-redis.sh\",\"redis\",\"node\",\"index.js\"]\n  redis:\n    image: redis:7-alpine\n    ports:\n      - 6379:6379\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\nnetworks:\n  default:\n    name: appnet\n```\n\nFollow-up Questions\n- How would you adapt for an optional Redis cache with a fallback?\n- How would you test failure of Redis and verify API behavior?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","MongoDB","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:58:39.175Z","createdAt":"2026-01-14T06:58:39.175Z"},{"id":"q-1760","question":"In a three-node Docker Swarm spanning two data centers, introduce a new internal auth service that all APIs depend on. Roll it out with zero downtime and a canary, using update_config (start-first, parallelism 1), Docker Secrets, and a routing shim. Provide exact commands to init/join the swarm, create the overlay, deploy the stack, add the secret, and perform the canary upgrade with health checks?","answer":"Two-stage canary: deploy auth-v2 with 1 replica and route 5% of traffic to it; ensure health checks pass; then roll the main stack with update_config start-first, parallelism 1. Commands: docker swarm","explanation":"## Why This Is Asked\nRealistic multi-datacenter upgrades require controlled rollouts with canary, health checks, and secrets. This tests operational discipline and deep Docker Swarm knowledge.\n\n## Key Concepts\n- Swarm upgrades with update_config; - Canaries across regions; - Secrets management; - Overlay networking; - Health checks and rollback.\n\n## Code Example\n```javascript\nversion: '3.8'\nservices:\n  auth:\n    image: myrepo/auth:canary\n    secrets:\n      - source: auth-secret\n        target: /etc/auth/secret.json\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nsecrets:\n  auth-secret:\n    external: true\n```\n\n## Follow-up Questions\n- How would you automate canary traffic routing without a reverse proxy? \n- How would you verify no active sessions are dropped during promotion?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:46:53.036Z","createdAt":"2026-01-14T09:46:53.036Z"},{"id":"q-1786","question":"In a 3-node Docker Swarm spanning two data centers, deploy a GPU-accelerated model-serving API (TorchServe) using the NVIDIA runtime. Expose it behind an internal overlay network and a simple LB. Ensure zero-downtime upgrades with canary traffic shifts and a pre-warm sidecar to warm the new replica without serving traffic. Outline the steps for swarm init/join, overlay creation, service spec with GPU constraints, secret handling, and a separate migration container if needed. Include a minimal docker-compose snippet showing update_config (start-first, parallelism 1)?","answer":"Outline a GPU-enabled TorchServe deployment on a 3-node Swarm across 2 DCs. Use NVIDIA runtime and a service with GPU constraint (nvidia.com/gpu=1). Implement canary upgrades: deploy 1 new replica, ru","explanation":"## Why This Is Asked\nTests ability to orchestrate GPU-enabled deployments across DCs, implement safe upgrades, and coordinate sidecar pre-warming with a migration task.\n\n## Key Concepts\n- GPU scheduling in Swarm with NVIDIA runtime\n- Overlay networks across data centers\n- Canary rollout using update_config (start-first, single-threaded)\n- Sidecar pre-warm pattern for zero-downtime\n- Migration container for schema/model updates\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  model:\n    image: myorg/torchserve:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities:\n                -gpu\n                  count: 1\n```\n\n## Follow-up Questions\n- How would you monitor GPU utilization across nodes?\n- How would you handle model/version rollback in a canary rollout?","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create Overlay Network]\n  B --> C[Deploy TorchServe with NVIDIA runtime]\n  C --> D[Canary Upgrade: 1 new replica]\n  D --> E[Health Checks & Traffic Shift]\n  E --> F[Promote & Cleanup]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:48:28.317Z","createdAt":"2026-01-14T10:48:28.317Z"},{"id":"q-856","question":"You're running a Docker Swarm with services frontend, api, and worker. A feature-flag config is provided via Docker Config mounted at /etc/flags.json in all containers. You must rotate this config weekly with zero downtime. Describe the exact sequence of commands to create a new config version, rotate the services to use it, and implement a graceful reload inside apps so the new flags are picked up without losing requests. Include any Swarm update options you would tune?","answer":"Create a new config file (e.g., /tmp/flags.v2.json) and docker config create flags.v2 /tmp/flags.v2.json. Then update each service: docker service update --config-rm flags.v1 --config-add flags.v2 --u","explanation":"## Why This Is Asked\nTo assess practical config rotation in Swarm and application reload behavior.\n\n## Key Concepts\n- Docker Config rotation\n- Rolling updates with update-parallelism and update-delay\n- Graceful reload semantics (SIGHUP or /reload)\n\n## Code Example\n```javascript\n// Node.js reload handler\nconst fs = require('fs');\nlet flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\nprocess.on('SIGHUP', () => {\n  flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\n  // apply flags to runtime features\n});\n```\n\n## Follow-up Questions\n- How would you test the zero-downtime rollout in a CI pipeline?\n- What failure scenarios would prompt you to revert the config rotation?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:38:40.484Z","createdAt":"2026-01-12T13:38:40.484Z"},{"id":"q-862","question":"In a Docker Swarm with a stateful web app that uses Postgres, you must roll out version 3.2 with a DB schema migration and zero downtime. Propose a concrete upgrade plan that uses a start-first, one-task-at-a-time update, a separate migration container, and post-migration validation. Include exact Swarm commands and a minimal docker-compose snippet showing update_config?","answer":"Plan: run DB migration first in a dedicated one-off container, then perform a start-first, one-task-at-a-time web upgrade. Commands: docker run --rm --network swarm_net migrate:3.2; docker service upd","explanation":"## Why This Is Asked\nAssesses ability to coordinate schema migrations with zero downtime, manage Swarm update strategies, and handle rollback safely.\n\n## Key Concepts\n- Start-first updates and parallelism control\n- Separate migration container orchestration\n- Post-migration validation and rollback\n- Health checks and observability during upgrade\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  web:\n    image: myapp:3.2\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 15s\n        order: start-first\n```\n\n## Follow-up Questions\n- How would you handle long-running migrations?\n- How ensure data consistency with read replicas during upgrade?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:43:29.032Z","createdAt":"2026-01-12T13:43:29.032Z"}],"subChannels":["general"],"companies":["Airbnb","Amazon","Bloomberg","Cloudflare","Databricks","DoorDash","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Meta","MongoDB","Netflix","PayPal","Salesforce","Scale Ai","Snowflake","Stripe","Tesla","Two Sigma"],"stats":{"total":12,"beginner":4,"intermediate":3,"advanced":5,"newThisWeek":12}}