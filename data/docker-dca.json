{"questions":[{"id":"docker-dca-image-creation-1768206789900-0","question":"When building a production Docker image for a microservice, which approach minimizes final image size while preserving build cache and readability?","answer":"[{\"id\":\"a\",\"text\":\"Use a multi-stage build and copy only the final binary to a minimal base image\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Use a single-stage build with the full toolchain to simplify the Dockerfile\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Install build tools in the final image to ensure reproducibility\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Pin the base image tag to latest to receive security updates automatically\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nThe correct option is a because using a multi-stage build reduces the final image size by excluding the build tools and intermediate artifacts from the runtime image.\n\n## Why Other Options Are Wrong\n\n- Option B: Using a single-stage build with the full toolchain would bloat the final image and hamper caching.\n- Option C: Installing build tools in the final image defeats the purpose of a minimal runtime image.\n- Option D: Pinning the base image tag to latest leads to non-deterministic builds and potential drift.\n\n## Key Concepts\n\n- Multi-stage builds\n- Minimal runtime images\n- Build cache optimization\n\n## Real-World Application\n\nEmploy multi-stage builds in CI pipelines to produce lean images, speeding deployments and reducing attack surface.","diagram":null,"difficulty":"intermediate","tags":["Docker","ECR","EKS","Terraform","certification-mcq","domain-weight-20"],"channel":"docker-dca","subChannel":"image-creation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:33:09.901Z","createdAt":"2026-01-12 08:33:10"},{"id":"docker-dca-image-creation-1768206789900-1","question":"To ensure that only signed images are deployed to a private registry, which practice should you implement?","answer":"[{\"id\":\"a\",\"text\":\"Disable content trust and rely on registry access controls\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable Docker Content Trust and sign images with Notary before pushing\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Sign images only after deployment using runtime attestation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use an external script to verify checksums after pulling images\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption B is correct because Docker Content Trust signs images using Notary, ensuring only signed images are deployed.\n\n## Why Other Options Are Wrong\n\n- Option A: Disabling content trust removes integrity guarantees and undermines deployment policies.\n- Option C: Runtime attestation is not the standard mechanism for enforcing signed images at push time.\n- Option D: Verifying checksums after pulling does not enforce signing and provenance at build/push time.\n\n## Key Concepts\n\n- Docker Content Trust\n- Notary\n- Image signing\n\n## Real-World Application\n\nImplements policy enforcement in CI/CD workflows, preventing untrusted images from reaching production registries.","diagram":null,"difficulty":"intermediate","tags":["Docker","ECR","Kubernetes","Terraform","certification-mcq","domain-weight-20"],"channel":"docker-dca","subChannel":"image-creation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:33:10.341Z","createdAt":"2026-01-12 08:33:10"},{"id":"docker-dca-image-creation-1768206789900-2","question":"Your private registry is growing and stale images consume storage. Which approach is recommended to reclaim space in a Docker Registry V2 when artifacts are unreferenced by any tag or digest?","answer":"[{\"id\":\"a\",\"text\":\"Run registry garbage collection with the garbage-collect tool to reclaim unreferenced blobs\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Manually delete blobs from the registry's filesystem\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use docker image prune on the registry host\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Set a hard limit on repository size and purge via cron job\",\"isCorrect\":false}]","explanation":"## Correct Answer\n\nOption A is correct because registry garbage collection reclaims unreferenced blobs and cleans up space; manual deletion can corrupt blob storage; docker image prune operates on the host, not the registry storage; hard limits with cron pose data loss risks.\n\n## Why Other Options Are Wrong\n\n- Option B: Manually deleting blobs is error-prone and not scalable.\n- Option C: Docker image prune affects only the host daemon, not the registry storage.\n- Option D: Hard limits risk data loss and are not a robust cleanup strategy.\n\n## Key Concepts\n\n- Registry garbage collection\n- Unreferenced blobs\n- Blob storage lifecycle\n\n## Real-World Application\n\nKeeps private registries lean by reclaiming storage as images become unreferenced, reducing storage costs and ensuring cleaner artifact management.","diagram":null,"difficulty":"intermediate","tags":["Docker","ECR","Kubernetes","Terraform","certification-mcq","domain-weight-20"],"channel":"docker-dca","subChannel":"image-creation","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T08:33:10.747Z","createdAt":"2026-01-12 08:33:10"},{"id":"docker-dca-orchestration-1768169949801-0","question":"In Docker Swarm, which approach best achieves a rolling update with at most two updated tasks at a time and a ten-second delay between updates, while minimizing downtime?","answer":"[{\"id\":\"a\",\"text\":\"docker service update --update-parallelism 2 --update-delay 10s <service>\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"docker stack deploy --compose-file docker-compose.yaml <stack>\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"docker service update --update-parallelism 3 --update-delay 10s <service>\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"docker service update --update-order start-first --update-parallelism 2 --update-delay 10s <service>\",\"isCorrect\":true}]","explanation":"## Correct Answer\n**Option D**\n\nThe best approach explicitly sets the update order to start-first, ensuring new tasks come up before old ones are stopped, which minimizes downtime. It also enforces a maximum of two simultaneous updates and a 10s delay between updates via --update-parallelism 2 and --update-delay 10s.\n\n```javascript\n# Example (illustrative only):\ndocker service update --update-order start-first --update-parallelism 2 --update-delay 10s my_web_service\n```\n\n## Why Other Options Are Wrong\n- A: Lacks an explicit update-order, so it may follow the default stop-first behavior which can increase downtime.\n- B: Deploys a new stack rather than performing an in-place update of an existing service.\n- C: Uses a higher parallelism (3), violating the requirement of at most two concurrent updates.\n\n## Key Concepts\n- docker service update options: --update-parallelism, --update-delay, --update-order\n- Update order semantics: start-first minimizes downtime; stop-first is safer but can cause longer downtime\n\n## Real-World Application\n- Precise rollout controls in production Swarm clusters reduce risk during deployments.","diagram":null,"difficulty":"intermediate","tags":["Docker","Kubernetes","Terraform","Orchestration","certification-mcq","domain-weight-25"],"channel":"docker-dca","subChannel":"orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:09.803Z","createdAt":"2026-01-11 22:19:10"},{"id":"docker-dca-orchestration-1768169949801-1","question":"You want to securely provide a database password to all replicas of a service in a Swarm cluster. Which approach is correct?","answer":"[{\"id\":\"a\",\"text\":\"Pass the password as an environment variable in the service spec\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a Docker secret named db_password and attach it to the service; read from /run/secrets/db_password\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store the password in a mounted file on the host and read it from the container\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a Kubernetes ConfigMap to inject the password\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**Option B**\n\nDocker secrets provide encrypted storage and are mounted into containers at /run/secrets/<secret_name>, and only to the services that are granted the secret. This avoids plaintext environment variables and keeps credentials out of image layers.\n\n```bash\n# Example conceptually (secret creation and attach):\ndocker secret create db_password password.txt\ndocker service update --secret-add db_password my_db_service\n```\n\n## Why Other Options Are Wrong\n- A: Environment variables can leak via process listing and are stored in container metadata and image layers.\n- C: Host-mounted files are not managed by Swarm and can be less secure and harder to rotate.\n- D: Configs are for non-secret data; they are not ideal for sensitive credentials.\n\n## Key Concepts\n- Docker Secrets\n- /run/secrets/<name> access path\n- Service-level access control for secrets\n\n## Real-World Application\n- Centralized secret management for database credentials in a Swarm cluster, enabling secure rotation and restricted access.","diagram":null,"difficulty":"intermediate","tags":["Docker","Kubernetes","Terraform","Orchestration","certification-mcq","domain-weight-25"],"channel":"docker-dca","subChannel":"orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:10.273Z","createdAt":"2026-01-11 22:19:10"},{"id":"docker-dca-orchestration-1768169949801-2","question":"Which statement best reflects autoscaling capabilities in Docker Swarm for a service based on CPU utilization?","answer":"[{\"id\":\"a\",\"text\":\"Docker Swarm provides built-in autoscaling based on CPU via an HPA-like feature\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Autoscaling can be achieved automatically by Swarm when CPU usage spikes\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"There is no built-in autoscaling in Swarm; external tooling or custom scripts are required to adjust replicas based on metrics\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Swarm automatically scales across nodes when there is a single failed node\",\"isCorrect\":false}]","explanation":"## Correct Answer\n**Option C**\n\nDocker Swarm does not include built-in autoscaling based on metrics. To auto-scale, you typically integrate external monitoring/automation (e.g., custom scripts, external schedulers) that adjust the replica count via the Docker API or CLI.\n\n## Why Other Options Are Wrong\n- A: Swarm lacks an HPA-like autoscaler comparable to Kubernetes.\n- B: Swarm does not automatically scale purely on CPU without external tooling.\n- D: Swarm does not auto-scale on node failures by default.\n\n## Key Concepts\n- Lack of native autoscaling in Swarm\n- External autoscaling approaches (external monitors, scripts, API calls)\n\n## Real-World Application\n- Implementing a monitoring-based scaler to maintain desired replica counts in response to load in a Swarm cluster.","diagram":null,"difficulty":"intermediate","tags":["Docker","Kubernetes","Terraform","Orchestration","certification-mcq","domain-weight-25"],"channel":"docker-dca","subChannel":"orchestration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T22:19:10.736Z","createdAt":"2026-01-11 22:19:10"}],"subChannels":["image-creation","orchestration"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}