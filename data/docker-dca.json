{"questions":[{"id":"q-1392","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API across an overlay network and ensure zero-downtime upgrades via canary, using update_config (start-first, parallelism 1). Outline the exact sequence of commands to init/join the swarm, create the overlay, deploy the service with update settings, and perform a canary upgrade with health checks. Include a minimal docker-compose snippet showing update_config?","answer":"Init swarm on node A: docker swarm init --advertise-addr <A>; join B/C: docker swarm join --token <tok> <A>:2377; overlay: docker network create -d overlay --attachable app-net; deploy: docker service","explanation":"## Why This Is Asked\nTests practical mastery of Swarm lifecycle, overlay networking, and zero-downtime upgrades in multi-datacenter setups.\n\n## Key Concepts\n- Docker Swarm init/join and multi-datacenter networking\n- Overlay networks and service deployment in Swarm\n- update_config for canary upgrades and health checks\n\n## Code Example\n```docker-compose\nversion: '3.8'\nservices:\n  api:\n    image: nginx:stable\n    networks:\n      - app-net\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\nnetworks:\n  app-net:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you handle service traffic shifting for canary without external LB?\n- What are failure_action and monitor thresholds used for in update_config?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Cloudflare","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T14:52:07.307Z","createdAt":"2026-01-13T14:52:07.307Z"},{"id":"q-1412","question":"Scenario: you’re building a beginner-friendly Docker Compose setup for a FastAPI microservice with PostgreSQL on a single host. Create Dockerfiles for the app and an init script, plus a docker-compose.yml with a named volume for Postgres data, healthchecks, and a startup script that waits for PostgreSQL on port 5432 before starting the app. Explain the exact files, commands, and deployment sequence?","answer":"I would dockerize the FastAPI app with Python 3.11, add a Postgres container, and provide a docker-compose.yml with services app and db, a named volume pgdata, environment vars, and healthchecks. Incl","explanation":"## Why This Is Asked\nTests practical Docker Compose skills: multi-service setup, data persistence, healthchecks, startup dependencies.\n\n## Key Concepts\n- Dockerfile basics, Python 3.11\n- Postgres container with pgdata volume\n- docker-compose networks/depends_on healthchecks\n- wait-for-it pattern for DB readiness\n\n## Code Example\n```yaml\n# docker-compose.yaml (excerpt)\nversion: '3.9'\nservices:\n  app:\n    build: ./app\n    ports:\n      - '8000:8000'\n    depends_on:\n      - db\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      retries: 5\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: example\n    volumes:\n      - pgdata:/var/lib/postgresql/data\nvolumes:\n  pgdata:\n    name: pgdata\n```\n\n## Follow-up Questions\n- How would you add a migration step to initialize schemas?\n- How would you scale this with separate networks or secrets management?","diagram":"flowchart TD\nA[Developer writes app] --> B[Build Dockerfile]\nB --> C[Create docker-compose.yaml]\nC --> D[Start stack with docker compose up -d]\nD --> E[Healthchecks verify readiness]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T15:51:50.736Z","createdAt":"2026-01-13T15:51:50.737Z"},{"id":"q-1443","question":"In a 3-node Swarm across DC-A and DC-B, deploy a stateless API via overlay api-net with DC-affinity (2 replicas in DC-A and 1 in DC-B). Outline the exact CLI steps to init/join, create the overlay, and deploy two services with update_config (order: start-first, parallelism: 1). Describe a canary upgrade process that gradually updates replicas across DCs and validates with health checks. Include a minimal docker-compose snippet showing the two services, the overlay network, and update_config?","answer":"Init Swarm on DC-A; join DC-B; create overlay api-net; deploy two services: api-dcA with 2 replicas constrained to DC-A and api-dcB with 1 replica constrained to DC-B, both on api-net and update_confi","explanation":"## Why This Is Asked\nTests cross-DC orchestration, DC-aware placement, and canary upgrades using Docker Swarm update_config.\n\n## Key Concepts\n- Overlay networks spanning DCs\n- Placement constraints and spread/preference for DC distribution\n- update_config for staged upgrades\n- Canary rollout and health-check driven promotion\n\n## Code Example\n```javascript\nversion: \"3.8\"\nservices:\n  api-dcA:\n    image: myapi:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-A\n      networks:\n        - api-net\n  api-dcB:\n    image: myapi:latest\n    deploy:\n      replicas: 1\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-B\n      networks:\n        - api-net\nnetworks:\n  api-net:\n```\n\n## Follow-up Questions\n- How would you monitor canary success across DCs and automate rollback if latency spikes? \n- How would you adapt this for a rolling upgrade with multiple versions concurrently?","diagram":"flowchart TD\n  A[Init Swarm in DC-A] --> B[Join DC-B]\n  B --> C[Create overlay api-net]\n  C --> D[Deploy two services with update_config]\n  D --> E[Canary rollout across DCs]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T17:34:28.800Z","createdAt":"2026-01-13T17:34:28.803Z"},{"id":"q-1530","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API with TLS termination that uses Vault for dynamic TLS certificate rotation. Use Docker secrets to distribute certs, and implement a lightweight sidecar that refreshes certificates without dropping connections. Configure a canary-style rolling upgrade ensuring zero-downtime during cert rotations. Outline the exact steps: swarm init/join, overlay network creation, stack/deploy with secret handling, and the certificate rotation workflow with health checks?","answer":"Plan: initialize a 3-node Docker Swarm across two data centers, create an overlay network, deploy a stack with API and sidecar containers, mount Vault-issued certificates as Docker secrets and rotate them via the sidecar without container restarts, and perform a canary-style rolling upgrade ensuring zero-downtime during certificate rotations.","explanation":"## Why This Is Asked\nTests multi-datacenter Docker Swarm setup, TLS automation with HashiCorp Vault, Docker secrets management, and zero-downtime deployment strategies.\n\n## Key Concepts\n- Docker Swarm spanning multiple data centers\n- Docker secrets with external secret management (Vault)\n- Sidecar pattern for live certificate rotation\n- Update configuration with start-first for zero-downtime upgrades\n- Health checks and canary rollout strategies\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  api:\n    image: myorg/api:latest\n    ports:\n      - \"80:80\"\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n      healthcheck:\n        test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:80/health\"]\n        interval: 30s\n        timeout: 10s\n        retries: 3\n  sidecar:\n    image: myorg/cert-rotator:latest\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n      - source: vault_token\n        target: vault.token\n    deploy:\n      replicas: 1\nsecrets:\n  tls_cert:\n    external: true\n  vault_token:\n    external: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:10:39.873Z","createdAt":"2026-01-13T20:46:17.744Z"},{"id":"q-1579","question":"Design a secret-rotation workflow for a Docker Swarm stack that uses Vault to rotate a TLS cert and a database credential with zero downtime. Use Swarm secrets and a rolling update (start-first). Outline exact steps: swarm init/join, overlay network, create secrets, deploy stack, Vault rotate trigger, service update commands. Include a minimal docker-compose snippet showing secret usage and update_config?","answer":"Plan: Vault issues new TLS certificate and database credential; create new Swarm secrets (e.g., api-tls-v2, db-cred-v2); perform service updates with `docker service update --secret-add` then `--secret-rm`, using update_config with start-first strategy for zero downtime.\n\n## Implementation Steps\n\n1. **Initialize Swarm cluster**\n   ```bash\n   docker swarm init --advertise-addr <MANAGER-IP>\n   docker swarm join --token <TOKEN> <MANAGER-IP>:2377\n   ```\n\n2. **Create overlay network**\n   ```bash\n   docker network create --driver overlay --attachable app-network\n   ```\n\n3. **Create initial secrets from Vault**\n   ```bash\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v1 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v1 -\n   ```\n\n4. **Deploy stack with rolling update configuration**\n   ```yaml\n   version: '3.8'\n   services:\n     api:\n       image: myapp:latest\n       secrets:\n         - source: api-tls-v1\n           target: /app/tls.crt\n         - source: db-cred-v1\n           target: /app/db-cred\n       networks:\n         - app-network\n       update_config:\n         parallelism: 1\n         delay: 10s\n         order: start-first\n       healthcheck:\n           test: [\"CMD\", \"curl\", \"-f\", \"https://localhost:8443/health\"]\n           interval: 30s\n           timeout: 10s\n           retries: 3\n   ```\n\n5. **Vault rotation trigger**\n   - Vault generates new TLS certificate and database credential\n   - Automation script detects rotation event\n\n6. **Service update with new secrets**\n   ```bash\n   # Create new secret versions\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v2 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v2 -\n   \n   # Update service to add new secrets\n   docker service update api \\\n     --secret-add source=api-tls-v2,target=/app/tls.crt \\\n     --secret-add source=db-cred-v2,target=/app/db-cred\n   \n   # Remove old secrets after health checks pass\n   docker service update api \\\n     --secret-rm api-tls-v1 \\\n     --secret-rm db-cred-v1\n   ```","explanation":"## Why This Is Asked\nDemonstrates practical secret lifecycle management in Docker Swarm, integrating Vault for automated rotation with zero-downtime upgrades and proper secret versioning.\n\n## Key Concepts\n- Swarm secrets versioning and dynamic reattachment\n- Vault-based rotation triggers and secret provisioning\n- Rolling updates with start-first strategy to avoid downtime\n- Health checks to confirm new secrets are loaded before removing old ones\n- Atomic secret updates using add-then-remove pattern\n\n## Code Example\n```javascript\n// Pseudo-automation: rotate Vault-derived Swarm secrets\nasync function rotateSecrets(serviceName, vaultPath) {\n  // Fetch new credentials from Vault\n  const newCreds = await vault.read(vaultPath);\n  \n  // Create new Swarm secrets\n  const newSecrets = await createSwarmSecrets(newCreds);\n  \n  // Update service with new secrets\n  await updateService(serviceName, newSecrets);\n  \n  // Verify health before cleanup\n  await verifyServiceHealth(serviceName);\n  \n  // Remove old secrets\n  await cleanupOldSecrets(serviceName);\n}\n```","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T05:56:17.721Z","createdAt":"2026-01-13T22:45:30.688Z"},{"id":"q-1628","question":"Scenario: In a 3-node Swarm across two DCs, deploy an API service behind Traefik with image signing enforcement (cosign/DOCKER_CONTENT_TRUST) and implement a canary upgrade to v2 with a 10% traffic split via a separate api-v2-canary service. Outline exact commands, Swarm update_config usage, and docker-compose/service definitions to achieve zero-downtime upgrade and safe rollback?","answer":"Enable Docker Content Trust and cosign signing on all nodes (DOCKER_CONTENT_TRUST=1; cosign sign). Deploy api-v1 and a canary api-v2-canary behind Traefik with a 10% canary route. Use update_config { ","explanation":"## Why This Is Asked\nEvaluates image provenance, canary sequencing, and Swarm upgrade semantics in a multi-datacenter setup.\n\n## Key Concepts\n- Image signing with cosign and DOCKER_CONTENT_TRUST\n- Swarm update_config for controlled upgrades\n- Traffic splitting via an in-cluster reverse proxy (Traefik)\n- Canary pattern and safe rollback in production\n\n## Code Example\n```javascript\n// illustrative docker-compose-like snippet (Traefik routing hints)\nservices:\n  api-v1:\n    image: registry.example.com/api:v1\n    deploy:\n      replicas: 4\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v1.rule=Host(`api.example.com` )\"\n  api-v2-canary:\n    image: registry.example.com/api:v2-canary\n    deploy:\n      replicas: 1\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v2-canary.rule=Host(`canary.api.example.com` )\"\n```\n\n## Follow-up Questions\n- How would key rotation and automatic signing verification be automated?\n- How would you measure canary health and decide promotion/rollback automatically?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:16:19.227Z","createdAt":"2026-01-14T04:16:19.227Z"},{"id":"q-1653","question":"Scenario: On a single host, implement a beginner-friendly Docker Compose stack: a Node.js API that talks to Redis and a Fluent Bit logging service that reads logs from the API via a shared volume and forwards them to stdout. Provide a Dockerfile for the API, a docker-compose.yml with api, redis, fluent-bit, a logs volume, and healthchecks; explain the run steps and verification?","answer":"Create a docker-compose.yml with api, redis, and fluent-bit services on one host, plus a shared logs volume. The API writes to /var/log/app/app.log; Fluent Bit tails that file and forwards to stdout. ","explanation":"## Why This Is Asked\nTests practical docker-compose discipline: multi-service coordination, logging discipline, and health checks.\n\n## Key Concepts\n- docker-compose multi-service orchestration\n- log aggregation with Fluent Bit\n- log file sharing via volumes\n- minimal health checks for API service\n\n## Code Example\n```dockerfile\n# Dockerfile for API\nFROM node:18\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD node server.js\n```\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  api:\n    build: ./api\n    depends_on:\n      - redis\n    environment:\n      - REDIS_URL=redis://redis:6379\n    healthcheck:\n      test: curl -f http://localhost:3000/health || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - ./logs:/var/log/app\n  redis:\n    image: redis:7\n  fluent-bit:\n    image: fluent/fluent-bit:1.9\n    volumes:\n      - ./logs:/var/log/app\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf\n    depends_on:\n      - api\n```\n\n## Follow-up Questions\n- How would you extend this to ship logs to an external system\n- How would you ensure log retention and rotate the log files","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Instacart","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:35:42.804Z","createdAt":"2026-01-14T05:35:42.804Z"},{"id":"q-1688","question":"Beginner-level: design a local docker-compose stack for a Node.js API that uses Redis as a cache. Provide a Dockerfile for the API, a startup script that waits for Redis to be reachable on 6379 before starting, and a docker-compose.yml with healthchecks for both services on a shared network. Include exact file contents or minimal snippets, the commands to build and run, and how to validate a cache-hit endpoint?","answer":"Build a Node.js API image with a Dockerfile, and a start script wait-for-redis.sh that pings redis:6379 until ready, then runs node index.js. In docker-compose.yml, define services api and redis on a ","explanation":"Why This Is Asked\nTests ability to coordinate container startup and readiness in Compose using a startup gate and healthchecks.\n\nKey Concepts\n- Dockerfile for Node.js\n- startup gating with a wait script\n- docker-compose healthchecks\n- Docker networking and service discovery\n\nCode Example\n```javascript\n# Dockerfile\nFROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\n# Start directly with node (no quotes) for simplicity\nCMD node index.js\n```\n```javascript\n# wait-for-redis.sh (simplified)\nuntil nc -z  redis 6379; do\n  sleep 0.2\ndone\nexec \"$@\"\n```\n```javascript\n# docker-compose.yml\nversion: '3.9'\nservices:\n  api:\n    build: .\n    ports:\n      - 3000:3000\n    depends_on:\n      - redis\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    command: [\"sh\",\"/wait-for-redis.sh\",\"redis\",\"node\",\"index.js\"]\n  redis:\n    image: redis:7-alpine\n    ports:\n      - 6379:6379\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\nnetworks:\n  default:\n    name: appnet\n```\n\nFollow-up Questions\n- How would you adapt for an optional Redis cache with a fallback?\n- How would you test failure of Redis and verify API behavior?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","MongoDB","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:58:39.175Z","createdAt":"2026-01-14T06:58:39.175Z"},{"id":"q-1760","question":"In a three-node Docker Swarm spanning two data centers, introduce a new internal auth service that all APIs depend on. Roll it out with zero downtime and a canary, using update_config (start-first, parallelism 1), Docker Secrets, and a routing shim. Provide exact commands to init/join the swarm, create the overlay, deploy the stack, add the secret, and perform the canary upgrade with health checks?","answer":"Two-stage canary: deploy auth-v2 with 1 replica and route 5% of traffic to it; ensure health checks pass; then roll the main stack with update_config start-first, parallelism 1. Commands: docker swarm","explanation":"## Why This Is Asked\nRealistic multi-datacenter upgrades require controlled rollouts with canary, health checks, and secrets. This tests operational discipline and deep Docker Swarm knowledge.\n\n## Key Concepts\n- Swarm upgrades with update_config; - Canaries across regions; - Secrets management; - Overlay networking; - Health checks and rollback.\n\n## Code Example\n```javascript\nversion: '3.8'\nservices:\n  auth:\n    image: myrepo/auth:canary\n    secrets:\n      - source: auth-secret\n        target: /etc/auth/secret.json\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nsecrets:\n  auth-secret:\n    external: true\n```\n\n## Follow-up Questions\n- How would you automate canary traffic routing without a reverse proxy? \n- How would you verify no active sessions are dropped during promotion?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:46:53.036Z","createdAt":"2026-01-14T09:46:53.036Z"},{"id":"q-1786","question":"In a 3-node Docker Swarm spanning two data centers, deploy a GPU-accelerated model-serving API (TorchServe) using the NVIDIA runtime. Expose it behind an internal overlay network and a simple LB. Ensure zero-downtime upgrades with canary traffic shifts and a pre-warm sidecar to warm the new replica without serving traffic. Outline the steps for swarm init/join, overlay creation, service spec with GPU constraints, secret handling, and a separate migration container if needed. Include a minimal docker-compose snippet showing update_config (start-first, parallelism 1)?","answer":"Outline a GPU-enabled TorchServe deployment on a 3-node Swarm across 2 DCs. Use NVIDIA runtime and a service with GPU constraint (nvidia.com/gpu=1). Implement canary upgrades: deploy 1 new replica, ru","explanation":"## Why This Is Asked\nTests ability to orchestrate GPU-enabled deployments across DCs, implement safe upgrades, and coordinate sidecar pre-warming with a migration task.\n\n## Key Concepts\n- GPU scheduling in Swarm with NVIDIA runtime\n- Overlay networks across data centers\n- Canary rollout using update_config (start-first, single-threaded)\n- Sidecar pre-warm pattern for zero-downtime\n- Migration container for schema/model updates\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  model:\n    image: myorg/torchserve:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities:\n                -gpu\n                  count: 1\n```\n\n## Follow-up Questions\n- How would you monitor GPU utilization across nodes?\n- How would you handle model/version rollback in a canary rollout?","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create Overlay Network]\n  B --> C[Deploy TorchServe with NVIDIA runtime]\n  C --> D[Canary Upgrade: 1 new replica]\n  D --> E[Health Checks & Traffic Shift]\n  E --> F[Promote & Cleanup]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:48:28.317Z","createdAt":"2026-01-14T10:48:28.317Z"},{"id":"q-1832","question":"Design and implement a zero-downtime upgrade for a 4-node Docker Swarm across two data centers hosting a stateful Redis queue and a stateless worker service. The worker consumes messages encoded in a new proto format; the cluster uses TLS mutual authentication with Vault for cert rotation and Docker Secrets for credentials. Outline exact upgrade steps, a 10% canary rollout, health checks, and a rollback plan, and include a minimal docker-compose snippet showing update_config(order: start-first, parallelism: 1)?","answer":"Use a 4-node Swarm across two DCs, with a 10% canary of the worker upgraded to the new proto-format, while 90% stay on the legacy image. Deploy update_config: order: start-first; parallelism: 1. Route","explanation":"## Why This Is Asked\nTests real-world upgrade workflows in a distributed Swarm with cross-DC considerations, TLS cert rotation, and in-flight data.\n\n## Key Concepts\n- Swarm update_config with start-first and parallelism\n- Canary rollouts and rollback triggers\n- TLS mutual authentication, Vault cert rotation, Docker secrets\n- In-flight data migration and zero-downtime guarantees\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  worker:\n    image: myorg/worker:upgrade\n    deploy:\n      replicas: 4\n      update_config:\n        order: start-first\n        parallelism: 1\n    secrets:\n      - tls_cert\n      - db_creds\n    environment:\n      - PROTO_VERSION=v2\n```\n\n## Follow-up Questions\n- How would you validate canary health beyond a simple Liveness probe?\n- What rollback automation would you add to rapidly revert if metrics deteriorate?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Two Sigma","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T13:15:02.309Z","createdAt":"2026-01-14T13:15:02.310Z"},{"id":"q-1967","question":"In a production Swarm across two data centers with four nodes, implement end-to-end image provenance using Cosign. Sign CI artifacts, publish signatures to a registry, and enforce verification before deploys. Outline the exact steps: key management, signing workflow in CI, signature verification at pull-time, updating services with image digests, and a rollback plan if verification fails. Provide concrete Cosign commands and how to incorporate into a CI/CD pipeline?","answer":"CI builds, signs, and publishes; Swarm deploy uses digest; if cosign verify fails, rollback to previous digest. Commands: cosign generate-key-pair, cosign sign --key cosign.key registry.example.com/ap","explanation":"## Why This Is Asked\nAssesses practical image provenance, CI/CD integration, and rollback readiness in distributed Swarm.\n\n## Key Concepts\n- Image signing with Cosign; key management; digest-based deployments; runtime verification; rollback strategy.\n\n## Code Example\n```\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you automate key rotation and revocation?\n- How do you test the rollback in a canary deployment?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","DoorDash","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:00:51.280Z","createdAt":"2026-01-14T19:00:51.281Z"},{"id":"q-2016","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API behind a Traefik ingress with a Redis-backed cache layer and mutual TLS between services. Use Docker secrets/configs for TLS certs and cache creds. Apply zero-downtime upgrades via update_config (start-first, parallelism 1) and implement a canary upgrade path with health checks and automatic rollback. Outline the exact init/join commands, overlay creation, stack file, and upgrade sequence?","answer":"Initialize a three-node Swarm across two DCs, join the remaining nodes with generated tokens, create an overlay network, and deploy a Traefik-based API with a Redis cache layer. Use Docker secrets for","explanation":"## Why This Is Asked\nTests orchestration across DCs, zero-downtime upgrades, and secure service-to-service traffic with mTLS. It also probes secret/config management, canary rollout, and rollback handling.\n\n## Key Concepts\n- Swarm multi-DC deployment and node join tokens\n- Overlay networks and Traefik ingress with mTLS\n- Docker secrets/configs for TLS and credentials\n- update_config with start_first and parallelism, canary deployments\n\n## Code Example\n```yaml\n# docker-stack.yml (excerpt)\nversion: '3.8'\nservices:\n  api:\n    image: myapi:v2\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    secrets:\n      - redis-creds\n      - tls-cert\n    networks:\n      - app-net\n  cache:\n    image: redis:6\n    deploy:\n      replicas: 3\n    secrets:\n      - redis-creds\n    networks:\n      - app-net\nnetworks:\n  app-net:\n    external: true\nsecrets:\n  tls-cert:\n    external: true\n  redis-creds:\n    external: true\n```\n\n## Follow-up Questions\n- How would you implement automatic rollback on canary failure?\n- How do you measure canary success beyond HTTP 200s (latency, error rate)?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T20:53:37.375Z","createdAt":"2026-01-14T20:53:37.375Z"},{"id":"q-2022","question":"Scenario: On a single host, implement a blue-green deployment for a stateless API behind an Nginx reverse proxy using docker-compose. Start with green (v1) receiving all traffic; deploy blue (v2) and switch traffic to blue only after a 30-second health-check window confirms readiness, ensuring zero downtime. Provide: a) docker-compose.yml with two API services (api-green and api-blue) and Nginx, b) nginx.conf with a switchable upstream, c) a Bash script upgrade.sh that promotes blue by reconfiguring upstream and reloading Nginx, d) exact commands to bring up green, deploy blue, run the upgrade, and verify with curl?","answer":"Bootstrap green (v1) behind a single Nginx proxy. Deploy blue (v2) as a separate container and run healthchecks. When blue is healthy for 30s, swap nginx upstream to point to api-blue and reload Nginx","explanation":"## Why This Is Asked\nTests practical blue-green deployment on a single host, emphasizing health-driven promotion and service-rotations with minimal downtime.\n\n## Key Concepts\n- Blue-green deployment on a standalone host\n- Docker Compose for multi-service apps\n- Nginx upstream switching and live reload\n- Health checks and rollback safety\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  nginx:\n    container_name: nginx\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n  api-green:\n    image: myapi:v1\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\n  api-blue:\n    image: myapi:v2\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\nnetworks:\n  default:\n    driver: bridge\n```\n\n```nginx\nevents { worker_connections 1024; }\nhttp {\n  upstream api_green { server api-green:8080; }\n  server { listen 80; location / { proxy_pass http://api_green; } }\n}\n```\n\n```bash\n#!/usr/bin/env bash\nset -e\n# Start green (v1)\ndocker-compose up -d api-green nginx\n# Deploy blue (v2)\ndocker-compose up -d api-blue\n# Wait for blue health (simplified placeholder)\n# ... poll health until healthy for 30s ...\n# Promote blue\nsed -i 's/server api-green:8080;/server api-blue:8080;/' nginx.conf\ndocker exec -i nginx nginx -s reload\n```\n\n## Follow-up Questions\n- How would you automate the 30s health window and rollback if any check fails?\n- How would you extend this to three or more canaries and track traffic ratios over time?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T21:31:46.162Z","createdAt":"2026-01-14T21:31:46.162Z"},{"id":"q-2053","question":"In a four-node **Docker Swarm** spanning two data centers, deploy a stateless API with a Redis-backed rate limiter and a shared cache. Implement a canary upgrade of the API using update_config (start-first, parallelism 1), with a front-door that routes the canary subset using label-based routing. Outline exact commands: swarm init/join, overlay creation, stack deploy, and the health-check-driven promotion. Include a minimal docker-compose snippet showing update_config?","answer":"Initialize a 4-node Docker Swarm across two data centers and create an overlay network for cross-DC communication. Deploy the API stack with 3 production replicas and 1 canary replica, both configured with update_config using parallelism: 1 and order: start-first. Implement label-based routing through a front-door proxy that directs traffic to the canary based on service labels. Monitor health checks and promote the canary by updating the production service image after validation.","explanation":"## Why This Is Asked\nTests practical canary deployment strategies across distributed infrastructure with stateful dependencies (Redis rate limiter, shared cache) and intelligent traffic routing. Evaluates understanding of Swarm's update_config mechanics and health-driven promotion workflows.\n\n## Key Concepts\n- Docker Swarm update_config with start-first ordering\n- Canary deployment patterns and traffic splitting\n- Multi-datacenter overlay networking\n- Health check-based promotion strategies\n- Label-based service routing\n\n## Code Example\n```yaml\nversion: \"3.8\"\nservices:\n api:\n   image: myapi:2.0\n   deploy:\n     replicas: 3\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=production\"\n   networks:\n     - front\n   healthcheck:\n     test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n     interval: 30s\n     timeout: 10s\n     retries: 3\n canary:\n   image: myapi:2.0-canary\n   deploy:\n     replicas: 1\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=canary\"\n   networks:\n     - front\n redis:\n   image: redis:alpine\n   deploy:\n     replicas: 1\n   networks:\n     - front\nnetworks:\n front:\n   driver: overlay\n   attachable: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:40:42.873Z","createdAt":"2026-01-14T22:40:23.213Z"},{"id":"q-2120","question":"In a two-node Swarm, deploy a TLS-secured stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API settings, and a small sidecar that ships logs without affecting requests. Attach both services to a single overlay network and perform a canary upgrade with a rolling update (start-first, parallelism 1). Provide exact commands and a docker-compose.yml skeleton?","answer":"Initialize the Swarm cluster on node A with `docker swarm init --advertise-addr <IP1>`, then join node B using `docker swarm join --token <SWMTKN...> <IP1>:2377`. Create the overlay network with `docker network create -d overlay prod-net`.","explanation":"## Why This Is Asked\nThis question assesses practical mastery of Docker Swarm, including secrets management, overlay networking, and zero-downtime deployments through rolling updates.\n\n## Key Concepts\n- Swarm initialization and multi-node clustering\n- Overlay network creation and service attachment\n- Docker secrets and configs for secure configuration management\n- Rolling updates with health checks and canary-style deployments\n- Sidecar pattern for non-blocking log shipping\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  proxy:\n    image: nginx:alpine\n    ports:\n      - '443:443'\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n  api:\n    image: my-api:latest\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n  log-shipper:\n    image: log-shipper:latest\n    networks: [ prod-net ]\n    depends_on: [ api ]\n```\n\n## Additional Commands\n```bash\n# Create secrets\necho \"cert-content\" | docker secret create tls_cert -\necho \"key-content\" | docker secret create tls_key -\n\n# Create config\necho \"app-settings\" | docker config create app_config -\n\n# Deploy stack\ndocker stack deploy -c docker-compose.yml myapp\n```","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create overlay net]\n  B --> C[Create secrets/configs]\n  C --> D[Stack deploy]\n  D --> E[Canary upgrade]\n  E --> F[Promote canary]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:53:30.558Z","createdAt":"2026-01-15T02:28:35.499Z"},{"id":"q-2140","question":"In a two-datacenter Docker Swarm (2 nodes per DC), deploy a stateless API behind Traefik with TLS termination on an overlay network across DCs. Implement a canary rollout for a feature-flag change using a Swarm Config and route 10% of traffic to canary via Traefik labels. Outline exact swarm init/join commands, overlay creation, stack deploys, config creation, and the canary upgrade with health checks and rollback criteria?","answer":"Plan: Bring up both DCs as a single swarm, create an attachable overlay, deploy Traefik with TLS via Docker secrets, create a Swarm Config with the feature flag, launch two API stacks (prod and canary","explanation":"## Why This Is Asked\nTests cross-datacenter orchestration, canary traffic, and secret/config handling with Traefik in Swarm across DCs.\n\n## Key Concepts\n- Docker Swarm multi-DC overlay networking\n- Traefik dynamic routing and weights for canaries\n- Swarm Config vs Secret for feature flags\n- Health checks and safe rollback strategies\n\n## Code Example\n```bash\n# Swarm init (DC1)\ndocker swarm init --advertise-addr <dc1-ip>\n# Join DC2\n# docker swarm join ...\n\n\ndocker network create -d overlay --attachable traefik-net\n# Deploy Traefik with TLS secret and config-driven routes\n# ...\n```\n\n## Follow-up Questions\n- How would you test the rollover window and rollback boundaries?\n- How would you monitor traffic split and auto-promote canary on success?","diagram":"flowchart TD\nA[Two-DC Swarm] --> B[Overlay Network]\nB --> C[Traefik TLS]\nC --> D[Prod API]\nC --> E[Canary API]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:20:30.901Z","createdAt":"2026-01-15T04:20:30.901Z"},{"id":"q-2231","question":"In a four-node docker-dca cluster, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints, and add an Envoy sidecar per app to drive traffic-splitting controlled by a central Consul KV flag. Implement a progressive canary: 10% steps every 30s up to 100%, with health checks and automatic rollback on failure. Provide explicit bootstrap commands and a docker-compose.yml skeleton?","answer":"Use a four-node docker-dca canary with Envoy sidecars, edge TLS via Docker secrets, and a Consul KV flag to drive 10%→100% traffic steps every 30s. Health checks gate progress; rollback triggers on tw","explanation":"## Why This Is Asked\nTests practical orchestration of traffic-shifting, secret/config management, and automated rollback in a docker-dca setup.\n\n## Key Concepts\n- Envoy sidecars for per-service traffic-splitting\n- Consul KV as a dynamic control flag\n- Docker secrets/configs for TLS and endpoints\n- Canary rollout with health checks and rollback\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    secrets:\n      - tls_cert\n      - tls_key\n    configs:\n      - source: api_endpoints\n        target: /etc/api_endpoints.conf\n  app:\n    image: myapi:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    depends_on:\n      - envoy\n  envoy:\n    image: envoyproxy/envoy:v1.18.3\n    depends_on:\n      - app\n    volumes:\n      - ./envoy.yaml:/etc/envoy/envoy.yaml:ro\nsecrets:\n  tls_cert:\n  tls_key:\nconfigs:\n  api_endpoints:\n```\n\n## Follow-up Questions\n- How would you test rollback safety during regional failover?\n- How would you extend the flow to autoscale canary windows based on real-time metrics?","diagram":"flowchart TD\n  A[Edge TLS Termination (Nginx)] --> B[App Replica Set 1]\n  A --> C[App Replica Set 2]\n  B --> D[Envoy Sidecar]\n  C --> E[Envoy Sidecar]\n  D --> F[Central Router (Consul Map)]\n  E --> F","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T08:47:25.253Z","createdAt":"2026-01-15T08:47:25.253Z"},{"id":"q-2254","question":"Create a local Docker Compose setup with two Python services: web (Flask API) and cache (Redis). Duplicate web as web_canary with CANARY=true. Add an Nginx container as a reverse proxy routing /api to web and /canary to web_canary. Use a named volume for Redis data. Add healthchecks for all three containers and provide a docker-compose.yml skeleton plus exact bootstrap commands to seed data and verify endpoints?","answer":"Four services: web, web_canary, cache, and nginx. web and web_canary expose ports and use CANARY to differentiate behavior. Redis uses a named volume redis-data for persistence. Nginx routes /api to w","explanation":"## Why This Is Asked\n\nTests ability to design a practical local deployment with a stable/canary pattern, data persistence, and a proxy layer.\n\n## Key Concepts\n\n- Docker Compose service composition\n- Health checks and readiness\n- Canary routing via a dedicated proxy\n- Volume for data persistence\n\n## Code Example\n\n```javascript\n// Placeholder illustrating structure for health checks\n```\n\n## Follow-up Questions\n\n- How would you promote canary to stable with zero downtime?\n- How would you extend to multiple canaries and metrics-based routing?","diagram":"flowchart TD\n  Client --> NginxProxy[Nginx Proxy]\n  NginxProxy --> Web[web]\n  NginxProxy --> Canary[web_canary]\n  NginxProxy --> Redis[cache]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:39:38.182Z","createdAt":"2026-01-15T09:39:38.182Z"},{"id":"q-2295","question":"In a 5-node Docker Swarm spanning two data centers, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for per-tenant routing templates, consuming routing directives from a central HTTP API. Attach a per-service Envoy sidecar to drive traffic-splitting with a progressive canary (25% steps every 20s). Ship logs via a separate sidecar to a Loki stack without blocking requests. Implement a zero-downtime upgrade using update_config (start-first, parallelism 1). Provide exact commands and a docker-compose.yml skeleton?","answer":"Architect a 5-node Swarm across DCs, TLS via Docker secrets, Nginx edge proxy, and a per-service Envoy sidecar for canary routing. Routing rules pulled from a central HTTP API rendered into a Docker c","explanation":"## Why This Is Asked\n\nTests ability to design multi-DC Swarm, TLS secrets, dynamic routing, and Canary with sidecars and observability. Checks how routing rules are distributed and how upgrades remain zero-downtime.\n\n## Key Concepts\n\n- Docker Swarm across data centers\n- Secrets and Configs for TLS and routing\n- Nginx edge proxy with per-service Envoy sidecar\n- Canary rollout with health checks and rollback\n- Sidecar logging to Loki without blocking requests\n\n## Code Example\n\n```yaml\nversion: \"3.8\"\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    secrets: [ tls_cert ]\n    configs: [ routing_tpl ]\n  api:\n    image: my/api:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n```\n\n## Follow-up Questions\n\n- How would you validate canary health signals and rollback criteria?\n- How would you handle TLS certificate rotation without downtime?\n","diagram":"flowchart TD\n  DC1[Data Center 1] --> SwarmMgr[Swarm Manager]\n  DC2[Data Center 2] --> SwarmMgr\n  SwarmMgr --> Edge[Edge Proxy: Nginx]\n  Edge --> API[API Service]\n  API --> Logger[Log-Sidecar]\n  API --> Canary[Envoy Sidecar]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Slack","Tesla","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T10:56:17.946Z","createdAt":"2026-01-15T10:56:17.946Z"},{"id":"q-2346","question":"In a 3-node docker-dca cluster spanning two data centers, deploy a TLS-secured stateless API behind an Nginx proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints. Add a shadow sidecar that mirrors 5% of production traffic to a canary version. Implement a canary rollout by adjusting weights in 10% increments using update_config, with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton?","answer":"Implement dynamic traffic shadow: deploy a main API and a canary, with a shadow Envoy sidecar mirroring ~5% of traffic to the canary; TLS via Docker secrets; Nginx routes 95% to main and 5% to shadow;","explanation":"## Why This Is Asked\nTests ability to orchestrate multi-DC deployments, secret-driven TLS, and traffic shaping with live canary upgrades. It also probes rollback discipline and the interaction between edge proxies, sidecars, and the orchestrator.\n\n## Key Concepts\n- Docker secrets and configs for TLS and endpoints\n- Nginx/Envoy traffic routing and shadow/canary pattern\n- Canary rollout via update_config with health checks\n- Multi-DC networking and rollback strategies\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  nginx:\n    image: nginx:stable\n    secrets:\n      - tls_cert\n    configs:\n      - source: api_endpoints\n        target: /etc/api/endpoints.conf\n  api-main:\n    image: myapi:latest\n    secrets:\n      - tls_cert\n  api-canary:\n    image: myapi:canary\n    secrets:\n      - tls_cert\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        failure_action: rollback\nsecrets:\n  tls_cert:\n    file: ./certs/tls_cert.pem\nconfigs:\n  api_endpoints:\n    file: ./configs/endpoints.conf\n```\n\n## Follow-up Questions\n- How would you monitor canary health and automate rollback decisions?\n- How would you secure inter-service communication and ensure TLS mutual authentication across DCs?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:35:40.425Z","createdAt":"2026-01-15T14:35:40.425Z"},{"id":"q-2386","question":"In a two-datacenter Docker Swarm with a TLS-enabled REST API behind an Nginx edge proxy, TLS certs are stored as Docker secrets. Design a zero-downtime rotation workflow: publish a new cert secret api_tls_new without restarting Nginx, upgrade the service with the new secret using a canary approach (update_config: order start-first, parallelism 1), and provide the exact shell commands plus a minimal docker-compose.yml skeleton showing secrets, config, and a small log-shipper sidecar that does not delay requests?","answer":"Rotate TLS certs by creating api_tls_new, attach it via docker service update with --secret-add api_tls_new and --secret-rm api_tls_old using update-order start-first and update-parallelism 1 for a ca","explanation":"Why This Is Asked\nTests ability to design zero-downtime secret rotation in Swarm, including secret lifecycle, canary upgrade discipline, and edge-reload strategy.\n\nKey Concepts\n- Docker secrets lifecycle and updates\n- Swarm update_config for canary-like upgrades\n- Edge proxy reload without downtime\n- Non-blocking sidecar logging\n\nCode Example\n```yaml\nversion: '3.8'\nservices:\n  api:\n    image: myapi:latest\n    secrets:\n      - api_tls_old\n      - api_tls_new\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n  log_shipper:\n    image: log-shipper:latest\n    secrets:\n      - api_tls_old\n      - api_tls_new\nsecrets:\n  api_tls_old:\n    external: true\n  api_tls_new:\n    external: true\n```\n\nFollow-up Questions\n- How would you automate rotation cadence and auditing of secret changes?\n- How would you test the zero-downtime guarantee in CI/CD before production rollout?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Meta","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T15:50:28.068Z","createdAt":"2026-01-15T15:50:28.068Z"},{"id":"q-2432","question":"In a 4-node docker-dca Swarm, deploy a TLS-secured event-processing pipeline behind an Nginx edge proxy. Use Docker secrets for TLS certs, a Docker config for routing rules, and implement a 5% canary upgrade for the Transform service controlled by a Consul KV flag. Provide exact commands and a docker-compose.yml skeleton that demonstrates canary traffic, health checks, and zero-downtime upgrades?","answer":"Set up a 4-node Swarm with an overlay network, create TLS secrets tls.crt and tls.key, and a routing config. Deploy ingest, transform-prod, transform-canary, and sink behind edge-nginx. Route 95% to p","explanation":"## Why This Is Asked\n\nTests ability to orchestrate secrets/configs with a canary using a proxy. Requires Swarm networking, overlay, health checks, and rollback semantics.\n\n## Key Concepts\n\n- Docker secrets/configs\n- Swarm services and update_config\n- Overlay networks and edge proxy traffic-splitting\n- Consul KV flag-based traffic routing\n\n## Code Example\n\n```yaml\nversion: '3.8'\nservices:\n  ingest:\n    image: myreg/ingest:latest\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: on-failure\n  transform-prod:\n    image: myreg/transform-prod:latest\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 1\n        order: start-first\n  transform-canary:\n    image: myreg/transform-canary:latest\n    deploy:\n      replicas: 1\n  sink:\n    image: myreg/sink:latest\n    deploy:\n      replicas: 1\n  edge-nginx:\n    image: nginx:alpine\n    secrets:\n      - tls_crt\n      - tls_key\n    configs:\n      - source: routing_conf\n        target: /etc/nginx/conf.d/routing.conf\nnetworks:\n  pipeline:\n    driver: overlay\nsecrets:\n  tls_crt:\n    file: ./certs/tls.crt\n  tls_key:\n    file: ./certs/tls.key\nconfigs:\n  routing_conf:\n    file: ./routing/nginx.conf\n```\n\n## Follow-up Questions\n\n- How would you test the canary flag in production-like load?\n- How would you roll back if the canary shows degradation?","diagram":"flowchart TD\n  A[Edge Proxy] --> B[Ingest]\n  B --> C[Transform Prod]\n  C --> D[Sink]\n  D --> E[Storage]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T17:50:37.495Z","createdAt":"2026-01-15T17:50:37.495Z"},{"id":"q-2485","question":"In a three-node Docker Swarm spanning two data centers, deploy a TLS-secured stateless event API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints. Introduce an SPIRE-based mTLS mesh by wiring an SPIRE agent as a sidecar to each app container to issue short-lived mTLS certs and enforce SPIFFE IDs. Implement automatic certificate rotation every 60 minutes and a progressive canary upgrade (start-first, parallelism 1). Provide exact docker-compose.yml skeleton and bootstrap commands?","answer":"A possible answer would outline: init a swarm across both data centers, create an overlay network, load TLS secrets and API configs, deploy the app with a sidecar SPIRE agent container, configure SPIR","explanation":"## Why This Is Asked\nTests knowledge of multi-datacenter Swarm, TLS secrets, config usage, and a real-world mTLS service mesh with SPIRE. It also probes canary upgrades and security in production.\n\n## Key Concepts\n- Docker Swarm orchestration across DCs\n- TLS with Docker secrets and configs\n- SPIRE-based mTLS workload identity\n- Certificate rotation and health-driven canaries\n- Update strategy: start-first, parallelism 1\n\n## Code Example\n```yaml\n# docker-compose.yml skeleton\nversion: '3.8'\nservices:\n  api:\n    image: my/api:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n    configs:\n      - source: api_config\n        target: /etc/api/config.yaml\n    secrets:\n      - tls_cert\n      - tls_key\n    networks:\n      - ov\n    depends_on: []\n    # SPIRE sidecar will be defined in a separate service or as a sidecar container\n  spire-agent:\n    image: quay.io/spiffe/spire-agent:latest\n    volumes:\n      - /var/lib/spire:/run/spire\n    command: run\n    deploy:\n      replicas: 2\n      labels:\n        SPIRE: agent\nnetworks:\n  ov:\n    external: true\nsecrets:\n  tls_cert:\n    file: ./certs/server.crt\n  tls_key:\n    file: ./certs/server.key\nconfigs:\n  api_config:\n    file: ./config/api.yaml\n```\n\n### Follow-up Steps\n- Show exact bootstrap commands for swarm init/join and SPIRE setup.\n- Describe monitoring and rotation verification.","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Citadel","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:46:58.046Z","createdAt":"2026-01-15T19:46:58.046Z"},{"id":"q-2558","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API endpoints, and a lightweight log-shipper sidecar that adds no latency. Attach both services to a single overlay network. Implement a 5% canary rollout with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton, plus how to measure and enforce performance during the rollout?","answer":"Initialize a two-node Docker Swarm cluster, create an overlay network, store TLS certificates as Docker secrets, API endpoints as a Docker config, deploy Nginx as an edge proxy with the stateless API backend, include a lightweight log-shipper sidecar, implement a 5% canary rollout with health checks and automatic rollback on failure, and measure performance throughout the deployment process.","explanation":"## Why This Is Asked\nTests practical experience with Docker Swarm fundamentals, secrets and configs management, edge proxy orchestration, controlled deployment strategies, and performance monitoring during rollouts.\n\n## Key Concepts\n- Docker Swarm initialization and overlay networking\n- Docker secrets for sensitive data (TLS certificates)\n- Docker configs for application configuration\n- Edge proxy pattern with Nginx in Swarm\n- Canary deployments with health-check-driven rollbacks\n- Sidecar containers for log shipping\n- Performance measurement and enforcement during rollouts\n\n## Code Example\n```\n","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","DoorDash","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:26:12.739Z","createdAt":"2026-01-15T22:46:54.516Z"},{"id":"q-2588","question":"On a two-node Docker Swarm, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use a Docker secret for TLS certs and a Docker config for API endpoints. Ensure the app runs as a non-root user and add a tiny sidecar that tails logs to a shared volume without affecting requests. Attach both services to an overlay network and implement a rolling update with start_first, parallelism 1. Include exact commands to initialize swarm, create secret/config, build/deploy, and a docker-compose.yml skeleton?","answer":"Run: `docker swarm init`; `docker network create -d overlay appnet`; `docker secret create tls.pem cert.pem`; `docker secret create tls.key key.pem`; `docker config create api-endpoints /path/api.json`; `docker stack deploy -c docker-compose.yml mystack`","explanation":"## Why This Is Asked\nTests wiring of secrets/config, non-root containers, and safe rolling updates in a two-node swarm.\n\n## Key Concepts\n- Docker secrets/config\n- Non-root user in containers\n- Sidecar log shipping\n- Overlay networking and rolling updates\n\n## Code Example\n```dockerfile\nFROM node:18\nRUN groupadd -r app && useradd -r -g app app\nUSER app\nWORKDIR /app\nCOPY --chmod=644 . .\nCMD [\"node\",\"server.js\"]\n```\n\n```yaml\nversion: \"3.8\"\nservices:\n  api:\n    image: mystack/api:latest\n    networks: [ appnet ]\n    secrets: [ tls.pem, tls.key ]\n    configs: [ api-endpoints ]\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n      restart_policy:\n        condition: on-failure\n  nginx:\n    image: nginx:alpine\n    networks: [ appnet ]\n    secrets: [ tls.pem, tls.key ]\n    ports:\n      - \"443:443\"\n    deploy:\n      replicas: 1\n  logtailer:\n    image: alpine:latest\n    command: tail -f /logs/app.log\n    volumes:\n      - shared-logs:/logs\n    networks: [ appnet ]\n    deploy:\n      replicas: 1\n\nnetworks:\n  appnet:\n    driver: overlay\n    external: true\n\nvolumes:\n  shared-logs:\n```\n\n## Implementation Steps\n1. Initialize swarm on both nodes and join them\n2. Create overlay network for service communication\n3. Generate TLS certificates and create secrets\n4. Create API endpoint configuration\n5. Build and push API image with non-root user\n6. Deploy stack with rolling update configuration\n7. Verify TLS termination and log shipping functionality","diagram":"flowchart TD\n  A[Swarm Init] --> B[Create Overlay Network]\n  B --> C[Create Secrets & Configs]\n  C --> D[Deploy Stack]\n  D --> E[Canary Upgrade / Health Checks]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:07:32.152Z","createdAt":"2026-01-15T23:46:32.556Z"},{"id":"q-2829","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx edge proxy. Add a shadow version of the API and use traffic mirroring to send 5% of live traffic to the shadow for black-box testing without affecting live latency. Use Docker secrets for TLS certs and a Docker config for API endpoints. Ensure health checks and automatic rollback if the shadow underperforms. Provide exact commands and a docker-compose.yml skeleton?","answer":"Deploy TLS-enabled API behind Nginx edge proxy with a second shadow API. Mirror 5% of requests to the shadow via Nginx mirror, keeping live path on the primary. Use Docker secrets for TLS certs and a ","explanation":"## Why This Is Asked\nTests ability to implement traffic mirroring for safe shadow testing, validate latency impact, and design robust rollback.\n\n## Key Concepts\n- traffic mirroring with Nginx\n- docker secrets/configs\n- overlay networking in Swarm\n- health checks and rollback policies\n- non-disruptive canary/shadow deployments\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  live-api:\n    image: myorg/live\n    secrets: [ tls_cert, tls_key ]\n  shadow-api:\n    image: myorg/shadow\n    secrets: [ tls_cert, tls_key ]\n  edge-nginx:\n    image: nginx:latest\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n    depends_on: [live-api, shadow-api]\n    configs: [ api-endpoints_config ]\nconfigs:\n  api-endpoints_config:\n    external: true\nsecrets:\n  tls_cert:\n    external: true\n  tls_key:\n    external: true\nnetworks:\n  proxy:\n    driver: overlay\n    attachable: true\n```\n\n```nginx\n# nginx.conf (simplified)\nserver {\n  listen 443 ssl;\n  ssl_certificate /run/secrets/tls_cert;\n  ssl_certificate_key /run/secrets/tls_key;\n  location / {\n    proxy_pass http://live-api:8080;\n    mirror /mirror_shadow;\n  }\n  location = /mirror_shadow {\n    proxy_pass http://shadow-api:8081$request_uri;\n    internal;\n  }\n}\n```\n\n## Follow-up Questions\n- How would you calculate and enforce a 95th percentile SLA during shadow testing?\n- How would you automate rollback if shadow latency exceeds threshold for three consecutive minutes?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Plaid","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T14:03:42.560Z","createdAt":"2026-01-16T14:03:42.560Z"},{"id":"q-2918","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config to store per-tenant ACLs. Add an Open Policy Agent (OPA) sidecar to enforce per-request authorization, with policy loaded from a Docker config. Include a separate log-collector sidecar that writes audit logs to a shared volume. Implement a 20% canary rollout every 15 seconds with health checks and automatic rollback on policy violation. Provide exact commands and a minimal docker-compose.yml skeleton?","answer":"Deploy a TLS-enabled API behind Nginx with OPA policy enforcement and canary rollouts. Use Docker secrets for certs, configs for ACLs, and sidecar containers for authorization and logging. Implement 20% canary deployment with health checks and automatic rollback on policy violations.\n\n## Commands\n```bash\n# Create TLS secrets\necho \"-----BEGIN CERTIFICATE-----\" | docker secret create tls-cert -\necho \"-----BEGIN PRIVATE KEY-----\" | docker secret create tls-key -\n\n# Create OPA policy config\ncat > policy.rego << 'EOF'\npackage example.api.auth\ndefault allow = false\nallow {\n  input.method == \"GET\"\n  input.path = [\"api\", \"v1\", \"data\"]\n  input.tenants[_] = input.user.tenant\n}\nEOF\ndocker config create opa-policy policy.rego\n\n# Create ACL config\ncat > acls.json << 'EOF'{\"tenants\": {\"tenant1\": [\"read\", \"write\"], \"tenant2\": [\"read\"]}}\nEOF\ndocker config create tenant-acls acls.json\n\n# Deploy stack\ndocker stack deploy -c docker-compose.yml api-stack\n\n# Monitor canary rollout\nwatch docker service ps api-stack_api\n```","explanation":"## Why This Is Asked\nTests ability to implement zero-trust security, multi-tenant isolation, and safe deployment patterns in Docker Swarm with policy-as-code enforcement.\n\n## Key Concepts\n- Swarm secrets/configs for secure data management\n- Sidecar pattern for policy enforcement and logging\n- Canary deployments with automatic rollback\n- TLS termination at edge proxy\n- OPA for real-time authorization decisions\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  nginx:\n    image: nginx:alpine\n    ports: ['443:443']\n    secrets:\n      - source: tls-cert\n        target: /etc/nginx/ssl/tls.crt\n      - source: tls-key\n        target: /etc/nginx/ssl/tls.key\n    configs:\n      - source: nginx-conf\n        target: /etc/nginx/nginx.conf\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n    networks:\n      - frontend\n\n  api:\n    image: my-api:latest\n    environment:\n      - TENANT_CONFIGS=/configs/acls.json\n    configs:\n      - source: tenant-acls\n        target: /configs/acls.json\n    deploy:\n      replicas: 5\n      update_config:\n        parallelism: 1\n        delay: 15s\n        failure_action: rollback\n        monitor: 30s\n        max_failure_ratio: 0.2\n      rollback_config:\n        parallelism: 1\n        delay: 10s\n      healthcheck:\n        test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n        interval: 10s\n        timeout: 5s\n        retries: 3\n        start_period: 30s\n    networks:\n      - frontend\n      - backend\n    volumes:\n      - audit-logs:/var/log/audit\n\n  opa:\n    image: openpolicyagent/opa:latest\n    command: [\"run\", \"--server\", \"/policies/policy.rego\"]\n    configs:\n      - source: opa-policy\n        target: /policies/policy.rego\n    environment:\n      - OPA_LOG_LEVEL=info\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8181/v1/data\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n\n  log-collector:\n    image: fluent/fluent-bit:latest\n    command: [\"/fluent-bit/bin/fluent-bit\", \"--config\", \"/fluent-bit/etc/fluent-bit.conf\"]\n    volumes:\n      - audit-logs:/var/log/audit\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro\n    networks:\n      - backend\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: on-failure\n\nsecrets:\n  tls-cert:\n    external: true\n  tls-key:\n    external: true\n\nconfigs:\n  nginx-conf:\n    external: true\n  opa-policy:\n    external: true\n  tenant-acls:\n    external: true\n\nvolumes:\n  audit-logs:\n    driver: local\n\nnetworks:\n  frontend:\n    driver: overlay\n  backend:\n    driver: overlay\n    internal: true\n```\n\n## fluent-bit.conf\n```ini\n[SERVICE]\n    Flush         5\n    Log_Level     info\n    Daemon        off\n\n[INPUT]\n    Name          tail\n    Path          /var/log/audit/*.log\n    Tag           audit.*\n    Refresh_Interval 10\n\n[OUTPUT]\n    Name          file\n    Match         audit.*\n    Path          /var/log/processed\n    File          audit.log\n```\n\n## Implementation Details\n\n**OPA Integration**: OPA sidecar loads policies from Docker config and exposes authorization endpoint at `http://localhost:8181/v1/data`. API checks authorization before processing requests.\n\n**Canary Strategy**: 20% rollout (1 out of 5 replicas) every 15 seconds with 30-second health monitoring. Automatic rollback on >20% failures.\n\n**Security**: TLS termination at Nginx edge, secrets management for certificates, internal backend network isolation, per-tenant ACL enforcement.\n\n**Logging**: Audit logs written to shared volume, processed by fluent-bit sidecar for aggregation and forwarding.","diagram":"flowchart TD\n  Edge[Nginx edge proxy] --> API[API service]\n  API --> OPA[OPA sidecar (policy)]\n  OPA --> API\n  API --> Log[Audit logs]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T03:50:28.764Z","createdAt":"2026-01-16T17:39:15.047Z"},{"id":"q-2951","question":"On a three-node docker-dca Swarm, deploy a TLS-enabled API behind an Nginx TLS-terminating proxy with mutual TLS to the API, using Vault PKI to issue short-lived certs and a sidecar that auto-refreshes certs into a shared volume; implement a 25% canary rollout every 20s with health checks and auto-rollback. Include exact swarm bootstrap commands and a docker-compose.yml skeleton?","answer":"Bootstrap a 3-node Swarm; initialize Vault PKI, create roles for API and clients with short TTLs; store Vault token in a Docker secret; define services: nginx (TLS, mTLS, certs from a writable volume)","explanation":"## Why This Is Asked\nTests secure, rotating certs in Swarm with Vault, handling cert storage (secret vs volume), and canary semantics.\n\n## Key Concepts\n- Swarm multi-node with TLS and mTLS\n- Vault PKI for dynamic certs\n- Certs via writable volume + sidecar refresh\n- Canary rollout with health checks and rollback\n- Nginx TLS termination and service-to-service mTLS\n\n## Code Example\n```javascript\n// Simple cert refresh watcher from Vault to a mounted volume\nconst fetch = require('node-fetch');\nconst fs = require('fs');\nasync function refresh() {\n  const res = await fetch('https://vault.example/v1/pki/issue/api', { headers: { 'X-Vault-Token': process.env.VAULT_TOKEN } });\n  const cert = await res.text();\n  fs.writeFileSync('/certs/api.crt', cert);\n}\nsetInterval(refresh, 5 * 60 * 1000);\n```\n\n## Follow-up Questions\n- How would you validate cert rotation does not break existing connections?\n- How would you monitor Vault token renewal and automatic revocation?","diagram":"flowchart TD\n  Init[Swarm Init] --> Vault[Vault PKI setup]\n  Vault --> Nginx[Nginx TLS termination]\n  Nginx --> API[API with mTLS]\n  API --> Canary[Canary rollout with Health Checks]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Oracle","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T18:55:28.921Z","createdAt":"2026-01-16T18:55:28.921Z"},{"id":"q-3052","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind Nginx. Use Docker secrets for TLS certs and a Docker Config named flag.json mounted at /config/flag.json. Implement a simple feature toggle in the API that reads the flag from /config/flag.json and supports hot reload via SIGHUP without restarting. Add a progressive canary rollout: enable the feature in 0%, 25%, 50%, 75%, 100% in 20-second steps with health checks and automatic rollback on failure. Provide exact docker commands and a docker-compose.yml skeleton that demonstrates the rollout. Also show how to verify latency impact during each step?","answer":"Deploy a Flask API that reads /config/flag.json to toggle GET /v1/feature, with SIGUSR1 handling for hot reload. TLS termination via Nginx using Docker Secrets, running 2 replicas on an overlay network. Implement canary rollout from 0% to 100% in 25% increments every 20 seconds with health checks and automatic rollback on failure.","explanation":"## Why This Is Asked\nTests dynamic configuration reload, feature toggling, and safe canary rollout capabilities in a Docker Swarm environment.\n\n## Key Concepts\n- Docker Configs and Secrets management\n- TLS termination with Nginx reverse proxy\n- Signal-based hot reload in Python applications\n- Progressive canary deployment with health monitoring\n- Automated rollback mechanisms\n\n## Code Example\n```python\nfrom flask import Flask, jsonify\nimport json, signal\napp = Flask(__name__)\nflag = False\n\ndef load_flag():\n    global flag\n    try:\n        with open('/config/flag.json') as f:\n            data = json.load(f)\n            flag = data.get('feature_x', False)\n    except Exception:\n        flag = False\n\ndef reload_handler(signum, frame):\n    load_flag()\n    \nsignal.signal(signal.SIGUSR1, reload_handler)\nload_flag()\n\n@app.route('/v1/feature')\ndef feature():\n    return jsonify({'enabled': flag})\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=8080)\n```\n\n## Implementation\n- Docker Config mounts flag.json at /config/flag.json\n- Docker Secrets store TLS certificates for Nginx\n- SIGUSR1 triggers config reload without container restart\n- Canary rollout uses service update with rollback on health check failure","diagram":"flowchart TD\n  Swarm[Two-Node Swarm] --> Nginx[Nginx TLS on Secrets]\n  Nginx --> API[API replicas on overlay]\n  API --> Config[Docker Config /config/flag.json]\n  Config -->|Reload| API\n  Canary[Canary rollout] --> Health[Health checks]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:15:13.387Z","createdAt":"2026-01-16T22:45:29.570Z"},{"id":"q-3119","question":"In a two-node docker-dca Swarm spanning two data centers, deploy a TLS-enabled stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints. Attach both services to a single overlay network. Add an Envoy sidecar to the API service to perform region-aware traffic-splitting driven by a global feature flag stored in Consul KV at /features/new-api. Implement a progressive canary: 20% traffic to v2 until the flag is 1, with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton?","answer":"Leverage Envoy as a per-service sidecar to implement traffic-splitting, controlled by Consul KV flag /features/new-api. Nginx edge handles TLS via Docker secrets; services join one overlay network. St","explanation":"Why this is asked\n- Tests practical canary via a sidecar proxy and a feature flag, without a full service mesh\n- Validates multi-site deployment, TLS handling, and dynamic traffic control\n\nKey Concepts\n- Envoy as a sidecar for per-service traffic shaping\n- Consul KV feature flags for cross-service rollout control\n- Docker secrets/config for TLS and API metadata\n- Canary progression and rollback based on health/latency metrics\n\nCode Example\n```yaml\nversion: '3.8'\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    secrets:\n      - tls_cert\n      - tls_key\n    networks:\n      - overlay\n  api:\n    image: myapi:latest\n    depends_on:\n      - envoy\n    networks:\n      - overlay\n  envoy:\n    image: envoyproxy/envoy:v1.25.0\n    volumes:\n      - ./envoy.yaml:/etc/envoy/envoy.yaml:ro\n    networks:\n      - overlay\n\ndevices: []\nsecrets:\n  tls_cert:\n    file: ./certs/server.crt\n  tls_key:\n    file: ./certs/server.key\nnetworks:\n  overlay:\n    driver: overlay\n```\n\nFollow-up Questions\n- How would you monitor and alert on canary drift vs. full traffic?\n- How would you handle certificate rotation without downtime in Swarm?","diagram":"flowchart TD\n  A[Client] --> B[Edge: Nginx TLS]\n  B --> C[Envoy Sidecar]\n  C --> D[API v1]\n  C --> E[API v2]\n  D --> F[Backend]\n  E --> F","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Oracle","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:02:19.096Z","createdAt":"2026-01-17T04:02:19.096Z"},{"id":"q-3162","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs, a Docker config for API endpoints, and a lightweight traffic-controller container that adjusts canary weights by updating a shared Nginx config mounted as a Docker config. Route 10% traffic to v2 initially, then scale to 100% per 15-second steps based on p95 latency measured via a small health-check endpoint; auto rollback to previous weight if latency exceeds 250ms for two consecutive checks. Provide exact docker commands and a docker-compose.yml skeleton, plus how to measure latency and trigger rollback?","answer":"Implement a Python controller in Swarm that reads p95 latency from a Prometheus-compatible endpoint and gradually shifts Nginx upstream weights from 10/90 to 0/100 in 15s steps. Use Docker secrets for","explanation":"## Why This Is Asked\nTests ability to design dynamic traffic routing with strict latency guardrails in a small Swarm, plus integration of Docker secrets/configs and live config reloads.\n\n## Key Concepts\n- Swarm-based Canary with external controller\n- Nginx upstream weight management via Docker Configs\n- TLS secrets for mTLS-like security\n- Latency-driven rollback and health checks\n\n## Code Example\n```bash\n# example commands showing secret/config creation and stack deploy\ndocker swarm init\ndocker secret create tls_api path/to/tls.pem\ndocker secret create tls_key path/to/key.pem\ndocker config create upstreams.yaml /dev/null\n# deploy stack with nginx, api-v1, api-v2, traffic-controller\n```\n\n## Follow-up Questions\n- How would you ensure idempotent config updates?\n- How to validate rollback safety under burst traffic?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Goldman Sachs","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:56:12.240Z","createdAt":"2026-01-17T04:56:12.240Z"},{"id":"q-3283","question":"In a three-node docker-dca cluster, deploy a TLS-enabled API behind an Nginx gateway using mutual TLS. Secrets: CA and API certs as Docker secrets; a Vault-backed secret-provider sidecar rotates short-lived MTLS creds with zero latency. Add a lightweight tracing sidecar to ship spans non-blockingly. All services on one overlay network. Implement zero-downtime rotation with health checks and automatic rollback on failure. Provide docker-compose skeleton and bootstrap steps?","answer":"Mutual TLS between Nginx and the API using CA and service certs as Docker secrets (ca.pem, api.crt/api.key). Add a Vault-backed secret-provider sidecar to rotate short-lived MTLS creds with zero laten","explanation":"## Why This Is Asked\nTests mastery of secure service-to-service communication, secret rotation, and non-disruptive deployments in docker-dca. Emphasizes Safer-by-design patterns and observable behavior under rotation.\n\n## Key Concepts\n- Mutual TLS between gateway and API with Docker secrets\n- Vault-based secret provisioning for dynamic cert rotation\n- Sidecar patterns: tracing and credential rotation with no request latency\n- Overlay networking, zero-downtime updates, health-check driven rollback\n- Bootstrap steps: swarm init/join, secret/config creation, compose deploy\n\n## Code Example\n```yaml\nversion: \"3.8\"\nservices:\n  nginx:\n    image: nginx:stable-alpine\n    ports:\n      - \"443:443\"\n    secrets:\n      - source: ca.pem\n        target: ca.pem\n    configs:\n      - source: api-endpoints\n        target: /etc/nginx/conf.d/api-endpoints.conf\n  api:\n    image: myorg/api:latest\n    secrets:\n      - source: ca.pem\n      - source: api.crt\n      - source: api.key\n    deploy:\n      replicas: 2\n  secret-provider:\n    image: vault-bridge:latest\n    environment:\n      - VAULT_ADDR=http://vault:8200\n    depends_on:\n      - vault\n  tracing:\n    image: tracing-collector:latest\n    depends_on:\n      - api\n```\n\n## Follow-up Questions\n- How would you verify rotation safety under peak traffic?\n- What metrics would you collect to detect failed rotations early?\n- How would you handle secret revocation if a node goes offline?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T09:45:46.300Z","createdAt":"2026-01-17T09:45:46.301Z"},{"id":"q-3297","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx proxy. Instrument the API with OpenTelemetry and run an OpenTelemetry Collector as a sidecar in each service, exporting traces to a Jaeger backend running on the swarm. Use Docker secrets for TLS certs and a Docker config for API endpoints. Attach both services to a single overlay network. Set 50% sampling; verify traces in Jaeger; ensure per-request latency overhead stays under 2 ms. Provide exact docker-compose.yml skeleton and minimal OTEL/Jaeger config?","answer":"Instrument the API with OpenTelemetry, run a per-task OTEL Collector sidecar, and export traces to Jaeger via OTLP. TLS via Docker secrets; TLS termination at Nginx. All services on a single overlay n","explanation":"## Why This Is Asked\n\nAssessing observability discipline in Docker Swarm: instrumenting code, sidecar collectors, and end-to-end tracing with Jaeger, while validating latency overhead.\n\n## Key Concepts\n\n- OpenTelemetry instrumentation and OTLP exporters\n- Sidecar collector pattern in Swarm\n- Jaeger backend and sampling configuration\n- Docker secrets for TLS and Docker configs for routing\n- Overlay network communication and minimal overhead\n\n## Code Example\n\n```yaml\n# docker-compose skeleton (draft)\nversion: '3.8'\nservices:\n  api:\n    image: myapi:latest\n    secrets:\n      - tls_cert\n      - tls_key\n    configs:\n      - source: endpoints\n        target: /config/endpoints.json\n    networks:\n      - overlay\n    deploy:\n      replicas: 1\n  otel-collector:\n    image: otel/opentelemetry-collector-contrib:0.63.0\n    volumes:\n      - ./otel-config.yaml:/conf/otel-config.yaml\n    command: [\"--config\", \"/conf/otel-config.yaml\"]\n    networks:\n      - overlay\n    deploy:\n      replicas: 1\nnetworks:\n  overlay:\n    driver: overlay\nsecrets:\n  tls_cert:\n    file: ./certs/api.crt\n  tls_key:\n    file: ./certs/api.key\nconfigs:\n  endpoints:\n    file: ./config/endpoints.json\n```\n\n## Follow-up Questions\n\n- How would you scale the OTEL collectors in swarm?\n- How to adjust sampling dynamically without redeploying?\n","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T10:35:51.882Z","createdAt":"2026-01-17T10:35:51.882Z"},{"id":"q-3395","question":"**Advanced Docker DCA Challenge**: In a three-node docker-dca cluster across two data centers, deploy a TLS-enabled, stateful API behind an Nginx edge proxy. Use Docker secrets for TLS, a Docker config for API endpoints, and a sidecar that ships logs to a central ELK stack with zero latency. Implement blue-green deploy with health checks and automatic rollback; include exact commands and a minimal docker-compose.yml, plus how to measure performance during rollout?","answer":"Deploy plan: create TLS secret and API endpoints config, run a two-variant stack (blue/green) behind Nginx, wire a sidecar log-shipper, attach to overlay net, and use health checks with automatic roll","explanation":"## Why This Is Asked\nTests ability to design cross-datacenter, TLS-terminated, stateful deployment with zero-downtime, plus observability-driven rollbacks.\n\n## Key Concepts\n- docker-dca, TLS secrets, Docker configs, overlay networks\n- blue-green rollout, health checks, automatic rollback\n- sidecar logging without request latency, stateful volume handling\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  api:\n    image: myorg/api:latest\n    deploy:\n      replicas: 2\n    configs:\n      - source: api-endpoints\n        target: /etc/api/endpoints.json\n    secrets:\n      - source: tls-cert\n        target: tls.crt\n    networks:\n      - overlay\n    volumes:\n      - api-data:/var/lib/api\n  sidecar:\n    image: log-shipper:latest\n    deploy:\n      replicas: 1\n    volumes:\n      - api-logs:/var/log/api\n    networks:\n      - overlay\nnetworks:\n  overlay:\n    driver: overlay\nvolumes:\n  api-data:\n  api-logs:\nsecrets:\n  tls-cert:\n    file: tls/cert.pem\nconfigs:\n  api-endpoints:\n    file: configs/endpoints.json\n```\n\n## Follow-up Questions\n- How would you test rollback behavior under latency spikes?\n- What observability signals and thresholds ensure safe rollout?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T14:35:44.736Z","createdAt":"2026-01-17T14:35:44.736Z"},{"id":"q-3425","question":"In a three-node docker-dca cluster spanning on-prem and cloud, implement a TLS-enabled, multi-tenant API gateway behind an Nginx edge. Use one TLS secret per tenant, per-tenant rate limits via a small config mounted as a Docker config, and a Redis-backed counter. Add a canary rollout for a new per-tenant routing rule driven by a Consul KV flag, with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton?","answer":"Use a per-tenant TLS secret and an Nginx map keyed by host to select the certs, plus a Redis-backed rate limiter per tenant read via a small gateway helper. Apply a canary rollout controlled by a Cons","explanation":"## Why This Is Asked\nTests ability to design multi-tenant TLS handling, dynamic routing, and safe deployments across hybrid clusters, tying together secrets, configs, and feature flags.\n\n## Key Concepts\n- Docker secrets/configs per tenant\n- Nginx TLS SNI-based cert selection\n- Redis-backed per-tenant rate limiting\n- Consul KV feature flags for canary routing\n- Swarm update_config with rollback on failure\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  edge:\n    image: nginx:1.25\n    ports:\n      - '443:443'\n    secrets:\n      - tenantA.crt\n      - tenantA.key\n      - tenantB.crt\n      - tenantB.key\n    configs:\n      - source: nginx_tenant_map\n        target: /etc/nginx/conf.d/tenant_map.conf\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 5s\n        order: start-first\n        failure_action: rollback\nconfigs:\n  nginx_tenant_map:\n    file: ./nginx/tenant_map.conf\n```\n\n## Follow-up Questions\n- How would you test canary rollout without affecting production traffic?\n- How would you audit tenant isolation and key rotation?\n- What are the failure modes if Redis is unreachable during rollout?","diagram":"flowchart TD\n  A[Client] --> B[Nginx Edge]\n  B --> C[Tenant API]\n  B --> D[Canary Route]\n  D --> E[Health Checks]\n  E --> F[Rollback on Failure]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T15:39:44.805Z","createdAt":"2026-01-17T15:39:44.805Z"},{"id":"q-3592","question":"In a docker-dca Swarm across two data centers, add end-to-end distributed tracing to a TLS-enabled API behind an Nginx proxy. Deploy an OpenTelemetry Collector as a sidecar on the API service and a central collector, propagate W3C trace context, configure sampling via Docker config, and export via OTLP to Jaeger. Measure and keep overhead under 1 ms per request; provide commands and a docker-compose skeleton?","answer":"Instrument the API with OpenTelemetry, deploy a sidecar collector per replica, propagate W3C trace context across services, and export traces via OTLP to Jaeger. Configure sampling through Docker configs, ensure cross-datacenter trace delivery, and maintain sub-1ms overhead through optimized collector configuration and proper resource allocation.","explanation":"## Why This Is Asked\n\nThis question evaluates your ability to design and implement distributed tracing across a multi-datacenter Docker Swarm environment while meeting strict performance requirements and handling TLS/Nginx integration complexities.\n\n## Key Concepts\n\n- OpenTelemetry instrumentation and configuration\n- W3C trace context propagation across service boundaries\n- OTLP (OpenTelemetry Protocol) exporters and data flow\n- Jaeger backend integration for trace storage and visualization\n- Docker secrets and configs for secure configuration management\n- Multi-datacenter deployment considerations and latency optimization\n- Sidecar patterns for collector deployment\n- Performance monitoring and overhead control strategies\n\n## Code Example\n\n```yaml\n# docker-compose.yml skeleton for distributed tracing\nversion: '3.8'\nservices:\n  api:\n    image: my-api:latest\n    deploy:\n      replicas: 2\n    environment:\n      - OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317\n      - OTEL_SERVICE_NAME=my-api\n      - OTEL_RESOURCE_ATTRIBUTES=service.name=my-api\n    depends_on:\n      - otel-collector\n  otel-collector:\n    image: otel/opentelemetry-collector-contrib:latest\n    deploy:\n      replicas: 1\n    volumes:\n      - ./otel-collector-config.yml:/etc/otelcol-contrib/config.yaml\n    command: [\"--config=/etc/otelcol-contrib/config.yaml\"]","diagram":"flowchart TD\n  API[API service]\n  Nginx[Nginx proxy]\n  OTEL[OpenTelemetry Collector]\n  Jaeger[Jaeger backend]\n  API --> Nginx\n  Nginx --> API\n  API --> OTEL\n  OTEL --> Jaeger","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Two Sigma","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:31:47.090Z","createdAt":"2026-01-17T22:39:07.222Z"},{"id":"q-3762","question":"In a three-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API endpoints, and add a small compliance sidecar that streams headers and audit data to a central collector via UDP without affecting request latency. Attach services to a single overlay network and implement a progressive canary that also validates a policy flag (X-Policy: strict) in 5% increments every 20s with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton?","answer":"Outline a three-node Swarm deployment using TLS secrets, a config for endpoints, an Nginx proxy, an API service, and a lightweight compliance sidecar that UDPs audit data to a collector with no measur","explanation":"Why This Is Asked\n- Tests ability to design a tight, auditable, policy-driven deployment with sidecars that don’t impact latency.\n\nKey Concepts\n- Docker secrets for TLS, Docker configs for runtime endpoints\n- Sidecar pattern for compliance/audit without altering app logic\n- UDP-based, zero-latency streaming to a centralized collector\n- Canary rollout with policy validation and automatic rollback\n- Proper health checks and overlay network wiring\n\nCode Example\n```yaml\nversion: '3.8'\nservices:\n  nginx:\n    image: nginx:stable\n    ports:\n      - 443:443\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 1\n        order: start-first\n    secrets:\n      - tls_cert\n      - tls_key\n    configs:\n      - source: endpoints\n        target: /etc/endpoints.json\n    networks:\n      - overlay-net\n  api:\n    image: my/api:latest\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 1\n        order: start-first\n        failure_action: rollback\n    secrets:\n      - tls_cert\n      - tls_key\n    configs:\n      - source: endpoints\n        target: /etc/endpoints.json\n    networks:\n      - overlay-net\n  compliance:\n    image: compliance-sidecar:latest\n    depends_on:\n      - api\n    networks:\n      - overlay-net\n    deploy:\n      resources:\n        limits:\n          cpus: '0.1'\n          memory: 128M\nsecrets:\n  tls_cert:\n    file: tls/api.crt\n  tls_key:\n    file: tls/api.key\nconfigs:\n  endpoints:\n    file: endpoints.json\nnetworks:\n  overlay-net:\n    external: true\n```\n\nFollow-up Questions\n- How would you handle cert rotation without restarting services?\n- How would you simulate and verify rollback behavior under load?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T08:43:24.663Z","createdAt":"2026-01-18T08:43:24.664Z"},{"id":"q-3803","question":"In a three-node docker-dca cluster across two data centers, deploy a TLS-enabled API behind an Nginx edge proxy. Use Vault to issue SPIFFE SVIDs, and a sidecar that validates them and enforces an OPA policy loaded via a Docker Config; include a lightweight log-shipper. Attach to a single overlay network. Implement a 20% canary rollout with latency/errors thresholds and automatic rollback. Provide exact commands and a docker-compose.yml skeleton?","answer":"Outline a zero-trust path: in a three-node docker-dca cluster across two data centers, deploy a TLS-enabled API behind an Nginx edge proxy. Use Vault to issue SPIFFE SVIDs, and a per-app sidecar that ","explanation":"## Why This Is Asked\nAssesses ability to design zero-trust with SPIFFE, Vault-based certs, policy enforcement, and safe rollouts in Docker DCA.\n\n## Key Concepts\n- Zero-trust networking\n- SPIFFE/SVIDs and Vault integration\n- Sidecar pattern for mTLS validation\n- OPA policies via Docker Config\n- Canary rollout safety checks\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n      - secrets:/secrets:ro\n  api:\n    image: myapi:latest\n    secrets:\n      - spa-cert\nvolumes:\n  secrets:\n    external: true\n```\n\n## Follow-up Questions\n- How would you rotate SPIFFE certs without downtime?\n- How would you test policy changes safely?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T10:31:32.924Z","createdAt":"2026-01-18T10:31:32.924Z"},{"id":"q-3933","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled REST API behind Traefik as the edge proxy. Configure Traefik's ACME to obtain TLS certificates from Let's Encrypt in staging. Attach all services to a single overlay network. Implement a 15% canary rollout of a new /status/v2 endpoint (v1 remains) using Traefik's weighted routing with health checks, automatic rollback on failures. Add a minimal OpenTelemetry tracing sidecar exporting to stdout; ensure trace headers propagate?","answer":"Set up a two-node docker-dca Swarm with Traefik as the edge proxy, TLS via Let’s Encrypt staging, and a single overlay network. Deploy api-v1 and a canary api-v2; steer 15% traffic to v2 using Traefik","explanation":"## Why This Is Asked\n\nTests ability to configure a lightweight canary in a real swarm, using Traefik as a modern edge proxy, and integrate observability with OpenTelemetry. It checks practical networking, TLS setup, and traffic shaping without requiring complex multi-cluster setups.\n\n## Key Concepts\n\n- Docker Swarm overlay networks and service deployment\n- Traefik ACME TLS with staging\n- Weighted canary routing and health-check-based rollback\n- Lightweight OpenTelemetry tracing (export to stdout) and header propagation\n\n## Code Example\n\n```javascript\n// Example: simple trace header propagation (conceptual)\nconst http = require('http');\nhttp.get({ hostname: 'api.example', path: '/status', headers: { 'Trace-Id': 'abc123' } }, (res) => {\n  // handle response\n});\n```\n\n## Follow-up Questions\n\n- How would you monitor the canary rollout with metrics and logs?\n- How to handle TLS certificate rotation during canary without downtime?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Scale Ai","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T15:47:17.632Z","createdAt":"2026-01-18T15:47:17.632Z"},{"id":"q-3944","question":"In a three-node docker-dca Swarm within a single data center, deploy a TLS-enabled API behind an Nginx edge proxy. Use Docker Secrets for TLS certificates and a Docker Config to supply a canary routing rule. Add a lightweight log-shipper as a sidecar and attach both services to a single overlay network. Implement a 15% canary rollout of a new API image with automatic rollback on failed health checks. Provide exact commands and a docker-compose.yml skeleton?","answer":"Proposed approach: three-node Swarm, TLS secrets mounted by nginx, a config with canary routing, and a log-shipper container. Deploy api and nginx on an overlay network; implement 15% canary by runnin","explanation":"## Why This Is Asked\nTests understanding of basic Swarm deployment, secret/config handling, and safe canary rollouts with health checks.\n\n## Key Concepts\n- Docker Secrets and Configs\n- Overlay networks and Swarm deploy\n- Canary rollouts and rollback on health failure\n- Basic log-shipper sidecar\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  api:\n    image: myorg/api:latest\n    secrets:\n      - tls.crt\n      - tls.key\n    configs:\n      - source: nginx_canary_conf\n        target: /etc/nginx/conf.d/canary.conf\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n      health_check:\n        test: [\"CMD-SHELL\", \"curl -f https://localhost/health || exit 1\"]\n        interval: 10s\n        timeout: 5s\n        retries: 3\n    networks:\n      - overlay_net\n  nginx:\n    image: nginx:alpine\n    secrets:\n      - tls.crt\n      - tls.key\n    configs:\n      - source: nginx_canary_conf\n        target: /etc/nginx/conf.d/canary.conf\n    deploy:\n      replicas: 2\n      update_config:\n        parallelism: 1\n        order: start-first\n    networks:\n      - overlay_net\n  log-shipper:\n    image: myorg/log-shipper:latest\n    volumes:\n      - logs:/var/log/app\n    deploy:\n      replicas: 1\n    networks:\n      - overlay_net\nvolumes:\n  logs:\nnetworks:\n  overlay_net:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you verify the 15% canary routing meets latency SLA?\n- How would you automate secret rotation without downtime?","diagram":"flowchart TD\n  A[User Request] --> B[Swarm Manager]\n  B --> C[Nginx Edge Proxy]\n  B --> D[API Replica Set]\n  C --> E[Canary Routing Config]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T16:42:23.443Z","createdAt":"2026-01-18T16:42:23.444Z"},{"id":"q-3981","question":"In a four-node docker-dca cluster across two data centers, deploy a TLS-enabled API behind an Nginx edge proxy. Use Vault to issue SPIFFE SVIDs; attach an Envoy sidecar per app to validate them and enforce tenant RBAC via OPA policies stored in Consul KV (refreshed via webhook). Attach all to one overlay network. Implement a progressive canary rollout of 15% steps every 30s with latency >200ms or error rate >2% triggering rollback. Provide exact commands and a docker-compose.yml skeleton?","answer":"Design multi-DC deployment with Vault SPIFFE SVIDs, Envoy sidecar enforcing per-tenant RBAC via OPA in Consul KV, and Nginx edge. Canary 15% every 30s, rollback on latency >200ms or error rate >2%. In","explanation":"## Why This Is Asked\nTests capability for complex, real-world docker-dca setups: SPIFFE SVIDs from Vault, Envoy as a policy-enforcing proxy, Consul KV-driven OPA policies, and geo-distributed canary rollouts with strict SLA boundaries.\n\n## Key Concepts\n- Multi-DC docker-dca deployment\n- Vault SPIFFE SVID provisioning\n- Envoy sidecar with mTLS and OPA RBAC via Consul KV\n- Webhook-driven policy refresh\n- Canary rollout discipline with latency/error budgets and automatic rollback\n\n## Code Example\n```javascript\n# docker-compose.yml skeleton (YAML content displayed in a JS code block for formatting)\nversion: '3.8'\nservices:\n  edge:\n    image: nginx:stable\n    ports:\n      - \"443:443\"\n    networks:\n      - web\n  api:\n    image: myapi:latest\n    networks:\n      - web\n    depends_on:\n      - edge\n  envoy:\n    image: envoyproxy/envoy-alpine:v1.25.0\n    networks:\n      - web\n# TLS, SPIFFE, and policy integration are configured via mounts/ENVs in real setup\nnetworks:\n  web:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you measure policy evaluation latency and ensure webhook refresh doesn’t become a bottleneck?\n- How would you simulate a DC failure and verify rollback guarantees in production-like conditions?","diagram":"flowchart TD\n  Client([Client]) --> Edge[Nginx Edge Proxy]\n  Edge --> App[App Service]\n  App --> Env[Envoy Sidecar]\n  Env --> Vault[Vault SPIFFE SVIDs]\n  Env --> Polis[OPA Policies (Consul KV)]\n  Client -. TLS .-> Edge","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Plaid","Square","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T18:41:16.663Z","createdAt":"2026-01-18T18:41:16.663Z"},{"id":"q-4237","question":"Three-node docker-dca Swarm across two data centers; deploy a TLS-enabled API behind an Nginx edge proxy. Enforce a Cosign-based supply-chain policy: only attested images for API and sidecars; add a gate sidecar that verifies attestations at startup with Vault keys. Attach to a single overlay network. Implement a 10% canary rollout with health checks and automatic rollback. Provide exact commands and docker-compose skeleton?","answer":"Use Cosign attestations for the API and all sidecars; store keys in Vault and provide a gate sidecar that runs cosign verify on startup to reject non-attested images. Route through TLS-enabled Nginx e","explanation":"## Why This Is Asked\nTests real-world supply-chain security in container deployments, using Cosign attestations, Vault-managed keys, and a gate sidecar to enforce policy before service start. Combines Swarm networking, TLS, and canary rollback under load.\n\n## Key Concepts\n- Image attestation with Cosign\n- Vault for key distribution and rotation\n- Gate sidecar for startup verification\n- Nginx TLS edge proxy integration\n- Canary rollout with health checks and rollback\n- Overlay network in Swarm\n\n## Code Example\n```javascript\n// gate sidecar startup check (pseudo)\nasync function verify(image){/* cosign verify against Vault key */}\nverify(process.env.IMAGE);\n```\n\n## Follow-up Questions\n- How would you test attestation failure scenarios in CI/CD?\n- How would you rotate Cosign keys without downtime?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Netflix","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T09:51:29.455Z","createdAt":"2026-01-19T09:51:29.455Z"},{"id":"q-4268","question":"In a two-node docker-dca cluster, deploy a TLS-enabled API behind an Nginx edge proxy. Use Redis as a feature flag to roll a 20% canary to a v2 endpoint, controlled by flag feature.canary.v2. Implement latency and error-rate thresholds (latency <300ms, error rate <5%) with automatic rollback. Provide exact commands and a docker-compose.yml skeleton to implement this setup?","answer":"Proposed approach: 2-node docker-dca Swarm with an Nginx TLS edge proxy and TLS certs in Secrets. Deploy Redis as the feature-flag store; canary routing sends 20% to /api/v2 when feature.canary.v2=1. ","explanation":"## Why This Is Asked\nTests practical canary rollout using a lightweight feature flag store, edge routing, and rollback logic. It also covers TLS handling and essential orchestration setup.\n\n## Key Concepts\n- Canary routing via feature flags in Redis\n- TLS termination at Nginx edge proxy\n- Lightweight health checks and rollback policy\n- Docker Compose/Swarm bootstrap and service interdependence\n\n## Code Example\n```yaml\n# docker-compose.yml (skeleton)\nversion: '3.8'\nservices:\n  edge:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    secrets:\n      - tls-cert\n    configs:\n      - source: nginx.conf\n        target: /etc/nginx/nginx.conf\n  api:\n    image: myorg/api:latest\n  redis:\n    image: redis:6-alpine\nsecrets:\n  tls-cert:\n    file: ./certs/server.crt\n  tls-key:\n    file: ./certs/server.key\nbr:\n  version: '3.8'\n```\n\n## Follow-up Questions\n- How would you extend this to 3+ nodes across data centers?\n- What metrics and dashboards would you build to verify rollout health?","diagram":"flowchart TD\n  A(Client) --> B[Edge TLS Nginx]\n  B --> C[API v1]\n  B --> D[API v2 (canary)]\n  D --> E[Redis canary flag]\n  E --> F[Health/Latency Monitor]\n  F --> G{Threshold breached?}\n  G -->|Yes| H[Rollback & flip flag]\n  G -->|No| I[Continue canary]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T10:58:50.382Z","createdAt":"2026-01-19T10:58:50.382Z"},{"id":"q-4345","question":"In a three-node docker-dca cluster across two data centers, deploy a TLS-enabled API behind an Nginx edge proxy. Enforce image provenance with Docker Content Trust (Notary) by signing base images and validating signatures in a dedicated 'sigver' sidecar before the request reaches the app. Use Vault to issue SPIFFE SVIDs; enforce an OPA policy loaded via a Docker Config to gate access. Implement a 20% canary rollout with latency and error-rate thresholds and automatic rollback. Provide exact commands and a docker-compose.yml skeleton?","answer":"I would sign images with Docker Content Trust, add a lightweight 'sigver' sidecar that validates signatures against Notary on container startup and before traffic; issue SVIDs with Vault for mTLS; fet","explanation":"## Why This Is Asked\nTests ability to design end-to-end trust from image provenance to runtime policy enforcement, plus canary control and rollback.\n\n## Key Concepts\n- Docker Content Trust/Notary for image provenance\n- SPIFFE/SVIDs via Vault for mTLS\n- OPA policies loaded via Docker Config\n- Sigver sidecar for per-request validation\n- Canary rollout with latency/error thresholds and rollback\n\n## Code Example\n```javascript\n// Pseudo example: verify image signature before starting app\nasync function verifySignature(image) {\n  const sig = await notary.verify(image);\n  if (!sig || !sig.valid) throw new Error('invalid image');\n  return true;\n}\n```\n\n## Follow-up Questions\n- How would you handle signature revocation and key rotation in this setup?\n- How would you scale the sigver and policy sidecars across nodes?\n","diagram":"flowchart TD\n  Client(Client) --> Edge[Nginx Edge Proxy]\n  Edge --> SigVer[Signature Verifier Sidecar]\n  SigVer --> App[App Container]\n  App --> Policy[OPA Policy Enforcer]\n  Policy --> Vault[Vault SPIFFE SVIDs]\n","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","LinkedIn","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T14:53:51.311Z","createdAt":"2026-01-19T14:53:51.312Z"},{"id":"q-4384","question":"In a three-node docker-dca cluster across two data centers, implement a per-tenant dynamic rate limiter as an Envoy-sidecar attached to the API container. The limiter reads quotas from Vault KV, caches in Redis, and uses a token-bucket or sliding-window approach. Edge TLS is terminated by Nginx; tenants are identified by a JWT in Authorization header validated by Vault OIDC. Provide exact commands and a docker-compose.yml skeleton?","answer":"Use Envoy as a per-tenant rate limiter sidecar tied to the API service. Validate JWT via Vault OIDC, fetch quotas from Vault KV on cache miss, store per-tenant state in Redis with short TTL, and enfor","explanation":"## Why This Is Asked\nTests ability to design per-tenant traffic control with dynamic quotas, secrets management, and a tight edge-data plane boundary. Requires knowledge of Envoy filters, Vault, Redis, and container wiring.\n\n## Key Concepts\n- Per-tenant rate limiting with Envoy sidecar\n- Vault KV storage and OIDC for JWT validation\n- Redis caching and TTL for quota state\n- Edge TLS termination with Nginx and secure service-to-service routing\n\n## Code Example\n```yaml\n# docker-compose.yml sketch\nversion: '3.8'\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx/conf.d:/etc/nginx/conf.d\n  api:\n    image: myorg/api:latest\n  envoy-svc:\n    image: envoyproxy/envoy:v1.26.0\n    depends_on:\n      - api\n  vault:\n    image: vault:1.14\n  redis:\n    image: redis:7\n```\n\n## Follow-up Questions\n- How would you rotate JWT signing keys without downtime?\n- How would you scale quotas across multiple regions?\n","diagram":"flowchart TD\n  A[Client Request] --> B[Nginx Edge TLS]\n  B --> C[Envoy RateLimiter Sidecar]\n  C --> D[API Service]\n  D --> E[(Redis Cache)]\n  E --> F[Vault KV: quotas]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","OpenAI","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T16:49:30.908Z","createdAt":"2026-01-19T16:49:30.908Z"},{"id":"q-4491","question":"In a two-node docker-dca cluster, deploy a TLS-enabled API behind an Nginx edge proxy. Implement 10% canary routing to a v2 image using a Lua-based split controlled by a Docker Config flag. Enforce image provenance with cosign; reject unsigned images at the edge. Provide exact commands and a docker-compose.yml skeleton?","answer":"Cosign sign both images: cosign sign myapi:v1; cosign sign myapi:v2. Deploy nginx edge with a Lua script to route 10% of requests to v2 via a canary_percent flag from Docker Config. Verify signatures ","explanation":"## Why This Is Asked\nPractical edge-routing scenario with basic security.\n\n## Key Concepts\n- TLS termination at edge\n- Lua-based traffic split controlled by Docker Config\n- Image provenance with cosign\n- Canary and rollout basics\n- Docker Secrets/Configs usage\n\n## Code Example\n```lua\n-- nginx Lua for canary routing (conceptual)\nmath.randomseed(ngx.now())\nlocal rate = tonumber(ngx.shared.canary_ratio:get('v2') or '0.1')\nif math.random() < rate then\n  ngx.exec('@v2')\nelse\n  ngx.exec('@v1')\nend\n```\n\n## Follow-up Questions\n- How would you extend to multiple regions with per-region canaries?\n- How would you instrument and alert on canary success/failure?","diagram":"flowchart TD\n  A[Edge proxy] --> B[TLS terminated]\n  B --> C[Canary check]\n  C --> D[Back-end v1]\n  C --> E[Back-end v2]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Scale Ai","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T20:53:55.044Z","createdAt":"2026-01-19T20:53:55.044Z"},{"id":"q-4507","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled API behind an Nginx edge proxy and enforce mutual TLS (mTLS) with client certificates issued by a private CA. Store server and CA certs as Docker secrets, configure Nginx to require and validate client certs, and ensure the API receives the client identity via a header. Provide exact docker-compose.yml skeleton and the certificate generation steps, plus test commands?","answer":"Generate a private CA, issue server and client certificates, and store them as Docker secrets. Configure Nginx with `ssl_verify_client on; ssl_client_certificate /certs/ca.pem; proxy_set_header X-Client-Subject $ssl_client_s_dn;` to enforce mutual TLS and propagate client identity to the backend API.","explanation":"## Why This Is Asked\nTests practical mTLS implementation, Docker secrets management, and edge proxy configuration in a Swarm environment. Evaluates operational skills for secure service-to-service communication.\n\n## Key Concepts\n- Docker secrets for TLS certificate management\n- Nginx mutual TLS verification and client certificate validation\n- Client identity propagation to backend services via HTTP headers\n\n## Code Example\n```yaml\n# skeleton docker-compose.yml\nversion: '3.9'\nservices:\n  edge:\n    image: nginx:alpine\n    ports:\n      - '443:443'\n    secrets:\n      - source: nginx_server_cert\n        target: server.crt\n      - source: nginx_server_key\n        target: server.key\n      - source: nginx_ca_cert\n        target: ca.pem\n    configs:\n      - source: nginx_config\n        target: /etc/nginx/nginx.conf\n  api:\n    image: your-api:latest\n    deploy:\n      replicas: 2\nsecrets:\n  nginx_server_cert:\n    external: true\n  nginx_server_key:\n    external: true\n  nginx_ca_cert:\n    external: true\nconfigs:\n  nginx_config:\n    external: true\n```\n\n## Certificate Generation\n```bash\n# Create private CA\nopenssl genrsa -out ca.key 4096\nopenssl req -new -x509 -days 365 -key ca.key -out ca.pem\n\n# Generate server certificate\nopenssl genrsa -out server.key 2048\nopenssl req -new -key server.key -out server.csr\nopenssl x509 -req -in server.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out server.crt -days 365\n\n# Generate client certificate\nopenssl genrsa -out client.key 2048\nopenssl req -new -key client.key -out client.csr\nopenssl x509 -req -in client.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out client.crt -days 365\n\n# Create Docker secrets\ndocker secret create nginx_server_cert server.crt\ndocker secret create nginx_server_key server.key\ndocker secret create nginx_ca_cert ca.pem\n```\n\n## Testing Commands\n```bash\n# Test with client certificate\ncurl --cert client.crt --key client.key --cacert ca.pem https://your-service:443/api\n\n# Test without client certificate (should fail)\ncurl --cacert ca.pem https://your-service:443/api\n\n# Verify client identity header\ncurl --cert client.crt --key client.key --cacert ca.pem https://your-service:443/api -v | grep X-Client-Subject\n```","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:27:44.837Z","createdAt":"2026-01-19T21:48:03.538Z"},{"id":"q-4640","question":"Across two data centers, deploy a TLS-enabled API behind an Nginx edge proxy in a docker-dca cluster. Enforce mTLS between services with SPIFFE SVIDs issued by Vault, and attach a sidecar that validates the SVIDs and enforces an OPA policy loaded via Docker Config for per-tenant feature gates. Implement a canary rollout with traffic shifting and automatic rollback. Include exact bootstrap commands and a minimal docker-compose skeleton?","answer":"To solve this, terminate TLS at the edge, enable mTLS inside the cluster via Vault-issued SPIFFE SVIDs, and run a cert-verifying sidecar next to each service. The OPA policy, stored in a Docker Config","explanation":"## Why This Is Asked\nTests ability to design multi-DC, mTLS, SPIFFE, Vault, OPA, canary strategy in docker-dca, with real-world constraints and measurable rollouts.\n\n## Key Concepts\n- mTLS inside cluster, SPIFFE SVIDs, Vault integration\n- Sidecar pattern for security and policy enforcement\n- Docker Config-based policies and per-tenant gates\n- Canary rollouts and automatic rollback using traffic shaping\n- Observability thresholds and rollback criteria\n\n## Code Example\n```bash\n# bootstrap sketch\ndocker swarm init\nvault server -config=config.hcl\nvault write ... # issue SVIDs\n```\n```\n\n## Follow-up Questions\n- How to test canary path under latency spikes?\n- How to rotate SVIDs without downtime?\n```\n","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:57:01.519Z","createdAt":"2026-01-20T05:57:01.519Z"},{"id":"q-4660","question":"In a two-data-center docker-dca cluster, design a cross-tenant image attestation workflow that runs before deployment: an attest sidecar validates base image digests against an external Notary v2 attestation service, with tenant policies stored in an OPA Docker Config and enforced by the edge proxy. Implement a 10% canary rollout with latency budgets and automatic rollback. Provide exact commands and a docker-compose.yml skeleton?","answer":"Describe an image-attestation workflow for docker-dca: an attest sidecar calls an external Notary v2 attestor to verify the image digest against a tenant-scoped policy stored in an OPA Docker Config; ","explanation":"## Why This Is Asked\n\nTests ability to design a pre-deploy attestation pipeline using Notary v2, OPA, and canary strategies in a docker-dca multi-DC setup.\n\n## Key Concepts\n\n- Image attestation with Notary v2\n- Attestation sidecar pattern\n- OPA policies via Docker Config\n- Edge-proxy gating\n- Canary rollout with latency budgets\n\n## Code Example\n\n```yaml\nversion: \"3.9\"\nservices:\n  edge:\n    image: nginx:stable\n  attest:\n    image: attestor/notary-v2:latest\n  app:\n    image: registry.example/tenant-app:latest\n    depends_on:\n      - attest\n    environment:\n      - TENANT=tenant-a\n```\n\n## Follow-up Questions\n\n- How would you rotate attestation keys and revoke compromised policies?\n- How would you measure success during canary and trigger rollback?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Plaid","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T07:05:32.234Z","createdAt":"2026-01-20T07:05:32.234Z"},{"id":"q-4996","question":"In a two-node docker-dca cluster, deploy a TLS-enabled API behind a Traefik edge proxy. Use a lightweight in-cluster CA (OpenSSL) to issue and rotate certificates for both the API and the proxy; store certs in Docker Secrets and configure mTLS between Traefik and the API. Add a tiny feature flag service via Docker Config that toggles a field in the API response per-tenant. Implement a 10% canary routing to a forked backend; provide a docker-compose skeleton and exact bootstrap steps?","answer":"Bootstrap a lightweight OpenSSL CA, issue certificates for Traefik and the API, and load them as Docker Secrets. Configure Traefik to enforce mTLS with clientAuth and TLS settings, route via TLS to the API, add a canary backend with weighted routing, and implement feature flags using Docker Config for per-tenant toggles.","explanation":"## Why This Is Asked\n\nTests comprehensive TLS setup, mTLS implementation without external tools like Vault, feature flag management with Docker Config, and canary deployment strategies in a beginner-friendly Docker Swarm scenario.\n\n## Key Concepts\n\n- **TLS mutual authentication** with a lightweight in-cluster CA using OpenSSL\n- **Docker Secrets** for secure certificate storage and management\n- **Docker Config** for per-tenant feature flag configuration\n- **Traefik edge proxy** dynamic routing and weighted canary deployments\n- **Certificate rotation** strategies and automated renewal processes\n- **Simple bootstrap steps** with a minimal docker-compose skeleton\n\n## Code Example\n\n```bash\n# Bootstrap OpenSSL CA\n#!/bin/bash\n# Create CA\nopenssl req -new -x509 -days 365 -nodes -out ca.crt -keyout ca.key -subj \"/CN=My-CA\"\n\n# Create Traefik certs\nopenssl req -new -nodes -out traefik.csr -keyout traefik.key -subj \"/CN=traefik\"\nopenssl x509 -req -in traefik.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out traefik.crt -days 365\n\n# Create API certs\nopenssl req -new -nodes -out api.csr -keyout api.key -subj \"/CN=api\"\nopenssl x509 -req -in api.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out api.crt -days 365\n\n# Create Docker Secrets\ndocker secret create ca.crt ca.crt\ndocker secret create traefik.key traefik.key\ndocker secret create traefik.crt traefik.crt\ndocker secret create api.key api.key\ndocker secret create api.crt api.crt\n\n# Create feature flag config\necho '{\"tenant_a\": {\"premium_features\": true}, \"tenant_b\": {\"premium_features\": false}}' > feature-flags.json\ndocker config create feature-flags feature-flags.json\n```\n\n```yaml\n# docker-compose.yml\nversion: '3.8'\n\nservices:\n  traefik:\n    image: traefik:v2.10\n    command:\n      - --api.insecure=true\n      - --providers.docker=true\n      - --entrypoints.websecure.address=:443\n      - --entrypoints.websecure.http.tls=true\n      - --entrypoints.websecure.http.tls.options=default\n      - --entrypoints.websecure.http.tls.certResolver=myresolver\n      - --certificatesresolvers.myresolver.acme.tlschallenge=true\n      - --serversTransport.insecureSkipVerify=false\n    ports:\n      - \"443:443\"\n      - \"8080:8080\"\n    secrets:\n      - ca.crt\n      - traefik.key\n      - traefik.crt\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    deploy:\n      replicas: 1\n\n  api:\n    image: my-api:latest\n    environment:\n      - TLS_CERT_PATH=/run/secrets/api.crt\n      - TLS_KEY_PATH=/run/secrets/api.key\n      - CA_CERT_PATH=/run/secrets/ca.crt\n    secrets:\n      - api.crt\n      - api.key\n      - ca.crt\n    configs:\n      - feature-flags\n    deploy:\n      replicas: 2\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api.rule=Host(`api.example.com`)\"\n        - \"traefik.http.routers.api.entrypoints=websecure\"\n        - \"traefik.http.routers.api.tls=true\"\n        - \"traefik.http.routers.api.tls.options=default\"\n        - \"traefik.http.services.api.loadbalancer.server.port=8443\"\n\n  api-canary:\n    image: my-api:canary\n    environment:\n      - TLS_CERT_PATH=/run/secrets/api.crt\n      - TLS_KEY_PATH=/run/secrets/api.key\n      - CA_CERT_PATH=/run/secrets/ca.crt\n    secrets:\n      - api.crt\n      - api.key\n      - ca.crt\n    configs:\n      - feature-flags\n    deploy:\n      replicas: 1\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-canary.rule=Host(`api.example.com`)\"\n        - \"traefik.http.routers.api-canary.entrypoints=websecure\"\n        - \"traefik.http.routers.api-canary.tls=true\"\n        - \"traefik.http.services.api-canary.loadbalancer.server.port=8443\"\n        - \"traefik.http.services.api.loadbalancer.mirrors.api-canary.weight=10\"\n\nsecrets:\n  ca.crt:\n    external: true\n  traefik.key:\n    external: true\n  traefik.crt:\n    external: true\n  api.key:\n    external: true\n  api.crt:\n    external: true\n\nconfigs:\n  feature-flags:\n    external: true\n```\n\n## Implementation Steps\n\n1. **Initialize CA infrastructure** using OpenSSL commands\n2. **Generate and sign certificates** for both Traefik and API services\n3. **Create Docker Secrets** for secure certificate distribution\n4. **Configure Traefik** with TLS and mTLS settings\n5. **Set up canary deployment** with 10% weighted routing\n6. **Implement feature flags** using Docker Config for tenant-specific toggles\n7. **Deploy stack** and verify TLS handshake and mTLS enforcement","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Google","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T04:32:31.359Z","createdAt":"2026-01-20T22:50:46.791Z"},{"id":"q-5175","question":"In a two-node docker-dca cluster, deploy a TLS-enabled API behind an Nginx edge proxy. Extend with OpenTelemetry tracing: instrument the API, add an otel-collector sidecar, and export traces to Jaeger; ensure trace context propagates through Nginx to the API; provide a docker-compose.yml skeleton and bootstrap commands; include a quick validation by hitting an endpoint and checking Jaeger UI?","answer":"Instrument the API with OpenTelemetry (Node/Python). Export traces via OTLP to an otel-collector sidecar, which forwards to Jaeger. Propagate trace-context through Nginx by enabling W3C traceparent he","explanation":"## Why This Is Asked\nTests ability to add observability with OpenTelemetry in a docker-dca context, ensuring end-to-end trace propagation from edge to service and basic validation.\n\n## Key Concepts\n- OpenTelemetry instrumentation and OTLP exporter\n- otel-collector as a sidecar and Jaeger backend\n- Trace context propagation (traceparent/tracestate)\n- docker-compose scaffolding for api, nginx, collector\n- Basic end-to-end validation via Jaeger UI\n\n## Code Example\n```javascript\n// Node.js OpenTelemetry setup (simplified)\nconst { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-otlp-http');\nconst { SimpleSpanProcessor } = require('@opentelemetry/tracing');\n\nconst provider = new NodeTracerProvider();\nprovider.addSpanProcessor(new SimpleSpanProcessor(\n  new OTLPTraceExporter({ url: 'http://otel-collector:4318/v1/traces' })\n));\nprovider.register();\n```\n\n## Follow-up Questions\n- How would you adjust sampling and metric correlation to avoid perf impact on a busy API?\n- How would you test trace failures or collector downtime without losing observability?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Discord"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T09:45:25.513Z","createdAt":"2026-01-21T09:45:25.513Z"},{"id":"q-856","question":"You're running a Docker Swarm with services frontend, api, and worker. A feature-flag config is provided via Docker Config mounted at /etc/flags.json in all containers. You must rotate this config weekly with zero downtime. Describe the exact sequence of commands to create a new config version, rotate the services to use it, and implement a graceful reload inside apps so the new flags are picked up without losing requests. Include any Swarm update options you would tune?","answer":"Create a new config file (e.g., /tmp/flags.v2.json) and docker config create flags.v2 /tmp/flags.v2.json. Then update each service: docker service update --config-rm flags.v1 --config-add flags.v2 --u","explanation":"## Why This Is Asked\nTo assess practical config rotation in Swarm and application reload behavior.\n\n## Key Concepts\n- Docker Config rotation\n- Rolling updates with update-parallelism and update-delay\n- Graceful reload semantics (SIGHUP or /reload)\n\n## Code Example\n```javascript\n// Node.js reload handler\nconst fs = require('fs');\nlet flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\nprocess.on('SIGHUP', () => {\n  flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\n  // apply flags to runtime features\n});\n```\n\n## Follow-up Questions\n- How would you test the zero-downtime rollout in a CI pipeline?\n- What failure scenarios would prompt you to revert the config rotation?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:38:40.484Z","createdAt":"2026-01-12T13:38:40.484Z"},{"id":"q-862","question":"In a Docker Swarm with a stateful web app that uses Postgres, you must roll out version 3.2 with a DB schema migration and zero downtime. Propose a concrete upgrade plan that uses a start-first, one-task-at-a-time update, a separate migration container, and post-migration validation. Include exact Swarm commands and a minimal docker-compose snippet showing update_config?","answer":"Plan: run DB migration first in a dedicated one-off container, then perform a start-first, one-task-at-a-time web upgrade. Commands: docker run --rm --network swarm_net migrate:3.2; docker service upd","explanation":"## Why This Is Asked\nAssesses ability to coordinate schema migrations with zero downtime, manage Swarm update strategies, and handle rollback safely.\n\n## Key Concepts\n- Start-first updates and parallelism control\n- Separate migration container orchestration\n- Post-migration validation and rollback\n- Health checks and observability during upgrade\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  web:\n    image: myapp:3.2\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 15s\n        order: start-first\n```\n\n## Follow-up Questions\n- How would you handle long-running migrations?\n- How ensure data consistency with read replicas during upgrade?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:43:29.032Z","createdAt":"2026-01-12T13:43:29.032Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":54,"beginner":17,"intermediate":17,"advanced":20,"newThisWeek":41}}