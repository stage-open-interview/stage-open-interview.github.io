{"questions":[{"id":"q-1392","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API across an overlay network and ensure zero-downtime upgrades via canary, using update_config (start-first, parallelism 1). Outline the exact sequence of commands to init/join the swarm, create the overlay, deploy the service with update settings, and perform a canary upgrade with health checks. Include a minimal docker-compose snippet showing update_config?","answer":"Init swarm on node A: docker swarm init --advertise-addr <A>; join B/C: docker swarm join --token <tok> <A>:2377; overlay: docker network create -d overlay --attachable app-net; deploy: docker service","explanation":"## Why This Is Asked\nTests practical mastery of Swarm lifecycle, overlay networking, and zero-downtime upgrades in multi-datacenter setups.\n\n## Key Concepts\n- Docker Swarm init/join and multi-datacenter networking\n- Overlay networks and service deployment in Swarm\n- update_config for canary upgrades and health checks\n\n## Code Example\n```docker-compose\nversion: '3.8'\nservices:\n  api:\n    image: nginx:stable\n    networks:\n      - app-net\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\nnetworks:\n  app-net:\n    driver: overlay\n```\n\n## Follow-up Questions\n- How would you handle service traffic shifting for canary without external LB?\n- What are failure_action and monitor thresholds used for in update_config?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Cloudflare","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:52:07.307Z","createdAt":"2026-01-13T14:52:07.307Z"},{"id":"q-1412","question":"Scenario: you’re building a beginner-friendly Docker Compose setup for a FastAPI microservice with PostgreSQL on a single host. Create Dockerfiles for the app and an init script, plus a docker-compose.yml with a named volume for Postgres data, healthchecks, and a startup script that waits for PostgreSQL on port 5432 before starting the app. Explain the exact files, commands, and deployment sequence?","answer":"I would dockerize the FastAPI app with Python 3.11, add a Postgres container, and provide a docker-compose.yml with services app and db, a named volume pgdata, environment vars, and healthchecks. Incl","explanation":"## Why This Is Asked\nTests practical Docker Compose skills: multi-service setup, data persistence, healthchecks, startup dependencies.\n\n## Key Concepts\n- Dockerfile basics, Python 3.11\n- Postgres container with pgdata volume\n- docker-compose networks/depends_on healthchecks\n- wait-for-it pattern for DB readiness\n\n## Code Example\n```yaml\n# docker-compose.yaml (excerpt)\nversion: '3.9'\nservices:\n  app:\n    build: ./app\n    ports:\n      - '8000:8000'\n    depends_on:\n      - db\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 10s\n      retries: 5\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: example\n    volumes:\n      - pgdata:/var/lib/postgresql/data\nvolumes:\n  pgdata:\n    name: pgdata\n```\n\n## Follow-up Questions\n- How would you add a migration step to initialize schemas?\n- How would you scale this with separate networks or secrets management?","diagram":"flowchart TD\nA[Developer writes app] --> B[Build Dockerfile]\nB --> C[Create docker-compose.yaml]\nC --> D[Start stack with docker compose up -d]\nD --> E[Healthchecks verify readiness]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:51:50.736Z","createdAt":"2026-01-13T15:51:50.737Z"},{"id":"q-1443","question":"In a 3-node Swarm across DC-A and DC-B, deploy a stateless API via overlay api-net with DC-affinity (2 replicas in DC-A and 1 in DC-B). Outline the exact CLI steps to init/join, create the overlay, and deploy two services with update_config (order: start-first, parallelism: 1). Describe a canary upgrade process that gradually updates replicas across DCs and validates with health checks. Include a minimal docker-compose snippet showing the two services, the overlay network, and update_config?","answer":"Init Swarm on DC-A; join DC-B; create overlay api-net; deploy two services: api-dcA with 2 replicas constrained to DC-A and api-dcB with 1 replica constrained to DC-B, both on api-net and update_confi","explanation":"## Why This Is Asked\nTests cross-DC orchestration, DC-aware placement, and canary upgrades using Docker Swarm update_config.\n\n## Key Concepts\n- Overlay networks spanning DCs\n- Placement constraints and spread/preference for DC distribution\n- update_config for staged upgrades\n- Canary rollout and health-check driven promotion\n\n## Code Example\n```javascript\nversion: \"3.8\"\nservices:\n  api-dcA:\n    image: myapi:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-A\n      networks:\n        - api-net\n  api-dcB:\n    image: myapi:latest\n    deploy:\n      replicas: 1\n      update_config:\n        order: start-first\n        parallelism: 1\n      placement:\n        constraints:\n          - node.labels.dc == DC-B\n      networks:\n        - api-net\nnetworks:\n  api-net:\n```\n\n## Follow-up Questions\n- How would you monitor canary success across DCs and automate rollback if latency spikes? \n- How would you adapt this for a rolling upgrade with multiple versions concurrently?","diagram":"flowchart TD\n  A[Init Swarm in DC-A] --> B[Join DC-B]\n  B --> C[Create overlay api-net]\n  C --> D[Deploy two services with update_config]\n  D --> E[Canary rollout across DCs]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:34:28.800Z","createdAt":"2026-01-13T17:34:28.803Z"},{"id":"q-1530","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API with TLS termination that uses Vault for dynamic TLS certificate rotation. Use Docker secrets to distribute certs, and implement a lightweight sidecar that refreshes certificates without dropping connections. Configure a canary-style rolling upgrade ensuring zero-downtime during cert rotations. Outline the exact steps: swarm init/join, overlay network creation, stack/deploy with secret handling, and the certificate rotation workflow with health checks?","answer":"Plan: initialize a 3-node Docker Swarm across two data centers, create an overlay network, deploy a stack with API and sidecar containers, mount Vault-issued certificates as Docker secrets and rotate them via the sidecar without container restarts, and perform a canary-style rolling upgrade ensuring zero-downtime during certificate rotations.","explanation":"## Why This Is Asked\nTests multi-datacenter Docker Swarm setup, TLS automation with HashiCorp Vault, Docker secrets management, and zero-downtime deployment strategies.\n\n## Key Concepts\n- Docker Swarm spanning multiple data centers\n- Docker secrets with external secret management (Vault)\n- Sidecar pattern for live certificate rotation\n- Update configuration with start-first for zero-downtime upgrades\n- Health checks and canary rollout strategies\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  api:\n    image: myorg/api:latest\n    ports:\n      - \"80:80\"\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n      healthcheck:\n        test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:80/health\"]\n        interval: 30s\n        timeout: 10s\n        retries: 3\n  sidecar:\n    image: myorg/cert-rotator:latest\n    secrets:\n      - source: tls_cert\n        target: tls.crt\n      - source: vault_token\n        target: vault.token\n    deploy:\n      replicas: 1\nsecrets:\n  tls_cert:\n    external: true\n  vault_token:\n    external: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:10:39.873Z","createdAt":"2026-01-13T20:46:17.744Z"},{"id":"q-1579","question":"Design a secret-rotation workflow for a Docker Swarm stack that uses Vault to rotate a TLS cert and a database credential with zero downtime. Use Swarm secrets and a rolling update (start-first). Outline exact steps: swarm init/join, overlay network, create secrets, deploy stack, Vault rotate trigger, service update commands. Include a minimal docker-compose snippet showing secret usage and update_config?","answer":"Plan: Vault issues new TLS certificate and database credential; create new Swarm secrets (e.g., api-tls-v2, db-cred-v2); perform service updates with `docker service update --secret-add` then `--secret-rm`, using update_config with start-first strategy for zero downtime.\n\n## Implementation Steps\n\n1. **Initialize Swarm cluster**\n   ```bash\n   docker swarm init --advertise-addr <MANAGER-IP>\n   docker swarm join --token <TOKEN> <MANAGER-IP>:2377\n   ```\n\n2. **Create overlay network**\n   ```bash\n   docker network create --driver overlay --attachable app-network\n   ```\n\n3. **Create initial secrets from Vault**\n   ```bash\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v1 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v1 -\n   ```\n\n4. **Deploy stack with rolling update configuration**\n   ```yaml\n   version: '3.8'\n   services:\n     api:\n       image: myapp:latest\n       secrets:\n         - source: api-tls-v1\n           target: /app/tls.crt\n         - source: db-cred-v1\n           target: /app/db-cred\n       networks:\n         - app-network\n       update_config:\n         parallelism: 1\n         delay: 10s\n         order: start-first\n       healthcheck:\n           test: [\"CMD\", \"curl\", \"-f\", \"https://localhost:8443/health\"]\n           interval: 30s\n           timeout: 10s\n           retries: 3\n   ```\n\n5. **Vault rotation trigger**\n   - Vault generates new TLS certificate and database credential\n   - Automation script detects rotation event\n\n6. **Service update with new secrets**\n   ```bash\n   # Create new secret versions\n   vault kv get -field=cert secret/api/tls | docker secret create api-tls-v2 -\n   vault kv get -field=cred secret/api/db | docker secret create db-cred-v2 -\n   \n   # Update service to add new secrets\n   docker service update api \\\n     --secret-add source=api-tls-v2,target=/app/tls.crt \\\n     --secret-add source=db-cred-v2,target=/app/db-cred\n   \n   # Remove old secrets after health checks pass\n   docker service update api \\\n     --secret-rm api-tls-v1 \\\n     --secret-rm db-cred-v1\n   ```","explanation":"## Why This Is Asked\nDemonstrates practical secret lifecycle management in Docker Swarm, integrating Vault for automated rotation with zero-downtime upgrades and proper secret versioning.\n\n## Key Concepts\n- Swarm secrets versioning and dynamic reattachment\n- Vault-based rotation triggers and secret provisioning\n- Rolling updates with start-first strategy to avoid downtime\n- Health checks to confirm new secrets are loaded before removing old ones\n- Atomic secret updates using add-then-remove pattern\n\n## Code Example\n```javascript\n// Pseudo-automation: rotate Vault-derived Swarm secrets\nasync function rotateSecrets(serviceName, vaultPath) {\n  // Fetch new credentials from Vault\n  const newCreds = await vault.read(vaultPath);\n  \n  // Create new Swarm secrets\n  const newSecrets = await createSwarmSecrets(newCreds);\n  \n  // Update service with new secrets\n  await updateService(serviceName, newSecrets);\n  \n  // Verify health before cleanup\n  await verifyServiceHealth(serviceName);\n  \n  // Remove old secrets\n  await cleanupOldSecrets(serviceName);\n}\n```","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Databricks","Hashicorp"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:56:17.721Z","createdAt":"2026-01-13T22:45:30.688Z"},{"id":"q-1628","question":"Scenario: In a 3-node Swarm across two DCs, deploy an API service behind Traefik with image signing enforcement (cosign/DOCKER_CONTENT_TRUST) and implement a canary upgrade to v2 with a 10% traffic split via a separate api-v2-canary service. Outline exact commands, Swarm update_config usage, and docker-compose/service definitions to achieve zero-downtime upgrade and safe rollback?","answer":"Enable Docker Content Trust and cosign signing on all nodes (DOCKER_CONTENT_TRUST=1; cosign sign). Deploy api-v1 and a canary api-v2-canary behind Traefik with a 10% canary route. Use update_config { ","explanation":"## Why This Is Asked\nEvaluates image provenance, canary sequencing, and Swarm upgrade semantics in a multi-datacenter setup.\n\n## Key Concepts\n- Image signing with cosign and DOCKER_CONTENT_TRUST\n- Swarm update_config for controlled upgrades\n- Traffic splitting via an in-cluster reverse proxy (Traefik)\n- Canary pattern and safe rollback in production\n\n## Code Example\n```javascript\n// illustrative docker-compose-like snippet (Traefik routing hints)\nservices:\n  api-v1:\n    image: registry.example.com/api:v1\n    deploy:\n      replicas: 4\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v1.rule=Host(`api.example.com` )\"\n  api-v2-canary:\n    image: registry.example.com/api:v2-canary\n    deploy:\n      replicas: 1\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.api-v2-canary.rule=Host(`canary.api.example.com` )\"\n```\n\n## Follow-up Questions\n- How would key rotation and automatic signing verification be automated?\n- How would you measure canary health and decide promotion/rollback automatically?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:16:19.227Z","createdAt":"2026-01-14T04:16:19.227Z"},{"id":"q-1653","question":"Scenario: On a single host, implement a beginner-friendly Docker Compose stack: a Node.js API that talks to Redis and a Fluent Bit logging service that reads logs from the API via a shared volume and forwards them to stdout. Provide a Dockerfile for the API, a docker-compose.yml with api, redis, fluent-bit, a logs volume, and healthchecks; explain the run steps and verification?","answer":"Create a docker-compose.yml with api, redis, and fluent-bit services on one host, plus a shared logs volume. The API writes to /var/log/app/app.log; Fluent Bit tails that file and forwards to stdout. ","explanation":"## Why This Is Asked\nTests practical docker-compose discipline: multi-service coordination, logging discipline, and health checks.\n\n## Key Concepts\n- docker-compose multi-service orchestration\n- log aggregation with Fluent Bit\n- log file sharing via volumes\n- minimal health checks for API service\n\n## Code Example\n```dockerfile\n# Dockerfile for API\nFROM node:18\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD node server.js\n```\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  api:\n    build: ./api\n    depends_on:\n      - redis\n    environment:\n      - REDIS_URL=redis://redis:6379\n    healthcheck:\n      test: curl -f http://localhost:3000/health || exit 1\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - ./logs:/var/log/app\n  redis:\n    image: redis:7\n  fluent-bit:\n    image: fluent/fluent-bit:1.9\n    volumes:\n      - ./logs:/var/log/app\n      - ./fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf\n    depends_on:\n      - api\n```\n\n## Follow-up Questions\n- How would you extend this to ship logs to an external system\n- How would you ensure log retention and rotate the log files","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Instacart","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:35:42.804Z","createdAt":"2026-01-14T05:35:42.804Z"},{"id":"q-1688","question":"Beginner-level: design a local docker-compose stack for a Node.js API that uses Redis as a cache. Provide a Dockerfile for the API, a startup script that waits for Redis to be reachable on 6379 before starting, and a docker-compose.yml with healthchecks for both services on a shared network. Include exact file contents or minimal snippets, the commands to build and run, and how to validate a cache-hit endpoint?","answer":"Build a Node.js API image with a Dockerfile, and a start script wait-for-redis.sh that pings redis:6379 until ready, then runs node index.js. In docker-compose.yml, define services api and redis on a ","explanation":"Why This Is Asked\nTests ability to coordinate container startup and readiness in Compose using a startup gate and healthchecks.\n\nKey Concepts\n- Dockerfile for Node.js\n- startup gating with a wait script\n- docker-compose healthchecks\n- Docker networking and service discovery\n\nCode Example\n```javascript\n# Dockerfile\nFROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\n# Start directly with node (no quotes) for simplicity\nCMD node index.js\n```\n```javascript\n# wait-for-redis.sh (simplified)\nuntil nc -z  redis 6379; do\n  sleep 0.2\ndone\nexec \"$@\"\n```\n```javascript\n# docker-compose.yml\nversion: '3.9'\nservices:\n  api:\n    build: .\n    ports:\n      - 3000:3000\n    depends_on:\n      - redis\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    command: [\"sh\",\"/wait-for-redis.sh\",\"redis\",\"node\",\"index.js\"]\n  redis:\n    image: redis:7-alpine\n    ports:\n      - 6379:6379\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\nnetworks:\n  default:\n    name: appnet\n```\n\nFollow-up Questions\n- How would you adapt for an optional Redis cache with a fallback?\n- How would you test failure of Redis and verify API behavior?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","MongoDB","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:58:39.175Z","createdAt":"2026-01-14T06:58:39.175Z"},{"id":"q-1760","question":"In a three-node Docker Swarm spanning two data centers, introduce a new internal auth service that all APIs depend on. Roll it out with zero downtime and a canary, using update_config (start-first, parallelism 1), Docker Secrets, and a routing shim. Provide exact commands to init/join the swarm, create the overlay, deploy the stack, add the secret, and perform the canary upgrade with health checks?","answer":"Two-stage canary: deploy auth-v2 with 1 replica and route 5% of traffic to it; ensure health checks pass; then roll the main stack with update_config start-first, parallelism 1. Commands: docker swarm","explanation":"## Why This Is Asked\nRealistic multi-datacenter upgrades require controlled rollouts with canary, health checks, and secrets. This tests operational discipline and deep Docker Swarm knowledge.\n\n## Key Concepts\n- Swarm upgrades with update_config; - Canaries across regions; - Secrets management; - Overlay networking; - Health checks and rollback.\n\n## Code Example\n```javascript\nversion: '3.8'\nservices:\n  auth:\n    image: myrepo/auth:canary\n    secrets:\n      - source: auth-secret\n        target: /etc/auth/secret.json\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nsecrets:\n  auth-secret:\n    external: true\n```\n\n## Follow-up Questions\n- How would you automate canary traffic routing without a reverse proxy? \n- How would you verify no active sessions are dropped during promotion?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:46:53.036Z","createdAt":"2026-01-14T09:46:53.036Z"},{"id":"q-1786","question":"In a 3-node Docker Swarm spanning two data centers, deploy a GPU-accelerated model-serving API (TorchServe) using the NVIDIA runtime. Expose it behind an internal overlay network and a simple LB. Ensure zero-downtime upgrades with canary traffic shifts and a pre-warm sidecar to warm the new replica without serving traffic. Outline the steps for swarm init/join, overlay creation, service spec with GPU constraints, secret handling, and a separate migration container if needed. Include a minimal docker-compose snippet showing update_config (start-first, parallelism 1)?","answer":"Outline a GPU-enabled TorchServe deployment on a 3-node Swarm across 2 DCs. Use NVIDIA runtime and a service with GPU constraint (nvidia.com/gpu=1). Implement canary upgrades: deploy 1 new replica, ru","explanation":"## Why This Is Asked\nTests ability to orchestrate GPU-enabled deployments across DCs, implement safe upgrades, and coordinate sidecar pre-warming with a migration task.\n\n## Key Concepts\n- GPU scheduling in Swarm with NVIDIA runtime\n- Overlay networks across data centers\n- Canary rollout using update_config (start-first, single-threaded)\n- Sidecar pre-warm pattern for zero-downtime\n- Migration container for schema/model updates\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  model:\n    image: myorg/torchserve:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    environment:\n      - NVIDIA_VISIBLE_DEVICES=all\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - capabilities:\n                -gpu\n                  count: 1\n```\n\n## Follow-up Questions\n- How would you monitor GPU utilization across nodes?\n- How would you handle model/version rollback in a canary rollout?","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create Overlay Network]\n  B --> C[Deploy TorchServe with NVIDIA runtime]\n  C --> D[Canary Upgrade: 1 new replica]\n  D --> E[Health Checks & Traffic Shift]\n  E --> F[Promote & Cleanup]","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:48:28.317Z","createdAt":"2026-01-14T10:48:28.317Z"},{"id":"q-1832","question":"Design and implement a zero-downtime upgrade for a 4-node Docker Swarm across two data centers hosting a stateful Redis queue and a stateless worker service. The worker consumes messages encoded in a new proto format; the cluster uses TLS mutual authentication with Vault for cert rotation and Docker Secrets for credentials. Outline exact upgrade steps, a 10% canary rollout, health checks, and a rollback plan, and include a minimal docker-compose snippet showing update_config(order: start-first, parallelism: 1)?","answer":"Use a 4-node Swarm across two DCs, with a 10% canary of the worker upgraded to the new proto-format, while 90% stay on the legacy image. Deploy update_config: order: start-first; parallelism: 1. Route","explanation":"## Why This Is Asked\nTests real-world upgrade workflows in a distributed Swarm with cross-DC considerations, TLS cert rotation, and in-flight data.\n\n## Key Concepts\n- Swarm update_config with start-first and parallelism\n- Canary rollouts and rollback triggers\n- TLS mutual authentication, Vault cert rotation, Docker secrets\n- In-flight data migration and zero-downtime guarantees\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  worker:\n    image: myorg/worker:upgrade\n    deploy:\n      replicas: 4\n      update_config:\n        order: start-first\n        parallelism: 1\n    secrets:\n      - tls_cert\n      - db_creds\n    environment:\n      - PROTO_VERSION=v2\n```\n\n## Follow-up Questions\n- How would you validate canary health beyond a simple Liveness probe?\n- What rollback automation would you add to rapidly revert if metrics deteriorate?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Two Sigma","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T13:15:02.309Z","createdAt":"2026-01-14T13:15:02.310Z"},{"id":"q-1967","question":"In a production Swarm across two data centers with four nodes, implement end-to-end image provenance using Cosign. Sign CI artifacts, publish signatures to a registry, and enforce verification before deploys. Outline the exact steps: key management, signing workflow in CI, signature verification at pull-time, updating services with image digests, and a rollback plan if verification fails. Provide concrete Cosign commands and how to incorporate into a CI/CD pipeline?","answer":"CI builds, signs, and publishes; Swarm deploy uses digest; if cosign verify fails, rollback to previous digest. Commands: cosign generate-key-pair, cosign sign --key cosign.key registry.example.com/ap","explanation":"## Why This Is Asked\nAssesses practical image provenance, CI/CD integration, and rollback readiness in distributed Swarm.\n\n## Key Concepts\n- Image signing with Cosign; key management; digest-based deployments; runtime verification; rollback strategy.\n\n## Code Example\n```\n// Implementation code here\n```\n\n## Follow-up Questions\n- How would you automate key rotation and revocation?\n- How do you test the rollback in a canary deployment?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","DoorDash","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:00:51.280Z","createdAt":"2026-01-14T19:00:51.281Z"},{"id":"q-2016","question":"In a three-node Docker Swarm spanning two data centers, deploy a stateless API behind a Traefik ingress with a Redis-backed cache layer and mutual TLS between services. Use Docker secrets/configs for TLS certs and cache creds. Apply zero-downtime upgrades via update_config (start-first, parallelism 1) and implement a canary upgrade path with health checks and automatic rollback. Outline the exact init/join commands, overlay creation, stack file, and upgrade sequence?","answer":"Initialize a three-node Swarm across two DCs, join the remaining nodes with generated tokens, create an overlay network, and deploy a Traefik-based API with a Redis cache layer. Use Docker secrets for","explanation":"## Why This Is Asked\nTests orchestration across DCs, zero-downtime upgrades, and secure service-to-service traffic with mTLS. It also probes secret/config management, canary rollout, and rollback handling.\n\n## Key Concepts\n- Swarm multi-DC deployment and node join tokens\n- Overlay networks and Traefik ingress with mTLS\n- Docker secrets/configs for TLS and credentials\n- update_config with start_first and parallelism, canary deployments\n\n## Code Example\n```yaml\n# docker-stack.yml (excerpt)\nversion: '3.8'\nservices:\n  api:\n    image: myapi:v2\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    secrets:\n      - redis-creds\n      - tls-cert\n    networks:\n      - app-net\n  cache:\n    image: redis:6\n    deploy:\n      replicas: 3\n    secrets:\n      - redis-creds\n    networks:\n      - app-net\nnetworks:\n  app-net:\n    external: true\nsecrets:\n  tls-cert:\n    external: true\n  redis-creds:\n    external: true\n```\n\n## Follow-up Questions\n- How would you implement automatic rollback on canary failure?\n- How do you measure canary success beyond HTTP 200s (latency, error rate)?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T20:53:37.375Z","createdAt":"2026-01-14T20:53:37.375Z"},{"id":"q-2022","question":"Scenario: On a single host, implement a blue-green deployment for a stateless API behind an Nginx reverse proxy using docker-compose. Start with green (v1) receiving all traffic; deploy blue (v2) and switch traffic to blue only after a 30-second health-check window confirms readiness, ensuring zero downtime. Provide: a) docker-compose.yml with two API services (api-green and api-blue) and Nginx, b) nginx.conf with a switchable upstream, c) a Bash script upgrade.sh that promotes blue by reconfiguring upstream and reloading Nginx, d) exact commands to bring up green, deploy blue, run the upgrade, and verify with curl?","answer":"Bootstrap green (v1) behind a single Nginx proxy. Deploy blue (v2) as a separate container and run healthchecks. When blue is healthy for 30s, swap nginx upstream to point to api-blue and reload Nginx","explanation":"## Why This Is Asked\nTests practical blue-green deployment on a single host, emphasizing health-driven promotion and service-rotations with minimal downtime.\n\n## Key Concepts\n- Blue-green deployment on a standalone host\n- Docker Compose for multi-service apps\n- Nginx upstream switching and live reload\n- Health checks and rollback safety\n\n## Code Example\n```yaml\nversion: \"3.9\"\nservices:\n  nginx:\n    container_name: nginx\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n  api-green:\n    image: myapi:v1\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\n  api-blue:\n    image: myapi:v2\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 5s\n      timeout: 2s\n      retries: 3\nnetworks:\n  default:\n    driver: bridge\n```\n\n```nginx\nevents { worker_connections 1024; }\nhttp {\n  upstream api_green { server api-green:8080; }\n  server { listen 80; location / { proxy_pass http://api_green; } }\n}\n```\n\n```bash\n#!/usr/bin/env bash\nset -e\n# Start green (v1)\ndocker-compose up -d api-green nginx\n# Deploy blue (v2)\ndocker-compose up -d api-blue\n# Wait for blue health (simplified placeholder)\n# ... poll health until healthy for 30s ...\n# Promote blue\nsed -i 's/server api-green:8080;/server api-blue:8080;/' nginx.conf\ndocker exec -i nginx nginx -s reload\n```\n\n## Follow-up Questions\n- How would you automate the 30s health window and rollback if any check fails?\n- How would you extend this to three or more canaries and track traffic ratios over time?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T21:31:46.162Z","createdAt":"2026-01-14T21:31:46.162Z"},{"id":"q-2053","question":"In a four-node **Docker Swarm** spanning two data centers, deploy a stateless API with a Redis-backed rate limiter and a shared cache. Implement a canary upgrade of the API using update_config (start-first, parallelism 1), with a front-door that routes the canary subset using label-based routing. Outline exact commands: swarm init/join, overlay creation, stack deploy, and the health-check-driven promotion. Include a minimal docker-compose snippet showing update_config?","answer":"Initialize a 4-node Docker Swarm across two data centers and create an overlay network for cross-DC communication. Deploy the API stack with 3 production replicas and 1 canary replica, both configured with update_config using parallelism: 1 and order: start-first. Implement label-based routing through a front-door proxy that directs traffic to the canary based on service labels. Monitor health checks and promote the canary by updating the production service image after validation.","explanation":"## Why This Is Asked\nTests practical canary deployment strategies across distributed infrastructure with stateful dependencies (Redis rate limiter, shared cache) and intelligent traffic routing. Evaluates understanding of Swarm's update_config mechanics and health-driven promotion workflows.\n\n## Key Concepts\n- Docker Swarm update_config with start-first ordering\n- Canary deployment patterns and traffic splitting\n- Multi-datacenter overlay networking\n- Health check-based promotion strategies\n- Label-based service routing\n\n## Code Example\n```yaml\nversion: \"3.8\"\nservices:\n api:\n   image: myapi:2.0\n   deploy:\n     replicas: 3\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=production\"\n   networks:\n     - front\n   healthcheck:\n     test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n     interval: 30s\n     timeout: 10s\n     retries: 3\n canary:\n   image: myapi:2.0-canary\n   deploy:\n     replicas: 1\n     update_config:\n       parallelism: 1\n       order: start-first\n     labels:\n       - \"version=canary\"\n   networks:\n     - front\n redis:\n   image: redis:alpine\n   deploy:\n     replicas: 1\n   networks:\n     - front\nnetworks:\n front:\n   driver: overlay\n   attachable: true\n```","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:40:42.873Z","createdAt":"2026-01-14T22:40:23.213Z"},{"id":"q-2120","question":"In a two-node Swarm, deploy a TLS-secured stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API settings, and a small sidecar that ships logs without affecting requests. Attach both services to a single overlay network and perform a canary upgrade with a rolling update (start-first, parallelism 1). Provide exact commands and a docker-compose.yml skeleton?","answer":"Initialize the Swarm cluster on node A with `docker swarm init --advertise-addr <IP1>`, then join node B using `docker swarm join --token <SWMTKN...> <IP1>:2377`. Create the overlay network with `docker network create -d overlay prod-net`.","explanation":"## Why This Is Asked\nThis question assesses practical mastery of Docker Swarm, including secrets management, overlay networking, and zero-downtime deployments through rolling updates.\n\n## Key Concepts\n- Swarm initialization and multi-node clustering\n- Overlay network creation and service attachment\n- Docker secrets and configs for secure configuration management\n- Rolling updates with health checks and canary-style deployments\n- Sidecar pattern for non-blocking log shipping\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  proxy:\n    image: nginx:alpine\n    ports:\n      - '443:443'\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n  api:\n    image: my-api:latest\n    secrets: [ tls_cert, tls_key ]\n    configs: [ app_config ]\n    networks: [ prod-net ]\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 10s\n        failure_action: rollback\n        order: start-first\n  log-shipper:\n    image: log-shipper:latest\n    networks: [ prod-net ]\n    depends_on: [ api ]\n```\n\n## Additional Commands\n```bash\n# Create secrets\necho \"cert-content\" | docker secret create tls_cert -\necho \"key-content\" | docker secret create tls_key -\n\n# Create config\necho \"app-settings\" | docker config create app_config -\n\n# Deploy stack\ndocker stack deploy -c docker-compose.yml myapp\n```","diagram":"flowchart TD\n  A[Init Swarm] --> B[Create overlay net]\n  B --> C[Create secrets/configs]\n  C --> D[Stack deploy]\n  D --> E[Canary upgrade]\n  E --> F[Promote canary]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:53:30.558Z","createdAt":"2026-01-15T02:28:35.499Z"},{"id":"q-2140","question":"In a two-datacenter Docker Swarm (2 nodes per DC), deploy a stateless API behind Traefik with TLS termination on an overlay network across DCs. Implement a canary rollout for a feature-flag change using a Swarm Config and route 10% of traffic to canary via Traefik labels. Outline exact swarm init/join commands, overlay creation, stack deploys, config creation, and the canary upgrade with health checks and rollback criteria?","answer":"Plan: Bring up both DCs as a single swarm, create an attachable overlay, deploy Traefik with TLS via Docker secrets, create a Swarm Config with the feature flag, launch two API stacks (prod and canary","explanation":"## Why This Is Asked\nTests cross-datacenter orchestration, canary traffic, and secret/config handling with Traefik in Swarm across DCs.\n\n## Key Concepts\n- Docker Swarm multi-DC overlay networking\n- Traefik dynamic routing and weights for canaries\n- Swarm Config vs Secret for feature flags\n- Health checks and safe rollback strategies\n\n## Code Example\n```bash\n# Swarm init (DC1)\ndocker swarm init --advertise-addr <dc1-ip>\n# Join DC2\n# docker swarm join ...\n\n\ndocker network create -d overlay --attachable traefik-net\n# Deploy Traefik with TLS secret and config-driven routes\n# ...\n```\n\n## Follow-up Questions\n- How would you test the rollover window and rollback boundaries?\n- How would you monitor traffic split and auto-promote canary on success?","diagram":"flowchart TD\nA[Two-DC Swarm] --> B[Overlay Network]\nB --> C[Traefik TLS]\nC --> D[Prod API]\nC --> E[Canary API]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:20:30.901Z","createdAt":"2026-01-15T04:20:30.901Z"},{"id":"q-2231","question":"In a four-node docker-dca cluster, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints, and add an Envoy sidecar per app to drive traffic-splitting controlled by a central Consul KV flag. Implement a progressive canary: 10% steps every 30s up to 100%, with health checks and automatic rollback on failure. Provide explicit bootstrap commands and a docker-compose.yml skeleton?","answer":"Use a four-node docker-dca canary with Envoy sidecars, edge TLS via Docker secrets, and a Consul KV flag to drive 10%→100% traffic steps every 30s. Health checks gate progress; rollback triggers on tw","explanation":"## Why This Is Asked\nTests practical orchestration of traffic-shifting, secret/config management, and automated rollback in a docker-dca setup.\n\n## Key Concepts\n- Envoy sidecars for per-service traffic-splitting\n- Consul KV as a dynamic control flag\n- Docker secrets/configs for TLS and endpoints\n- Canary rollout with health checks and rollback\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    secrets:\n      - tls_cert\n      - tls_key\n    configs:\n      - source: api_endpoints\n        target: /etc/api_endpoints.conf\n  app:\n    image: myapi:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n    depends_on:\n      - envoy\n  envoy:\n    image: envoyproxy/envoy:v1.18.3\n    depends_on:\n      - app\n    volumes:\n      - ./envoy.yaml:/etc/envoy/envoy.yaml:ro\nsecrets:\n  tls_cert:\n  tls_key:\nconfigs:\n  api_endpoints:\n```\n\n## Follow-up Questions\n- How would you test rollback safety during regional failover?\n- How would you extend the flow to autoscale canary windows based on real-time metrics?","diagram":"flowchart TD\n  A[Edge TLS Termination (Nginx)] --> B[App Replica Set 1]\n  A --> C[App Replica Set 2]\n  B --> D[Envoy Sidecar]\n  C --> E[Envoy Sidecar]\n  D --> F[Central Router (Consul Map)]\n  E --> F","difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Microsoft","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T08:47:25.253Z","createdAt":"2026-01-15T08:47:25.253Z"},{"id":"q-2254","question":"Create a local Docker Compose setup with two Python services: web (Flask API) and cache (Redis). Duplicate web as web_canary with CANARY=true. Add an Nginx container as a reverse proxy routing /api to web and /canary to web_canary. Use a named volume for Redis data. Add healthchecks for all three containers and provide a docker-compose.yml skeleton plus exact bootstrap commands to seed data and verify endpoints?","answer":"Four services: web, web_canary, cache, and nginx. web and web_canary expose ports and use CANARY to differentiate behavior. Redis uses a named volume redis-data for persistence. Nginx routes /api to w","explanation":"## Why This Is Asked\n\nTests ability to design a practical local deployment with a stable/canary pattern, data persistence, and a proxy layer.\n\n## Key Concepts\n\n- Docker Compose service composition\n- Health checks and readiness\n- Canary routing via a dedicated proxy\n- Volume for data persistence\n\n## Code Example\n\n```javascript\n// Placeholder illustrating structure for health checks\n```\n\n## Follow-up Questions\n\n- How would you promote canary to stable with zero downtime?\n- How would you extend to multiple canaries and metrics-based routing?","diagram":"flowchart TD\n  Client --> NginxProxy[Nginx Proxy]\n  NginxProxy --> Web[web]\n  NginxProxy --> Canary[web_canary]\n  NginxProxy --> Redis[cache]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:39:38.182Z","createdAt":"2026-01-15T09:39:38.182Z"},{"id":"q-2295","question":"In a 5-node Docker Swarm spanning two data centers, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for per-tenant routing templates, consuming routing directives from a central HTTP API. Attach a per-service Envoy sidecar to drive traffic-splitting with a progressive canary (25% steps every 20s). Ship logs via a separate sidecar to a Loki stack without blocking requests. Implement a zero-downtime upgrade using update_config (start-first, parallelism 1). Provide exact commands and a docker-compose.yml skeleton?","answer":"Architect a 5-node Swarm across DCs, TLS via Docker secrets, Nginx edge proxy, and a per-service Envoy sidecar for canary routing. Routing rules pulled from a central HTTP API rendered into a Docker c","explanation":"## Why This Is Asked\n\nTests ability to design multi-DC Swarm, TLS secrets, dynamic routing, and Canary with sidecars and observability. Checks how routing rules are distributed and how upgrades remain zero-downtime.\n\n## Key Concepts\n\n- Docker Swarm across data centers\n- Secrets and Configs for TLS and routing\n- Nginx edge proxy with per-service Envoy sidecar\n- Canary rollout with health checks and rollback\n- Sidecar logging to Loki without blocking requests\n\n## Code Example\n\n```yaml\nversion: \"3.8\"\nservices:\n  edge-nginx:\n    image: nginx:alpine\n    secrets: [ tls_cert ]\n    configs: [ routing_tpl ]\n  api:\n    image: my/api:latest\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        order: start-first\n```\n\n## Follow-up Questions\n\n- How would you validate canary health signals and rollback criteria?\n- How would you handle TLS certificate rotation without downtime?\n","diagram":"flowchart TD\n  DC1[Data Center 1] --> SwarmMgr[Swarm Manager]\n  DC2[Data Center 2] --> SwarmMgr\n  SwarmMgr --> Edge[Edge Proxy: Nginx]\n  Edge --> API[API Service]\n  API --> Logger[Log-Sidecar]\n  API --> Canary[Envoy Sidecar]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Slack","Tesla","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T10:56:17.946Z","createdAt":"2026-01-15T10:56:17.946Z"},{"id":"q-2346","question":"In a 3-node docker-dca cluster spanning two data centers, deploy a TLS-secured stateless API behind an Nginx proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints. Add a shadow sidecar that mirrors 5% of production traffic to a canary version. Implement a canary rollout by adjusting weights in 10% increments using update_config, with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton?","answer":"Implement dynamic traffic shadow: deploy a main API and a canary, with a shadow Envoy sidecar mirroring ~5% of traffic to the canary; TLS via Docker secrets; Nginx routes 95% to main and 5% to shadow;","explanation":"## Why This Is Asked\nTests ability to orchestrate multi-DC deployments, secret-driven TLS, and traffic shaping with live canary upgrades. It also probes rollback discipline and the interaction between edge proxies, sidecars, and the orchestrator.\n\n## Key Concepts\n- Docker secrets and configs for TLS and endpoints\n- Nginx/Envoy traffic routing and shadow/canary pattern\n- Canary rollout via update_config with health checks\n- Multi-DC networking and rollback strategies\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  nginx:\n    image: nginx:stable\n    secrets:\n      - tls_cert\n    configs:\n      - source: api_endpoints\n        target: /etc/api/endpoints.conf\n  api-main:\n    image: myapi:latest\n    secrets:\n      - tls_cert\n  api-canary:\n    image: myapi:canary\n    secrets:\n      - tls_cert\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n        failure_action: rollback\nsecrets:\n  tls_cert:\n    file: ./certs/tls_cert.pem\nconfigs:\n  api_endpoints:\n    file: ./configs/endpoints.conf\n```\n\n## Follow-up Questions\n- How would you monitor canary health and automate rollback decisions?\n- How would you secure inter-service communication and ensure TLS mutual authentication across DCs?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Google","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:35:40.425Z","createdAt":"2026-01-15T14:35:40.425Z"},{"id":"q-2386","question":"In a two-datacenter Docker Swarm with a TLS-enabled REST API behind an Nginx edge proxy, TLS certs are stored as Docker secrets. Design a zero-downtime rotation workflow: publish a new cert secret api_tls_new without restarting Nginx, upgrade the service with the new secret using a canary approach (update_config: order start-first, parallelism 1), and provide the exact shell commands plus a minimal docker-compose.yml skeleton showing secrets, config, and a small log-shipper sidecar that does not delay requests?","answer":"Rotate TLS certs by creating api_tls_new, attach it via docker service update with --secret-add api_tls_new and --secret-rm api_tls_old using update-order start-first and update-parallelism 1 for a ca","explanation":"Why This Is Asked\nTests ability to design zero-downtime secret rotation in Swarm, including secret lifecycle, canary upgrade discipline, and edge-reload strategy.\n\nKey Concepts\n- Docker secrets lifecycle and updates\n- Swarm update_config for canary-like upgrades\n- Edge proxy reload without downtime\n- Non-blocking sidecar logging\n\nCode Example\n```yaml\nversion: '3.8'\nservices:\n  api:\n    image: myapi:latest\n    secrets:\n      - api_tls_old\n      - api_tls_new\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n  log_shipper:\n    image: log-shipper:latest\n    secrets:\n      - api_tls_old\n      - api_tls_new\nsecrets:\n  api_tls_old:\n    external: true\n  api_tls_new:\n    external: true\n```\n\nFollow-up Questions\n- How would you automate rotation cadence and auditing of secret changes?\n- How would you test the zero-downtime guarantee in CI/CD before production rollout?","diagram":null,"difficulty":"intermediate","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Meta","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T15:50:28.068Z","createdAt":"2026-01-15T15:50:28.068Z"},{"id":"q-2432","question":"In a 4-node docker-dca Swarm, deploy a TLS-secured event-processing pipeline behind an Nginx edge proxy. Use Docker secrets for TLS certs, a Docker config for routing rules, and implement a 5% canary upgrade for the Transform service controlled by a Consul KV flag. Provide exact commands and a docker-compose.yml skeleton that demonstrates canary traffic, health checks, and zero-downtime upgrades?","answer":"Set up a 4-node Swarm with an overlay network, create TLS secrets tls.crt and tls.key, and a routing config. Deploy ingest, transform-prod, transform-canary, and sink behind edge-nginx. Route 95% to p","explanation":"## Why This Is Asked\n\nTests ability to orchestrate secrets/configs with a canary using a proxy. Requires Swarm networking, overlay, health checks, and rollback semantics.\n\n## Key Concepts\n\n- Docker secrets/configs\n- Swarm services and update_config\n- Overlay networks and edge proxy traffic-splitting\n- Consul KV flag-based traffic routing\n\n## Code Example\n\n```yaml\nversion: '3.8'\nservices:\n  ingest:\n    image: myreg/ingest:latest\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: on-failure\n  transform-prod:\n    image: myreg/transform-prod:latest\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 1\n        order: start-first\n  transform-canary:\n    image: myreg/transform-canary:latest\n    deploy:\n      replicas: 1\n  sink:\n    image: myreg/sink:latest\n    deploy:\n      replicas: 1\n  edge-nginx:\n    image: nginx:alpine\n    secrets:\n      - tls_crt\n      - tls_key\n    configs:\n      - source: routing_conf\n        target: /etc/nginx/conf.d/routing.conf\nnetworks:\n  pipeline:\n    driver: overlay\nsecrets:\n  tls_crt:\n    file: ./certs/tls.crt\n  tls_key:\n    file: ./certs/tls.key\nconfigs:\n  routing_conf:\n    file: ./routing/nginx.conf\n```\n\n## Follow-up Questions\n\n- How would you test the canary flag in production-like load?\n- How would you roll back if the canary shows degradation?","diagram":"flowchart TD\n  A[Edge Proxy] --> B[Ingest]\n  B --> C[Transform Prod]\n  C --> D[Sink]\n  D --> E[Storage]","difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T17:50:37.495Z","createdAt":"2026-01-15T17:50:37.495Z"},{"id":"q-2485","question":"In a three-node Docker Swarm spanning two data centers, deploy a TLS-secured stateless event API behind an Nginx edge proxy. Use Docker secrets for TLS certs and a Docker config for API endpoints. Introduce an SPIRE-based mTLS mesh by wiring an SPIRE agent as a sidecar to each app container to issue short-lived mTLS certs and enforce SPIFFE IDs. Implement automatic certificate rotation every 60 minutes and a progressive canary upgrade (start-first, parallelism 1). Provide exact docker-compose.yml skeleton and bootstrap commands?","answer":"A possible answer would outline: init a swarm across both data centers, create an overlay network, load TLS secrets and API configs, deploy the app with a sidecar SPIRE agent container, configure SPIR","explanation":"## Why This Is Asked\nTests knowledge of multi-datacenter Swarm, TLS secrets, config usage, and a real-world mTLS service mesh with SPIRE. It also probes canary upgrades and security in production.\n\n## Key Concepts\n- Docker Swarm orchestration across DCs\n- TLS with Docker secrets and configs\n- SPIRE-based mTLS workload identity\n- Certificate rotation and health-driven canaries\n- Update strategy: start-first, parallelism 1\n\n## Code Example\n```yaml\n# docker-compose.yml skeleton\nversion: '3.8'\nservices:\n  api:\n    image: my/api:latest\n    deploy:\n      replicas: 2\n      update_config:\n        order: start-first\n        parallelism: 1\n    configs:\n      - source: api_config\n        target: /etc/api/config.yaml\n    secrets:\n      - tls_cert\n      - tls_key\n    networks:\n      - ov\n    depends_on: []\n    # SPIRE sidecar will be defined in a separate service or as a sidecar container\n  spire-agent:\n    image: quay.io/spiffe/spire-agent:latest\n    volumes:\n      - /var/lib/spire:/run/spire\n    command: run\n    deploy:\n      replicas: 2\n      labels:\n        SPIRE: agent\nnetworks:\n  ov:\n    external: true\nsecrets:\n  tls_cert:\n    file: ./certs/server.crt\n  tls_key:\n    file: ./certs/server.key\nconfigs:\n  api_config:\n    file: ./config/api.yaml\n```\n\n### Follow-up Steps\n- Show exact bootstrap commands for swarm init/join and SPIRE setup.\n- Describe monitoring and rotation verification.","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Citadel","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:46:58.046Z","createdAt":"2026-01-15T19:46:58.046Z"},{"id":"q-2558","question":"In a two-node docker-dca Swarm, deploy a TLS-enabled stateless API behind an Nginx proxy. Use Docker secrets for TLS certs, a Docker config for API endpoints, and a lightweight log-shipper sidecar that adds no latency. Attach both services to a single overlay network. Implement a 5% canary rollout with health checks and automatic rollback on failure. Provide exact commands and a docker-compose.yml skeleton, plus how to measure and enforce performance during the rollout?","answer":"Initialize a two-node Docker Swarm cluster, create an overlay network, store TLS certificates as Docker secrets, API endpoints as a Docker config, deploy Nginx as an edge proxy with the stateless API backend, include a lightweight log-shipper sidecar, implement a 5% canary rollout with health checks and automatic rollback on failure, and measure performance throughout the deployment process.","explanation":"## Why This Is Asked\nTests practical experience with Docker Swarm fundamentals, secrets and configs management, edge proxy orchestration, controlled deployment strategies, and performance monitoring during rollouts.\n\n## Key Concepts\n- Docker Swarm initialization and overlay networking\n- Docker secrets for sensitive data (TLS certificates)\n- Docker configs for application configuration\n- Edge proxy pattern with Nginx in Swarm\n- Canary deployments with health-check-driven rollbacks\n- Sidecar containers for log shipping\n- Performance measurement and enforcement during rollouts\n\n## Code Example\n```\n","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","DoorDash","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:26:12.739Z","createdAt":"2026-01-15T22:46:54.516Z"},{"id":"q-2588","question":"On a two-node Docker Swarm, deploy a TLS-secured stateless API behind an Nginx edge proxy. Use a Docker secret for TLS certs and a Docker config for API endpoints. Ensure the app runs as a non-root user and add a tiny sidecar that tails logs to a shared volume without affecting requests. Attach both services to an overlay network and implement a rolling update with start_first, parallelism 1. Include exact commands to initialize swarm, create secret/config, build/deploy, and a docker-compose.yml skeleton?","answer":"Run: `docker swarm init`; `docker network create -d overlay appnet`; `docker secret create tls.pem cert.pem`; `docker secret create tls.key key.pem`; `docker config create api-endpoints /path/api.json`; `docker stack deploy -c docker-compose.yml mystack`","explanation":"## Why This Is Asked\nTests wiring of secrets/config, non-root containers, and safe rolling updates in a two-node swarm.\n\n## Key Concepts\n- Docker secrets/config\n- Non-root user in containers\n- Sidecar log shipping\n- Overlay networking and rolling updates\n\n## Code Example\n```dockerfile\nFROM node:18\nRUN groupadd -r app && useradd -r -g app app\nUSER app\nWORKDIR /app\nCOPY --chmod=644 . .\nCMD [\"node\",\"server.js\"]\n```\n\n```yaml\nversion: \"3.8\"\nservices:\n  api:\n    image: mystack/api:latest\n    networks: [ appnet ]\n    secrets: [ tls.pem, tls.key ]\n    configs: [ api-endpoints ]\n    deploy:\n      update_config:\n        parallelism: 1\n        order: start-first\n      restart_policy:\n        condition: on-failure\n  nginx:\n    image: nginx:alpine\n    networks: [ appnet ]\n    secrets: [ tls.pem, tls.key ]\n    ports:\n      - \"443:443\"\n    deploy:\n      replicas: 1\n  logtailer:\n    image: alpine:latest\n    command: tail -f /logs/app.log\n    volumes:\n      - shared-logs:/logs\n    networks: [ appnet ]\n    deploy:\n      replicas: 1\n\nnetworks:\n  appnet:\n    driver: overlay\n    external: true\n\nvolumes:\n  shared-logs:\n```\n\n## Implementation Steps\n1. Initialize swarm on both nodes and join them\n2. Create overlay network for service communication\n3. Generate TLS certificates and create secrets\n4. Create API endpoint configuration\n5. Build and push API image with non-root user\n6. Deploy stack with rolling update configuration\n7. Verify TLS termination and log shipping functionality","diagram":"flowchart TD\n  A[Swarm Init] --> B[Create Overlay Network]\n  B --> C[Create Secrets & Configs]\n  C --> D[Deploy Stack]\n  D --> E[Canary Upgrade / Health Checks]","difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Salesforce","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:07:32.152Z","createdAt":"2026-01-15T23:46:32.556Z"},{"id":"q-856","question":"You're running a Docker Swarm with services frontend, api, and worker. A feature-flag config is provided via Docker Config mounted at /etc/flags.json in all containers. You must rotate this config weekly with zero downtime. Describe the exact sequence of commands to create a new config version, rotate the services to use it, and implement a graceful reload inside apps so the new flags are picked up without losing requests. Include any Swarm update options you would tune?","answer":"Create a new config file (e.g., /tmp/flags.v2.json) and docker config create flags.v2 /tmp/flags.v2.json. Then update each service: docker service update --config-rm flags.v1 --config-add flags.v2 --u","explanation":"## Why This Is Asked\nTo assess practical config rotation in Swarm and application reload behavior.\n\n## Key Concepts\n- Docker Config rotation\n- Rolling updates with update-parallelism and update-delay\n- Graceful reload semantics (SIGHUP or /reload)\n\n## Code Example\n```javascript\n// Node.js reload handler\nconst fs = require('fs');\nlet flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\nprocess.on('SIGHUP', () => {\n  flags = JSON.parse(fs.readFileSync('/etc/flags.json','utf8'));\n  // apply flags to runtime features\n});\n```\n\n## Follow-up Questions\n- How would you test the zero-downtime rollout in a CI pipeline?\n- What failure scenarios would prompt you to revert the config rotation?","diagram":null,"difficulty":"beginner","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:38:40.484Z","createdAt":"2026-01-12T13:38:40.484Z"},{"id":"q-862","question":"In a Docker Swarm with a stateful web app that uses Postgres, you must roll out version 3.2 with a DB schema migration and zero downtime. Propose a concrete upgrade plan that uses a start-first, one-task-at-a-time update, a separate migration container, and post-migration validation. Include exact Swarm commands and a minimal docker-compose snippet showing update_config?","answer":"Plan: run DB migration first in a dedicated one-off container, then perform a start-first, one-task-at-a-time web upgrade. Commands: docker run --rm --network swarm_net migrate:3.2; docker service upd","explanation":"## Why This Is Asked\nAssesses ability to coordinate schema migrations with zero downtime, manage Swarm update strategies, and handle rollback safely.\n\n## Key Concepts\n- Start-first updates and parallelism control\n- Separate migration container orchestration\n- Post-migration validation and rollback\n- Health checks and observability during upgrade\n\n## Code Example\n```yaml\nversion: '3.8'\nservices:\n  web:\n    image: myapp:3.2\n    deploy:\n      update_config:\n        parallelism: 1\n        delay: 15s\n        order: start-first\n```\n\n## Follow-up Questions\n- How would you handle long-running migrations?\n- How ensure data consistency with read replicas during upgrade?","diagram":null,"difficulty":"advanced","tags":["docker-dca"],"channel":"docker-dca","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:43:29.032Z","createdAt":"2026-01-12T13:43:29.032Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Meta","Microsoft","MongoDB","NVIDIA","Netflix","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snowflake","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":28,"beginner":9,"intermediate":8,"advanced":11,"newThisWeek":28}}