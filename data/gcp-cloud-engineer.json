{"questions":[{"id":"gcp-cloud-engineer-access-security-1768195883281-0","question":"A web app running on Google Kubernetes Engine (GKE) in your GCP project needs to read objects from a Cloud Storage bucket and publish messages to a Pub/Sub topic. To follow the principle of least privilege and avoid long‑lived credentials, which approach should you implement?","answer":"[{\"id\":\"a\",\"text\":\"Bind the project’s default service account to the bucket and the Pub/Sub topic at the project level, granting broad access.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a dedicated service account for the app and grant it only storage.objectViewer on the bucket and pubsub.publisher on the topic, with IAM bindings at the resource level; consider using Workload Identity Federation if the app runs on Kubernetes.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Store a service account key for the app in Cloud Storage and rotate it monthly.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use the allUsers principal to allow anyone to read objects from the bucket.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because it applies the principle of least privilege by granting the app only the permissions it needs on the specific resources, and not at the project level. Using a dedicated service account prevents over-broad access and avoids embedding long‑lived credentials; when the app runs on Kubernetes, Workload Identity Federation further eliminates the need to manage short‑lived keys.\n\n## Why Other Options Are Wrong\n- Option A grants broad access at the project level, increasing blast radius and violating least privilege.\n- Option C relies on long‑lived credentials (a key), which is discouraged; rotating keys does not mitigate the risk of exposure.\n- Option D makes the bucket public to all users, which is insecure and inappropriate for private data.\n\n## Key Concepts\n- Least privilege principle\n- Service accounts and resource-level IAM bindings\n- Workload Identity Federation (WIF)\n- Avoiding long‑lived credentials\n\n## Real-World Application\nThis pattern is commonly used when deploying apps to GKE that need selective access to Cloud Storage and Pub/Sub, reducing risk while maintaining operational practicality.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","IAM","Kubernetes","Workload Identity Federation","Cloud Storage","Pub/Sub","AWS","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"access-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:31:23.282Z","createdAt":"2026-01-12 05:31:23"},{"id":"gcp-cloud-engineer-access-security-1768195883281-1","question":"Your organization wants to ensure that data egress from your Google Cloud environment to external networks is restricted and that access to Google APIs is allowed only within a defined security perimeter. Which construct best enforces this boundary?","answer":"[{\"id\":\"a\",\"text\":\"Configure a firewall rule to block all egress traffic from resources except to Google API endpoints.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a VPC Service Controls perimeter and use Access Context Manager to define trusted sources and restrict Google API access to within the perimeter.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Use Cloud Identity-Aware Proxy to restrict access to the workload.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use Cloud NAT to control outbound internet access.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because VPC Service Controls perimeters, together with Access Context Manager, define a security boundary that limits data access and API calls to resources inside the perimeter, reducing data exfiltration risk.\n\n## Why Other Options Are Wrong\n- Option A is insufficient in practice and hard to maintain for all Google API endpoints; perimeters provide stronger, centralized control.\n- Option C focuses on user access to workloads rather than restricting perimeters for API access and data exfiltration.\n- Option D controls outbound NAT behavior but does not enforce API access boundaries or data exfiltration controls across services.\n\n## Key Concepts\n- VPC Service Controls perimeters\n- Access Context Manager\n- Data exfiltration risk mitigation\n\n## Real-World Application\nThis approach is standard for regulated environments (e.g., financial, healthcare) to prevent data leakage when workloads access Google APIs or store data in Google services.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","VPC Service Controls","Access Context Manager","Data Security","GKE","AWS","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"access-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:31:23.647Z","createdAt":"2026-01-12 05:31:23"},{"id":"gcp-cloud-engineer-access-security-1768195883281-2","question":"An organization uses an AWS-hosted CI/CD pipeline that must deploy to GCP resources. To avoid managing long‑lived credentials, which option provides temporary credentials for the pipeline to access GCP resources when running on AWS?","answer":"[{\"id\":\"a\",\"text\":\"Create a Google Cloud service account and store its key in AWS Secrets Manager; use the key directly from Jenkins.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Configure Workload Identity Federation with an AWS OpenID Connect provider; grant the associated Google service account minimal permissions; Jenkins obtains short‑lived credentials via STS.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Create a Google user account and share login credentials with the AWS team.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use a Google Cloud API key for the pipeline.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Workload Identity Federation allows the external AWS identity to obtain short‑lived credentials from GCP without creating or storing long‑lived keys, enabling secure cross‑cloud access with least privilege.\n\n## Why Other Options Are Wrong\n- Option A relies on long‑lived keys stored in AWS Secrets Manager, which increases risk if secrets are compromised.\n- Option C uses a human user account credentials, which is inappropriate for automated pipelines and violates best practices.\n- Option D API keys are not suitable for server‑to‑server interactions requiring identity and fine‑grained IAM controls.\n\n## Key Concepts\n- Workload Identity Federation (WIF)\n- OIDC and external identities\n- Short‑lived credentials\n- Least privilege cross‑cloud access\n\n## Real-World Application\nThis pattern is widely used to safely connect CI/CD pipelines across cloud providers without managing long‑lived credentials, improving security posture for multi‑cloud deployments.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Workload Identity Federation","AWS","OIDC","STS","IAM","Terraform","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"access-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T05:31:24.014Z","createdAt":"2026-01-12 05:31:24"},{"id":"gcp-cloud-engineer-deploying-implementing-1768156084677-0","question":"You manage a web application that currently runs on a single Compute Engine VM. You expect traffic spikes and want autoscaling, rolling updates with zero downtime, and minimal operational overhead. Which approach best meets these requirements?","answer":"[{\"id\":\"a\",\"text\":\"Use a managed instance group with an HTTP(S) load balancer and a rolling update configuration.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Migrate to App Engine Standard and deploy the app as a single service version.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Containerize the app and run it on Cloud Run with a traffic split across revisions.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Keep using the single VM with manual scaling and manual deployments.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nUsing a managed instance group with an HTTP(S) load balancer and rolling update configuration provides autoscaling, rolling deployments with minimal downtime, and low operational overhead for VM-based workloads.\n\n## Why Other Options Are Wrong\n- B: Migrating to App Engine Standard could offer autoscaling and zero-downtime deployments, but it implies refactoring a VM-based workload and may not guarantee zero-downtime for the existing setup without significant changes.\n- C: Cloud Run requires containerization; while it supports traffic splitting, it adds containerization overhead and may not be ideal for a monolithic VM-based app without refactoring.\n- D: A single VM with manual scaling offers no autoscaling and higher risk of downtime during deployments.\n\n## Key Concepts\n- Managed Instance Groups (MIG)\n- HTTP(S) Load Balancer\n- Rolling updates\n\n## Real-World Application\nIn production, many teams consolidate to MIG + HTTP(S) Load Balancer to achieve predictable autoscaling and safe, zero-downtime deployments for VM-based workloads.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Compute Engine","Cloud Load Balancing","Kubernetes","Terraform","AWS EC2","EKS","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"deploying-implementing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:28:04.678Z","createdAt":"2026-01-11 18:28:04"},{"id":"gcp-cloud-engineer-deploying-implementing-1768156084677-1","question":"Your organization has two GCP projects: dev and prod. You want centralized firewall policies and shared subnets across both projects, while maintaining isolation of resources. Which networking pattern should you choose?","answer":"[{\"id\":\"a\",\"text\":\"Shared VPC where a host project contains the shared subnets and firewall rules, with service projects attaching to it.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"VPC peering between dev and prod projects.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Two independent VPCs with identical firewall rules replicated manually.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Project-level firewall rules with no network sharing.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nShared VPC allows central management of subnets and firewall policies in a host project while each environment (service project) maintains resource isolation and security boundaries.\n\n## Why Other Options Are Wrong\n- B: VPC peering connects networks but does not centralize firewall rules or shared subnets, making policy management harder across projects.\n- C: Manually replicating rules increases drift risk and defeats centralization and consistency.\n- D: Project-level firewall rules alone do not enable shared subnets or centralized policy management across projects.\n\n## Key Concepts\n- Shared VPC\n- Host project vs. service projects\n- Centralized firewall rules\n\n## Real-World Application\nOrganizations use Shared VPC to enforce a common security posture across multiple environments (dev/prod) while preserving project isolation and resource boundaries.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","VPC","Shared VPC","Kubernetes","Terraform","AWS EC2","EKS","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"deploying-implementing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:28:05.057Z","createdAt":"2026-01-11 18:28:05"},{"id":"gcp-cloud-engineer-deploying-implementing-1768156084677-2","question":"You are deploying a multi-region web service with strict low-latency requirements. You need global load balancing with regional backends and automatic failover; which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"Configure Google Cloud Load Balancing with backend services spanning multiple regions and backends in Compute Engine or GKE.\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Deploy a single regional load balancer and rely on DNS for latency optimization.\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Place a Cloud CDN in front of a single regional endpoint.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Set up VPN tunnels to connect regional networks and route traffic manually.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA\n\nGlobal HTTP(S) Load Balancing with multi-region backends provides low-latency routing, automatic failover, and seamless autoscaling across regions for a worldwide user base.\n\n## Why Other Options Are Wrong\n- B: A single regional load balancer cannot optimally serve users across regions and lacks true global failover.\n- C: Cloud CDN improves cacheability and edge performance but does not provide regional compute backends or automatic failover across regions.\n- D: VPN tunnels are complex to manage for user traffic routing and do not provide built-in global load balancing or automatic failover.\n\n## Key Concepts\n- Global HTTP(S) Load Balancing\n- Multi-region backends\n- Regional Compute Engine / GKE integration\n\n## Real-World Application\nGlobal SaaS providers deploy backend services across multiple regions and front them with a global load balancer to minimize latency and ensure resilience during regional outages.\n","diagram":null,"difficulty":"intermediate","tags":["GCP","Cloud Load Balancing","GKE","Compute Engine","Terraform","AWS EC2","EKS","certification-mcq","domain-weight-22"],"channel":"gcp-cloud-engineer","subChannel":"deploying-implementing","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T18:28:05.434Z","createdAt":"2026-01-11 18:28:05"}],"subChannels":["access-security","deploying-implementing"],"companies":[],"stats":{"total":6,"beginner":0,"intermediate":6,"advanced":0,"newThisWeek":6}}