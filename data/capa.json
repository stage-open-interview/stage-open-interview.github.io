{"questions":[{"id":"q-1091","question":"Scenario: An OTA firmware update causes GPS altitude drift in a subset of IoT devices across regions. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API for CAPAs with device logs, 4) region/device-type metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollback plan for OTA updates?","answer":"Design a CAPA program with a data model including fields for CAPA id, incident id, device_id, region, firmware_version, evidence, actions, status, and timestamps; a lifecycle from DETECT to CLOSED; a ","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for hardware deployments, emphasizing evidence capture, state management, and canary safety.\n\n## Key Concepts\n- CAPA data model tailored to IoT/OTA scenarios\n- Lifecycle state machine for CAPA progression\n- Minimal API design for linking CAPAs to device logs\n- Region/device-type metrics to prove effectiveness\n- RCA templates and safe rollback strategies\n\n## Code Example\n```javascript\n// Minimal CAPA creation schema (pseudo)\nconst createCAPA = (payload) => ({ id: generateId(), ...payload, status: 'OPEN' })\n```\n\n## Follow-up Questions\n- How would you ensure evidence provenance and tamper-evidence across devices?\n- How would you test the canary rollback plan with real devices at scale?","diagram":"flowchart TD\n  A[Detect Drift] --> B[Collect Evidence]\n  B --> C[Create CAPA]\n  C --> D[Canary OTA]\n  D --> E[Evaluate Metrics]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Plaid","Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T22:23:48.606Z","createdAt":"2026-01-12T22:23:48.606Z"},{"id":"q-1111","question":"Scenario: Production ML feature store drift after a data refresh degrades latency and CTR across regions due to stale features and late streaming data. Propose a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPAs, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove containment and recurrence, 5) an RCA template and a canary rollout plan to prevent recurrence during future refreshes?","answer":"CAPA data model should store evidence (logs, traces, feature clocks) and artifacts (RCA, mitigations, rollback scripts). Lifecycle: detected → triaged → containment → root cause → corrective action → ","explanation":"## Why This Is Asked\nTests ability to design scalable CAPA for data drift in production ML pipelines, including evidence management, lifecycle, API design, and robust canary strategies.\n\n## Key Concepts\n- CAPA data model with evidence links\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for CAPAs\n- Region-aware metrics (MTTR, recurrence, containment)\n- RCA templates and canary rollout planning\n\n## Code Example\n```javascript\n// CAPA data model sketch\n{\n  \"id\": \"CAPA-20260112-001\",\n  \"issue\": \"Feature store drift causing latency and CTR degradation\",\n  \"regions\": [\"us-east-1\",\"eu-west-1\"],\n  \"evidenceLinks\": [\"https://log/123\",\"https://trace/456\"],\n  \"lifecycle\": \"detected\",\n  \"actions\": [\n    {\"step\":\"containment\",\"owner\":\"SRE\",\"status\":\"pending\"}\n  ],\n  \"canaryPlan\": {\"enabled\":true,\"regions\":[\"us-east-1\"]}\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA API for high throughput and cross-region consistency?\n- What RCA sections ensure actionable preventive measures and auditability?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T23:20:43.169Z","createdAt":"2026-01-12T23:20:43.169Z"},{"id":"q-1132","question":"Scenario: batch ingestion misses PII masking in two tenants across regions, raising privacy risk. Design a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant/region-aware metrics to prove containment and recurrence (MTTD, MTTR, false positives), 5) an RCA template and a canary rollout plan to validate policy enforcement before global deployment?","answer":"Approach: define CAPA data model with evidence, logs, and artifacts; lifecycle states: detected, triaged, in_progress, contained, closed; REST API endpoints POST /caps, PUT /caps/{id} with linked trac","explanation":"## Why This Is Asked\n\nTests ability to design end-to-end CAPA workflow for data privacy policy failures, including evidence capture and cross-tenant rollout.\n\n## Key Concepts\n\n- CAPA data modeling for evidence and artifacts\n- Lifecycle state machine and ownership\n- Minimal REST API design with linked logs/traces\n- Tenant/region metrics for containment and recurrence\n- RCA templates and canary rollout planning\n\n## Code Example\n\n```javascript\n// CAPA core types (overview)\ninterface CAPA {\n  id: string;\n  title: string;\n  evidence: string[];\n  artifacts: string[];\n  state: 'detected'|'triaged'|'in_progress'|'contained'|'closed';\n  createdAt: string;\n  updatedAt?: string;\n  links?: { type: string; url: string }[];\n}\n```\n\n## Follow-up Questions\n\n- How would you scale CAPA data stores across regions?\n- How to ensure regulatory auditability and evidence integrity?","diagram":"flowchart TD\n  A[Incident Detected] --> B[Evidence Collected]\n  B --> C[CAPA Created]\n  C --> D[Root Cause Analysis]\n  D --> E[Containment]\n  E --> F[Preventive Action]\n  F --> G[Canary Validation]\n  G --> H[Global Rollout]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","MongoDB","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:23:32.007Z","createdAt":"2026-01-13T01:23:32.007Z"},{"id":"q-1156","question":"Scenario: A distributed streaming analytics pipeline processes click events for an online marketplace. A recently deployed shard rebalancing causes out-of-order events in two regions, leading to incorrect revenue attribution and fraud alerts. Design a CAPA program that covers: 1) a CAPA data model that captures evidence (events, traces, timestamps, orderings) and artifacts (config, manifest, canary results), 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces and event metadata, 4) region- and shard-aware metrics to prove containment (recurrence rate, MTTR, misattribution rate), 5) an RCA template and a canary-rollback plan for shard rebalancing?","answer":"Propose a CAPA program for out-of-order events from shard rebalancing in a streaming analytics pipeline. Data model: CAPA(id, region, shard, evidence: [eventId, traceId, timestamp], artifacts: [config","explanation":"Why This Is Asked\nTests end-to-end CAPA thinking for distributed streaming with event-ordering issues and rollback safety.\n\nKey Concepts\n- CAPA data model for evidence and artifacts\n- Lifecycle state machine with containment and prevention\n- Minimal REST API for linking logs/traces to CAPAs\n- Region/shard-aware metrics and attribution correctness\n- RCA template and canary rollback strategy\n\nCode Example\n```javascript\n// Minimal REST API sketch (Express)\nconst express = require('express');\nconst app = express();\napp.use(express.json());\napp.post('/caps', (req, res) => {\n  // validate and persist CAPA with evidence refs\n  res.status(201).send({ id: 'capa-123' });\n});\n```\n\nFollow-up Questions\n- How would you validate and test the canary rollback under varying traffic patterns?\n- What data retention and privacy controls are needed for CAPA artifacts?","diagram":"flowchart TD\nA[Incident Observed] --> B[Triage & Evidence]\nB --> C[Containment via Canary]\nC --> D[Root Cause Analysis]\nD --> E[Corrective Action]\nE --> F[Preventive Action]\nF --> G[Close CAPA]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T03:28:35.156Z","createdAt":"2026-01-13T03:28:35.156Z"},{"id":"q-1200","question":"Scenario: A global real-time telemetry platform for autonomous vehicles experiences intermittent PII exposure due to a log-redaction misconfiguration after a software update in two regions. Design a CAPA program to detect, document, and prevent recurrence. Include: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant- and region-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary-based rollback/patch plan, 6) a policy gate preventing deployment until redact coverage is above threshold?","answer":"CAPA design: use a normalized CAPA data model with fields like id, tenants, regions, evidence_refs (logs/traces), artifacts, state, severity, and timestamps. Lifecycle: New → Open → Investigating → Co","explanation":"## Why This Is Asked\n\nTests ability to design end-to-end CAPA workflow for privacy incidents, including across tenants and regions, with concrete artifacts and controls.\n\n## Key Concepts\n\n- CAPA data model, state machine, API design, region-tenant metrics, RCA, canary rollback, policy gates.\n\n## Code Example\n\n```javascript\n// Example CAPA payload shape\ninterface CAPA { id: string; tenants: string[]; regions: string[]; evidence_refs: string[]; artifacts: string[]; state: string; severity: string; timestamps: Record<string,string>; }\n```\n\n## Follow-up Questions\n\n- How would you verify redact coverage? What tests would you add?\n- How do you design region-aware dashboards to avoid alert fatigue?\n","diagram":"flowchart TD\nA[New CAPA] --> B[Open]\nB --> C[Investigating]\nC --> D[Containment]\nD --> E[Corrective Action]\nE --> F[Verified]\nF --> G[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:48:36.347Z","createdAt":"2026-01-13T04:48:36.347Z"},{"id":"q-1426","question":"Scenario: A multi-tenant SaaS billing system release unintentionally changes pricing rules for a subset of tenants, triggering incorrect invoices and revenue churn. Design a beginner CAPA program to address this. Your task: 1) propose a CAPA data model capturing evidence (invoices, logs, traces) and artifacts (config, feature flags, pricing rules); 2) define a lifecycle state machine for CAPA progression; 3) outline a minimal REST API to create/update CAPAs with linked billing events; 4) specify tenant- and plan-level metrics to prove containment (recurrence rate, MTTR, false positives); 5) provide an RCA template and a canary-based patch plan before full rollout; 6) draft a simple policy gate that prevents deployment until pricing rules pass a preflight check?","answer":"CAPA data model: capa_id, tenant_id, invoice_id, evidence_refs, artifacts, pricing_rule_version; lifecycle: detected -> validated -> in_progress -> contained -> resolved -> closed; API: POST/PUT /caps","explanation":"## Why This Is Asked\nTests practical CAPA thinking: data modeling, lifecycle, minimal API, and measurable outcomes for a realistic beginner scenario.\n\n## Key Concepts\n- CAPA data model with evidence and artifacts\n- Lifecycle state machine for progress\n- Minimal REST API for CAPAs\n- Tenant/plan metrics to prove containment\n- RCA template and canary remediation plan\n\n## Code Example\n```javascript\n// example schema outline\nconst CAPASchema = {\n  capa_id: String,\n  tenant_id: String,\n  invoice_id: String,\n  evidence_refs: [String],\n  artifacts: [String],\n  pricing_rule_version: String\n}\n```\n\n## Follow-up Questions\n- How would you version artifacts and signatures for integrity?\n- What alerting would you add to detect recurring pricing issues?","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T16:47:28.090Z","createdAt":"2026-01-13T16:47:28.090Z"},{"id":"q-1450","question":"Scenario: A global multi-tenant data platform implements a new consent-logging feature. After rollout, a bug in the consent service causes PII redaction failures in two regions, risking data exposure and compliance violations. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region- and tenant-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollout plan to validate fixes before global deployment?","answer":"Design a CAPA: data model with CAPA, evidence, artifacts, linked logs/traces; lifecycle: Identified → Investigating → Contained → Eradicated → Verified → Closed; REST API: POST /caps to create, PATCH ","explanation":"## Why This Is Asked\nTests the ability to architect an end-to-end CAPA workflow for a data-platform reliability incident that spans regions and tenants, including how to model evidence and link traces for audit trails.\n\n## Key Concepts\n- CAPA data model with evidence and linked artifacts\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for creating/updating CAPAs\n- Region- and tenant-aware metrics (recurrence, MTTR, false positives)\n- RCA templates and canary rollout planning\n\n## Code Example\n```javascript\n// Example CAPA schema (illustrative)\n{\n  id: string,\n  title: string,\n  region: string,\n  tenant_id: string,\n  status: string,\n  evidence: string[],\n  artifacts: string[],\n  remediation: object\n}\n```\n\n## Follow-up Questions\n- How would you automate evidence collection across services?\n- How would you handle new tenants with no historical CAPA data?","diagram":"flowchart TD\n  A[Identified] --> B[Investigating]\n  B --> C[Contained]\n  C --> D[Eradicated]\n  D --> E[Verified]\n  E --> F[Closed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","LinkedIn","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T17:46:10.476Z","createdAt":"2026-01-13T17:46:10.477Z"},{"id":"q-1485","question":"**Scenario**: A cross-tenant data export feature in a multi-tenant SaaS app accidentally exposes data from unrelated tenants during a canary rollout in two regions. Design a beginner **CAPA** program to detect, document, and prevent recurrence. Your task: 1) propose a CAPA data model framing evidence and artifacts, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with linked logs/traces, 4) specify tenant-scoped metrics for containment, 5) provide an RCA template and a canary-based fix plan to validate before broader rollout?","answer":"CAPA data model: CAPA{id, tenantId, region, evidenceRefs, severity, rootCause, correctiveAction, preventiveAction, status, timestamps}. Lifecycle: new→triage→investigate→remediate→verify→closed. API: POST /capas (create), GET /capas/{id}, PUT /capas/{id} (update), POST /capas/{id}/evidence (link logs/traces). Tenant-scoped metrics: dataExposureEvents{tenantId, region, count}, containmentTime{tenantId, region, ms}, rcaCompletionRate{tenantId, percentage}, canaryValidationSuccess{tenantId, boolean}. RCA template: incidentSummary, timeline, rootCauseAnalysis, impactAssessment, correctiveActions, preventiveActions, verificationCriteria. Canary fix plan: 1) implement fix in single tenant, 2) validate no data leakage, 3) monitor containment metrics, 4) gradual regional rollout, 5) full deployment after 24h clean monitoring.","explanation":"## Why This Is Asked\nTests ability to translate incident learnings into a repeatable CAPA workflow for multi-tenant data exposure, focusing on a basic data model, lifecycle, measurable containment, and practical API design.\n\n## Key Concepts\n- CAPA data modeling with tenant isolation\n- Lifecycle state machine for incident response\n- REST API design for evidence management\n- Tenant-scoped containment metrics\n- RCA templates and canary validation\n\n## Code Example\n```javascript\n// CAPA record with evidence linking\nconst CAPA = {\n  id, tenantId, region,\n  evidenceRefs: [\"log:trace-123\", \"metric:exposure-456\"],\n  severity, rootCause,\n  correctiveAction, preventiveAction,\n  status, createdAt, updatedAt\n};\n```\n\n## Follow-up Questions\n- How would privacy-by-design constraints influence CAPA data fields?\n- Which minimal tests verify the canary fix works without regressions?","diagram":"flowchart TD\n  A[CAPA Initiated] --> B[Triage]\n  B --> C[Investigation]\n  C --> D[Remediate]\n  D --> E[Verify]\n  E --> F[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":["capa data model","lifecycle state machine","rest api design","tenant-scoped metrics","rca template","canary fix plan","multi-tenant saas","data exposure","evidence management","containment metrics","root cause analysis","gradual rollout"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-14T05:11:47.713Z","createdAt":"2026-01-13T18:58:29.114Z"},{"id":"q-1502","question":"Scenario: A new analytics feature ingests raw customer IDs into a 3rd-party BI dataset due to a masking policy misconfiguration in the data pipeline. Design a CAPA program to detect, document, and prevent recurrence. Your tasks: 1) propose a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant-scoped metrics for containment and recurrence, 5) an RCA template and a canary-based remediation plan to validate before rollout?","answer":"CAPA data model: id, incident_id, tenant_id, data_asset, evidence_uris, lineage_digest, root_cause, containment_actions, corrective_actions, verification, status, created_at, updated_at. State machine","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for data leakage via a 3rd-party BI integration, emphasizing evidence capture, containment, and validation before rollout.\n\n## Key Concepts\n- CAPA data model, lifecycle, tenant-scoped metrics, RCA templates, canary remediation.\n- Data lineage, masking policy correctness, logs/traces, DLP controls.\n\n## Code Example\n```javascript\nconst capa = {\n  id: 'CAPA-XXXX',\n  incident_id: 'INC-1234',\n  tenant_id: 'T1',\n  data_asset: 'BI_dataset_X',\n  evidence_uris: ['s3://logs/inc-1234/trace1','s3://evidence/policy.yaml'],\n  lineage_digest: 'abcd1234',\n  root_cause: 'masking_policy_misconfig',\n  containment_actions: ['disable_bi_feed'],\n  corrective_actions: ['update_masking', 'retrain_policy'],\n  verification: 'passed',\n  status: 'CLOSED',\n  created_at: '2026-01-01T00:00:00Z',\n  updated_at: '2026-01-02T12:00:00Z'\n}\n```\n\n## Follow-up Questions\n- How would you automate evidence collection across services?\n- What metrics would you visualize to verify containment and recurrence reduction?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T19:39:15.407Z","createdAt":"2026-01-13T19:39:15.407Z"},{"id":"q-1528","question":"Scenario: A vendor data feed for pricing and product metadata experiences occasional delays and duplicates during a quarterly refresh, causing price mismatches in two regions. Design a beginner CAPA program to address this. Your tasks: 1) propose a CAPA data model capturing evidence and artifacts, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with linked feed records, 4) specify region- and tenant-aware metrics to prove containment, 5) provide an RCA template and a canary-based preventive action plan to validate before broader rollout?","answer":"Propose a CAPA data model capturing evidence (feed_id, timestamp, region, tenant, price_record) and artifacts (config, rules, vendor_version); define a lifecycle state machine with states (open → investigate → containment → corrective → preventive → closed); outline a minimal REST API with endpoints POST /capas and PUT /capas/:id supporting linked feed records; specify region- and tenant-aware metrics including containment rate, duplicate frequency, and price mismatch latency; provide an RCA template covering timeline, root causes, and impact analysis; and implement a canary-based preventive action plan with staged validation before broader rollout.","explanation":"## Why This Is Asked\nAssesses practical CAPA skill under a vendor-feed incident with regional impact.\n\n## Key Concepts\n- CAPA data model, evidence artifacts\n- Lifecycle management, state transitions\n- API design with linked feed records\n- Region/tenant metrics for containment\n- RCA template and canary-based preventive actions\n\n## Code Example\n```javascript\n// Minimal CAPA schema sketch\n{ \"id\": \"CAPA-001\", \"incident\": \"vendor-feed\", \"state\": \"open\" }\n```\n\n## Follow-up Questions\n- How would you validate the canary plan across regions?\n- How would you prevent future duplicates in the feed?","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Coinbase","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T06:49:29.965Z","createdAt":"2026-01-13T20:45:01.344Z"},{"id":"q-1556","question":"Two regions saw bids inflated after a cache invalidation caused an expired pricing model to be applied in an ad-bidding pipeline. Design a CAPA program to detect, document, and prevent recurrence. Your task: 1) CAPA data model for evidence and artifacts, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) region-asset metrics for containment (recurrence rate, MTTR, false positives), 5) RCA template and a canary cache-invalidation plan before rollout?","answer":"CAPA data model should include: id, region, asset, incident_id, evidence_links, artifacts, state, severity, timestamps, corrective_action, preventive_action, canary_results. State machine: New → In Progress → Review → Approved → Implemented → Verified → Closed. REST API endpoints: POST /capas, GET /capas/{id}, PUT /capas/{id}, GET /capas/{id}/logs, GET /capas/{id}/traces. Region-asset metrics: recurrence_rate, mttr, false_positive_rate, containment_time. RCA template sections: incident_summary, timeline, root_causes, impact_assessment, corrective_actions, preventive_actions, lessons_learned. Canary cache-invalidation plan: validate pricing model versioning, implement cache warming, add rollback triggers, monitor bid accuracy during rollout.","explanation":"## Why This Is Asked\nAssess ability to design end-to-end CAPA tooling for real-world pipeline failures, including data modeling, lifecycle governance, API ergonomics, measurable containment metrics, and a concrete RCA/canary plan.\n\n## Key Concepts\n- CAPA data modeling\n- State machine design\n- REST API design for incident artifacts\n- Regional metrics and RCA templates\n- Canary rollback for cache invalidation\n\n## Code Example\n```javascript\n// Skeleton CAPA entity\nclass CAPA { constructor(...) { ... } }\n```\n\n## Follow-up Questions\n- How would you version CAPA artifacts and enforce security constraints?","diagram":"flowchart TD\n  A[New CAPA] --> B[In Progress]\n  B --> C[Containment Verified]\n  C --> D[Root Cause]\n  D --> E[Corrective Action]\n  E --> F[Preventive Action]\n  F --> G[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-14T06:25:02.549Z","createdAt":"2026-01-13T21:42:31.859Z"},{"id":"q-1635","question":"A distributed cache layer across two regions intermittently serves stale reads after a deployment; design a beginner CAPA program to detect, document, and prevent recurrence?","answer":"CAPA data model: id, issue, evidence, containment, rootCause, actions, status, timeline. State machine: DETECTED → EVALUATED → CONTAINED → CORRECTED → VERIFIED → CLOSED. API: POST /caps, PATCH /caps/{","explanation":"## Why This Is Asked\n\nTests practical CAPA planning for a production cache issue, ensuring a clear, beginner-friendly workflow.\n\n## Key Concepts\n\n- CAPA data model design\n- Lifecycle state machine\n- Minimal REST API design\n- Metrics for containment\n- RCA structure\n- Canary rollout and rollback strategies\n- Policy gates\n\n## Code Example\n\n```json\n{\n  \"id\": \"CAPA-0002\",\n  \"issue\": \"stale-cache-read\",\n  \"evidence\": [\"log:cache-miss\", \"trace:deploy\"],\n  \"containment\": \"paused deploy to region A\",\n  \"rootCause\": \"cache TTL misconfiguration\",\n  \"actions\": [\"revert deploy\", \"adjust TTLs\", \"validate with canary\"],\n  \"status\": \"open\",\n  \"timeline\": [\"2026-01-14T12:00Z\"]\n}\n```\n\n## Follow-up Questions\n\n- How would you ensure idempotency of CAPA creation?\n- How would you extend metrics for multi-region detection latency?","diagram":"flowchart TD\n  Detect[Detect CAPA] --> Eval[Evaluate Evidence]\n  Eval --> Contain[Containment Actions]\n  Contain --> Root[Root Cause Analysis]\n  Root --> Plan[Plan Preventive Actions]\n  Plan --> Close[Close CAPA]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:21:10.430Z","createdAt":"2026-01-14T04:21:10.431Z"},{"id":"q-1745","question":"Scenario: In a multi-tenant payments platform serving PayPal, Lyft, and Coinbase, a policy change to transaction masking and logging fails to propagate to streaming and analytics pipelines in two regions, raising privacy risk and audit gaps. Design a CAPA program to address this: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces and policy versions, 4) region-aware metrics to prove containment (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollback plan for policy changes?","answer":"Model CAPAs with: id, policy_version, evidence_refs, artifacts, region, status, root_cause, corrective_action, verification. Lifecycle: pending → evidence_collected → impact_assessed → containment → r","explanation":"## Why This Is Asked\nTests ability to design a scalable CAPA program for policy drift affecting data masking and logging, with cross-region impact.\n\n## Key Concepts\n- CAPA data model with evidence and artifacts\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for CAPAs with linkage to logs/traces and policy versions\n- Region-aware metrics (recurrence, MTTR, false positives)\n- RCA template and canary rollback strategy\n\n## Code Example\n```javascript\nconst CAPA = {\n  id: 'string',\n  policy_version: 'string',\n  region: 'string',\n  evidence_refs: ['string'],\n  artifacts: {config: 'string', manifest: 'string'},\n  status: 'pending',\n  root_cause: 'string',\n  corrective_action: 'string',\n  verification: 'string'\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA data store for high-cardinality evidence refs?\n- What are safe-guards to prevent false rollbacks during canary rollout?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Lyft","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:04:06.160Z","createdAt":"2026-01-14T09:04:06.160Z"},{"id":"q-1848","question":"Design a CAPA for drift in an ML fraud detector across regions: 1) CAPA data model with driftIndex, affectedFeatures, modelVersion, evidence and artifact links; 2) lifecycle: detected → investigating → containment → RCA → closed; 3) minimal REST API to create/update CAPAs with logs and model snapshots; 4) region metrics: drift magnitude, MTTR, FPR/TPR changes; 5) RCA and canary rollback plan?","answer":"Design a CAPA for drift in an ML fraud detector across regions: 1) CAPA data model with driftIndex, affectedFeatures, modelVersion, evidence and artifact links; 2) lifecycle: detected → investigating ","explanation":"## Why This Is Asked\nML drift is a real, high-stakes problem across Netflix/Cloudflare/Uber. This question tests ability to model CAPA data, design lifecycle, and tie it to actionable metrics and rollback.\n\n## Key Concepts\n- Drift detection and data provenance\n- Model versioning and artifacts\n- Canary-based rollback vs retraining\n- Cross-region governance and metrics\n\n## Code Example\n```javascript\n// CAPA data model sketch\nconst CAPA = {\n  id: 'capa-123',\n  driftIndex: 0.42,\n  affectedFeatures: ['featureA','featureB'],\n  modelVersion: 'v1.2.3',\n  evidenceLinks: ['log/link1'],\n  artifacts: { modelSnapshot: 's3://bucket/model.v1.2.3.zip' }\n}\n```\n\n## Follow-up Questions\n- How would you test the canary rollback in production?\n- How do you prevent recurrence long-term?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Netflix","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T14:34:57.024Z","createdAt":"2026-01-14T14:34:57.024Z"},{"id":"q-1899","question":"Scenario: A real-time analytics service relies on a 3rd-party enrichment API. Under peak load, enrichment latency spikes cause backpressure and data loss in two regions. Design a beginner CAPA program to address this. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with evidence, 4) region-aware metrics to prove containment, 5) an RCA template and a canary-based fallback plan?","answer":"Approach: CAPA data model includes id, region, service, dependency, evidenceLinks, artifacts, severity, status. Lifecycle: detected → investigating → mitigating → RCA → closed. API: POST/PUT CAPA with","explanation":"## Why This Is Asked\nTests ability to model CAPA for external dependencies and design minimal controls in a beginner context.\n\n## Key Concepts\n- CAPA data model and lifecycle\n- Evidence capture and artifact linking\n- Region-aware metrics and canary planning\n- RCA templates and rollback strategies\n\n## Code Example\n```javascript\n// Minimal CAPA object\nconst capa = {\n  id: \"capa-123\",\n  region: \"us-east-1\",\n  service: \"real-time-analytics\",\n  dependency: \"enrichment-api\",\n  evidenceLinks: [\"https://trace.example/1\"],\n  artifacts: [\"trace.json\", \"snapshot.png\"],\n  severity: \"medium\",\n  status: \"detected\"\n}\n```\n\n## Follow-up Questions\n- How would you validate and measure the success of the canary fallback before full rollout?\n- What privacy or data-handling considerations arise when collecting evidence across regions?","diagram":"flowchart TD\n  Detected[Detected] --> Investigating[Investigating]\n  Investigating --> Mitigating[Mitigating]\n  Mitigating --> RCA[RCA]\n  RCA --> Closed[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T16:43:13.575Z","createdAt":"2026-01-14T16:43:13.575Z"},{"id":"q-1952","question":"Scenario: A multi-tenant data platform powering market data feeds experiences cross-tenant data leakage under peak load. Design a CAPA program to detect, contain, and prevent recurrence. Include: 1) a CAPA data model capturing tenantId, policyId, incidentId, evidence and artifact links; 2) a lifecycle state machine; 3) a minimal REST API to create/update CAPAs with tenant-scoped logs and traces; 4) tenant-aware metrics (recurrence, MTTR, spillover rate); 5) RCA template and a canary policy rollout plan?","answer":"Design focuses on strong isolation and traceability: a CAPA data model with tenantId, policyId, incidentId,EvidenceLinks,ArtifactSnapshots,affectedTables,dataClassification; states: detected→investiga","explanation":"## Why This Is Asked\nThis question tests ability to design a production-grade CAPA for a multi-tenant data platform, emphasizing isolation, auditability, and scalable rollout.\n\n## Key Concepts\n- Tenant-scoped CAPA data model with evidence and artifacts\n- Immutable links to logs/traces and resource metadata\n- Lifecycle state machine and canary-based enforcement\n- Per-tenant metrics (recurrence, MTTR, spillover rate)\n\n## Code Example\n```javascript\n// TypeScript interface for CAPA\ninterface CAPA {\n  id: string;\n  tenantId: string;\n  policyId: string;\n  incidentId: string;\n  evidenceLinks: string[];\n  artifacts: string[];\n  affectedResources: string[];\n  dataClassification: string;\n}\n```\n\n## Follow-up Questions\n- How would you handle CAPA versioning and backward compatibility?\n- How to simulate cross-tenant leakage in a canary without impacting production?","diagram":"flowchart TD\nA[Detected CAPA] --> B[Investigating]\nB --> C[Containment]\nC --> D[RCA]\nD --> E[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","MongoDB","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:49:17.889Z","createdAt":"2026-01-14T18:49:17.890Z"},{"id":"q-2132","question":"Scenario: A multi-region real-time bidding system processes ad events via Kafka across us-east-1 and eu-west-1. A recently deployed bid normalization microservice causes timeouts and mispricing, leading to revenue variance and increased false positives in two regions. Design a CAPA program that covers: 1) a CAPA data model capturing evidence, artifacts, and cross-region traces; 2) a lifecycle state machine for CAPA progression; 3) a minimal REST API to create/update CAPAs with linked logs/traces; 4) region-aware metrics to prove containment (recurrence rate, MTTR, revenue delta, false-positive rate); 5) an RCA template and a canary rollout plan for the normalization service?","answer":"Craft a CAPA with: 1) data model capturing incidentId, region, service, timestamps, logs, traces, and artifact links; 2) a lifecycle: detected → triaged → containment → RCA → remediation → closed; 3) ","explanation":"## Why This Is Asked\nAssesses ability to design production-grade CAPA across multiple regions for real-time pipelines, with verifiable metrics and controlled rollout.\n\n## Key Concepts\n- CAPA data modeling with cross-region traces and artifacts\n- Lifecycle state machine for remediation workflows\n- Minimal REST API design for linking evidence\n- Region-aware metrics and alerting strategies\n- RCA template and canary rollout plans\n\n## Code Example\n```javascript\ntype CAPARecord = {\n  incidentId: string;\n  region: string;\n  service: string;\n  detectedAt: string;\n  status: 'detected'|'triaged'|'containment'|'RCA'|'remediation'|'closed';\n  evidenceLinks: string[];\n  artifactLinks: string[];\n  linkedLogs: string[];\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA store for high cardinality regions and tenants?\n- What thresholds would trigger automatic containment vs. human triage?","diagram":"flowchart TD\n  A[Detect] --> B[Investigate]\n  B --> C[Containment]\n  C --> D[RCA]\n  D --> E[Remediation]\n  E --> F[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Salesforce","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:15:47.411Z","createdAt":"2026-01-15T04:15:47.411Z"},{"id":"q-2174","question":"Scenario: A data-access policy violation occurs when a misconfigured feature-flag rollout temporarily allows cross-tenant data access in two regions. Design a CAPA program to detect, document, and prevent recurrence. Include: 1) a CAPA data model capturing lineage, access changes, and remediation artifacts; 2) a lifecycle state machine; 3) a minimal REST API to create/update CAPAs with linked logs/traces and policy changes; 4) region- and tenant-scoped metrics; 5) an RCA template and a canary-based remediation plan?","answer":"CAPA plan for a data-access policy violation caused by a misconfigured feature flag that briefly allowed cross-tenant access in two regions. 1) CAPA data model capturing lineage, access changes, and r","explanation":"## Why This Is Asked\nTests ability to plan CAPA around privacy and cross-tenant isolation, including evidence capture, lifecycle control, and safe remediation.\n\n## Key Concepts\n- CAPA data model with lineage and access-change artifacts\n- Data privacy/regulatory considerations\n- REST API design for CAPA creation/update with traces\n- Canary-based remediation and regional rollout controls\n- Metrics: containment MTTR, recurrence rate, false positives\n\n## Code Example\n```javascript\nconst capa = { id: \"CAPA-001\", incidentId: \"INC-12345\", evidence: [\"log:auth-01\"], state: \"detected\" };\n```\n\n## Follow-up Questions\n- How would you test the RCA template under high-traffic load?\n- What mitigations would you add to the canary remediation plan?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:49:29.109Z","createdAt":"2026-01-15T05:49:29.109Z"},{"id":"q-2228","question":"Scenario: A webhook-driven notification service intermittently loses messages in two regions after deploying a new retry-backoff policy. Design a beginner CAPA program to address this. Your task: 1) propose a CAPA data model, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with evidence, 4) specify practical, region-aware metrics to prove containment, 5) provide an RCA template and a canary-based rollback/test plan before full rollout?","answer":"Develop a CAPA for intermittent webhook message loss after switching to a stricter retry-backoff. Data model: id, detectedAt, service, region, issueDescription, evidenceLinks, artifacts, status, rootC","explanation":"## Why This Is Asked\n\nThis question tests a candidate's ability to translate a real incident into a repeatable CAPA workflow with concrete data modeling, lifecycle, measurable metrics, and an actionable rollback plan.\n\n## Key Concepts\n\n- CAPA data model design\n- Lifecycle state machine for CAPA\n- Region-aware metrics and evidence linking\n- RCA templating and canary-based validation\n\n## Code Example\n\n```javascript\n// Minimal CAPA store skeleton\nclass CAPA { constructor(id, region, issue){ this.id=id; this.region=region; this.issue=issue; this.status='detected'; } }\n```\n\n## Follow-up Questions\n\n- How would you extend the model for multi-tenant isolation and audit trails?\n- What tests would you add to validate the canary rollback triggers?","diagram":"flowchart TD\n  A[Detected] --> B[Investigating]\n  B --> C[Containment]\n  C --> D[RCA]\n  D --> E[Preventive/Canary]\n  E --> F[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Instacart","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T08:43:41.547Z","createdAt":"2026-01-15T08:43:41.547Z"},{"id":"q-2363","question":"In a multi-region streaming analytics platform, a surge triggers backpressure and late events in two regions. Design a CAPA program that focuses on data-plane backlogs affecting downstream attribution. Include: 1) a CAPA data model capturing evidence and artifacts, 2) a region/shard-aware lifecycle, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) metrics proving containment (latency drift, backlog depth, MTTR), 5) RCA template and a canary rollout for a dynamic circuit-breaker in the ingestion path?","answer":"CAPA data model with id, incidentId, regions, shards, startTime, evidenceLinks, logsTraces, metricsSnapshots, containmentPlan, rootCause, RCA, artifacts; lifecycle states: detected→assessing→backlogCo","explanation":"## Why This Is Asked\nTests ability to craft a CAPA with data-plane focus, multi-region correlation, and concrete artifacts to track containment and recurrence.\n\n## Key Concepts\n- CAPA data model with evidence and artifact links\n- Region/shard-aware lifecycle and metrics\n- Minimal REST API to link logs/traces to CAPAs\n- RCA templates and safe canary rollout for ingestion controls\n\n## Code Example\n```javascript\n// Example REST handler sketch (for CAPA creation)\nfunction createCAPA(req, res) {\n  const capa = req.body;\n  // validate required fields: id, region, shard, startTime\n  res.status(201).send({ ok: true, id: capa.id });\n}\n```\n\n## Follow-up Questions\n- How would you validate canary success without customer impact?\n- What strategies mitigate false positives when region clocks drift? ","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T14:52:47.749Z","createdAt":"2026-01-15T14:52:47.749Z"},{"id":"q-2393","question":"Scenario: A cost spike in cloud spend occurs due to a runaway batch job in two regions; design a beginner CAPA that addresses this. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with evidence, 4) region-aware metrics to prove containment, 5) an RCA template and a canary-based remediation plan?","answer":"Cost spike CAPA for a runaway batch causing cloud spend in two regions. 1) Data model: id, risk, service, regions, evidenceLinks, artifacts, costDelta, window. 2) Lifecycle: detected → investigating →","explanation":"## Why This Is Asked\nTests ability to translate a real cost-incident into a structured CAPA program.\n\n## Key Concepts\n- CAPA data model, lifecycle, minimal API, region-aware metrics, RCA, canary remediation.\n- Trade-offs: sampling evidence vs. privacy, canary granularity, cost thresholds.\n\n## Code Example\n```javascript\n// Pseudo-structure for CAPA object\nconst capa = { id: '', risk: '', service: '', regions: [], evidenceLinks: [], artifacts: [], costDelta: 0, window: '' };\n```\n\n## Follow-up Questions\n- How would you measure preventiveness over time? \n- What thresholds would trigger automatic containment actions?","diagram":"flowchart TD\n  D[Detection] --> C[Containment]\n  C --> R[RCA]\n  R --> M[Remediation]\n  M --> V[Verification]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Instacart","Snowflake","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T16:44:03.206Z","createdAt":"2026-01-15T16:44:03.208Z"},{"id":"q-2430","question":"Scenario: A multi-region analytics platform begins exporting customer PII to a BI partner after a schema change, risking regulatory non-compliance. Design a CAPA program to address this: 1) CAPA data model for evidence and artifacts, 2) lifecycle state machine, 3) minimal REST API to create/update CAPAs with linked logs and data-access policy checks, 4) region-aware metrics (policy-violation rate, MTTR, false positives), 5) RCA template and a canary rollout plan with automated data redaction?","answer":"Propose a CAPA for cross-region analytics where a schema change inadvertently exports PII to a BI partner. Deliver: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine,","explanation":"## Why This Is Asked\nTests ability to design CAPA from data governance, not just incident response.\n\n## Key Concepts\n- CAPA data model for evidence, artifacts, and policy checks\n- Lifecycle state machine with DETECT → INVESTIGATE → CONTAIN → REMEDIATE → VERIFY → CLOSED\n- Minimal REST API design for CAPA creation/update with linked traces\n- Region-aware compliance metrics (violation rate, MTTR, FP rate)\n- RCA template and canary rollout with automated data redaction\n\n## Code Example\n```javascript\n// CAPA data model sketch (TypeScript)\ntype CAPARecord = {\n  id: string;\n  title: string;\n  evidenceUrls: string[];\n  policyChecks: string[];\n  region: string;\n  state: 'DETECTED'|'INVESTIGATING'|'CONTAINED'|'REMEDIATED'|'VERIFIED'|'CLOSED';\n  createdAt: string;\n  updatedAt: string;\n};\n```\n\n## Follow-up Questions\n- How would you surface policy checks in runtime dashboards?\n- How would you automate data redaction in canary tests before broader rollout?","diagram":"flowchart TD\n  A[Detect Violation] --> B[Collect Evidence]\n  B --> C[Contain Data Export]\n  C --> D[Remediate Schema/Policy]\n  D --> E[Verify Compliance]\n  E --> F[Close CAPA]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Tesla","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T17:49:16.501Z","createdAt":"2026-01-15T17:49:16.501Z"},{"id":"q-2611","question":"Scenario: A global data-analytics pipeline intermittently drops events in two regions during peak load due to a misconfigured ETL window. Design a beginner CAPA program: 1) CAPA data model, 2) lifecycle state machine, 3) a minimal REST API to create/update CAPAs with evidence, 4) region-aware metrics to prove containment and prevent recurrence, 5) RCA template and a canary-based remediation plan. Keep it implementable with simple tooling?","answer":"CAPA Data Model: {id, title, affectedRegions, evidence, rootCause, correctiveAction, preventiveAction, status, createdBy, createdAt, updatedAt}. Lifecycle State Machine: detected → validated → contained → investigating → remediated → verified → closed. REST API: POST /capas to create with evidence, PUT /capas/:id to update, GET /capas/:id to retrieve, PATCH /capas/:id/status for state transitions. Region-Aware Metrics: eventDropRate(region), pipelineLatency(region), containmentScore(region), remediationEffectiveness(region). RCA Template: {incidentSummary, timeline, rootCauseAnalysis, impactAssessment, containmentActions, lessonsLearned}. Canary-Based Remediation: Deploy fix to single region, monitor metrics for 30 minutes, verify containment, then execute staged global rollout with rollback capability.","explanation":"## Why This Is Asked\n\nAssesses ability to design a practical CAPA program for ensuring data integrity in global distributed systems, emphasizing traceability, containment, and systematic problem resolution.\n\n## Key Concepts\n\n- CAPA data modeling and lifecycle management\n- State machine design for systematic issue resolution\n- RESTful API design with evidence handling\n- Region-specific monitoring and metrics\n- Root Cause Analysis methodologies\n- Canary deployment strategies for safe remediation\n\n## Code Example\n\n```javascript\n// Minimal REST API for CAPA management\nconst express = require('express');\nconst app = express();\n\napp.use(express.json());\n\n// CAPA data storage (in production, use proper database)\nlet capas = {};\n\n// POST /capas - Create new CAPA with evidence\napp.post('/capas', (req, res) => {\n  const capa = {\n    id: Date.now().toString(),\n    ...req.body,\n    status: 'detected',\n    createdAt: new Date().toISOString()\n  };\n  capas[capa.id] = capa;\n  res.status(201).json(capa);\n});\n\n// PUT /capas/:id - Update existing CAPA\napp.put('/capas/:id', (req, res) => {\n  const id = req.params.id;\n  if (!capas[id]) return res.status(404).json({error: 'CAPA not found'});\n  \n  capas[id] = {\n    ...capas[id],\n    ...req.body,\n    updatedAt: new Date().toISOString()\n  };\n  res.json(capas[id]);\n});\n\n// PATCH /capas/:id/status - Update CAPA status\napp.patch('/capas/:id/status', (req, res) => {\n  const id = req.params.id;\n  if (!capas[id]) return res.status(404).json({error: 'CAPA not found'});\n  \n  capas[id].status = req.body.status;\n  capas[id].updatedAt = new Date().toISOString();\n  res.json(capas[id]);\n});\n\napp.listen(3000, () => console.log('CAPA API running on port 3000'));\n```","diagram":"flowchart TD\n  A[Detect CAPA] --> B[Validate Evidence]\n  B --> C[State:InProgress]\n  C --> D[Containment]\n  D --> E[Investigation]\n  E --> F[Remediation Canary]\n  F --> G[Verification]\n  G --> H[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","MongoDB","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:01:45.867Z","createdAt":"2026-01-16T02:42:35.935Z"},{"id":"q-2731","question":"Scenario: A real-time telemetry pipeline logs PII after a schema update in two regions, triggering a privacy incident. Design a CAPA program to prevent recurrence: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with redacted evidence (logs/traces), 4) region-aware metrics to prove containment (PII_exposure_rate, MTTR, false_positives), 5) an RCA template and a canary rollout plan for patching the logging/path?","answer":"Define a CAPA data model: id, region, evidence, artifacts, root_cause, corrective_actions, preventive_actions, status, timestamps. Lifecycle: Detected → Triaged → Contained → Eradicated → Verified → C","explanation":"Why This Is Asked\nTests privacy-aware CAPA handling in multi-region pipelines with practical API design and measurable containment.\n\nKey Concepts\n- Data redaction and auditability\n- Region-aware metrics\n- Canary rollouts and rollback\n\nCode Example\n```javascript\nfunction redactLog(log){ return log.replace(/(email|phone|SSN|credit)/i, '[REDACTED]'); }\n```\n\nFollow-up Questions\n- How would you test the redaction function to ensure no PII leaks remains?\n- How would you structure RCA sections for a privacy CAPA and ensure regulatory traceability?","diagram":"flowchart TD\n  A[CAPA Detected] --> B[Evidence Collected]\n  B --> C{Containment Needed?}\n  C -->|Yes| D[Containment Implemented]\n  C -->|No| E[Escalate]\n  D --> F[Eradicated/Verified]\n  F --> G[Closed]\n  E --> H[Root Cause Analysis]\n  H --> I[Preventive Action]\n  I --> J[Canary Rollout]\n  J --> F","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T09:42:40.719Z","createdAt":"2026-01-16T09:42:40.720Z"},{"id":"q-2753","question":"In a global platform handling encrypted customer data, a key-rotation facility misdeploy causes decrypt failures in two regions, blocking access to data. Design a CAPA program to detect, contain, and prevent recurrence. Your task: 1) propose a CAPA data model capturing evidence and artifacts, 2) define a region-aware lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with linked logs/traces, 4) specify region-aware metrics to prove containment (downtime, MTTR, data-access success rate, false positives), 5) provide an RCA template and a canary-based remediation plan for key-rotation changes?","answer":"Propose a CAPA for a cross-region encryption-key rotation failure. Data model: CAPA {id, incidentId, regions, keyId, artifacts, logsLinks, evidence}; lifecycle: detected→triaged→contained→rootCause→re","explanation":"## Why This Is Asked\nAssesses ability to design CAPA for security-critical cross-region encryption failures, including evidence capture and regulatory considerations.\n\n## Key Concepts\n- CAPA data model capturing evidence and artifacts\n- Region-aware lifecycle with multi-region coordination\n- Minimal REST API for CAPAs with logs and traces\n- Metrics for containment, MTTR, recurrence, false positives\n- RCA templates and canary rollout strategies for secure rotation\n\n## Code Example\n```javascript\ntype CAPA = {\n  id: string;\n  incidentId: string;\n  regions: string[];\n  keyId: string;\n  artifacts: string[];\n  logs: string[];\n  evidenceLinks: string[];\n  status: string;\n  createdAt: string;\n  updatedAt: string;\n};\n```\n\n## Follow-up Questions\n- How would you integrate regulatory reporting and data-retention rules?\n- What monitoring would you add to prevent regression on rotation schedules?","diagram":"flowchart TD\n  DetectIssue[Detect Issue] --> Triage[Triage CAPA]\n  Triage --> Contain[Containment Initiated]\n  Contain --> RCA[Root Cause Analysis]\n  RCA --> Remed[Remediation Deployed]\n  Remed --> Closed[CAPA Closed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","NVIDIA","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T10:40:27.897Z","createdAt":"2026-01-16T10:40:27.897Z"},{"id":"q-2785","question":"In a multi-tenant analytics platform, a schema evolution causes cross-tenant data leakage and inconsistent joins during peak load. Design a CAPA program that mitigates these risks: 1) a CAPA data model capturing evidence and lineage, 2) a cross-tenant lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollout plan with rollback?","answer":"Propose a CAPA blueprint for multi-tenant schema evolution leakage. Data model: capa_id, tenant_id, evidence_uri, artifact_sha, affected_tables, root_cause, containment, remediation, status, timestamp","explanation":"## Why This Is Asked\nWhy this is asked: tests modeling of data-heavy CAPA workflows with tenant isolation and cross-tenant risk containment.\n\n## Key Concepts\n- CAPA data model with evidence lineage\n- Cross-tenant lifecycle and access controls\n- Canary rollout and rollback strategies for schema changes\n\n## Code Example\n```javascript\n// Example CAPA payload (pseudo)\n{\n  \"capa_id\":\"capa-123\",\n  \"tenant_id\":\"tenant-A\",\n  \"evidence_uri\":\"s3://bkt/evidence/123\",\n  \"artifact_sha\":\"abcdef\",\n  \"affected_tables\":[\"events\"],\n  \"root_cause\":\"schema drift during upgrade\",\n  \"containment\":[\"block writes to affected_tables\"],\n  \"remediation\":\"apply patch, reindex\",\n  \"status\":\"PREPARED\",\n  \"timestamps\":{ \"raised\":\"2025-09-01T12:00:00Z\" }\n}\n```\n\n## Follow-up Questions\n- How would you enforce tenant isolation in the API and data access during CAPA progression?\n- How would you validate canary success before global rollout?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Snowflake","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T11:42:22.728Z","createdAt":"2026-01-16T11:42:22.728Z"},{"id":"q-2888","question":"A multi-tenant policy engine used for feature-flag entitlements in a globally distributed SaaS shows inconsistent user permissions after a policy rollout in two regions, causing sporadic authorization errors (429/403) and revenue leakage. Design a CAPA program focused on data-feed integrity and policy-vs-data latency. Include: 1) a CAPA data model, 2) a region-aware lifecycle, 3) a minimal REST API for CAPAs with linked logs, 4) metrics to prove containment, 5) RCA template and a canary rollout plan for policy updates?","answer":"Propose a CAPA with fields: id, incidentId, region, tenantId, policyVersion, evidence (log/trace IDs), state, createdAt, updatedAt, remediation. API: POST/PUT to /capas with evidence links; logs linke","explanation":"## Why This Is Asked\nTests end-to-end CAPA design focusing on data-feed integrity and cross-region policy latency.\n\n## Key Concepts\n- CAPA data model with provenance for logs/traces\n- Region-aware lifecycle and state transitions\n- REST API linking CAPAs to evidence logs/traces\n- Region-aware metrics: MTTR, recurrence, false positives, latency\n- RCA template and canary rollout plan for policy updates\n\n## Code Example\n```javascript\ninterface CAPA {\n  id: string;\n  incidentId: string;\n  region: string;\n  tenantId: string;\n  policyVersion: string;\n  evidence: string[]; // logs/traces\n  state: 'identified'|'investigating'|'contained'|'mitigated'|'closed';\n  createdAt: string;\n  updatedAt: string;\n  remediation?: string;\n}\n```\n\n## Follow-up Questions\n- How would you validate data-feed integrity across regions during rollback?\n- What trade-offs exist between rapid containment and thorough RCA in high-throughput systems?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","NVIDIA","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T16:41:06.450Z","createdAt":"2026-01-16T16:41:06.450Z"},{"id":"q-2912","question":"Scenario: An ML labeling pipeline for ad quality causes bias in two regions after a data source change. Design a CAPA program to detect, contain, and prevent recurrence. Include: 1) a CAPA data model with incident_id, timestamps, regions, data_source, bias_metric, and evidence artifacts; 2) region-aware lifecycle: detected, containment, investigation, remediation, verification, closed; 3) REST API to create/update CAPAs with logs/traces; 4) metrics: bias_delta, MTTR, FP_rate by region; 5) RCA template and a canary remediation plan?","answer":"Implement a CAPA for an ML labeling pipeline bias incident. Data model includes incident_id, timestamps, regions, data_source, bias_metric, and evidence artifacts; lifecycle: detected, containment, in","explanation":"## Why This Is Asked\nAssesses CAPA design for ML bias, data provenance, and cross-region containment in a real product workflow.\n\n## Key Concepts\n- CAPA data model for bias incidents and lineage\n- Region-aware lifecycle and metrics\n- Minimal REST API for CAPA creation/update with evidence\n- RCA templates and canary remediation strategies\n\n## Code Example\n```javascript\n{\n  incident_id: 'INC123',\n  regions: ['us-east-1','eu-west-1'],\n  data_source: 'datasource-A',\n  bias_metric: { type: 'precision_bias', value: 0.08 },\n  evidence: ['logs.zip','trace.json']\n}\n```\n\n## Follow-up Questions\n- How would you enforce immutable data provenance?\n- How would you set thresholds for cross-region drift detection?","diagram":"flowchart TD\n  A[Bias detected] --> B[Evidence capture]\n  B --> C[Containment]\n  C --> D[Root-cause investigation]\n  D --> E[Remediation and verification]\n  E --> F[Closure]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","LinkedIn","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T17:31:51.028Z","createdAt":"2026-01-16T17:31:51.028Z"},{"id":"q-2962","question":"Scenario: A two-region rollout of a new ML-powered recommender model causes drift in user-item interactions and CTR drop within the first hour. Design a CAPA program to prevent recurrence. Include: 1) a CAPA data model capturing evidence and artifacts (drift stats, feature distributions, logs, and model/version with region), 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics (drift decay, MTTR, false positives), 5) an RCA template and a canary-based rollback plan?","answer":"Design a CAPA for ML drift after a two-region rollout of a recommender model. Capture evidence: drift stats, feature distributions, logs, and model/version with region tags. Lifecycle: detect → triage","explanation":"## Why This Is Asked\nTests ability to handle production ML incidents and governance beyond basic infra issues, emphasizing data-driven CAPA tracing and regional controls.\n\n## Key Concepts\n- CAPA data models for ML drift artifacts\n- Lifecycle gating with detection, triage, containment, remediation, verification, and closure\n- REST API design linking CAPA records to logs/traces and model artifacts\n- Region-aware metrics for containment and false positives\n\n## Code Example\n```javascript\n// Example: CAPA creation payload (pseudo)\n{\n  id: 'capa-123',\n  region: 'us-east-1',\n  modelVersion: 'v1.3.2',\n  evidence: {\n    driftStats: {},\n    featureDistributions: {},\n    logsRef: 'log-id-xyz'\n  },\n  status: 'detect'\n}\n```\n\n## Follow-up Questions\n- How would you automate thresholding for drift signals?\n- How would you validate the effectiveness of the canary rollback?","diagram":"flowchart TD\n  Detect[Drift Detected] --> Triage[Triage CAPA]\n  Triage --> Contain[Contain Issue]\n  Contain --> Remediate[Remediate Model]\n  Remediate --> Verify[Verify Metrics]\n  Verify --> Close[Close CAPA]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Apple","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T19:25:59.333Z","createdAt":"2026-01-16T19:25:59.334Z"},{"id":"q-3157","question":"Scenario: A cross-tenant data-sharing microservice was extended to support dynamic data scoping, and a release leaked data across two regions. Design a CAPA program to detect, triage, and prevent recurrence. Include: 1) a CAPA data model, 2) a region-aware lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-level metrics proving containment and recurrence, 5) an RCA template and a canary rollout plan for the data-scoping change?","answer":"Design a CAPA program for cross-tenant data leakage in a shared microservice across two regions. Data model: CAPA { id, region, service, evidenceLinks, artifacts, severity, status, lifecycle, rootCaus","explanation":"## Why This Is Asked\nTests ability to model CAPA data, design scalable regional state machines, and tie incidents to concrete metrics and RCA.\n\n## Key Concepts\n- CAPA data model, region-aware lifecycle, API design, region metrics, RCA templates, canary strategies.\n- Trade-offs: data privacy, auditability, latency vs safety.\n\n## Code Example\n```javascript\n// Example CAPA interface (TypeScript)\ninterface CAPA {\n  id: string\n  region: string\n  service: string\n  evidenceLinks: string[]\n  artifacts: string[]\n  severity: 'low'|'medium'|'high'\n  status: string\n  lifecycle: string[]\n  rootCause?: string\n  remediation?: string\n}\n```\n\n## Follow-up Questions\n- How would you enforce policy as code for data-scoping changes?\n- How would you automate RCA template population from logs and traces?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","DoorDash","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T04:52:57.380Z","createdAt":"2026-01-17T04:52:57.380Z"},{"id":"q-3177","question":"Scenario: An ML inference service deployed globally leaks user features after a feature-store refresh and model rollback. Design a CAPA program to detect, capture evidence, contain the leak, and prevent recurrence. Include: 1) a CAPA data model capturing evidence, artifacts, and model/feature lineage, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region- and data-class metrics (containment time, false negatives, drift delta), 5) an RCA template and a canary-based remediation plan (retrain on a subset, gated rollout, rollback if KPI fail)?","answer":"Design a CAPA for an ML inference service with regional leakage after a feature-store refresh. Include: 1) CAPA data model: capa_id, model_id, version, feature_store_snapshot, evidence_links, region, ","explanation":"## Why This Is Asked\nTests ability to design a CAPA system around ML model leakage, emphasizing traceability, cross-region governance, and safe remediation.\n\n## Key Concepts\n- CAPA data modeling for ML artifacts and lineage\n- Region-aware lifecycle and event-driven triggers\n- REST API design for evidence-linked CAPAs\n- Metrics for containment, drift, and leakage\n- RCA templates and canary-based risk mitigation\n\n## Code Example\n```javascript\n// Example CAPA payload (POST /caps)\n{\n  id: \"CAPA-2026-ML-01\",\n  model_id: \"m-1234\",\n  version: \"v2.1.3\",\n  feature_store_snapshot: \"fs-20260101\",\n  evidence_links: [\"log:http://..\", \"trace:trx-789\"],\n  region: \"us-west-2\",\n  timestamps: { created: \"2026-01-01T12:00:00Z\" },\n  root_causes: [\"feature leakage\", \"rollback bug\"]\n}\n```\n\n## Follow-up Questions\n- How would you test the canary remediation before full rollout?\n- What privacy constraints influence CAPA data retention and auditing?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:38:42.145Z","createdAt":"2026-01-17T05:38:42.146Z"},{"id":"q-3287","question":"In a real-time feature-store pipeline, a schema evolution causes feature drift and model drift across regions, impacting revenue. Design a CAPA program with: 1) a CAPA data model capturing evidence and artifacts, 2) a region-aware lifecycle, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) region metrics (driftScore, featureAge, MTTR, FP rate), 5) an RCA template and a canary rollout plan for schema changes?","answer":"Create a CAPA that tracks drift and schema diffs tied to a central registry and feature-store versions. Core: (a) data model for evidence, diffs, tests; (b) region-aware lifecycle; (c) REST API to att","explanation":"## Why This Is Asked\n\nThis question probes end-to-end CAPA design for drift in a global, latency-sensitive feature-store, including data modeling, lifecycle, API surfaces, metrics, and rollback strategy.\n\n## Key Concepts\n\n- Schema evolution and drift detection\n- Region-aware containment and MTTR\n- Evidence collection and artifact stores\n- Canary-driven rollout for changes\n\n## Code Example\n\n```javascript\n// Sketch: CAPA data model (pseudo)\nconst CAPA = {\n  id: String,\n  region: String,\n  evidence: [{type:String, payload:Buffer, timestamp:Date}],\n  artifacts: [{type:String, location:String}],\n  state: 'detected'|'triaged'|'mitigated'|'verified',\n  driftScores: {[feature:String]: Number}\n}\n```\n\n## Follow-up Questions\n\n- How would you tune drift thresholds across regions?\n- What tests verify canary rollouts before global deployment?","diagram":"flowchart TD\n  Detect[Drift Detected] --> Triage[Triaged]\n  Triage --> Mitigate[Mitigate & Canary]\n  Mitigate --> Verify[Containment Verified]\n  Verify --> Complete[CAPA Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Netflix","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T10:29:37.606Z","createdAt":"2026-01-17T10:29:37.606Z"},{"id":"q-3333","question":"Scenario: A real-time fraud-detection service shows a surge in false positives after a deployment across three regions. Design a CAPA program focusing on model and data drift. Include: 1) a CAPA data model capturing evidence, signals, and data lineage; 2) a lifecycle state machine for CAPA progression; 3) a minimal REST API to create/update CAPAs with logs/traces; 4) region-aware metrics (precision, recall, F1, drift_score, MTTR); 5) RCA template and a canary retraining/feature rollout plan?","answer":"The CAPA should define a data model with id, region, trigger, evidence, logs, drift_score, metrics snapshot, and lineage. Use a state machine: open -> triaged -> investigating -> contained -> remediat","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for ML-driven, multi-region systems, emphasizing drift handling, evidence capture, state management, and safe remediation.\n\n## Key Concepts\n- CAPA data model with evidence, lineage, and drift metrics\n- Drift detection signals and region-aware metrics\n- Lifecycle/state machines and minimal API design\n- RCA templates and canary rollout strategies\n\n## Code Example\n```javascript\n// Example CAPA data model\nconst CAPA = {\n  id: \"CAPA-123\",\n  region: \"us-central1\",\n  trigger: \"model_drift\",\n  evidence: [\"log1\", \"log2\"],\n  metrics: { precision: 0.82, recall: 0.65, drift_score: 0.72, mttr: 3600 },\n  state: \"open\",\n  lineage: { dataset: \"transactions_v2\", model: \"fraud_v3\" }\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA API under high throughput?\n- Which drift detection techniques would you choose and why?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Goldman Sachs","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T11:39:54.708Z","createdAt":"2026-01-17T11:39:54.709Z"},{"id":"q-3541","question":"In a multi-tenant data platform used by Zoom and Databricks, a sudden ingestion spike from one tenant causes backpressure that delays processing for others across regions. Design a CAPA program to detect, capture evidence, contain, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API for CAPAs with linked logs and traces, 4) tenant-/region-aware metrics (backlog depth, MTTR, recurrence rate), 5) RCA template and a canary rollback plan for throttle-based remediation?","answer":"Adopt a CAPA data model with tables CAPA, Evidence, Artifact keyed by tenant_id/region. Implement a state machine: DETECTED → ANALYZING → CONTAINMENT → INVESTIGATION → REMEDIATION → VERIFIED → CLOSED.","explanation":"## Why This Is Asked\n\nAssesses capability to design scalable, tenant-aware CAPA for a shared data platform, balancing fairness and speed while ensuring traceability.\n\n## Key Concepts\n\n- Multi-tenant isolation and backpressure control\n- Evidence collection and artifact management\n- Lifecycle state machine design\n- REST API design for CAPA with logs/traces\n- Tenant/region metrics and RCA structuring\n- Canary rollout and rollback strategies\n\n## Code Example\n\n```javascript\ninterface CAPA {\n  id: string;\n  tenantId: string;\n  region: string;\n  onset: string;\n  status: string;\n  logs: string[];\n}\n```\n\n## Follow-up Questions\n\n- How would you store and query cross-tenant artifacts at scale?\n- What tests would validate canary safety under burst traffic?","diagram":"flowchart TD\nA[Detected] --> B[Analyzing]\nB --> C[Containment]\nC --> D[Investigation]\nD --> E[Remediation]\nE --> F[Verified]\nF --> G[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T20:39:51.992Z","createdAt":"2026-01-17T20:39:51.993Z"},{"id":"q-3568","question":"Scenario: A data ingestion pipeline across two regions experiences data skew during the daily batch window, causing delayed events and stale dashboards. Design a beginner CAPA to address this. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with evidence, 4) region-aware metrics to prove containment and time-to-containment, 5) an RCA template and a canary-based remediation plan?","answer":"Proposed CAPA data model: id, title, region, evidence, rootCause, correctiveActions, preventiveActions, status, timestamps. Lifecycle: detected → triaged → rootCause → remediation → verified → closed.","explanation":"## Why This Is Asked\nTests the ability to craft a cross-region CAPA for ingestion skew; introduces a new angle not covered by existing questions.\n\n## Key Concepts\n- CAPA data model fields\n- State machine lifecycle\n- Lightweight REST API\n- Region-aware metrics\n- RCA template and canary remediation\n\n## Code Example\n```javascript\n// Minimal CAPA schema (illustrative)\nconst CAPASchema = {\n  id: 'string',\n  title: 'string',\n  region: 'string',\n  evidence: ['string'],\n  rootCause: 'string',\n  correctiveActions: ['string'],\n  preventiveActions: ['string'],\n  status: 'string',\n  timestamps: 'object',\n};\n```","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Netflix","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:43:54.642Z","createdAt":"2026-01-17T21:35:49.260Z"},{"id":"q-3616","question":"Scenario: After a feature-store schema evolution, a real-time fraud-detection model begins misclassifying events, causing elevated false positives in two regions. Design a CAPA program to address this: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove effectiveness (precision, recall drift, MTTR, false-positive rate), 5) an RCA template and a canary rollout plan for feature window validation and model rollback?","answer":"I propose a comprehensive CAPA program featuring a robust data model that captures incidentId, featureStoreVersion, modelVersion, affectedRegions, evidenceLinks, and traces to logs. The lifecycle follows: detected → triaged → containment → investigation → remediation → validation → closed. This includes a minimal REST API for CAPA creation and updates with linked logs and traces, region-aware metrics (precision, recall drift, MTTR, false-positive rate), an RCA template, and a canary rollout plan for feature window validation and model rollback.","explanation":"## Why This Is Asked\n\nThis tests robust containment and ML-driven CAPAs in data pipelines, focusing on schema-change impact, cross-region metrics, and auditable artifacts.\n\n## Key Concepts\n\n- CAPA data modeling for ML incidents\n- Region-aware metrics and drift detection\n- Canary-style rollout and rollback for feature windows\n- Traceability with logs/traces and model registry\n\n## Code Example\n\n```javascript\n// Example payload structure for CAPA API\nconst payload = { incidentId, featureStoreVersion, modelVersion, regions, evidenceLinks, traces };\n```\n\n## Follow-up Questions\n\n- How would you auto-generate CAPAs from drift alerts?\n- What triggers rollback vs. progressive canary expansion?\n- How do you ensure evidence immutability across regions?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Databricks","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:14:41.669Z","createdAt":"2026-01-17T23:39:11.351Z"},{"id":"q-3687","question":"In a multi-region Databricks lakehouse, a misconfigured data-classification rule briefly exposes PII in two regions. Design a beginner CAPA to prevent recurrence. Include: 1) a CAPA data model to capture evidence, root cause, corrective and preventive actions, 2) a simple lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/evidence, 4) region-aware containment metrics, 5) an RCA template and a canary-based remediation plan before full rollout?","answer":"Propose a CAPA: a data model with id, region, evidenceLinks, rootCause, correctiveActions, preventiveActions, metrics, state, timestamps; lifecycle Detected->Investigating->Containment->Remediation->V","explanation":"## Why This Is Asked\nTests practical CAPA design for data governance in multi-region data stacks.\n\n## Key Concepts\n- Data governance CAPA model\n- State machine lifecycle\n- Lightweight API design\n- Region-aware metrics and RCA\n- Canary risk mitigation\n\n## Code Example\n```javascript\n// Skeleton REST handler Mock\n```\n\n## Follow-up Questions\n- How would you test the canary reliably?\n- How to version CAPA templates for audits?","diagram":"flowchart TD\nA[Detected exposure] --> B[Containment]\nB --> C[RCA]\nC --> D[Corrective Action]\nD --> E[Verified]\nE --> F[Canary Rollout]\nF --> G[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:37:32.986Z","createdAt":"2026-01-18T05:37:32.986Z"},{"id":"q-3780","question":"Scenario: An identity service misrouting leads to token leakage under load, exposing user data in two regions. Design a CAPA program that addresses security risk at scale. Deliverables: 1) a CAPA data model capturing evidence, tenants, and config changes, 2) a region-aware lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) metrics for containment (leakage_rate, MTTR, recurrence, false_positives), 5) an RCA template and a canary rollout plan to validate remediation before global rollout, including key-rotation strategy?","answer":"Propose: 1) CAPA data model: incident_id, region, tenants, evidence (logs/traces), RCA, remediation, status; 2) lifecycle: detected → triaged → containment → remediation → verify → closed; 3) REST API","explanation":"## Why This Is Asked\nTests ability to design CAPA for security incidents in globally distributed services, emphasizing evidence management, lifecycle rigor, and measurable containment.\n\n## Key Concepts\n- Region-aware CAPA data model with audit-ready evidence\n- Immutable, linked logs/traces for traceability\n- Canary-driven remediation and safe key/token rotation\n- Production-scale metrics: leakage_rate, MTTR, recurrence, false_positives\n- RCA templating for repeatable learning\n\n## Code Example\n```javascript\n// Example CAPA data structure (simplified)\n{\n  incident_id: 'INC-202601',\n  region: 'us-east-1',\n  tenants: ['t1','t2'],\n  evidence: ['logs/abc', 'traces/xyz'],\n  rca: '',\n  remediation: '',\n  status: 'detected'\n}\n```\n\n## Follow-up Questions\n- How would you ensure PII remains protected in CAPA evidence?\n- How would you scale the REST API for millions of CAPAs and high write throughput?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","OpenAI","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T09:33:03.503Z","createdAt":"2026-01-18T09:33:03.504Z"},{"id":"q-3822","question":"Scenario: A multi-tenant AI model hosting platform uncovers cross-tenant data leakage after a deployment that altered data partitioning. Design a CAPA program to detect, capture evidence, and prevent recurrence. Include: 1) a CAPA data model for evidence, lineage, and remediation; 2) a tenant-aware lifecycle; 3) a minimal REST API to create/update CAPAs with linked logs; 4) tenant-scoped metrics (leak rate, time-to-detection, MTTR); 5) RCA template and canary rollback plan targeting partitioning code?","answer":"I would implement a CAPA program for cross-tenant data leakage in a multi-tenant AI hosting platform. CAPA data model includes CAPA, Evidence, DataLineage, Tenant, Incident, Remediation; lifecycle: de","explanation":"## Why This Is Asked\nThis question probes end-to-end CAPA design under data-privacy risk in multi-tenant systems, including lineage, access control, and rollbacks.\n\n## Key Concepts\n- Data lineage and evidence aggregation across tenants\n- Tenant-aware lifecycle and RBAC implications\n- Canary-based remediation and RCA framing\n\n## Code Example\n```javascript\n// Example CAPA schema (simplified)\ntype CAPA = {\n  id: string\n  tenantId: string\n  incidentId: string\n  evidenceRefs: string[]\n  dataLineage: string\n  status: 'detected'|'triaged'|'contained'|'remediated'|'verified'|'closed'\n  createdAt: string\n  updatedAt: string\n}\n```\n\n## Follow-up Questions\n- How would you simulate data leakage to validate the CAPA workflow without exposing real data?\n- What additional metrics would you add for regulatory compliance reporting?","diagram":"flowchart TD\n  A[Leak detected] --> B[Create CAPA]\n  B --> C[Containment]\n  C --> D[Remediation]\n  D --> E[Verification]\n  E --> F[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T10:45:31.504Z","createdAt":"2026-01-18T10:45:31.504Z"},{"id":"q-3869","question":"Scenario: In a multi-tenant data platform used by enterprise customers, an ingestion job drift triggers potential exposure of PII across two regions due to a schema evolution. Design a CAPA program focused on privacy and regulatory compliance: 1) a CAPA data model capturing privacy artifacts (PII fields, masking rules, data lineage, access controls), 2) a region-aware lifecycle state machine (discovery, containment, remediation, verification, closure), 3) a minimal REST API to create/update CAPAs with linked logs and lineage, 4) privacy metrics (time-to-containment for sensitive data drift, PIIs discovered, false positives), 5) an RCA template and a canary plan to validate masking and access controls before global rollout?","answer":"CAPA data model: CAPA, Evidence, PrivacyArtifact (PII fields, maskingRule, dataLineage), AccessControl, DataSubjectMetric. Lifecycle: discovery -> containment -> remediation -> verification -> closure","explanation":"## Why This Is Asked\nTests ability to design privacy-aware CAPA in a data platform, measure regulatory impact, and ship safe canaries. It exercises data lineage, masking, access control, and cross-region governance.\n\n## Key Concepts\n- Privacy-by-design CAPA, data lineage, masking rules, and access controls\n- Regulatory compliance considerations (GDPR/CCPA)\n- Cross-region data governance and canary testing for masking\n\n## Code Example\n```javascript\n// Example CAPA schema fragment\nconst CAPA_SCHEMA = {\n  id: 'string',\n  privacyArtifacts: {\n    piiFields: ['customer_email', 'ssn'],\n    maskingRule: 'partial_mask',\n    dataLineage: 'path/to/lineage'\n  },\n  lifecycle: ['discovery','containment','remediation','verification','closure'],\n  metrics: { timeToContainmentMs: 1234 }\n}\n```\n\n## Follow-up Questions\n- How would you automate drift detection of PII fields in logs across regions?\n- What trade-offs exist between masking depth and query performance when auditing large datasets?","diagram":"flowchart TD\n  A[Detection] --> B{Containment}\n  B --> C[Evidence Collection]\n  C --> D[Investigation]\n  D --> E[Remediation]\n  E --> F[Validation]\n  F --> G[Closure]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T13:08:50.072Z","createdAt":"2026-01-18T13:08:50.072Z"},{"id":"q-3952","question":"Scenario: A globally deployed fraud-detection ML model starts showing elevated false positives in two regions after a retrain. Design a CAPA program to detect model drift, contain impact, and prevent recurrence. Include: 1) a CAPA data model capturing evidence (drift metrics, feature distributions, FP rate by region, logs, dataset snapshots) and artifacts (model version, data lineage), 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked traces, 4) region-aware metrics proving containment (drift score, FP rate, MTTR), 5) RCA template and a canary-based remediation plan (retrain with backfill, rollback, feature-store checks)?","answer":"Outline a CAPA for ML drift: 1) CAPA data model storing evidence (drift metrics, feature distributions, FP rate by region, logs, dataset snapshots) and artifacts (model version, data lineage), 2) life","explanation":"## Why This Is Asked\nTests ability to design CAPA for ML drift across regions, integrating data lineage, artifacts, API design, and remediation strategies.\n\n## Key Concepts\n- ML drift detection and regional observability\n- CAPA data model and lifecycle\n- Canary-based remediation and rollback\n\n## Code Example\n```javascript\n// Payload shape (illustrative)\nconst payload = {\n  capaId: 'CAPA-123',\n  evidence: { drift: { score: 0.42 }, fpRateByRegion: { US: 0.03, EU: 0.05 } },\n  modelVersion: 'v1.2.3',\n  state: 'open'\n}\n```\n\n## Follow-up Questions\n- How would you set drift thresholds and alerting? \n- How would you validate a rollback without regressing customers?","diagram":"flowchart TD\n  A[Ingest] --> B[Drift detected]\n  B --> C[CAPA Open]\n  C --> D[Containment]\n  D --> E[Remediate]\n  E --> F[Verification]\n  F --> G[Closed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Hashicorp","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T16:47:15.688Z","createdAt":"2026-01-18T16:47:15.688Z"},{"id":"q-4036","question":"Scenario: A cross-region ML content-safety classifier drift after a rollout causes increased unsafe-content passes in Region A while Region B remains fine. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model; 2) a region-aware lifecycle; 3) a minimal REST API to create/update CAPAs with evidence; 4) region-based metrics to prove containment; 5) RCA template and a canary/rollback plan?","answer":"Design a comprehensive CAPA program for cross-region ML content-safety classifier drift. Data model: CAPA(id, incident_id, region, model_name, version, evidence:[logs,traces,metrics], state, created_at, updated_at, owner). Region-aware lifecycle: detection → evidence collection → containment → RCA → remediation → verification → closure, with region-specific state tracking and cross-region coordination. Minimal REST API: POST /capas (create), PUT /capas/{id} (update), GET /capas/{id}/evidence, POST /capas/{id}/evidence, with region-based filtering and evidence attachment support. Region-based metrics: containment_rate, false_positive_rate, model_drift_score, latency_p99 per region, with trend analysis and alerting thresholds. RCA template: incident timeline, affected regions, drift analysis, root causes, containment actions, preventive measures, lessons learned. Canary/rollback plan: gradual traffic shifting (5% → 25% → 50% → 100%), automated monitoring with rollback triggers, region-specific canary groups, and blue-green deployment fallback.","explanation":"## Why This Is Asked\nTests ability to design a scalable, region-aware CAPA program for ML incidents with comprehensive evidence capture and controlled deployment strategies.\n\n## Key Concepts\n- CAPA data modeling for ML incidents with cross-region coordination\n- Region-aware lifecycle management with state tracking\n- Evidence collection from logs, traces, and metrics\n- Canary rollout strategy with automated rollback triggers\n- RCA documentation with preventive action planning\n- Region-specific metrics and containment verification\n\n## Code Example\n```javascript\n// CAPA schema with region awareness\nconst CAPASchema = {\n  id: 'uuid',\n  incident_id: 'string',\n  region: 'string',\n  model_name: 'string',\n  version: 'string',\n  evidence: ['logs', 'traces', 'metrics'],\n  state: 'enum',\n  created_at: 'timestamp',\n  updated_at: 'timestamp',\n  owner: 'string'\n};\n```","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Hugging Face","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T06:22:17.910Z","createdAt":"2026-01-18T20:47:03.888Z"},{"id":"q-4140","question":"Scenario: A multi-region EV telemetry pipeline relies on a third‑party enrichment service. An outage causes inconsistent vehicle trip durations and location matching in Regions North and East. Design a CAPA program that covers: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for cross‑vendor CAPAs, 3) a minimal REST API to create/update CAPAs with logs/traces and vendor links, 4) region-aware metrics to prove containment (recurrence rate, MTTR, false positive rate), 5) an RCA template and a canary rollback plan for vendor changes?","answer":"CAPA data model includes id, incidentId, region, vendor, dataSource, evidence, traces, rca, remediation, status, timestamps. Lifecycle: detected → triaged → containment → remediation → validated → clo","explanation":"## Why This Is Asked\nTests cross‑vendor CAPA governance, multi‑region data quality, and evidence‑driven remediation beyond basic incident handling.\n\n## Key Concepts\n- Cross‑vendor data quality\n- Region‑aware containment\n- Evidence‑driven CAPA data model\n- Canary rollback with supplier changes\n\n## Code Example\n```javascript\n// Minimal CAPA data model sketch\nconst CAPA = {\n  id: '',\n  incidentId: '',\n  region: '',\n  vendor: '',\n  dataSource: '',\n  evidence: [],\n  traces: [],\n  rca: '',\n  remediation: '',\n  status: 'detected',\n  createdAt: '',\n  updatedAt: ''\n};\n```\n\n## Follow-up Questions\n- How would you test the API and the metrics? \n- What privacy considerations apply to evidence logs in a multi‑vendor setup?","diagram":"flowchart TD\n  A[Incident] --> B[CAPA Created]\n  B --> C[Containment Initiated]\n  C --> D[Remediation Applied]\n  D --> E[Validation]\n  E --> F[Closed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T04:41:50.036Z","createdAt":"2026-01-19T04:41:50.036Z"},{"id":"q-4187","question":"Scenario: A dynamic ride-pricing model experiences unexplained underpricing after a feature-store schema evolution, leading to regional revenue drop. Design a CAPA program to detect drift, collect evidence (model version, feature lineage, data distributions, logs), and prevent recurrence. Include: 1) a CAPA data model, 2) a region-aware lifecycle, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) drift-aware metrics to prove containment (drift rate, MTTR, FP rate), 5) an RCA template and a canary remediation plan (rollback to prior feature/version, retraining)?","answer":"Propose a CAPA: data model with model_id, region, schema_version, feature_version, evidence_refs, containment_status. Lifecycle: detected → investigated → contained → eradicated → verified. API: POST/","explanation":"## Why This Is Asked\n\nEvaluates end-to-end CAPA design for ML pricing with data lineage across regions, including containment and rollback viability.\n\n## Key Concepts\n\n- ML drift detection and measurement\n- Data provenance and feature lineage\n- Region-aware canary remediation and metrics\n- Root-cause analysis templates\n\n## Code Example\n\n```json\n{\n  \"model_id\": \"pricing_v3\",\n  \"region\": \"us-east-1\",\n  \"schema_version\": \"2026-01-19\",\n  \"feature_version\": \"fv4\",\n  \"evidence_refs\": [\"log-789\",\"trace-101112\"],\n  \"containment_status\": \"detected\"\n}\n```\n\n## Follow-up Questions\n\n- How would you automate data-lineage capture across the feature store?\n- What drift thresholds would you use and how would you validate canaries?","diagram":"flowchart TD\n  Detect[Detect drift] --> Investigate[Investigate evidence]\n  Investigate --> Contain[Containment]\n  Contain --> RCA[Root cause + RCA]\n  RCA --> Canary[Canary remediation]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Lyft","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T07:03:16.575Z","createdAt":"2026-01-19T07:03:16.576Z"},{"id":"q-4302","question":"In a real-time model serving pipeline for a high-frequency trading platform, a schema evolution in the feature store causes online scores to be computed with mismatched features across three regions, leading to incorrect risk estimates. Design a CAPA program to address this: 1) a CAPA data model capturing evidence and artifacts, 2) a region-aware lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) region/feature-type metrics to prove containment and avoid recurrence, 5) an RCA template and a canary-based rollback plan for feature changes?","answer":"Propose a versioned CAPA data model capturing CAPA metadata, evidence references, and a region-to-feature-map; implement a region-aware lifecycle with states: identified, contained, investigated, reme","explanation":"## Why This Is Asked\n\nThis question probes end-to-end CAPA design under real-time drift in a multi-region ML workflow, focusing on data models, lifecycle, APIs, metrics, RCA, and canary rollout.\n\n## Key Concepts\n\n- CAPA data modeling\n- region-aware lifecycle\n- evidence/logs integration\n- region-feature metrics\n- RCA templates and canary plans\n\n## Code Example\n\n```javascript\n// Minimal CAPA data model snippet\ntype CAPA = {\n  id: string;\n  region: string;\n  status: string;\n  evidenceRefs: string[];\n  artifacts: string[];\n  createdAt: string;\n  updatedAt: string;\n}\n```\n\n## Follow-up Questions\n\n- How would you version CAPA data models and migrations?\n- How do you ensure canary rollouts remain drift-free across regions?\n","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Hugging Face","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T13:07:33.885Z","createdAt":"2026-01-19T13:07:33.885Z"},{"id":"q-4434","question":"Scenario: In a multi-tenant data lake used by a regulated enterprise, one tenant's ingestion triggers data skew that contaminates downstream analytics while costing spikes. Design a CAPA program focusing on tenant isolation, data provenance, and cost control. Include: 1) a CAPA data model capturing evidence and artifacts, 2) a tenant-scoped lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant-aware metrics to prove containment and recurrence, 5) an RCA template and a safe rollback plan for data ingestion changes. What would you implement and why?","answer":"I would implement a CAPA with 1) a data model: capA_id, tenant_id, incident_id, evidence_links, logs_traces, affected_tables, feature_versions, severity, status; 2) lifecycle: new -> investigating -> ","explanation":"## Why This Is Asked\nTests ability to handle CAPA at multi-tenant scale with data provenance, cost control, and isolation. Requires concrete data model, lifecycle, API surface, and measurable metrics.\n\n## Key Concepts\n- Data provenance and lineage\n- Tenant isolation vs shared infra\n- Cost-aware remediation\n- Lifecycle state machine\n- REST API design and observability\n\n## Code Example\n```javascript\ntype CAPA = {\n  capa_id:string;\n  tenant_id:string;\n  incident_id:string;\n  evidence_links:string[];\n  logs_traces:string[];\n  affected_tables:string[];\n  feature_versions:string[];\n  severity:string;\n  status:'new'|'investigating'|'containment'|'RCA'|'remediation'|'closed';\n}\n```\n\n## Follow-up Questions\n- How would you validate the canary rollback in prod?\n- What trade-offs exist between strict tenant isolation and operational complexity?","diagram":"flowchart TD\n  A[New CAPA] --> B[Investigating]\n  B --> C[Containment]\n  C --> D[RCA]\n  D --> E[Remediation]\n  E --> F[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","LinkedIn","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T18:56:03.798Z","createdAt":"2026-01-19T18:56:03.798Z"},{"id":"q-4526","question":"In a cross-region data-aggregation pipeline for fraud detection, a misconfigured regional join flag breaks data lineage and risks PII exposure in one region. Design a CAPA program with: 1) a CAPA data model for evidence and artifacts, 2) a cross-region lifecycle state machine, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) region-specific privacy metrics (lineage completeness, PII access, MTTR), 5) an RCA template and a canary rollout plan for flag changes?","answer":"Design a comprehensive CAPA program with: 1) A structured data model capturing evidence, artifacts, and metadata with region-specific context; 2) A cross-region lifecycle state machine managing phases from IDENTIFIED → INVESTIGATING → CONTAINMENT → RESOLVED → CLOSED with escalation triggers; 3) REST API endpoints (POST /capas, PUT /capas/{id}) integrating logging, tracing, and audit trails; 4) Region-specific privacy metrics including lineage completeness scores, PII access patterns, and mean-time-to-resolution; 5) RCA template framework and canary rollout strategy with rollback criteria for flag configuration changes.","explanation":"## Why This Is Asked\nThe scenario evaluates end-to-end CAPA thinking spanning privacy engineering, data lineage management, cross-region coordination, and controlled remediation practices.\n\n## Key Concepts\n- CAPA data model with evidence/artifacts correlation\n- Cross-region lifecycle with state transitions\n- Privacy metrics and compliance tracking\n- Canary deployment and rollback mechanisms\n\n## Code Example\n```javascript\nconst CAPA = {\n  id: '',\n  region: '',\n  symptom: '',\n  evidence: [],\n  artifacts: [],\n  state: 'IDENTIFIED',\n  correlationId: ''\n}\n```\n\n## Follow-up Questions\n- What specific rollback triggers would you implement for flag changes?\n- How would you measure and report privacy metrics across regions?\n- What monitoring capabilities would ensure early detection of similar issues?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T06:54:20.040Z","createdAt":"2026-01-19T22:38:03.753Z"},{"id":"q-4601","question":"Scenario: In a fleet of autonomous vehicles operating across multiple regions, a recently rolled OTA firmware update causes sporadic misdetections in sensor fusion, leading to unsafe behavior in Region A and Region B. Design a CAPA program to detect, contain, and prevent recurrence. Include: 1) a CAPA data model capturing evidence, telemetry, firmware/OTA versions, and logs; 2) a region-aware lifecycle state machine for CAPA progression; 3) a minimal REST API to create/update CAPAs with linked logs/traces; 4) region- and sensor-type metrics to prove containment (recurrence rate, MTTR, false positives, drift); 5) an RCA template and a staged canary rollout plan for firmware/feature changes?","answer":"Propose a CAPA plan that includes: 1) a CAPA data model mapping evidence to telemetry, logs, and OTA versions; 2) a regional lifecycle state machine (Triaged → Contained → Investigating → Remediated →","explanation":"## Why This Is Asked\nTests ability to design end-to-end CAPA, including data models, state management, and safety-conscious rollout in a high-stakes, multi-region domain.\n\n## Key Concepts\n- CAPA data modeling and evidence linking\n- Region-aware lifecycle and escalation\n- Lightweight API for CAPA CRUD with traces\n- Metrics for containment and recurrence\n- RCA templates and canary rollout strategies\n\n## Code Example\n```javascript\n// Minimal Express endpoint sketch\nconst express = require('express');\nconst app = express();\napp.use(express.json());\napp.post('/capa', (req, res) => {\n  // validate and persist CAPA with linked traces\n  res.status(201).send({ id: 'capa-123' });\n});\n```\n\n## Follow-up Questions\n- How would you model data retention for CAPA artifacts across regions?\n- How would you audit changes to CAPAs and ensure traceability?","diagram":"flowchart TD\n  CAPA[CAPA] --> DM[Data Model]\n  CAPA --> LS[Lifecycle State Machine]\n  CAPA --> API[REST API]\n  CAPA --> M[Metrics & RCA]\n  API --> TR[Linked Logs/Traces]\n  M --> Canary[Canary Rollout Plan]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T04:13:43.645Z","createdAt":"2026-01-20T04:13:43.646Z"},{"id":"q-4722","question":"Scenario: After a deployment, a misconfigured ETL sink writes PII to a non-prod data lake in Region-2, triggering a data-governance alert. Design a CAPA program to detect, contain, and prevent recurrence. Include: 1) a CAPA data model with evidence, lineage, and owners; 2) a region-aware lifecycle with gates; 3) a minimal REST API to create/update CAPAs with logs/traces and lineage links; 4) region metrics for containment and leakage; 5) an RCA template and a canary rollback plan for sink changes?","answer":"CAPA data model with capa_id, incident_time, data_class, evidence_refs, lineage, owner, remediation, status, RCA_id. Lifecycle: IDENTIFY → CONTAIN → INVESTIGATE → REMEDIATE → VERIFY → CLOSED with gate","explanation":"## Why This Is Asked\nTests ability to design a CAPA program around data governance, cross-region containment, and traceability after a data-leak fault in a deployment.\n\n## Key Concepts\n- Data lineage and evidence tagging\n- Region-aware CAPA lifecycle gates\n- REST API design for CAPA management with linked logs/traces\n- Regional leakage metrics and false positive handling\n- RCA templates and canary rollback for data sinks\n\n## Code Example\n```javascript\n// Minimal CAPA data model in TypeScript\ntype CAPA = {\n  capa_id: string;\n  incident_time: string;\n  data_class: string;\n  evidence_refs: string[];\n  lineage: string;\n  owner: string;\n  remediation: string;\n  status: 'IDENTIFY'|'CONTAIN'|'INVESTIGATE'|'REMEDIATE'|'VERIFY'|'CLOSED';\n  RCA_id?: string;\n}\n```\n\n## Follow-up Questions\n- How would you integrate with an existing audit log system?\n- How would you enforce access controls for CAPA modification?","diagram":"flowchart TD\n  A[Detect PII Leak] --> B[Contain & Quarantine Sink]\n  B --> C[Trace Lineage & Gather Evidence]\n  C --> D[Root Cause Analysis]\n  D --> E[Remediate Sink & Canaries]\n  E --> F[Verify & Close]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T09:56:19.580Z","createdAt":"2026-01-20T09:56:19.580Z"},{"id":"q-4750","question":"Scenario: A multi-tenant streaming platform experiences sudden, per-tenant drift in sessionization in Region-2, causing incorrect churn metrics for several tenants. Design a CAPA program that addresses drift without impacting others. Include: 1) a CAPA data model capturing tenant scope, evidence, and lineage; 2) a region-tenant gated lifecycle; 3) a minimal REST API to create/update CAPAs with linked logs/traces; 4) tenant-scoped metrics to prove containment and recurrence; 5) an RCA template and a canary rollout plan for the sessionization logic updates?","answer":"Propose a CAPA with a data model: fields for id, tenant_id, region, evidence_links, candidate_root_cause, containment_actions, owners, timing. Lifecycle: DETECT -> CONTAIN -> ERADICATE -> VALIDATE -> ","explanation":"## Why This Is Asked\nTests handling of drift in a multi-tenant streaming system with region isolation, ensuring containment without collateral impact. It also probes data lineage, governance, and rollout discipline.\n\n## Key Concepts\n- CAPA data model with tenant scope, region, evidence, ownership, and lineage\n- Region-tenant gated lifecycle to prevent cross-tenant bleed\n- Minimal REST API for CAPA creation/update with linked logs/traces\n- Tenant-scoped metrics: containment MTTR, drift score, recurrence rate, false positives\n- RCA template and canary rollback plan for sessionization logic changes\n\n## Code Example\n```javascript\n// Skeleton: CAPA data model (conceptual)\nclass CAPA {\n  constructor(id, tenantId, region) {\n    this.id = id;\n    this.tenantId = tenantId;\n    this.region = region;\n    this.evidence = [];\n    this.rootCause = null;\n    this.actions = [];\n    this.owner = null;\n    this.state = 'DETECTED';\n    this.timestamps = {};\n  }\n}\n```\n\n## Follow-up Questions\n- How would you test isolation between tenants during a canary rollout?\n- How would you handle cross-tenant drift if tenants share resources?\n","diagram":"flowchart TD\n  A[Detect drift per tenant] --> B[Create CAPA with tenant scope]\n  B --> C{Gate: region-tenant}\n  C --> D[Containment actions]\n  D --> E[RCA template]\n  E --> F[Canary rollout on subset]\n  F --> G[Monitor acceptance and roll back if needed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T10:50:46.363Z","createdAt":"2026-01-20T10:50:46.363Z"},{"id":"q-4950","question":"Scenario: A labeling quality issue in two regions after a policy update affects multilingual captions used to fine-tune a model. Design a beginner CAPA program to address this. Include: 1) a CAPA data model capturing evidence (samples, annotator IDs, tool version, policyVersion, region), 2) a regionalized lifecycle state machine, 3) a minimal REST API to create/update CAPAs with evidence, 4) region-aware metrics to prove containment (per-region labelAccuracy, interAnnotatorAgreement, MTTR, relapseRate), 5) an RCA template and a staged canary remediation plan (revert policy in one region, update annotations, re-run validation)?","answer":"Implement CAPA for a labeling quality issue in two regions after a policy change. Data model: CAPA {id, title, evidenceSamples[], annotatorIDs[], toolVersion, policyVersion, region}; lifecycle: {Disco","explanation":"Why This Is Asked\nEvaluates ability to design a practical CAPA for data labeling quality issues in ML pipelines, focusing on evidence provenance, regional containment, and staged remediation.\n\nKey Concepts\n- CAPA data model with evidence, versions, and regional scope\n- Lifecycle state machine for progression and governance\n- Minimal REST API for creating/updating CAPAs with evidence links\n- Region-aware metrics to prove containment and prevention\n- RCA template and canary-based remediation strategy\n\nCode Example\n```json\n{\n  \"CAPA\": {\n    \"id\": \"CAPA-001\",\n    \"title\": \"Labeling quality issue in multilingual captions\",\n    \"evidenceSamples\": [\"sample1\", \"sample2\"],\n    \"annotatorIDs\": [\"a1\", \"a2\"],\n    \"toolVersion\": \"v3.2\",\n    \"policyVersion\": \"2026-01\",\n    \"region\": \"eu-west-1\"\n  }\n}\n```\n\nFollow-up Questions\n- How would you validate the canary remediation plan before full rollout?\n- What logs and metrics would you collect to demonstrate containment to stakeholders?","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T20:46:10.256Z","createdAt":"2026-01-20T20:46:10.256Z"},{"id":"q-4957","question":"Scenario: In a multi-tenant data platform, a newly deployed user-defined function (UDF) inadvertently leaks PII across tenants during aggregation. Design a CAPA program to detect, contain, and prevent recurrence. Include: 1) CAPA data model capturing evidence, access events, and UDF versions; 2) tenant-aware lifecycle state machine; 3) minimal REST API to create/update CAPAs with linked logs/traces; 4) per-tenant metrics proving containment; 5) RCA template and a canary rollout plan for UDF changes?","answer":"Design a comprehensive CAPA program for a multi-tenant data platform where a newly introduced UDF leaks PII across tenants during aggregation. Data model: id, tenant_id, event_time, evidence, logs, udf_version, affected_tables, remediation_status, containment_metrics. Tenant-aware lifecycle state machine: detected → analyzing → containing → remediating → verifying → closed, with per-tenant SLA tracking. Minimal REST API: POST /capas, GET /capas/{id}, PUT /capas/{id}, supporting evidence linkage and log/trace correlation. Per-tenant metrics: containment_time, data_leakage_volume, affected_users, remediation_success_rate. RCA template: timeline, root_cause, impact_assessment, containment_actions, prevention_measures. Canary rollout plan: tenant isolation, gradual rollout with automated monitoring, rollback triggers, and success criteria validation.","explanation":"## Why This Is Asked\nTests practical CAPA design for cross-tenant data leakage in a shared data platform, emphasizing isolation, traceability, and controlled deployments.\n\n## Key Concepts\n- Tenant-aware CAPA data model\n- Evidence linkage across logs/traces\n- Lifecycle governance and SLAs\n- Canary rollout with per-tenant gating\n\n## Code Example\n```javascript\n{\n  \"id\": \"CAPA-20260120-01\",\n  \"tenant_id\": \"tenant-a\",\n  \"event_time\": \"2026-01-20T12:34:56Z\",\n  \"evidence\": [\"s3://bucket/logs/123\",\"trace/789\"],\n  \"udf_version\": \"v2.4.0\",\n  \"affected_tables\": [\"orders\"],\n  \"remediation\": \"disable udf immediately\"\n}\n```","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Databricks"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T06:14:16.361Z","createdAt":"2026-01-20T21:31:38.494Z"},{"id":"q-5120","question":"In a multi-region data platform with cross-border backups, an automated backup job writes a sensitive dataset to region with weaker residency controls, triggering a compliance alert. Design a CAPA program that: 1) captures evidence, lineage, owners in a CAPA data model; 2) defines a region-aware lifecycle with gates (detect, contain, remediate, verify); 3) provides a minimal REST API to create/update CAPAs with logs/traces and policy tags; 4) metrics for containment and cross-region recurrence; 5) an RCA template and a canary rollout plan for policy/guardrail changes?","answer":"Implement a CAPA using a data model that records evidence, data lineage, owners, and policy tags; a region-aware lifecycle with gates (detect → contain → remediate → verify); a minimal REST API to ups","explanation":"## Why This Is Asked\n\nTests ability to design CAPA for cross-border data governance with explicit owners, evidence capture, and trackable gates. It requires multi-region controls, policy tagging, and canary-based remediation to minimize risk.\n\n## Key Concepts\n\n- CAPA data model with evidence, lineage, owners\n- Region-aware lifecycle with gates\n- Minimal REST API for CAPA CRUD with logs/traces and policy tags\n- Cross-region residency metrics (MTTR, recurrence, false positives)\n- RCA templates and canary rollout plans\n\n## Code Example\n\n```javascript\n// Example CAPA data model (simplified)\nconst CAPA = {\n  id: 'capa-123',\n  incidentId: 'inc-987',\n  evidence: ['log1','data-map-123'],\n  owners: ['sec-team','data-owners'],\n  region: 'us-west-1',\n  status: 'detect',\n  lifecycle: ['detect','contain','remediate','verify','close']\n};\n```\n\n## Follow-up Questions\n\n- How would you test the region gates and canary rollouts?\n- What metrics would you use to decide closure versus escalation?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T07:08:14.130Z","createdAt":"2026-01-21T07:08:14.130Z"},{"id":"q-5192","question":"Scenario: A multi-region data bus occasionally routes tenant data to the wrong region due to a routing bug, risking residency violations and regulatory alerts. Design a CAPA program: 1) a data model capturing evidence, lineage, and owners; 2) a region-aware lifecycle state machine with gates (detect, contain, remediate, verify); 3) a minimal REST API to create/update CAPAs with logs and lineage; 4) region metrics for leakage and dwell time; 5) RCA template and a canary rollout plan for routing changes?","answer":"CAPA data model: id, tenant_id, region, incident_time, evidence, lineage_links, owners, severity; store with versioning. Lifecycle: detect -> contain -> remediate -> verify -> close with canary gates.","explanation":"## Why This Is Asked\nTests practical CAPA engineering: data lineage, region-aware workflows, and automated containment. It also probes how candidates tie metrics to policy changes and canary strategies.\n\n## Key Concepts\n- CAPA data model with evidence and lineage\n- Region-aware lifecycle and gates\n- Minimal API design for create/update with logs\n- Metrics tying containment and recurrence\n- RCA template and canary rollout\n\n## Code Example\n```javascript\n// Example TypeScript-like CAPA data model\ninterface CAPA {\n  id: string\n  tenantId: string\n  region: string\n  incidentTime: string\n  evidenceLinks: string[]\n  lineageLinks: string[]\n  owners: string[]\n  severity: 'low'|'medium'|'high'\n}\n```\n\n## Follow-up Questions\n- How would you test the canary rollout across regions?\n- How would you ensure tamper-evident evidence logs?","diagram":"flowchart TD\n  Detect[Detect] --> Contain[Contain]\n  Contain --> Remediate[Remediate]\n  Remediate --> Verify[Verify]\n  Verify --> Close[Close]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","DoorDash","Goldman Sachs"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T10:17:02.214Z","createdAt":"2026-01-21T10:17:02.214Z"},{"id":"q-5221","question":"Scenario: A multi-tenant data platform used by advertisers experiences a region-specific schema evolution in the event ingestion path that, due to GDPR consent flags, only affects EU tenants. Design a CAPA program that addresses privacy-by-design while containment and recurrence prevention. Include: 1) a CAPA data model capturing evidence, consent flags, data locality, and audit traces; 2) a tenant-scoped lifecycle state machine for CAPA progression; 3) a minimal REST API to create/update CAPAs with linked logs/traces; 4) privacy-aware metrics (containment time, recurrence by tenant, consent-compliance rate) by region; 5) an RCA template and a canary rollout plan that respects data locality and consent constraints?","answer":"Model a CAPA with tenant_id, region, consent_flags, evidence_refs, data_location, logs, and SLA state. Lifecycle: DETECTED -> INVESTIGATING -> CONTAINED -> CORRECTED -> VERIFIED -> CLOSED, with region","explanation":"## Why This Is Asked\nTests ability to design CAPA with privacy-by-design in a multi-tenant, region-aware system.\n\n## Key Concepts\n- CAPA data model with consent, locality, and audit trails\n- Tenant-scoped lifecycle and regulatory constraints\n- Logs/traces linkage and privacy controls\n- Region-aware metrics and privacy validation\n- RCA template and guarded canary rollout\n\n## Code Example\n```javascript\nconst CAPA_STATE_MACHINE = [\"DETECTED\",\"INVESTIGATING\",\"CONTAINED\",\"CORRECTED\",\"VERIFIED\",\"CLOSED\"];\n```\n\n## Follow-up Questions\n- How would you test the canary plan under GDPR constraints?\n- Which metrics would you monitor to detect data leakage early?","diagram":"flowchart TD\n  A[DETECTED] --> B[INVESTIGATING]\n  B --> C[CONTAINED]\n  C --> D[CORRECTED]\n  D --> E[VERIFIED]\n  E --> F[CLOSED]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T11:32:14.799Z","createdAt":"2026-01-21T11:32:14.801Z"},{"id":"q-841","question":"Design a CAPA workflow for a high-volume platform (Airbnb/LinkedIn scale). The system must log incidents, perform RCA, implement corrective and preventive actions, and verify outcomes before closing. Provide: 1) a CAPA data model, 2) a lifecycle state machine, 3) an API surface to create/update CAPAs, 4) metrics to prove effectiveness (recurrence rate, time-to-close)?","answer":"Propose: Incident → RCA → corrective action → preventive action → verification → closed. CAPA data: id, incident_id, root_cause, actions[], owner, status, due, evidence, metrics. State machine: Open →","explanation":"## Why This Is Asked\n\nThis question probes the candidate's ability to design a scalable CAPA workflow, integrating incident management with RCA, corrective/preventive actions, and verification. It also tests data modeling, API design, and measurable outcomes for compliance and quality.\n\n## Key Concepts\n\n- CAPA lifecycle\n- RCA techniques\n- Data modeling\n- Observability metrics\n- Compliance/audit trails\n\n## Code Example\n\n```javascript\nclass CAPA {\n  constructor(id, incidentId) {\n    this.id = id;\n    this.incidentId = incidentId;\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you test the CAPA workflow end-to-end?\n- How would you handle concurrency and race conditions in CAPA creation?\n- What privacy and retention considerations apply?","diagram":"flowchart TD\n  Incident --> RCA\n  RCA --> Action\n  Action --> Verification\n  Verification --> Closed","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:25:13.492Z","createdAt":"2026-01-12T13:25:13.492Z"},{"id":"q-937","question":"Scenario: A post-rollout incident caused latency spikes and higher error rates for a subset of regions when a new feature flag was enabled. Design a beginner-friendly CAPA to address this. Your task: 1) propose a CAPA data model, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with evidence, 4) specify practical metrics to prove effectiveness, 5) provide a simple RCA template and a canary-based preventive action you would test before full rollout?","answer":"Open a CAPA for the feature-flag incident. Data model: capa_id, incident_id, flag_name, region, start_ts, end_ts, root_cause, corrective_actions, verification, status. Lifecycle: Open → Diagnosing → R","explanation":"## Why This Is Asked\n\nTests the ability to tailor CAPA for deployment-driven incidents tied to feature flags, mirroring real-world release risks.\n\n## Key Concepts\n\n- Incident-scoped CAPA data model\n- Lightweight state machine suitable for beginners\n- Minimal API design for CAPA lifecycle\n- Practical metrics to prove effectiveness\n- Canary-based verification strategy\n\n## Code Example\n\n```javascript\n// Example payload for creating a CAPA (JSON)\n{\n  \"capa_id\": \"CAPA-123\",\n  \"incident_id\": \"INC-456\",\n  \"flag_name\": \"new_home_feed\",\n  \"region\": \"eu-west\",\n  \"start_ts\": 1700000000,\n  \"end_ts\": 1700003600,\n  \"root_cause\": \"flag evaluation path added latency\",\n  \"corrective_actions\": [\"roll back flag\", \"optimize evaluation\"],\n  \"verification\": {\"canary_pass\": true, \"throughput_stable\": true},\n  \"status\": \"Open\"\n}\n```\n\n## Follow-up Questions\n\n- What fields would you deem optional to keep the CAPA lightweight, and why?\n- How would you extend the data model to include evidence provenance (logs/traces) without bloating the schema?\n","diagram":"flowchart TD\n  Open[Open] --> Diagnosing[Diagnosing]\n  Diagnosing --> RCAReady[RCA Ready]\n  RCAReady --> Actioned[Actioned]\n  Actioned --> Verified[Verified]\n  Verified --> Closed[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:26:25.479Z","createdAt":"2026-01-12T16:26:25.479Z"},{"id":"q-965","question":"Scenario: A multilingual moderation model update causes spikes in unsafe content in two locales. Design a beginner CAPA plan focusing on locale-scoped evidence, drift checks, and a safe rollback with feature flags. Include: 1) a CAPA data model, 2) a lifecycle machine, 3) a minimal REST API to capture CAPAs with evidence, 4) locale-specific success metrics, 5) an RCA template and a locale-specific canary plan for preview before global rollout?","answer":"Data model: CAPA with locale, incident_id, evidence_refs, corrective_actions, preventive_actions, status, timestamps; Incident stores description, locale, severity; Lifecycle: detected → triaged → inv","explanation":"## Why This Is Asked\nThis question probes minimal-CAPA design for localization-specific ML incidents and safe rollout controls.\n\n## Key Concepts\n- Locale-scoped CAPA data\n- Drift-detection integration\n- Canary-based rollback\n- Lightweight API design\n\n## Code Example\n```javascript\ntype CAPA = { id: string; locale: string; incident_id: string; evidence_refs: string[]; corrective_actions: string[]; preventive_actions: string[]; status: string; created_at: string; updated_at: string; };\n```\n\n## Follow-up Questions\n- How would you test drift checks locally before tagging a canary?\n- What minimal schema changes if a locale adds a new language?","diagram":"flowchart TD\n  Detect[Detected] --> Triage[Triage]\n  Triage --> Investigate[Investigate]\n  Investigate --> Action[Implement Action]\n  Action --> Verify[Verify]\n  Verify --> Close[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:26:38.660Z","createdAt":"2026-01-12T17:26:38.660Z"},{"id":"q-986","question":"Scenario: After a schema evolution in the event ingestion pipeline, latency spikes and incorrect bids appear in two regions. Design a CAPA program with: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove effectiveness (recurrence rate, mean time to containment, false-positive rate), 5) an RCA template and a canary rollout plan to validate before global deployment?","answer":"CAPA data model: id, title, incidentId, region, evidenceLinks[], rootCause, correctiveActions[], preventiveActions[], status, created, updated. Lifecycle: DETECTED → ANALYZING → APPROVED → EXECUTE → V","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for a real ingestion pipeline with regional scope, evidence traceability, and auditable outcomes.\n\n## Key Concepts\n- CAPA data model and evidence linkage\n- Lifecycle state machine with SLAs\n- API design for CAPA lifecycle management\n- Region-aware metrics and roll-back safety\n\n## Code Example\n```javascript\n// Example CAPA object skeleton\nconst capa = {\n  id: 'capa-987',\n  title: 'Schema rollback for ingestion',\n  incidentId: 'inc-555',\n  region: 'us-west-2',\n  evidenceLinks: ['logs/trace-1', 'trace-2'],\n  rootCause: 'schema mismatch',\n  correctiveActions: ['revert schema', 'replay events'],\n  preventiveActions: ['add schema checks'],\n  status: 'DETECTED',\n  created: '2026-01-12T12:00:00Z',\n  updated: '2026-01-12T12:00:00Z'\n};\n```\n\n## Follow-up Questions\n- How would you test the CAPA lifecycle transitions in CI/CD?\n- Which telemetry would you instrument to ensure accurate region-specific metrics?","diagram":"flowchart TD\n  A[Detect] --> B[Analyze]\n  B --> C[Plan]\n  C --> D[Execute]\n  D --> E[Verify]\n  E --> F[Close]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:31:51.916Z","createdAt":"2026-01-12T18:31:51.916Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Cloudflare","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":59,"beginner":13,"intermediate":20,"advanced":26,"newThisWeek":42}}