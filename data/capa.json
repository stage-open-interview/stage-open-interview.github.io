{"questions":[{"id":"q-1091","question":"Scenario: An OTA firmware update causes GPS altitude drift in a subset of IoT devices across regions. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API for CAPAs with device logs, 4) region/device-type metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollback plan for OTA updates?","answer":"Design a CAPA program with a data model including fields for CAPA id, incident id, device_id, region, firmware_version, evidence, actions, status, and timestamps; a lifecycle from DETECT to CLOSED; a ","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for hardware deployments, emphasizing evidence capture, state management, and canary safety.\n\n## Key Concepts\n- CAPA data model tailored to IoT/OTA scenarios\n- Lifecycle state machine for CAPA progression\n- Minimal API design for linking CAPAs to device logs\n- Region/device-type metrics to prove effectiveness\n- RCA templates and safe rollback strategies\n\n## Code Example\n```javascript\n// Minimal CAPA creation schema (pseudo)\nconst createCAPA = (payload) => ({ id: generateId(), ...payload, status: 'OPEN' })\n```\n\n## Follow-up Questions\n- How would you ensure evidence provenance and tamper-evidence across devices?\n- How would you test the canary rollback plan with real devices at scale?","diagram":"flowchart TD\n  A[Detect Drift] --> B[Collect Evidence]\n  B --> C[Create CAPA]\n  C --> D[Canary OTA]\n  D --> E[Evaluate Metrics]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Plaid","Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T22:23:48.606Z","createdAt":"2026-01-12T22:23:48.606Z"},{"id":"q-1111","question":"Scenario: Production ML feature store drift after a data refresh degrades latency and CTR across regions due to stale features and late streaming data. Propose a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPAs, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove containment and recurrence, 5) an RCA template and a canary rollout plan to prevent recurrence during future refreshes?","answer":"CAPA data model should store evidence (logs, traces, feature clocks) and artifacts (RCA, mitigations, rollback scripts). Lifecycle: detected → triaged → containment → root cause → corrective action → ","explanation":"## Why This Is Asked\nTests ability to design scalable CAPA for data drift in production ML pipelines, including evidence management, lifecycle, API design, and robust canary strategies.\n\n## Key Concepts\n- CAPA data model with evidence links\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for CAPAs\n- Region-aware metrics (MTTR, recurrence, containment)\n- RCA templates and canary rollout planning\n\n## Code Example\n```javascript\n// CAPA data model sketch\n{\n  \"id\": \"CAPA-20260112-001\",\n  \"issue\": \"Feature store drift causing latency and CTR degradation\",\n  \"regions\": [\"us-east-1\",\"eu-west-1\"],\n  \"evidenceLinks\": [\"https://log/123\",\"https://trace/456\"],\n  \"lifecycle\": \"detected\",\n  \"actions\": [\n    {\"step\":\"containment\",\"owner\":\"SRE\",\"status\":\"pending\"}\n  ],\n  \"canaryPlan\": {\"enabled\":true,\"regions\":[\"us-east-1\"]}\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA API for high throughput and cross-region consistency?\n- What RCA sections ensure actionable preventive measures and auditability?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T23:20:43.169Z","createdAt":"2026-01-12T23:20:43.169Z"},{"id":"q-1132","question":"Scenario: batch ingestion misses PII masking in two tenants across regions, raising privacy risk. Design a CAPA program: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant/region-aware metrics to prove containment and recurrence (MTTD, MTTR, false positives), 5) an RCA template and a canary rollout plan to validate policy enforcement before global deployment?","answer":"Approach: define CAPA data model with evidence, logs, and artifacts; lifecycle states: detected, triaged, in_progress, contained, closed; REST API endpoints POST /caps, PUT /caps/{id} with linked trac","explanation":"## Why This Is Asked\n\nTests ability to design end-to-end CAPA workflow for data privacy policy failures, including evidence capture and cross-tenant rollout.\n\n## Key Concepts\n\n- CAPA data modeling for evidence and artifacts\n- Lifecycle state machine and ownership\n- Minimal REST API design with linked logs/traces\n- Tenant/region metrics for containment and recurrence\n- RCA templates and canary rollout planning\n\n## Code Example\n\n```javascript\n// CAPA core types (overview)\ninterface CAPA {\n  id: string;\n  title: string;\n  evidence: string[];\n  artifacts: string[];\n  state: 'detected'|'triaged'|'in_progress'|'contained'|'closed';\n  createdAt: string;\n  updatedAt?: string;\n  links?: { type: string; url: string }[];\n}\n```\n\n## Follow-up Questions\n\n- How would you scale CAPA data stores across regions?\n- How to ensure regulatory auditability and evidence integrity?","diagram":"flowchart TD\n  A[Incident Detected] --> B[Evidence Collected]\n  B --> C[CAPA Created]\n  C --> D[Root Cause Analysis]\n  D --> E[Containment]\n  E --> F[Preventive Action]\n  F --> G[Canary Validation]\n  G --> H[Global Rollout]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","MongoDB","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:23:32.007Z","createdAt":"2026-01-13T01:23:32.007Z"},{"id":"q-1156","question":"Scenario: A distributed streaming analytics pipeline processes click events for an online marketplace. A recently deployed shard rebalancing causes out-of-order events in two regions, leading to incorrect revenue attribution and fraud alerts. Design a CAPA program that covers: 1) a CAPA data model that captures evidence (events, traces, timestamps, orderings) and artifacts (config, manifest, canary results), 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces and event metadata, 4) region- and shard-aware metrics to prove containment (recurrence rate, MTTR, misattribution rate), 5) an RCA template and a canary-rollback plan for shard rebalancing?","answer":"Propose a CAPA program for out-of-order events from shard rebalancing in a streaming analytics pipeline. Data model: CAPA(id, region, shard, evidence: [eventId, traceId, timestamp], artifacts: [config","explanation":"Why This Is Asked\nTests end-to-end CAPA thinking for distributed streaming with event-ordering issues and rollback safety.\n\nKey Concepts\n- CAPA data model for evidence and artifacts\n- Lifecycle state machine with containment and prevention\n- Minimal REST API for linking logs/traces to CAPAs\n- Region/shard-aware metrics and attribution correctness\n- RCA template and canary rollback strategy\n\nCode Example\n```javascript\n// Minimal REST API sketch (Express)\nconst express = require('express');\nconst app = express();\napp.use(express.json());\napp.post('/caps', (req, res) => {\n  // validate and persist CAPA with evidence refs\n  res.status(201).send({ id: 'capa-123' });\n});\n```\n\nFollow-up Questions\n- How would you validate and test the canary rollback under varying traffic patterns?\n- What data retention and privacy controls are needed for CAPA artifacts?","diagram":"flowchart TD\nA[Incident Observed] --> B[Triage & Evidence]\nB --> C[Containment via Canary]\nC --> D[Root Cause Analysis]\nD --> E[Corrective Action]\nE --> F[Preventive Action]\nF --> G[Close CAPA]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Apple"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T03:28:35.156Z","createdAt":"2026-01-13T03:28:35.156Z"},{"id":"q-1200","question":"Scenario: A global real-time telemetry platform for autonomous vehicles experiences intermittent PII exposure due to a log-redaction misconfiguration after a software update in two regions. Design a CAPA program to detect, document, and prevent recurrence. Include: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant- and region-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary-based rollback/patch plan, 6) a policy gate preventing deployment until redact coverage is above threshold?","answer":"CAPA design: use a normalized CAPA data model with fields like id, tenants, regions, evidence_refs (logs/traces), artifacts, state, severity, and timestamps. Lifecycle: New → Open → Investigating → Co","explanation":"## Why This Is Asked\n\nTests ability to design end-to-end CAPA workflow for privacy incidents, including across tenants and regions, with concrete artifacts and controls.\n\n## Key Concepts\n\n- CAPA data model, state machine, API design, region-tenant metrics, RCA, canary rollback, policy gates.\n\n## Code Example\n\n```javascript\n// Example CAPA payload shape\ninterface CAPA { id: string; tenants: string[]; regions: string[]; evidence_refs: string[]; artifacts: string[]; state: string; severity: string; timestamps: Record<string,string>; }\n```\n\n## Follow-up Questions\n\n- How would you verify redact coverage? What tests would you add?\n- How do you design region-aware dashboards to avoid alert fatigue?\n","diagram":"flowchart TD\nA[New CAPA] --> B[Open]\nB --> C[Investigating]\nC --> D[Containment]\nD --> E[Corrective Action]\nE --> F[Verified]\nF --> G[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T04:48:36.347Z","createdAt":"2026-01-13T04:48:36.347Z"},{"id":"q-1426","question":"Scenario: A multi-tenant SaaS billing system release unintentionally changes pricing rules for a subset of tenants, triggering incorrect invoices and revenue churn. Design a beginner CAPA program to address this. Your task: 1) propose a CAPA data model capturing evidence (invoices, logs, traces) and artifacts (config, feature flags, pricing rules); 2) define a lifecycle state machine for CAPA progression; 3) outline a minimal REST API to create/update CAPAs with linked billing events; 4) specify tenant- and plan-level metrics to prove containment (recurrence rate, MTTR, false positives); 5) provide an RCA template and a canary-based patch plan before full rollout; 6) draft a simple policy gate that prevents deployment until pricing rules pass a preflight check?","answer":"CAPA data model: capa_id, tenant_id, invoice_id, evidence_refs, artifacts, pricing_rule_version; lifecycle: detected -> validated -> in_progress -> contained -> resolved -> closed; API: POST/PUT /caps","explanation":"## Why This Is Asked\nTests practical CAPA thinking: data modeling, lifecycle, minimal API, and measurable outcomes for a realistic beginner scenario.\n\n## Key Concepts\n- CAPA data model with evidence and artifacts\n- Lifecycle state machine for progress\n- Minimal REST API for CAPAs\n- Tenant/plan metrics to prove containment\n- RCA template and canary remediation plan\n\n## Code Example\n```javascript\n// example schema outline\nconst CAPASchema = {\n  capa_id: String,\n  tenant_id: String,\n  invoice_id: String,\n  evidence_refs: [String],\n  artifacts: [String],\n  pricing_rule_version: String\n}\n```\n\n## Follow-up Questions\n- How would you version artifacts and signatures for integrity?\n- What alerting would you add to detect recurring pricing issues?","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hashicorp","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T16:47:28.090Z","createdAt":"2026-01-13T16:47:28.090Z"},{"id":"q-1450","question":"Scenario: A global multi-tenant data platform implements a new consent-logging feature. After rollout, a bug in the consent service causes PII redaction failures in two regions, risking data exposure and compliance violations. Design a CAPA program to detect, collect evidence, and prevent recurrence. Include: 1) a CAPA data model, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region- and tenant-aware metrics (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollout plan to validate fixes before global deployment?","answer":"Design a CAPA: data model with CAPA, evidence, artifacts, linked logs/traces; lifecycle: Identified → Investigating → Contained → Eradicated → Verified → Closed; REST API: POST /caps to create, PATCH ","explanation":"## Why This Is Asked\nTests the ability to architect an end-to-end CAPA workflow for a data-platform reliability incident that spans regions and tenants, including how to model evidence and link traces for audit trails.\n\n## Key Concepts\n- CAPA data model with evidence and linked artifacts\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for creating/updating CAPAs\n- Region- and tenant-aware metrics (recurrence, MTTR, false positives)\n- RCA templates and canary rollout planning\n\n## Code Example\n```javascript\n// Example CAPA schema (illustrative)\n{\n  id: string,\n  title: string,\n  region: string,\n  tenant_id: string,\n  status: string,\n  evidence: string[],\n  artifacts: string[],\n  remediation: object\n}\n```\n\n## Follow-up Questions\n- How would you automate evidence collection across services?\n- How would you handle new tenants with no historical CAPA data?","diagram":"flowchart TD\n  A[Identified] --> B[Investigating]\n  B --> C[Contained]\n  C --> D[Eradicated]\n  D --> E[Verified]\n  E --> F[Closed]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","LinkedIn","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:46:10.476Z","createdAt":"2026-01-13T17:46:10.477Z"},{"id":"q-1485","question":"**Scenario**: A cross-tenant data export feature in a multi-tenant SaaS app accidentally exposes data from unrelated tenants during a canary rollout in two regions. Design a beginner **CAPA** program to detect, document, and prevent recurrence. Your task: 1) propose a CAPA data model framing evidence and artifacts, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with linked logs/traces, 4) specify tenant-scoped metrics for containment, 5) provide an RCA template and a canary-based fix plan to validate before broader rollout?","answer":"CAPA data model: CAPA{id, tenantId, region, evidenceRefs, severity, rootCause, correctiveAction, preventiveAction, status, timestamps}. Lifecycle: new→triage→investigate→remediate→verify→closed. API: POST /capas (create), GET /capas/{id}, PUT /capas/{id} (update), POST /capas/{id}/evidence (link logs/traces). Tenant-scoped metrics: dataExposureEvents{tenantId, region, count}, containmentTime{tenantId, region, ms}, rcaCompletionRate{tenantId, percentage}, canaryValidationSuccess{tenantId, boolean}. RCA template: incidentSummary, timeline, rootCauseAnalysis, impactAssessment, correctiveActions, preventiveActions, verificationCriteria. Canary fix plan: 1) implement fix in single tenant, 2) validate no data leakage, 3) monitor containment metrics, 4) gradual regional rollout, 5) full deployment after 24h clean monitoring.","explanation":"## Why This Is Asked\nTests ability to translate incident learnings into a repeatable CAPA workflow for multi-tenant data exposure, focusing on a basic data model, lifecycle, measurable containment, and practical API design.\n\n## Key Concepts\n- CAPA data modeling with tenant isolation\n- Lifecycle state machine for incident response\n- REST API design for evidence management\n- Tenant-scoped containment metrics\n- RCA templates and canary validation\n\n## Code Example\n```javascript\n// CAPA record with evidence linking\nconst CAPA = {\n  id, tenantId, region,\n  evidenceRefs: [\"log:trace-123\", \"metric:exposure-456\"],\n  severity, rootCause,\n  correctiveAction, preventiveAction,\n  status, createdAt, updatedAt\n};\n```\n\n## Follow-up Questions\n- How would privacy-by-design constraints influence CAPA data fields?\n- Which minimal tests verify the canary fix works without regressions?","diagram":"flowchart TD\n  A[CAPA Initiated] --> B[Triage]\n  B --> C[Investigation]\n  C --> D[Remediate]\n  D --> E[Verify]\n  E --> F[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":["capa data model","lifecycle state machine","rest api design","tenant-scoped metrics","rca template","canary fix plan","multi-tenant saas","data exposure","evidence management","containment metrics","root cause analysis","gradual rollout"],"voiceSuitable":true,"isNew":true,"lastUpdated":"2026-01-14T05:11:47.713Z","createdAt":"2026-01-13T18:58:29.114Z"},{"id":"q-1502","question":"Scenario: A new analytics feature ingests raw customer IDs into a 3rd-party BI dataset due to a masking policy misconfiguration in the data pipeline. Design a CAPA program to detect, document, and prevent recurrence. Your tasks: 1) propose a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) tenant-scoped metrics for containment and recurrence, 5) an RCA template and a canary-based remediation plan to validate before rollout?","answer":"CAPA data model: id, incident_id, tenant_id, data_asset, evidence_uris, lineage_digest, root_cause, containment_actions, corrective_actions, verification, status, created_at, updated_at. State machine","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for data leakage via a 3rd-party BI integration, emphasizing evidence capture, containment, and validation before rollout.\n\n## Key Concepts\n- CAPA data model, lifecycle, tenant-scoped metrics, RCA templates, canary remediation.\n- Data lineage, masking policy correctness, logs/traces, DLP controls.\n\n## Code Example\n```javascript\nconst capa = {\n  id: 'CAPA-XXXX',\n  incident_id: 'INC-1234',\n  tenant_id: 'T1',\n  data_asset: 'BI_dataset_X',\n  evidence_uris: ['s3://logs/inc-1234/trace1','s3://evidence/policy.yaml'],\n  lineage_digest: 'abcd1234',\n  root_cause: 'masking_policy_misconfig',\n  containment_actions: ['disable_bi_feed'],\n  corrective_actions: ['update_masking', 'retrain_policy'],\n  verification: 'passed',\n  status: 'CLOSED',\n  created_at: '2026-01-01T00:00:00Z',\n  updated_at: '2026-01-02T12:00:00Z'\n}\n```\n\n## Follow-up Questions\n- How would you automate evidence collection across services?\n- What metrics would you visualize to verify containment and recurrence reduction?","diagram":null,"difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Oracle","PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T19:39:15.407Z","createdAt":"2026-01-13T19:39:15.407Z"},{"id":"q-1528","question":"Scenario: A vendor data feed for pricing and product metadata experiences occasional delays and duplicates during a quarterly refresh, causing price mismatches in two regions. Design a beginner CAPA program to address this. Your tasks: 1) propose a CAPA data model capturing evidence and artifacts, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with linked feed records, 4) specify region- and tenant-aware metrics to prove containment, 5) provide an RCA template and a canary-based preventive action plan to validate before broader rollout?","answer":"Propose a CAPA data model capturing evidence (feed_id, timestamp, region, tenant, price_record) and artifacts (config, rules, vendor_version); define a lifecycle state machine with states (open → investigate → containment → corrective → preventive → closed); outline a minimal REST API with endpoints POST /capas and PUT /capas/:id supporting linked feed records; specify region- and tenant-aware metrics including containment rate, duplicate frequency, and price mismatch latency; provide an RCA template covering timeline, root causes, and impact analysis; and implement a canary-based preventive action plan with staged validation before broader rollout.","explanation":"## Why This Is Asked\nAssesses practical CAPA skill under a vendor-feed incident with regional impact.\n\n## Key Concepts\n- CAPA data model, evidence artifacts\n- Lifecycle management, state transitions\n- API design with linked feed records\n- Region/tenant metrics for containment\n- RCA template and canary-based preventive actions\n\n## Code Example\n```javascript\n// Minimal CAPA schema sketch\n{ \"id\": \"CAPA-001\", \"incident\": \"vendor-feed\", \"state\": \"open\" }\n```\n\n## Follow-up Questions\n- How would you validate the canary plan across regions?\n- How would you prevent future duplicates in the feed?","diagram":null,"difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Coinbase","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:49:29.965Z","createdAt":"2026-01-13T20:45:01.344Z"},{"id":"q-1556","question":"Two regions saw bids inflated after a cache invalidation caused an expired pricing model to be applied in an ad-bidding pipeline. Design a CAPA program to detect, document, and prevent recurrence. Your task: 1) CAPA data model for evidence and artifacts, 2) a lifecycle state machine, 3) a minimal REST API to create/update CAPAs with logs/traces, 4) region-asset metrics for containment (recurrence rate, MTTR, false positives), 5) RCA template and a canary cache-invalidation plan before rollout?","answer":"CAPA data model should include: id, region, asset, incident_id, evidence_links, artifacts, state, severity, timestamps, corrective_action, preventive_action, canary_results. State machine: New → In Progress → Review → Approved → Implemented → Verified → Closed. REST API endpoints: POST /capas, GET /capas/{id}, PUT /capas/{id}, GET /capas/{id}/logs, GET /capas/{id}/traces. Region-asset metrics: recurrence_rate, mttr, false_positive_rate, containment_time. RCA template sections: incident_summary, timeline, root_causes, impact_assessment, corrective_actions, preventive_actions, lessons_learned. Canary cache-invalidation plan: validate pricing model versioning, implement cache warming, add rollback triggers, monitor bid accuracy during rollout.","explanation":"## Why This Is Asked\nAssess ability to design end-to-end CAPA tooling for real-world pipeline failures, including data modeling, lifecycle governance, API ergonomics, measurable containment metrics, and a concrete RCA/canary plan.\n\n## Key Concepts\n- CAPA data modeling\n- State machine design\n- REST API design for incident artifacts\n- Regional metrics and RCA templates\n- Canary rollback for cache invalidation\n\n## Code Example\n```javascript\n// Skeleton CAPA entity\nclass CAPA { constructor(...) { ... } }\n```\n\n## Follow-up Questions\n- How would you version CAPA artifacts and enforce security constraints?","diagram":"flowchart TD\n  A[New CAPA] --> B[In Progress]\n  B --> C[Containment Verified]\n  C --> D[Root Cause]\n  D --> E[Corrective Action]\n  E --> F[Preventive Action]\n  F --> G[Closed]","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:25:02.549Z","createdAt":"2026-01-13T21:42:31.859Z"},{"id":"q-1635","question":"A distributed cache layer across two regions intermittently serves stale reads after a deployment; design a beginner CAPA program to detect, document, and prevent recurrence?","answer":"CAPA data model: id, issue, evidence, containment, rootCause, actions, status, timeline. State machine: DETECTED → EVALUATED → CONTAINED → CORRECTED → VERIFIED → CLOSED. API: POST /caps, PATCH /caps/{","explanation":"## Why This Is Asked\n\nTests practical CAPA planning for a production cache issue, ensuring a clear, beginner-friendly workflow.\n\n## Key Concepts\n\n- CAPA data model design\n- Lifecycle state machine\n- Minimal REST API design\n- Metrics for containment\n- RCA structure\n- Canary rollout and rollback strategies\n- Policy gates\n\n## Code Example\n\n```json\n{\n  \"id\": \"CAPA-0002\",\n  \"issue\": \"stale-cache-read\",\n  \"evidence\": [\"log:cache-miss\", \"trace:deploy\"],\n  \"containment\": \"paused deploy to region A\",\n  \"rootCause\": \"cache TTL misconfiguration\",\n  \"actions\": [\"revert deploy\", \"adjust TTLs\", \"validate with canary\"],\n  \"status\": \"open\",\n  \"timeline\": [\"2026-01-14T12:00Z\"]\n}\n```\n\n## Follow-up Questions\n\n- How would you ensure idempotency of CAPA creation?\n- How would you extend metrics for multi-region detection latency?","diagram":"flowchart TD\n  Detect[Detect CAPA] --> Eval[Evaluate Evidence]\n  Eval --> Contain[Containment Actions]\n  Contain --> Root[Root Cause Analysis]\n  Root --> Plan[Plan Preventive Actions]\n  Plan --> Close[Close CAPA]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Microsoft","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:21:10.430Z","createdAt":"2026-01-14T04:21:10.431Z"},{"id":"q-1745","question":"Scenario: In a multi-tenant payments platform serving PayPal, Lyft, and Coinbase, a policy change to transaction masking and logging fails to propagate to streaming and analytics pipelines in two regions, raising privacy risk and audit gaps. Design a CAPA program to address this: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces and policy versions, 4) region-aware metrics to prove containment (recurrence rate, MTTR, false positives), 5) an RCA template and a canary rollback plan for policy changes?","answer":"Model CAPAs with: id, policy_version, evidence_refs, artifacts, region, status, root_cause, corrective_action, verification. Lifecycle: pending → evidence_collected → impact_assessed → containment → r","explanation":"## Why This Is Asked\nTests ability to design a scalable CAPA program for policy drift affecting data masking and logging, with cross-region impact.\n\n## Key Concepts\n- CAPA data model with evidence and artifacts\n- Lifecycle state machine for CAPA progression\n- Minimal REST API design for CAPAs with linkage to logs/traces and policy versions\n- Region-aware metrics (recurrence, MTTR, false positives)\n- RCA template and canary rollback strategy\n\n## Code Example\n```javascript\nconst CAPA = {\n  id: 'string',\n  policy_version: 'string',\n  region: 'string',\n  evidence_refs: ['string'],\n  artifacts: {config: 'string', manifest: 'string'},\n  status: 'pending',\n  root_cause: 'string',\n  corrective_action: 'string',\n  verification: 'string'\n}\n```\n\n## Follow-up Questions\n- How would you scale the CAPA data store for high-cardinality evidence refs?\n- What are safe-guards to prevent false rollbacks during canary rollout?","diagram":null,"difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Lyft","PayPal"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:04:06.160Z","createdAt":"2026-01-14T09:04:06.160Z"},{"id":"q-841","question":"Design a CAPA workflow for a high-volume platform (Airbnb/LinkedIn scale). The system must log incidents, perform RCA, implement corrective and preventive actions, and verify outcomes before closing. Provide: 1) a CAPA data model, 2) a lifecycle state machine, 3) an API surface to create/update CAPAs, 4) metrics to prove effectiveness (recurrence rate, time-to-close)?","answer":"Propose: Incident → RCA → corrective action → preventive action → verification → closed. CAPA data: id, incident_id, root_cause, actions[], owner, status, due, evidence, metrics. State machine: Open →","explanation":"## Why This Is Asked\n\nThis question probes the candidate's ability to design a scalable CAPA workflow, integrating incident management with RCA, corrective/preventive actions, and verification. It also tests data modeling, API design, and measurable outcomes for compliance and quality.\n\n## Key Concepts\n\n- CAPA lifecycle\n- RCA techniques\n- Data modeling\n- Observability metrics\n- Compliance/audit trails\n\n## Code Example\n\n```javascript\nclass CAPA {\n  constructor(id, incidentId) {\n    this.id = id;\n    this.incidentId = incidentId;\n  }\n}\n```\n\n## Follow-up Questions\n\n- How would you test the CAPA workflow end-to-end?\n- How would you handle concurrency and race conditions in CAPA creation?\n- What privacy and retention considerations apply?","diagram":"flowchart TD\n  Incident --> RCA\n  RCA --> Action\n  Action --> Verification\n  Verification --> Closed","difficulty":"advanced","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","LinkedIn"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:25:13.492Z","createdAt":"2026-01-12T13:25:13.492Z"},{"id":"q-937","question":"Scenario: A post-rollout incident caused latency spikes and higher error rates for a subset of regions when a new feature flag was enabled. Design a beginner-friendly CAPA to address this. Your task: 1) propose a CAPA data model, 2) define a lifecycle state machine, 3) outline a minimal REST API to create/update CAPAs with evidence, 4) specify practical metrics to prove effectiveness, 5) provide a simple RCA template and a canary-based preventive action you would test before full rollout?","answer":"Open a CAPA for the feature-flag incident. Data model: capa_id, incident_id, flag_name, region, start_ts, end_ts, root_cause, corrective_actions, verification, status. Lifecycle: Open → Diagnosing → R","explanation":"## Why This Is Asked\n\nTests the ability to tailor CAPA for deployment-driven incidents tied to feature flags, mirroring real-world release risks.\n\n## Key Concepts\n\n- Incident-scoped CAPA data model\n- Lightweight state machine suitable for beginners\n- Minimal API design for CAPA lifecycle\n- Practical metrics to prove effectiveness\n- Canary-based verification strategy\n\n## Code Example\n\n```javascript\n// Example payload for creating a CAPA (JSON)\n{\n  \"capa_id\": \"CAPA-123\",\n  \"incident_id\": \"INC-456\",\n  \"flag_name\": \"new_home_feed\",\n  \"region\": \"eu-west\",\n  \"start_ts\": 1700000000,\n  \"end_ts\": 1700003600,\n  \"root_cause\": \"flag evaluation path added latency\",\n  \"corrective_actions\": [\"roll back flag\", \"optimize evaluation\"],\n  \"verification\": {\"canary_pass\": true, \"throughput_stable\": true},\n  \"status\": \"Open\"\n}\n```\n\n## Follow-up Questions\n\n- What fields would you deem optional to keep the CAPA lightweight, and why?\n- How would you extend the data model to include evidence provenance (logs/traces) without bloating the schema?\n","diagram":"flowchart TD\n  Open[Open] --> Diagnosing[Diagnosing]\n  Diagnosing --> RCAReady[RCA Ready]\n  RCAReady --> Actioned[Actioned]\n  Actioned --> Verified[Verified]\n  Verified --> Closed[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:26:25.479Z","createdAt":"2026-01-12T16:26:25.479Z"},{"id":"q-965","question":"Scenario: A multilingual moderation model update causes spikes in unsafe content in two locales. Design a beginner CAPA plan focusing on locale-scoped evidence, drift checks, and a safe rollback with feature flags. Include: 1) a CAPA data model, 2) a lifecycle machine, 3) a minimal REST API to capture CAPAs with evidence, 4) locale-specific success metrics, 5) an RCA template and a locale-specific canary plan for preview before global rollout?","answer":"Data model: CAPA with locale, incident_id, evidence_refs, corrective_actions, preventive_actions, status, timestamps; Incident stores description, locale, severity; Lifecycle: detected → triaged → inv","explanation":"## Why This Is Asked\nThis question probes minimal-CAPA design for localization-specific ML incidents and safe rollout controls.\n\n## Key Concepts\n- Locale-scoped CAPA data\n- Drift-detection integration\n- Canary-based rollback\n- Lightweight API design\n\n## Code Example\n```javascript\ntype CAPA = { id: string; locale: string; incident_id: string; evidence_refs: string[]; corrective_actions: string[]; preventive_actions: string[]; status: string; created_at: string; updated_at: string; };\n```\n\n## Follow-up Questions\n- How would you test drift checks locally before tagging a canary?\n- What minimal schema changes if a locale adds a new language?","diagram":"flowchart TD\n  Detect[Detected] --> Triage[Triage]\n  Triage --> Investigate[Investigate]\n  Investigate --> Action[Implement Action]\n  Action --> Verify[Verify]\n  Verify --> Close[Closed]","difficulty":"beginner","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:26:38.660Z","createdAt":"2026-01-12T17:26:38.660Z"},{"id":"q-986","question":"Scenario: After a schema evolution in the event ingestion pipeline, latency spikes and incorrect bids appear in two regions. Design a CAPA program with: 1) a CAPA data model capturing evidence and artifacts, 2) a lifecycle state machine for CAPA progression, 3) a minimal REST API to create/update CAPAs with linked logs/traces, 4) region-aware metrics to prove effectiveness (recurrence rate, mean time to containment, false-positive rate), 5) an RCA template and a canary rollout plan to validate before global deployment?","answer":"CAPA data model: id, title, incidentId, region, evidenceLinks[], rootCause, correctiveActions[], preventiveActions[], status, created, updated. Lifecycle: DETECTED → ANALYZING → APPROVED → EXECUTE → V","explanation":"## Why This Is Asked\nTests end-to-end CAPA design for a real ingestion pipeline with regional scope, evidence traceability, and auditable outcomes.\n\n## Key Concepts\n- CAPA data model and evidence linkage\n- Lifecycle state machine with SLAs\n- API design for CAPA lifecycle management\n- Region-aware metrics and roll-back safety\n\n## Code Example\n```javascript\n// Example CAPA object skeleton\nconst capa = {\n  id: 'capa-987',\n  title: 'Schema rollback for ingestion',\n  incidentId: 'inc-555',\n  region: 'us-west-2',\n  evidenceLinks: ['logs/trace-1', 'trace-2'],\n  rootCause: 'schema mismatch',\n  correctiveActions: ['revert schema', 'replay events'],\n  preventiveActions: ['add schema checks'],\n  status: 'DETECTED',\n  created: '2026-01-12T12:00:00Z',\n  updated: '2026-01-12T12:00:00Z'\n};\n```\n\n## Follow-up Questions\n- How would you test the CAPA lifecycle transitions in CI/CD?\n- Which telemetry would you instrument to ensure accurate region-specific metrics?","diagram":"flowchart TD\n  A[Detect] --> B[Analyze]\n  B --> C[Plan]\n  C --> D[Execute]\n  D --> E[Verify]\n  E --> F[Close]","difficulty":"intermediate","tags":["capa"],"channel":"capa","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Oracle","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:31:51.916Z","createdAt":"2026-01-12T18:31:51.916Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Citadel","Coinbase","Discord","DoorDash","Hashicorp","Hugging Face","LinkedIn","Lyft","Microsoft","MongoDB","Oracle","PayPal","Plaid","Salesforce","Snowflake","Stripe","Tesla","Twitter","Uber","Zoom"],"stats":{"total":17,"beginner":6,"intermediate":4,"advanced":7,"newThisWeek":17}}