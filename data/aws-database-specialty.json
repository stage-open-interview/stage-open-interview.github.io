{"questions":[{"id":"aws-database-specialty-database-security-1768253260513-0","question":"During encryption key rotation, which approach provides secure rotation with minimal downtime for an RDS instance encrypted with a customer-managed CMK?","answer":"[{\"id\":\"a\",\"text\":\"Enable automatic rotation on the CMK so data is transparently re-encrypted\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a new KMS CMK and re-encrypt by taking a fresh snapshot and restoring to a new RDS instance using the new CMK\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Revoke access to the old CMK and continue using the same CMK\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Directly rotate the RDS master key without involving KMS\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. Create a new KMS CMK and re-encrypt by taking a fresh snapshot and restoring to a new RDS instance using the new CMK.\n\n## Why Other Options Are Wrong\n- A: Automatic CMK rotation rotates the CMK material but does not automatically re-encrypt existing data in RDS, which can leave data encrypted under old material until a separate re-encryption occurs.\n- C: Revoking access to the old CMK does not re-encrypt data and can render existing data undecryptable if the old key is required.\n- D: There is no in-place zero-downtime rotation of an encrypted RDS instance via a simple key rotation; re-encryption steps are needed.\n\n## Key Concepts\n- AWS KMS customer-managed CMKs\n- RDS encryption at rest\n- Data re-encryption via snapshot restore\n- Cutover planning for minimal downtime\n\n## Real-World Application\n- Used in regulated environments where encryption keys must be rotated regularly; plan a controlled cutover, validate access, and verify decryption with the new CMK after switch.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","KMS","IAM","Aurora","Database Security","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"database-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:27:40.513Z","createdAt":"2026-01-12 21:27:41"},{"id":"aws-database-specialty-database-security-1768253260513-1","question":"A company runs an Aurora PostgreSQL cluster and must meet regulatory requirements to audit every data access and SQL statement with user identity and timestamps. Which AWS feature provides near real-time, SQL-level auditability for database activity?","answer":"[{\"id\":\"a\",\"text\":\"CloudTrail data events for RDS\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Database Activity Streams (DAS)\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Enhanced Monitoring\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"S3 access logging\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. Database Activity Streams (DAS) provides near real-time, row-level auditing including who, when, and what SQL was executed. CloudTrail logs API calls, not SQL statements, while Enhanced Monitoring tracks OS metrics and does not capture SQL details. S3 access logs are unrelated to database query auditing.\n\n## Why Other Options Are Wrong\n- A: CloudTrail logs API calls to AWS services, not the actual SQL statements run inside the database.\n- C: Enhanced Monitoring focuses on OS-level metrics, not SQL-level activity.\n- D: S3 access logs do not capture database query activity.\n\n## Key Concepts\n- Database Activity Streams (DAS)\n- Row-level auditing\n- Regulatory compliance for databases\n\n## Real-World Application\n- Enables auditors and security teams to detect and investigate unauthorized data access and SQL changes in near real-time.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","Aurora PostgreSQL","DAS","CloudWatch","Database Security","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"database-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:27:41.248Z","createdAt":"2026-01-12 21:27:41"},{"id":"aws-database-specialty-database-security-1768253260513-2","question":"IAM database authentication is enabled on an Aurora PostgreSQL cluster. A developer needs read-only access to a specific subset of tables. What is the correct approach to implement this access?","answer":"[{\"id\":\"a\",\"text\":\"Create a database user for the developer and grant SELECT on the allowed tables; the developer authenticates via IAM and uses the mapped database user\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Attach an IAM policy that directly grants SELECT on database tables\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Store the credentials in Secrets Manager and rotate them regularly\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Restrict access using only VPC security groups and leave database privileges at default\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. With IAM DB authentication, the AWS identity authenticates to the database, but database privileges are enforced inside the DB. Create a database user/role for the developer and grant SELECT on the specific tables, then bind that database user to the IAM identity. IAM policies cannot grant table-level privileges inside the database, and Secrets Manager alone does not grant privileges. VPC controls do not define per-table access.\n\n## Why Other Options Are Wrong\n- B: IAM policies grant AWS permissions, not database privileges.\n- C: Secrets Manager rotation handles credentials but does not define per-table permissions.\n- D: Privileges require explicit database-level grants.\n\n## Key Concepts\n- IAM DB authentication mapping to DB users\n- Fine-grained DB privileges (SELECT on specific tables)\n- Aurora PostgreSQL integration with IAM\n\n## Real-World Application\n- Enables least-privilege access control for developers connecting via IAM-authenticated sessions.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","IAM","Aurora","PostgreSQL","Database Security","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"database-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:27:41.766Z","createdAt":"2026-01-12 21:27:41"},{"id":"aws-database-specialty-database-security-1768253260513-3","question":"A financial application needs to detect and alert on any SQL statements that modify customer data in an Aurora MySQL cluster. Which AWS feature provides near real-time visibility of such statements along with user identity?","answer":"[{\"id\":\"a\",\"text\":\"CloudTrail data events for RDS\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Database Activity Streams (DAS)\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Enhanced Monitoring\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"VPC Flow Logs\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. Database Activity Streams (DAS) provides near real-time visibility into database statements with user identity, ideal for detecting modifications to customer data. CloudTrail logs API calls and does not capture individual SQL statements. Enhanced Monitoring focuses on OS metrics, and VPC Flow Logs capture network traffic, not SQL-level changes.\n\n## Why Other Options Are Wrong\n- A: CloudTrail logs AWS API calls, not SQL statements executed inside the database.\n- C: Enhanced Monitoring does not provide SQL-level activity.\n- D: VPC Flow Logs monitor network traffic, not database SQL activity.\n\n## Key Concepts\n- DAS for SQL-level auditing\n- Real-time security monitoring\n- Compliance for data modification events\n\n## Real-World Application\n- Used in security operations to detect and respond to inappropriate data changes in databases.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","Aurora","DAS","CloudWatch","Database Security","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"database-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:27:41.951Z","createdAt":"2026-01-12 21:27:42"},{"id":"aws-database-specialty-database-security-1768253260513-4","question":"You have encrypted RDS snapshots in a region and want to copy one snapshot to a different AWS region for disaster recovery. What must you do to ensure the copy is encrypted with a CMK available in the destination region?","answer":"[{\"id\":\"a\",\"text\":\"Copy the snapshot as-is using the same CMK\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Copy the snapshot to the destination region and specify a CMK in the destination region to re-encrypt the snapshot\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"You cannot copy encrypted RDS snapshots across regions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Copy the snapshot unencrypted and re-encrypt later in the destination region\",\"isCorrect\":false}]","explanation":"## Correct Answer\nB. When copying an encrypted RDS snapshot to another region, you must specify a CMK in the destination region to re-encrypt the snapshot there. Copying with the same CMK is only possible if that CMK exists in the destination region. Copying encrypted snapshots across regions is supported, and the destination region must have a CMK to re-encrypt during the copy.\n\n## Why Other Options Are Wrong\n- A: The destination region must have a CMK that can decrypt and re-encrypt; otherwise copy fails.\n- C: Cross-region copy of encrypted snapshots is supported.\n- D: Re-encrypting after the copy is possible, but you still must perform a destination-region CMK-based re-encryption during the copy process.\n\n## Key Concepts\n- Cross-region snapshot copy\n- KMS CMK in destination region\n- Encryption at rest for RDS snapshots\n\n## Real-World Application\n- Enables DR planning with encrypted backups across regions while maintaining key management boundaries.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","KMS","Aurora","DR","Database Security","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"database-security","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:27:42.130Z","createdAt":"2026-01-12 21:27:42"},{"id":"aws-database-specialty-deployment-migration-1768189741649-0","question":"You're migrating a 5 TB on-prem MySQL database to Amazon RDS for MySQL with minimal downtime. Which approach best achieves this while preserving data consistency and minimizing downtime?","answer":"[{\"id\":\"a\",\"text\":\"Perform a one-time full backup restore to RDS and switch endpoints during a maintenance window.\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Use AWS SCT to convert the schema, then run a DMS task with full load plus CDC to migrate data while keeping the sources in sync, and cut over during a brief maintenance window.\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Migrate by exporting data to CSV and importing into RDS after downtime.\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use AWS DataSync to move data files and then replay changes after cutover.\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B provides near-zero downtime by performing a full data load via DMS's CDC-based replication and using SCT to convert the schema, allowing cutover to occur during a brief maintenance window while keeping source and target in sync.\n\n## Why Other Options Are Wrong\n- A: A one-time backup restore requires a longer maintenance window and does not keep ongoing changes synchronized.\n- C: CSV export/import is manual, error-prone, and incurs downtime during data load and reconciliation.\n- D: DataSync moves files, not the database state or incremental changes, so it cannot capture ongoing transactions.\n\n## Key Concepts\n- AWS DMS for continuous data replication during migrations\n- AWS Schema Conversion Tool for schema compatibility\n- Cutover planning to minimize downtime\n- Zero-downtime migration strategies in relational databases\n\n## Real-World Application\nIn production migrations, combine SCT and DMS to minimize downtime, ensure schema compatibility, and perform a controlled cutover during a maintenance window.","diagram":null,"difficulty":"intermediate","tags":["AWS DMS","AWS SCT","Amazon RDS","MySQL","Migration","Terraform","certification-mcq","domain-weight-20"],"channel":"aws-database-specialty","subChannel":"deployment-migration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:49:01.650Z","createdAt":"2026-01-12 03:49:01"},{"id":"aws-database-specialty-deployment-migration-1768189741649-1","question":"For a globally distributed relational database requiring low-latency reads in two regions with fast cross-region failover and a single writer, which AWS solution best meets this requirement?","answer":"[{\"id\":\"a\",\"text\":\"RDS Cross-Region Read Replicas\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Aurora Global Database with cross-region replication\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"DynamoDB Global Tables\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"RDS Multi-AZ with cross-region replication\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Aurora Global Database provides low-latency reads across regions with a single writer per database and supports fast cross-region failover.\n\n## Why Other Options Are Wrong\n- A: RDS cross-region read replicas are read-only in the secondary region and do not provide a fast global failover solution with a single writer.\n- C: DynamoDB is a NoSQL service and does not provide a PostgreSQL-relational experience; not suitable for this workload.\n- D: RDS Multi-AZ is an in-region HA feature and does not span regions for cross-region failover.\n\n## Key Concepts\n- Aurora Global Database\n- Cross-region replication\n- Single writer architecture\n- Disaster recovery planning\n\n## Real-World Application\nUse Aurora Global Database to serve low-latency reads globally while keeping a single primary writer and enabling regional failover when needed.","diagram":null,"difficulty":"intermediate","tags":["Aurora Global Database","Amazon RDS","PostgreSQL","Cross-Region Replication","Disaster Recovery","certification-mcq","domain-weight-20"],"channel":"aws-database-specialty","subChannel":"deployment-migration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:49:02.038Z","createdAt":"2026-01-12 03:49:02"},{"id":"aws-database-specialty-deployment-migration-1768189741649-2","question":"An organization plans to migrate a transactional PostgreSQL workload from on-premises to AWS and expects highly variable traffic. Which AWS service provides automatic compute scaling with PostgreSQL compatibility while minimizing cost?","answer":"[{\"id\":\"a\",\"text\":\"RDS for PostgreSQL with provisioned instances\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Aurora PostgreSQL with Serverless\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"RDS for PostgreSQL with read replicas in multiple regions\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"DynamoDB\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption B is correct because Aurora PostgreSQL with Serverless automatically scales compute capacity to match variable workloads and is compatible with PostgreSQL.\n\n## Why Other Options Are Wrong\n- A: Provisioned RDS requires manual sizing and does not automatically scale with traffic.\n- C: Read replicas do not handle compute scaling for the primary write workload and are not a scaling solution.\n- D: DynamoDB is a NoSQL service and not PostgreSQL-compatible.\n\n## Key Concepts\n- Aurora Serverless for PostgreSQL\n- Automatic compute scaling\n- PostgreSQL compatibility in Aurora\n\n## Real-World Application\nFor workloads with unpredictable spikes, use Aurora Serverless to minimize costs while maintaining compatibility with PostgreSQL applications.","diagram":null,"difficulty":"intermediate","tags":["Aurora Serverless","Amazon RDS","PostgreSQL","Terraform","certification-mcq","domain-weight-20"],"channel":"aws-database-specialty","subChannel":"deployment-migration","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T03:49:02.463Z","createdAt":"2026-01-12 03:49:02"},{"id":"q-1074","question":"Scenario: A global time-series platform ingests 1M events/hour in us-west-2; dashboards in eu-central-1 and ap-southeast-2 need sub-200ms reads on the latest window. Data must be immutable for 90 days for compliance. Compare DynamoDB Global Tables with DAX vs Aurora PostgreSQL Global Database with cross-region backups. Provide topology, replication, PITR/backup plans, and RPO/RTO targets?","answer":"Choose DynamoDB Global Tables in three regions (us-west-2, eu-central-1, ap-southeast-2) with DAX caching per region and multi-region writes. Enable PITR for 35 days and S3 immutable archives for 90 d","explanation":"## Why This Is Asked\n\nTests cross-region replication, latency trade-offs, and DR design between NoSQL and relational engines.\n\n## Key Concepts\n- Global Tables vs Global Database replication\n- Read latency and consistency models\n- PITR and cross-region backups\n- Archival and compliance (S3 Object Lock)\n\n## Code Example\n\n```javascript\n// Example: pseudo-endpoint selection logic for region failover\n```\n\n## Follow-up Questions\n- How would you validate RPO/RTO in a simulated outage?\n- What monitoring would you implement to detect replication lag across regions?","diagram":"flowchart TD\nA[Ingest] --> B[Global Tables: us-west-2, eu-central-1, ap-southeast-2]\nB --> C[DAX per region]\nA --> D[S3 immutable archive (90d)]\nC --> E[Dashboards in region]","difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:33:34.955Z","createdAt":"2026-01-12T21:33:34.955Z"},{"id":"q-1131","question":"**Hybrid Analytics Path for Multiregion Aurora**\n\nYou're running an Aurora PostgreSQL OLTP cluster with tenant isolation via RLS in us-east-1. A regulatory BI team in eu-west-1 requires near real-time analytics with masked PII. Design a hybrid analytics path using Aurora Global Database for OLTP replicas and a CDC-based analytic store (Redshift or DynamoDB+Lambda) in eu-west-1. Describe data flow, masking strategy, encryption, failover, and how to meet RPO 5s and RTO 60s, including cost considerations?","answer":"Run OLTP in Aurora PostgreSQL with RLS isolation in us-east-1. Replicate via Aurora Global Database to eu-west-1. Ingest CDC to a masked analytics store (Redshift or DynamoDB) in eu-west-1; apply per-","explanation":"## Why This Is Asked\nTests cross-region replication, hybrid OLTP/OLAP, security, and DR.\n\n## Key Concepts\n- Aurora Global Database, RLS, CDC, masking, cross-region KMS, hot failover\n- DR: RPO 5s, RTO 60s\n- Cost considerations: hot standby vs on-demand\n\n## Code Example\n```javascript\n// AWS CLI example (conceptual)\naws dms create-replication-task --replication-task-identifier cbd-task --source-endpoint-arn <src> --target-endpoint-arn <tgt> --migration-type full-load-and-cdc\n```\n\n## Follow-up Questions\n- How would you validate masking correctness without exposing PII?\n- What metrics indicate replication lag violations and how to remediate?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Goldman Sachs","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:22:46.568Z","createdAt":"2026-01-13T01:22:46.568Z"},{"id":"q-1279","question":"In a multi-tenant SaaS on AWS, run a single Aurora PostgreSQL cluster with per-tenant schemas and RLS to isolate data. An analytics team in eu-west-1 requires cross-tenant BI with masked PII in near real-time dashboards. Design a cost-aware architecture that delivers masking, auditing, and SLA, comparing per-tenant schemas in a single cluster vs separate clusters per tenant. Include data flow, backup, and failover?","answer":"Adopt a hybrid: maintain one Aurora PostgreSQL cluster with per-tenant schemas and RLS for isolation; expose masked analytic views for BI from a dedicated eu-west-1 read replica. Use a CDC pipeline to","explanation":"## Why This Is Asked\nThis question probes practical multi-tenant isolation, cross-region analytics, and governance trade-offs in AWS databases.\n\n## Key Concepts\n- Row-level security and per-tenant schemas\n- Cross-region BI with masked analytics\n- CDC pipelines to analytics stores\n- Audit, backup (PITR), and cost governance\n- Single-cluster vs multi-cluster trade-offs\n\n## Code Example\n```sql\n-- Enable RLS on a tenant table\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_rls ON orders\n  USING (tenant_id = current_setting('my.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you implement masking for PII in the analytics store without leaking through cached results?\n- How would you monitor latency, replication lag, and cost to meet SLA?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Hugging Face","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:44:04.097Z","createdAt":"2026-01-13T07:44:04.097Z"},{"id":"q-1303","question":"In a multi-tenant SaaS using Aurora PostgreSQL with Global Database spanning us-west-2 and us-east-1, tenants must have isolated data access and BI dashboards must mask PII in real time. Propose an end-to-end design using per-tenant RLS, dynamic masking for BI, and a separate analytics store fed by CDC (DMS/Debezium). Include cross-region DR with RPO <5s and RTO <60s, data flow, encryption, backups, and a concrete sizing plan (replicas, window, network)?","answer":"Leverage Aurora PostgreSQL with per-tenant RLS and dynamic BI masking, plus a CDC pipeline (DMS/Debezium) feeding a dedicated analytics store (Redshift or DynamoDB+ Lambda) in the secondary region. Us","explanation":"## Why This Is Asked\nTests ability to architect multi-tenant isolation, real-time masking, and cross-region DR.\n\n## Key Concepts\n- Aurora PostgreSQL with Global Database\n- Row-Level Security and dynamic masking\n- CDC pipelines (DMS/Debezium)\n- Analytics stores (Redshift, DynamoDB)\n- DR targets (RPO/RTO), encryption, backups\n\n## Code Example\n```javascript\n-- SQL for RLS policy (illustrative)\nALTER TABLE events ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON events\n  USING (tenant_id = current_setting('app.tenant_id')::int)\n  WITH CHECK (tenant_id = current_setting('app.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you test tenant isolation in the analytics path?\n- What changes if BI dashboards must also support cross-tenant rollups?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T08:50:50.803Z","createdAt":"2026-01-13T08:50:50.803Z"},{"id":"q-851","question":"Two-region OLTP SaaS with a single writer in us-east-1 and read replicas in eu-west-1. Compare Aurora Global Database (PostgreSQL) vs DynamoDB Global Tables for this workload: latency targets, consistency model, failover behavior, and cost. Which approach would you pick and why, and what concrete configuration (replica count, failover window, write routing) would you implement to meet RTO < 60s and RPO < 5s?","answer":"Choose Aurora Global Database (PostgreSQL) with a single writer in us-east-1 and one or more read replicas in eu-west-1. It preserves transactional invariants with asynchronous cross-region replicatio","explanation":"## Why This Is Asked\nThis question probes understanding of cross-region OLTP replication choices, consistency, failover, and cost. It contrasts HTAP-like needs with strict ACID guarantees in real-world deployments.\n\n## Key Concepts\n- Aurora Global Database vs DynamoDB Global Tables trade-offs\n- Single-writer constraint and cross-region replication lag\n- RTO/RPO targets, failover orchestration, PITR\n\n## Code Example\n```javascript\naws rds create-global-database --global-database-name my-globaldb --source-db-cluster-identifier mydbcluster\n```\n```\n\n## Follow-up Questions\n- How would you monitor replication lag and what alerts would you set?\n- How would you handle schema migrations with zero downtime across regions?\n","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:32:32.498Z","createdAt":"2026-01-12T13:32:32.498Z"},{"id":"q-871","question":"Migration plan: An OLTP app runs on Aurora PostgreSQL provisioned; traffic is bursty; you want to evaluate Aurora Serverless v2. Provide a concrete plan to migrate, including: (1) start/stop criteria and scaling configuration; (2) handling of long-running transactions and prepared statements; (3) how to keep reads consistent during scaling; (4) testing approach for failover/RTO targets; (5) cost considerations and potential pitfalls with Serverless v2?","answer":"Plan a phased migration to Aurora Serverless v2 from provisioned instances. Use min_capacity 0.5 and max_capacity 16, disable auto_pause initially, route traffic through RDS Proxy, and validate long-r","explanation":"## Why This Is Asked\nServerless migrations are common; evaluate trade-offs.\n\n## Key Concepts\n- Aurora Serverless v2\n- scaling policies\n- transaction semantics\n- prepared statements\n- RDS Proxy\n- failover testing\n\n## Code Example\n```javascript\n// Aurora Serverless v2 config (example)\nconst auroraConfig = {\n  engine: 'aurora-postgresql',\n  scale: { min_capacity: 0.5, max_capacity: 16, auto_pause: false }\n};\n```\n\n## Follow-up Questions\n- How would you monitor connection pool usage during scaling?\n- What are Serverless v2 limitations with prepared statements or long-running queries?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T13:53:18.115Z","createdAt":"2026-01-12T13:53:18.115Z"},{"id":"q-895","question":"Your multi-region SaaS needs an audit-friendly cross-tenant analytics store with writes transactional in us-east-1 and analytics queries in eu-west-1 under GDPR. Compare Aurora PostgreSQL Global Database vs DynamoDB Global Tables for this workload, focusing on transactional integrity, analytics capability, PITR/retention, cross-region latency, and cost. Recommend a concrete configuration (writer region, replica counts, PITR window, tenant isolation, ETL approach) to meet RPO 15 minutes and RTO 1 hour?","answer":"Aurora PostgreSQL Global Database best meets cross-region transactional integrity with SQL analytics, in a GDPR context. Put writer in us-east-1, two read replicas in eu-west-1; enable PITR 30 days; r","explanation":"## Why This Is Asked\nTests a candidate's ability to balance transactional integrity, cross-region DR, and analytics in a regulated multi-tenant environment.\n\n## Key Concepts\n- Aurora Global Database vs DynamoDB Global Tables\n- PITR, RPO/RTO targets, GDPR/tenant isolation\n- ETL paths to analytics stores (Redshift/Data Lake)\n\n## Code Example\n```javascript\n// Pseudo: configure a DMS task to replicate from us-east-1 to eu-west-1\nconst task = await dms.createReplicationTask({ ... });\n```\n\n## Follow-up Questions\n- How would you handle schema changes across regions without downtime?\n- What telemetry would you collect to validate RPO/RTO in production?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Slack","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:36:01.445Z","createdAt":"2026-01-12T14:36:01.445Z"},{"id":"q-956","question":"For a real-time fraud graph application needing sub-100ms neighbor lookups across two AWS regions, compare Amazon Neptune Global Database with DynamoDB (using graph patterns and DAX) for this workload. Writer region us-east-1; readers in eu-west-1; assess graph traversal latency, consistency guarantees, failover behavior, and total cost. Provide a concrete setup (cluster engine and size, replica counts, PITR window, backup schedule, and network/config) to meet an RPO of 5s and an RTO of 60s?","answer":"Choose Neptune Global Database for graph-centric queries. It provides cross-region replication with near real-time reads; DynamoDB+DAX is weaker for complex traversals. Recommend a primary cluster in ","explanation":"## Why This Is Asked\nDiscusses cross-region graph DB choices and DR readiness in practice.\n\n## Key Concepts\n- Neptune Global Database vs DynamoDB/DAX trade-offs\n- Graph traversals, latency budgets, consistency models\n- Cross-region failover, PITR, backups, and cost\n\n## Code Example\n```javascript\n// Illustrative AWS CLI usage (not executed here)\naws neptune create-global-cluster --global-cluster-name FraudGraphGlobal --engine neptune\n```\n\n## Follow-up Questions\n- How would you monitor replication lag and graph query latency?\n- What tests validate RPO/RTO under regional failure?\n","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","NVIDIA","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T16:42:36.355Z","createdAt":"2026-01-12T16:42:36.355Z"},{"id":"q-964","question":"You run an Amazon RDS PostgreSQL in **us-east-1** with automated backups. A regional outage blocks access from that region. How would you achieve **RPO ≤ 60s** and **RTO ≤ 15 minutes** by restoring to **eu-west-1**? Compare cross-region read replicas, backup copy, and Aurora Global Database, and outline concrete steps, knobs, and caveats?","answer":"Prefer Aurora Global Database for true cross-region DR with <60s RPO and <15m RTO. If constrained to RDS PostgreSQL, copy automated backups to eu-west-1 and create a read replica there; promote replic","explanation":"## Why This Is Asked\nDR planning across AWS regions is a core skill. This question tests understanding of RPO/RTO, replication guarantees, and the trade-offs between RDS Cross-Region Replicas, snapshot copying, and Aurora Global Database.\n\n## Key Concepts\n- RPO vs RTO and replication lag\n- Cross-region DR options: RDS read replicas, snapshot copy, Aurora Global DB\n- Failover orchestration and DNS routing\n\n## Code Example\n```javascript\n// AWS CLI example: copy a snapshot to another region\naws rds copy-db-snapshot --source-db-snapshot-identifier arn:aws:rds:us-east-1:123456789012:snapshot:mydb-2026-01-01 --target-db-snapshot-identifier eu-west-1-mydb-2026-01-01 --source-region us-east-1 --region eu-west-1\n\n// Restore a DB instance from the cross-region snapshot\naws rds restore-db-instance-from-db-snapshot --db-instance-identifier eu-west-1-mydb-restored --db-snapshot-identifier eu-west-1-mydb-2026-01-01\n```\n\n## Follow-up Questions\n- How would you automate the failover and DNS switch?\n- What monitoring would you put in place to detect lag and test RPO/RTO?","diagram":"flowchart TD\n A[Source: RDS us-east-1] --> B{Strategy}\n B --> C[Aurora Global Database]\n B --> D[Cross-region backups + EU replica]\n C --> E[Fast RTO, low RPO]\n D --> F[Longer RPO, slower failover]","difficulty":"beginner","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T17:26:08.106Z","createdAt":"2026-01-12T17:26:08.106Z"},{"id":"aws-database-specialty-management-operations-1768217010401-0","question":"A multinational e-commerce application runs a production RDS MySQL instance in us-east-1 with Multi-AZ and automated backups. A regional disaster takes us-east-1 offline and you must meet an RTO of 15 minutes and an RPO under 5 minutes by running your DR workload in us-west-2. Which approach provides the best cross-region disaster recovery with the stated RPO?","answer":"[{\"id\":\"a\",\"text\":\"Enable Multi-AZ deployment in the primary region\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Create a cross-region read replica in us-west-2 and promote it on failover\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Rely on automated backups and perform a manual restore in the secondary region\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use DynamoDB Global Tables for this workload\",\"isCorrect\":false}]","explanation":"## Correct Answer\nCreate a cross-region read replica in the DR region and promote it on failover. This provides a dedicated DR copy in another region with asynchronous replication, enabling a controlled cutover within the target RTO and meeting the required RPO if replication lag is within acceptable limits.\n\n## Why Other Options Are Wrong\n- A: Multi-AZ improves high availability within a single region, not cross-region disaster recovery.\n- C: Automated backups in the primary region do not automatically provide a ready-to-use DR instance in another region within the required RPO.\n- D: DynamoDB Global Tables apply to NoSQL workloads, not a relational RDS MySQL workload.\n\n## Key Concepts\n- Cross-region read replicas\n- Disaster recovery (DR) planning\n- RPO and RTO considerations\n\n## Real-World Application\n- Enable cross-region replica in us-west-2 for the primary RDS instance in us-east-1.\n- Regularly test failover by promoting the replica and routing traffic to the DR region.\n- Monitor replication lag and adjust instance sizes to meet latency targets.","diagram":null,"difficulty":"intermediate","tags":["RDS","CrossRegion","HA","DR","MySQL","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"management-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:23:30.402Z","createdAt":"2026-01-12 11:23:30"},{"id":"aws-database-specialty-management-operations-1768217010401-1","question":"An RDS PostgreSQL instance in us-east-1 experiences a user deleting a row at 12:03 UTC. You have 7 days of automated backups and point-in-time recovery (PITR) enabled. To recover only the deleted row without affecting other data, which approach is most appropriate?","answer":"[{\"id\":\"a\",\"text\":\"Restore the most recent backup to a new instance and export the deleted row, then import into production\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Perform a PITR to 12:03 UTC on a new temporary instance and copy the row back to production\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Perform a PITR to 12:00 UTC on a new temporary instance and copy the row back to production\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Use a read replica to retrieve the deleted row and apply it to production\",\"isCorrect\":false}]","explanation":"## Correct Answer\nPerform a PITR to 12:00 UTC on a new temporary instance and copy the row back to production. Restoring to a moment before the deletion allows you to recover the specific row in isolation and then apply it to the production database without rolling forward transactions past the deletion.\n\n## Why Other Options Are Wrong\n- A: Restoring the most recent backup may miss the interval before deletion and would require broader data reconciliation.\n- B: Restoring exactly to 12:03 UTC would reintroduce the deleted row at the moment of deletion, not recover it.\n- D: A read replica is typically read-only; it cannot be used to selectively recover a single deleted row without additional steps.\n\n## Key Concepts\n- Point-in-time recovery (PITR)\n- Time-window-based recovery strategy\n- Row-level recovery methods in relational DBs\n\n## Real-World Application\n- Initiate PITR to a timestamp before the incident on a temporary instance.\n- Extract the missing row (e.g., via a bounded SELECT) and apply an INSERT/UPDATE to the production database within a controlled window.\n- Validate data integrity after the patch and monitor for any replication lag or conflicts.","diagram":null,"difficulty":"intermediate","tags":["RDS","PITR","PostgreSQL","Backups","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"management-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:23:30.780Z","createdAt":"2026-01-12 11:23:31"},{"id":"aws-database-specialty-management-operations-1768217010401-2","question":"You run an RDS instance encrypted with a customer-managed CMK in AWS KMS. You need to rotate the encryption keys with minimal downtime. Which approach is recommended?","answer":"[{\"id\":\"a\",\"text\":\"Create a new encrypted copy of the DB using a new CMK and switch over\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Enable automatic rotation of the CMK used to encrypt the RDS instance\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Disable encryption, re-create the DB with a new key, and re-import data\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Take a cross-region encrypted snapshot and restore in the target region\",\"isCorrect\":false}]","explanation":"## Correct Answer\nEnable automatic rotation of the CMK used to encrypt the RDS instance. AWS KMS key rotation for CMKs rotates the cryptographic material without requiring downtime, and RDS-encrypted storage will transparently use the new data keys as keys are rotated.\n\n## Why Other Options Are Wrong\n- A: Re-creating a new encrypted copy can be done, but it incurs downtime and effort; automatic CMK rotation avoids this.\n- C: Decrypting and re-encrypting would require downtime and data movement.\n- D: Cross-region restoration does not address in-place key rotation and adds unnecessary complexity.\n\n## Key Concepts\n- KMS CMK rotation\n- In-place encryption key management\n- Transparent re-encryption with CMK rotation\n\n## Real-World Application\n- Enable automatic CMK rotation on the CMK used by the RDS encryption.\n- Validate that disk encryption and backup/restore paths continue to work post-rotation.\n- Plan a verification run to confirm no performance impact during rotation.","diagram":null,"difficulty":"intermediate","tags":["RDS","KMS","CMK","Encryption","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"management-operations","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T11:23:31.140Z","createdAt":"2026-01-12 11:23:31"},{"id":"aws-database-specialty-monitoring-troubleshooting-1768243396885-0","question":"During business hours, an RDS for MySQL instance is experiencing rising query latency and higher ReadIOPS. Which action most directly helps you identify the root cause of the slowdown?","answer":"[{\"id\":\"a\",\"text\":\"Enable Enhanced Monitoring and inspect OS-level processes during peak load\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Increase the instance size immediately to mitigate latency\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Enable Performance Insights and analyze top SQL by wait events and database load\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Create a new read replica to offload reads\",\"isCorrect\":false}]","explanation":"## Correct Answer\nC. Enabling Performance Insights and analyzing top SQL by wait events and database load directly identifies the statements and wait events causing the latency, enabling targeted tuning. \n\n## Why Other Options Are Wrong\n- A: Enhanced Monitoring shows OS metrics but doesn’t readily reveal the slow SQL causing latency. \n- B: Increasing instance size may mitigate latency but does not diagnose the root cause. \n- D: A read replica offloads reads but does not diagnose or fix slow queries on the primary.\n\n## Key Concepts\n- Performance Insights\n- Top SQL by wait events\n- Database load visualization\n\n## Real-World Application\n- Use Performance Insights during peak traffic to pinpoint expensive queries, then optimize those queries or indexes to reduce latency during busy periods.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","Performance Insights","Monitoring","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"monitoring-troubleshooting","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:43:16.886Z","createdAt":"2026-01-12 18:43:17"},{"id":"aws-database-specialty-monitoring-troubleshooting-1768243396885-1","question":"A DynamoDB table is experiencing throttling during peak hours despite autoscaling being enabled. Which change most directly prevents throttling during traffic spikes?","answer":"[{\"id\":\"a\",\"text\":\"Enable DynamoDB Auto Scaling to adjust RCU/WCU during spikes\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Increase RCU/WCU provisioned capacity manually\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Switch table to On-Demand Capacity Mode\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Enable DAX caching for reads\",\"isCorrect\":false}]","explanation":"## Correct Answer\nC. Switching DynamoDB to On-Demand Capacity Mode eliminates throttling during unpredictable spikes by removing the need to provision capacity in advance. \n\n## Why Other Options Are Wrong\n- A: Auto Scaling helps but does not guarantee no throttling during sudden, extreme spikes. \n- B: Manually increasing provisioned capacity may still fall short during surges. \n- D: DAX helps with hot reads but does not address write throttling or general throughput throttling scenarios.\n\n## Key Concepts\n- DynamoDB capacity modes (Provisioned vs On-Demand)\n- Throttling behavior during spikes\n- Autoscaling considerations\n\n## Real-World Application\n- For unpredictable workloads, migrate to On-Demand or combine autoscaling with capacity planning to maintain steady performance during promo events.","diagram":null,"difficulty":"intermediate","tags":["AWS","DynamoDB","Throughput","CloudWatch","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"monitoring-troubleshooting","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:43:17.545Z","createdAt":"2026-01-12 18:43:17"},{"id":"aws-database-specialty-monitoring-troubleshooting-1768243396885-2","question":"An RDS instance uses gp2 storage and experiences high write latency during peak loads. CloudWatch shows BurstBalance trending toward 0%. Which action would most effectively address this issue in the long term?","answer":"[{\"id\":\"a\",\"text\":\"Move storage to Provisioned IOPS (io1/io2) or gp3 with higher baseline IOPS\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase the DB instance CPU size\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Add a read replica to distribute write traffic\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable Multi-AZ failover for better write performance\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. gp2 bursts share a limited pool of IOPS; when BurstBalance is exhausted, write latency increases. Switching to a storage class with higher consistent IOPS (io1/io2) or gp3 mitigates this long-term.\n\n## Why Other Options Are Wrong\n- B: CPU size affects processing but does not address storage IOPS bottlenecks. \n- C: Adding a read replica does not reduce write latency on the primary. \n- D: Multi-AZ improves availability, not raw write throughput.\n\n## Key Concepts\n- EBS gp2 BurstBalance mechanics\n- Provisioned IOPS vs bursty GP storage\n- Long-term throughput planning\n\n## Real-World Application\n- When bursts deplete, migrate to higher-IOPS storage to maintain write performance during peak events.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","EBS","GP2/GP3","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"monitoring-troubleshooting","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:43:18.017Z","createdAt":"2026-01-12 18:43:18"},{"id":"aws-database-specialty-monitoring-troubleshooting-1768243396885-3","question":"Your application opens a large number of concurrent connections to an Aurora MySQL DB instance, leading to connection storms and resource contention. Which AWS solution best reduces connection churn and improves scalability?","answer":"[{\"id\":\"a\",\"text\":\"Increase the max_connections parameter on the DB instance\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Scale to a larger DB instance class\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Deploy and configure RDS Proxy to pool connections\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Enable Performance Insights to optimize queries\",\"isCorrect\":false}]","explanation":"## Correct Answer\nC. RDS Proxy provides connection pooling, reducing the overhead of establishing connections and smoothing spikes, which mitigates connection storms. \n\n## Why Other Options Are Wrong\n- A: Simply increasing max_connections does not manage pool efficiency and can worsen resource contention. \n- B: Scaling up may help but does not address churn or pooling. \n- D: Performance Insights helps diagnose queries but not connection management.\n\n## Key Concepts\n- Connection pooling strategies\n- RDS Proxy capabilities\n- Concurrency handling\n\n## Real-World Application\n- Implement RDS Proxy for high-traffic apps to stabilize connection utilization and improve overall DB throughput.","diagram":null,"difficulty":"intermediate","tags":["AWS","RDS","Aurora","RDS Proxy","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"monitoring-troubleshooting","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:43:18.179Z","createdAt":"2026-01-12 18:43:18"},{"id":"aws-database-specialty-monitoring-troubleshooting-1768243396885-4","question":"In an Aurora Global Database deployment, a secondary region reports replication lag measured by the AuroraReplicaLag metric. What is the best initial step to diagnose and reduce lag?","answer":"[{\"id\":\"a\",\"text\":\"Check the AuroraReplicaLag metric on the secondary region and investigate cross-region network latency\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Immediately scale up the secondary region's instance class\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Pause and resume replication to reset lag\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Migrate replication via DMS to reinitialize cross-region replication\",\"isCorrect\":false}]","explanation":"## Correct Answer\nA. The first step is to observe the AuroraReplicaLag metric in the secondary region and assess cross-region network latency and throughput to identify root causes of lag. \n\n## Why Other Options Are Wrong\n- B: Scaling may help if resources are insufficient, but it isn’t the first diagnostic step. \n- C: Pausing/resuming replication is not a supported or effective remedy for Aurora Global Database lag. \n- D: Reinitializing replication via DMS is disruptive and unnecessary for typical lag scenarios.\n\n## Key Concepts\n- AuroraReplicaLag metric\n- Global Database replication topology\n- Cross-region network considerations\n\n## Real-World Application\n- Use lag metrics to guide whether to optimize network routes, adjust write workload, or scale the primary/secondary resources to reduce replication delays.","diagram":null,"difficulty":"intermediate","tags":["AWS","Aurora","Global Database","CloudWatch","certification-mcq","domain-weight-18"],"channel":"aws-database-specialty","subChannel":"monitoring-troubleshooting","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:43:18.356Z","createdAt":"2026-01-12 18:43:18"},{"id":"aws-database-specialty-workload-requirements-1768148665414-0","question":"An ecommerce retailer runs an OLTP workload on Amazon RDS for PostgreSQL. During business hours, analytics queries run on the same database, causing CPU spikes and higher latency for transactions. What is the most appropriate architecture to allow analytics without impacting OLTP performance?","answer":"[{\"id\":\"a\",\"text\":\"Create RDS Read Replicas and route analytics queries to the replicas\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Enable Multi-AZ with synchronous replication to the primary for better write durability\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Move analytics to a separate Amazon Redshift cluster and keep OLTP unchanged\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Enable Amazon Aurora Global Database with cross-region writes to support analytics\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct choice is a) Create RDS Read Replicas and route analytics queries to the replicas. This offloads read-heavy analytics to replicas, reducing contention on the primary and preserving OLTP latency.\n\n## Why Other Options Are Wrong\n- b) While Multi-AZ improves availability, it does not offload analytics or reduce OLTP contention, so it doesn't address the primary issue.\n- c) Moving analytics to Redshift is viable but involves ETL and separate data stores; it adds latency and complexity for integrated OLTP analytics and may not preserve transactional latency.\n- d) Aurora Global Database focuses on cross-region disaster recovery and global writes; it isn't the most suitable path to offload analytics from a single primary region.\n\n## Key Concepts\n- OLTP vs OLAP separation\n- Read replicas for read-heavy workloads\n- Asynchronous replication latency considerations\n\n## Real-World Application\n- Implement read replicas for analytics workloads and direct BI queries to replicas; monitor replication lag and ensure ETL pipelines keep data synced to reporting schemas.","diagram":null,"difficulty":"intermediate","tags":["RDS","Aurora","Redshift","OLTP","OLAP","AWS","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T16:24:25.415Z","createdAt":"2026-01-11 16:24:25"},{"id":"aws-database-specialty-workload-requirements-1768148665414-1","question":"Which AWS database option best supports a global, low-latency relational workload with cross-region disaster recovery and minimal downtime?","answer":"[{\"id\":\"a\",\"text\":\"DynamoDB Global Tables\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"RDS with cross-region read replicas\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Amazon Aurora Global Database\",\"isCorrect\":true},{\"id\":\"d\",\"text\":\"Redshift\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct choice is c) Amazon Aurora Global Database. It provides a relational, ACID-compliant engine with a primary region and read-only replicas in other regions for low-latency reads and DR support across regions. It minimizes downtime by enabling rapid disaster recovery and continuity.\n\n## Why Other Options Are Wrong\n- a) DynamoDB Global Tables are multi-region and fast for non-relational workloads but not ideal for traditional relational OLTP schemas.\n- b) RDS with cross-region read replicas can provide some DR but lacks the seamless global read-localization and scale of Aurora Global Database.\n- d) Redshift is analytic-oriented and not suitable for OLTP workload requirements.\n\n## Key Concepts\n- Aurora Global Database for cross-region DR\n- Relational OLTP with global reads\n- Recovery time objectives in multi-region setups\n\n## Real-World Application\n- Use Aurora Global Database to serve global customers with near-local reads; plan failover strategies and DR testing across regions.","diagram":null,"difficulty":"intermediate","tags":["Aurora","RDS","DynamoDB","Global Tables","DR","AWS","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T16:24:25.761Z","createdAt":"2026-01-11 16:24:26"},{"id":"aws-database-specialty-workload-requirements-1768148665414-2","question":"A DynamoDB table stores user session events with partition key userId and sort key eventTime. A small subset of users generate events at very high rates, creating hot partitions that throttle throughput. Which design change best distributes load and avoids hot partitions?","answer":"[{\"id\":\"a\",\"text\":\"Add a random prefix (shard) to the partition key to distribute traffic across partitions\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Increase provisioned throughput on the existing partition key to handle bursts\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Migrate to a relational database to manage hot partitions more effectively\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Introduce DynamoDB Streams to throttle write throughput\",\"isCorrect\":false}]","explanation":"## Correct Answer\na) Add a random prefix (shard) to the partition key to distribute traffic across partitions. This mitigates hot partitions by spreading writes across multiple partition keys.\n\n## Why Other Options Are Wrong\n- b) Simply increasing throughput on the same partition key does not solve uneven distribution and keeps the hot-partition risk.\n- c) Migrating to a relational database does not inherently fix partition-level throttling in DynamoDB and adds unnecessary complexity.\n- d) DynamoDB Streams does not throttle writes and is intended for change data capture, not load distribution.\n\n## Key Concepts\n- DynamoDB partition keys and hot partitions\n- Horizontal sharding strategies\n- Throughput management in DynamoDB\n\n## Real-World Application\n- Implement sharding at the partition key layer when encountering hot keys; monitor partition-level utilization and adjust shard count as needed.","diagram":null,"difficulty":"intermediate","tags":["DynamoDB","PartitionKey","Sharding","Throughput","AWS","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-11T16:24:26.103Z","createdAt":"2026-01-11 16:24:26"},{"id":"aws-database-specialty-workload-requirements-1768279496760-0","question":"A global e-commerce application must serve single-digit millisecond reads across customers in Europe and Asia while keeping a single writable region for financial transactions. Which AWS design best satisfies these requirements while providing robust disaster recovery for the relational workload?","answer":"[{\"id\":\"a\",\"text\":\"RDS MySQL with cross-region asynchronous read replicas in multiple regions\",\"isCorrect\":false},{\"id\":\"b\",\"text\":\"Aurora Global Database with a single primary region and fast cross-region reads\",\"isCorrect\":true},{\"id\":\"c\",\"text\":\"Separate RDS instances in each region with application-level reconciliation\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Migrate to DynamoDB for relational workload\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is **B** because Aurora Global Database provides a single writable region with fast cross-region replicas in multiple regions, enabling low-latency global reads and seamless disaster recovery for relational workloads. It avoids complex cross-region synchronization and data drift for writes.\n\n## Why Other Options Are Wrong\n- **A**: Cross-region read replicas do not offer the same global write consistency guarantees and can incur higher failover latency for a globally distributed relational workload.\n- **C**: Regional deployments with manual data reconciliation introduce drift risk and operational complexity.\n- **D**: DynamoDB is a NoSQL store; migrating a relational workload to it would require a substantial data-model rewrite and still might not meet SQL query needs.\n\n## Key Concepts\n- Aurora Global Database\n- Multi-region disaster recovery\n- Relational workload design and latency considerations\n\n## Real-World Application\n- Use when designing globally distributed relational apps needing fast reads and robust DR across regions.","diagram":null,"difficulty":"intermediate","tags":["Aurora","RDS","GlobalDatabase","MultiRegion","DR","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:44:56.761Z","createdAt":"2026-01-13 04:44:57"},{"id":"aws-database-specialty-workload-requirements-1768279496760-1","question":"An on-premises MySQL database must be migrated to AWS with minimal downtime and ongoing replication until cutover. Which approach best achieves this?","answer":"[{\"id\":\"a\",\"text\":\"AWS DMS with ongoing CDC and a controlled cutover\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Take a nightly RDS snapshot and restore in the target region\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Use AWS Glue to transform and move data during a traditional bulk load\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Use DataSync to migrate live database files directly\",\"isCorrect\":false}]","explanation":"## Correct Answer\nThe correct option is **A** because AWS DMS supports ongoing Change Data Capture (CDC) alongside an initial load, allowing near-zero downtime during cutover and continuous replication of changes from on-prem to AWS.\n\n## Why Other Options Are Wrong\n- **B**: Nightly snapshots cause prolonged downtime and do not support continuous replication.\n- **C**: Glue is primarily for ETL and batch processing, not real-time DB migrations.\n- **D**: DataSync moves files and blobs, not live database transactions or replication streams.\n\n## Key Concepts\n- AWS DMS, CDC, homogeneous vs heterogeneous migrations\n- Cutover strategies and minimal downtime\n\n## Real-World Application\n- Use during lift-and-shift migrations where business continuity is critical during transition.","diagram":null,"difficulty":"intermediate","tags":["DMS","CDC","Migration","RDS","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:44:57.144Z","createdAt":"2026-01-13 04:44:57"},{"id":"aws-database-specialty-workload-requirements-1768279496760-2","question":"A data analytics workload processes petabytes of structured data with complex BI queries. Which AWS service is most suitable for scalable, columnar storage and analytical workloads?","answer":"[{\"id\":\"a\",\"text\":\"Amazon Redshift\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"Amazon RDS for PostgreSQL\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"DynamoDB\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Amazon Aurora PostgreSQL\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption **A** (Amazon Redshift) is the best fit for petabyte-scale analytics due to its columnar storage, massively parallel processing, and suitability for complex BI workloads.\n\n## Why Other Options Are Wrong\n- **B**: RDS PostgreSQL is row-oriented and not optimized for large-scale analytical scans.\n- **C**: DynamoDB is a NoSQL key-value store not designed for complex analytical queries across large datasets.\n- **D**: Aurora PostgreSQL is OLTP-focused; while capable, it doesn’t match Redshift’s analytics-optimized architecture.\n\n## Key Concepts\n- Columnar storage and MPP in Redshift\n- OLAP vs OLTP suitability\n\n## Real-World Application\n- Use Redshift for data warehousing, BI dashboards, and large-scale analytics workloads.","diagram":null,"difficulty":"intermediate","tags":["Redshift","OLAP","DataWarehouse","BI","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:44:57.489Z","createdAt":"2026-01-13 04:44:57"},{"id":"aws-database-specialty-workload-requirements-1768279496760-3","question":"A microservices-based application requires sub-millisecond latency with high write throughput for a key-value store. Which AWS service is most suitable for this workload?","answer":"[{\"id\":\"a\",\"text\":\"DynamoDB\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"RDS\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Aurora\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"S3\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption **A** (DynamoDB) is the canonical choice for a high-throughput key-value store with low latency at scale, offering predictable microsecond to millisecond latency and flexible throughput models.\n\n## Why Other Options Are Wrong\n- **B**: RDS is a traditional relational store with higher latency under extreme throughput, not optimized for key-value access at sub-millisecond speeds.\n- **C**: Aurora provides relational features with high throughput but is not the ideal KV store for ultra-low latency key-value patterns.\n- **D**: S3 is an object store with higher latency for random reads/writes and not suitable as a primary KV store.\n\n## Key Concepts\n- DynamoDB throughput models (provisioned/on-demand)\n- Latency and scalability for KV workloads\n\n## Real-World Application\n- Use DynamoDB for session storage, feature flags, or user state in microservices requiring fast, predictable latency.","diagram":null,"difficulty":"intermediate","tags":["DynamoDB","NoSQL","KVStore","Throughput","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:44:57.614Z","createdAt":"2026-01-13 04:44:57"},{"id":"aws-database-specialty-workload-requirements-1768279496760-4","question":"A social networking app requires flexible graph traversals to recommend connections and content. Which AWS service is best suited for graph workloads with efficient traversal queries?","answer":"[{\"id\":\"a\",\"text\":\"Amazon Neptune\",\"isCorrect\":true},{\"id\":\"b\",\"text\":\"DynamoDB\",\"isCorrect\":false},{\"id\":\"c\",\"text\":\"Amazon Redshift\",\"isCorrect\":false},{\"id\":\"d\",\"text\":\"Amazon RDS\",\"isCorrect\":false}]","explanation":"## Correct Answer\nOption **A** (Amazon Neptune) is purpose-built for graph workloads and supports graph query languages (Gremlin, SPARQL) that enable efficient traversals essential for social graph recommendations.\n\n## Why Other Options Are Wrong\n- **B**: DynamoDB is not optimized for graph traversals or complex path queries.\n- **C**: Redshift is a columnar analytical engine, not a graph database, making graph traversals inefficient.\n- **D**: RDS is a general relational DB; while it can model graphs, Neptune provides specialized graph capabilities and performance.\n\n## Key Concepts\n- Graph databases and traversal queries\n- Neptune’s labeled-property graph and RDF models\n\n## Real-World Application\n- Use Neptune to implement friend recommendations, mutual connections, and social graph analytics at scale.","diagram":null,"difficulty":"intermediate","tags":["Neptune","GraphDB","Gremlin","Cypher","certification-mcq","domain-weight-26"],"channel":"aws-database-specialty","subChannel":"workload-requirements","sourceUrl":null,"videos":null,"companies":null,"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T04:44:57.739Z","createdAt":"2026-01-13 04:44:57"}],"subChannels":["database-security","deployment-migration","general","management-operations","monitoring-troubleshooting","workload-requirements"],"companies":["Amazon","Apple","Coinbase","Databricks","Goldman Sachs","Google","Hugging Face","IBM","LinkedIn","Lyft","Meta","Microsoft","NVIDIA","Robinhood","Slack","Snap","Snowflake","Square","Tesla","Two Sigma","Uber"],"stats":{"total":33,"beginner":1,"intermediate":30,"advanced":2,"newThisWeek":33}}