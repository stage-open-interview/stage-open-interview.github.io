{"questions":[{"id":"q-1074","question":"Scenario: A global time-series platform ingests 1M events/hour in us-west-2; dashboards in eu-central-1 and ap-southeast-2 need sub-200ms reads on the latest window. Data must be immutable for 90 days for compliance. Compare DynamoDB Global Tables with DAX vs Aurora PostgreSQL Global Database with cross-region backups. Provide topology, replication, PITR/backup plans, and RPO/RTO targets?","answer":"Choose DynamoDB Global Tables in three regions (us-west-2, eu-central-1, ap-southeast-2) with DAX caching per region and multi-region writes. Enable PITR for 35 days and S3 immutable archives for 90 d","explanation":"## Why This Is Asked\n\nTests cross-region replication, latency trade-offs, and DR design between NoSQL and relational engines.\n\n## Key Concepts\n- Global Tables vs Global Database replication\n- Read latency and consistency models\n- PITR and cross-region backups\n- Archival and compliance (S3 Object Lock)\n\n## Code Example\n\n```javascript\n// Example: pseudo-endpoint selection logic for region failover\n```\n\n## Follow-up Questions\n- How would you validate RPO/RTO in a simulated outage?\n- What monitoring would you implement to detect replication lag across regions?","diagram":"flowchart TD\nA[Ingest] --> B[Global Tables: us-west-2, eu-central-1, ap-southeast-2]\nB --> C[DAX per region]\nA --> D[S3 immutable archive (90d)]\nC --> E[Dashboards in region]","difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T21:33:34.955Z","createdAt":"2026-01-12T21:33:34.955Z"},{"id":"q-1131","question":"**Hybrid Analytics Path for Multiregion Aurora**\n\nYou're running an Aurora PostgreSQL OLTP cluster with tenant isolation via RLS in us-east-1. A regulatory BI team in eu-west-1 requires near real-time analytics with masked PII. Design a hybrid analytics path using Aurora Global Database for OLTP replicas and a CDC-based analytic store (Redshift or DynamoDB+Lambda) in eu-west-1. Describe data flow, masking strategy, encryption, failover, and how to meet RPO 5s and RTO 60s, including cost considerations?","answer":"Run OLTP in Aurora PostgreSQL with RLS isolation in us-east-1. Replicate via Aurora Global Database to eu-west-1. Ingest CDC to a masked analytics store (Redshift or DynamoDB) in eu-west-1; apply per-","explanation":"## Why This Is Asked\nTests cross-region replication, hybrid OLTP/OLAP, security, and DR.\n\n## Key Concepts\n- Aurora Global Database, RLS, CDC, masking, cross-region KMS, hot failover\n- DR: RPO 5s, RTO 60s\n- Cost considerations: hot standby vs on-demand\n\n## Code Example\n```javascript\n// AWS CLI example (conceptual)\naws dms create-replication-task --replication-task-identifier cbd-task --source-endpoint-arn <src> --target-endpoint-arn <tgt> --migration-type full-load-and-cdc\n```\n\n## Follow-up Questions\n- How would you validate masking correctness without exposing PII?\n- What metrics indicate replication lag violations and how to remediate?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Goldman Sachs","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:22:46.568Z","createdAt":"2026-01-13T01:22:46.568Z"},{"id":"q-1279","question":"In a multi-tenant SaaS on AWS, run a single Aurora PostgreSQL cluster with per-tenant schemas and RLS to isolate data. An analytics team in eu-west-1 requires cross-tenant BI with masked PII in near real-time dashboards. Design a cost-aware architecture that delivers masking, auditing, and SLA, comparing per-tenant schemas in a single cluster vs separate clusters per tenant. Include data flow, backup, and failover?","answer":"Adopt a hybrid: maintain one Aurora PostgreSQL cluster with per-tenant schemas and RLS for isolation; expose masked analytic views for BI from a dedicated eu-west-1 read replica. Use a CDC pipeline to","explanation":"## Why This Is Asked\nThis question probes practical multi-tenant isolation, cross-region analytics, and governance trade-offs in AWS databases.\n\n## Key Concepts\n- Row-level security and per-tenant schemas\n- Cross-region BI with masked analytics\n- CDC pipelines to analytics stores\n- Audit, backup (PITR), and cost governance\n- Single-cluster vs multi-cluster trade-offs\n\n## Code Example\n```sql\n-- Enable RLS on a tenant table\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_rls ON orders\n  USING (tenant_id = current_setting('my.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you implement masking for PII in the analytics store without leaking through cached results?\n- How would you monitor latency, replication lag, and cost to meet SLA?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Hugging Face","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T07:44:04.097Z","createdAt":"2026-01-13T07:44:04.097Z"},{"id":"q-1303","question":"In a multi-tenant SaaS using Aurora PostgreSQL with Global Database spanning us-west-2 and us-east-1, tenants must have isolated data access and BI dashboards must mask PII in real time. Propose an end-to-end design using per-tenant RLS, dynamic masking for BI, and a separate analytics store fed by CDC (DMS/Debezium). Include cross-region DR with RPO <5s and RTO <60s, data flow, encryption, backups, and a concrete sizing plan (replicas, window, network)?","answer":"Leverage Aurora PostgreSQL with per-tenant RLS and dynamic BI masking, plus a CDC pipeline (DMS/Debezium) feeding a dedicated analytics store (Redshift or DynamoDB+ Lambda) in the secondary region. Us","explanation":"## Why This Is Asked\nTests ability to architect multi-tenant isolation, real-time masking, and cross-region DR.\n\n## Key Concepts\n- Aurora PostgreSQL with Global Database\n- Row-Level Security and dynamic masking\n- CDC pipelines (DMS/Debezium)\n- Analytics stores (Redshift, DynamoDB)\n- DR targets (RPO/RTO), encryption, backups\n\n## Code Example\n```javascript\n-- SQL for RLS policy (illustrative)\nALTER TABLE events ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON events\n  USING (tenant_id = current_setting('app.tenant_id')::int)\n  WITH CHECK (tenant_id = current_setting('app.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you test tenant isolation in the analytics path?\n- What changes if BI dashboards must also support cross-tenant rollups?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Lyft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T08:50:50.803Z","createdAt":"2026-01-13T08:50:50.803Z"},{"id":"q-1314","question":"Design a GDPR-compliant data deletion strategy for a multi-region Aurora PostgreSQL Global Database that uses us-east-1 as the writer and replicas in multiple regions. How would you implement Right-to-Erasure for tenant data, propagate deletions with minimal latency, handle referential integrity, and maintain an auditable trail while meeting RPO/RTO targets? Include practical steps and trade-offs?","answer":"Adopt soft deletes with a tenant-scoped deleted_at flag and propagate deletions via logical replication or DMS CDC to all regions. Enforce FK cascades in the origin region only; keep a purge window (e","explanation":"## Why This Is Asked\nData privacy and cross-region deletion are common but tricky with global databases. The answer tests practical strategies for timing, integrity, and audit.\n\n## Key Concepts\n- GDPR deletion rights and retention policies\n- Aurora Global Database cross-region replication\n- Soft vs hard deletes and foreign-key considerations\n- Auditability and compliance tracking\n\n## Code Example\n```\nALTER TABLE tenants ADD COLUMN deleted_at TIMESTAMPTZ;\nCREATE VIEW active_items AS SELECT * FROM items WHERE deleted_at IS NULL;\nUPDATE items SET deleted_at = NOW() WHERE id = ?;\n```\n\n## Follow-up Questions\n- How would you test cross-region deletion latency and audit integrity?\n- How to handle legal-hold scenarios and purge timing?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hashicorp","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T11:28:34.774Z","createdAt":"2026-01-13T11:28:34.776Z"},{"id":"q-1382","question":"In an Aurora PostgreSQL Global Database with a writer in us-east-1 and replicas in eu-west-1, a financial balance update must be atomic across regions. Explain why cross-region distributed transactions are not supported and propose a practical pattern to achieve atomic-ish behavior with low latency, including data flow, failover handling, and cost/latency trade-offs?","answer":"Cross-region atomicity isn’t supported: Aurora Global Database uses asynchronous cross-region replication, so a two-stage commit across regions can’t be guaranteed. A practical pattern is a single-wri","explanation":"## Why This Is Asked\n\nTests understanding of cross-region replication limits in Aurora Global Database and practical patterns to achieve atomic-like behavior without distributed transactions.\n\n## Key Concepts\n\n- Aurora Global Database replication model and its eventual cross-region consistency\n- ACID vs eventual consistency in multi-region setups\n- Single-writer boundary, event-driven replication, compensating actions, and idempotent processing\n\n## Code Example\n\n```javascript\n// Pseudo-implementation: single-writer boundary with event emission\nasync function updateBalance(accountId, delta) {\n  // Begin in writer region\n  await beginLocalTx();\n  await updateLocalBalance(accountId, delta);\n  await commitLocalTx();\n  // Publish event to eu-west-1 for downstream update\n  await publishEvent({ accountId, delta, txnId: generateId() });\n}\n```\n\n## Follow-up Questions\n\n- How would you test this pattern under network partitions?\n- What latency and cost implications arise from cross-region event streams and reconciliation?","diagram":"flowchart TD\n  A[Client Request] --> B[Coordinator (us-east-1)]\n  B --> C[Prepare: Update primary balance]\n  C --> D[Commit: Emit event to eu-west-1]\n  D --> E[Apply delta in eu-west-1]\n  E --> F[Response to client]","difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T14:45:15.419Z","createdAt":"2026-01-13T14:45:15.419Z"},{"id":"q-1441","question":"In Aurora PostgreSQL (us-east-1) with tenant isolation via RLS, design a near real-time analytics path for a eu-west-1 consumer needing masked data and <5s lag. Use Aurora Global Database for OLTP and a CDC store in eu-west-1 (Redshift or DynamoDB+Lambda). Explain data flow, masking/encryption, consistency, failover, and cost with concrete config sketches?","answer":"Use Aurora Global Database to keep a writer in us-east-1 with cross-region replicas; route analytic reads to eu-west-1 via DMS CDC to Redshift or DynamoDB+Lambda. Implement per-tenant masking in the p","explanation":"## Why This Is Asked\nTests ability to design cross-region analytics paths, balancing data masking, security, latency, failover, and cost for a regulated multi-tenant SaaS using AWS DB services.\n\n## Key Concepts\n- Aurora Global Database cross-region replication\n- CDC options: DMS vs Debezium vs native\n- Data masking: per-tenant with RLS and column-level masking\n- Encryption: KMS, TLS, envelope encryption\n- Failure scenarios: failover/failback and RPO/RTO\n- Cost trade-offs: Redshift vs DynamoDB, compute/storage\n\n## Code Example\n```javascript\n// Example: publication for CDC (PostgreSQL)\nALTER SYSTEM SET wal_level = logical;\nCREATE PUBLICATION analytics_pub FOR TABLE orders, customers;\n```\n\n## Follow-up Questions\n- How would you validate lag and data completeness end-to-end?\n- How would you enforce per-tenant masking in the analytics store?","diagram":"flowchart TD\n  A[OLTP writer us-east-1] --> B[Global DB replica us-east-1]\n  A --> C[DMS CDC in eu-west-1? (for analytics store)]\n  B --> D[Analytics store in eu-west-1]\n  D --> E[Analytics consumer in eu-west-1]","difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:03:20.591Z","createdAt":"2026-01-13T17:03:20.592Z"},{"id":"q-1447","question":"You run a high-volume ecommerce on Aurora PostgreSQL Global Database with a single writer in us-east-1 and read replicas in eu-west-1. An outage in us-east-1 requires routing writes to eu-west-1 within 60s while ensuring RPO<5s, idempotent writes, and no double billing. Design the architecture and concrete configuration (replica counts, failover procedures, analytics CDC path, masking, PITR) to meet these goals?","answer":"Use Aurora Global Database with a hot-standby writable clone in eu-west-1 for DR so writes can continue within 60s of a us-east outage. Route writes to the EU writer via Route 53 health checks; keep a","explanation":"## Why This Is Asked\n\nAssesses cross-region DR planning for a mission-critical OLTP with minimal data loss and downtime, plus robust write-idempotency and analytics integration.\n\n## Key Concepts\n\n- Aurora Global Database architecture and cross-region failover considerations\n- DR targets: RPO < 5s, RTO < 60s with hot-standby writable clone\n- Idempotent write patterns: transaction IDs, upserts to prevent double billing\n- CDC to analytics (DMS) and data masking at read time\n- PITR retention planning and backup strategies\n\n## Code Example\n\n```sql\n-- idempotent upsert pattern for an order\nINSERT INTO orders (order_id, customer_id, amount, txn_id)\nVALUES (:order_id, :customer_id, :amount, :txn_id)\nON CONFLICT (order_id) DO UPDATE\n  SET amount = EXCLUDED.amount, updated_at = NOW(), txn_id = EXCLUDED.txn_id;\n```\n\n## Follow-up Questions\n\n- How would you validate RPO/RTO in production and what telemetry would you collect?\n- How would you test and verify the cross-region failover without impacting live traffic?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T17:43:10.564Z","createdAt":"2026-01-13T17:43:10.564Z"},{"id":"q-1550","question":"In a two-region deployment with a single writer in us-east-1 and analytic reads in eu-west-1, design a CDC pipeline to keep a near real-time analytic store updated within 5 seconds of commits, while masking per-tenant data and enforcing encryption at rest and in transit. Compare AWS DMS, Debezium/Kafka, and native Aurora logical replication, and provide concrete configuration (engine, instance types, replica counts, PITR, KMS keys, VPC endpoints, and network topology) to meet RPO 5s and RTO 60s?","answer":"Deploy an Aurora Global Database with the primary writer in us-east-1 and implement a CDC pipeline using AWS DMS to maintain a near real-time analytic store in eu-west-1. Configure DMS with change data capture to stream committed changes within 5 seconds, applying per-tenant data masking and enforcing encryption both in transit and at rest. AWS DMS provides operational simplicity with managed infrastructure, meeting the RPO of 5 seconds and RTO of 60 seconds while ensuring data security and compliance requirements.","explanation":"## Why This Is Asked\nTests ability to design cross-region CDC pipelines with strict latency targets while implementing tenant-level data masking and comprehensive encryption. It also evaluates knowledge of live replication technologies and their operational trade-offs.\n\n## Key Concepts\n- Change data capture latency across AWS regions\n- Cross-region data movement options (AWS DMS vs Debezium/Kafka vs native Aurora logical replication)\n- Per-tenant data masking and encryption strategies\n- Network topology and VPC endpoint configuration\n- Disaster recovery objectives: RPO/RTO, PITR, and failover procedures\n\n## Code Example\n```sql\n-- On writer: publish all tables for CDC\nCREATE PUBLICATION cdc_pub FOR ALL TABLES;\n```\n\n## Follow-up Questions\n- How would you handle failover scenarios and ensure data consistency?\n- What monitoring and alerting would you implement for the CDC pipeline?\n- How would you optimize costs while maintaining the 5-second latency requirement?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","DoorDash","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:30:05.991Z","createdAt":"2026-01-13T21:38:49.169Z"},{"id":"q-1747","question":"You run a multi-region SaaS with Aurora PostgreSQL as the OLTP in us-east-1 and read replicas in eu-west-1. A new requirement enforces strict per-tenant data isolation via Row-Level Security and data residency controls for backups. Design a concrete approach: RLS policy skeletons for all tables, session-based tenant_id from authentication, per-tenant restore strategy, cross-region backup copy schedule, and a testing/validation plan that proves no cross-tenant leakage under burden. Include concrete config knobs and a sample policy?","answer":"Implement per-tenant isolation with Postgres Row-Level Security on all tables, driven by a session tenant_id set from the user’s JWT. Use a separate role per tenant and policies like: USING (tenant_id","explanation":"## Why This Is Asked\nTests ability to implement robust data isolation with RLS, ensure data residency through cross-region snapshots, and design test plans for high-concurrency workloads.\n\n## Key Concepts\n- PostgreSQL Row-Level Security (RLS) on all tables\n- session context via SET myapp.tenant_id from authentication\n- cross-region Aurora backups and snapshot copies\n- PITR windows and data residency/compliance\n- tenant onboarding/offboarding and data retention controls\n\n## Code Example\n```sql\n-- Example RLS skeleton\nCREATE POLICY tenant_rls ON users\nFOR ALL USING (tenant_id = current_setting('myapp.tenant_id')::int)\nWITH CHECK (tenant_id = current_setting('myapp.tenant_id')::int);\n\nALTER TABLE users ENABLE ROW LEVEL SECURITY;\nALTER TABLE users FORCE ROW LEVEL SECURITY;\n```\n\n## Follow-up Questions\n- How would you automate per-tenant onboarding to ensure tenant_id is set on every DB connection?\n- What metrics would you monitor to detect leakage or policy misconfigurations?","diagram":"flowchart TD\n  C[Client Request] --> APP[App Layer]\n  APP --> U[Aurora US-East OLTP]\n  U --> EU[EU-West Replica]\n  APP --> S[Snapshot Copy to EU-West]\n  S --> D[Data Residency & Compliance]\n  D --> M[Monitoring & Alerts]","difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T09:37:30.426Z","createdAt":"2026-01-14T09:37:30.428Z"},{"id":"q-1775","question":"In a multi-region Aurora PostgreSQL Global Database setup (writer in us-east-1; readers in eu-west-1 and ap-south-1) with strict tenant-level data residency, design a scalable architecture that provides sub-50ms reads for hot paths in each region while ensuring RPO <= 5s and RTO <= 60s, using row-level security and a CDC-based analytic store; explain data partitioning, access controls, and failover strategy, plus cost trade-offs?","answer":"Use region-scoped tenant sharding with Postgres RLS to enforce residency; writer in us-east-1 with Aurora Global Database and replicas in eu-west-1/ap-south-1 for sub-50ms regional reads. Use CDC from","explanation":"## Why This Is Asked\nAssesses ability to architect cross-region, residency-bound databases with real-time analytics, balancing latency, consistency, and cost.\n\n## Key Concepts\n- Aurora Global Database and cross-region replication\n- Row-Level Security (RLS) for tenant isolation\n- CDC-based analytic store (Redshift/S3+Glue)\n- RPO/RTO design and failover strategy\n- Cost trade-offs: replication, egress, storage, and analytics\n\n## Code Example\n```sql\n-- Example RLS policy\nCREATE POLICY tenant_rls ON orders\n  USING (tenant_id = current_setting('myapp.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you validate RPO/RTO in a disaster scenario?\n- What strategies minimize cross-region CDC costs while preserving freshness?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:39:05.726Z","createdAt":"2026-01-14T10:39:05.727Z"},{"id":"q-1882","question":"Design a cross-region analytic path for a SaaS app with an Aurora PostgreSQL OLTP cluster in us-east-1 as the single writer and regional read replicas in us-west-2. The goal: near real-time analytics with masked PII in the analytics store. Propose a CDC-based pipeline (Aurora CDC, DMS, Debezium, or Kinesis) to load into Redshift or DynamoDB in us-west-2, choose masking strategy, encryption, data freshness target (RPO), failover plan, and cost considerations. Include concrete config choices (instance types, retention, network, and security)?","answer":"Use Aurora Global Database to replicate OLTP across regions, and implement CDC from the writer to a masked analytics store in the remote region (Redshift via DMS or DynamoDB via Kinesis). Mask PII at ","explanation":"## Why This Is Asked\nAssess cross-region data flow, masking, and cost-aware analytics separation. It tests practical CDC choices, DR timing, and security implications.\n\n## Key Concepts\n- Aurora Global Database, CDC, DMS/Debezium, Redshift Spectrum, DynamoDB Streams\n- Data masking, encryption at rest/in transit, RPO/RTO targets\n- Cross-region networking and cost optimization\n\n## Code Example\n```sql\n-- Example masking policy sketch (pseudo)\nCREATE POLICY mask_ssn ON customers\nAS (SELECT mask_ssn(ssn) AS ssn_masked);\n```\n\n## Follow-up Questions\n- How would you test RPO/RTO guarantees in this pipeline?\n- What are failure modes if CDC lag increases beyond threshold?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Snowflake","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T15:42:33.696Z","createdAt":"2026-01-14T15:42:33.696Z"},{"id":"q-2139","question":"You run OLTP in Aurora PostgreSQL us-east-1 and need near real-time BI in us-west-2. Design a CDC pipeline: enable a dedicated logical replication slot in Aurora; use DMS in CDC mode to stream changes to Redshift in us-west-2 via a staging S3 bucket; apply PII masking at BI layer; enable PITR and cross-region backups; target end-to-end latency ~2s and RTO <60s. Include data flow, failover, and cost trade-offs?","answer":"Enable a dedicated Aurora logical replication slot in us-east-1; route changes through DMS in CDC mode to Redshift in us-west-2 (via S3 staging). Use MERGE-based upserts for idempotence. Apply PII mas","explanation":"## Why This Is Asked\nTests real-time cross-region CDC design with security, masking, and failover.\n\n## Key Concepts\n- Aurora logical replication\n- AWS DMS CDC\n- Redshift ingestion from S3\n- Data masking and RLS\n- PITR and cross-region backups\n- Cost trade-offs\n\n## Code Example\n```json\n{\n  \"DMSTaskSettings\": {\"TargetTablePrepMode\":\"DO_NOTHING\",\"FullLoadTask\": false,\"CdcInsertsOnly\": false}\n}\n```\n\n## Follow-up Questions\n- How to handle schema changes downstream?\n- What metrics validate 2s latency under load?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:19:48.906Z","createdAt":"2026-01-15T04:19:48.906Z"},{"id":"q-2163","question":"A multi-region SaaS app needs sub-20ms reads for hot tenants across three continents, writes allowed in any region, and PCI-DSS data residency constraints. Design a data-layer using AWS: compare Aurora PostgreSQL Global Database with DynamoDB Global Tables plus CDC to an analytics store, including consistency, DR, backups, and concrete configurations to meet RPO 5s and RTO 60s?","answer":"Option A: Aurora PostgreSQL Global Database with a single writer in us-east-1 and regional read replicas in eu-west-1 and ap-south-1; 7-day PITR, KMS encryption, TLS, and Route 53 latency routing to m","explanation":"## Why This Is Asked\nTests cross-region DR, read latency, and data residency decisions for AWS database services.\n\n## Key Concepts\n- Aurora Global Database constraints: single writer, cross-region replication\n- DynamoDB Global Tables: multi-region writes with replication and eventual consistency trade-offs\n- Data residency and PCI-DSS: encryption (at rest/in transit), KMS keys, IAM access controls\n- DR planning: RPO/RTO targets, PITR, backups, failover orchestration\n\n## Code Example\n```javascript\n// CDK sketch for core Aurora Global DB settings (conceptual)\nconst glb = new aurora.GlobalDatabase(this, 'GlobalDb', {\n  writerRegion: 'us-east-1',\n  regions: ['us-east-1', 'eu-west-1', 'ap-south-1'],\n  engine: aurora.PostgresEngineVersion.VER_13_6,\n});\n```\n\n## Follow-up Questions\n- If latency budgets tighten, how would you restructure reads?\n- How would you monitor cross-region replication lag and auto-tune write routing?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:41:48.135Z","createdAt":"2026-01-15T05:41:48.135Z"},{"id":"q-2211","question":"Two-region, multi-tenant SaaS with strict data residency: EU tenants' data must stay in EU, US tenants' data in US. Needs sub-15ms reads for hot tenants, writes in any region, and cross-region analytics. Compare Aurora PostgreSQL Global Database vs DynamoDB Global Tables with analytics options; provide a concrete topology, replication, backups, and DR plan to meet RPO 5s and RTO 60s, including per-tenant routing and residency enforcement?","answer":"Use Aurora PostgreSQL Global Database across EU and US with per-tenant residency enforced by Row-Level Security; hot reads served from a regional cache (DynamoDB or MemoryDB) and analytics from a data","explanation":"## Why This Is Asked\nTests ability to design multi-region, tenancy-aware architectures with DR and residency constraints; assesses knowledge of Aurora Global Database, RLS, read caching, analytics integration, and cost/latency trade-offs.\n\n## Key Concepts\n- Data residency with row-level security (RLS) in PostgreSQL\n- Aurora Global Database topology across regions\n- Cross-region replication and WAL shipping mechanics\n- Read caching and analytics integration (DynamoDB/MemoryDB, S3/Glue)\n\n## Code Example\n```sql\n-- Enable per-tenant isolation via RLS\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON orders\n  USING (tenant_id = current_setting('app.tenant_id')::int);\n```\n\n## Follow-up Questions\n- How would you validate DR failover latency and RPO under peak load?\n- What monitoring and cost controls would you implement to maintain SLAs across regions?","diagram":"flowchart TD\n  EU_Tenant[EU region data store] --> EU_Reads[EU read replicas]\n  US_Tenant[US region data store] --> US_Reads[US read replicas]\n  EU_Reads --> AnalyticsEU[Analytics]\n  US_Reads --> AnalyticsUS[Analytics]\n  AnalyticsEU --> Lake[Analytics Lake]\n  AnalyticsUS --> Lake","difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","Salesforce","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T07:40:12.465Z","createdAt":"2026-01-15T07:40:12.466Z"},{"id":"q-2248","question":"A SaaS news site logs user events at ~1000 writes/s, with dashboards needing sub-200 ms reads. Data is append-only; hot data kept 30 days, archived after. Compare DynamoDB (on-demand, TTL, GSI) vs Aurora PostgreSQL (partitioned tables, read replicas) for this workload. Provide concrete configs (primary key design, indexes, TTL window, backup/retention, RPO/RTO) and justify choice?","answer":"Recommended: DynamoDB on-demand with a TTL attribute of 90 days, primary key (user_id HASH, event_ts RANGE), optional GSI on event_type for analytics, enable Streams for CDC, and PITR. Data is append-","explanation":"## Why This Is Asked\nTests ability to pick between a serverless NoSQL and a relational option for high-velocity, append-only data with TTL and analytics needs. Assesses data modeling, retention strategy, and DR considerations.\n\n## Key Concepts\n- Append-only data modeling for time-series-like logs\n- Throughput modes: on-demand vs provisioned capacity\n- TTL data pruning and retention windows\n- Read latency strategies (indexes, caching, Streams)\n- Backups, PITR, and DR differences between DynamoDB and Aurora\n\n## Code Example\n```sql\nCREATE TABLE event_logs (\n  user_id VARCHAR(36) NOT NULL,\n  event_ts BIGINT NOT NULL,\n  payload JSON,\n  PRIMARY KEY (user_id, event_ts)\n) PARTITION BY RANGE (event_ts);\n```\n\n```bash\naws dynamodb create-table --table-name UserEventLog \\\n  --attribute-definitions AttributeName=user_id,AttributeType=S AttributeName=event_ts,AttributeType=N \\\n  --key-schema AttributeName=user_id,KeyType=HASH AttributeName=event_ts,KeyType=RANGE \\\n  --billing-mode PAY_PER_REQUEST \\\n  --stream-specification StreamEnabled=true,StreamViewType=NEW_IMAGE\n```\n\n```bash\naws dynamodb update-time-to-live --table-name UserEventLog --time-to-live-specification Enabled=true,AttributeName=ttl\n```\n\n## Follow-up Questions\n- What are the trade-offs of not using TTL on DynamoDB for hot data?\n- How would you validate data durability and latency under bursty traffic?","diagram":null,"difficulty":"beginner","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Square","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:04:51.962Z","createdAt":"2026-01-15T09:04:51.962Z"},{"id":"q-2268","question":"Your app uses AWS Lambda functions that connect to an RDS PostgreSQL instance; during bursts, you see many connections causing failures. How would you leverage Amazon RDS Proxy to manage connections, configure auth, and ensure stable performance? Include what to monitor, any pricing considerations, and a basic setup outline?","answer":"Use RDS Proxy to pool connections and decouple Lambda bursts from DB connection limits. Create a private RDS Proxy in the same VPC, target the RDS instance, store credentials in Secrets Manager, attac","explanation":"This question tests practical understanding of connection management for serverless apps. Candidates should cite: where to place the proxy, how credentials are supplied, how to route Lambda traffic, what to monitor (proxy health, connection count, latency), and cost trade-offs. They should mention security group rules and multi-AZ considerations.","diagram":null,"difficulty":"beginner","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Goldman Sachs","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:50:32.865Z","createdAt":"2026-01-15T09:50:32.865Z"},{"id":"q-2320","question":"Scenario: A SaaS app stores event data in DynamoDB and must retain 90 days in DynamoDB and archive older events to S3 for analytics. Design a pragmatic lifecycle: data model, TTL, export to S3, per-tenant/year/month partitioning, storage class selection, and validation plan to ensure data integrity and queryability via Athena. Include concrete steps and considerations for cost?","answer":"Two-tier approach: keep hot data for 90 days in DynamoDB with TTL on expireAt; archive older events to S3 per tenant/year/month using DynamoDB export-to-S3 (or Glue), compress to Parquet, and apply li","explanation":"## Why This Is Asked\nValidates practical data lifecycle design, cost awareness, and AWS integration.\n\n## Key Concepts\n- DynamoDB TTL on expireAt\n- DynamoDB export-to-S3 or Glue-based export\n- S3 Lifecycle and storage classes (Standard/IA/Glacier)\n- Per-tenant partitioning in S3 (tenant/year/month)\n- Athena/Glue for analytics on archived data\n\n## Code Example\n```javascript\n// TTL example snippet (not production-ready)\nconst item = { tenantId:'T1', eventId:'E123', ts:Date.now(), expireAt: Math.floor(Date.now()/1000) + 90*24*3600 };\n```\n\n## Follow-up Questions\n- How would you adjust for cross-region access to archived data?\n- What are trade-offs of online TTL vs scheduled archive windows?","diagram":null,"difficulty":"beginner","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T11:49:47.720Z","createdAt":"2026-01-15T11:49:47.720Z"},{"id":"q-2331","question":"For a multi-tenant SaaS app storing per-tenant PII with EU/US data residency, compare Aurora PostgreSQL with Row-Level Security (RLS) vs DynamoDB with per-tenant access patterns. Explain schema design, replication strategy, consistency, DR, and cost. Provide a concrete configuration to meet RPO < 5s and RTO < 60s, including region placement, replica counts, backup windows, and key management?","answer":"Recommended approach: Aurora PostgreSQL Global Database with per-tenant RLS and cross-region replicas. Writer in us-east-1; replicas in eu-west-1 and ap-south-1; enable PITR for 35 days and automated ","explanation":"## Why This Is Asked\nEvaluates RBAC at the database layer, cross-region data residency, and trade-offs between relational and NoSQL models in multi-tenant SaaS.\n\n## Key Concepts\n- Row-Level Security (RLS) in PostgreSQL\n- DynamoDB conditional writes and per-tenant design\n- Cross-region replication, PITR, and RTO/RPO targets\n\n## Code Example\n\n```javascript\nCREATE POLICY tenant_access ON users\nFOR ALL USING (tenant_id = current_setting('tenants.current')::int);\n```\n\n## Follow-up Questions\n- How would you audit per-tenant data access across regions?\n- What metrics would you monitor to detect RBAC misconfigurations?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["MongoDB","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T13:07:36.036Z","createdAt":"2026-01-15T13:07:36.036Z"},{"id":"q-2411","question":"In an IoT platform, 100k writes/sec of time-series data arrive from devices worldwide. You must ingest region-locally with sub-20ms latency, perform near real-time analytics in a separate region, retain 30 days of data, and ensure PCI-DSS residency. Compare AWS Timestream, DynamoDB Global Tables with a CDC pipeline, and an Aurora-based time-series schema. Propose architecture, data model, retention, DR, and concrete config to meet RPO 5s and RTO 60s?","answer":"DynamoDB Global Tables with regional writes, plus DynamoDB Streams feeding a near-real-time analytics path (Kinesis→S3/Redshift). For PCI residency, encrypt at rest with a restricted KMS CMK and stric","explanation":"## Why This Is Asked\nTests multi-region data ingestion, analytics separation, retention, and compliance trade-offs with real workloads.\n\n## Key Concepts\n- DynamoDB Global Tables, DynamoDB Streams, KMS\n- Data residency for PCI-DSS, PITR, TTL\n- Time-series patterns, retention strategies, and analytics integration\n\n## Code Example\n```bash\n# Create a Global Table (example flag values for illustration)\naws dynamodb create-global-table --table-name IoTTimeSeries \\\n  --region us-east-1 us-west-2 eu-west-1\n```\n\n## Follow-up Questions\n- How would you validate RPO/RTO in disaster scenarios?\n- What monitoring/alerting ensures latency stays within targets?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Twitter","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T16:59:48.253Z","createdAt":"2026-01-15T16:59:48.253Z"},{"id":"q-2465","question":"An Aurora PostgreSQL cluster in us-east-1 serves 10k+ tenants via IAM database authentication. Each tenant must only access its own rows using Row-Level Security. A separate analytics workload must run against a eu-west-1 replica with data within 5 seconds of writes. Design the architecture: RLS policy and session management for per-tenant isolation, how analytics access is granted without leaking data, replication strategy (global DB vs separate KV store), backup/PITR, and a practical test plan to verify isolation and latency?","answer":"Implement RLS with per-session tenant_id set by the application, using policy USING (tenant_id = current_setting('app.tenant_id')::BIGINT) and WITH CHECK the same. Middleware sets app.tenant_id on con","explanation":"## Why This Is Asked\nTests practical RLS design, session-scoped tenant isolation, and cross-region analytics with minimal leakage.\n\n## Key Concepts\n- Row-Level Security (RLS) in Aurora PostgreSQL\n- Per-session context via current_setting()\n- IAM DB authentication integration\n- Aurora Global Database cross-region replication\n- PITR, KMS encryption, and audit logging\n\n## Code Example\n```sql\nALTER TABLE orders ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON orders\n  USING (tenant_id = current_setting('app.tenant_id')::BIGINT)\n  WITH CHECK (tenant_id = current_setting('app.tenant_id')::BIGINT);\n```\n```sql\nSET app.tenant_id = '12345';\n```\n```sql\nSET row_security = OFF; -- on analytics connection if needed for cross-tenant analytics\n```\n\n## Follow-up Questions\n- How would you validate tenant isolation under peak write latency?\n- What monitoring would you add to detect RLS bypass attempts or replication lag spikes?","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","Oracle","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:05:57.687Z","createdAt":"2026-01-15T19:05:57.687Z"},{"id":"q-2511","question":"In a globally distributed SaaS, Aurora PostgreSQL Global Database writer in us-east-1 and read replicas in eu-west-1 and ap-southeast-2. To deliver sub-50ms reads for hot tenants during peak while writes can occur anywhere, design a hybrid path using ElastiCache Redis in each region plus a cache-aside strategy. Include concrete config: DB instance classes, replica counts, Redis node types, TTL, invalidation mechanism, and a failover plan that meets RPO 5s and RTO 60s?","answer":"Use Aurora PostgreSQL Global Database with a writer in us-east-1 and cross-region replicas in eu-west-1 and ap-southeast-2. Layer in ElastiCache Redis in each region for the hot keys, cache-aside, TTL","explanation":"## Why This Is Asked\nTests ability to design multi-region data paths with both OLTP and caching to meet latency SLAs.\n\n## Key Concepts\n- Aurora Global Database cross-region replication.\n- Cache-aside strategy with ElastiCache Redis.\n- Per-region caching and invalidation messaging.\n- SLOs, RPO/RTO alignment.\n\n## Code Example\n```javascript\nasync function getUserRow(id){\n  const cached = await cache.get(`user:${id}`)\n  if(cached) return JSON.parse(cached)\n  const row = await db.query('SELECT * FROM users WHERE id=$1', [id])\n  await cache.set(`user:${id}`, JSON.stringify(row), 60)\n  return row\n}\n```\n\n## Follow-up Questions\n- How would you validate cache stampede risk and implement backpressure?\n- What are the DR implications if the writer region fails?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","MongoDB","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T20:54:14.192Z","createdAt":"2026-01-15T20:54:14.192Z"},{"id":"q-2533","question":"In a multi-region SaaS app using Aurora PostgreSQL with a single writer in us-east-1 and reads in eu-west-1 and ap-south-1, implement row-level security to restrict each tenant's data. Explain how you would design the RLS policy, index usage, and the impact on cross-region CDC via DMS or logical replication, and outline monitoring for unauthorized access. Include testing steps?","answer":"Implement PostgreSQL Row-Level Security (RLS) with per-tenant session context. Create the policy: `USING (tenant_id = current_setting('app.tenant_id')::int)` and enable RLS on the tenant table. The application must set `set_config('app.tenant_id', tenant_id, true)` at connection initialization. For cross-region replication, RLS policies propagate automatically via DMS or logical replication, but session context does not—each region must independently enforce tenant isolation. Monitor through CloudWatch metrics for RLS policy violations and audit logs using pg_audit. Validate with multi-tenant scenarios, cross-region consistency checks, and unauthorized access attempt testing.","explanation":"## Why This Is Asked\nTests ability to design secure data access patterns in multi-region Aurora environments. It combines RBAC-like row-level security with cross-region replication and monitoring, requiring understanding of policy propagation and comprehensive testing strategies.\n\n## Key Concepts\n- Row Level Security (RLS) and policy implementation in PostgreSQL/Aurora\n- Session context management via current_setting/set_config\n- Cross-region replication implications with DMS or logical replication\n- Performance optimization, audit capabilities, and failover considerations\n\n## Code Example","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Netflix","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:35:46.313Z","createdAt":"2026-01-15T21:41:50.605Z"},{"id":"q-2581","question":"Global SaaS with EU data residency: Writes in us-east-1; reads in EU must be sub-20ms; PCI-DSS data residency constraints; design a cross-region OLTP data layer and compare Aurora PostgreSQL Global Database vs DynamoDB Global Tables with CDC. Provide concrete configurations (engine/edition, instance types, replica counts, PITR window, backup cadence, KMS keys, VPC design, inter-region networking), DR plan, and how you meet RPO <5s and RTO <60s?","answer":"Design a cross-region OLTP architecture with writes in us-east-1 and EU reads under 20ms, adhering to PCI-DSS data residency requirements. Compare Aurora PostgreSQL Global Database against DynamoDB Global Tables with CDC, providing specific configurations including engine/edition, instance types, replica counts, PITR window, backup cadence, KMS keys, VPC design, and inter-region networking. Deliver a disaster recovery plan achieving RPO <5s and RTO <60s.","explanation":"## Why This Is Asked\nTests the ability to design cross-region OLTP systems under strict residency and security constraints while comparing relational global databases with NoSQL global tables, including concrete disaster recovery configurations.\n\n## Key Concepts\n- Cross-region OLTP architectures\n- Data residency and PCI-DSS compliance\n- Aurora Global Database vs DynamoDB Global Tables with CDC\n- DR metrics: RPO, RTO, PITR, backup strategies, KMS key policies\n\n## Code Example\n```javascript\n// Pseudo-CDK: define a DynamoDB global table across two regions\nconst table = new dynamodb.Table(this, 'OrderTable', {\n  partitionKey: { name: 'orderId', type: dynamodb.AttributeType.STRING },\n  billingMode: dynamodb.BillingMode.PROVISIONED,\n  readCapacity: 100,\n  writeCapacity: 50,\n  streams: dynamodb.StreamType.NEW_AND_OLD_IMAGES,\n  encryption: dynamodb.TableEncryption.AWS_MANAGED,\n  pointInTimeRecovery: true,\n  globalTables: [\n    { region: 'us-east-1' },\n    { region: 'eu-west-1' }\n  ]\n});\n```","diagram":null,"difficulty":"advanced","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","NVIDIA","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:14:31.132Z","createdAt":"2026-01-15T23:41:13.159Z"},{"id":"q-2701","question":"In Aurora PostgreSQL design per-tenant data isolation using Row-Level Security and partitioned tables for a global setup: writer in us-east-1; regional reads in eu-west-1 and ap-south-1. Propose a concrete data path and DR strategy to meet RPO 5s and RTO 60s, including instance types, backup windows, PITR, KMS, cross-region replication, and a real failover plan?","answer":"Use a single writer in us-east-1 with Aurora Global Database, partitioned tables by tenant_id, and enable RLS policies bound to a session context. Route reads to regional readers; writes hit the write","explanation":"## Why This Is Asked\n\nAssesses tenant isolation, cross-region replication, and DR under compliance constraints.\n\n## Key Concepts\n\n- Row-Level Security and partitioning for multi-tenant isolation\n- Aurora Global Database cross-region replication and write routing constraints\n- PCI-DSS and data residency, encryption with KMS, and backup strategies\n- RPO/RTO goals and failover planning\n\n## Code Example\n\n```sql\nCREATE TABLE tenants (\n  tenant_id TEXT NOT NULL,\n  data JSONB,\n  region TEXT\n);\nALTER TABLE tenants ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON tenants\n  USING (tenant_id = current_setting('app.tenant_id')::TEXT);\n```\n\n## Follow-up Questions\n\n- How would you test RLS policies at scale across regions?\n- What monitoring would you put in place to detect cross-region replication lag?","diagram":"flowchart TD\n  W[Writer in us-east-1] --> R1[Replica eu-west-1]\n  W --> R2[Replica ap-south-1]\n  R1 --> C1[(Cache layer)]\n  R2 --> C2[(Cache layer)]","difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T07:37:43.229Z","createdAt":"2026-01-16T07:37:43.230Z"},{"id":"q-851","question":"Two-region OLTP SaaS with a single writer in us-east-1 and read replicas in eu-west-1. Compare Aurora Global Database (PostgreSQL) vs DynamoDB Global Tables for this workload: latency targets, consistency model, failover behavior, and cost. Which approach would you pick and why, and what concrete configuration (replica count, failover window, write routing) would you implement to meet RTO < 60s and RPO < 5s?","answer":"Choose Aurora Global Database (PostgreSQL) with a single writer in us-east-1 and one or more read replicas in eu-west-1. It preserves transactional invariants with asynchronous cross-region replicatio","explanation":"## Why This Is Asked\nThis question probes understanding of cross-region OLTP replication choices, consistency, failover, and cost. It contrasts HTAP-like needs with strict ACID guarantees in real-world deployments.\n\n## Key Concepts\n- Aurora Global Database vs DynamoDB Global Tables trade-offs\n- Single-writer constraint and cross-region replication lag\n- RTO/RPO targets, failover orchestration, PITR\n\n## Code Example\n```javascript\naws rds create-global-database --global-database-name my-globaldb --source-db-cluster-identifier mydbcluster\n```\n```\n\n## Follow-up Questions\n- How would you monitor replication lag and what alerts would you set?\n- How would you handle schema migrations with zero downtime across regions?\n","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:32:32.498Z","createdAt":"2026-01-12T13:32:32.498Z"},{"id":"q-871","question":"Migration plan: An OLTP app runs on Aurora PostgreSQL provisioned; traffic is bursty; you want to evaluate Aurora Serverless v2. Provide a concrete plan to migrate, including: (1) start/stop criteria and scaling configuration; (2) handling of long-running transactions and prepared statements; (3) how to keep reads consistent during scaling; (4) testing approach for failover/RTO targets; (5) cost considerations and potential pitfalls with Serverless v2?","answer":"Plan a phased migration to Aurora Serverless v2 from provisioned instances. Use min_capacity 0.5 and max_capacity 16, disable auto_pause initially, route traffic through RDS Proxy, and validate long-r","explanation":"## Why This Is Asked\nServerless migrations are common; evaluate trade-offs.\n\n## Key Concepts\n- Aurora Serverless v2\n- scaling policies\n- transaction semantics\n- prepared statements\n- RDS Proxy\n- failover testing\n\n## Code Example\n```javascript\n// Aurora Serverless v2 config (example)\nconst auroraConfig = {\n  engine: 'aurora-postgresql',\n  scale: { min_capacity: 0.5, max_capacity: 16, auto_pause: false }\n};\n```\n\n## Follow-up Questions\n- How would you monitor connection pool usage during scaling?\n- What are Serverless v2 limitations with prepared statements or long-running queries?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Hugging Face","IBM","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T13:53:18.115Z","createdAt":"2026-01-12T13:53:18.115Z"},{"id":"q-895","question":"Your multi-region SaaS needs an audit-friendly cross-tenant analytics store with writes transactional in us-east-1 and analytics queries in eu-west-1 under GDPR. Compare Aurora PostgreSQL Global Database vs DynamoDB Global Tables for this workload, focusing on transactional integrity, analytics capability, PITR/retention, cross-region latency, and cost. Recommend a concrete configuration (writer region, replica counts, PITR window, tenant isolation, ETL approach) to meet RPO 15 minutes and RTO 1 hour?","answer":"Aurora PostgreSQL Global Database best meets cross-region transactional integrity with SQL analytics, in a GDPR context. Put writer in us-east-1, two read replicas in eu-west-1; enable PITR 30 days; r","explanation":"## Why This Is Asked\nTests a candidate's ability to balance transactional integrity, cross-region DR, and analytics in a regulated multi-tenant environment.\n\n## Key Concepts\n- Aurora Global Database vs DynamoDB Global Tables\n- PITR, RPO/RTO targets, GDPR/tenant isolation\n- ETL paths to analytics stores (Redshift/Data Lake)\n\n## Code Example\n```javascript\n// Pseudo: configure a DMS task to replicate from us-east-1 to eu-west-1\nconst task = await dms.createReplicationTask({ ... });\n```\n\n## Follow-up Questions\n- How would you handle schema changes across regions without downtime?\n- What telemetry would you collect to validate RPO/RTO in production?","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Slack","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:36:01.445Z","createdAt":"2026-01-12T14:36:01.445Z"},{"id":"q-956","question":"For a real-time fraud graph application needing sub-100ms neighbor lookups across two AWS regions, compare Amazon Neptune Global Database with DynamoDB (using graph patterns and DAX) for this workload. Writer region us-east-1; readers in eu-west-1; assess graph traversal latency, consistency guarantees, failover behavior, and total cost. Provide a concrete setup (cluster engine and size, replica counts, PITR window, backup schedule, and network/config) to meet an RPO of 5s and an RTO of 60s?","answer":"Choose Neptune Global Database for graph-centric queries. It provides cross-region replication with near real-time reads; DynamoDB+DAX is weaker for complex traversals. Recommend a primary cluster in ","explanation":"## Why This Is Asked\nDiscusses cross-region graph DB choices and DR readiness in practice.\n\n## Key Concepts\n- Neptune Global Database vs DynamoDB/DAX trade-offs\n- Graph traversals, latency budgets, consistency models\n- Cross-region failover, PITR, backups, and cost\n\n## Code Example\n```javascript\n// Illustrative AWS CLI usage (not executed here)\naws neptune create-global-cluster --global-cluster-name FraudGraphGlobal --engine neptune\n```\n\n## Follow-up Questions\n- How would you monitor replication lag and graph query latency?\n- What tests validate RPO/RTO under regional failure?\n","diagram":null,"difficulty":"intermediate","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","NVIDIA","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T16:42:36.355Z","createdAt":"2026-01-12T16:42:36.355Z"},{"id":"q-964","question":"You run an Amazon RDS PostgreSQL in **us-east-1** with automated backups. A regional outage blocks access from that region. How would you achieve **RPO ≤ 60s** and **RTO ≤ 15 minutes** by restoring to **eu-west-1**? Compare cross-region read replicas, backup copy, and Aurora Global Database, and outline concrete steps, knobs, and caveats?","answer":"Prefer Aurora Global Database for true cross-region DR with <60s RPO and <15m RTO. If constrained to RDS PostgreSQL, copy automated backups to eu-west-1 and create a read replica there; promote replic","explanation":"## Why This Is Asked\nDR planning across AWS regions is a core skill. This question tests understanding of RPO/RTO, replication guarantees, and the trade-offs between RDS Cross-Region Replicas, snapshot copying, and Aurora Global Database.\n\n## Key Concepts\n- RPO vs RTO and replication lag\n- Cross-region DR options: RDS read replicas, snapshot copy, Aurora Global DB\n- Failover orchestration and DNS routing\n\n## Code Example\n```javascript\n// AWS CLI example: copy a snapshot to another region\naws rds copy-db-snapshot --source-db-snapshot-identifier arn:aws:rds:us-east-1:123456789012:snapshot:mydb-2026-01-01 --target-db-snapshot-identifier eu-west-1-mydb-2026-01-01 --source-region us-east-1 --region eu-west-1\n\n// Restore a DB instance from the cross-region snapshot\naws rds restore-db-instance-from-db-snapshot --db-instance-identifier eu-west-1-mydb-restored --db-snapshot-identifier eu-west-1-mydb-2026-01-01\n```\n\n## Follow-up Questions\n- How would you automate the failover and DNS switch?\n- What monitoring would you put in place to detect lag and test RPO/RTO?","diagram":"flowchart TD\n A[Source: RDS us-east-1] --> B{Strategy}\n B --> C[Aurora Global Database]\n B --> D[Cross-region backups + EU replica]\n C --> E[Fast RTO, low RPO]\n D --> F[Longer RPO, slower failover]","difficulty":"beginner","tags":["aws-database-specialty"],"channel":"aws-database-specialty","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:26:08.106Z","createdAt":"2026-01-12T17:26:08.106Z"}],"subChannels":["general"],"companies":["Adobe","Airbnb","Amazon","Apple","Citadel","Coinbase","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hashicorp","Hugging Face","IBM","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","Oracle","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":30,"beginner":4,"intermediate":15,"advanced":11,"newThisWeek":30}}