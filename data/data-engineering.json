{"questions":[{"id":"q-1077","question":"Design a data ingestion and processing pipeline for a global ride-hailing platform that ingests 5 TB/day of operational events from multiple regional Kafka topics and batch feeds. Requirements: idempotent upserts into a table (Iceberg/Delta), handle late-arriving events, schema evolution, and partition pruning by country/date. Compare Flink vs Spark for streaming, and outline testing, monitoring, and data quality checks?","answer":"Propose a hybrid pipeline: streaming with Flink writing to Iceberg, using idempotent upserts on (region, event_id), watermarking for late data, and Iceberg schema evolution; batch reconciliation with ","explanation":"## Why This Is Asked\nThis question probes end-to-end data engineering design, covering multi-source ingest, schema evolution, late data handling, and cost-aware architecture at scale.\n\n## Key Concepts\n- Multi-source ingestion, idempotent upserts, upsert semantics\n- Schema evolution, partition pruning, Iceberg/Delta\n- Late data handling, watermarking, out-of-order events\n- Streaming vs batch trade-offs, observability\n\n## Code Example\n```javascript\n// Example pseudo outline (not executable)\nfunction ingest(){ /* ... */ }\n```\n\n## Follow-up Questions\n- How would you test idempotence across regional sources?\n- What metrics and dashboards would you establish for data quality and SLA.\n","diagram":"flowchart TD\n  A[Regional Kafka Topics] --> B[Flink Streaming]\n  B --> C[Iceberg Table]\n  C --> D[Spark Batch Reconciliation]\n  D --> E[Monitoring & Quality]\n","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","LinkedIn","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T21:35:02.996Z","createdAt":"2026-01-12T21:35:02.996Z"},{"id":"q-1140","question":"Given daily 1 GB of web logs in JSON lines stored on S3 with fields user_id, timestamp, path, status, and optional referrer, design a beginner-friendly pipeline (Python or Node.js) that deduplicates by timestamp+user_id+path, validates required fields, normalizes timestamp to UTC, and writes date-partitioned Parquet to a data lake; include basic tests and monitoring?","answer":"Use a small streaming script (Python or Node.js) to read daily JSONL from S3, deduplicate by (timestamp, user_id, path), validate required fields (user_id, timestamp, path, status), coerce timestamp t","explanation":"## Why This Is Asked\nThis question tests practical, beginner-friendly construction of a data pipeline with common tasks: deduplication, validation, timestamp handling, and partitioned Parquet, plus testing and monitoring.\n\n## Key Concepts\n- JSON Lines parsing\n- Idempotent deduplication\n- Data quality checks (required fields, types)\n- Timestamp normalization to UTC\n- Parquet writing and date partitioning\n- Basic testing and observability\n\n## Code Example\n```javascript\nconst fs = require('fs');\nconst readline = require('readline');\n(async () => {\n  const rl = readline.createInterface({ input: fs.createReadStream('logs.jsonl'), crlfDelay: Infinity });\n  const seen = new Set();\n  for await (const line of rl) {\n    const obj = JSON.parse(line);\n    if (!obj.user_id || !obj.timestamp || !obj.path || !obj.status) continue;\n    const key = `${obj.timestamp}|${obj.user_id}|${obj.path}`;\n    if (seen.has(key)) continue;\n    seen.add(key);\n    // normalization and persistence would occur here\n  }\n})();\n```\n\n## Follow-up Questions\n- How would you scale this for multi-region logs?\n- What metrics and alerts would you add for production reliability?","diagram":"flowchart TD\n  Ingest[Ingest daily JSONL from S3] --> Dedup[Dedupe by timestamp+user_id+path]\n  Dedup --> Validate[Validate required fields]\n  Validate --> Normalize[Normalize timestamp to UTC]\n  Normalize --> Persist[Persist Parquet to date-partitioned path]\n  Persist --> Test[Basic tests and monitoring]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","NVIDIA","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T01:27:30.496Z","createdAt":"2026-01-13T01:27:30.496Z"},{"id":"q-1272","question":"Design a data pipeline to ingest 2M GPU telemetry events per minute from a global fleet of AI training clusters into a data lake and a feature store. Events include host_id, region, timestamp, metric_type, and value. Requirements: immutable raw Parquet storage partitioned by region/hour; near-real-time metrics and anomaly alerts (1–2 minute latency) via a streaming engine; idempotent upserts into a feature store; schema evolution handling; late-arriving data; cost-aware storage/compute; monitoring and tests; compare Spark vs Flink for streaming components?","answer":"Architect a pipeline ingesting ~2M GPU telemetry events per minute from global clusters. Use Kafka -> Flink (or Spark Structured Streaming) to compute 1–2 minute rolling metrics and an anomaly score; ","explanation":"## Why This Is Asked\nThis question probes end-to-end data pipeline design for a hardware/AI-ops context, focusing on high-throughput ingestion, real-time analytics, schema evolution, late data, and cost—areas Apple/NVIDIA encounter in telemetry, MLops, and GPU monitoring.\n\n## Key Concepts\n- High-throughput streaming, watermarking, late data\n- Immutable raw storage and partitioning\n- Idempotent upserts in a feature store (Iceberg/Delta)\n- Schema evolution and data quality checks\n- Cost optimization (tiered storage, compute)\n\n## Code Example\n```javascript\n// Pseudo-code for anomaly score snippet\nfunction score(series) {\n  const mean = mean(series)\n  const std = stdDev(series)\n  return (series[-1] - mean) / std\n}\n```\n\n## Follow-up Questions\n- How would you test schema evolution without downtime?\n- How would you measure latency and data quality in production?","diagram":"flowchart TD\n  Kafka[(Kafka)]\n  Stream[(Streaming Engine)]\n  Raw[(Raw Parquet Lake)]\n  Features[(Feature Store)]\n  Alerts[(Alerts)]\n  Late[(Late Data)]\n  Kafka --> Stream\n  Stream --> Raw\n  Stream --> Features\n  Raw --> Features\n  Features --> Alerts\n  Late -.-> Stream","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T07:38:05.936Z","createdAt":"2026-01-13T07:38:05.936Z"},{"id":"q-1498","question":"Design a global data ingestion and governance pipeline for a real-time ad-tech platform that processes 200k events/sec from 3 cloud regions into a centralized lakehouse. Each event has event_id, tenant_id, timestamp, event_type, and payload. Requirements: enforce data contracts via a central registry (schema + compatibility rules), support schema evolution with automatic catalog updates, and ensure multi-tenant data isolation and access control. Implement partitioning by tenant/date, handle late-arriving data within a 1–2 minute SLA, ensure data lineage and quality checks, and provide rollback semantics for contracts. Compare Iceberg vs Delta as the storage layer, outline testing/monitoring, and describe concrete example schemas and contract definitions. Include how you'd validate end-to-end?","answer":"I would implement a contract-first pipeline using a central schema registry (Avro/JSON), publish backward/forward-compatible schemas, and isolate data per tenant in Lakehouse partitions tenant/date. I","explanation":"## Why This Is Asked\nTests ability to design end-to-end, contract-driven lakehouse pipelines with multi-tenant governance, schema evolution, and robust observability.\n\n## Key Concepts\n- Data contracts and registry (Avro/JSON schemas, compatibility rules)\n- Multi-tenant isolation and fine-grained access control\n- Schema evolution with catalog updates and versioning\n- Late-arriving data handling and watermarking\n- Data lineage, quality checks, and rollback semantics\n- Iceberg vs Delta trade-offs at scale\n\n## Code Example\n```json\n{\n  \"type\": \"record\",\n  \"name\": \"AdEvent\",\n  \"namespace\": \"com.accel.adtech\",\n  \"fields\": [\n    {\"name\": \"event_id\", \"type\": \"string\"},\n    {\"name\": \"tenant_id\", \"type\": \"string\"},\n    {\"name\": \"timestamp\", \"type\": {\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}},\n    {\"name\": \"event_type\", \"type\": \"string\"},\n    {\"name\": \"payload\", \"type\": \"string\"}\n  ]\n}\n```\n\n## Follow-up Questions\n- How would you validate a new schema version in canary before rollout?\n- How would you enforce per-tenant access to the lakehouse while preserving analytics flexibility?","diagram":"flowchart TD\n  A[Raw events] --> B[Schema Registry]\n  B --> C[Catalog (Iceberg/Delta)]\n  C --> D[Tenant/date partitions]\n  D --> E[Access / BI / ML]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Scale Ai","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-13T19:32:55.649Z","createdAt":"2026-01-13T19:32:55.650Z"},{"id":"q-1692","question":"In a social app generating 100 GB/day of newline-delimited JSON events across 3 regions stored in S3, design a beginner-friendly batch pipeline that validates fields (event_id, user_id, timestamp, event_type), derives date, deduplicates by event_id, hashes user_id for privacy, and writes Parquet partitioned by date to a data lake. Compute a daily data-quality score (0-1) based on missing/invalid fields and store it in a metadata table. Outline tooling, testing, and monitoring?","answer":"Use a Spark batch job that reads 100 GB/day of newline-delimited JSON from S3, validates fields (event_id, user_id, timestamp, event_type), derives date, deduplicates by event_id, hashes user_id with ","explanation":"## Why This Is Asked\nAssesses ability to build an end-to-end batch pipeline with data validation, deduplication, privacy, and basic quality metrics. It also touches data lake organization and basic monitoring.\n\n## Key Concepts\n- Batch processing with Spark\n- Schema validation and deduplication\n- Privacy via sha-256 hashing\n- Parquet partitioning by date\n- Data-quality scoring and metadata tracking\n\n## Code Example\n```javascript\n# Pseudo-PySpark outline\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import sha2, col, to_date\nspark = SparkSession.builder.getOrCreate()\ndf = spark.read.json(\"s3://bucket/events/2025-*/\")\ndf = df.filter(\"event_id IS NOT NULL AND user_id IS NOT NULL\")\ndf = df.dropDuplicates([\"event_id\"])\ndf = df.withColumn(\"user_id_hash\", sha2(col(\"user_id\"), 256))\ndf = df.withColumn(\"date\", to_date(col(\"timestamp\")))\ndf.write.partitionBy(\"date\").parquet(\"s3://bucket/processed/\")\n```\n\n## Follow-up Questions\n- How would you adjust for late-arriving data or schema drift?\n- What tests would you add to validate deduplication and quality scoring?","diagram":"flowchart TD\n  A[Input data] --> B[Validation]\n  B --> C[Deduplicate by event_id]\n  C --> D[Hash user_id]\n  D --> E[Write Parquet partitioned by date]\n  E --> F[Daily quality score in metadata table]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","PayPal","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T07:01:59.981Z","createdAt":"2026-01-14T07:01:59.982Z"},{"id":"q-1701","question":"Ingest 3 TB/day of regional event data from Kafka (EU/US/APAC) with user_id, session_id, event_type, timestamp, and attributes. Design a privacy-first analytics pipeline: per-region salt pseudonymization of user_id before cross-region joins, idempotent upserts into Apache Iceberg, event-time processing with 15-minute tumbling windows and 1-hour late data, and immutable audits and data contracts. Compare Spark Structured Streaming vs Flink for the streaming layer, and specify GDPR masking after aggregation?","answer":"Per-region salts for user_id, then SHA-256 hash to pseudonymize before cross-region joins; write idempotent upserts to Iceberg; use 15-minute tumbling windows with 1-hour allowed lateness; maintain im","explanation":"## Why This Is Asked\n\nThis question tests privacy-first, scalable analytics across regions with data contracts.\n\n## Key Concepts\n\n- Per-region pseudonymization\n- Iceberg upserts\n- Event-time windows and lateness handling\n- Immutable audits and data contracts\n- Spark vs Flink trade-offs for streaming\n\n## Code Example\n\n```javascript\n// Region-aware salt hash (Node.js)\nconst crypto = require('crypto');\nfunction saltedHash(region, id, salts){\n  const salt = salts[region] ?? salts.default;\n  return crypto.createHash('sha256').update(id + salt).digest('hex');\n}\n```\n\n## Follow-up Questions\n\n- How would you test idempotency and audit coverage?\n- How would you handle a new region with a different privacy policy?","diagram":"flowchart TD\n  Ingest[Ingest regional Kafka topics] --> Mask[Per-region salt masking of user_id]\n  Mask --> Upsert[Iceberg upserts in lakehouse]\n  Upsert --> Audit[Audit logs & data contracts]\n  Audit --> Monitor[Monitoring & testing]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Lyft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T07:37:37.148Z","createdAt":"2026-01-14T07:37:37.149Z"},{"id":"q-1928","question":"Design a cost-aware real-time ingestion pipeline that processes 50 TB/day of clickstream data from multiple sources (Kafka topics and batch feeds) into a lakehouse. Ensure idempotent upserts into an Iceberg/Delta table, handle late-arriving events, and support schema evolution with partition pruning by date and region. Compare Spark Structured Streaming vs Flink for the path and outline data quality checks, testing, and monitoring strategies?","answer":"Design a pipeline ingesting 50 TB/day of clickstream data from Kafka topics and batch feeds into a lakehouse. Use an idempotent upsert into Iceberg/Delta, with watermarking for late events, and schema","explanation":"## Why This Is Asked\nTests ability to design scalable, cost-aware streaming pipelines with exactly-once semantics, late-arriving data handling, and schema evolution in a lakehouse.\n\n## Key Concepts\n- Ingestion from heterogeneous sources and batch feeds\n- Idempotent upserts into Iceberg/Delta\n- Watermarking and late-arriving data handling\n- Schema evolution and registry integration\n- Partition pruning by date/region; cost-aware resource planning\n- Testing, monitoring, and data quality checks\n- Trade-offs Spark vs Flink\n\n## Code Example\n```javascript\n// Pseudo: upsert function shape for events\nfunction upsertEvent(event){\n  // compute dedup key, apply to Iceberg/Delta table with primary key\n  // handle schema evolution via registry\n}\n```\n\n## Follow-up Questions\n- How would you implement exactly-once guarantees across Kafka and batch feeds?\n- How would you validate data quality and detect drift in this setup?\n- What monitoring metrics and SLAs would you track for latency and data freshness?","diagram":"flowchart TD\n  A[Sources: Kafka + Batch] --> B[Ingestion]\n  B --> C[Processing: watermarking & upsert]\n  C --> D[Lakehouse: Iceberg/Delta]\n  D --> E[Monitoring & Quality Checks]\n","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Robinhood","Two Sigma"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T17:43:26.111Z","createdAt":"2026-01-14T17:43:26.111Z"},{"id":"q-1965","question":"Design a GDPR/CCPA-compliant, multi-source data pipeline for an e-commerce analytics platform. Ingest CDC from OLTP databases plus batch feeds, preserve raw data immutably, and enable per-tenant data isolation. Implement lineage via a metadata catalog, apply privacy techniques (PII redaction and differential privacy for aggregates), and support schema evolution. Compare Flink vs Spark for streaming, outline tests, monitoring, and cost implications across regions?","answer":"Ingest CDC from OLTP and batch feeds into an immutable lake with per-tenant isolation and a metadata catalog for lineage. Redact PII and implement differential privacy for aggregates; store raw Parque","explanation":"## Why This Is Asked\nTests ability to design privacy-conscious, governance-aware pipelines across regions with real-world constraints.\n\n## Key Concepts\n- GDPR/CCPA data handling\n- CDC and batch ingestion\n- Immutable storage and Iceberg/Delta\n- Metadata catalogs and lineage\n- Data masking and differential privacy\n- Per-tenant isolation and cost-aware regional replication\n- Flink vs Spark for streaming\n\n## Code Example\n```javascript\n// pseudo-code sketch for DP on aggregates\n```\n\n## Follow-up Questions\n- How would you test schema evolution compatibility across regions?\n- What failure modes affect privacy and how would you mitigate?\n","diagram":null,"difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","LinkedIn","Robinhood"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:59:13.741Z","createdAt":"2026-01-14T18:59:13.742Z"},{"id":"q-1971","question":"You run a product analytics pipeline for a global iOS/Android app (telemetry: user_id, device_id, ts, event, properties). Data must be ingested from a MongoDB Atlas source into a lakehouse on S3 using Apache Iceberg. Design an end-to-end pipeline that supports idempotent upserts, late-arriving events, and schema evolution, while enforcing PII masking and GDPR data deletion requests. Compare using Flink vs Spark for streaming, outline testing, monitoring, and data-quality checks?","answer":"Design: Ingest MongoDB Atlas via Change Streams into a durable sink (Kafka). Use a streaming engine (Flink or Spark Structured Streaming) to materialize an Iceberg table on S3 with upserts keyed by (u","explanation":"## Why This Is Asked\nThis question probes practical data engineering design for a privacy-conscious, scalable lakehouse pipeline that can handle cross-platform ingestion from MongoDB Atlas, with robust correctness (idempotence, late data, schema evolution) and trade-offs between Flink and Spark. It also touches testing, monitoring, and data quality.\n\n## Key Concepts\n- Change Data Capture from MongoDB Atlas (Change Streams)\n- Upserts with Iceberg on S3\n- Watermarks and lateness handling\n- Schema evolution in Iceberg and compatibility\n- PII masking and GDPR deletions in streaming\n- Flink vs Spark trade-offs; testing and monitoring\n\n## Code Example\n```javascript\n// Pseudocode outline for CDC -> Kafka -> Iceberg\n```\n\n## Follow-up Questions\n- How would you implement GDPR delete propagation across components?\n- How would you validate idempotence and late-arrival correctness?","diagram":"flowchart TD\n  A[MongoDB Atlas] --> B[Change Streams]\n  B --> C[Kafka]\n  C --> D[Flink/Spark]\n  D --> E[Iceberg on S3]\n  E --> F[Analytics/BI]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Apple","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:27:27.822Z","createdAt":"2026-01-14T19:27:27.825Z"},{"id":"q-2272","question":"Design a global telemetry ingest pipeline for 8 regional Kafka clusters, totaling 20 TB/day of JSON events. Build an end-to-end flow into a lakehouse using Iceberg, ensuring idempotent upserts, late-arriving events, and schema evolution for nested JSON; enforce per-country data sovereignty and GDPR deletion requests. Compare Spark Structured Streaming vs Flink, and outline testing, monitoring, and data-quality checks?","answer":"Design a regional-first ingest into Iceberg lakehouses partitioned by country/date, using exactly-once streaming (Flink preferred; Spark for batch). Achieve idempotent upserts via MERGE INTO, support ","explanation":"## Why This Is Asked\nThis question probes cross-region data ingestion, schema evolution for nested data, and regulatory compliance at scale.\n\n## Key Concepts\n- Exactly-once streaming across multi-region sources\n- Iceberg MERGE Upserts and schema evolution\n- Data sovereignty, GDPR deletions, field masking\n- lineage, monitoring, data quality checks\n- Flink vs Spark trade-offs at scale\n\n## Code Example\n```sql\nMERGE INTO lake.country_data AS t\nUSING staged AS s\nON t.id = s.id\nWHEN MATCHED THEN UPDATE SET t.data = s.data\nWHEN NOT MATCHED THEN INSERT (id, data) VALUES (s.id, s.data)\n```\n\n## Follow-up Questions\n- How would you test late-arriving data and out-of-order events?\n- How to enforce per-country sovereignty in partitioning and retention?\n- How would GDPR deletion requests be propagated through the pipeline and sinks?","diagram":"flowchart TD\n  S[8 regional Kafka clusters] --> I[Ingestion Layer]\n  I --> P[Streaming Processor (Flink)]\n  P --> L[Iceberg Lakehouse (country/date partitions)]\n  L --> Governance[Governance: lineage, privacy, GDPR tombstones]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T09:54:51.819Z","createdAt":"2026-01-15T09:54:51.819Z"},{"id":"q-2433","question":"Design a multi-tenant data ingestion pipeline that streams 40 TB/day of event data from dozens of publishers, each with its own schema and retention policy. Explain how you enforce per-tenant data contracts, support dynamic schema evolution, guarantee idempotent upserts into a lakehouse, handle late-arriving events and GDPR delete requests, and implement cross-region replication with cost controls. Compare Spark Structured Streaming vs Flink for this workload and outline testing and monitoring?","answer":"Implement a per-tenant schema registry and data contracts; stream 40 TB/day via Flink (exactly-once) or Spark, upsert into Iceberg partitioned by tenant/date; manage late events with watermarks and id","explanation":"## Why This Is Asked\nThis question probes multi-tenant ingestion, dynamic schemas, and governance at scale.\n\n## Key Concepts\n- Per-tenant data contracts and schema registry\n- Exactly-once streaming with idempotent upserts into Iceberg\n- Late-arriving events, watermarks, tombstones for deletes\n- Cross-region replication, cost controls, data lineage\n- Spark vs Flink trade-offs (backpressure, CDC, state management)\n\n## Code Example\n```javascript\n// Placeholder: pseudo-implementation sketch\nfunction validate(record, contract) { return schema.matches(record); }\n```\n\n## Follow-up Questions\n- How would you implement per-tenant quotas and isolation?\n- How would you test schema evolution without breaking tenants?","diagram":null,"difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Bloomberg","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T17:51:08.942Z","createdAt":"2026-01-15T17:51:08.942Z"},{"id":"q-2460","question":"Design an end-to-end data pipeline for a multi-tenant ride-hailing platform where city-level feature stores power online fraud scoring and offline model training. Ingest 1) trip events, 2) driver status, 3) external pricing data; ensure per-city isolation, schema evolution, and GDPR deletion. Compare Spark Structured Streaming vs Flink for streaming, outline tests and monitoring?","answer":"Ingest via Kafka into a Spark Structured Streaming job or Flink, write features to an Iceberg-backed feature store partitioned by city. Provide online features in Redis for low latency; offline featur","explanation":"## Why This Is Asked\nAssesses ability to design multi-tenant pipelines, real-time features, and governance across regions.\n\n## Key Concepts\n- Multi-tenant feature store with city partitioning\n- Real-time vs offline feature separation\n- Schema evolution and data quality drift detection\n- GDPR delete propagation and data sovereignty\n- Testing with synthetic data and end-to-end pipelines\n\n## Code Example\n```python\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n# Read from Kafka\ndf = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\",\"kafka:9092\").option(\"subscribe\",\"trip_events\").load()\n# Simple feature extraction\nfeatures = df.selectExpr(\"CAST(value AS STRING) as json\").select(\"json\").where(\"json IS NOT NULL\")\n# Write to Iceberg feature store\nfeatures.writeStream.format(\"iceberg\").option(\"table\",\"feature_store.cityA.trips_features\").start()\n```\n\n## Follow-up Questions\n- How would you implement drift detection thresholds for features?\n- How to validate GDPR deletion propagation across online/offline stores?\n- How would you scale to thousands of cities while preserving isolation?\n- What metrics and alerts would you include for data quality and latency?","diagram":"flowchart TD\n  A[Ingest] --> B[Feature Store]\n  B --> C[Online Store]\n  B --> D[Offline Store]\n  C --> E[Serving Layer]\n  D --> F[Model Training]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Lyft","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T19:02:31.364Z","createdAt":"2026-01-15T19:02:31.364Z"},{"id":"q-2564","question":"You're building a cross-region analytics platform ingesting 200M events/day into a lakehouse. Design a data-contract–driven pipeline with a central schema registry enforcing compatibility, add automated data quality, lineage, and privacy masking for PII, and ensure BI dashboards and model training never see raw sensitive fields. Compare Spark vs Flink for streaming governance and outline testing and monitoring?","answer":"Implement a data-contract-driven architecture with a centralized schema registry enforcing backward and forward compatibility. Ingest events using Flink for near real-time processing into a lakehouse, publishing masked views for BI and ML while maintaining strict access controls. Deploy automated data quality checks, comprehensive lineage tracking, and PII masking at the ingestion layer. Leverage Spark for batch transformations and complex analytics, while utilizing Flink for streaming governance with lower latency requirements. Establish robust testing frameworks including schema validation, data quality assertions, and end-to-end pipeline monitoring across all regions.","explanation":"## Why This Is Asked\n\nThis question assesses practical expertise in data governance, cross-region pipeline architecture, and technology selection. It evaluates a candidate's ability to design data contracts, enforce privacy controls, and provide observable lineage across streaming and batch workloads while balancing Spark vs Flink trade-offs.\n\n## Key Concepts\n\n- Data contracts and schema registry for compatibility enforcement\n- Privacy masking and access controls for PII protection\n- Data lineage and metadata catalog integration\n- Streaming (Flink) vs batch (Spark) processing considerations","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Bloomberg","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T05:22:19.374Z","createdAt":"2026-01-15T22:53:48.446Z"},{"id":"q-2730","question":"You're building a multi-tenant retail analytics pipeline. Ingest JSON logs of user sessions from regional storefronts: {user_id, session_id, region, items: [{sku, qty, price}], event_ts, revenue, marketing}. Data lands in S3 daily and must feed a lakehouse (Iceberg) with near-real-time revenue per SKU by region. Requirements: per-tenant masking, GDPR deletion, schema evolution, idempotent upserts, late-arriving events, and robust testing/monitoring. Describe the end-to-end design, data contracts, and trade-offs between Flink and Spark for streaming?","answer":"Proposed pipeline: regional JSON events ingested via Kafka, parsed in Flink with event-time processing and 10-min lateness, written to Iceberg upserts (revenue by SKU-region-date; dims: product, regio","explanation":"## Why This Is Asked\nExplores end-to-end multi-tenant data governance, privacy enforcement, and the practical trade-offs of streaming engines in a lakehouse.\n\n## Key Concepts\n- Event-time processing and late data handling\n- Upserts in Iceberg with schema evolution\n- PII masking and GDPR deletion pipelines\n- Data contracts and data quality testing\n- Engine trade-offs: Flink vs Spark for stateful streams\n\n## Code Example\n```javascript\n// Flink streaming job skeleton (Java-like)\n```\n\n## Follow-up Questions\n- How would you test schema drift and GDPR deletion across partitions?\n- What would you monitor to catch data leakage between tenants?","diagram":"flowchart TD\n  Ingest[Ingest Events] --> Parse[Parse & Enrich]\n  Parse --> Mask[Mask PII]\n  Mask --> Upsert[Iceberg Upserts]\n  Upsert --> GDPR[GDPR Delete & Purge]\n  GDPR --> Monitor[Monitoring & Quality Checks]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Salesforce","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T09:42:13.301Z","createdAt":"2026-01-16T09:42:13.301Z"},{"id":"q-2762","question":"You're given a daily 200–500 MB CSV of user events with columns: user_id, event_time, event_type, payload. Design a beginner-friendly pipeline to load it into a Parquet lakehouse, partitioned by event_date, deduplicated on user_id+event_time, and with a small audit log for rows with invalid timestamps. Outline steps and a minimal PySpark snippet to start?","answer":"Use a PySpark batch pipeline: read the daily CSV, parse event_time with to_timestamp, extract event_date, deduplicate by user_id and event_time, and write to Parquet partitioned by event_date. Maintai","explanation":"## Why This Is Asked\nTests basic ETL design, simple validation, and idempotent daily loads using familiar tools.\n\n## Key Concepts\n- PySpark basics: read CSV, to_timestamp, to_date, dropDuplicates, partitionBy\n- Data quality: timestamp parsing and invalid-row auditing\n- Idempotent daily loads: deterministic dedup before write\n\n## Code Example\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import to_timestamp, to_date, col\n\nspark = SparkSession.builder.appName(\"DailyIngest\").getOrCreate()\n\npath = \"s3://bucket/daily/events_YYYYMMDD.csv\"\ndf = spark.read.csv(path, header=True, inferSchema=True)\ndf = df.withColumn(\"ts\", to_timestamp(col(\"event_time\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\"))\nvalid = df.filter(col(\"ts\").isNotNull())\nvalid = valid.withColumn(\"event_date\", to_date(col(\"ts\")))\n\n# Deduplicate and write\nvalid.dropDuplicates([\"user_id\", \"ts\"]).write.partitionBy(\"event_date\").mode(\"append\").parquet(\"s3://bucket/warehouse/events\")\n\n# Audit invalid timestamps\ninvalid = df.filter(col(\"ts\").isNull())\ninvalid.write.csv(\"s3://bucket/audit/invalid_rows.csv\", header=True)\n```\n\n## Follow-up Questions\n- How would you test idempotence for daily re-runs?\n- How would you monitor data quality and failures in production?","diagram":"flowchart TD\n  Ingest[Ingest daily CSV] --> Validate[Parse and validate timestamps]\n  Validate --> Dedup[Deduplicate by user_id + event_time]\n  Dedup --> Write[Write partitioned Parquet by event_date]\n  Validate --> Audit[Log invalid timestamps]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","LinkedIn","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T10:50:49.591Z","createdAt":"2026-01-16T10:50:49.592Z"},{"id":"q-2789","question":"You are onboarding a partner providing a daily JSON event feed (fields: user_id, event_ts, event_type, payload). Design a beginner-friendly batch ETL to normalize into a flat table, store Parquet in a lake partitioned by date, and perform idempotent upserts into the warehouse. Include basic data quality: non-null fields, timestamp sanity (within 90 days), and malformed-record handling. Compare batch vs streaming ingestion and outline tests?","answer":"Propose a Spark batch pipeline: read daily 50k JSON events, infer schema, flatten payload, enforce user_id and event_ts presence, drop bad rows, and filter out future timestamps. Write Parquet to lake","explanation":"## Why This Is Asked\nIntroduces batch ingestion with validation and idempotent upserts, a common beginner task for real-world data warehouses.\n\n## Key Concepts\n- Batch ETL basics: extract, transform, load\n- Data quality: non-null checks, timestamp sanity, malformed record handling\n- Parquet partitioning by date for query locality\n- Idempotent upserts via MERGE into warehouse tables\n\n## Code Example\n```javascript\n// Pseudo-code: batch ETL outline\nconst events = loadJSONLines('daily/input.json');\nconst flat = events.map(flattenEvent).filter(isValidEvent);\nwriteParquet(flat, `lake/partition_date=${date}`, {mode:'overwrite'});\nupsertTable('warehouse.events', `lake/partition_date=${date}`);\n```\n\n## Follow-up Questions\n- How would you handle schema drift between daily feeds?\n- What are simple testing strategies for data quality and idempotence?","diagram":"flowchart TD\n  A[Ingest daily feed] --> B[Parse & flatten to flat schema]\n  B --> C[Validate quality & filter malformed]\n  C --> D[Write Parquet partitioned by date]\n  D --> E[MERGE into warehouse (idempotent upserts)]\n  E --> F[Run tests & monitoring]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Scale Ai","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T11:46:19.657Z","createdAt":"2026-01-16T11:46:19.657Z"},{"id":"q-2884","question":"Ingest streaming IoT telemetry from a global fleet where devices send json envelopes with id, ts, region, metrics, and an optional base64-encoded payload. Build an end-to-end pipeline into a lakehouse that decodes payloads, handles schema evolution, late events, and per-region masking, and supports GDPR delete requests. Compare Spark Structured Streaming vs Flink for this workload and outline testing/monitoring strategies?","answer":"Architect a streaming IoT telemetry pipeline: decode optional base64 payloads, apply schema evolution via a registry, and upsert into Iceberg; enforce region-based masking and GDPR delete hooks; imple","explanation":"## Why This Is Asked\nThis question probes practical streaming design for IoT data, including binary payloads, dynamic schemas, regional privacy rules, and lakehouse upserts, plus trade-offs between engines.\n\n## Key Concepts\n- Streaming ingestion, event-time, watermarking\n- Schema evolution with a registry and conformance checks\n- Data masking by region and GDPR delete integration\n- Upserts into Iceberg/lakehouse with idempotent sinks\n- Testing, observability, and fault-injection strategies\n\n## Code Example\n```javascript\n// Decode and parse base64 payload in a streaming map function\nconst payload = Buffer.from(record.base64Payload, 'base64').toString('utf-8');\nconst payloadObj = JSON.parse(payload);\n```\n\n## Follow-up Questions\n- How would you implement GDPR deletes across regions without data loss?\n- How would you validate schema evolution compatibility in production?","diagram":"flowchart TD\n  A[Ingest: Kafka/Kinesis] --> B[Parse envelope]\n  B --> C[Decode base64 payload]\n  C --> D[Schema validation/evolution via registry]\n  D --> E[Region-based masking & GDPR hooks]\n  E --> F[Upsert to Iceberg lakehouse]\n  F --> G[Observability & testing]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T15:55:34.786Z","createdAt":"2026-01-16T15:55:34.786Z"},{"id":"q-2984","question":"You receive a nightly CSV feed customers.csv with fields customer_id, signup_date, region, tier, and email_verified. A customer can appear on multiple nights with updated fields. Design a beginner-friendly pipeline to upsert into a canonical table customers_dim, ensure late changes are captured, implement basic data-quality checks, and describe how you'd test it?","answer":"Load nightly customers.csv into a staging table, then MERGE into customers_dim on customer_id using the latest row per id (based on signup_date or an updated_at column). Update non-key fields; insert ","explanation":"## Why This Is Asked\n\nAssesses ability to design a simple, reliable upsert pipeline with late-arriving updates and basic data quality checks at a beginner level.\n\n## Key Concepts\n\n- Upserts via MERGE or equivalent\n- Staging area and idempotency\n- Data quality checks: type safety, null checks, value constraints\n- Testing: unit tests with synthetic data, end-to-end smoke tests\n\n## Code Example\n\n```sql\n-- Pseudo SQL illustrating the merge into customers_dim\nMERGE INTO customers_dim AS d\nUSING staging AS s\nON d.customer_id = s.customer_id\nWHEN MATCHED THEN\n  UPDATE SET d.region = s.region,\n             d.tier = s.tier,\n             d.email_verified = s.email_verified,\n             d.signup_date = s.signup_date\nWHEN NOT MATCHED THEN\n  INSERT (customer_id, signup_date, region, tier, email_verified)\n  VALUES (s.customer_id, s.signup_date, s.region, s.tier, s.email_verified);\n```\n\n## Follow-up Questions\n\n- How would you handle schema evolution for new columns?\n- How would you test idempotence across multiple nightly runs?","diagram":"flowchart TD\n  A[Ingest nightly CSV] --> B[Staging Table]\n  B --> C[Merge into customers_dim]\n  C --> D[Quality Checks]\n  D --> E[Downstream Metrics]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Meta","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-16T19:47:14.961Z","createdAt":"2026-01-16T19:47:14.962Z"},{"id":"q-3087","question":"You're handed a monthly 5GB JSON Lines file of e-commerce orders: {order_id, user_id, product_id, price, qty, timestamp, status}. Design a beginner-friendly batch ETL to deduplicate by order_id, normalize timestamp, fill missing price with 0 and status with 'new', and store as partitioned Parquet by year-month in a data lake. Explain validation, idempotence, and tests; compare Spark vs Pandas for this workload?","answer":"Use PySpark with a defined schema, read the JSON Lines file, cast the timestamp field to proper datetime format, fill missing price values with 0 and status with 'new', deduplicate by order_id using dropDuplicates(['order_id']), and write to Parquet partitioned by year-month using partitionBy('year', 'month') with overwrite mode for idempotence.","explanation":"## Why This Is Asked\n\nThis question evaluates practical batch ETL thinking for beginners, focusing on data quality, deduplication, and idempotent write operations.\n\n## Key Concepts\n\n- Batch ETL with schema enforcement\n- Deduplication on a key field\n- Time-based partitioning for efficient querying\n- Idempotent writes via partition overwrite\n\n## Code Example\n\n```python\nfrom pyspark.sql import SparkSession, functions as F\nfrom pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n\nspark = SparkSession.builder.getOrCreate()\nschema = StructType([\n  StructField('order_id', StringType(), nullable=False),\n  StructField('user_id', StringType(), nullable=True),\n  StructField('product_id', StringType(), nullable=True),\n  StructField('price', DoubleType(), nullable=True),\n  StructField('qty', IntegerType(), nullable=True),\n  StructField('timestamp', StringType(), nullable=True),\n  StructField('status', StringType(), nullable=True)\n])\n\n# Read JSON Lines with schema\ndf = spark.read.schema(schema).json('orders.jsonl')\n\n# Transform: normalize timestamp, fill missing values, deduplicate\ndf = df.withColumn('timestamp', F.to_timestamp('timestamp'))\n     .fillna({'price': 0, 'status': 'new'})\n     .withColumn('year', F.year('timestamp'))\n     .withColumn('month', F.month('timestamp'))\n     .dropDuplicates(['order_id'])\n\n# Write partitioned Parquet\n(df.write\n   .mode('overwrite')\n   .partitionBy('year', 'month')\n   .parquet('data_lake/orders/'))\n```\n\n## Validation Strategy\n\n- Schema validation on read\n- Null checks before fill operations\n- Record count verification pre/post deduplication\n- Partition existence validation on write\n\n## Idempotence\n\nPartition overwrite ensures re-running produces identical results. Deduplication guarantees single record per order_id regardless of input duplicates.\n\n## Tests\n\n- Unit: test transform functions with sample data\n- Integration: end-to-end pipeline with test JSON Lines file\n- Performance: validate Spark cluster handles 5GB efficiently\n\n## Spark vs Pandas\n\n**Spark**: Better for 5GB+ data, distributed processing, built-in partitioning, handles out-of-memory. **Pandas**: Simpler syntax for small data (<1GB), single-machine only, manual chunking required for large files. Spark is preferred for production batch ETL at this scale.","diagram":"flowchart TD\n  A[JSON Lines] --> B[Schema & Cast]\n  B --> C[Deduplicate]\n  C --> D[Partitioned Parquet Write]\n  D --> E[Commit final path]\n  E --> F[Quality checks]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","MongoDB","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:04:20.773Z","createdAt":"2026-01-17T02:11:38.439Z"},{"id":"q-3181","question":"Design a global customer-analytics pipeline for a multi-region marketplace. Region-specific Kafka streams deliver events: user_id, session_id, region, event_type, timestamp, and attributes. Build a unified, near-real-time profile in an Iceberg lakehouse with per-region privacy, GDPR deletion, and schema evolution. Describe data contracts, idempotent upserts, late-arriving events, and trade-offs between Spark Structured Streaming and Flink; include testing and monitoring plan?","answer":"Adopt a Flink streaming pipeline feeding Iceberg. De-duplicate with a stable ingestion_id; upsert profiles by user_id using MERGE INTO. Enforce per-region privacy by masking PII and honoring GDPR dele","explanation":"## Why This Is Asked\nEvaluates ability to design cross-region streaming with privacy, schema evolution, and upserts.\n\n## Key Concepts\n- Data contracts, idempotent upserts, late-arriving events, GDPR deletion, per-region masking\n- Iceberg MERGE semantics, Flink vs Spark trade-offs, testing\n\n## Code Example\n```sql\nMERGE INTO iceberg.table AS t\nUSING staging AS s\nON t.user_id = s.user_id\nWHEN MATCHED THEN UPDATE SET ...\nWHEN NOT MATCHED THEN INSERT ...\n```\n\n## Follow-up Questions\n- How would you test idempotency and privacy masking at scale?\n- How would you monitor data quality across regions?","diagram":"flowchart TD\n  Kafka[Regional Kafka] --> Streaming[Flink]--> Iceberg[Iceberg Lakehouse]\n  Iceberg --> Profile[Unified User Profile]\n  GDPR[GDPR Deletions] --> Iceberg\n  Monitor[Monitoring & Alerts] --> Iceberg","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Instacart","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T05:41:50.722Z","createdAt":"2026-01-17T05:41:50.722Z"},{"id":"q-3189","question":"You operate a streaming ingestion system that consumes 50k JSON events per second from mobile devices across regions. Events have nested payloads with optional fields and must be transformed into a star schema in a lakehouse (Iceberg) with schema evolution. Data arrives late (up to 2 hours). Describe end-to-end design, including idempotent upserts, per-record data contracts, and per-record lineage. Compare Spark Structured Streaming vs Flink for processing and outline testing/monitoring?","answer":"Prefer Flink: ingest from Kafka with event-time processing and 2h lateness. Validate against a schema registry, parse nested JSON, upsert into Iceberg star schema using (device_id, event_id) as PK. Em","explanation":"## Why This Is Asked\n\nTests practical streaming design at scale: late data, schema evolution, upserts into a lakehouse, data contracts, and lineage, plus engine trade-offs.\n\n## Key Concepts\n\n- Upserts into Iceberg with PK\n- Event-time processing and lateness\n- Nested JSON and data contracts\n- Data lineage and observability\n\n## Code Example\n\n```javascript\n// Pseudo-code: upsert path to Iceberg\n```\n\n## Follow-up Questions\n\n- How would you version data contracts for evolving fields?\n- How do you validate lineage correctness in prod?","diagram":"flowchart TD\n  Kafka --> Flink\n  Flink --> Iceberg\n  Iceberg --> DataMart\n  DataMart --> Lineage","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","Discord","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T06:41:37.218Z","createdAt":"2026-01-17T06:41:37.218Z"},{"id":"q-3312","question":"Design an end-to-end cross-region streaming pipeline ingesting 2.5M events/day from mobile apps into a lakehouse. Build a real-time feature store with time-bounded features, support late arrivals up to 10 minutes, and enforce per-region residency and masking. Compare Spark Structured Streaming vs Flink for the pipeline, and outline testing, monitoring, and data-contract guarantees?","answer":"Design a cross-region streaming pipeline that builds a time-bounded feature store from 2.5M events/day. Include late arrivals (up to 10 minutes), per-region residency and masking, and idempotent featu","explanation":"## Why This Is Asked\nTests ability to design end-to-end streaming pipelines with real-world constraints like region residency, privacy masking, and feature store integration; evaluates trade-offs between engines.\n\n## Key Concepts\n- Streaming ingestion and watermarking\n- Feature store versioning and idempotent upserts\n- Late-arrival handling and data contracts\n- Data residency and privacy controls\n- Testing and observability\n\n## Code Example\n```python\n# Pseudo upsert for a feature row\ndef upsert_feature(key, feature, store):\n    existing = store.get(key)\n    if existing is None or feature.version > existing.version:\n        store.put(key, feature)\n```\n\n## Follow-up Questions\n- How would you test data contracts for late events while ensuring training reproducibility?\n- Which metrics define latency targets across regions and how would you enforce backpressure?","diagram":"flowchart TD\n  A[Ingest Events] --> B[Resolve Region Residency]\n  B --> C[Mask PII & Apply Privacy Rules]\n  C --> D[Compute Time-Bounded Features]\n  D --> E[Store in Feature Lakehouse]\n  E --> F[Serve to Models]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Netflix","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T11:24:44.071Z","createdAt":"2026-01-17T11:24:44.071Z"},{"id":"q-3441","question":"Ingest 2 TB/day mobile app events in JSON with nested optional fields into an Iceberg lakehouse. Timestamps arrive in multiple time zones. Design end-to-end pipeline that normalizes times to UTC, flattens key nested fields into a flat schema, and upserts with per-record lineage. Include schema validation, handling of missing fields, and monitoring; compare Spark Structured Streaming vs Flink for this workload?","answer":"Design end-to-end: read 2 TB/day JSON events, normalize timestamps to UTC, flatten selected nested fields, and upsert into Iceberg with per-record lineage. Use a data contract to validate optional fie","explanation":"## Why This Is Asked\nThis angle tests time zone normalization, per-record lineage, and practical upsert challenges not covered by prior questions.\n\n## Key Concepts\n- Iceberg upserts, schema evolution\n- Nested JSON flattening, data contracts\n- Timezone normalization, idempotency, lineage\n\n## Code Example\n```javascript\n// Placeholder illustrative example: normalize timestamp and flatten nested fields\nfunction normalize(record) {\n  // pseudo-code\n}\n```\n\n## Follow-up Questions\n- How would you implement per-record lineage storage? \n- How do you validate schema evolution and backward compatibility? \n- How would you monitor data quality and alert on schema drift? ","diagram":"flowchart TD\n  Ingest[Ingest JSON] --> Normalize[Normalize Timestamps to UTC]\n  Normalize --> Flatten[Flatten Nested Fields]\n  Flatten --> Upsert[Idempotent Upsert into Iceberg]\n  Upsert --> Lineage[Per-Record Lineage]\n  Lineage --> Monitor[Monitoring & Alerts]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T16:39:39.317Z","createdAt":"2026-01-17T16:39:39.317Z"},{"id":"q-3545","question":"Design a real-time user-event pipeline ingesting multi-region nested JSON into a lakehouse (Iceberg). Each event includes user_id, event_ts, app_version, and a nested payload with optional fields that can evolve. Build an end-to-end flow with per-record data contracts, idempotent upserts, and per-record lineage; support late data, GDPR deletion, and maintain an online feature store for scoring with sub-100ms reads. Compare Spark Structured Streaming vs Flink for the streaming path, and outline testing and monitoring?","answer":"Ingest multi-region Kafka into Iceberg with a central schema registry. Enforce per-record contracts via runtime schema validation; implement idempotent upserts using event_id; handle late data with ev","explanation":"## Why This Is Asked\n\nTests ability to design a scalable, observable streaming pipeline that enforces contracts, handles schema evolution, and provides low-latency serving while satisfying privacy needs.\n\n## Key Concepts\n\n- Data contracts and runtime schema validation\n- Idempotent upserts and event_id management\n- Late-arrival handling with event-time semantics\n- GDPR deletions and tombstone strategies\n- Online feature store integration and serving latency targets\n- Spark vs Flink trade-offs for streaming\n- Observability: tests, monitoring, data quality checks\n\n## Code Example\n\n```python\ndef validate_event(event):\n    # Ensure required fields exist and types are correct\n    if 'user_id' not in event or 'event_ts' not in event:\n        return False\n    # Optional nested fields can be validated if present\n    return True\n```\n\n## Follow-up Questions\n\n- How would you test this pipeline with synthetic regional data and drift scenarios?\n- What rollback and backfill strategies would you implement for schema changes and GDPR deletions?","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Netflix","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-17T20:43:46.945Z","createdAt":"2026-01-17T20:43:46.945Z"},{"id":"q-3693","question":"Ingest 3 TB/day of JSON telemetry from 30 regional devices into an Iceberg lakehouse. Events include nested payloads with optional fields. Build a streaming pipeline that upserts using an idempotent upsert_id (device_id+event_id), enforces per-record data contracts with a schema registry, and records lineage. Handle late data (12h) and tombstones for deletes. Compare Spark Structured Streaming vs Flink and outline tests/monitoring?","answer":"Derive upsert_id from device_id+event_id and upsert into Iceberg via MERGE for idempotence. Validate each record against a schema registry (Avro/JSON) and emit per-record lineage to a lineage store. I","explanation":"## Why This Is Asked\nAssesses practical streaming design, data contracts, and lineage in a lakehouse; focuses on idempotence, schema evolution, late data, and operational visibility.\n\n## Key Concepts\n- Data contracts and schema evolution\n- Idempotent upserts in lakehouse (Iceberg)\n- Per-record lineage and data provenance\n- Late-arrival handling and tombstones\n\n## Code Example\n```javascript\n// Pseudo-Spark SQL MERGE for upsert into Iceberg\nspark.sql(`MERGE INTO iceberg.table AS t\n  USING updates AS s\n  ON t.upsert_id = s.upsert_id\n  WHEN MATCHED THEN UPDATE SET *\n  WHEN NOT MATCHED THEN INSERT *`)\n```\n\n## Follow-up Questions\n- How would you test schema evolution with non-breaking and breaking changes?\n- How would you monitor end-to-end latency and lineage quality?","diagram":"flowchart TD\n  Ingest[Ingest Events] --> Validate[Validate Contracts]\n  Validate --> Upsert[Upsert to Iceberg]\n  Upsert --> Lineage[Record Lineage]\n  Upsert --> Late[Late Data Handling]\n  Late --> Iceberg[Iceberg (Schema Evolution)]\n  Iceberg --> Monitor[Monitoring/Alerts]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["DoorDash","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T05:42:30.295Z","createdAt":"2026-01-18T05:42:30.295Z"},{"id":"q-3821","question":"You're building a real-time graph analytics platform that ingests edge events from IoT devices: fields include device_id, neighbor_id, ts, tenant_id, and edge_attrs (nested, evolving). Data lands per-tenant in object storage and must feed a lakehouse (Iceberg) with near-real-time graph views. Requirements: per-tenant isolation, late-arriving edges up to 12 hours, idempotent upserts for edge state, schema evolution for edge_attrs, and end-to-end data contracts with lineage. Compare Flink vs Spark for streaming, and outline testing, monitoring, and GDPR-delete handling?","answer":"Ingest per-tenant edges with Flink, write idempotent upserts to Iceberg using a composite key (tenant_id, device_id, neighbor_id) for edge_attrs. Allow late arrivals up to 12 hours with constrained la","explanation":"## Why This Is Asked\n\nAssesses ability to design scalable, multi-tenant streaming graph pipelines with strict data contracts, lineage, and compliance controls in modern lakehouse setups.\n\n## Key Concepts\n\n- Real-time streaming patterns: watermarking, lateness windows, fault tolerance\n- Idempotent upserts in Iceberg with composite keys (tenant/device/neighbor)\n- Schema evolution for nested attributes and backward compatibility\n- Per-record lineage and auditability; GDPR delete handling via tombstones\n- Multi-tenant isolation, access controls, and governance\n\n## Code Example\n\n```javascript\n// Pseudo upsert for edge state\nfunction upsertEdge(existing, incoming) {\n  const key = `${incoming.tenant_id}:${incoming.device_id}:${incoming.neighbor_id}`;\n  if (!existing || existing.version < incoming.version) return incoming;\n  return existing;\n}\n```\n\n## Follow-up Questions\n\n- How would you test late-arrival handling across tenants?\n- What monitoring would you implement to detect cross-tenant data leakage or drift?\n","diagram":null,"difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Plaid","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T10:44:58.693Z","createdAt":"2026-01-18T10:44:58.693Z"},{"id":"q-3827","question":"Design a global real-time fraud-detection pipeline for a fintech with three regional streams (Kafka and MQTT) producing JSON/Parquet. Build a lakehouse (Iceberg) with bronze/silver/gold layers, ensure per-record lineage and region-based data isolation, and GDPR deletion. Implement idempotent upserts and late-data handling with schema evolution. Compare Spark Structured Streaming vs Flink for the stream path and outline testing, monitoring, and rollback strategies?","answer":"Design a 3-layer lakehouse: bronze raw events, silver canonical schema with evolution, gold features/alerts. Use region-scoped namespaces and per-record lineage; implement GDPR tombstones and region-b","explanation":"## Why This Is Asked\n\nTests ability to design a cross-region streaming data platform with strict governance, lineage, and regulatory compliance. It also probes trade-offs between two leading engines in real-time pipelines.\n\n## Key Concepts\n\n- Multi-source streaming ingestion (Kafka, MQTT)\n- Iceberg lakehouse with bronze/silver/gold\n- Per-record lineage and region-based isolation\n- GDPR deletion and tombstones\n- Idempotent upserts, late data handling, schema evolution\n- Spark vs Flink trade-offs and testing\n\n## Code Example\n\n```javascript\n// Pseudo: upsert pattern using unique key with a sink table\n```\n\n## Follow-up Questions\n\n- How would you validate schema evolution without breaking downstream queries?\n- What monitoring metrics and alerting would you implement for data drift?\n","diagram":null,"difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","IBM","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-18T11:24:46.050Z","createdAt":"2026-01-18T11:24:46.051Z"},{"id":"q-4164","question":"Design a data mesh for ML features: ingest millions of signals from diverse sources, publish stable feature views to a central feature store, enforce per-source data contracts, implement drift detection and lineage to models, and honor GDPR deletions. Explain schema evolution, near-zero downtime feature updates, and a testing/monitoring plan?","answer":"Adopt a data mesh with a central feature store (Feast-like) backed by Iceberg tables. Enforce per-source contracts via a schema registry, publish versioned feature views, and emit lineage to models. I","explanation":"## Why This Is Asked\nThis question probes data-mesh ESL depth, feature-store design, data contracts, drift, and privacy controls in ML pipelines.\n\n## Key Concepts\n- Data mesh and centralized feature store\n- Per-source contracts and schema registry\n- Feature versioning and drift detection\n- GDPR deletion propagation\n- Testing and monitoring for quality and lineage\n\n## Code Example\n```yaml\n# Pseudo-config (not executable)\nsources:\n  payments:\n    contract: v1\n    retention_days: 365\nfeatures:\n  user_value_score_v1:\n    type: double\n    ttl_days: 7\n```\n\n## Follow-up Questions\n- How would you test drift detection thresholds and alerting?\n- What strategies ensure GDPR deletions propagate across feature versions?","diagram":"flowchart TD\nA[Publish per-source contracts] --> B[Central Feature Store]\nB --> C[Model training and inference]\nD[Drift detection] --> E[Alerts]\nE --> F[GDPR delete propagation]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Adobe","Meta","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T05:52:39.661Z","createdAt":"2026-01-19T05:52:39.661Z"},{"id":"q-4246","question":"Design a policy-driven data masking and lineage system for streaming user data into a data lakehouse. Data arrives from regional sources with PII; implement dynamic masking based on consent and region, propagate masking decisions downstream, and ensure end-to-end lineage and a reproducible testable rollback. Include data contracts, schema evolution, and GDPR delete handling. Compare Spark vs Flink for the streaming leg and outline testing/monitoring?","answer":"Build a policy-driven masking layer in the streaming path, sourcing consent and region from a policy service. Apply per-record field masking before writing to Iceberg, tag each row with policy_id for ","explanation":"## Why This Is Asked\nAssesses ability to design privacy-aware pipelines with per-record masking and full lineage in a lakehouse, plus real-world testing and compliance.\n\n## Key Concepts\n- Policy-driven masking; consent/regional governance\n- Per-record lineage propagation; OpenLineage-compatible\n- Data contracts; schema evolution; GDPR delete handling\n- Streaming choice: Flink vs Spark trade-offs\n\n## Code Example\n```python\ndef apply_mask(record, policy):\n    if policy.get('mask_email'):\n        record['email'] = mask_email(record['email'])\n    return record\n```\n\n## Follow-up Questions\n- How would you test end-to-end masking correctness across regions?\n- How would you backfill masking decisions if consent changes retroactively?","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Google","Meta","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T09:59:56.306Z","createdAt":"2026-01-19T09:59:56.306Z"},{"id":"q-4395","question":"Design a multi-region CDC ingest for a payments platform: region adapters expose fields (payment_id, user_id, region, timestamp, event_type, metadata) with differing schemas; implement a canonical Avro, a changelog for schema evolution, and an end-to-end pipeline that upserts into Iceberg lakehouse via Flink (or Beam on Dataflow). Ensure per-event lineage, GDPR delete handling, and test/monitor strategies; justify trade-offs between Flink and Beam?","answer":"Ingest with a canonical Avro and region adapters; publish a region-specific changelog; sink via Flink exactly-once upserts to Iceberg; record per-event lineage in a catalog; support GDPR deletes via t","explanation":"## Why This Is Asked\nTests ability to design cross-region, schema-evolving streaming ecosystems with strict compliance, lineage, and cost considerations.\n\n## Key Concepts\n- CDC and region adapters\n- Canonical schema and schema evolution\n- Iceberg lakehouse upserts\n- Per-event lineage and data catalog\n- GDPR delete handling and tombstones\n\n## Code Example\n```javascript\n// Pseudo: enable checkpointing for exactly-once semantics in Flink\nval env = StreamExecutionEnvironment.getExecutionEnvironment()\nenv.enableCheckpointing(60000)\n```\n\n## Follow-up Questions\n- How would you test schema evolution without downtime?\n- What metrics indicate coastline drift and data-skew across regions?","diagram":"flowchart TD\n A[Region Ingest] --> B[CDC Changelog]\n B --> C[Kafka]\n C --> D[Flink Upsert to Iceberg]\n D --> E[Iceberg Lakehouse]\n E --> F[Data Catalog lineage]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Amazon","Square","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T16:59:43.002Z","createdAt":"2026-01-19T16:59:43.002Z"},{"id":"q-4440","question":"Design and implement a CDC-based data pipeline that captures changes (insert/update/delete) from a PostgreSQL source at 50k rows/sec, streams to a data lake using Apache Iceberg, ensures idempotent upserts, per-record lineage, and automatic schema drift handling; compare Debezium + Spark Structured Streaming vs Flink for sink upserts, and describe testing and monitoring strategies?","answer":"Use a CDC source (Debezium) to capture inserts/updates/deletes from PostgreSQL at 50k rows/sec, emit an envelope with id, ts, op, and before/after, then upsert into Iceberg via Flink (exactly-once) us","explanation":"## Why This Is Asked\n\nTests ability to design CDC-driven pipelines with upserts in Iceberg, including deletes, lineage, and schema drift.\n\n## Key Concepts\n\n- CDC (Debezium)\n- Iceberg MERGE semantics\n- Exactly-once streaming\n- Data contracts and lineage\n- Monitoring and testing\n\n## Code Example\n\n```sql\nMERGE INTO iceberg_table AS t\nUSING staged_changes AS s\nON t.id = s.id\nWHEN MATCHED AND s.op = 'd' THEN DELETE\nWHEN MATCHED THEN UPDATE SET t.col1 = s.new_val, t.updated_at = s.ts\nWHEN NOT MATCHED THEN INSERT (id, col1, updated_at) VALUES (s.id, s.new_val, s.ts);\n```\n\n## Follow-up Questions\n\n- How would you test idempotence under retries?\n- How would you handle schema drift with evolving columns?\n","diagram":"flowchart TD\n  A[CDC Source: PostgreSQL via Debezium] --> B[Envelope + op]\n  B --> C[Iceberg Sink (MERGE INTO)]\n  C --> D[Data Lake]\n  B --> E[Lineage Channel]\n  E --> F[Audit/Monitoring]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","MongoDB","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T19:02:55.506Z","createdAt":"2026-01-19T19:02:55.506Z"},{"id":"q-4448","question":"You're building a geo-distributed ride-hailing analytics platform across 50 cities. Ingest GPS traces (vehicle_id, rider_id, ts, lat, lon), events (type: trip_start, trip_end), and telemetry. 2 TB/day of JSON. Requirements: per-city data isolation, GDPR deletion, schema evolution, idempotent upserts, late data up to 30 minutes, per-record data contracts, and robust data-quality gates. Propose end-to-end design: streaming ingestion, lakehouse (Iceberg), partitioning by city, and per-record lineage. Compare Spark Structured Streaming vs Flink for processing, and outline testing/monitoring strategies including contract tests?","answer":"Partition by city; ingest JSON events to a lakehouse (Iceberg) with idempotent upserts; enforce per-record data contracts via a schema registry (Avro/JSON) and support schema evolution; handle late da","explanation":"## Why This Is Asked\nTests handling of multi-city data sovereignty, strict data contracts, and production readiness for evolving schemas at scale. It probes thinking on idempotent upserts, late-arriving data, GDPR deletion, and governance alongside trade-offs between Spark and Flink.\n\n## Key Concepts\n- City-level partitioning and data isolation\n- Data contracts via schema registry and schema evolution\n- Lakehouse upserts with Iceberg and idempotency guarantees\n- Late data handling with watermarks and allowed lateness\n- GDPR deletion via tombstones and per-record lineage\n- Spark vs Flink trade-offs for latency and throughput\n- Data-quality gates and contract testing\n\n## Code Example\n```javascript\n// Pseudo contract check for incoming event against schema registry\nfunction validateEvent(event, schema) {\n  // validate required fields and types; fail fast on mismatch\n  // this is illustrative; integrate with a real registry in production\n  if (!event.vehicle_id || !event.ts) return false;\n  return true;\n}\n```\n\n## Follow-up Questions\n- How would you implement per-city data masking while preserving analytics?\n- How would you test schema evolution with backward/forward compatibility?","diagram":"flowchart TD\n  Ingest[Ingest streams] --> Process[Stream Processing]\n  Process --> Lake[Lakehouse (Iceberg)]\n  Lake --> BI[Analytics]\n  Ingest --> Govern[Governance & Deletion]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Airbnb","Scale Ai","Square"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-19T19:30:45.823Z","createdAt":"2026-01-19T19:30:45.823Z"},{"id":"q-4519","question":"You operate nightly ingestion of 30 regional vendor CSV feeds, each with up to 60 columns, some added over time. Data must land in a lakehouse (Iceberg) with per-record lineage and idempotent upserts, while dynamic schema evolution handles new columns. How would you design an end-to-end pipeline that enforces per-record data contracts, buffers late rows (up to 24h), isolates data by region, and validates data quality before load? Include simple monitoring and a concrete MERGE example?","answer":"Implement regional batch jobs that ingest CSV files into a staging Iceberg table with schema evolution capabilities, then upsert into the canonical table using MERGE on the primary key. Maintain per-record lineage in a dedicated LINEAGE table tracking source file, timestamp, and processing metadata. Configure a 24-hour buffer window for handling late-arriving data, validate all records against defined data contracts before staging, and enforce regional isolation through partitioned storage. Monitor job success rates, record counts, and data quality metrics with automated alerts.","explanation":"## Why This Is Asked\nTests practical design capabilities for batch-fed, multi-source data pipelines with evolving schemas, upserts, and lineage tracking. This scenario assesses intermediate-level understanding of data engineering patterns including data contracts, late data handling, and production monitoring.\n\n## Key Concepts\n- Regional batch processing with isolation\n- Iceberg schema evolution and idempotent upserts\n- Per-record lineage and contract enforcement\n- Late data buffering and quality validation\n- Production monitoring and observability\n\n## Code Example\n```sql\nMERGE INTO lake.target AS t\nUSING lake.staging AS s\nON t.primary_key = s.primary_key\nWHEN MATCHED THEN UPDATE SET *\nWHEN NOT MATCHED THEN INSERT *;\n```","diagram":"flowchart TD\n  Ingest[Regional CSV Feeds] --> Stage[Stage in Iceberg (staging)]\n  Stage --> Upsert[Upsert into Canonical Iceberg]\n  Upsert --> Lineage[Per-record Lineage]\n  Lineage --> Monitor[Quality Monitoring]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T07:13:04.669Z","createdAt":"2026-01-19T22:00:38.656Z"},{"id":"q-457","question":"You need to process 10GB of CSV files daily and load them into a PostgreSQL database. The files contain user activity logs with timestamps, user IDs, and event types. How would you design an efficient ETL pipeline using Python?","answer":"Use pandas with chunking for memory efficiency: `pd.read_csv('file.csv', chunksize=10000)`. Process each chunk, validate data types, convert timestamps with `pd.to_datetime()`, and use `psycopg2.extras.execute_batch()` for bulk inserts.","explanation":"## Key Components\n\n- **Memory Management**: Chunk large files to avoid memory issues\n- **Data Validation**: Check for missing values, correct data types\n- **Bulk Operations**: Use batch inserts instead of row-by-row\n- **Error Handling**: Log failed records for retry\n\n## Implementation Strategy\n\n```python\nimport pandas as pd\nimport psycopg2\nfrom psycopg2.extras import execute_batch\n\ndef process_csv_chunk(chunk):\n    # Clean and validate data\n    chunk['timestamp'] = pd.to_datetime(chunk['timestamp'])\n    chunk.dropna(inplace=True)\n    return chunk\n\ndef load_to_db(chunks):\n    conn = psycopg2.connect(database_url)\n    cursor = conn.cursor()\n    \n    for chunk in chunks:\n        processed_chunk = process_csv_chunk(chunk)\n        execute_batch(cursor, INSERT_QUERY, processed_chunk.values.tolist())\n    \n    conn.commit()\n    cursor.close()\n    conn.close()\n```","diagram":"flowchart TD\n  A[CSV Files] --> B[Chunk Processing]\n  B --> C[Data Validation]\n  C --> D[Type Conversion]\n  D --> E[Batch Insert]\n  E --> F[PostgreSQL]\n  B --> G[Error Logging]\n  G --> H[Retry Queue]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Anthropic","Discord","MongoDB"],"eli5":null,"relevanceScore":null,"voiceKeywords":["etl","chunking","pandas","memory efficiency","data validation","psycopg2"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-09T08:56:39.590Z","createdAt":"2025-12-26 12:51:05"},{"id":"q-4590","question":"You're building a real-time ad-tech analytics pipeline with impression and click events from multiple CDNs; data must be region-isolated, support late events up to 15 minutes, and GDPR deletions, with Iceberg as the lakehouse. Design end-to-end ingestion, processing, and storage, plus lineage and testing; compare Spark vs Flink trade-offs?","answer":"Implement region-scoped Kafka topics with Flink for low-latency upserts into Iceberg tables partitioned by region and date. Enforce per-record data contracts using Avro schemas with evolution rules, apply watermarking with 15-minute lateness tolerance, and handle GDPR deletions through Iceberg's row-level delete capabilities combined with metadata-based lineage tracking.","explanation":"## Why This Is Asked\nThis question evaluates practical streaming architecture design incorporating data contracts, late data handling, and privacy controls across geographic regions. It assesses understanding of Spark versus Flink trade-offs and implementation of idempotent upserts with comprehensive lineage tracking.\n\n## Key Concepts\n- Real-time ingestion with upserts to Iceberg lakehouse\n- Region-based partitioning and GDPR compliance\n- Data contracts enforced via Avro schemas\n- Watermarking and lateness tolerance management\n- Event lineage through unique IDs and metadata tracking\n\n## Code Example\n```scala\n// Flink job skeleton\nval env = StreamExecutionEnvironment.getExecutionEnvironment\nval stream = env.fromSource(KafkaSource.builder","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","Google","NVIDIA"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T05:56:44.094Z","createdAt":"2026-01-20T02:47:51.795Z"},{"id":"q-4689","question":"Design a beginner-friendly ingestion pipeline for a mobile app emitting JSON events (open, screen_views) at ~60k/min across regions. Ingest into a lakehouse with per-record data contracts and idempotent upserts. Flatten nested payloads, support late events up to 15 minutes, and produce daily active users by country/version. Compare Airflow vs Dagster for orchestration and outline tests and monitoring?","answer":"Use Spark Structured Streaming with a strict JSON schema to ingest 60k/min across regions, enforce per-record contracts, and upsert into Iceberg via MERGE on event_id. Flatten payloads, apply a 15-min","explanation":"## Why This Is Asked\nTests practical ingestion design, idempotent upserts to Iceberg, late-data handling, and simple downstream analytics. It also probes tooling choices for orchestration.\n\n## Key Concepts\n- Strict JSON schema to enforce per-record contracts\n- Idempotent upserts using event_id as key\n- Watermarks and allowed lateness to handle late events\n- Flattening nested payloads for downstream analytics\n- MERGE INTO for Iceberg writes\n- Windowed daily DAU by country/version\n- Dagster vs Airflow for testing, logging, and observability\n\n## Code Example\n```python\n# PySpark-like pseudocode (simplified)\ndf = spark.readStream.format(\"json\").load(\"/events\")\nstaged = df.selectExpr(\"event_id\", \"region\", \"payload.*\")\nstaged.createOrReplaceTempView(\"staging\")\n\nspark.sql(\"\"\"\nMERGE INTO iceberg.db.events AS t\nUSING staging AS s\nON t.event_id = s.event_id\nWHEN MATCHED THEN UPDATE SET t.region = s.region, t.payload = s.payload\nWHEN NOT MATCHED THEN INSERT (event_id, region, payload) VALUES (s.event_id, s.region, s.payload)\n\"\"\")\n```\n\n## Follow-up Questions\n- How would you test idempotency and late-arrival handling end-to-end?\n- What observability would you add to detect schema drift and data-skew issues?","diagram":"flowchart TD\n  A[Ingest JSON events] --> B[Flatten payloads]\n  B --> C[MERGE into Iceberg]\n  C --> D[Compute DAU window]\n  D --> E[Store results]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Coinbase","DoorDash","Salesforce"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T07:56:44.304Z","createdAt":"2026-01-20T07:56:44.304Z"},{"id":"q-4718","question":"You're building a geo-distributed rideshare telemetry pipeline across 24 regions. Ingest JSON events with nested metrics; land into Iceberg lakehouse with per-record lineage, and perform idempotent upserts on (vehicle_id, event_ts). Support dynamic schema evolution and late data up to 10 minutes. Describe end-to-end ingestion, region isolation, data contracts, a concrete MERGE example; compare Spark vs Flink for streaming and outline monitoring?","answer":"Design a region-scoped Iceberg lakehouse with per-record lineage and idempotent upserts on (vehicle_id, event_ts). Enforce contracts via a Schema Registry and Avro schemas; buffer late events up to 10","explanation":"## Why This Is Asked\n\nThis question probes ability to design a scalable, region-isolated streaming ingestion with evolving schemas, lineage, and upserts. It tests familiarity with Iceberg, schema management, and the trade-offs between Spark and Flink in production.\n\n## Key Concepts\n\n- Iceberg lakehouse + MERGE/UPSERT\n- Per-record lineage and data contracts via Schema Registry\n- Region isolation and partitioning\n- Late-arriving data handling and buffering\n- Observability: lineage tables, data quality gates\n\n## Code Example\n\n```sql\nMERGE INTO iceberg.ride_events AS target\nUSING staged_events AS source\nON target.vehicle_id = source.vehicle_id AND target.event_ts = source.event_ts\nWHEN MATCHED THEN UPDATE SET ...\nWHEN NOT MATCHED THEN INSERT ...\n```\n\n## Follow-up Questions\n\n- How would you implement per-region isolation in storage and compute?\n- What tests would you add for schema evolution and upserts?","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","Lyft","Twitter"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T09:48:27.330Z","createdAt":"2026-01-20T09:48:27.330Z"},{"id":"q-4812","question":"Ingesting 100 TB/day of Parquet into an Iceberg lakehouse across regions, design a cost-aware data lifecycle with per-tenant retention, dynamic tiering to hot/warm/cold storage, and a policy engine that preserves Iceberg time travel; how would you ensure sub-60s dashboard reads, encryption at rest, per-tenant masking, and scalable partition pruning for cost control?","answer":"Use Iceberg partition pruning and metadata caching to read only relevant partitions; drive tiering with a policy engine (OPA) tagging data by tenant and age, moving files to hot S3 for recent data, wa","explanation":"## Why This Is Asked\nTests ability to design scalable data lifecycle with multi-tenant governance and cost control; integrates Iceberg features, storage tiering, policy-driven retention, and query-layer masking.\n\n## Key Concepts\n- Iceberg time travel via snapshots\n- Dynamic data tiering (hot/warm/cold)\n- Per-tenant data masking\n- Encryption at rest (KMS)\n- Partition pruning and metadata caching\n\n## Code Example\n```javascript\nfunction selectTier(tenant, ageDays) {\n  const retention = (tenantRetention[tenant] || 365);\n  if (ageDays < 30) return 'hot';\n  if (ageDays < retention) return 'warm';\n  return 'cold';\n}\n```\n\n## Follow-up Questions\n- How would you test data freshness and mask correctness across tiers?\n- How would you validate time travel remains accurate after tiering moves?","diagram":"flowchart TD\n  A[Ingest 100 TB/day] --> B[Iceberg Lakehouse]\n  B --> C[Tier Policy Engine]\n  C --> D[Hot/Warm/Cold Storage]\n  D --> E[Time Travel via Snapshots]\n  E --> F[Masked Tenant Views]\n  F --> G[Dashboard Reads <60s]","difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Microsoft","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T14:43:15.367Z","createdAt":"2026-01-20T14:43:15.367Z"},{"id":"q-488","question":"You're building a real-time analytics pipeline for a food delivery app. How would you design a data pipeline to process 1M events/day with 5-minute latency, considering data quality, schema evolution, and cost optimization?","answer":"Use Kafka + Flink for stream processing with exactly-once semantics. Implement schema registry for evolution, use Debezium CDC for change capture. Store raw events in S3, processed data in Redshift. Use schema validation, data quality checks, and dead letter queues for reliability. Optimize costs with spot instances, S3 Intelligent Tiering, and Redshift RA3 nodes. Monitor with CloudWatch metrics and data freshness alerts.","explanation":"## Architecture\n- **Ingestion**: Apache Kafka with 3 partitions, replication factor 3\n- **Processing**: Apache Flink for windowed aggregations and joins with exactly-once semantics\n- **Storage**: Raw events in S3 (Parquet format), processed data in Redshift\n\n## Data Quality & Schema Evolution\n- Schema validation using Confluent Schema Registry\n- Data quality checks with Great Expectations\n- Dead letter queue for failed events\n- Debezium CDC for reliable change data capture\n\n## Cost Optimization\n- Spot instances for Flink cluster\n- S3 Intelligent Tiering for raw data\n- Redshift RA3 nodes for compute-storage separation\n\n## Monitoring\n- CloudWatch metrics for pipeline health\n- Data freshness alerts","diagram":"flowchart TD\n  A[Mobile Events] --> B[Kafka Broker]\n  B --> C[Flink Processing]\n  C --> D[Data Quality Check]\n  D --> E[S3 Raw Storage]\n  D --> F[Redshift Analytics]\n  F --> G[Bi Dashboard]\n  C --> H[Dead Letter Queue]","difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Google","Instacart"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-08T11:58:29.130Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-4887","question":"Design a beginner-friendly batch ingestion pipeline for daily Parquet files arriving from three partners (via S3). Each file contains customer events with fields: customer_id, event_ts, product_id, and a nested metadata field. Over time, new optional fields may be added. Describe end‑to‑end processing to flatten, enforce per-record contracts, upsert into an Iceberg lakehouse partitioned by date, and emit per‑file lineage. Include a simple test plan and a concrete MERGE example?","answer":"Ingest daily Parquet files from three partners, flatten nested metadata, enforce per-record contracts (customer_id, event_ts, product_id required; sensible defaults for optional fields), and upsert in","explanation":"Why This Is Asked\n- Assesses ability to design batch ingestion with schema evolution, data contracts, and lineage.\n- Exercises practical steps for flattening, validation, and idempotent upserts into a lakehouse.\n- Includes testing strategy and a concrete MERGE example.\n\nKey Concepts\n- Batch ETL for Parquet and multi-partner ingestion\n- Per-record data contracts and defaults for optional fields\n- Flattening nested fields to flat schema\n- Iceberg schema evolution and MERGE-based upserts\n- Per-file lineage via a manifest/log table\n- Simple test plan and basic monitoring\n\nCode Example\n```python\n# Pseudo-code: validate and normalize a record before MERGE\ndef validate(record):\n    if 'customer_id' not in record or 'event_ts' not in record or 'product_id' not in record:\n        return False\n    if not isinstance(record['customer_id'], int):\n        return False\n    # event_ts as ISO string or int epoch\n    return True\n\ndef normalize(record):\n    record.setdefault('country', 'UNKNOWN')\n    record['metadata'] = flatten(record.get('metadata', {}))\n    return record\n```\n\nFollow-up Questions\n- How would you handle late-arriving files and ensure idempotent MERGE semantics?\n- How would you validate schema evolution with Iceberg (e.g., new fields) and perform backward-compatible reads?","diagram":"flowchart TD\n  A[Ingest Parquet files] --> B[Flatten nested fields]\n  B --> C[Validate per-record contract]\n  C --> D[Upsert to Iceberg (MERGE)]\n  D --> E[Emit per-file lineage]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["IBM","MongoDB","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-20T17:45:10.641Z","createdAt":"2026-01-20T17:45:10.641Z"},{"id":"q-4979","question":"Ingest daily JSONL batches of video view events from a CDN into a lakehouse. Each event has required fields: view_id, user_id, video_id, timestamp; optional: device_type, country. Design a beginner-friendly end-to-end ETL to validate per-record contracts, perform idempotent upserts by view_id, and support schema evolution for new fields. Partition by date, handle late-arriving data via staging, and include basic tests and monitoring?","answer":"Use a Spark batch ETL that reads daily JSONL batches from S3, enforces a per-record contract (view_id, user_id, video_id, timestamp required; device_type, country optional), deduplicates by view_id, and performs idempotent upserts into an Iceberg table partitioned by date. The pipeline includes a staging layer for late-arriving data, supports schema evolution for new fields, and incorporates basic validation tests with monitoring metrics.","explanation":"## Why This Is Asked\nTests practical batch ETL design with data contracts, idempotent operations, and Iceberg schema evolution in a realistic, beginner-friendly scenario.\n\n## Key Concepts\n- JSONL batch ingestion and per-record validation\n- Deduplication by natural key with idempotent upserts\n- Iceberg table schema evolution capabilities\n- Date-based partitioning and staging for data safety\n- Essential testing patterns and monitoring metrics\n\n## Code Example\n```python\n# PySpark implementation sketch\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, to_date\n\nspark = SparkSession.builder.getOrCreate()\n\n# Read daily batch\ndf = spark.read.json(\"s3://cdn-batch/video-views/20260101/*.jsonl\")\n\n# Validate required fields\nvalidated = df.filter(\n    col(\"view_id\").isNotNull() & \n    col(\"user_id\").isNotNull() & \n    col(\"video_id\").isNotNull() & \n    col(\"timestamp\").isNotNull()\n)\n\n# Add date partition and deduplicate\nfinal_df = validated.withColumn(\"date\", to_date(col(\"timestamp\")))\\\n    .dropDuplicates([\"view_id\"])\n```","diagram":"flowchart TD\n  CDN[CDN JSONL Batch] --> Staging[Staging Area]\n  Staging --> Validation[Contract Validation]\n  Validation --> Dedup[Deduplicate by view_id]\n  Dedup --> Iceberg[Iceberg Table (partition date)]\n  Iceberg --> Monitoring[Monitoring & Alerts]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["Bloomberg","DoorDash","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T04:35:47.401Z","createdAt":"2026-01-20T22:33:25.661Z"},{"id":"q-5078","question":"Design a beginner-friendly data ingestion pipeline for a fleet of autonomous devices issuing 800 events/sec per region as nested JSON. Ingest into a lakehouse (Iceberg) with per-record data contracts (JSON Schema), redaction of PII at the edge before load, and per-record lineage. Support additive schema evolution and late arrivals up to 15 minutes. Outline end-to-end flow, data quality checks, monitoring, and a simple idempotent upsert strategy?","answer":"Edge devices redact PII before sending; use JSON Schema contracts to validate each event; stream into a staging area and upsert into Iceberg using MERGE with event_id as the key; emit per-record linea","explanation":"## Why This Is Asked\n\nTests ability to design an end-to-end ingestion with privacy, lineage, schema evolution, and late data handling, at a beginner-friendly level.\n\n## Key Concepts\n\n- JSON Schema data contracts\n- Edge redaction of PII\n- Per-record lineage/audit\n- Iceberg upserts (MERGE) and additive schema evolution\n- Late-arrival handling with watermark\n\n## Code Example\n\n```sql\nMERGE INTO iceberg_table AS t\nUSING staging AS s\nON t.event_id = s.event_id\nWHEN MATCHED THEN UPDATE SET ...\nWHEN NOT MATCHED THEN INSERT (...);\n```\n\n## Follow-up Questions\n\n- How would you validate additive-only schema changes across regions?\n- How would you simulate late events during testing and measure latency?","diagram":"flowchart TD\n  A[Edge Device] --> B[Ingest & Validate]\n  B --> C[PII Redaction]\n  C --> D[Streaming Ingest]\n  D --> E[Staging -> Iceberg]\n  E --> F[Idempotent Upsert (MERGE)]\n  F --> G[Audit Lineage]\n  G --> H[Monitoring]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":null,"companies":["NVIDIA","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-21T05:39:03.373Z","createdAt":"2026-01-21T05:39:03.373Z"},{"id":"q-518","question":"You have a 10GB CSV file with user activity logs that needs to be processed daily. The file contains user_id, timestamp, action_type, and metadata. How would you design a data pipeline to efficiently process this file and load it into a data warehouse?","answer":"Use a distributed processing framework like Apache Spark or AWS Glue. Split the CSV into partitions, process in parallel, apply schema validation and data cleaning, then load into the warehouse using bulk insert operations.","explanation":"## Key Considerations\n- **File Size**: 10GB requires distributed processing for efficient handling\n- **Schema**: Define proper data types and constraints to ensure data quality\n- **Performance**: Implement partitioning and parallel processing for scalability\n\n## Pipeline Architecture\n- **Ingestion**: Store in S3 or similar object storage for scalable access\n- **Processing**: Use Spark/PySpark for distributed computation across multiple nodes\n- **Transformation**: Apply data cleaning, validation, and enrichment logic\n- **Loading**: Perform bulk insert operations to the warehouse (Snowflake, BigQuery)\n\n## Implementation Steps\n- Read CSV with proper schema definition to optimize parsing\n- Handle malformed records with comprehensive error logging\n- Apply business rules and data quality checks\n- Load processed data into warehouse using efficient bulk loading methods","diagram":"flowchart TD\n  A[10GB CSV] --> B[Spark Cluster]\n  B --> C[Data Validation]\n  C --> D[Transformation]\n  D --> E[Data Warehouse]\n  C --> F[Error Logging]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Adobe","Airbnb","Oracle"],"eli5":null,"relevanceScore":null,"voiceKeywords":["apache spark","aws glue","distributed processing","data warehouse","schema validation","data cleaning"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-08T11:42:43.700Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-571","question":"How would you design a data pipeline to process 1M ride events per minute from Uber's real-time streaming system?","answer":"Design a data pipeline using Apache Kafka to ingest 1M ride events per minute with partitioning by ride_id, Apache Flink for real-time stream processing with windowed aggregations, and write optimized Parquet files to S3 partitioned by date and hour for efficient querying.","explanation":"## Architecture\n- **Ingestion**: Kafka with 3x replication, partitioned by geographic region\n- **Processing**: Flink with exactly-once semantics, 1-minute tumbling windows\n- **Storage**: S3 with Parquet format, compressed with Snappy\n\n## Key Considerations\n- **Scalability**: Auto-scale consumer groups based on lag metrics\n- **Fault tolerance**: Checkpointing to HDFS every 30 seconds\n- **Data quality**: Schema validation and duplicate detection\n\n## Code Example\n```python\nfrom pyflink.datastream import StreamExecutionEnvironment\nfrom pyflink.table import StreamTableEnvironment\nfrom pyflink.datastream.connectors import FlinkKafkaConsumer\nfrom pyflink.datastream.formats.json import JsonRowDeserializationSchema\n\n# Setup Flink environment\nenv = StreamExecutionEnvironment.get_execution_environment()\nenv.set_parallelism(12)  # Scale based on throughput\nenv.enable_checkpointing(30000)  # 30s checkpointing\n\n# Kafka consumer configuration\nkafka_props = {\n    'bootstrap.servers': 'kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092',\n    'group.id': 'ride-events-processor',\n    'auto.offset.reset': 'latest'\n}\n\n# Define ride event schema\ntype_info = Types.ROW_NAMED(\n    ['ride_id', 'timestamp', 'lat', 'lon', 'driver_id', 'rider_id', 'fare'],\n    [Types.STRING(), Types.SQL_TIMESTAMP(), Types.DOUBLE(), Types.DOUBLE(), \n     Types.STRING(), Types.STRING(), Types.DOUBLE()]\n)\n\n# Create Kafka source\nkafka_source = FlinkKafkaConsumer(\n    topics='ride-events',\n    deserialization_schema=JsonRowDeserializationSchema.builder()\n        .type_info(type_info)\n        .build(),\n    properties=kafka_props\n)\n\n# Process ride events with 1-minute windows\nride_stream = env.add_source(kafka_source) \\\n    .key_by(lambda x: x[2]) \\\n    .window(TumblingEventTimeWindows.of(Time.minutes(1))) \\\n    .aggregate(\n        aggregate_function=RideMetricsAggregator(),\n        window_function=MetricsWindowFunction()\n    )\n\n# Write to S3 in Parquet format\nride_stream.add_sink(\n    StreamingFileSink.for_bulk_format(\n        's3://uber-ride-events/processed/',\n        ParquetBulkWriter.for_schema(type_info)\n    ).build()\n)\n\n# Execute pipeline\nenv.execute('uber-ride-events-pipeline')\n```\n\n## Monitoring\n- Consumer lag alerts\n- Processing latency metrics\n- Data completeness checks","diagram":"flowchart TD\n  A[Ride Events] --> B[Kafka Cluster]\n  B --> C[Flink Processing]\n  C --> D[S3 Parquet Files]\n  C --> E[Real-time Dashboard]\n  D --> F[Analytics DB]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Meta","Twitter","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":["apache kafka","apache flink","stream processing","partitioning","parquet","windowed aggregations"],"voiceSuitable":true,"isNew":false,"lastUpdated":"2026-01-07T03:44:27.623Z","createdAt":"2025-12-27T01:12:24.585Z"},{"id":"q-885","question":"You operate a multi-tenant SaaS analytics platform ingesting per-tenant event streams from Kafka into Snowflake. Each tenant has different event schemas that can evolve independently. Design a data pipeline to enforce per-tenant data contracts, support late-arriving events, and minimize schema drift while controlling storage costs. Include schema versioning, validation, and deployment safety steps?","answer":"Design a per-tenant schema registry with versioned contracts and a streaming processor that validates each event against its tenant’s current contract, routing to tenant-specific Snowflake partitions ","explanation":"## Why This Is Asked\nTests ability to model per-tenant contracts and schema evolution in a streaming pipeline and to handle late-arriving data without breaking consumers.\n\n## Key Concepts\n- Per-tenant data contracts and a registry\n- Schema evolution policies and compatibility checks\n- Late-arrival handling with watermarking\n- Cost-aware storage isolation per tenant\n\n## Code Example\n```javascript\n// Pseudo-code illustrating per-tenant validation\nfunction validateEvent(event, tenant) {\n  const contract = registry.getContract(tenant, event.version);\n  return contract ? contract.validate(event) : false;\n}\n```\n\n## Follow-up Questions\n- How would you test schema drift detection?\n- How would you roll back a bad schema change without data loss?","diagram":null,"difficulty":"intermediate","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["NVIDIA","Snowflake","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T14:23:12.167Z","createdAt":"2026-01-12T14:23:12.167Z"},{"id":"q-915","question":"You ingest 200k newline-delimited JSON app events daily into S3. Each event has event_id, user_id, timestamp, event_type, and attributes. Design a beginner-friendly pipeline to deduplicate by event_id, hash user_id for privacy, validate required fields, and write Parquet data partitioned by date in a data lake. Address simple schema drift and testing?","answer":"Ingest daily JSON lines, deduplicate by event_id, hash user_id with SHA-256, validate required fields, and write Parquet data partitioned by date in a data lake. Include a simple schema-drift strategy","explanation":"## Why This Is Asked\n\nThis question tests practical basics of building a reliable, beginner-friendly data pipeline: ingestion from S3, deduplication, privacy via hashing, basic schema drift handling, and testing. It avoids company-specific traps while focusing on core ETL behavior.\n\n## Key Concepts\n\n- Ingestion from object storage and newline-delimited JSON\n- Deduplication by stable key event_id\n- Privacy: deterministic hashing of user_id\n- Schema drift: optional fields with defaults\n- Parquet partitioning by date; lightweight validation\n\n## Code Example\n\n```python\n# Pseudo-code sketch for deduplication\nimport json, hashlib\n\ndef process(lines):\n    seen = set()\n    for line in lines:\n        e = json.loads(line)\n        if 'event_id' not in e or 'user_id' not in e or 'timestamp' not in e:\n            continue\n        if e['event_id'] in seen:\n            continue\n        seen.add(e['event_id'])\n        yield {\n            'event_id': e['event_id'],\n            'timestamp': e['timestamp'],\n            'user_id_hashed': hashlib.sha256(e['user_id'].encode()).hexdigest(),\n            'event_type': e.get('event_type'),\n            'attributes': e.get('attributes', {})\n        }\n```\n\n## Follow-up Questions\n\n- How would you test idempotency for reprocessing files?\n- How would you monitor data quality and schema drift over time?","diagram":"flowchart TD\n  A[Source: S3] --> B[Ingest] \n  B --> C[Deduplicate by event_id] \n  C --> D[Transform] \n  D --> E[Partitioned Parquet Lake]","difficulty":"beginner","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","MongoDB","Snap"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T15:27:56.228Z","createdAt":"2026-01-12T15:27:56.228Z"},{"id":"q-993","question":"Design a global, multi-tenant data ingestion system for a ride-hailing platform with streams for billing, trips, safety, and promotions. Each tenant defines a data contract; schemas evolve independently; late-arriving events up to 15 minutes must be accepted. Describe architecture using Apache Kafka, Schema Registry (Avro/JSON), an Iceberg/Delta lake sink, and a streaming processor (Flink/Spark). Include data model, schema evolution, backfill handling, testing, and observability?","answer":"Design a multi-tenant ingestion: enforce per-tenant contracts via a central Schema Registry (Avro) with backward/forward compatibility, publish to dedicated Kafka topics per stream, process with Flink","explanation":"## Why This Is Asked\nAssesses ability to build scalable, contract-driven ingestion across tenants with late data, schema evolution, and strong observability.\n\n## Key Concepts\n- Per-tenant data contracts and registry-based schema governance\n- Backward/forward compatibility and evolution strategy\n- Late-arriving data handling with event-time processing and watermarks\n- Exactly-once semantics, idempotent writes, and upserts\n- Observability: lineage, data freshness SLIs, drift alerts\n- Backfill testing and controlled replay plans\n\n## Code Example\n```json\n{\n  \"type\": \"record\",\n  \"name\": \"TripEvent\",\n  \"namespace\": \"com.example\",\n  \"fields\": [\n    {\"name\": \"tenant_id\", \"type\": \"string\"},\n    {\"name\": \"event_time\", \"type\": {\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}},\n    {\"name\": \"payload\", \"type\": {\"type\": \"map\", \"values\": \"string\"}}\n  ]\n}\n```\n\n## Follow-up Questions\n- How would you test schema drift across tenants without affecting throughput?\n- How would you design rollback and backfill workflows for a failed batch?","diagram":null,"difficulty":"advanced","tags":["data-engineering"],"channel":"data-engineering","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Coinbase","DoorDash","Meta"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2026-01-12T18:37:56.085Z","createdAt":"2026-01-12T18:37:56.085Z"},{"id":"q-176","question":"How would you design a data pipeline that handles both batch and streaming workloads for real-time analytics?","answer":"I would implement a Lambda architecture that combines both batch and streaming processing. The batch layer would handle historical data processing for accuracy, while the speed layer would process real-time data streams for immediate insights. Both layers would be integrated through a unified serving layer that merges results and provides a comprehensive view.","explanation":"## Why Asked\nThis question evaluates your understanding of modern data architecture patterns and your ability to design systems that handle multiple processing paradigms effectively.\n\n## Key Concepts\nLambda architecture, batch processing, stream processing, data consistency, real-time analytics, fault tolerance, scalability\n\n## Code Example\n```\n// Stream processing example (Apache Flink)\nDataStream<Event> stream = env.addSource(kafkaSource);\nstream.window(TumblingProcessingTimeWindows.of(Time.minutes(5)))\n      .aggregate(new CountAggregate())\n      .addSink(sink);\n```","diagram":"flowchart TD\n    A[Data Source] --> B[Batch Layer]\n    A --> C[Speed Layer]\n    B --> D[Batch View]\n    C --> E[Real-time View]\n    D --> F[Serving Layer]\n    E --> F\n    F --> G[Analytics/Queries]","difficulty":"beginner","tags":["streaming","kafka"],"channel":"data-engineering","subChannel":"streaming","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Meta","Netflix","Uber"],"eli5":"Imagine you have two ways to make lemonade at your lemonade stand! One way is making big batches in the morning (that's your batch processing) - you mix everything perfectly and it tastes great. The other way is making fresh cups one by one as friends arrive (that's your streaming) - super fast but maybe not as perfect. The smart trick is having both! You serve the fresh cups right away for instant refreshment, but you also have your perfect batch ready for when someone wants the best-tasting lemonade. Your brain keeps track of both - you know who got fresh cups now and who will get the perfect batch later. That way, everyone gets lemonade exactly when they need it, and you can tell your parents exactly how much you sold today!","relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2025-12-29T08:40:26.305Z","createdAt":"2025-12-26 12:51:06"},{"id":"q-222","question":"How would you design a Kafka Streams application to handle exactly-once processing with stateful aggregations while maintaining sub-second latency during peak loads of 100K events/sec?","answer":"Configure EOS_ALPHA with processing.guarantee=exactly_once_v2, use RocksDB state stores with changelog compaction, enable standby replicas, tune num.stream.threads=cores*2, set cache.max.bytes.buffering=10MB, and monitor consumer lag with Prometheus metrics.","explanation":"## Architecture\n**Exactly-once semantics**: EOS_ALPHA with transactional producers ensures atomic state updates and output commits\n**State management**: RocksDB local state + compacted changelog topics for fast recovery\n**Performance tuning**: Optimize thread pool, buffer sizes, and batch processing for sub-second latency\n\n## NFRs & Calculations\n**Throughput**: 100K events/sec ÷ 4 cores = 25K events/thread/sec\n**Latency**: Target <500ms with 100ms batch intervals\n**Storage**: 1GB state store ÷ 10MB cache = 100 cache entries\n**Recovery**: Standby replicas enable <30s failover\n\n## Key Configurations\n```properties\nprocessing.guarantee=exactly_once_v2\nnum.standby.replicas=1\ncache.max.bytes.buffering=10485760\ncommit.interval.ms=100\n```\n\n## Monitoring & Error Handling\n**Metrics**: consumer-lag, stream-latency, state-size\n**Alerts**: lag > 1000 events, latency > 1s\n**Recovery**: Automatic state restoration from changelog with incremental backups","diagram":"flowchart LR\n    A[Producer] --> B[Kafka Topic]\n    B --> C[Kafka Streams App]\n    C --> D[State Store]\n    C --> E[Standby Replica]\n    D --> F[Compact Topic]\n    E --> F\n    C --> G[Output Topic]\n    G --> H[Consumer]\n    I[Traffic Spike] --> C\n    C --> J[Adaptive Processing]\n    J --> K[Scale Out]","difficulty":"advanced","tags":["kafka","flink","kinesis"],"channel":"data-engineering","subChannel":"streaming","sourceUrl":null,"videos":{"longVideo":"https://www.youtube.com/watch?v=Z_gCv4Uum44"},"companies":["Amazon","Confluent","Netflix","Stripe","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2025-12-26T16:34:11.088Z","createdAt":"2025-12-26 12:51:07"},{"id":"q-248","question":"How would you implement exactly-once processing in a data pipeline when both source (Kafka) and sink (database) can fail, ensuring no duplicate data or data loss during network partitions and system crashes?","answer":"Implement Kafka transactions with idempotent producers (enable.idempotence=true), use database transaction IDs for deduplication, commit offsets only after successful DB commit, and configure EOS=ALWAYS for exactly-once semantics. Include retry logic with exponential backoff and dead-letter queue handling.","explanation":"## Core Implementation\n\n**Kafka Configuration:**\n```java\nProperties props = new Properties();\nprops.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\nprops.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"pipeline-\" + UUID.randomUUID());\nprops.put(ProducerConfig.ACKS_CONFIG, \"all\");\nprops.put(ProducerConfig.RETRIES_CONFIG, Integer.MAX_VALUE);\n```\n\n**Transaction Pattern:**\n```java\n// Initialize transaction\nproducer.initTransactions();\n\ntry {\n    // Begin Kafka transaction\n    producer.beginTransaction();\n    \n    // Process and send to Kafka\n    ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);\n    producer.send(record);\n    \n    // Database operation with transaction ID\n    String txId = UUID.randomUUID().toString();\n    jdbcTemplate.update(\"INSERT INTO data_table VALUES (?, ?, ?)\", \n        id, value, txId);\n    \n    // Commit offset only after DB success\n    producer.sendOffsetsToTransaction(offsets, consumer);\n    producer.commitTransaction();\n    \n} catch (Exception e) {\n    producer.abortTransaction();\n    // Retry logic with exponential backoff\n}\n```\n\n## Failure Recovery Strategies\n\n**Database Deduplication:**\n- Unique constraint on transaction_id column\n- INSERT IGNORE or ON CONFLICT DO NOTHING\n- Periodic cleanup of processed transaction IDs\n\n**Offset Management:**\n- Manual offset commits after successful processing\n- Store offsets in database for consistency\n- Use consumer group coordination for failover\n\n**Error Handling:**\n- Circuit breaker pattern for database failures\n- Dead-letter queue for unprocessable messages\n- Monitoring and alerting for transaction failures\n\n## Real-World Considerations\n\n**Performance Trade-offs:**\n- EOS=ALLS adds ~20% latency overhead\n- Increased memory usage for transaction state\n- Requires careful broker configuration (min.insync.replicas=2)\n\n**Edge Cases:**\n- Network partitions during commit phase\n- Broker leadership changes mid-transaction\n- Database connection pool exhaustion\n\n**Monitoring:**\n- Track transaction abort rates\n- Monitor consumer lag during failures\n- Alert on duplicate detection events","diagram":"graph TD\n    A[Kafka Topic] --> B[Consumer Poll]\n    B --> C[Begin Transaction]\n    C --> D[Process Records]\n    D --> E[Database UPSERT with TxID]\n    E --> F{Success?}\n    F -->|Yes| G[Send Offsets to Transaction]\n    F -->|No| H[Abort Transaction]\n    G --> I[Commit Transaction]\n    H --> J[Retry Processing]\n    I --> K[Next Poll]\n    J --> B","difficulty":"intermediate","tags":["dag","orchestration","scheduling"],"channel":"data-engineering","subChannel":"streaming","sourceUrl":null,"videos":null,"companies":["Amazon","Google","Meta","Microsoft","Netflix","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":false,"lastUpdated":"2025-12-26T16:38:30.418Z","createdAt":"2025-12-26 12:51:07"}],"subChannels":["general","streaming"],"companies":["Adobe","Airbnb","Amazon","Anthropic","Apple","Bloomberg","Citadel","Coinbase","Confluent","Databricks","Discord","DoorDash","Goldman Sachs","Google","IBM","Instacart","LinkedIn","Lyft","Meta","Microsoft","MongoDB","NVIDIA","Netflix","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Snap","Snowflake","Square","Stripe","Tesla","Twitter","Two Sigma","Uber","Zoom"],"stats":{"total":50,"beginner":18,"intermediate":17,"advanced":15,"newThisWeek":34}}