{"questions":[{"id":"q-1006","question":"Design a real-time telemetry ingestion pipeline for a fleet of autonomous vehicles on Azure. Events arrive at high volume per region; you must store compact per-vehicle summaries in Cosmos DB and archive raw events to Data Lake Gen2. How would you achieve exactly-once processing for aggregates, sub-200 ms latency, and zero data loss on transient failures? Propose architecture using Event Hubs, Functions, Databricks, and cross-region replication; justify idempotency and retry strategies?","answer":"Implement a pipeline: Ingest events via Event Hubs, process with Databricks Structured Streaming to produce per-vehicle aggregates on a sliding window with watermarking; write to Cosmos DB using idemp","explanation":"## Why This Is Asked\nTests ability to design scalable, fault-tolerant ingest with exactly-once semantics across regions.\n\n## Key Concepts\n- Ingestion via Event Hubs; streaming processing with Databricks; idempotent sinks in Cosmos DB; archive to ADLS Gen2; multi-region writes; retries; dead-lettering.\n\n## Code Example\n```javascript\n// Idempotent upsert for aggregate sink\nconst key = vehicleId + '|' + windowEnd;\nawait container.items.upsert({ id: key, vehicleId, windowEnd, sum, count, ts: Date.now() });\n```\n\n## Follow-up Questions\n- How would you test exactly-once semantics under backpressure? \n- What monitoring would you add for cross-region latency and data loss?","diagram":"flowchart TD\nA[Event Hubs ingress] --> B[Databricks Structured Streaming]\nB --> C[Cosmos DB upsert: id=vehicleId|windowEnd]\nA --> D[ADLS Gen2 Archive via Capture]\nC --> E[Multi-region Cosmos Writes]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:51:22.684Z","createdAt":"2026-01-12T18:51:22.684Z"},{"id":"q-1136","question":"Design an end-to-end telemetry ingestion pipeline for 1M devices/min delivering messages {vehicleId, ts, lat, lon, speed}. Ingest via HTTPS into Event Hubs with vehicleId as partition key, process with a Function app (Event Hubs trigger) using batchSize=100; deduplicate per vehicle with Durable Entity and upsert to Cosmos DB multi-region. Explain data model, idempotency, Change Feed, backpressure, and monitoring?","answer":"Event Hubs partitioned by vehicleId; Functions with Event Hubs trigger (batchSize 100, prefetch 300) writes upserts to Cosmos DB (multi-region) and uses a per-vehicle Durable Entity to deduplicate, pr","explanation":"## Why This Is Asked\nTests ability to design scalable, fault-tolerant ingest with exactly-once semantics on Cosmos DB.\n\n## Key Concepts\n- Event Hubs partitioning, throughput units\n- Durable Entities for per-vehicle state\n- Cosmos DB multi-region upserts\n- Change Feed for read models and analytics\n- Backpressure, retries, monitoring\n\n## Code Example\n```javascript\n// Pseudo: durable entity for dedupe per vehicle\nclass VehicleState {\n  apply(event) { /* debounce and upsert once */ }\n}\n```\n\n## Follow-up Questions\n- How would you handle schema evolution for vehicle telemetry?\n- How would you validate end-to-end latency under peak loads?","diagram":"flowchart TD\n  Ingest[HTTPS Telemetry] --> EH[Event Hubs]\n  EH --> Fn[Functions (E/H trigger)]\n  Fn --> Cosmos[Cosmos DB (upsert)]\n  Cosmos --> Read[Read Model (Change Feed)]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Amazon","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:25:35.864Z","createdAt":"2026-01-13T01:25:35.864Z"},{"id":"q-1248","question":"Design an end-to-end Azure ingestion pipeline for multi-tenant IoT events: thousands of devices per region send JSON to a gateway, per-tenant aggregates stored in Cosmos DB, raw data archived to Data Lake Gen2. Explain chosen services (Event Hub, Function/Durable Function, Cosmos DB with TTL, Data Lake), how you enforce per-tenant isolation and auditability, and how you achieve exactly-once processing and retry semantics?","answer":"Use Event Hubs in a regional namespace to ingest; route to Durable Functions that implement idempotent writes using a composite key (tenantId, messageId). Cosmos DB with partitionKey=tenantId stores a","explanation":"## Why This Is Asked\nThis tests practical Azure data-pipeline design, multi-tenancy, and reliability in production.\n\n## Key Concepts\n- Event Hubs, Durable Functions, Cosmos DB, Data Lake Gen2\n- Per-tenant partitioning, RBAC, Managed Identities\n- Deduplication, idempotent writes, retry strategies\n\n## Code Example\n```javascript\n// Pseudo Durable Function outline for idempotent processing\n```\n\n## Follow-up Questions\n- How would you test for cross-tenant data leakage?\n- How would you monitor latency and backpressure across regions?","diagram":null,"difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Citadel","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T06:42:46.713Z","createdAt":"2026-01-13T06:42:46.713Z"},{"id":"q-1277","question":"Design a real-time multi-tenant feature-store pipeline on Azure for a high-velocity AI platform. Ingest telemetry events via Event Hubs (tenantId, featureName, value, ts). Build end-to-end streaming with exactly-once semantics, isolation by tenant, and low-latency online reads. Specify concrete components (Event Hubs, Spark Structured Streaming, Cosmos DB with tenantId partition, Redis online store), auditability, TTL, and testing strategy?","answer":"Ingress: Event Hubs (tenantId key). Processing: Spark Structured Streaming with strict checkpointing for exactly-once; writes to Cosmos DB partitioned by tenantId (upsert for idempotence) plus a Redis","explanation":"## Why This Is Asked\nAssess ability to architect multi-tenant streaming systems on Azure with strong data isolation, idempotence, and end-to-end correctness.\n\n## Key Concepts\n- Event Hubs + Spark Structured Streaming\n- Cosmos DB partitioning by tenantId\n- Upsert semantics for idempotence\n- Redis as online store for latency\n- Audit/logging, TTL, RBAC and data isolation\n\n## Code Example\n```javascript\n// Pseudocode for upsert into Cosmos DB to preserve idempotence\nfunction saveFeature(tenantId, key, value, timestamp) {\n  const doc = { id: `${tenantId}:${key}`, tenantId, key, value, ts: timestamp };\n  cosmos.upsertItem(doc);\n}\n```\n\n## Follow-up Questions\n- How would you test end-to-end with replay and fault injection?\n- How would you enforce data retention, privacy, and tenant isolation in practice?","diagram":"flowchart TD\n  A[Event Ingest] --> B[Spark Structured Streaming]\n  B --> C[Cosmos DB (tenantId PK)]\n  B --> D[Redis Online Store]\n  C --> E[Audit Log / Changelog]\n  D --> E","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T07:40:49.401Z","createdAt":"2026-01-13T07:40:49.401Z"},{"id":"q-1359","question":"A small API running on Azure Functions must securely retrieve a database connection string from Azure Key Vault at startup and refresh it periodically without restarting the function. Propose a beginner-friendly, low-latency approach using Managed Identity and Key Vault, including caching strategy, rotation handling, and error fallback?","answer":"Use a single Function App with a managed identity to fetch the connection string from Key Vault via SecretClient. Cache the secret in-memory with a short TTL (5–10 minutes) and refresh via a timer-bas","explanation":"## Why This Is Asked\nTests ability to combine cloud identity, secret management, and cache-based freshness in a simple serverless setup. It also probes handling secret rotation with minimal downtime.\n\n## Key Concepts\n- Managed Identity and Key Vault access\n- Secret retrieval patterns and in-memory caching\n- Cache invalidation and rotation handling\n- Error fallback and observability\n\n## Code Example\n```javascript\nimport { SecretClient } from \"@azure/keyvault-secrets\";\nimport { DefaultAzureCredential } from \"@azure/identity\";\n\nconst credential = new DefaultAzureCredential();\nconst vaultUrl = process.env.KEY_VAULT_URL;\nconst client = new SecretClient(vaultUrl, credential);\nlet cachedConnStr = null;\nlet cacheExpiry = 0;\n\nasync function loadConnStr() {\n  const secret = await client.getSecret(\"DbConnectionString\");\n  cachedConnStr = secret.value;\n  cacheExpiry = Date.now() + 10 * 60 * 1000; // 10 minutes\n  return cachedConnStr;\n}\n```\n\n## Follow-up Questions\n- How would you simulate and test secret rotation without impacting users?\n- How would you scale this in a multi-instance Function App deployment?\n- What changes if Key Vault is temporarily unavailable?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Salesforce","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:13:54.965Z","createdAt":"2026-01-13T13:13:54.965Z"},{"id":"q-1397","question":"Design a multi-region, per-tenant Azure API with data residency, deterministic retries, and exactly-once semantics at scale. Propose services (APIM, Functions + Durable Functions, Cosmos DB per-tenant, Front Door, Private Endpoints) and explain how per-tenant isolation, data residency, and retry determinism are achieved?","answer":"Use APIM in each region in front of a Durable Functions orchestrator that enforces idempotency via a per-tenant idempotency key. Route writes to Cosmos DB with per-tenant partition keys and multi-regi","explanation":"## Why This Is Asked\n\nAssesses practical Azure design for data residency, regional routing, and robust exactly-once processing at scale. Expected to justify service choices, tenancy isolation, and fault-tolerant retry strategies.\n\n## Key Concepts\n\n- Idempotency keys and per-tenant isolation\n- Durable Functions orchestrations for reliable retries\n- Cosmos DB per-tenant partitions with controlled multi-region writes\n- Data residency via region-specific routing and Private Endpoints\n- Global routing with Front Door and secure exposure\n\n## Code Example\n\n```javascript\n// Pseudo: acquire idempotency key, check store, and proceed with orchestrator\nconst id = req.headers['x-idempotency-key'];\nconst seen = await cosmos.find({ id, partitionKey: idTenant(req) });\nif (seen) return { status: 200, body: seen.result };\nawait durableClient.startNew('Orchestrator', { id, tenant: req.tenant, payload: req.body });\n```\n\n## Follow-up Questions\n\n- How would you test idempotency guarantees across regions?\n- Which failure scenarios require compensating actions and how would you implement them?","diagram":"flowchart TD\n  A[Client Calls API] --> B[APIM Region A]\n  A --> C[APIM Region B]\n  B --> D[Durable Functions Orchestrator]\n  C --> D\n  D --> E[Cosmos DB per-Tenant in Residency Region]\n  D --> F[Event Grid for Tenant Events]\n  E --> G[Private Endpoints & Front Door]\n  F --> G","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Oracle","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T15:37:44.877Z","createdAt":"2026-01-13T15:37:44.877Z"},{"id":"q-1539","question":"Design a real-time, multi-tenant analytics pipeline for a chat platform: events arrive at 5-10k msgs/sec total via Azure Event Hubs; process with Azure Databricks on Delta Lake stored in ADLS Gen2; governance via Unity Catalog; ensure strict per-tenant isolation, auditability, and exactly-once processing; TTL/retention; cross-region read; cost constraints. Describe architecture decisions, data layouts, and failure scenarios?","answer":"Proposed architecture: Ingest events from Azure Event Hubs into Delta Lake tables on ADLS Gen2 using Databricks Structured Streaming. Ensure exactly-once processing through idempotent writes leveraging unique event_id identifiers. Enforce strict tenant isolation by implementing dedicated schemas per tenant within Unity Catalog, complemented by row-level security using tenant_id columns. Configure TTL and retention through Delta Lake's OPTIMIZE and VACUUM operations, enable cross-region reads via Azure's geo-redundant storage, and optimize costs with Databricks autoscaling and spot instances. Implement comprehensive audit logging through Unity Catalog's access controls and Delta Lake's transaction logs.","explanation":"## Why This Is Asked\nThis tests knowledge of real-time data pipelines, Azure Databricks, and data governance in multi-tenant contexts.\n\n## Key Concepts\n- Durable ingestion and exactly-once processing with Structured Streaming and Delta Lake\n- Unity Catalog RBAC and per-tenant isolation (tenant_id, dedicated schemas)\n- Row-level security and auditability with Unity Catalog logs\n- TTL/retention, Vacuum, and cost-aware autoscaling\n\n## Code Example\n```sql\nMERGE INTO delta_table AS target\nUSING staging AS source\nON target.event_id = source.event_id\nWHEN MATCHED THEN UPDATE SET *\nWHEN NOT MATCHED THEN INSERT *\n```","diagram":"flowchart TD\n  A[Event Hubs] --> B[Databricks Structured Streaming]\n  B --> C[Delta Lake (ADLS Gen2)]\n  C --> D[Unity Catalog Governance]\n  D --> E[RBAC/RLS per Tenant]\n  C --> F[Audit Logs]\n  F --> G[TTL & Vacuum]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Discord","Microsoft"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:32:48.345Z","createdAt":"2026-01-13T20:54:39.547Z"},{"id":"q-1565","question":"Design a zero-trust, per-tenant access model to a private Azure SQL Database from a microservices mesh. Use Azure AD, Managed Identities, Row-Level Security, and dynamic data masking. Explain how you enforce least privilege, tenant isolation, auditing, and how you validate access policies in CI/CD?","answer":"Implement Row-Level Security (RLS) on Azure SQL with a predicate function that returns TRUE when @TenantId = USER_CONTEXT(N'TenantId'); map each service identity to a SQL user restricted to its tenant's rows. Enable dynamic data masking on sensitive columns, configure Azure AD authentication with Managed Identities, and set up SQL Database auditing to log all access attempts. Enforce least privilege by granting only necessary permissions to each service identity and validate access policies through automated tests in CI/CD pipelines.","explanation":"## Why This Is Asked\nTests ability to implement per-tenant isolation, security controls, and CI/CD validation in a real Azure SQL setup.\n\n## Key Concepts\n- Zero-trust with per-tenant isolation\n- Row-Level Security and USER_CONTEXT()\n- Managed Identities and least privilege\n- Dynamic data masking and SQL auditing\n- CI/CD policy checks and automated tests\n\n## Code Example\n```sql\nCREATE FUNCTION dbo.fnTenantPredicate(@TenantId int)\nRETURNS TABLE\nWITH SCHEMABINDING\nAS RETURN SELECT 1 AS access WHERE @TenantId = CAST(USER_CONTEXT(N'TenantId') AS int);\n\nCREATE SECURITY POLICY dbo.TenantPolicy\nADD FILTER PREDICATE dbo.fnTenantPredicate(TenantId) ON dbo.YourTable,\nADD BLOCK PREDICATE dbo.fnTenantPredicate(TenantId) ON dbo.YourTable;\n```","diagram":"flowchart TD\n  A[Service] --> B[Managed Identity]\n  B --> C[Azure SQL with RLS]\n  C --> D[Audit Log]\n  C --> E[Masked Columns]","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Discord","Google","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T06:18:28.116Z","createdAt":"2026-01-13T21:50:51.430Z"},{"id":"q-1594","question":"You're building a real-time, multi-tenant feature-flag platform on Azure to serve traffic across three regions with sub-50ms evaluation latency. Each tenant has per-flag rules, canary/A/B experiments, and strict audit requirements. Outline end-to-end design: data model for flags and experiments, evaluation path, storage choices (Cosmos DB vs SQL), caching, event sourcing, cross-region synchronization, security (Managed Identities, Key Vault, RBAC), rollback strategy, and failure modes. Include how you'd test canary safety and ensure tenant isolation?","answer":"Two-tier architecture: fast in-region evaluation with central governance. Store versioned flags in Cosmos DB with multi-region replication; cache per-region in Redis Enterprise; evaluate via deterministic hash-based routing for canary experiments.","explanation":"## Why This Is Asked\nTests ability to design low-latency, multi-tenant feature-flag systems on Azure, integrating multiple services and making informed trade-offs.\n\n## Key Concepts\n- Low-latency, region-local evaluation path\n- Multi-region replication and canary experiments\n- Versioned data model for flags/experiments\n- Secure access via Managed Identities and Key Vault\n- Auditability with Event Hubs to ADLS Gen2\n\n## Code Example\n```javascript\nfunction selectFlag(userId, tenantId, flagVersion, canary) { \n  const key = `${tenantId}:${userId}:${flagVersion}`;\n  const bucket = hash(key) % 100;\n```","diagram":"flowchart TD\n A[Client Request] --> B[API Gateway]\n B --> C[Region Redis Cache]\n C --> D[Flag Service (Cosmos DB)]\n D --> E[Evaluation Engine]\n E --> F[Response]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Citadel","DoorDash"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:34:33.777Z","createdAt":"2026-01-13T23:29:11.837Z"},{"id":"q-1620","question":"You're architecting a **multi-region telemetry ingestion** pipeline for a real-time fraud-detection service. Edge devices per region push JSON events to **Azure IoT Hub**; you must ingest, partition by tenant, store raw and processed results with exact-once semantics, and enforce strict per-tenant isolation and auditability within tight cost constraints. Propose architecture choices (IoT Hub, **Event Hubs**, **Delta Lake**, **Unity Catalog**, **Cosmos DB**), data layout, and failure modes; how would you test end-to-end dedup and cross-region replayability?","answer":"Use a shared Event Hub with tenantId as the partition key; cross-region replication via paired namespaces; Spark Structured Streaming into Delta Lake with transactionId dedup for exactly-once; store raw events in Delta Lake with tenant-specific paths, processed results in Cosmos DB with tenant isolation, and enforce governance through Unity Catalog with row-level security.","explanation":"Why This Is Asked\n- Tests end-to-end thinking for cross-region telemetry pipelines with strict isolation, auditability, and exactly-once guarantees.\n- Evaluates choice of Azure services, data layouts, and governance patterns under cost constraints.\n\nKey Concepts\n- Tenant isolation and data governance in a shared data plane\n- Exactly-once processing across streaming and lakehouse layers\n- Partitioning strategy and cross-region replication\n- Durable deduplication and auditing mechanisms\n\nCode Example\n```python\n# PySpark pseudo-code for deduplication in a streaming Delta Lake sink\nfrom pyspark.sql.functions import col\nfrom delta.tables import DeltaTable\n\ndef dedup_streaming_batch(df, batch_id):\n    delta_table = DeltaTable.forPath(spark, \"/raw/telemetry\")\n    (delta_table.alias(\"target\")\n     .merge(df.alias(\"source\"), \"source.transactionId = target.transactionId\")\n     .whenNotMatchedInsertAll()\n     .execute())\n```","diagram":null,"difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T04:02:16.999Z","createdAt":"2026-01-14T02:45:10.285Z"},{"id":"q-1668","question":"You’re building a beginner Azure Function (HTTP trigger) that calls a 3rd‑party API. Do not store API keys in code or app settings. How would you securely fetch the API key at runtime from Azure Key Vault using a managed identity? Outline the steps to enable the identity, grant access, and provide a minimal code snippet to read the secret?","answer":"Enable the Function App's system-assigned managed identity and grant it Key Vault Secrets Reader on the vault. In code, read the secret with DefaultAzureCredential and SecretClient, then use it in the","explanation":"## Why This Is Asked\nThis tests practical credential management in Azure: using managed identities, granting least privilege, and runtime secret retrieval to avoid embedding keys.\n\n## Key Concepts\n- Managed Identity (system-assigned)\n- Azure Key Vault Secrets Reader\n- Azure.Identity DefaultAzureCredential\n- Azure.Security.KeyVault.Secrets SecretClient\n- Avoiding secret provisioning in config\n\n## Code Example\n```csharp\nusing Azure.Identity;\nusing Azure.Security.KeyVault.Secrets;\nvar cred = new DefaultAzureCredential();\nvar client = new SecretClient(new Uri(\"https://<vault>.vault.azure.net/\"), cred);\nvar apiKey = (await client.GetSecretAsync(\"ApiKey\")).Value.Value;\n```\n\n## Follow-up Questions\n- How would you handle secret rotation and cache expiration?\n- How would you secure the Key Vault access policy for multiple environments (dev/stage/prod)?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["LinkedIn","Slack"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T05:51:55.453Z","createdAt":"2026-01-14T05:51:55.453Z"},{"id":"q-1727","question":"You're building a polyglot Azure-based service with HTTP APIs, background workers, and a data lake. You need end-to-end tracing across Functions, AKS, and Databricks jobs using OpenTelemetry and a single trace across services. Describe how you'd implement tracing, propagate context, and collect/export to Azure Monitor, including sampling strategy and validation steps?","answer":"Instrument Functions, AKS, and Databricks with OpenTelemetry. Use W3C TraceContext propagation; carry traceparent across HTTP, queues, and Delta Lake jobs. Export spans via OTLP to Azure Monitor (Log ","explanation":"## Why This Is Asked\nEvaluate ability to implement observability across heterogeneous runtimes in Azure, with end-to-end tracing and cross-service propagation.\n\n## Key Concepts\n- OpenTelemetry across Functions, AKS, Databricks\n- W3C TraceContext; OTLP exporting to Azure Monitor\n- Context propagation through queues and Delta Lake\n- Sampling strategies and trace retention\n\n## Code Example\n```javascript\nconst { trace, context, propagation } = require('@opentelemetry/api');\nconst { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');\nconst { SimpleSpanProcessor } = require('@opentelemetry/sdk-trace-base');\nconst { OTLPTraceExporter } = require('@opentelemetry/exporter-otlp-http');\n\nconst provider = new NodeTracerProvider();\nconst exporter = new OTLPTraceExporter({ url: 'https://<region>.monitor.azure.com/v1/traces' });\nprovider.addSpanProcessor(new SimpleSpanProcessor(exporter));\nprovider.register();\n\nmodule.exports = async function (context, req) {\n  const tracer = trace.getTracer('example-function');\n  const span = tracer.startSpan('http-request');\n  // downstream calls propagate context automatically when using OpenTelemetry API\n  span.end();\n  return { status: 200, body: 'OK' };\n};\n```\n\n## Follow-up Questions\n- How would you test end-to-end traces across services?\n- How would you adjust sampling in production without outages?","diagram":"flowchart TD\n  A[Azure Function] --> B[OpenTelemetry Span]\n  B --> C[OTLP Exporter]\n  A --> D[AKS services]\n  D --> E[Databricks jobs]","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Databricks","Meta","Zoom"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T08:46:16.131Z","createdAt":"2026-01-14T08:46:16.131Z"},{"id":"q-1791","question":"You're building an Azure-native, multi-tenant data platform for real-time payments used by PayPal and Tesla. Ingest via Event Hubs, process with AKS and Functions, store in Delta Lake on ADLS Gen2, expose a data API. How would you enforce strict per-tenant isolation, achieve end-to-end exactly-once semantics across services, and implement a shadow-traffic ML model deployment with safe rollback and audit trails? Include architecture choices, data layouts, and failure modes?","answer":"Per-tenant isolation via Delta Lake databases per tenant managed by Unity Catalog with VNet-protected ADLS Gen2; exactly-once via outbox pattern: commit row then deduplicated sink to Delta Lake, struc","explanation":"## Why This Is Asked\nInterview context explanation.\n\n## Key Concepts\n- Per-tenant isolation with Delta Lake, Unity Catalog, and network controls\n- Exactly-once semantics via outbox + idempotent sinks + structured streaming\n- Shadow ML deployment with traffic-splitting and rollback\n- Governance with Purview lineage\n\n## Code Example\n```javascript\n// Pseudo outbox transaction\nasync function handleEvent(evt) {\n  await db.insert({table: 'outbox', ...evt});\n  await writeToDeltaLake(evt); // idempotent\n}\n```\n\n## Follow-up Questions\n- How would you validate end-to-end exactly-once guarantees?\n- How would you enforce tenant RBAC across all data paths?","diagram":"flowchart TD\nA[Event Hubs intake] --> B[AKS/Functions processing]\nB --> C[Delta Lake per tenant] --> D[Data API]\nD --> E[Purview lineage]\nF[Azure ML Shadow Model] --> G[Traffic split 5-10%]\nG --> H[Latency/Accuracy metrics]\nH --> I[Promote or rollback]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["PayPal","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T10:52:31.948Z","createdAt":"2026-01-14T10:52:31.948Z"},{"id":"q-1839","question":"You're building an Azure IoT telemetry platform for a global fleet. Devices send 20–30k events/sec to IoT Hub. You need per-tenant isolation, real-time enrichment (geolocation, device type), and fan-out to three sinks: Delta Lake on ADLS Gen2, Azure Data Explorer dashboards, and an AI inference service on AKS. Must guarantee at-least-once semantics, handle out-of-order data, and support cross-region DR with measurable RPO. Compare two architectures: (A) serverless micro-batch: IoT Hub → Event Hubs → Functions for lightweight enrichment; Spark Structured Streaming writes to Delta Lake on ADLS Gen2; sinks feed Data Explorer and AKS inference. (B) pure streaming: Event Hubs → Spark Structured Streaming with larger cluster, stricter SLAs, and end-to-end exactly-once semantics. Explain data models, failure modes, and governance?","answer":"Two architectures: (A) micro-batch: IoT Hub → Event Hubs → Functions for lightweight enrichment; Spark Structured Streaming to Delta Lake on ADLS Gen2; feeds to Data Explorer and AKS inference; per-te","explanation":"## Why This Is Asked\nTests the ability to design scalable IoT pipelines with per-tenant isolation and multi-sink consumption. It also probes idempotent processing, dedup, and cross-region DR.\n\n## Key Concepts\n- IoT Hub, Event Hubs, and Spark Structured Streaming\n- Delta Lake on ADLS Gen2, Azure Data Explorer, AKS inference\n- Per-tenant isolation via managed identities and resource tagging\n- Exactly-once vs at-least-once semantics, dedup, watermarking\n- DR and RPO considerations\n\n## Code Example\n```javascript\n// Example foreachBatch to ensure idempotent writes\nfunction foreachBatch(batch, batchId) {\n  const dedup = batch.dropDuplicates(['event_id'])\n  dedup.write.format('delta').mode('append').save('/mnt/delta/events')\n}\n```\n\n## Follow-up Questions\n- How to handle out of order events? \n- How would you implement per-tenant data segregation in storage and compute?","diagram":"flowchart TD\n  A[IoT Hub Ingest] --> B[Event Hubs]\n  B --> C[Enrichment (Functions / Spark)]\n  C --> D1[Delta Lake (ADLS Gen2)]\n  C --> D2[Azure Data Explorer]\n  C --> D3[AKS Inference Service]\n  D1 --> E[Cross-region DR]\n  D2 --> E\n  D3 --> E","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Google","Netflix"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T13:24:17.847Z","createdAt":"2026-01-14T13:24:17.847Z"},{"id":"q-1962","question":"You’re building a beginner Azure Function (HTTP trigger) that receives event payloads and stores them in a data container. Design a lightweight, auditable approach to log every write without slowing latency. Include how you would generate an immutable audit trail and what storage pattern you’d use. Provide a minimal code snippet to append an audit line with timestamp, eventId, and userId derived from Authorization header?","answer":"Use an HTTP-triggered Function on the Consumption plan that writes to a data container and appends a separate line to an immutable audit blob in the same storage account. Extract userId from a JWT in ","explanation":"## Why This Is Asked\nTests the ability to design lightweight auditing with low latency using Append Blobs and JWT parsing; demonstrates immutability, data-audit separation, and basic error handling.\n\n## Key Concepts\n- Append Blob usage for immutable, append-only logs\n- JWT payload extraction from Authorization header\n- Per-event audit entries with timestamp and eventId\n- Resilient writes with basic retry/backoff\n\n## Code Example\n```javascript\n// Minimal Azure Function snippet (TypeScript)\nimport { ContainerClient, AppendBlobClient } from \"@azure/storage-blob\";\nconst containerClient = new ContainerClient(\"<storage-url>\", new DefaultAzureCredential());\nexport async function run(context, req){\n  const auth = req.headers[\"authorization\"] ?? \"\";\n  const token = auth.split(\" \")[1] ?? \"\";\n  const payload = JSON.parse(Buffer.from(token.split(\".\")[1], 'base64').toString());\n  const userId = payload?.sub ?? \"anonymous\";\n  const eventId = req.body?.eventId ?? crypto.randomUUID();\n  const line = JSON.stringify({ ts: new Date().toISOString(), eventId, userId, status: 'received' }) + \"\\n\";\n  const audit = containerClient.getAppendBlobClient(\"audit.log\");\n  await audit.appendBlock(line, line.length);\n  context.res = { status: 200, body: { eventId } };\n}\n```\n\n## Follow-up Questions\n- How would you extend this to handle audit log rotation or retention?\n- How would you enforce per-tenant isolation for audits?\n","diagram":"flowchart TD\nA[HTTP Trigger] --> B[Write Data Blob]\nA --> C[Append Audit Log]\nC --> D[Audit blob in same storage account]\nB --> E[Return eventId]","difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T18:56:50.374Z","createdAt":"2026-01-14T18:56:50.374Z"},{"id":"q-1995","question":"Describe how you would implement a timer-triggered Azure Function that runs every 15 minutes to poll an on‑prem REST endpoint and write a daily aggregation blob to Azure Blob Storage. How would you guarantee idempotent writes to avoid duplicates across retries, including blob naming strategy and a minimal check-then-write code pattern?","answer":"Use a TimerTrigger Azure Function (every 15 minutes) to fetch 15‑minute metrics, compute a window key like 20260114-0915, and write a single blob named agg-20260114-0915.json. Before writing, check fo","explanation":"## Why This Is Asked\nThis probes practical use of Timer triggers, external data polling, and robust idempotent writes to object storage, a common beginner scenario with real-world reliability concerns.\n\n## Key Concepts\n- Timer-triggered functions and external REST calls\n- Idempotent writes and atomic blob operations\n- Blob naming for time-windowed aggregates\n- Concurrency, retries, and race condition handling\n\n## Code Example\n```csharp\nvar container = blobServiceClient.GetBlobContainerClient(\"metrics\");\nawait container.CreateIfNotExistsAsync();\nstring blobName = $\"agg-{start:yyyyMMdd-HHmm}.json\";\nBlobClient blob = container.GetBlobClient(blobName);\nif (!await blob.ExistsAsync())\n{\n    using var stream = new MemoryStream(Encoding.UTF8.GetBytes(payload));\n    await blob.UploadAsync(stream, new BlobHttpHeaders { ContentType = \"application/json\" });\n}\n```\n\n## Follow-up Questions\n- How would you handle idempotency if multiple function instances run concurrently?\n- How would you ensure correct window alignment across time zones and daylight saving changes?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Cloudflare","Plaid","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-14T19:50:29.731Z","createdAt":"2026-01-14T19:50:29.731Z"},{"id":"q-2059","question":"Design an Azure-native data export service for a fintech that must export per-customer data on demand and on a schedule, with strict data residency, consent checks, and an audit trail. Use ADLS Gen2, Cosmos DB, Event Grid, Durable Functions or Functions, and Key Vault. Explain data partitioning, encryption, access control, idempotency, and failure modes including retries, outages, and rollback. Provide a concrete data model and flow?","answer":"A Durable Functions orchestrator triggers per-customer export jobs after validating consent in Cosmos DB. Data is read from source tables, streamed to ADLS Gen2 under tenant-specific prefixes, encrypted with customer-managed keys from Key Vault, and logged to an immutable audit trail. The system ensures idempotency through request deduplication and status tracking, handles failures with exponential backoff and circuit breakers, and maintains data residency through region-specific deployments.","explanation":"## Why This Is Asked\nThis question evaluates real-world enterprise concerns: per-customer data exports, consent management, data residency compliance, auditability, and failure handling within Azure-native architectures.\n\n## Key Concepts\n- Durable Functions orchestration patterns and idempotency\n- Customer-managed keys (CMK) with Azure Key Vault\n- Consent management and compliance workflows\n- Immutable audit logging and cross-region replication\n- Tenant-based data partitioning and AAD access control\n\n## Code Example\n```javascript\n// Pseudo: orchestrator outline\n```\n\n## Follow-up Questions\n- How would you handle large-scale concurrent exports?\n- What monitoring and alerting strategies would you implement?\n- How do you ensure data consistency during partial failures?\n- What strategies would you use for cost optimization?","diagram":"flowchart TD\n  A[Request export] --> B{Consent?}\n  B -- Yes --> C[Orchestrator (Durable Functions)]\n  C --> D[Read Source Data]\n  D --> E[Write to ADLS Gen2 (tenant prefix)]\n  E --> F[Encrypt with CMK (Key Vault)]\n  F --> G[Audit in Cosmos + immutable logs]\n  B --> H[Handle Denial]\n  G --> I[Retry/rollback]","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Goldman Sachs","Robinhood","Stripe"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:50:43.792Z","createdAt":"2026-01-14T22:47:07.627Z"},{"id":"q-2109","question":"You're building a real-time moderation pipeline for a global social app on Azure. Ingest flows via Azure Event Hubs at 20-40k msgs/sec, then you apply NLP classification in a chain of Functions (or Durable Functions) to flag policy-violating messages, store results in Cosmos DB with per-tenant isolation, and index metadata in Azure Cognitive Search for fast queries. How would you design for latency under 150ms per event, strict per-tenant data isolation, idempotent retries, and auditable trails across services? Include error handling and rollback strategies?","answer":"Leverage Azure Event Hubs with Durable Functions orchestrator to sequence the pipeline: classify, persist, and index. Partition Cosmos DB by tenant for strict data isolation, and create per-tenant Azure Cognitive Search indexes. Implement messageId-based idempotency and establish cross-service error handling with dead-letter queues for failed events.","explanation":"## Why This Is Asked\nTests practical multi-service orchestration, data isolation, and end-to-end reliability in Azure cloud environments.\n\n## Key Concepts\n- Durable Functions orchestrations for reliable workflow management\n- Idempotent writes using messageId-based deduplication\n- Per-tenant partitioning for strict data isolation\n- Cross-service error handling with dead-letter queues\n- Event-driven architecture with proper retry mechanisms\n\n## Code Example\n```javascript\n// Azure Function snippet: upsertCosmos(message)\nconst { CosmosClient } = require('@azure/cosmos');\nconst client = new CosmosClient(process.env.COSMOS_ENDPOINT);\n```","diagram":"flowchart TD\n  EH[Event Hubs] --> OF[Durable Functions orchestrator]\n  OF --> CD[Cosmos DB (Tenant partition key)]\n  OF --> CS[Search Index per tenant]\n  CD --> AUD[Audit log]","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Amazon","Plaid"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T04:58:58.598Z","createdAt":"2026-01-15T02:21:13.266Z"},{"id":"q-2155","question":"You're building a tenant-aware API gateway on Azure that serves dozens of microservices for hundreds of tenants. Implement per-tenant quotas, latency budgets, and canary rollouts. Describe a concrete architecture using Azure API Management, Azure Front Door, Redis for rate-limiting, and per-tenant state in Cosmos DB or Redis; explain failure modes, rollback, and testing strategies under traffic spikes?","answer":"Implement a tenant-aware API gateway using Azure API Management with a rate-limit-by-key policy keyed on tenant-id, backed by Redis token-bucket counters and Azure Front Door for global routing. Persi","explanation":"## Why This Is Asked\n\nAssesses ability to design a robust, Azure-native API gateway handling per-tenant isolation, dynamic canary deployments, and precise quota controls under load.\n\n## Key Concepts\n\n- Tenant isolation in API Management with per-tenant rate limits\n- Redis-based token-bucket or sliding-window throttling\n- Canary deployments via APIM revisions and feature flags\n- Global routing with Azure Front Door\n- Observability and audit trails in Cosmos DB and Application Insights\n\n## Code Example\n\n```xml\n<policies>\n  <inbound>\n    <rate-limit-by-key calls=\"1000\" renewal-period=\"60\" counter-key=\"@(context.Variables.GetValueOrDefault('tenantId','anonymous'))\" />\n  </inbound>\n</policies>\n```\n\n```lua\n-- Redis Lua example (tenant-scoped bucket)\nlocal key = KEYS[1]\nlocal now = tonumber(ARGV[1])\nlocal capacity = tonumber(ARGV[2])\nlocal refill = tonumber(ARGV[3])\nlocal tokens = tonumber(redis.call('GET', key) or capacity)\nif tokens <= 0 then\n  return {err=\"rate-limited\"}\nelse\n  redis.call('SET', key, tokens-1, 'EX', 60)\n  return {ok, tokens-1}\nend\n```\n\n## Follow-up Questions\n\n- How would you test race conditions in quota counters under high concurrency?\n- How would you monitor and alert on tenant quota breaches without noisy alerts?","diagram":"flowchart TD\n  Client(Client) --> FrontDoor(Azure Front Door)\n  FrontDoor --> APIM(API Management)\n  APIM --> Redis(Redis rate limiter per tenant)\n  Redis --> Backend[Backend microservices]\n  APIM --> CosmosAudit(Audit & events store)\n","difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["IBM","Uber"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-15T05:36:19.391Z","createdAt":"2026-01-15T05:36:19.392Z"},{"id":"q-891","question":"Design a beginner-friendly serverless image-upload API on Azure: clients POST JPEGs to an HTTP-triggered Function, which saves the file to Blob Storage, enqueues a processing job, and stores a metadata record in Cosmos DB. How would you ensure idempotency, handle retries with back-off, and keep costs predictable on a Consumption plan?","answer":"Implement idempotency via an idempotency-key header; persist seen keys in Cosmos DB; on duplicates, return 200 and skip work. Decouple with a queue; HTTP function enqueues, blob saved. Processing func","explanation":"## Why This Is Asked\n\nTests practical serverless data flow, idempotency, and cost control in Azure. It also touches inter-service communication and observability.\n\n## Key Concepts\n\n- Idempotent HTTP endpoints using an idempotency key\n- Decoupling with HTTP → Blob → Queue → Worker\n- Cosmos DB for idempotency store and metadata\n- Retry/backoff and dead-lettering\n- Cost-conscious design on Consumption plan\n\n## Code Example\n\n```javascript\n// Skeleton: HTTP trigger checks idempotency key, writes blob, enqueues, and stores metadata\nmodule.exports = async function (context, req) {\n  const key = req.headers[\"x-idempotency-key\"];\n  // look up key in Cosmos DB; if exists, return 200\n  // otherwise, save blob, enqueue job, write metadata, and return 202\n};\n```\n\n## Follow-up Questions\n\n- How would you test idempotency guarantees in this flow?\n- What metrics would you collect to validate retry/backoff behavior and cost control?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Salesforce","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:31:34.107Z","createdAt":"2026-01-12T14:31:34.107Z"},{"id":"q-973","question":"Case: You’re building a beginner-friendly Azure API that accepts events from mobile apps. Each event includes userId, eventType, and timestamp. The API should write a compact summary to Cosmos DB and stream raw events to Event Hubs for analytics. On a Consumption plan, outline the minimal architecture, bindings, and error handling to ensure low latency, safe retries, and no data loss during transient outages?","answer":"HTTP-triggered Azure Function validates payload (userId, eventType, timestamp). Store a compact summary in Cosmos DB using a composite id (userId+timestamp) to enforce idempotency, and emit the full e","explanation":"## Why This Is Asked\nTests knowledge of a realistic ingestion path: HTTP input, idempotent storage, and streaming analytics with Azure services, plus the constraints of a Consumption plan.\n\n## Key Concepts\n- HTTP trigger in Azure Functions\n- Cosmos DB best practices for idempotent keys\n- Event Hubs for scalable intake of streams\n- Retry/backoff strategies on Consumption plan\n- Bindings and error handling in serverless architectures\n\n## Code Example\n```javascript\nmodule.exports = async function(context, req) {\n  const body = req.body;\n  // basic validation\n  if (!body?.userId || !body?.eventType || !body?.timestamp) {\n    context.res = { status: 400, body: 'Invalid payload' };\n    return;\n  }\n  const id = `${body.userId}|${body.timestamp}`;\n  // write summary to Cosmos DB (idempotent key)\n  context.bindings.cosmosDoc = { id, userId: body.userId, timestamp: body.timestamp, eventType: body.eventType };\n  // publish raw event to Event Hubs\n  context.bindings.outputEventHub = body;\n  context.res = { status: 202, body: 'Accepted' };\n};\n```\n\n## Follow-up Questions\n- How would you validate and test idempotency in this flow? \n- What metrics would you observe to ensure latency stays low during bursts?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["PayPal","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:37:30.997Z","createdAt":"2026-01-12T17:37:30.997Z"}],"subChannels":["general"],"companies":["Airbnb","Amazon","Citadel","Cloudflare","Databricks","Discord","DoorDash","Goldman Sachs","Google","Hugging Face","IBM","LinkedIn","Lyft","Meta","Microsoft","Netflix","OpenAI","Oracle","PayPal","Plaid","Robinhood","Salesforce","Scale Ai","Slack","Snowflake","Stripe","Tesla","Uber","Zoom"],"stats":{"total":21,"beginner":6,"intermediate":8,"advanced":7,"newThisWeek":21}}