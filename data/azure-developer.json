{"questions":[{"id":"q-1006","question":"Design a real-time telemetry ingestion pipeline for a fleet of autonomous vehicles on Azure. Events arrive at high volume per region; you must store compact per-vehicle summaries in Cosmos DB and archive raw events to Data Lake Gen2. How would you achieve exactly-once processing for aggregates, sub-200 ms latency, and zero data loss on transient failures? Propose architecture using Event Hubs, Functions, Databricks, and cross-region replication; justify idempotency and retry strategies?","answer":"Implement a pipeline: Ingest events via Event Hubs, process with Databricks Structured Streaming to produce per-vehicle aggregates on a sliding window with watermarking; write to Cosmos DB using idemp","explanation":"## Why This Is Asked\nTests ability to design scalable, fault-tolerant ingest with exactly-once semantics across regions.\n\n## Key Concepts\n- Ingestion via Event Hubs; streaming processing with Databricks; idempotent sinks in Cosmos DB; archive to ADLS Gen2; multi-region writes; retries; dead-lettering.\n\n## Code Example\n```javascript\n// Idempotent upsert for aggregate sink\nconst key = vehicleId + '|' + windowEnd;\nawait container.items.upsert({ id: key, vehicleId, windowEnd, sum, count, ts: Date.now() });\n```\n\n## Follow-up Questions\n- How would you test exactly-once semantics under backpressure? \n- What monitoring would you add for cross-region latency and data loss?","diagram":"flowchart TD\nA[Event Hubs ingress] --> B[Databricks Structured Streaming]\nB --> C[Cosmos DB upsert: id=vehicleId|windowEnd]\nA --> D[ADLS Gen2 Archive via Capture]\nC --> E[Multi-region Cosmos Writes]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Lyft","Slack","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T18:51:22.684Z","createdAt":"2026-01-12T18:51:22.684Z"},{"id":"q-1136","question":"Design an end-to-end telemetry ingestion pipeline for 1M devices/min delivering messages {vehicleId, ts, lat, lon, speed}. Ingest via HTTPS into Event Hubs with vehicleId as partition key, process with a Function app (Event Hubs trigger) using batchSize=100; deduplicate per vehicle with Durable Entity and upsert to Cosmos DB multi-region. Explain data model, idempotency, Change Feed, backpressure, and monitoring?","answer":"Event Hubs partitioned by vehicleId; Functions with Event Hubs trigger (batchSize 100, prefetch 300) writes upserts to Cosmos DB (multi-region) and uses a per-vehicle Durable Entity to deduplicate, pr","explanation":"## Why This Is Asked\nTests ability to design scalable, fault-tolerant ingest with exactly-once semantics on Cosmos DB.\n\n## Key Concepts\n- Event Hubs partitioning, throughput units\n- Durable Entities for per-vehicle state\n- Cosmos DB multi-region upserts\n- Change Feed for read models and analytics\n- Backpressure, retries, monitoring\n\n## Code Example\n```javascript\n// Pseudo: durable entity for dedupe per vehicle\nclass VehicleState {\n  apply(event) { /* debounce and upsert once */ }\n}\n```\n\n## Follow-up Questions\n- How would you handle schema evolution for vehicle telemetry?\n- How would you validate end-to-end latency under peak loads?","diagram":"flowchart TD\n  Ingest[HTTPS Telemetry] --> EH[Event Hubs]\n  EH --> Fn[Functions (E/H trigger)]\n  Fn --> Cosmos[Cosmos DB (upsert)]\n  Cosmos --> Read[Read Model (Change Feed)]","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Airbnb","Amazon","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T01:25:35.864Z","createdAt":"2026-01-13T01:25:35.864Z"},{"id":"q-1248","question":"Design an end-to-end Azure ingestion pipeline for multi-tenant IoT events: thousands of devices per region send JSON to a gateway, per-tenant aggregates stored in Cosmos DB, raw data archived to Data Lake Gen2. Explain chosen services (Event Hub, Function/Durable Function, Cosmos DB with TTL, Data Lake), how you enforce per-tenant isolation and auditability, and how you achieve exactly-once processing and retry semantics?","answer":"Use Event Hubs in a regional namespace to ingest; route to Durable Functions that implement idempotent writes using a composite key (tenantId, messageId). Cosmos DB with partitionKey=tenantId stores a","explanation":"## Why This Is Asked\nThis tests practical Azure data-pipeline design, multi-tenancy, and reliability in production.\n\n## Key Concepts\n- Event Hubs, Durable Functions, Cosmos DB, Data Lake Gen2\n- Per-tenant partitioning, RBAC, Managed Identities\n- Deduplication, idempotent writes, retry strategies\n\n## Code Example\n```javascript\n// Pseudo Durable Function outline for idempotent processing\n```\n\n## Follow-up Questions\n- How would you test for cross-tenant data leakage?\n- How would you monitor latency and backpressure across regions?","diagram":null,"difficulty":"intermediate","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Amazon","Citadel","Google"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T06:42:46.713Z","createdAt":"2026-01-13T06:42:46.713Z"},{"id":"q-1277","question":"Design a real-time multi-tenant feature-store pipeline on Azure for a high-velocity AI platform. Ingest telemetry events via Event Hubs (tenantId, featureName, value, ts). Build end-to-end streaming with exactly-once semantics, isolation by tenant, and low-latency online reads. Specify concrete components (Event Hubs, Spark Structured Streaming, Cosmos DB with tenantId partition, Redis online store), auditability, TTL, and testing strategy?","answer":"Ingress: Event Hubs (tenantId key). Processing: Spark Structured Streaming with strict checkpointing for exactly-once; writes to Cosmos DB partitioned by tenantId (upsert for idempotence) plus a Redis","explanation":"## Why This Is Asked\nAssess ability to architect multi-tenant streaming systems on Azure with strong data isolation, idempotence, and end-to-end correctness.\n\n## Key Concepts\n- Event Hubs + Spark Structured Streaming\n- Cosmos DB partitioning by tenantId\n- Upsert semantics for idempotence\n- Redis as online store for latency\n- Audit/logging, TTL, RBAC and data isolation\n\n## Code Example\n```javascript\n// Pseudocode for upsert into Cosmos DB to preserve idempotence\nfunction saveFeature(tenantId, key, value, timestamp) {\n  const doc = { id: `${tenantId}:${key}`, tenantId, key, value, ts: timestamp };\n  cosmos.upsertItem(doc);\n}\n```\n\n## Follow-up Questions\n- How would you test end-to-end with replay and fault injection?\n- How would you enforce data retention, privacy, and tenant isolation in practice?","diagram":"flowchart TD\n  A[Event Ingest] --> B[Spark Structured Streaming]\n  B --> C[Cosmos DB (tenantId PK)]\n  B --> D[Redis Online Store]\n  C --> E[Audit Log / Changelog]\n  D --> E","difficulty":"advanced","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Google","Hugging Face","OpenAI"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T07:40:49.401Z","createdAt":"2026-01-13T07:40:49.401Z"},{"id":"q-1359","question":"A small API running on Azure Functions must securely retrieve a database connection string from Azure Key Vault at startup and refresh it periodically without restarting the function. Propose a beginner-friendly, low-latency approach using Managed Identity and Key Vault, including caching strategy, rotation handling, and error fallback?","answer":"Use a single Function App with a managed identity to fetch the connection string from Key Vault via SecretClient. Cache the secret in-memory with a short TTL (5–10 minutes) and refresh via a timer-bas","explanation":"## Why This Is Asked\nTests ability to combine cloud identity, secret management, and cache-based freshness in a simple serverless setup. It also probes handling secret rotation with minimal downtime.\n\n## Key Concepts\n- Managed Identity and Key Vault access\n- Secret retrieval patterns and in-memory caching\n- Cache invalidation and rotation handling\n- Error fallback and observability\n\n## Code Example\n```javascript\nimport { SecretClient } from \"@azure/keyvault-secrets\";\nimport { DefaultAzureCredential } from \"@azure/identity\";\n\nconst credential = new DefaultAzureCredential();\nconst vaultUrl = process.env.KEY_VAULT_URL;\nconst client = new SecretClient(vaultUrl, credential);\nlet cachedConnStr = null;\nlet cacheExpiry = 0;\n\nasync function loadConnStr() {\n  const secret = await client.getSecret(\"DbConnectionString\");\n  cachedConnStr = secret.value;\n  cacheExpiry = Date.now() + 10 * 60 * 1000; // 10 minutes\n  return cachedConnStr;\n}\n```\n\n## Follow-up Questions\n- How would you simulate and test secret rotation without impacting users?\n- How would you scale this in a multi-instance Function App deployment?\n- What changes if Key Vault is temporarily unavailable?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["OpenAI","Salesforce","Snowflake"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-13T13:13:54.965Z","createdAt":"2026-01-13T13:13:54.965Z"},{"id":"q-891","question":"Design a beginner-friendly serverless image-upload API on Azure: clients POST JPEGs to an HTTP-triggered Function, which saves the file to Blob Storage, enqueues a processing job, and stores a metadata record in Cosmos DB. How would you ensure idempotency, handle retries with back-off, and keep costs predictable on a Consumption plan?","answer":"Implement idempotency via an idempotency-key header; persist seen keys in Cosmos DB; on duplicates, return 200 and skip work. Decouple with a queue; HTTP function enqueues, blob saved. Processing func","explanation":"## Why This Is Asked\n\nTests practical serverless data flow, idempotency, and cost control in Azure. It also touches inter-service communication and observability.\n\n## Key Concepts\n\n- Idempotent HTTP endpoints using an idempotency key\n- Decoupling with HTTP → Blob → Queue → Worker\n- Cosmos DB for idempotency store and metadata\n- Retry/backoff and dead-lettering\n- Cost-conscious design on Consumption plan\n\n## Code Example\n\n```javascript\n// Skeleton: HTTP trigger checks idempotency key, writes blob, enqueues, and stores metadata\nmodule.exports = async function (context, req) {\n  const key = req.headers[\"x-idempotency-key\"];\n  // look up key in Cosmos DB; if exists, return 200\n  // otherwise, save blob, enqueue job, write metadata, and return 202\n};\n```\n\n## Follow-up Questions\n\n- How would you test idempotency guarantees in this flow?\n- What metrics would you collect to validate retry/backoff behavior and cost control?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["Robinhood","Salesforce","Tesla"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T14:31:34.107Z","createdAt":"2026-01-12T14:31:34.107Z"},{"id":"q-973","question":"Case: You’re building a beginner-friendly Azure API that accepts events from mobile apps. Each event includes userId, eventType, and timestamp. The API should write a compact summary to Cosmos DB and stream raw events to Event Hubs for analytics. On a Consumption plan, outline the minimal architecture, bindings, and error handling to ensure low latency, safe retries, and no data loss during transient outages?","answer":"HTTP-triggered Azure Function validates payload (userId, eventType, timestamp). Store a compact summary in Cosmos DB using a composite id (userId+timestamp) to enforce idempotency, and emit the full e","explanation":"## Why This Is Asked\nTests knowledge of a realistic ingestion path: HTTP input, idempotent storage, and streaming analytics with Azure services, plus the constraints of a Consumption plan.\n\n## Key Concepts\n- HTTP trigger in Azure Functions\n- Cosmos DB best practices for idempotent keys\n- Event Hubs for scalable intake of streams\n- Retry/backoff strategies on Consumption plan\n- Bindings and error handling in serverless architectures\n\n## Code Example\n```javascript\nmodule.exports = async function(context, req) {\n  const body = req.body;\n  // basic validation\n  if (!body?.userId || !body?.eventType || !body?.timestamp) {\n    context.res = { status: 400, body: 'Invalid payload' };\n    return;\n  }\n  const id = `${body.userId}|${body.timestamp}`;\n  // write summary to Cosmos DB (idempotent key)\n  context.bindings.cosmosDoc = { id, userId: body.userId, timestamp: body.timestamp, eventType: body.eventType };\n  // publish raw event to Event Hubs\n  context.bindings.outputEventHub = body;\n  context.res = { status: 202, body: 'Accepted' };\n};\n```\n\n## Follow-up Questions\n- How would you validate and test idempotency in this flow? \n- What metrics would you observe to ensure latency stays low during bursts?","diagram":null,"difficulty":"beginner","tags":["azure-developer"],"channel":"azure-developer","subChannel":"general","sourceUrl":null,"videos":{"shortVideo":null,"longVideo":null},"companies":["PayPal","Scale Ai"],"eli5":null,"relevanceScore":null,"voiceKeywords":null,"voiceSuitable":false,"isNew":true,"lastUpdated":"2026-01-12T17:37:30.997Z","createdAt":"2026-01-12T17:37:30.997Z"}],"subChannels":["general"],"companies":["Airbnb","Amazon","Citadel","Google","Hugging Face","Lyft","OpenAI","PayPal","Robinhood","Salesforce","Scale Ai","Slack","Snowflake","Tesla"],"stats":{"total":7,"beginner":3,"intermediate":1,"advanced":3,"newThisWeek":7}}